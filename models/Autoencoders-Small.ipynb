{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "# reading the ratings data\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv', sep=\",\")\n",
    "\n",
    "ratings_pivot = pd.pivot_table(ratings[['userId', 'movieId', 'rating']], \n",
    "                               values='rating', index='userId', columns='movieId' ).fillna(0)\n",
    "\n",
    "\n",
    "# creating train and test sets\n",
    "X_train, X_test = train_test_split(ratings_pivot, train_size=0.8)\n",
    "# print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.to_csv(\"ratings2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many nodes each layer should have - Depending on the dataset's size\n",
    "movies_size = 9724 #15159 #58099\n",
    "n_nodes_inpl = movies_size\n",
    "n_nodes_hl1  = 256\n",
    "n_nodes_outl = movies_size\n",
    "\n",
    "# first hidden layer has 9723*256 weights and 256 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1, n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1, n_nodes_outl]))}\n",
    "\n",
    "input_layer = tf.placeholder('float', [None, movies_size])\n",
    "\n",
    "input_layer_const = tf.fill([tf.shape(input_layer)[0], 1], 1.0)\n",
    "input_layer_concat = tf.concat([input_layer, input_layer_const], 1)\n",
    "\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat, hidden_1_layer_vals['weights']))\n",
    "\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1], 1.0)\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "\n",
    "output_layer = tf.matmul(layer_concat, output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, movies_size])\n",
    "meansq = tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "\n",
    "learn_rate = 0.1   # learning rate\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)\n",
    "\n",
    "# initializing variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "writer.close()\n",
    "sess.run(init)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with one hidden layer\n",
    "\n",
    "![autoencoder with one layer](Images/autoencoders-1layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.2658078166941795 MSE test 12.77324684168542\n",
      "MAE train 1.739454665773725 MAE test 2.5067948726481464\n",
      "Epoch 0 / 10000 loss: 16.921318531036377\n",
      "MSE train 6.2656228215758825 MSE test 12.77315053670004\n",
      "MAE train 1.7394266726656857 MAE test 2.506788905793955\n",
      "Epoch 1 / 10000 loss: 16.92067265510559\n",
      "MSE train 6.265449999953294 MSE test 12.772911752894911\n",
      "MAE train 1.7394012218811732 MAE test 2.506760795879351\n",
      "Epoch 2 / 10000 loss: 16.91995644569397\n",
      "MSE train 6.265265039930655 MSE test 12.77281569200617\n",
      "MAE train 1.7393732348855884 MAE test 2.5067548564032105\n",
      "Epoch 3 / 10000 loss: 16.91930890083313\n",
      "MSE train 6.26509224530624 MSE test 12.772576907063376\n",
      "MAE train 1.7393477901656602 MAE test 2.5067267572478404\n",
      "Epoch 4 / 10000 loss: 16.918593883514404\n",
      "MSE train 6.264907233629095 MSE test 12.772480950493577\n",
      "MAE train 1.7393197957526845 MAE test 2.506720828140125\n",
      "Epoch 5 / 10000 loss: 16.917946338653564\n",
      "MSE train 6.2647345085592185 MSE test 12.772242273577703\n",
      "MAE train 1.7392943600736495 MAE test 2.5066927224650573\n",
      "Epoch 6 / 10000 loss: 16.91723108291626\n",
      "MSE train 6.264549537885551 MSE test 12.772146368253702\n",
      "MAE train 1.7392663671270834 MAE test 2.50668679977025\n",
      "Epoch 7 / 10000 loss: 16.916583776474\n",
      "MSE train 6.264376758147335 MSE test 12.77190793773868\n",
      "MAE train 1.739240924111798 MAE test 2.506658735388003\n",
      "Epoch 8 / 10000 loss: 16.915868520736694\n",
      "MSE train 6.264191738899444 MSE test 12.771812186839634\n",
      "MAE train 1.7392129275023414 MAE test 2.5066528429713077\n",
      "Epoch 9 / 10000 loss: 16.915220737457275\n",
      "MSE train 6.264019001393982 MSE test 12.7715737813577\n",
      "MAE train 1.7391874899219586 MAE test 2.5066247617123487\n",
      "Epoch 10 / 10000 loss: 16.914506435394287\n",
      "MSE train 6.26383409237687 MSE test 12.771478256843933\n",
      "MAE train 1.7391595011261243 MAE test 2.5066188759369674\n",
      "Epoch 11 / 10000 loss: 16.91385817527771\n",
      "MSE train 6.263661360808426 MSE test 12.77123993410038\n",
      "MAE train 1.7391340666612995 MAE test 2.5065908179509493\n",
      "Epoch 12 / 10000 loss: 16.913143634796143\n",
      "MSE train 6.263476373188906 MSE test 12.771144493680527\n",
      "MAE train 1.739106064571194 MAE test 2.5065849553708097\n",
      "Epoch 13 / 10000 loss: 16.91249656677246\n",
      "MSE train 6.263303645412653 MSE test 12.77090630696377\n",
      "MAE train 1.7390806272797044 MAE test 2.5065568961949807\n",
      "Epoch 14 / 10000 loss: 16.911781311035156\n",
      "MSE train 6.263118683874307 MSE test 12.770811148473772\n",
      "MAE train 1.739052635584064 MAE test 2.50655106746302\n",
      "Epoch 15 / 10000 loss: 16.911133527755737\n",
      "MSE train 6.262946043972582 MSE test 12.770573108943461\n",
      "MAE train 1.7390272124315127 MAE test 2.5065230258999587\n",
      "Epoch 16 / 10000 loss: 16.91041851043701\n",
      "MSE train 6.262761080379009 MSE test 12.77047792771286\n",
      "MAE train 1.738999207266139 MAE test 2.5065171882351636\n",
      "Epoch 17 / 10000 loss: 16.90977120399475\n",
      "MSE train 6.262588408430939 MSE test 12.770240129327748\n",
      "MAE train 1.7389737842784583 MAE test 2.506489186083755\n",
      "Epoch 18 / 10000 loss: 16.909055709838867\n",
      "MSE train 6.262403486596156 MSE test 12.770144977620033\n",
      "MAE train 1.7389457809194373 MAE test 2.5064833448447232\n",
      "Epoch 19 / 10000 loss: 16.908408641815186\n",
      "MSE train 6.262230750511866 MSE test 12.769907483569376\n",
      "MAE train 1.738920343829278 MAE test 2.506455382173855\n",
      "Epoch 20 / 10000 loss: 16.90769362449646\n",
      "MSE train 6.262045836604558 MSE test 12.769812547698686\n",
      "MAE train 1.7388923458036658 MAE test 2.5064495694751505\n",
      "Epoch 21 / 10000 loss: 16.907046794891357\n",
      "MSE train 6.261873157727046 MSE test 12.769575128362982\n",
      "MAE train 1.7388669206441278 MAE test 2.506421592320377\n",
      "Epoch 22 / 10000 loss: 16.906331300735474\n",
      "MSE train 6.261688223772145 MSE test 12.769480302883121\n",
      "MAE train 1.7388389200411856 MAE test 2.50641580088527\n",
      "Epoch 23 / 10000 loss: 16.90568447113037\n",
      "MSE train 6.261515582734382 MSE test 12.769243130131484\n",
      "MAE train 1.738813498036664 MAE test 2.5063878614262274\n",
      "Epoch 24 / 10000 loss: 16.90496850013733\n",
      "MSE train 6.261330630702813 MSE test 12.769148492844423\n",
      "MAE train 1.7387854858903784 MAE test 2.5063820893907183\n",
      "Epoch 25 / 10000 loss: 16.904321670532227\n",
      "MSE train 6.261157999061822 MSE test 12.768911379520253\n",
      "MAE train 1.7387600697226842 MAE test 2.50635416063073\n",
      "Epoch 26 / 10000 loss: 16.903606176376343\n",
      "MSE train 6.26097312125613 MSE test 12.768816992433214\n",
      "MAE train 1.7387320658497438 MAE test 2.5063484130238947\n",
      "Epoch 27 / 10000 loss: 16.90295910835266\n",
      "MSE train 6.260800436248035 MSE test 12.768580125345546\n",
      "MAE train 1.7387066481516478 MAE test 2.5063205046606742\n",
      "Epoch 28 / 10000 loss: 16.902244329452515\n",
      "MSE train 6.260615536418694 MSE test 12.768485684182796\n",
      "MAE train 1.7386786350452534 MAE test 2.506314753164507\n",
      "Epoch 29 / 10000 loss: 16.901597023010254\n",
      "MSE train 6.260442870160491 MSE test 12.768248963377044\n",
      "MAE train 1.7386532167852977 MAE test 2.5062868595181507\n",
      "Epoch 30 / 10000 loss: 16.900881052017212\n",
      "MSE train 6.260257943015567 MSE test 12.768154900098247\n",
      "MAE train 1.7386252009928405 MAE test 2.5062811558747846\n",
      "Epoch 31 / 10000 loss: 16.900234699249268\n",
      "MSE train 6.260085285378584 MSE test 12.767918447566911\n",
      "MAE train 1.7385997826802637 MAE test 2.5062532926136014\n",
      "Epoch 32 / 10000 loss: 16.899518489837646\n",
      "MSE train 6.259900377577982 MSE test 12.767824483891449\n",
      "MAE train 1.7385717695907923 MAE test 2.506247592741138\n",
      "Epoch 33 / 10000 loss: 16.89887046813965\n",
      "MSE train 6.259727783670655 MSE test 12.767588345671847\n",
      "MAE train 1.738546361851646 MAE test 2.5062197688372767\n",
      "Epoch 34 / 10000 loss: 16.89815592765808\n",
      "MSE train 6.259542824801471 MSE test 12.767494400466571\n",
      "MAE train 1.7385183337413856 MAE test 2.5062140736960923\n",
      "Epoch 35 / 10000 loss: 16.89750862121582\n",
      "MSE train 6.25937012868799 MSE test 12.767258462182838\n",
      "MAE train 1.7384929151459254 MAE test 2.506186277327445\n",
      "Epoch 36 / 10000 loss: 16.896793365478516\n",
      "MSE train 6.259185252265541 MSE test 12.767164987416564\n",
      "MAE train 1.7384649015338367 MAE test 2.506180641167872\n",
      "Epoch 37 / 10000 loss: 16.896145820617676\n",
      "MSE train 6.259012604596163 MSE test 12.76692902500275\n",
      "MAE train 1.7384394891673498 MAE test 2.5061528245291376\n",
      "Epoch 38 / 10000 loss: 16.89543080329895\n",
      "MSE train 6.258827648286899 MSE test 12.766835504534702\n",
      "MAE train 1.738411455336496 MAE test 2.506147169186435\n",
      "Epoch 39 / 10000 loss: 16.894781827926636\n",
      "MSE train 6.258654961621948 MSE test 12.766600002882823\n",
      "MAE train 1.7383860357809473 MAE test 2.506119407987994\n",
      "Epoch 40 / 10000 loss: 16.89406657218933\n",
      "MSE train 6.258470040034266 MSE test 12.76650675461375\n",
      "MAE train 1.73835801173168 MAE test 2.5061137882107825\n",
      "Epoch 41 / 10000 loss: 16.89341950416565\n",
      "MSE train 6.258297303549025 MSE test 12.76627151497987\n",
      "MAE train 1.7383325875507931 MAE test 2.506086051219095\n",
      "Epoch 42 / 10000 loss: 16.892704010009766\n",
      "MSE train 6.258112412385628 MSE test 12.766178404431365\n",
      "MAE train 1.738304561431971 MAE test 2.506080436374001\n",
      "Epoch 43 / 10000 loss: 16.89205551147461\n",
      "MSE train 6.257939743568196 MSE test 12.765943368491088\n",
      "MAE train 1.7382791497450747 MAE test 2.5060527405256545\n",
      "Epoch 44 / 10000 loss: 16.891339778900146\n",
      "MSE train 6.257754744293929 MSE test 12.765850536719713\n",
      "MAE train 1.7382511061210726 MAE test 2.5060471534114095\n",
      "Epoch 45 / 10000 loss: 16.89069151878357\n",
      "MSE train 6.257582053488507 MSE test 12.765615755663937\n",
      "MAE train 1.7382256980035875 MAE test 2.506019479340312\n",
      "Epoch 46 / 10000 loss: 16.889976978302002\n",
      "MSE train 6.257397108405045 MSE test 12.765523113970536\n",
      "MAE train 1.7381976610369856 MAE test 2.506013914856707\n",
      "Epoch 47 / 10000 loss: 16.88932776451111\n",
      "MSE train 6.257224384953771 MSE test 12.765288441345\n",
      "MAE train 1.7381722436185028 MAE test 2.5059862598775644\n",
      "Epoch 48 / 10000 loss: 16.888611555099487\n",
      "MSE train 6.257039360583193 MSE test 12.765196214227133\n",
      "MAE train 1.7381441921424523 MAE test 2.5059807417243003\n",
      "Epoch 49 / 10000 loss: 16.88796353340149\n",
      "MSE train 6.256866596498431 MSE test 12.764961799149212\n",
      "MAE train 1.738118777224774 MAE test 2.5059531006993447\n",
      "Epoch 50 / 10000 loss: 16.887247800827026\n",
      "MSE train 6.256681584349503 MSE test 12.76486969919947\n",
      "MAE train 1.7380907277208866 MAE test 2.5059476003483714\n",
      "Epoch 51 / 10000 loss: 16.88659906387329\n",
      "MSE train 6.256508837312251 MSE test 12.764635650998219\n",
      "MAE train 1.7380653091495213 MAE test 2.505920001050135\n",
      "Epoch 52 / 10000 loss: 16.885882139205933\n",
      "MSE train 6.25632380077009 MSE test 12.764543761054448\n",
      "MAE train 1.738037253787751 MAE test 2.5059145174861563\n",
      "Epoch 53 / 10000 loss: 16.885234117507935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.256150988467553 MSE test 12.764309784832307\n",
      "MAE train 1.7380118359572154 MAE test 2.5058869229442813\n",
      "Epoch 54 / 10000 loss: 16.884517192840576\n",
      "MSE train 6.25596591242861 MSE test 12.764218397909517\n",
      "MAE train 1.7379837753101453 MAE test 2.5058815149715374\n",
      "Epoch 55 / 10000 loss: 16.883867979049683\n",
      "MSE train 6.2557931219917915 MSE test 12.763984674540872\n",
      "MAE train 1.737958357950136 MAE test 2.5058539550166294\n",
      "Epoch 56 / 10000 loss: 16.88315200805664\n",
      "MSE train 6.2556080149003925 MSE test 12.76389347486571\n",
      "MAE train 1.7379302894178543 MAE test 2.5058485692934953\n",
      "Epoch 57 / 10000 loss: 16.882503032684326\n",
      "MSE train 6.255435097577902 MSE test 12.763660251846296\n",
      "MAE train 1.7379048597242601 MAE test 2.505821070275472\n",
      "Epoch 58 / 10000 loss: 16.881786346435547\n",
      "MSE train 6.255249994285277 MSE test 12.76356910190652\n",
      "MAE train 1.7378767901559997 MAE test 2.505815682254052\n",
      "Epoch 59 / 10000 loss: 16.881137132644653\n",
      "MSE train 6.255077058734904 MSE test 12.763336331357221\n",
      "MAE train 1.7378513602950452 MAE test 2.505788240873297\n",
      "Epoch 60 / 10000 loss: 16.880419969558716\n",
      "MSE train 6.254891920860637 MSE test 12.763245514038855\n",
      "MAE train 1.7378232756740688 MAE test 2.505782884747669\n",
      "Epoch 61 / 10000 loss: 16.879769802093506\n",
      "MSE train 6.254719020462022 MSE test 12.763012737650135\n",
      "MAE train 1.737797857740579 MAE test 2.5057554343583393\n",
      "Epoch 62 / 10000 loss: 16.87905192375183\n",
      "MSE train 6.25453376687916 MSE test 12.762922252879898\n",
      "MAE train 1.7377697597114152 MAE test 2.5057501212042483\n",
      "Epoch 63 / 10000 loss: 16.87840247154236\n",
      "MSE train 6.254360795250259 MSE test 12.76268989798452\n",
      "MAE train 1.7377443329276974 MAE test 2.5057227175052263\n",
      "Epoch 64 / 10000 loss: 16.877684354782104\n",
      "MSE train 6.254175484578734 MSE test 12.762599599908068\n",
      "MAE train 1.737716234689149 MAE test 2.5057174228227286\n",
      "Epoch 65 / 10000 loss: 16.877034425735474\n",
      "MSE train 6.254002469428734 MSE test 12.762367574798395\n",
      "MAE train 1.737690806583152 MAE test 2.5056900533539697\n",
      "Epoch 66 / 10000 loss: 16.87631607055664\n",
      "MSE train 6.253817141533428 MSE test 12.762277587667834\n",
      "MAE train 1.7376626952061751 MAE test 2.5056847865167327\n",
      "Epoch 67 / 10000 loss: 16.87566590309143\n",
      "MSE train 6.253644111137529 MSE test 12.762045725864805\n",
      "MAE train 1.7376372757362766 MAE test 2.505657440898231\n",
      "Epoch 68 / 10000 loss: 16.874947547912598\n",
      "MSE train 6.253458741361709 MSE test 12.76195624023902\n",
      "MAE train 1.73760915748025 MAE test 2.505652249651028\n",
      "Epoch 69 / 10000 loss: 16.874297380447388\n",
      "MSE train 6.253285644632424 MSE test 12.761724662692293\n",
      "MAE train 1.7375837305831114 MAE test 2.505624928810974\n",
      "Epoch 70 / 10000 loss: 16.873578548431396\n",
      "MSE train 6.253100242171001 MSE test 12.761635162917148\n",
      "MAE train 1.7375556116236002 MAE test 2.5056197248356717\n",
      "Epoch 71 / 10000 loss: 16.87292766571045\n",
      "MSE train 6.252927061300864 MSE test 12.761403952421228\n",
      "MAE train 1.7375301802161291 MAE test 2.5055924416895112\n",
      "Epoch 72 / 10000 loss: 16.8722083568573\n",
      "MSE train 6.252741600429312 MSE test 12.761314725323336\n",
      "MAE train 1.7375020514755732 MAE test 2.505587270081951\n",
      "Epoch 73 / 10000 loss: 16.871557474136353\n",
      "MSE train 6.252568427868523 MSE test 12.761083780362931\n",
      "MAE train 1.7374766270075042 MAE test 2.5055600177004944\n",
      "Epoch 74 / 10000 loss: 16.870837211608887\n",
      "MSE train 6.252383012316695 MSE test 12.760994795229072\n",
      "MAE train 1.7374484935527645 MAE test 2.5055548832263472\n",
      "Epoch 75 / 10000 loss: 16.87018632888794\n",
      "MSE train 6.2522097984298055 MSE test 12.760764070180773\n",
      "MAE train 1.7374230829153683 MAE test 2.5055276643908946\n",
      "Epoch 76 / 10000 loss: 16.86946678161621\n",
      "MSE train 6.252024275975301 MSE test 12.760675365219393\n",
      "MAE train 1.7373949414973837 MAE test 2.5055225595976682\n",
      "Epoch 77 / 10000 loss: 16.868814945220947\n",
      "MSE train 6.251851063279537 MSE test 12.76044482870073\n",
      "MAE train 1.7373695304752825 MAE test 2.5054953592525204\n",
      "Epoch 78 / 10000 loss: 16.868096113204956\n",
      "MSE train 6.251665645405487 MSE test 12.76035625185723\n",
      "MAE train 1.7373413980447558 MAE test 2.505490266798602\n",
      "Epoch 79 / 10000 loss: 16.867443799972534\n",
      "MSE train 6.251492367403843 MSE test 12.760125930316317\n",
      "MAE train 1.7373159771883924 MAE test 2.5054630895785692\n",
      "Epoch 80 / 10000 loss: 16.86672329902649\n",
      "MSE train 6.251306910862295 MSE test 12.76003756330758\n",
      "MAE train 1.737287845815792 MAE test 2.505458031406278\n",
      "Epoch 81 / 10000 loss: 16.866072416305542\n",
      "MSE train 6.251133702281737 MSE test 12.759807416186133\n",
      "MAE train 1.737262453339393 MAE test 2.5054308894201403\n",
      "Epoch 82 / 10000 loss: 16.865351915359497\n",
      "MSE train 6.250948265310578 MSE test 12.759719181985963\n",
      "MAE train 1.7372343283165712 MAE test 2.5054258394256514\n",
      "Epoch 83 / 10000 loss: 16.864699840545654\n",
      "MSE train 6.250775163119271 MSE test 12.7594890867104\n",
      "MAE train 1.7372089461076379 MAE test 2.5053987002504448\n",
      "Epoch 84 / 10000 loss: 16.863980293273926\n",
      "MSE train 6.250589749010535 MSE test 12.759400920018239\n",
      "MAE train 1.737180836533811 MAE test 2.505393671689492\n",
      "Epoch 85 / 10000 loss: 16.863328218460083\n",
      "MSE train 6.250416718604761 MSE test 12.759170911032655\n",
      "MAE train 1.7371554742216866 MAE test 2.505366547329544\n",
      "Epoch 86 / 10000 loss: 16.862608671188354\n",
      "MSE train 6.250231381539914 MSE test 12.759082733739266\n",
      "MAE train 1.737127362645444 MAE test 2.5053615112990295\n",
      "Epoch 87 / 10000 loss: 16.86195683479309\n",
      "MSE train 6.2500584979516205 MSE test 12.758852776205833\n",
      "MAE train 1.7371020254539518 MAE test 2.5053343950451676\n",
      "Epoch 88 / 10000 loss: 16.86123752593994\n",
      "MSE train 6.249873276339307 MSE test 12.758764493430997\n",
      "MAE train 1.7370739447524157 MAE test 2.505329368998784\n",
      "Epoch 89 / 10000 loss: 16.860585927963257\n",
      "MSE train 6.249700380953987 MSE test 12.758534469392291\n",
      "MAE train 1.7370485871554278 MAE test 2.5053022375723915\n",
      "Epoch 90 / 10000 loss: 16.859867811203003\n",
      "MSE train 6.2495153713009355 MSE test 12.758446194380163\n",
      "MAE train 1.7370205399610243 MAE test 2.505297213913036\n",
      "Epoch 91 / 10000 loss: 16.85921597480774\n",
      "MSE train 6.249342616747235 MSE test 12.758216139951868\n",
      "MAE train 1.7369952003518592 MAE test 2.5052700972197206\n",
      "Epoch 92 / 10000 loss: 16.85849928855896\n",
      "MSE train 6.2491577213288 MSE test 12.75812767152533\n",
      "MAE train 1.7369671641120759 MAE test 2.50526504848364\n",
      "Epoch 93 / 10000 loss: 16.857848167419434\n",
      "MSE train 6.248985142552837 MSE test 12.7578973854576\n",
      "MAE train 1.7369418325738673 MAE test 2.5052378967001387\n",
      "Epoch 94 / 10000 loss: 16.8571298122406\n",
      "MSE train 6.24880036283303 MSE test 12.757808873695028\n",
      "MAE train 1.7369138196848253 MAE test 2.50523287397446\n",
      "Epoch 95 / 10000 loss: 16.85647940635681\n",
      "MSE train 6.248627931392695 MSE test 12.757578507343005\n",
      "MAE train 1.736888508135099 MAE test 2.5052057291654517\n",
      "Epoch 96 / 10000 loss: 16.85576295852661\n",
      "MSE train 6.2484433353975115 MSE test 12.75748971372315\n",
      "MAE train 1.7368605104204664 MAE test 2.50520068348548\n",
      "Epoch 97 / 10000 loss: 16.855113744735718\n",
      "MSE train 6.248271101988267 MSE test 12.75725930957638\n",
      "MAE train 1.7368352271550587 MAE test 2.5051735526184475\n",
      "Epoch 98 / 10000 loss: 16.854397535324097\n",
      "MSE train 6.248086623246655 MSE test 12.757170379260115\n",
      "MAE train 1.7368072387918745 MAE test 2.505168496571826\n",
      "Epoch 99 / 10000 loss: 16.85374903678894\n",
      "MSE train 6.247914483371706 MSE test 12.756939766776991\n",
      "MAE train 1.7367819540910479 MAE test 2.5051413459528864\n",
      "Epoch 100 / 10000 loss: 16.853033304214478\n",
      "MSE train 6.247730151197552 MSE test 12.756850685764112\n",
      "MAE train 1.7367539690357943 MAE test 2.5051362705703286\n",
      "Epoch 101 / 10000 loss: 16.852384328842163\n",
      "MSE train 6.2475581658918555 MSE test 12.756619913828349\n",
      "MAE train 1.7367286950243142 MAE test 2.5051091179415907\n",
      "Epoch 102 / 10000 loss: 16.851669549942017\n",
      "MSE train 6.247373961018704 MSE test 12.756530596438264\n",
      "MAE train 1.7367007206185296 MAE test 2.505104033899379\n",
      "Epoch 103 / 10000 loss: 16.851021766662598\n",
      "MSE train 6.247202080509926 MSE test 12.756299561865529\n",
      "MAE train 1.7366754573436862 MAE test 2.505076854034274\n",
      "Epoch 104 / 10000 loss: 16.85030722618103\n",
      "MSE train 6.247017982655904 MSE test 12.756210101817388\n",
      "MAE train 1.7366474939880268 MAE test 2.505071756764972\n",
      "Epoch 105 / 10000 loss: 16.849661111831665\n",
      "MSE train 6.246846198781992 MSE test 12.75597906884906\n",
      "MAE train 1.7366222259225232 MAE test 2.5050445755815685\n",
      "Epoch 106 / 10000 loss: 16.848946809768677\n",
      "MSE train 6.246662235523017 MSE test 12.755889434786923\n",
      "MAE train 1.7365942894004909 MAE test 2.5050394792965633\n",
      "Epoch 107 / 10000 loss: 16.848299503326416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.246490570091193 MSE test 12.755658199561882\n",
      "MAE train 1.7365690233064643 MAE test 2.5050122740791565\n",
      "Epoch 108 / 10000 loss: 16.847585678100586\n",
      "MSE train 6.2463066573379695 MSE test 12.75556855600468\n",
      "MAE train 1.736541084916559 MAE test 2.505007177447167\n",
      "Epoch 109 / 10000 loss: 16.846939086914062\n",
      "MSE train 6.246135038349135 MSE test 12.755337334572413\n",
      "MAE train 1.7365158194619423 MAE test 2.504979988675323\n",
      "Epoch 110 / 10000 loss: 16.846225023269653\n",
      "MSE train 6.245951173956051 MSE test 12.755247379174053\n",
      "MAE train 1.7364878851078416 MAE test 2.504974868119119\n",
      "Epoch 111 / 10000 loss: 16.845579385757446\n",
      "MSE train 6.2457796889253565 MSE test 12.75501604462168\n",
      "MAE train 1.736462633720655 MAE test 2.504947675339845\n",
      "Epoch 112 / 10000 loss: 16.844865322113037\n",
      "MSE train 6.2455958579242115 MSE test 12.754926171504442\n",
      "MAE train 1.7364346935668944 MAE test 2.5049425848016766\n",
      "Epoch 113 / 10000 loss: 16.84421968460083\n",
      "MSE train 6.2454243918088705 MSE test 12.75469479118477\n",
      "MAE train 1.7364094427830599 MAE test 2.5049153886153044\n",
      "Epoch 114 / 10000 loss: 16.843507289886475\n",
      "MSE train 6.245240698888329 MSE test 12.75460474820146\n",
      "MAE train 1.7363815174158683 MAE test 2.504910270315168\n",
      "Epoch 115 / 10000 loss: 16.842861890792847\n",
      "MSE train 6.245069243668579 MSE test 12.754373365349414\n",
      "MAE train 1.7363562518700384 MAE test 2.5048830943036027\n",
      "Epoch 116 / 10000 loss: 16.842148303985596\n",
      "MSE train 6.244885558158983 MSE test 12.75428326897798\n",
      "MAE train 1.7363283236827594 MAE test 2.504877979301346\n",
      "Epoch 117 / 10000 loss: 16.84150218963623\n",
      "MSE train 6.244714155016747 MSE test 12.754051892515466\n",
      "MAE train 1.7363030722965258 MAE test 2.5048508083872125\n",
      "Epoch 118 / 10000 loss: 16.840789079666138\n",
      "MSE train 6.244530508113512 MSE test 12.753961817762892\n",
      "MAE train 1.7362751455407708 MAE test 2.504845701228015\n",
      "Epoch 119 / 10000 loss: 16.840144634246826\n",
      "MSE train 6.244359152931768 MSE test 12.753730331240078\n",
      "MAE train 1.7362498956593175 MAE test 2.5048185104972815\n",
      "Epoch 120 / 10000 loss: 16.839431762695312\n",
      "MSE train 6.244175560954127 MSE test 12.753640109451233\n",
      "MAE train 1.7362219624086306 MAE test 2.504813382930197\n",
      "Epoch 121 / 10000 loss: 16.838786602020264\n",
      "MSE train 6.244004225628591 MSE test 12.753408691713444\n",
      "MAE train 1.7361967120263277 MAE test 2.5047862137345107\n",
      "Epoch 122 / 10000 loss: 16.83807373046875\n",
      "MSE train 6.243820613980227 MSE test 12.75331857498154\n",
      "MAE train 1.736168773356438 MAE test 2.504781119984847\n",
      "Epoch 123 / 10000 loss: 16.83742928504944\n",
      "MSE train 6.243649331778061 MSE test 12.753087098903487\n",
      "MAE train 1.7361435235434168 MAE test 2.504753925410889\n",
      "Epoch 124 / 10000 loss: 16.83671545982361\n",
      "MSE train 6.243465725116473 MSE test 12.752996807195995\n",
      "MAE train 1.736115583576235 MAE test 2.5047488058301988\n",
      "Epoch 125 / 10000 loss: 16.83607053756714\n",
      "MSE train 6.2432945080460245 MSE test 12.752765417658047\n",
      "MAE train 1.7360903370126453 MAE test 2.504721649661838\n",
      "Epoch 126 / 10000 loss: 16.835357427597046\n",
      "MSE train 6.2431109839976 MSE test 12.752675073027063\n",
      "MAE train 1.736062399129676 MAE test 2.5047165231061244\n",
      "Epoch 127 / 10000 loss: 16.834713220596313\n",
      "MSE train 6.242939737648853 MSE test 12.752443539815227\n",
      "MAE train 1.7360371486541262 MAE test 2.5046893342434373\n",
      "Epoch 128 / 10000 loss: 16.833999156951904\n",
      "MSE train 6.242756242217092 MSE test 12.752353214416548\n",
      "MAE train 1.7360092125447135 MAE test 2.5046842240142073\n",
      "Epoch 129 / 10000 loss: 16.83335542678833\n",
      "MSE train 6.242584996708374 MSE test 12.752121730265923\n",
      "MAE train 1.7359839662637004 MAE test 2.504657049810993\n",
      "Epoch 130 / 10000 loss: 16.832642555236816\n",
      "MSE train 6.2424014740939935 MSE test 12.752031079020929\n",
      "MAE train 1.7359560193925259 MAE test 2.5046519082701124\n",
      "Epoch 131 / 10000 loss: 16.831997394561768\n",
      "MSE train 6.242230319163716 MSE test 12.751799516969278\n",
      "MAE train 1.7359307728796878 MAE test 2.5046247370645043\n",
      "Epoch 132 / 10000 loss: 16.83128523826599\n",
      "MSE train 6.242046872593495 MSE test 12.75170896113339\n",
      "MAE train 1.7359028384135808 MAE test 2.5046196033244206\n",
      "Epoch 133 / 10000 loss: 16.83064031600952\n",
      "MSE train 6.241875754196364 MSE test 12.751477287149784\n",
      "MAE train 1.7358776021036157 MAE test 2.504592421706276\n",
      "Epoch 134 / 10000 loss: 16.829927682876587\n",
      "MSE train 6.241692322928411 MSE test 12.751386476043878\n",
      "MAE train 1.7358496650270525 MAE test 2.504587262042409\n",
      "Epoch 135 / 10000 loss: 16.82928466796875\n",
      "MSE train 6.241521188384647 MSE test 12.751154611471168\n",
      "MAE train 1.7358244191498136 MAE test 2.5045600363488574\n",
      "Epoch 136 / 10000 loss: 16.82857084274292\n",
      "MSE train 6.241337825433717 MSE test 12.751063664270477\n",
      "MAE train 1.735796482230252 MAE test 2.5045548553857957\n",
      "Epoch 137 / 10000 loss: 16.82792639732361\n",
      "MSE train 6.241166678831291 MSE test 12.750831621529219\n",
      "MAE train 1.735771233569315 MAE test 2.504527622121358\n",
      "Epoch 138 / 10000 loss: 16.827213764190674\n",
      "MSE train 6.240983344069953 MSE test 12.75074058190793\n",
      "MAE train 1.7357432935539872 MAE test 2.5045224236048553\n",
      "Epoch 139 / 10000 loss: 16.82656955718994\n",
      "MSE train 6.240812288084388 MSE test 12.750508345304487\n",
      "MAE train 1.735718059363261 MAE test 2.5044951615321023\n",
      "Epoch 140 / 10000 loss: 16.825856924057007\n",
      "MSE train 6.240628930535588 MSE test 12.750417068568181\n",
      "MAE train 1.7356901118492547 MAE test 2.5044899318974916\n",
      "Epoch 141 / 10000 loss: 16.82521343231201\n",
      "MSE train 6.240457874086281 MSE test 12.75018450456628\n",
      "MAE train 1.735664874210206 MAE test 2.5044626296017394\n",
      "Epoch 142 / 10000 loss: 16.824501514434814\n",
      "MSE train 6.2402746110001415 MSE test 12.750092963291362\n",
      "MAE train 1.735636935049391 MAE test 2.5044573654418496\n",
      "Epoch 143 / 10000 loss: 16.823856830596924\n",
      "MSE train 6.240103606050204 MSE test 12.749860258868885\n",
      "MAE train 1.7356117070727255 MAE test 2.504430052839687\n",
      "Epoch 144 / 10000 loss: 16.823144674301147\n",
      "MSE train 6.239920367949272 MSE test 12.749768404444854\n",
      "MAE train 1.7355837623150578 MAE test 2.5044247678858373\n",
      "Epoch 145 / 10000 loss: 16.822500944137573\n",
      "MSE train 6.2397493486393465 MSE test 12.749535329626902\n",
      "MAE train 1.7355585308820747 MAE test 2.5043973948028233\n",
      "Epoch 146 / 10000 loss: 16.8217875957489\n",
      "MSE train 6.2395661242706675 MSE test 12.749443149008231\n",
      "MAE train 1.7355305937860404 MAE test 2.5043920486498705\n",
      "Epoch 147 / 10000 loss: 16.821144342422485\n",
      "MSE train 6.239395191425574 MSE test 12.749209854776945\n",
      "MAE train 1.7355053680618988 MAE test 2.5043646605814827\n",
      "Epoch 148 / 10000 loss: 16.820432662963867\n",
      "MSE train 6.239211922907947 MSE test 12.749117295173049\n",
      "MAE train 1.7354774238790514 MAE test 2.5043592578992486\n",
      "Epoch 149 / 10000 loss: 16.81978940963745\n",
      "MSE train 6.239041048578038 MSE test 12.74888360626775\n",
      "MAE train 1.735452214002639 MAE test 2.504331832907968\n",
      "Epoch 150 / 10000 loss: 16.81907820701599\n",
      "MSE train 6.238857881211298 MSE test 12.748790538706597\n",
      "MAE train 1.735424282238462 MAE test 2.5043263632637953\n",
      "Epoch 151 / 10000 loss: 16.8184335231781\n",
      "MSE train 6.238686990308345 MSE test 12.74855649548245\n",
      "MAE train 1.7353990693969672 MAE test 2.5042988642761665\n",
      "Epoch 152 / 10000 loss: 16.81772232055664\n",
      "MSE train 6.238503858833608 MSE test 12.748463111310308\n",
      "MAE train 1.7353711369883635 MAE test 2.5042933786330153\n",
      "Epoch 153 / 10000 loss: 16.817079782485962\n",
      "MSE train 6.238332984362013 MSE test 12.7482286956298\n",
      "MAE train 1.7353459220366387 MAE test 2.504265833129977\n",
      "Epoch 154 / 10000 loss: 16.81636881828308\n",
      "MSE train 6.238149891395993 MSE test 12.748134876363622\n",
      "MAE train 1.7353179943545332 MAE test 2.504260294586995\n",
      "Epoch 155 / 10000 loss: 16.815725326538086\n",
      "MSE train 6.23797903378285 MSE test 12.747899900652287\n",
      "MAE train 1.7352927854205926 MAE test 2.504232664970439\n",
      "Epoch 156 / 10000 loss: 16.815013885498047\n",
      "MSE train 6.237795914988495 MSE test 12.747805674464493\n",
      "MAE train 1.7352648523712915 MAE test 2.5042270570818927\n",
      "Epoch 157 / 10000 loss: 16.81437087059021\n",
      "MSE train 6.2376251555866595 MSE test 12.74757030952431\n",
      "MAE train 1.7352396584711558 MAE test 2.504199397572674\n",
      "Epoch 158 / 10000 loss: 16.813659191131592\n",
      "MSE train 6.237441992556006 MSE test 12.747475485604129\n",
      "MAE train 1.735211713203772 MAE test 2.5041937183046508\n",
      "Epoch 159 / 10000 loss: 16.81301736831665\n",
      "MSE train 6.237271222481686 MSE test 12.747239529677252\n",
      "MAE train 1.7351865143422658 MAE test 2.5041659651629216\n",
      "Epoch 160 / 10000 loss: 16.81230616569519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.237088146641959 MSE test 12.747144363185413\n",
      "MAE train 1.735158583592315 MAE test 2.5041602417500037\n",
      "Epoch 161 / 10000 loss: 16.81166386604309\n",
      "MSE train 6.236917396270545 MSE test 12.7469078707209\n",
      "MAE train 1.73513338829951 MAE test 2.504132419258012\n",
      "Epoch 162 / 10000 loss: 16.810952186584473\n",
      "MSE train 6.2367343252545435 MSE test 12.746812148896502\n",
      "MAE train 1.7351054548901808 MAE test 2.5041266377940765\n",
      "Epoch 163 / 10000 loss: 16.81031107902527\n",
      "MSE train 6.2365635427653725 MSE test 12.74657525976953\n",
      "MAE train 1.7350802536678471 MAE test 2.50409877685125\n",
      "Epoch 164 / 10000 loss: 16.809600830078125\n",
      "MSE train 6.236380473544608 MSE test 12.746478997170849\n",
      "MAE train 1.7350523188241112 MAE test 2.5040928996183025\n",
      "Epoch 165 / 10000 loss: 16.808958053588867\n",
      "MSE train 6.236209753244224 MSE test 12.746241518060454\n",
      "MAE train 1.7350271309698662 MAE test 2.5040649582668113\n",
      "Epoch 166 / 10000 loss: 16.808248043060303\n",
      "MSE train 6.236026670491804 MSE test 12.746144772359353\n",
      "MAE train 1.7349991950699382 MAE test 2.5040590261248115\n",
      "Epoch 167 / 10000 loss: 16.807605504989624\n",
      "MSE train 6.235855915958223 MSE test 12.74590678148043\n",
      "MAE train 1.7349740022255324 MAE test 2.5040310174256004\n",
      "Epoch 168 / 10000 loss: 16.806895971298218\n",
      "MSE train 6.235672838553213 MSE test 12.745809371395259\n",
      "MAE train 1.7349460627779192 MAE test 2.5040250019929484\n",
      "Epoch 169 / 10000 loss: 16.80625319480896\n",
      "MSE train 6.235502018985212 MSE test 12.745571095607696\n",
      "MAE train 1.7349208668151446 MAE test 2.5039969480958892\n",
      "Epoch 170 / 10000 loss: 16.80554461479187\n",
      "MSE train 6.23531897015667 MSE test 12.745473165723519\n",
      "MAE train 1.734892936417384 MAE test 2.503990876834635\n",
      "Epoch 171 / 10000 loss: 16.80490207672119\n",
      "MSE train 6.235148211932593 MSE test 12.745234301672285\n",
      "MAE train 1.7348677579837244 MAE test 2.503962754882094\n",
      "Epoch 172 / 10000 loss: 16.804192066192627\n",
      "MSE train 6.234965108473552 MSE test 12.745135893148994\n",
      "MAE train 1.7348398171005035 MAE test 2.5039566126761397\n",
      "Epoch 173 / 10000 loss: 16.803550958633423\n",
      "MSE train 6.23479436964864 MSE test 12.744896426640429\n",
      "MAE train 1.7348146356860072 MAE test 2.5039284058901483\n",
      "Epoch 174 / 10000 loss: 16.80284094810486\n",
      "MSE train 6.234611265381048 MSE test 12.744797680861153\n",
      "MAE train 1.7347866963223981 MAE test 2.5039222313521257\n",
      "Epoch 175 / 10000 loss: 16.802199840545654\n",
      "MSE train 6.2344404138000495 MSE test 12.744557675673484\n",
      "MAE train 1.7347615043498017 MAE test 2.5038939534478115\n",
      "Epoch 176 / 10000 loss: 16.801490783691406\n",
      "MSE train 6.234257293237254 MSE test 12.74445842270412\n",
      "MAE train 1.7347335537166477 MAE test 2.5038877129908843\n",
      "Epoch 177 / 10000 loss: 16.800849437713623\n",
      "MSE train 6.234086392392333 MSE test 12.744217863656695\n",
      "MAE train 1.73470835964272 MAE test 2.5038593659981654\n",
      "Epoch 178 / 10000 loss: 16.800139665603638\n",
      "MSE train 6.233903241816652 MSE test 12.744118103814642\n",
      "MAE train 1.7346804124924196 MAE test 2.5038530601290336\n",
      "Epoch 179 / 10000 loss: 16.799498558044434\n",
      "MSE train 6.233732309723293 MSE test 12.743877206772911\n",
      "MAE train 1.7346552116631808 MAE test 2.503824673032115\n",
      "Epoch 180 / 10000 loss: 16.798789262771606\n",
      "MSE train 6.233549081688945 MSE test 12.743776950412785\n",
      "MAE train 1.7346272474908038 MAE test 2.5038183104894314\n",
      "Epoch 181 / 10000 loss: 16.798148155212402\n",
      "MSE train 6.2333781640113965 MSE test 12.743535572606731\n",
      "MAE train 1.7346020466526557 MAE test 2.503789871215321\n",
      "Epoch 182 / 10000 loss: 16.797439336776733\n",
      "MSE train 6.2331949431747535 MSE test 12.743434714543294\n",
      "MAE train 1.7345740880910063 MAE test 2.5037834287891596\n",
      "Epoch 183 / 10000 loss: 16.79679775238037\n",
      "MSE train 6.23302394185766 MSE test 12.743192974655997\n",
      "MAE train 1.7345488835464427 MAE test 2.503754933917381\n",
      "Epoch 184 / 10000 loss: 16.79608917236328\n",
      "MSE train 6.232840594276791 MSE test 12.743091810620738\n",
      "MAE train 1.7345209053711343 MAE test 2.503748468488325\n",
      "Epoch 185 / 10000 loss: 16.795448064804077\n",
      "MSE train 6.2326695443997675 MSE test 12.742849636158835\n",
      "MAE train 1.734495697521153 MAE test 2.5037199286249274\n",
      "Epoch 186 / 10000 loss: 16.794739723205566\n",
      "MSE train 6.232486184695567 MSE test 12.742748096104435\n",
      "MAE train 1.734467724277501 MAE test 2.503713399349926\n",
      "Epoch 187 / 10000 loss: 16.794097185134888\n",
      "MSE train 6.2323150560958105 MSE test 12.742505255874688\n",
      "MAE train 1.7344425081543735 MAE test 2.5036847587100315\n",
      "Epoch 188 / 10000 loss: 16.79338788986206\n",
      "MSE train 6.232131670107172 MSE test 12.742403512693388\n",
      "MAE train 1.7344145241998374 MAE test 2.5036782254595824\n",
      "Epoch 189 / 10000 loss: 16.792747974395752\n",
      "MSE train 6.23196046796349 MSE test 12.742160441687675\n",
      "MAE train 1.7343892954307938 MAE test 2.5036495716208225\n",
      "Epoch 190 / 10000 loss: 16.792038440704346\n",
      "MSE train 6.231776917762561 MSE test 12.742057974478412\n",
      "MAE train 1.734361293859389 MAE test 2.5036429353314267\n",
      "Epoch 191 / 10000 loss: 16.79139804840088\n",
      "MSE train 6.231605713499885 MSE test 12.741814630698006\n",
      "MAE train 1.7343360689882386 MAE test 2.503614259791825\n",
      "Epoch 192 / 10000 loss: 16.790688037872314\n",
      "MSE train 6.231422105359702 MSE test 12.741711909467135\n",
      "MAE train 1.7343080671661841 MAE test 2.5036075853143744\n",
      "Epoch 193 / 10000 loss: 16.790047645568848\n",
      "MSE train 6.231250757645612 MSE test 12.741468058530955\n",
      "MAE train 1.7342828236583883 MAE test 2.503578845648264\n",
      "Epoch 194 / 10000 loss: 16.78933835029602\n",
      "MSE train 6.2310671389432075 MSE test 12.741365086658915\n",
      "MAE train 1.734254816415525 MAE test 2.5035721449372166\n",
      "Epoch 195 / 10000 loss: 16.78869652748108\n",
      "MSE train 6.230895740085869 MSE test 12.741120963119016\n",
      "MAE train 1.7342295714380989 MAE test 2.5035433705270704\n",
      "Epoch 196 / 10000 loss: 16.78798794746399\n",
      "MSE train 6.230711962476555 MSE test 12.741017706112038\n",
      "MAE train 1.7342015335991863 MAE test 2.5035366484660893\n",
      "Epoch 197 / 10000 loss: 16.787347078323364\n",
      "MSE train 6.2305404694494095 MSE test 12.740773382166044\n",
      "MAE train 1.7341762746236569 MAE test 2.5035078476852037\n",
      "Epoch 198 / 10000 loss: 16.78663682937622\n",
      "MSE train 6.2303566822462795 MSE test 12.740669676355575\n",
      "MAE train 1.73414824709156 MAE test 2.503501056090275\n",
      "Epoch 199 / 10000 loss: 16.78599500656128\n",
      "MSE train 6.230185076658615 MSE test 12.740425152333552\n",
      "MAE train 1.7341229673013183 MAE test 2.503472222891065\n",
      "Epoch 200 / 10000 loss: 16.785285711288452\n",
      "MSE train 6.230001131945924 MSE test 12.740321075950675\n",
      "MAE train 1.7340949103421521 MAE test 2.5034654142501997\n",
      "Epoch 201 / 10000 loss: 16.784645557403564\n",
      "MSE train 6.229829442984774 MSE test 12.740076181594807\n",
      "MAE train 1.7340696354610714 MAE test 2.5034365285484523\n",
      "Epoch 202 / 10000 loss: 16.783935070037842\n",
      "MSE train 6.229645375504052 MSE test 12.739971888834368\n",
      "MAE train 1.7340415543765968 MAE test 2.503429683801706\n",
      "Epoch 203 / 10000 loss: 16.7832932472229\n",
      "MSE train 6.229473613398458 MSE test 12.739726848964185\n",
      "MAE train 1.7340162639217238 MAE test 2.5034007929143707\n",
      "Epoch 204 / 10000 loss: 16.782582998275757\n",
      "MSE train 6.229289374839837 MSE test 12.739622333635248\n",
      "MAE train 1.733988167656062 MAE test 2.5033939167356625\n",
      "Epoch 205 / 10000 loss: 16.781941175460815\n",
      "MSE train 6.229117492235819 MSE test 12.739377006599195\n",
      "MAE train 1.7339628592048788 MAE test 2.503364991981389\n",
      "Epoch 206 / 10000 loss: 16.78123116493225\n",
      "MSE train 6.228933172897818 MSE test 12.739272329522935\n",
      "MAE train 1.7339347454190552 MAE test 2.503358102329455\n",
      "Epoch 207 / 10000 loss: 16.780588388442993\n",
      "MSE train 6.228761170620836 MSE test 12.739026651904949\n",
      "MAE train 1.7339094260430152 MAE test 2.503329123994929\n",
      "Epoch 208 / 10000 loss: 16.77987766265869\n",
      "MSE train 6.228576711118301 MSE test 12.738921747749199\n",
      "MAE train 1.7338812908888257 MAE test 2.503322214472221\n",
      "Epoch 209 / 10000 loss: 16.779235124588013\n",
      "MSE train 6.22840453401523 MSE test 12.738676038587098\n",
      "MAE train 1.7338559503314868 MAE test 2.5032932365810177\n",
      "Epoch 210 / 10000 loss: 16.778523683547974\n",
      "MSE train 6.22821995964852 MSE test 12.738570950169526\n",
      "MAE train 1.7338278017051911 MAE test 2.503286300280767\n",
      "Epoch 211 / 10000 loss: 16.777881383895874\n",
      "MSE train 6.22804760824389 MSE test 12.738324946331836\n",
      "MAE train 1.7338024292677872 MAE test 2.503257280280291\n",
      "Epoch 212 / 10000 loss: 16.777169942855835\n",
      "MSE train 6.227862848781375 MSE test 12.738219613264333\n",
      "MAE train 1.7337742589766931 MAE test 2.503250311257282\n",
      "Epoch 213 / 10000 loss: 16.77652597427368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.227690341195859 MSE test 12.737973443086599\n",
      "MAE train 1.7337488640986984 MAE test 2.503221281593524\n",
      "Epoch 214 / 10000 loss: 16.775813341140747\n",
      "MSE train 6.22750538161526 MSE test 12.737867968265926\n",
      "MAE train 1.7337206654348791 MAE test 2.5032142939122353\n",
      "Epoch 215 / 10000 loss: 16.775169372558594\n",
      "MSE train 6.227332698202568 MSE test 12.737621804116944\n",
      "MAE train 1.7336952414182751 MAE test 2.5031852630624307\n",
      "Epoch 216 / 10000 loss: 16.77445697784424\n",
      "MSE train 6.227147562551628 MSE test 12.737516089157573\n",
      "MAE train 1.7336670174428197 MAE test 2.503178263122953\n",
      "Epoch 217 / 10000 loss: 16.77381134033203\n",
      "MSE train 6.226974698302374 MSE test 12.737269770251029\n",
      "MAE train 1.733641566347432 MAE test 2.503149211746621\n",
      "Epoch 218 / 10000 loss: 16.77309823036194\n",
      "MSE train 6.226789258120087 MSE test 12.737163989743012\n",
      "MAE train 1.7336132997400626 MAE test 2.503142192578707\n",
      "Epoch 219 / 10000 loss: 16.772452116012573\n",
      "MSE train 6.22661614452114 MSE test 12.736917484705604\n",
      "MAE train 1.7335878106810585 MAE test 2.5031131084404645\n",
      "Epoch 220 / 10000 loss: 16.771738052368164\n",
      "MSE train 6.226430523679045 MSE test 12.736811616954611\n",
      "MAE train 1.733559508949226 MAE test 2.5031060944545778\n",
      "Epoch 221 / 10000 loss: 16.771090745925903\n",
      "MSE train 6.226257117838942 MSE test 12.736565027843705\n",
      "MAE train 1.7335339841413133 MAE test 2.503077003564849\n",
      "Epoch 222 / 10000 loss: 16.77037525177002\n",
      "MSE train 6.226071162979865 MSE test 12.736458921054702\n",
      "MAE train 1.733505626340378 MAE test 2.5030699561083183\n",
      "Epoch 223 / 10000 loss: 16.769726753234863\n",
      "MSE train 6.225897458161755 MSE test 12.73621231674411\n",
      "MAE train 1.7334800467905402 MAE test 2.5030408697790048\n",
      "Epoch 224 / 10000 loss: 16.769010543823242\n",
      "MSE train 6.2257111529805025 MSE test 12.736106155780547\n",
      "MAE train 1.73345164324033 MAE test 2.503033819029611\n",
      "Epoch 225 / 10000 loss: 16.768361568450928\n",
      "MSE train 6.225537082366984 MSE test 12.735859499918437\n",
      "MAE train 1.7334260128817889 MAE test 2.50300472607785\n",
      "Epoch 226 / 10000 loss: 16.767643213272095\n",
      "MSE train 6.2253503601843105 MSE test 12.735753142953936\n",
      "MAE train 1.7333975464690539 MAE test 2.50299764837836\n",
      "Epoch 227 / 10000 loss: 16.76699161529541\n",
      "MSE train 6.22517583987561 MSE test 12.735506438613683\n",
      "MAE train 1.7333718436375978 MAE test 2.502968542151865\n",
      "Epoch 228 / 10000 loss: 16.766271352767944\n",
      "MSE train 6.224988742702248 MSE test 12.73540010697981\n",
      "MAE train 1.7333433201535953 MAE test 2.5029614765259307\n",
      "Epoch 229 / 10000 loss: 16.7656192779541\n",
      "MSE train 6.2248136865647234 MSE test 12.7351531238854\n",
      "MAE train 1.733317536250482 MAE test 2.5029323391009015\n",
      "Epoch 230 / 10000 loss: 16.764896631240845\n",
      "MSE train 6.224625985186064 MSE test 12.735046667447902\n",
      "MAE train 1.7332889310301858 MAE test 2.5029252601088796\n",
      "Epoch 231 / 10000 loss: 16.764241456985474\n",
      "MSE train 6.22445036336804 MSE test 12.73479984781284\n",
      "MAE train 1.7332630733190153 MAE test 2.502896135726062\n",
      "Epoch 232 / 10000 loss: 16.763516902923584\n",
      "MSE train 6.224262069502118 MSE test 12.734693328230339\n",
      "MAE train 1.733234374628951 MAE test 2.5028890597005695\n",
      "Epoch 233 / 10000 loss: 16.762859106063843\n",
      "MSE train 6.224085715875129 MSE test 12.734446477656082\n",
      "MAE train 1.7332084116275863 MAE test 2.50285994818697\n",
      "Epoch 234 / 10000 loss: 16.762131214141846\n",
      "MSE train 6.22389660098184 MSE test 12.734339760434334\n",
      "MAE train 1.7331796029950046 MAE test 2.5028528226252367\n",
      "Epoch 235 / 10000 loss: 16.761470556259155\n",
      "MSE train 6.223719476734351 MSE test 12.734092805281138\n",
      "MAE train 1.7331535317938678 MAE test 2.50282370647113\n",
      "Epoch 236 / 10000 loss: 16.760740041732788\n",
      "MSE train 6.223529497959556 MSE test 12.733986011989652\n",
      "MAE train 1.7331245876097674 MAE test 2.502816588137407\n",
      "Epoch 237 / 10000 loss: 16.76007628440857\n",
      "MSE train 6.223351390477402 MSE test 12.73373895911299\n",
      "MAE train 1.7330983851900381 MAE test 2.5027874487498756\n",
      "Epoch 238 / 10000 loss: 16.759339809417725\n",
      "MSE train 6.223160297237057 MSE test 12.733632141127707\n",
      "MAE train 1.733069300275794 MAE test 2.5027803358422047\n",
      "Epoch 239 / 10000 loss: 16.758671760559082\n",
      "MSE train 6.222981082208305 MSE test 12.733385140348929\n",
      "MAE train 1.733042931449389 MAE test 2.5027512036800137\n",
      "Epoch 240 / 10000 loss: 16.757930755615234\n",
      "MSE train 6.222788766321943 MSE test 12.733278314845295\n",
      "MAE train 1.7330136651876304 MAE test 2.5027441028095327\n",
      "Epoch 241 / 10000 loss: 16.75725746154785\n",
      "MSE train 6.222608193290821 MSE test 12.733031075005359\n",
      "MAE train 1.73298708929998 MAE test 2.5027149428319015\n",
      "Epoch 242 / 10000 loss: 16.756511211395264\n",
      "MSE train 6.222414452887803 MSE test 12.732924164228491\n",
      "MAE train 1.7329576142274987 MAE test 2.502707822450405\n",
      "Epoch 243 / 10000 loss: 16.75583052635193\n",
      "MSE train 6.2222323019328885 MSE test 12.732676995574765\n",
      "MAE train 1.7329307973236814 MAE test 2.502678674894264\n",
      "Epoch 244 / 10000 loss: 16.755077838897705\n",
      "MSE train 6.222036991033899 MSE test 12.732569940106021\n",
      "MAE train 1.7329010805706309 MAE test 2.5026715364765546\n",
      "Epoch 245 / 10000 loss: 16.75438952445984\n",
      "MSE train 6.221853188184638 MSE test 12.732322727400186\n",
      "MAE train 1.732874018837045 MAE test 2.5026423945837566\n",
      "Epoch 246 / 10000 loss: 16.75363063812256\n",
      "MSE train 6.221656107815385 MSE test 12.732215660776045\n",
      "MAE train 1.7328440567273897 MAE test 2.5026352603332125\n",
      "Epoch 247 / 10000 loss: 16.75293517112732\n",
      "MSE train 6.221470542218894 MSE test 12.731968368308127\n",
      "MAE train 1.7328167307703017 MAE test 2.5026060938160786\n",
      "Epoch 248 / 10000 loss: 16.752167463302612\n",
      "MSE train 6.221271726056154 MSE test 12.731861182443806\n",
      "MAE train 1.7327864808744093 MAE test 2.5025989590198314\n",
      "Epoch 249 / 10000 loss: 16.751463413238525\n",
      "MSE train 6.221084463996768 MSE test 12.731613671271603\n",
      "MAE train 1.7327589055103951 MAE test 2.502569783446678\n",
      "Epoch 250 / 10000 loss: 16.75068712234497\n",
      "MSE train 6.220884065134605 MSE test 12.73150653616121\n",
      "MAE train 1.7327284458415149 MAE test 2.5025626566801207\n",
      "Epoch 251 / 10000 loss: 16.749977111816406\n",
      "MSE train 6.220695459608546 MSE test 12.731258946765282\n",
      "MAE train 1.7327006881904783 MAE test 2.5025334704305573\n",
      "Epoch 252 / 10000 loss: 16.7491934299469\n",
      "MSE train 6.220493986976593 MSE test 12.731151627495175\n",
      "MAE train 1.732670045754724 MAE test 2.502526320814725\n",
      "Epoch 253 / 10000 loss: 16.748475551605225\n",
      "MSE train 6.2203047172838435 MSE test 12.730903959697306\n",
      "MAE train 1.7326421530864182 MAE test 2.5024971338634003\n",
      "Epoch 254 / 10000 loss: 16.747686624526978\n",
      "MSE train 6.220102846338148 MSE test 12.730796496663585\n",
      "MAE train 1.7326114568012874 MAE test 2.5024899982011797\n",
      "Epoch 255 / 10000 loss: 16.746964931488037\n",
      "MSE train 6.2199136853135375 MSE test 12.730548731587382\n",
      "MAE train 1.7325836306436413 MAE test 2.5024608131929598\n",
      "Epoch 256 / 10000 loss: 16.746175050735474\n",
      "MSE train 6.21971250877274 MSE test 12.730441127807419\n",
      "MAE train 1.7325531473609543 MAE test 2.5024536656177143\n",
      "Epoch 257 / 10000 loss: 16.74545454978943\n",
      "MSE train 6.219524504358271 MSE test 12.730193317243703\n",
      "MAE train 1.7325255535696573 MAE test 2.5024244834018177\n",
      "Epoch 258 / 10000 loss: 16.744667768478394\n",
      "MSE train 6.219324958520226 MSE test 12.730085475946115\n",
      "MAE train 1.732495287092633 MAE test 2.502417309008358\n",
      "Epoch 259 / 10000 loss: 16.74395203590393\n",
      "MSE train 6.219138942605479 MSE test 12.729837528834711\n",
      "MAE train 1.7324679833618806 MAE test 2.5023881312118945\n",
      "Epoch 260 / 10000 loss: 16.743172883987427\n",
      "MSE train 6.21894169629672 MSE test 12.729729740836905\n",
      "MAE train 1.7324380365806578 MAE test 2.502380992541877\n",
      "Epoch 261 / 10000 loss: 16.74246621131897\n",
      "MSE train 6.2187581326801915 MSE test 12.729481488335349\n",
      "MAE train 1.7324110497473213 MAE test 2.5023517812310354\n",
      "Epoch 262 / 10000 loss: 16.741697549819946\n",
      "MSE train 6.218563398285619 MSE test 12.729373554886347\n",
      "MAE train 1.7323814853913428 MAE test 2.5023446271438274\n",
      "Epoch 263 / 10000 loss: 16.741003036499023\n",
      "MSE train 6.218382383060874 MSE test 12.729125372725552\n",
      "MAE train 1.7323548691037904 MAE test 2.502315439365929\n",
      "Epoch 264 / 10000 loss: 16.74024510383606\n",
      "MSE train 6.218190170787025 MSE test 12.729017343559342\n",
      "MAE train 1.7323256231383926 MAE test 2.5023082901592866\n",
      "Epoch 265 / 10000 loss: 16.739562273025513\n",
      "MSE train 6.218011506692099 MSE test 12.728769190854749\n",
      "MAE train 1.7322993246399647 MAE test 2.502279117188191\n",
      "Epoch 266 / 10000 loss: 16.738816738128662\n",
      "MSE train 6.217821431057478 MSE test 12.728661143678961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7322703635855763 MAE test 2.50227198158735\n",
      "Epoch 267 / 10000 loss: 16.738144159317017\n",
      "MSE train 6.21764469499222 MSE test 12.728413078682376\n",
      "MAE train 1.7322443151300946 MAE test 2.502242821249443\n",
      "Epoch 268 / 10000 loss: 16.737406969070435\n",
      "MSE train 6.217456388650471 MSE test 12.72830514947909\n",
      "MAE train 1.7322156068796024 MAE test 2.502235713437114\n",
      "Epoch 269 / 10000 loss: 16.736743211746216\n",
      "MSE train 6.217281288333679 MSE test 12.728056815079192\n",
      "MAE train 1.732189781929817 MAE test 2.502206536011667\n",
      "Epoch 270 / 10000 loss: 16.73601484298706\n",
      "MSE train 6.2170942620102 MSE test 12.727948977428579\n",
      "MAE train 1.7321612284600594 MAE test 2.5021994407850663\n",
      "Epoch 271 / 10000 loss: 16.735357999801636\n",
      "MSE train 6.216920334124647 MSE test 12.72770081158219\n",
      "MAE train 1.7321355424025655 MAE test 2.502170295047582\n",
      "Epoch 272 / 10000 loss: 16.734635591506958\n",
      "MSE train 6.216734479794146 MSE test 12.727592915447477\n",
      "MAE train 1.7321071369861891 MAE test 2.5021631953273293\n",
      "Epoch 273 / 10000 loss: 16.733983993530273\n",
      "MSE train 6.216561464449537 MSE test 12.727344710047372\n",
      "MAE train 1.732081572229257 MAE test 2.5021340523031466\n",
      "Epoch 274 / 10000 loss: 16.733266353607178\n",
      "MSE train 6.2163763748150656 MSE test 12.727237016512746\n",
      "MAE train 1.7320532768823695 MAE test 2.5021269884821997\n",
      "Epoch 275 / 10000 loss: 16.73261857032776\n",
      "MSE train 6.216204093917515 MSE test 12.726988850692814\n",
      "MAE train 1.732027843459672 MAE test 2.5020978603150428\n",
      "Epoch 276 / 10000 loss: 16.73190474510193\n",
      "MSE train 6.216019602291822 MSE test 12.726881182512873\n",
      "MAE train 1.7319996474804336 MAE test 2.5020908002353055\n",
      "Epoch 277 / 10000 loss: 16.73125958442688\n",
      "MSE train 6.2158478156095684 MSE test 12.72663315341001\n",
      "MAE train 1.7319742835755407 MAE test 2.502061688438468\n",
      "Epoch 278 / 10000 loss: 16.730549097061157\n",
      "MSE train 6.215663817008317 MSE test 12.726525412231211\n",
      "MAE train 1.7319461564622407 MAE test 2.5020546221085183\n",
      "Epoch 279 / 10000 loss: 16.7299063205719\n",
      "MSE train 6.215492465537849 MSE test 12.726277598998411\n",
      "MAE train 1.731920846132219 MAE test 2.502025541045824\n",
      "Epoch 280 / 10000 loss: 16.729196548461914\n",
      "MSE train 6.215308833185449 MSE test 12.72616981090538\n",
      "MAE train 1.7318927735472474 MAE test 2.5020184700976302\n",
      "Epoch 281 / 10000 loss: 16.72855544090271\n",
      "MSE train 6.215137770532707 MSE test 12.72592192671472\n",
      "MAE train 1.7318675026923886 MAE test 2.5019893829841697\n",
      "Epoch 282 / 10000 loss: 16.727848768234253\n",
      "MSE train 6.214954375046754 MSE test 12.725814241550362\n",
      "MAE train 1.7318394571621567 MAE test 2.5019823366828717\n",
      "Epoch 283 / 10000 loss: 16.727209329605103\n",
      "MSE train 6.214783600660163 MSE test 12.72556632180486\n",
      "MAE train 1.731814227941966 MAE test 2.5019532221841505\n",
      "Epoch 284 / 10000 loss: 16.726502180099487\n",
      "MSE train 6.214600434292097 MSE test 12.725458785416013\n",
      "MAE train 1.7317862078060555 MAE test 2.501946193151634\n",
      "Epoch 285 / 10000 loss: 16.72586464881897\n",
      "MSE train 6.21442980936611 MSE test 12.725210973979138\n",
      "MAE train 1.7317609976433974 MAE test 2.501917120475846\n",
      "Epoch 286 / 10000 loss: 16.72515845298767\n",
      "MSE train 6.214246846281569 MSE test 12.725103337713998\n",
      "MAE train 1.731732999845057 MAE test 2.5019100771008906\n",
      "Epoch 287 / 10000 loss: 16.72452139854431\n",
      "MSE train 6.2140763390965565 MSE test 12.724855365349722\n",
      "MAE train 1.7317078044831145 MAE test 2.50188096344533\n",
      "Epoch 288 / 10000 loss: 16.72381567955017\n",
      "MSE train 6.2138935007598715 MSE test 12.72474809933038\n",
      "MAE train 1.7316798342142214 MAE test 2.5018739761492705\n",
      "Epoch 289 / 10000 loss: 16.72317886352539\n",
      "MSE train 6.213723168851971 MSE test 12.724499991472218\n",
      "MAE train 1.73165466058796 MAE test 2.501844843407464\n",
      "Epoch 290 / 10000 loss: 16.722474098205566\n",
      "MSE train 6.213540426873413 MSE test 12.724392558882267\n",
      "MAE train 1.7316267073860119 MAE test 2.5018378256035554\n",
      "Epoch 291 / 10000 loss: 16.721837282180786\n",
      "MSE train 6.213370174055284 MSE test 12.724144747763301\n",
      "MAE train 1.7316015581035609 MAE test 2.5018087379284117\n",
      "Epoch 292 / 10000 loss: 16.721133947372437\n",
      "MSE train 6.21318751180401 MSE test 12.724037291785317\n",
      "MAE train 1.7315736098560197 MAE test 2.5018017201140257\n",
      "Epoch 293 / 10000 loss: 16.720497608184814\n",
      "MSE train 6.213017334437574 MSE test 12.723789402653916\n",
      "MAE train 1.7315484661448017 MAE test 2.50177260737733\n",
      "Epoch 294 / 10000 loss: 16.719794034957886\n",
      "MSE train 6.212834743335319 MSE test 12.723681970359305\n",
      "MAE train 1.7315205256488666 MAE test 2.501765597733798\n",
      "Epoch 295 / 10000 loss: 16.71915864944458\n",
      "MSE train 6.212664664003988 MSE test 12.723434032536167\n",
      "MAE train 1.7314953988739041 MAE test 2.5017364853506736\n",
      "Epoch 296 / 10000 loss: 16.718454837799072\n",
      "MSE train 6.212482114291713 MSE test 12.723326675708268\n",
      "MAE train 1.7314674672065784 MAE test 2.5017294697776897\n",
      "Epoch 297 / 10000 loss: 16.717820405960083\n",
      "MSE train 6.212312107333853 MSE test 12.72307865410372\n",
      "MAE train 1.7314423540442085 MAE test 2.5017003331402496\n",
      "Epoch 298 / 10000 loss: 16.71711778640747\n",
      "MSE train 6.212129609266095 MSE test 12.722971346240234\n",
      "MAE train 1.7314144249731565 MAE test 2.5016933430764707\n",
      "Epoch 299 / 10000 loss: 16.71648144721985\n",
      "MSE train 6.211959632543568 MSE test 12.72272335754517\n",
      "MAE train 1.7313893171399968 MAE test 2.5016642144920938\n",
      "Epoch 300 / 10000 loss: 16.715778827667236\n",
      "MSE train 6.211777163607033 MSE test 12.722616095888101\n",
      "MAE train 1.731361394758212 MAE test 2.501657218353487\n",
      "Epoch 301 / 10000 loss: 16.715144872665405\n",
      "MSE train 6.211607251113561 MSE test 12.722368112603347\n",
      "MAE train 1.7313362977905415 MAE test 2.5016280859692115\n",
      "Epoch 302 / 10000 loss: 16.714441299438477\n",
      "MSE train 6.211424815539984 MSE test 12.722260659810008\n",
      "MAE train 1.7313083746288158 MAE test 2.501621057616789\n",
      "Epoch 303 / 10000 loss: 16.713808059692383\n",
      "MSE train 6.211254877800003 MSE test 12.722012739372209\n",
      "MAE train 1.7312832739541675 MAE test 2.5015919108524067\n",
      "Epoch 304 / 10000 loss: 16.713104486465454\n",
      "MSE train 6.211072524484212 MSE test 12.721905407624819\n",
      "MAE train 1.7312553629729355 MAE test 2.5015849192983874\n",
      "Epoch 305 / 10000 loss: 16.712470054626465\n",
      "MSE train 6.210902633043065 MSE test 12.721657395657358\n",
      "MAE train 1.7312302708540372 MAE test 2.5015557617210407\n",
      "Epoch 306 / 10000 loss: 16.71176815032959\n",
      "MSE train 6.210720298020589 MSE test 12.72155012024749\n",
      "MAE train 1.731202361403919 MAE test 2.5015487612190945\n",
      "Epoch 307 / 10000 loss: 16.71113419532776\n",
      "MSE train 6.2105504430473 MSE test 12.721302029498567\n",
      "MAE train 1.7311772689924563 MAE test 2.5015196020157613\n",
      "Epoch 308 / 10000 loss: 16.710431575775146\n",
      "MSE train 6.210368076386077 MSE test 12.721194781405814\n",
      "MAE train 1.7311493527553357 MAE test 2.501512601509054\n",
      "Epoch 309 / 10000 loss: 16.709797382354736\n",
      "MSE train 6.2101982685071855 MSE test 12.72094675729688\n",
      "MAE train 1.7311242663978776 MAE test 2.5014834434290596\n",
      "Epoch 310 / 10000 loss: 16.70909595489502\n",
      "MSE train 6.210015976323482 MSE test 12.720839450236948\n",
      "MAE train 1.7310963625227065 MAE test 2.5014764354358787\n",
      "Epoch 311 / 10000 loss: 16.708461046218872\n",
      "MSE train 6.209846155171707 MSE test 12.720591395778555\n",
      "MAE train 1.7310712759228992 MAE test 2.5014472719734795\n",
      "Epoch 312 / 10000 loss: 16.707759380340576\n",
      "MSE train 6.209663812822368 MSE test 12.72048413882019\n",
      "MAE train 1.7310433597286545 MAE test 2.501440268356946\n",
      "Epoch 313 / 10000 loss: 16.707126140594482\n",
      "MSE train 6.209494044892308 MSE test 12.720236027277078\n",
      "MAE train 1.7310182827911378 MAE test 2.5014111001526325\n",
      "Epoch 314 / 10000 loss: 16.70642328262329\n",
      "MSE train 6.209311755507932 MSE test 12.720128627421742\n",
      "MAE train 1.7309903753732607 MAE test 2.501404070655828\n",
      "Epoch 315 / 10000 loss: 16.705790281295776\n",
      "MSE train 6.2091419974127735 MSE test 12.719880609267413\n",
      "MAE train 1.7309653007814818 MAE test 2.5013749059848873\n",
      "Epoch 316 / 10000 loss: 16.7050883769989\n",
      "MSE train 6.208959744321653 MSE test 12.719773129477662\n",
      "MAE train 1.730937396123211 MAE test 2.5013678687756555\n",
      "Epoch 317 / 10000 loss: 16.70445489883423\n",
      "MSE train 6.208789961666128 MSE test 12.71952517636431\n",
      "MAE train 1.7309123191376528 MAE test 2.5013387119806483\n",
      "Epoch 318 / 10000 loss: 16.70375370979309\n",
      "MSE train 6.208607698771628 MSE test 12.71941769555668\n",
      "MAE train 1.7308844058373858 MAE test 2.5013316640487377\n",
      "Epoch 319 / 10000 loss: 16.7031192779541\n",
      "MSE train 6.208437913717975 MSE test 12.719169614148832\n",
      "MAE train 1.7308593262556324 MAE test 2.501302486995587\n",
      "Epoch 320 / 10000 loss: 16.702417612075806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.208255677186526 MSE test 12.719062165335853\n",
      "MAE train 1.7308314193597378 MAE test 2.5012954535383147\n",
      "Epoch 321 / 10000 loss: 16.70178484916687\n",
      "MSE train 6.208085964348658 MSE test 12.718814122036754\n",
      "MAE train 1.7308063458287917 MAE test 2.5012662791341933\n",
      "Epoch 322 / 10000 loss: 16.701082229614258\n",
      "MSE train 6.207903738244372 MSE test 12.718706677453397\n",
      "MAE train 1.7307784438286684 MAE test 2.5012592414097528\n",
      "Epoch 323 / 10000 loss: 16.700448513031006\n",
      "MSE train 6.207733975681062 MSE test 12.718458630956095\n",
      "MAE train 1.7307533643080033 MAE test 2.50123006346741\n",
      "Epoch 324 / 10000 loss: 16.69974708557129\n",
      "MSE train 6.207551725246979 MSE test 12.71835119693535\n",
      "MAE train 1.7307254534501233 MAE test 2.501223023536246\n",
      "Epoch 325 / 10000 loss: 16.699113845825195\n",
      "MSE train 6.207382037014005 MSE test 12.71810327365253\n",
      "MAE train 1.73070038587793 MAE test 2.5011938585725013\n",
      "Epoch 326 / 10000 loss: 16.6984121799469\n",
      "MSE train 6.207199750295586 MSE test 12.717995621582773\n",
      "MAE train 1.7306724724287885 MAE test 2.5011867969154995\n",
      "Epoch 327 / 10000 loss: 16.697778701782227\n",
      "MSE train 6.207030084133743 MSE test 12.717747692145588\n",
      "MAE train 1.7306474034321762 MAE test 2.501157617110365\n",
      "Epoch 328 / 10000 loss: 16.69707751274109\n",
      "MSE train 6.2068478444375685 MSE test 12.717640117822299\n",
      "MAE train 1.7306194902248235 MAE test 2.5011505583137503\n",
      "Epoch 329 / 10000 loss: 16.696444749832153\n",
      "MSE train 6.206678137454146 MSE test 12.71739210409334\n",
      "MAE train 1.7305944226565613 MAE test 2.5011213839825728\n",
      "Epoch 330 / 10000 loss: 16.695743083953857\n",
      "MSE train 6.206495908203442 MSE test 12.717284540196237\n",
      "MAE train 1.7305665137216824 MAE test 2.501114326334637\n",
      "Epoch 331 / 10000 loss: 16.695109844207764\n",
      "MSE train 6.206326220520914 MSE test 12.717036419466428\n",
      "MAE train 1.7305414416129605 MAE test 2.501085122951293\n",
      "Epoch 332 / 10000 loss: 16.694408893585205\n",
      "MSE train 6.206143999138604 MSE test 12.716928905670477\n",
      "MAE train 1.7305135364206368 MAE test 2.5010780717210457\n",
      "Epoch 333 / 10000 loss: 16.693775177001953\n",
      "MSE train 6.205974317449897 MSE test 12.716680833668615\n",
      "MAE train 1.7304884638172031 MAE test 2.5010488806521005\n",
      "Epoch 334 / 10000 loss: 16.693074464797974\n",
      "MSE train 6.205792084988065 MSE test 12.716573248093844\n",
      "MAE train 1.7304605528420878 MAE test 2.5010418195047177\n",
      "Epoch 335 / 10000 loss: 16.69244074821472\n",
      "MSE train 6.2056223630632354 MSE test 12.716325307699751\n",
      "MAE train 1.730435479089716 MAE test 2.50101263476097\n",
      "Epoch 336 / 10000 loss: 16.691739320755005\n",
      "MSE train 6.205440192235432 MSE test 12.716217791652305\n",
      "MAE train 1.7304075694373413 MAE test 2.501005577651623\n",
      "Epoch 337 / 10000 loss: 16.691107511520386\n",
      "MSE train 6.205270474212396 MSE test 12.715969715773607\n",
      "MAE train 1.7303824966594605 MAE test 2.5009763810583716\n",
      "Epoch 338 / 10000 loss: 16.69040584564209\n",
      "MSE train 6.205088300148922 MSE test 12.715862014715993\n",
      "MAE train 1.730354582353222 MAE test 2.5009692948756697\n",
      "Epoch 339 / 10000 loss: 16.689772605895996\n",
      "MSE train 6.204918588988592 MSE test 12.715614042522274\n",
      "MAE train 1.7303295109431656 MAE test 2.500940121871598\n",
      "Epoch 340 / 10000 loss: 16.68907141685486\n",
      "MSE train 6.204736362535252 MSE test 12.715506332283024\n",
      "MAE train 1.730301592287958 MAE test 2.500933042203476\n",
      "Epoch 341 / 10000 loss: 16.688438415527344\n",
      "MSE train 6.2045667127306325 MSE test 12.715258299678647\n",
      "MAE train 1.7302765294828673 MAE test 2.5009038338300065\n",
      "Epoch 342 / 10000 loss: 16.687737464904785\n",
      "MSE train 6.204384489651499 MSE test 12.71515064553586\n",
      "MAE train 1.7302486029249007 MAE test 2.5008967642210704\n",
      "Epoch 343 / 10000 loss: 16.68710470199585\n",
      "MSE train 6.204214828784724 MSE test 12.714902604079347\n",
      "MAE train 1.7302235332820337 MAE test 2.5008675681987387\n",
      "Epoch 344 / 10000 loss: 16.686402559280396\n",
      "MSE train 6.204032599393356 MSE test 12.714794977784141\n",
      "MAE train 1.7301956072006048 MAE test 2.5008604971029262\n",
      "Epoch 345 / 10000 loss: 16.685770750045776\n",
      "MSE train 6.203862921279928 MSE test 12.714546838199684\n",
      "MAE train 1.7301705396877065 MAE test 2.500831289199661\n",
      "Epoch 346 / 10000 loss: 16.685069799423218\n",
      "MSE train 6.2036806699612175 MSE test 12.714439182632814\n",
      "MAE train 1.7301426046165649 MAE test 2.5008242050454106\n",
      "Epoch 347 / 10000 loss: 16.684436321258545\n",
      "MSE train 6.20351100716555 MSE test 12.714191115435975\n",
      "MAE train 1.7301175361828385 MAE test 2.5007950147045332\n",
      "Epoch 348 / 10000 loss: 16.683735609054565\n",
      "MSE train 6.203328813544216 MSE test 12.714083370255128\n",
      "MAE train 1.7300896082515453 MAE test 2.5007879227685947\n",
      "Epoch 349 / 10000 loss: 16.683103322982788\n",
      "MSE train 6.203159103596041 MSE test 12.713835251595095\n",
      "MAE train 1.7300645396990983 MAE test 2.500758708317995\n",
      "Epoch 350 / 10000 loss: 16.68240189552307\n",
      "MSE train 6.2029769077164385 MSE test 12.713727553854163\n",
      "MAE train 1.7300366049285931 MAE test 2.5007516251859943\n",
      "Epoch 351 / 10000 loss: 16.681769609451294\n",
      "MSE train 6.202807173729531 MSE test 12.713479478128466\n",
      "MAE train 1.7300115263208389 MAE test 2.5007224268191983\n",
      "Epoch 352 / 10000 loss: 16.681067943572998\n",
      "MSE train 6.202624981751172 MSE test 12.713371725386631\n",
      "MAE train 1.7299835906231602 MAE test 2.5007153405132447\n",
      "Epoch 353 / 10000 loss: 16.68043541908264\n",
      "MSE train 6.2024553055616165 MSE test 12.71312364340121\n",
      "MAE train 1.72995852560152 MAE test 2.5006861239093885\n",
      "Epoch 354 / 10000 loss: 16.679733753204346\n",
      "MSE train 6.202273045120985 MSE test 12.713015840209563\n",
      "MAE train 1.7299305773494478 MAE test 2.500679030456556\n",
      "Epoch 355 / 10000 loss: 16.679101705551147\n",
      "MSE train 6.202103358732336 MSE test 12.712767740012351\n",
      "MAE train 1.7299055002520944 MAE test 2.5006498232144945\n",
      "Epoch 356 / 10000 loss: 16.67840003967285\n",
      "MSE train 6.201921110463378 MSE test 12.712660067287846\n",
      "MAE train 1.729877559089618 MAE test 2.500642748463351\n",
      "Epoch 357 / 10000 loss: 16.677767992019653\n",
      "MSE train 6.20175140881424 MSE test 12.712411830156054\n",
      "MAE train 1.7298524838675202 MAE test 2.500613520193787\n",
      "Epoch 358 / 10000 loss: 16.677066564559937\n",
      "MSE train 6.201569114161971 MSE test 12.712304009114126\n",
      "MAE train 1.729824525937282 MAE test 2.5006064300929567\n",
      "Epoch 359 / 10000 loss: 16.67643451690674\n",
      "MSE train 6.201399439010646 MSE test 12.71205594514332\n",
      "MAE train 1.7297994558452723 MAE test 2.500577214087238\n",
      "Epoch 360 / 10000 loss: 16.67573308944702\n",
      "MSE train 6.20121711808358 MSE test 12.711948194812388\n",
      "MAE train 1.7297714907929074 MAE test 2.500570135175883\n",
      "Epoch 361 / 10000 loss: 16.675100803375244\n",
      "MSE train 6.201047474442486 MSE test 12.711699956681276\n",
      "MAE train 1.7297464233314246 MAE test 2.5005408924373462\n",
      "Epoch 362 / 10000 loss: 16.67439889907837\n",
      "MSE train 6.200865174597135 MSE test 12.711592137740976\n",
      "MAE train 1.7297184659823304 MAE test 2.500533801660885\n",
      "Epoch 363 / 10000 loss: 16.673766613006592\n",
      "MSE train 6.200695487936518 MSE test 12.711343920269845\n",
      "MAE train 1.7296933853067555 MAE test 2.500504575314946\n",
      "Epoch 364 / 10000 loss: 16.67306613922119\n",
      "MSE train 6.200513156318078 MSE test 12.711236084659875\n",
      "MAE train 1.7296654199484447 MAE test 2.500497469273049\n",
      "Epoch 365 / 10000 loss: 16.672433614730835\n",
      "MSE train 6.20034344976446 MSE test 12.71098782586616\n",
      "MAE train 1.7296403460819227 MAE test 2.5004682394848428\n",
      "Epoch 366 / 10000 loss: 16.671732425689697\n",
      "MSE train 6.200161174933683 MSE test 12.710880048511214\n",
      "MAE train 1.7296123823936955 MAE test 2.50046114879657\n",
      "Epoch 367 / 10000 loss: 16.671099424362183\n",
      "MSE train 6.199991406331313 MSE test 12.710631781547136\n",
      "MAE train 1.7295873011294154 MAE test 2.5004319114836924\n",
      "Epoch 368 / 10000 loss: 16.670398950576782\n",
      "MSE train 6.199809108241369 MSE test 12.710523879386857\n",
      "MAE train 1.7295593270116314 MAE test 2.5004247996612916\n",
      "Epoch 369 / 10000 loss: 16.66976547241211\n",
      "MSE train 6.199639344467558 MSE test 12.710275634276753\n",
      "MAE train 1.7295342490603658 MAE test 2.500395565947688\n",
      "Epoch 370 / 10000 loss: 16.669065952301025\n",
      "MSE train 6.199457009193818 MSE test 12.710167575293545\n",
      "MAE train 1.7295062701743604 MAE test 2.5003884401712058\n",
      "Epoch 371 / 10000 loss: 16.668433666229248\n",
      "MSE train 6.199287207216293 MSE test 12.709919349324913\n",
      "MAE train 1.7294811853845342 MAE test 2.5003592153627987\n",
      "Epoch 372 / 10000 loss: 16.667731523513794\n",
      "MSE train 6.1991048769402965 MSE test 12.70981147238627\n",
      "MAE train 1.7294532034061025 MAE test 2.500352115573679\n",
      "Epoch 373 / 10000 loss: 16.667099475860596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.198935128239514 MSE test 12.709563183835463\n",
      "MAE train 1.7294281299923735 MAE test 2.5003228763026213\n",
      "Epoch 374 / 10000 loss: 16.666399002075195\n",
      "MSE train 6.198752747141259 MSE test 12.709455177604813\n",
      "MAE train 1.729400138686738 MAE test 2.5003157690816042\n",
      "Epoch 375 / 10000 loss: 16.66576600074768\n",
      "MSE train 6.198582937388863 MSE test 12.709206842704727\n",
      "MAE train 1.7293750572752098 MAE test 2.5002865165930808\n",
      "Epoch 376 / 10000 loss: 16.665065050125122\n",
      "MSE train 6.1984005365884585 MSE test 12.709098902975095\n",
      "MAE train 1.7293470635240749 MAE test 2.500279419071061\n",
      "Epoch 377 / 10000 loss: 16.664432525634766\n",
      "MSE train 6.198230704254439 MSE test 12.708850422033368\n",
      "MAE train 1.729321978716164 MAE test 2.5002501523363527\n",
      "Epoch 378 / 10000 loss: 16.663731575012207\n",
      "MSE train 6.198048277266717 MSE test 12.708742284642662\n",
      "MAE train 1.7292939827874272 MAE test 2.5002430208988176\n",
      "Epoch 379 / 10000 loss: 16.66309881210327\n",
      "MSE train 6.197878478706813 MSE test 12.708493964418665\n",
      "MAE train 1.7292688941560517 MAE test 2.5002137913884397\n",
      "Epoch 380 / 10000 loss: 16.662398099899292\n",
      "MSE train 6.197695988422406 MSE test 12.70838585390912\n",
      "MAE train 1.7292408799701338 MAE test 2.500206657678763\n",
      "Epoch 381 / 10000 loss: 16.6617648601532\n",
      "MSE train 6.197526143480197 MSE test 12.70813739959691\n",
      "MAE train 1.7292157955450922 MAE test 2.5001773905450753\n",
      "Epoch 382 / 10000 loss: 16.66106367111206\n",
      "MSE train 6.197343667587307 MSE test 12.708029137350199\n",
      "MAE train 1.7291877756590062 MAE test 2.5001702550804445\n",
      "Epoch 383 / 10000 loss: 16.660431385040283\n",
      "MSE train 6.197173737417458 MSE test 12.707780744205612\n",
      "MAE train 1.7291626812684489 MAE test 2.500141010762982\n",
      "Epoch 384 / 10000 loss: 16.659730434417725\n",
      "MSE train 6.196991238701739 MSE test 12.70767250709663\n",
      "MAE train 1.7291346597799029 MAE test 2.500133872087439\n",
      "Epoch 385 / 10000 loss: 16.65909719467163\n",
      "MSE train 6.196821258768573 MSE test 12.707424036071718\n",
      "MAE train 1.729109553658016 MAE test 2.5001046138169007\n",
      "Epoch 386 / 10000 loss: 16.658396005630493\n",
      "MSE train 6.196638725680429 MSE test 12.707315736297891\n",
      "MAE train 1.729081525358075 MAE test 2.500097467070038\n",
      "Epoch 387 / 10000 loss: 16.657763957977295\n",
      "MSE train 6.196468756070581 MSE test 12.707067244147499\n",
      "MAE train 1.7290564182251966 MAE test 2.500068210976073\n",
      "Epoch 388 / 10000 loss: 16.657062530517578\n",
      "MSE train 6.196286198346387 MSE test 12.706959003574532\n",
      "MAE train 1.7290283870614926 MAE test 2.5000610799713825\n",
      "Epoch 389 / 10000 loss: 16.656429290771484\n",
      "MSE train 6.196116182003024 MSE test 12.706710416148914\n",
      "MAE train 1.7290032720541244 MAE test 2.500031802139137\n",
      "Epoch 390 / 10000 loss: 16.655729293823242\n",
      "MSE train 6.195933560094185 MSE test 12.70660198861453\n",
      "MAE train 1.7289752262576505 MAE test 2.500024656693601\n",
      "Epoch 391 / 10000 loss: 16.655096292495728\n",
      "MSE train 6.195763498132384 MSE test 12.7063533605306\n",
      "MAE train 1.728950101034023 MAE test 2.4999953791581677\n",
      "Epoch 392 / 10000 loss: 16.65439486503601\n",
      "MSE train 6.195580850382377 MSE test 12.70624488771403\n",
      "MAE train 1.7289220522816398 MAE test 2.4999882275891063\n",
      "Epoch 393 / 10000 loss: 16.653761625289917\n",
      "MSE train 6.195410721899123 MSE test 12.705996234525811\n",
      "MAE train 1.7288969264858494 MAE test 2.4999589382517917\n",
      "Epoch 394 / 10000 loss: 16.653059720993042\n",
      "MSE train 6.19522796771414 MSE test 12.705887787920862\n",
      "MAE train 1.7288688573952409 MAE test 2.4999517903884136\n",
      "Epoch 395 / 10000 loss: 16.65242648124695\n",
      "MSE train 6.195057848788694 MSE test 12.705639126104689\n",
      "MAE train 1.7288437262925083 MAE test 2.4999225067327346\n",
      "Epoch 396 / 10000 loss: 16.65172505378723\n",
      "MSE train 6.194875066913532 MSE test 12.705530507321933\n",
      "MAE train 1.728815649430285 MAE test 2.4999153426411334\n",
      "Epoch 397 / 10000 loss: 16.651092290878296\n",
      "MSE train 6.194704833259863 MSE test 12.705281812916782\n",
      "MAE train 1.7287905071973404 MAE test 2.4998860649781256\n",
      "Epoch 398 / 10000 loss: 16.65039038658142\n",
      "MSE train 6.194521992015204 MSE test 12.705173134915928\n",
      "MAE train 1.7287624160498063 MAE test 2.4998788803580494\n",
      "Epoch 399 / 10000 loss: 16.649757623672485\n",
      "MSE train 6.194351693025773 MSE test 12.704924498766857\n",
      "MAE train 1.7287372607744442 MAE test 2.4998496134776444\n",
      "Epoch 400 / 10000 loss: 16.649055004119873\n",
      "MSE train 6.194168837287606 MSE test 12.704815801020356\n",
      "MAE train 1.728709163739148 MAE test 2.4998424183966224\n",
      "Epoch 401 / 10000 loss: 16.64842176437378\n",
      "MSE train 6.1939985223930725 MSE test 12.704566928590559\n",
      "MAE train 1.7286840096090277 MAE test 2.499813126785942\n",
      "Epoch 402 / 10000 loss: 16.647720098495483\n",
      "MSE train 6.193815509137686 MSE test 12.704458282887018\n",
      "MAE train 1.7286558917064045 MAE test 2.4998059466519194\n",
      "Epoch 403 / 10000 loss: 16.647085189819336\n",
      "MSE train 6.193645095268051 MSE test 12.704209357481743\n",
      "MAE train 1.7286307137390642 MAE test 2.4997766502697427\n",
      "Epoch 404 / 10000 loss: 16.6463840007782\n",
      "MSE train 6.193462030665585 MSE test 12.704100524411942\n",
      "MAE train 1.7286025895813608 MAE test 2.4997694362971483\n",
      "Epoch 405 / 10000 loss: 16.645749807357788\n",
      "MSE train 6.1932915114755875 MSE test 12.703851555602244\n",
      "MAE train 1.7285773992207298 MAE test 2.499740134551425\n",
      "Epoch 406 / 10000 loss: 16.645047664642334\n",
      "MSE train 6.193108343786464 MSE test 12.70374270226182\n",
      "MAE train 1.728549259060774 MAE test 2.499732942843416\n",
      "Epoch 407 / 10000 loss: 16.644412994384766\n",
      "MSE train 6.192937747493264 MSE test 12.703493781276784\n",
      "MAE train 1.7285240552568308 MAE test 2.499703642345411\n",
      "Epoch 408 / 10000 loss: 16.643710613250732\n",
      "MSE train 6.192754454161372 MSE test 12.703384878502309\n",
      "MAE train 1.7284958926048606 MAE test 2.4996964493200236\n",
      "Epoch 409 / 10000 loss: 16.643076181411743\n",
      "MSE train 6.192583764231302 MSE test 12.703135799434873\n",
      "MAE train 1.7284706759271193 MAE test 2.499667130763571\n",
      "Epoch 410 / 10000 loss: 16.642373085021973\n",
      "MSE train 6.19240035081299 MSE test 12.703026748896521\n",
      "MAE train 1.728442492707148 MAE test 2.499659910540668\n",
      "Epoch 411 / 10000 loss: 16.641738176345825\n",
      "MSE train 6.19222952879778 MSE test 12.702777652641883\n",
      "MAE train 1.728417258159144 MAE test 2.499630591405372\n",
      "Epoch 412 / 10000 loss: 16.641034603118896\n",
      "MSE train 6.192045984440243 MSE test 12.702668403136624\n",
      "MAE train 1.728389052322945 MAE test 2.4996233506070364\n",
      "Epoch 413 / 10000 loss: 16.640398740768433\n",
      "MSE train 6.1918750147946 MSE test 12.702419153900994\n",
      "MAE train 1.7283637922122297 MAE test 2.499594018584977\n",
      "Epoch 414 / 10000 loss: 16.63969588279724\n",
      "MSE train 6.191691354510995 MSE test 12.702310043141411\n",
      "MAE train 1.7283355702312504 MAE test 2.4995867988669387\n",
      "Epoch 415 / 10000 loss: 16.63905954360962\n",
      "MSE train 6.191520186308416 MSE test 12.70206073111128\n",
      "MAE train 1.728310279738719 MAE test 2.4995574514368544\n",
      "Epoch 416 / 10000 loss: 16.63835573196411\n",
      "MSE train 6.191336381799904 MSE test 12.70195148108411\n",
      "MAE train 1.728282033830503 MAE test 2.499550216002259\n",
      "Epoch 417 / 10000 loss: 16.63771915435791\n",
      "MSE train 6.191165091289235 MSE test 12.701702156346157\n",
      "MAE train 1.7282567278644188 MAE test 2.4995208775257063\n",
      "Epoch 418 / 10000 loss: 16.637014389038086\n",
      "MSE train 6.1909810068094675 MSE test 12.701592622030361\n",
      "MAE train 1.7282284354395074 MAE test 2.499513603907448\n",
      "Epoch 419 / 10000 loss: 16.636377573013306\n",
      "MSE train 6.190809501972871 MSE test 12.70134320964179\n",
      "MAE train 1.7282030999295661 MAE test 2.4994842611815633\n",
      "Epoch 420 / 10000 loss: 16.635671854019165\n",
      "MSE train 6.1906251608347755 MSE test 12.701233821892517\n",
      "MAE train 1.7281747743241347 MAE test 2.499477000037756\n",
      "Epoch 421 / 10000 loss: 16.63503336906433\n",
      "MSE train 6.190453380530703 MSE test 12.700984153354307\n",
      "MAE train 1.7281493951307614 MAE test 2.499447619214609\n",
      "Epoch 422 / 10000 loss: 16.634326934814453\n",
      "MSE train 6.190268805547682 MSE test 12.700874655549455\n",
      "MAE train 1.7281210308375705 MAE test 2.49944036579006\n",
      "Epoch 423 / 10000 loss: 16.63368797302246\n",
      "MSE train 6.190096713013995 MSE test 12.700624833963422\n",
      "MAE train 1.7280956031329908 MAE test 2.4994109620382816\n",
      "Epoch 424 / 10000 loss: 16.632980585098267\n",
      "MSE train 6.1899118134396165 MSE test 12.700515131933258\n",
      "MAE train 1.7280671893235227 MAE test 2.4994036741900367\n",
      "Epoch 425 / 10000 loss: 16.632340908050537\n",
      "MSE train 6.189739335593325 MSE test 12.700265386323967\n",
      "MAE train 1.7280417097842853 MAE test 2.499374290694791\n",
      "Epoch 426 / 10000 loss: 16.63163185119629\n",
      "MSE train 6.189554034770615 MSE test 12.700155644511286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7280132401431163 MAE test 2.499366999644164\n",
      "Epoch 427 / 10000 loss: 16.630990266799927\n",
      "MSE train 6.189381169499782 MSE test 12.699905712687226\n",
      "MAE train 1.7279877073813301 MAE test 2.4993376056420122\n",
      "Epoch 428 / 10000 loss: 16.63028049468994\n",
      "MSE train 6.189195372276838 MSE test 12.699795809483598\n",
      "MAE train 1.7279591525334763 MAE test 2.499330299249421\n",
      "Epoch 429 / 10000 loss: 16.629637002944946\n",
      "MSE train 6.18902193943376 MSE test 12.699545598286706\n",
      "MAE train 1.7279335428693121 MAE test 2.499300856849397\n",
      "Epoch 430 / 10000 loss: 16.62892508506775\n",
      "MSE train 6.188835534654283 MSE test 12.699435559355612\n",
      "MAE train 1.7279048982496534 MAE test 2.499293539839282\n",
      "Epoch 431 / 10000 loss: 16.62827968597412\n",
      "MSE train 6.188661407756222 MSE test 12.699185354051627\n",
      "MAE train 1.7278791884878388 MAE test 2.4992640988407437\n",
      "Epoch 432 / 10000 loss: 16.627565383911133\n",
      "MSE train 6.188474251135137 MSE test 12.699075065210339\n",
      "MAE train 1.7278504342065983 MAE test 2.4992567553230014\n",
      "Epoch 433 / 10000 loss: 16.626917839050293\n",
      "MSE train 6.188299309572147 MSE test 12.698824788890894\n",
      "MAE train 1.7278246067099499 MAE test 2.49922732192508\n",
      "Epoch 434 / 10000 loss: 16.626198768615723\n",
      "MSE train 6.188111163632722 MSE test 12.69871437142716\n",
      "MAE train 1.7277957112117217 MAE test 2.499219955224439\n",
      "Epoch 435 / 10000 loss: 16.625547885894775\n",
      "MSE train 6.187935116619714 MSE test 12.698463822686332\n",
      "MAE train 1.7277697250663975 MAE test 2.4991904959454954\n",
      "Epoch 436 / 10000 loss: 16.624826669692993\n",
      "MSE train 6.187745752369138 MSE test 12.698353073937954\n",
      "MAE train 1.727740651798268 MAE test 2.4991830966628736\n",
      "Epoch 437 / 10000 loss: 16.624170064926147\n",
      "MSE train 6.187568340975684 MSE test 12.698102403330594\n",
      "MAE train 1.7277144667788615 MAE test 2.499153622905936\n",
      "Epoch 438 / 10000 loss: 16.623443603515625\n",
      "MSE train 6.187377309442183 MSE test 12.697991454609184\n",
      "MAE train 1.727685161930023 MAE test 2.4991462202106374\n",
      "Epoch 439 / 10000 loss: 16.622780561447144\n",
      "MSE train 6.187198009542073 MSE test 12.6977403362272\n",
      "MAE train 1.7276587029687955 MAE test 2.4991166969403804\n",
      "Epoch 440 / 10000 loss: 16.622047662734985\n",
      "MSE train 6.187004945501645 MSE test 12.697629244707391\n",
      "MAE train 1.7276291074589423 MAE test 2.4991092788283455\n",
      "Epoch 441 / 10000 loss: 16.621378183364868\n",
      "MSE train 6.186823295477261 MSE test 12.697377946892974\n",
      "MAE train 1.7276023273558643 MAE test 2.499079741611646\n",
      "Epoch 442 / 10000 loss: 16.620635509490967\n",
      "MSE train 6.186627717022895 MSE test 12.697266440341402\n",
      "MAE train 1.7275723763823223 MAE test 2.49907226341533\n",
      "Epoch 443 / 10000 loss: 16.61995553970337\n",
      "MSE train 6.186443235953248 MSE test 12.697014693757136\n",
      "MAE train 1.7275451903441073 MAE test 2.4990426832943036\n",
      "Epoch 444 / 10000 loss: 16.619201183319092\n",
      "MSE train 6.186244680066912 MSE test 12.69690289977283\n",
      "MAE train 1.7275147885566884 MAE test 2.4990351838051756\n",
      "Epoch 445 / 10000 loss: 16.618510246276855\n",
      "MSE train 6.1860572603271695 MSE test 12.696650851637253\n",
      "MAE train 1.7274871472198825 MAE test 2.49900556784377\n",
      "Epoch 446 / 10000 loss: 16.617743492126465\n",
      "MSE train 6.185855740731668 MSE test 12.69653852795562\n",
      "MAE train 1.7274562423295778 MAE test 2.498997994941734\n",
      "Epoch 447 / 10000 loss: 16.617037534713745\n",
      "MSE train 6.185666008059281 MSE test 12.696286300756636\n",
      "MAE train 1.727428198810576 MAE test 2.498968374680649\n",
      "Epoch 448 / 10000 loss: 16.61625838279724\n",
      "MSE train 6.18546310025727 MSE test 12.696173922862558\n",
      "MAE train 1.7273971670565356 MAE test 2.498960808873156\n",
      "Epoch 449 / 10000 loss: 16.615542888641357\n",
      "MSE train 6.185273088610268 MSE test 12.695921539161757\n",
      "MAE train 1.7273692308455242 MAE test 2.498931150665612\n",
      "Epoch 450 / 10000 loss: 16.61475706100464\n",
      "MSE train 6.185071452210503 MSE test 12.695808806433242\n",
      "MAE train 1.7273384204481848 MAE test 2.498923538809568\n",
      "Epoch 451 / 10000 loss: 16.6140398979187\n",
      "MSE train 6.184884312000977 MSE test 12.695556444669648\n",
      "MAE train 1.727310844320841 MAE test 2.4988938845507906\n",
      "Epoch 452 / 10000 loss: 16.613259315490723\n",
      "MSE train 6.184686724412483 MSE test 12.695443849972843\n",
      "MAE train 1.7272805474715116 MAE test 2.498886266280108\n",
      "Epoch 453 / 10000 loss: 16.6125545501709\n",
      "MSE train 6.184504342441349 MSE test 12.695191789541045\n",
      "MAE train 1.7272535694595947 MAE test 2.4988566283267413\n",
      "Epoch 454 / 10000 loss: 16.611790895462036\n",
      "MSE train 6.184311733208132 MSE test 12.695079513009105\n",
      "MAE train 1.7272239372553402 MAE test 2.4988490493021347\n",
      "Epoch 455 / 10000 loss: 16.611106395721436\n",
      "MSE train 6.184134054264398 MSE test 12.694827720839356\n",
      "MAE train 1.7271976407017726 MAE test 2.4988194296043233\n",
      "Epoch 456 / 10000 loss: 16.610364198684692\n",
      "MSE train 6.183945543201996 MSE test 12.694715601155432\n",
      "MAE train 1.727168570568184 MAE test 2.4988118590926134\n",
      "Epoch 457 / 10000 loss: 16.609699010849\n",
      "MSE train 6.183771109137999 MSE test 12.69446407125303\n",
      "MAE train 1.7271426853189003 MAE test 2.498782268662702\n",
      "Epoch 458 / 10000 loss: 16.608973264694214\n",
      "MSE train 6.183585129823713 MSE test 12.69435228348722\n",
      "MAE train 1.7271139280867935 MAE test 2.4987747323956855\n",
      "Epoch 459 / 10000 loss: 16.608320951461792\n",
      "MSE train 6.183412620263939 MSE test 12.69410078772497\n",
      "MAE train 1.727088308425304 MAE test 2.4987451511551417\n",
      "Epoch 460 / 10000 loss: 16.60760498046875\n",
      "MSE train 6.183228061077511 MSE test 12.693989182969384\n",
      "MAE train 1.7270597584357175 MAE test 2.498737641200709\n",
      "Epoch 461 / 10000 loss: 16.606959342956543\n",
      "MSE train 6.183056605500063 MSE test 12.693737703464055\n",
      "MAE train 1.7270342678036945 MAE test 2.4987080649843385\n",
      "Epoch 462 / 10000 loss: 16.6062490940094\n",
      "MSE train 6.182872723551284 MSE test 12.69362603815275\n",
      "MAE train 1.7270058012135967 MAE test 2.498700559082647\n",
      "Epoch 463 / 10000 loss: 16.605608224868774\n",
      "MSE train 6.182701822015031 MSE test 12.693374611803423\n",
      "MAE train 1.726980386376162 MAE test 2.4986709869931802\n",
      "Epoch 464 / 10000 loss: 16.604899168014526\n",
      "MSE train 6.182518351030847 MSE test 12.693262904772881\n",
      "MAE train 1.7269519676826186 MAE test 2.4986634959533083\n",
      "Epoch 465 / 10000 loss: 16.604260444641113\n",
      "MSE train 6.18234764418189 MSE test 12.693011445454768\n",
      "MAE train 1.726926580276628 MAE test 2.4986339309106986\n",
      "Epoch 466 / 10000 loss: 16.60355257987976\n",
      "MSE train 6.1821643131913095 MSE test 12.692899736147638\n",
      "MAE train 1.7268981732600108 MAE test 2.4986264237495477\n",
      "Epoch 467 / 10000 loss: 16.602914333343506\n",
      "MSE train 6.181993741865942 MSE test 12.692648077630984\n",
      "MAE train 1.7268727971803677 MAE test 2.4985968453163863\n",
      "Epoch 468 / 10000 loss: 16.602207899093628\n",
      "MSE train 6.18181042722024 MSE test 12.692536455989282\n",
      "MAE train 1.7268443849254294 MAE test 2.498589380045257\n",
      "Epoch 469 / 10000 loss: 16.601568698883057\n",
      "MSE train 6.181639808423271 MSE test 12.692284804676847\n",
      "MAE train 1.7268190008956976 MAE test 2.498559822060326\n",
      "Epoch 470 / 10000 loss: 16.60086441040039\n",
      "MSE train 6.181456462163355 MSE test 12.692172765456043\n",
      "MAE train 1.7267905840377007 MAE test 2.4985522986861266\n",
      "Epoch 471 / 10000 loss: 16.600225687026978\n",
      "MSE train 6.181285750425839 MSE test 12.691921250496124\n",
      "MAE train 1.7267651861873035 MAE test 2.4985227614234593\n",
      "Epoch 472 / 10000 loss: 16.59951901435852\n",
      "MSE train 6.181102309332988 MSE test 12.691809166616807\n",
      "MAE train 1.7267367460416294 MAE test 2.49851525195074\n",
      "Epoch 473 / 10000 loss: 16.598881483078003\n",
      "MSE train 6.180931450909396 MSE test 12.691557485015315\n",
      "MAE train 1.7267113221387909 MAE test 2.498485706906923\n",
      "Epoch 474 / 10000 loss: 16.598175287246704\n",
      "MSE train 6.180747955740341 MSE test 12.6914452308147\n",
      "MAE train 1.726682879616816 MAE test 2.498478166543186\n",
      "Epoch 475 / 10000 loss: 16.597535848617554\n",
      "MSE train 6.18057700950346 MSE test 12.691193354105774\n",
      "MAE train 1.726657435302123 MAE test 2.498448610418574\n",
      "Epoch 476 / 10000 loss: 16.5968279838562\n",
      "MSE train 6.1803932868828895 MSE test 12.691081020584964\n",
      "MAE train 1.7266289539373323 MAE test 2.498441065378098\n",
      "Epoch 477 / 10000 loss: 16.596190690994263\n",
      "MSE train 6.180222192286898 MSE test 12.690829005919987\n",
      "MAE train 1.726603487696385 MAE test 2.498411512631146\n",
      "Epoch 478 / 10000 loss: 16.59548306465149\n",
      "MSE train 6.180038281344038 MSE test 12.690716445171162\n",
      "MAE train 1.7265749703459947 MAE test 2.4984039478230984\n",
      "Epoch 479 / 10000 loss: 16.594843864440918\n",
      "MSE train 6.179867015546295 MSE test 12.690464246255324\n",
      "MAE train 1.7265494796725391 MAE test 2.498374379980677\n",
      "Epoch 480 / 10000 loss: 16.594135999679565\n",
      "MSE train 6.179682967045112 MSE test 12.69035152681327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7265209224859555 MAE test 2.498366798713785\n",
      "Epoch 481 / 10000 loss: 16.593495845794678\n",
      "MSE train 6.179511435929005 MSE test 12.690099093951163\n",
      "MAE train 1.726495384723082 MAE test 2.4983372077500143\n",
      "Epoch 482 / 10000 loss: 16.59278702735901\n",
      "MSE train 6.179327169596996 MSE test 12.689986132877209\n",
      "MAE train 1.7264667904248652 MAE test 2.498329612371275\n",
      "Epoch 483 / 10000 loss: 16.59214687347412\n",
      "MSE train 6.179155468874894 MSE test 12.689733491461478\n",
      "MAE train 1.7264412205771227 MAE test 2.498300009737183\n",
      "Epoch 484 / 10000 loss: 16.591436862945557\n",
      "MSE train 6.17897088869977 MSE test 12.689620372249614\n",
      "MAE train 1.7264125719170196 MAE test 2.4982924060380713\n",
      "Epoch 485 / 10000 loss: 16.590795755386353\n",
      "MSE train 6.17879892428842 MSE test 12.689367463532445\n",
      "MAE train 1.72638694679751 MAE test 2.4982627809014026\n",
      "Epoch 486 / 10000 loss: 16.59008502960205\n",
      "MSE train 6.178614130877933 MSE test 12.689253927140696\n",
      "MAE train 1.7263582489439262 MAE test 2.4982551305213097\n",
      "Epoch 487 / 10000 loss: 16.58944296836853\n",
      "MSE train 6.1784418622805415 MSE test 12.68900076152285\n",
      "MAE train 1.7263325673601781 MAE test 2.4982254862184616\n",
      "Epoch 488 / 10000 loss: 16.588730812072754\n",
      "MSE train 6.1782566334222855 MSE test 12.68888686527883\n",
      "MAE train 1.726303797076505 MAE test 2.4982178110351185\n",
      "Epoch 489 / 10000 loss: 16.58808732032776\n",
      "MSE train 6.178083999362473 MSE test 12.688633316890828\n",
      "MAE train 1.7262780450811228 MAE test 2.4981881471382943\n",
      "Epoch 490 / 10000 loss: 16.587373733520508\n",
      "MSE train 6.177898417650114 MSE test 12.68851910882096\n",
      "MAE train 1.7262491978661498 MAE test 2.4981804463926225\n",
      "Epoch 491 / 10000 loss: 16.5867280960083\n",
      "MSE train 6.177725280461167 MSE test 12.688265216080213\n",
      "MAE train 1.726223356387706 MAE test 2.4981507565240553\n",
      "Epoch 492 / 10000 loss: 16.586012601852417\n",
      "MSE train 6.177539112860381 MSE test 12.688150505323044\n",
      "MAE train 1.7261943978501741 MAE test 2.4981430101918334\n",
      "Epoch 493 / 10000 loss: 16.585365533828735\n",
      "MSE train 6.177365402131735 MSE test 12.687896083362462\n",
      "MAE train 1.7261684516140616 MAE test 2.4981132907911636\n",
      "Epoch 494 / 10000 loss: 16.58464813232422\n",
      "MSE train 6.177178527386375 MSE test 12.68778085239196\n",
      "MAE train 1.726139356432133 MAE test 2.4981055079560535\n",
      "Epoch 495 / 10000 loss: 16.583998203277588\n",
      "MSE train 6.177003970353515 MSE test 12.687525716402273\n",
      "MAE train 1.7261132577689469 MAE test 2.498075721878458\n",
      "Epoch 496 / 10000 loss: 16.583277225494385\n",
      "MSE train 6.176816109161794 MSE test 12.687409766301114\n",
      "MAE train 1.726083981245554 MAE test 2.498067895127152\n",
      "Epoch 497 / 10000 loss: 16.582622051239014\n",
      "MSE train 6.17664034404185 MSE test 12.687153945366516\n",
      "MAE train 1.7260576532706344 MAE test 2.498038060438487\n",
      "Epoch 498 / 10000 loss: 16.581896543502808\n",
      "MSE train 6.176451052392531 MSE test 12.687036997283249\n",
      "MAE train 1.726028118467809 MAE test 2.4980301297911387\n",
      "Epoch 499 / 10000 loss: 16.581236839294434\n",
      "MSE train 6.176273570526465 MSE test 12.686780067009074\n",
      "MAE train 1.7260014724758574 MAE test 2.498000211898753\n",
      "Epoch 500 / 10000 loss: 16.580503463745117\n",
      "MSE train 6.176082051564774 MSE test 12.686662044788532\n",
      "MAE train 1.7259715162626939 MAE test 2.497992205800708\n",
      "Epoch 501 / 10000 loss: 16.579835176467896\n",
      "MSE train 6.17590171305425 MSE test 12.686403792964079\n",
      "MAE train 1.7259443469738225 MAE test 2.497962197327565\n",
      "Epoch 502 / 10000 loss: 16.579092502593994\n",
      "MSE train 6.175706616207488 MSE test 12.686284187623848\n",
      "MAE train 1.7259137303443157 MAE test 2.497954077307203\n",
      "Epoch 503 / 10000 loss: 16.578409671783447\n",
      "MSE train 6.17552153874931 MSE test 12.686024016427655\n",
      "MAE train 1.7258856727570022 MAE test 2.4979239189390143\n",
      "Epoch 504 / 10000 loss: 16.57765030860901\n",
      "MSE train 6.175320049454267 MSE test 12.685902088678958\n",
      "MAE train 1.7258538305848292 MAE test 2.49791562504484\n",
      "Epoch 505 / 10000 loss: 16.57694435119629\n",
      "MSE train 6.175126500656647 MSE test 12.685639197081256\n",
      "MAE train 1.7258241391142777 MAE test 2.4978852596561043\n",
      "Epoch 506 / 10000 loss: 16.576152801513672\n",
      "MSE train 6.17491358275617 MSE test 12.68551418892153\n",
      "MAE train 1.7257901091128265 MAE test 2.4978767327465596\n",
      "Epoch 507 / 10000 loss: 16.57540798187256\n",
      "MSE train 6.174704740901302 MSE test 12.685247784057765\n",
      "MAE train 1.7257574668027529 MAE test 2.497846104052362\n",
      "Epoch 508 / 10000 loss: 16.57456135749817\n",
      "MSE train 6.174472680098004 MSE test 12.685118671178598\n",
      "MAE train 1.7257196597994204 MAE test 2.4978372444218695\n",
      "Epoch 509 / 10000 loss: 16.57374143600464\n",
      "MSE train 6.174242837041652 MSE test 12.684848400653383\n",
      "MAE train 1.7256827802521877 MAE test 2.4978063324158786\n",
      "Epoch 510 / 10000 loss: 16.57280158996582\n",
      "MSE train 6.17399466249476 MSE test 12.684716545537496\n",
      "MAE train 1.7256412177858078 MAE test 2.497797268797555\n",
      "Epoch 511 / 10000 loss: 16.57188081741333\n",
      "MSE train 6.173764436718289 MSE test 12.684446619703039\n",
      "MAE train 1.7256035514106485 MAE test 2.497766405257715\n",
      "Epoch 512 / 10000 loss: 16.570862531661987\n",
      "MSE train 6.173536896591137 MSE test 12.68431963857716\n",
      "MAE train 1.725565835033385 MAE test 2.4977577246202665\n",
      "Epoch 513 / 10000 loss: 16.56993842124939\n",
      "MSE train 6.173338999892418 MSE test 12.684058087748847\n",
      "MAE train 1.7255346758829224 MAE test 2.497727463640413\n",
      "Epoch 514 / 10000 loss: 16.56901979446411\n",
      "MSE train 6.17314000525067 MSE test 12.683940336470334\n",
      "MAE train 1.7255027998937529 MAE test 2.4977194835967604\n",
      "Epoch 515 / 10000 loss: 16.568253993988037\n",
      "MSE train 6.1729602908879695 MSE test 12.683686321137138\n",
      "MAE train 1.7254753320032732 MAE test 2.4976897988599953\n",
      "Epoch 516 / 10000 loss: 16.56747531890869\n",
      "MSE train 6.172771200901249 MSE test 12.683573687104499\n",
      "MAE train 1.7254455298782452 MAE test 2.4976821941796614\n",
      "Epoch 517 / 10000 loss: 16.56679630279541\n",
      "MSE train 6.172596532612029 MSE test 12.68332295652533\n",
      "MAE train 1.7254192195061024 MAE test 2.4976527799718524\n",
      "Epoch 518 / 10000 loss: 16.566065549850464\n",
      "MSE train 6.172410058437343 MSE test 12.683212563195395\n",
      "MAE train 1.7253900203883146 MAE test 2.4976453673050885\n",
      "Epoch 519 / 10000 loss: 16.565412521362305\n",
      "MSE train 6.172236830236708 MSE test 12.68296308030196\n",
      "MAE train 1.7253640671043644 MAE test 2.497616050204811\n",
      "Epoch 520 / 10000 loss: 16.564696073532104\n",
      "MSE train 6.1720512152601215 MSE test 12.682853228662738\n",
      "MAE train 1.7253351016344174 MAE test 2.497608667119976\n",
      "Epoch 521 / 10000 loss: 16.564048528671265\n",
      "MSE train 6.171878468892717 MSE test 12.682604213966297\n",
      "MAE train 1.7253092983876335 MAE test 2.497579375931226\n",
      "Epoch 522 / 10000 loss: 16.563335180282593\n",
      "MSE train 6.1716931034688 MSE test 12.682494566277258\n",
      "MAE train 1.7252804252001448 MAE test 2.497572013840791\n",
      "Epoch 523 / 10000 loss: 16.56269097328186\n",
      "MSE train 6.171520557088002 MSE test 12.682245563568983\n",
      "MAE train 1.7252546824717452 MAE test 2.497542721252724\n",
      "Epoch 524 / 10000 loss: 16.56197762489319\n",
      "MSE train 6.171335374981741 MSE test 12.682135814123248\n",
      "MAE train 1.725225835967513 MAE test 2.4975353422880966\n",
      "Epoch 525 / 10000 loss: 16.56133508682251\n",
      "MSE train 6.171162939432496 MSE test 12.681886662933426\n",
      "MAE train 1.7252001326761572 MAE test 2.497506027603977\n",
      "Epoch 526 / 10000 loss: 16.560622692108154\n",
      "MSE train 6.170977775487702 MSE test 12.681776866684334\n",
      "MAE train 1.7251712987340537 MAE test 2.4974986450778416\n",
      "Epoch 527 / 10000 loss: 16.559980630874634\n",
      "MSE train 6.170805344193742 MSE test 12.681527680858318\n",
      "MAE train 1.7251456012386148 MAE test 2.4974693336089326\n",
      "Epoch 528 / 10000 loss: 16.559269189834595\n",
      "MSE train 6.170620266762841 MSE test 12.681417588816451\n",
      "MAE train 1.7251167830376186 MAE test 2.4974619039590324\n",
      "Epoch 529 / 10000 loss: 16.55862593650818\n",
      "MSE train 6.1704479192678425 MSE test 12.681168246132989\n",
      "MAE train 1.7250910959908252 MAE test 2.4974325915674216\n",
      "Epoch 530 / 10000 loss: 16.55791473388672\n",
      "MSE train 6.170262876243317 MSE test 12.681057974098005\n",
      "MAE train 1.725062282189523 MAE test 2.4974251432278245\n",
      "Epoch 531 / 10000 loss: 16.55727219581604\n",
      "MSE train 6.170090545246431 MSE test 12.68080844185569\n",
      "MAE train 1.7250365907396692 MAE test 2.497395807299692\n",
      "Epoch 532 / 10000 loss: 16.556560039520264\n",
      "MSE train 6.169905484567842 MSE test 12.680698104011347\n",
      "MAE train 1.725007763657049 MAE test 2.49738834419576\n",
      "Epoch 533 / 10000 loss: 16.555917978286743\n",
      "MSE train 6.169733198841306 MSE test 12.680448365356096\n",
      "MAE train 1.7249820867723114 MAE test 2.4973589969968337\n",
      "Epoch 534 / 10000 loss: 16.55520725250244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.169548110207901 MSE test 12.680337796242576\n",
      "MAE train 1.7249532489813733 MAE test 2.497351509569496\n",
      "Epoch 535 / 10000 loss: 16.554564952850342\n",
      "MSE train 6.1693758888238115 MSE test 12.680088118463889\n",
      "MAE train 1.724927582689086 MAE test 2.4973221530093115\n",
      "Epoch 536 / 10000 loss: 16.55385446548462\n",
      "MSE train 6.169190846371271 MSE test 12.679977438292603\n",
      "MAE train 1.7248987507988887 MAE test 2.497314672370217\n",
      "Epoch 537 / 10000 loss: 16.553210735321045\n",
      "MSE train 6.169018628081961 MSE test 12.679727493028604\n",
      "MAE train 1.7248730779898034 MAE test 2.4972852852495615\n",
      "Epoch 538 / 10000 loss: 16.55250120162964\n",
      "MSE train 6.168833649181363 MSE test 12.679616745087307\n",
      "MAE train 1.724844245765992 MAE test 2.497277791748029\n",
      "Epoch 539 / 10000 loss: 16.551859617233276\n",
      "MSE train 6.168661428322028 MSE test 12.679366868885541\n",
      "MAE train 1.7248185677808987 MAE test 2.4972484168010176\n",
      "Epoch 540 / 10000 loss: 16.551148176193237\n",
      "MSE train 6.168476493282417 MSE test 12.679256015809452\n",
      "MAE train 1.7247897330913764 MAE test 2.497240905378027\n",
      "Epoch 541 / 10000 loss: 16.5505051612854\n",
      "MSE train 6.168304260460653 MSE test 12.679006030859039\n",
      "MAE train 1.7247640501560295 MAE test 2.497211513743211\n",
      "Epoch 542 / 10000 loss: 16.5497944355011\n",
      "MSE train 6.168119290866348 MSE test 12.678895288929848\n",
      "MAE train 1.7247351980226986 MAE test 2.4972040320494773\n",
      "Epoch 543 / 10000 loss: 16.549153566360474\n",
      "MSE train 6.1679471617541655 MSE test 12.678645290205163\n",
      "MAE train 1.7247095255831675 MAE test 2.497174642549673\n",
      "Epoch 544 / 10000 loss: 16.54844331741333\n",
      "MSE train 6.167762299513247 MSE test 12.678534366878928\n",
      "MAE train 1.7246806928663343 MAE test 2.497167145506234\n",
      "Epoch 545 / 10000 loss: 16.54780077934265\n",
      "MSE train 6.167590189063743 MSE test 12.678284345804789\n",
      "MAE train 1.724655029446503 MAE test 2.497137754873666\n",
      "Epoch 546 / 10000 loss: 16.547091484069824\n",
      "MSE train 6.167405419146276 MSE test 12.678173534062992\n",
      "MAE train 1.724626212212649 MAE test 2.497130265790569\n",
      "Epoch 547 / 10000 loss: 16.546449899673462\n",
      "MSE train 6.167233331154589 MSE test 12.67792337463461\n",
      "MAE train 1.7246005476821817 MAE test 2.4971008597339357\n",
      "Epoch 548 / 10000 loss: 16.545739889144897\n",
      "MSE train 6.167048518077959 MSE test 12.677812466458727\n",
      "MAE train 1.7245717138791041 MAE test 2.4970933422585566\n",
      "Epoch 549 / 10000 loss: 16.545098304748535\n",
      "MSE train 6.1668765642488 MSE test 12.677562402495596\n",
      "MAE train 1.7245460678920908 MAE test 2.497063961734638\n",
      "Epoch 550 / 10000 loss: 16.544389724731445\n",
      "MSE train 6.166691858648079 MSE test 12.677451491587126\n",
      "MAE train 1.724517241853549 MAE test 2.497056444669503\n",
      "Epoch 551 / 10000 loss: 16.543747663497925\n",
      "MSE train 6.166519911126495 MSE test 12.677201551553841\n",
      "MAE train 1.72449159644531 MAE test 2.497027066835427\n",
      "Epoch 552 / 10000 loss: 16.54303812980652\n",
      "MSE train 6.166335261817488 MSE test 12.677090608896052\n",
      "MAE train 1.724462775085432 MAE test 2.4970195495848198\n",
      "Epoch 553 / 10000 loss: 16.54239773750305\n",
      "MSE train 6.166163440727447 MSE test 12.676840665077194\n",
      "MAE train 1.724437152084653 MAE test 2.4969901712464115\n",
      "Epoch 554 / 10000 loss: 16.541688442230225\n",
      "MSE train 6.16597888414082 MSE test 12.676729787689608\n",
      "MAE train 1.7244083419485383 MAE test 2.4969826646551154\n",
      "Epoch 555 / 10000 loss: 16.541048049926758\n",
      "MSE train 6.165807081359637 MSE test 12.676480013904152\n",
      "MAE train 1.7243827283380602 MAE test 2.4969533063077227\n",
      "Epoch 556 / 10000 loss: 16.54033899307251\n",
      "MSE train 6.1656225866845125 MSE test 12.676368989419002\n",
      "MAE train 1.7243539301721604 MAE test 2.49694578272748\n",
      "Epoch 557 / 10000 loss: 16.539698362350464\n",
      "MSE train 6.165450891369111 MSE test 12.676119145483487\n",
      "MAE train 1.7243283384775165 MAE test 2.496916418987667\n",
      "Epoch 558 / 10000 loss: 16.53899121284485\n",
      "MSE train 6.165266483413991 MSE test 12.676008123787259\n",
      "MAE train 1.7242995507123495 MAE test 2.496908887134018\n",
      "Epoch 559 / 10000 loss: 16.53835129737854\n",
      "MSE train 6.165094864142942 MSE test 12.675758422235145\n",
      "MAE train 1.7242739744720135 MAE test 2.496879534973582\n",
      "Epoch 560 / 10000 loss: 16.53764247894287\n",
      "MSE train 6.164910541616043 MSE test 12.67564751490755\n",
      "MAE train 1.7242451984642875 MAE test 2.496872005464473\n",
      "Epoch 561 / 10000 loss: 16.53700304031372\n",
      "MSE train 6.164739040529134 MSE test 12.675397735864419\n",
      "MAE train 1.7242196513989563 MAE test 2.4968426422971075\n",
      "Epoch 562 / 10000 loss: 16.536296129226685\n",
      "MSE train 6.164554826836342 MSE test 12.675286837308501\n",
      "MAE train 1.7241909004447624 MAE test 2.496835119526473\n",
      "Epoch 563 / 10000 loss: 16.535656929016113\n",
      "MSE train 6.164383387268463 MSE test 12.675037192031231\n",
      "MAE train 1.7241653663043237 MAE test 2.4968057790432865\n",
      "Epoch 564 / 10000 loss: 16.53494954109192\n",
      "MSE train 6.164199233592448 MSE test 12.674926499847864\n",
      "MAE train 1.724136621337245 MAE test 2.4967982725178106\n",
      "Epoch 565 / 10000 loss: 16.534311056137085\n",
      "MSE train 6.164027984300261 MSE test 12.674676614021193\n",
      "MAE train 1.724111116075848 MAE test 2.4967688901513894\n",
      "Epoch 566 / 10000 loss: 16.533605098724365\n",
      "MSE train 6.163843936801078 MSE test 12.67456589948546\n",
      "MAE train 1.7240823941418326 MAE test 2.496761387690568\n",
      "Epoch 567 / 10000 loss: 16.532967805862427\n",
      "MSE train 6.1636727126617705 MSE test 12.67431623791264\n",
      "MAE train 1.7240569044132126 MAE test 2.4967320250697824\n",
      "Epoch 568 / 10000 loss: 16.532260179519653\n",
      "MSE train 6.163488778564031 MSE test 12.674205382519345\n",
      "MAE train 1.7240282082484857 MAE test 2.49672449898758\n",
      "Epoch 569 / 10000 loss: 16.531622409820557\n",
      "MSE train 6.163317687019501 MSE test 12.673955939547081\n",
      "MAE train 1.7240027457164238 MAE test 2.496695164850438\n",
      "Epoch 570 / 10000 loss: 16.530916929244995\n",
      "MSE train 6.163133833014282 MSE test 12.673845087662269\n",
      "MAE train 1.7239740529715006 MAE test 2.496687629054746\n",
      "Epoch 571 / 10000 loss: 16.530279636383057\n",
      "MSE train 6.162962811265284 MSE test 12.673595603613153\n",
      "MAE train 1.7239486111957272 MAE test 2.496658275997675\n",
      "Epoch 572 / 10000 loss: 16.529573917388916\n",
      "MSE train 6.162779095459835 MSE test 12.673484813556005\n",
      "MAE train 1.7239199453420175 MAE test 2.49665075673644\n",
      "Epoch 573 / 10000 loss: 16.52893877029419\n",
      "MSE train 6.16260819908982 MSE test 12.67323526788539\n",
      "MAE train 1.723894526769646 MAE test 2.4966213912957507\n",
      "Epoch 574 / 10000 loss: 16.52823281288147\n",
      "MSE train 6.162424553396975 MSE test 12.673124558289324\n",
      "MAE train 1.7238658616480993 MAE test 2.4966138717957262\n",
      "Epoch 575 / 10000 loss: 16.527597188949585\n",
      "MSE train 6.162253768336644 MSE test 12.672875145939258\n",
      "MAE train 1.723840463791727 MAE test 2.496584522854813\n",
      "Epoch 576 / 10000 loss: 16.52689290046692\n",
      "MSE train 6.162070205474493 MSE test 12.67276441951154\n",
      "MAE train 1.7238118228189458 MAE test 2.4965770073130535\n",
      "Epoch 577 / 10000 loss: 16.526257276535034\n",
      "MSE train 6.1618995345086205 MSE test 12.67251498271594\n",
      "MAE train 1.723786450667553 MAE test 2.4965476475217594\n",
      "Epoch 578 / 10000 loss: 16.525553226470947\n",
      "MSE train 6.1617161037982395 MSE test 12.672404437540662\n",
      "MAE train 1.7237578326343188 MAE test 2.4965401379134446\n",
      "Epoch 579 / 10000 loss: 16.524918794631958\n",
      "MSE train 6.1615455531373335 MSE test 12.672155014329409\n",
      "MAE train 1.7237324852886475 MAE test 2.4965107928875545\n",
      "Epoch 580 / 10000 loss: 16.524214506149292\n",
      "MSE train 6.161362206304362 MSE test 12.672044364994363\n",
      "MAE train 1.7237038804771239 MAE test 2.496503272923532\n",
      "Epoch 581 / 10000 loss: 16.523579359054565\n",
      "MSE train 6.1611917232066755 MSE test 12.671794948581395\n",
      "MAE train 1.7236785470928209 MAE test 2.4964739114875787\n",
      "Epoch 582 / 10000 loss: 16.522876262664795\n",
      "MSE train 6.161008505296326 MSE test 12.671684396729177\n",
      "MAE train 1.7236499608706732 MAE test 2.496466411968801\n",
      "Epoch 583 / 10000 loss: 16.522242069244385\n",
      "MSE train 6.160838091734272 MSE test 12.67143513786726\n",
      "MAE train 1.72362464345638 MAE test 2.496437056937994\n",
      "Epoch 584 / 10000 loss: 16.52154040336609\n",
      "MSE train 6.160655013801556 MSE test 12.671324531875399\n",
      "MAE train 1.7235960824397243 MAE test 2.4964295386227935\n",
      "Epoch 585 / 10000 loss: 16.520907402038574\n",
      "MSE train 6.160484761927646 MSE test 12.671075262828921\n",
      "MAE train 1.7235707986060467 MAE test 2.4964001945645076\n",
      "Epoch 586 / 10000 loss: 16.520204067230225\n",
      "MSE train 6.160301766765554 MSE test 12.670964616725225\n",
      "MAE train 1.7235422402145997 MAE test 2.4963926630131223\n",
      "Epoch 587 / 10000 loss: 16.51957130432129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.16013158063924 MSE test 12.670715423651695\n",
      "MAE train 1.7235169621793682 MAE test 2.4963633248806607\n",
      "Epoch 588 / 10000 loss: 16.51887011528015\n",
      "MSE train 6.1599486255798706 MSE test 12.670604978760085\n",
      "MAE train 1.7234884137898272 MAE test 2.4963558273405475\n",
      "Epoch 589 / 10000 loss: 16.518237113952637\n",
      "MSE train 6.159778565281332 MSE test 12.670355609926139\n",
      "MAE train 1.7234631605835837 MAE test 2.496326446030415\n",
      "Epoch 590 / 10000 loss: 16.51753568649292\n",
      "MSE train 6.159595703153726 MSE test 12.670245119684859\n",
      "MAE train 1.723434626135048 MAE test 2.4963189401359176\n",
      "Epoch 591 / 10000 loss: 16.516903400421143\n",
      "MSE train 6.159425791072474 MSE test 12.669995830697149\n",
      "MAE train 1.7234093995548447 MAE test 2.4962895780932257\n",
      "Epoch 592 / 10000 loss: 16.516202449798584\n",
      "MSE train 6.159243001670813 MSE test 12.669885388036489\n",
      "MAE train 1.7233808710900196 MAE test 2.496282064691143\n",
      "Epoch 593 / 10000 loss: 16.515570878982544\n",
      "MSE train 6.159073113709791 MSE test 12.669636020098734\n",
      "MAE train 1.7233556486843984 MAE test 2.4962526809628915\n",
      "Epoch 594 / 10000 loss: 16.514869689941406\n",
      "MSE train 6.158890437219597 MSE test 12.669525532356234\n",
      "MAE train 1.7233271247659478 MAE test 2.496245154907512\n",
      "Epoch 595 / 10000 loss: 16.514238834381104\n",
      "MSE train 6.158720617907544 MSE test 12.66927628451231\n",
      "MAE train 1.7233019109210364 MAE test 2.4962158039941778\n",
      "Epoch 596 / 10000 loss: 16.513538360595703\n",
      "MSE train 6.158538036188477 MSE test 12.669165979513844\n",
      "MAE train 1.723273402934264 MAE test 2.496208290850876\n",
      "Epoch 597 / 10000 loss: 16.51290798187256\n",
      "MSE train 6.15836833537274 MSE test 12.668916500843634\n",
      "MAE train 1.723248212845872 MAE test 2.49617890396422\n",
      "Epoch 598 / 10000 loss: 16.512207746505737\n",
      "MSE train 6.158185778456275 MSE test 12.668805957928003\n",
      "MAE train 1.723219704831339 MAE test 2.496171365436656\n",
      "Epoch 599 / 10000 loss: 16.511576175689697\n",
      "MSE train 6.1580161185957305 MSE test 12.668556722049848\n",
      "MAE train 1.7231945141858165 MAE test 2.496141999826543\n",
      "Epoch 600 / 10000 loss: 16.51087713241577\n",
      "MSE train 6.157833706319323 MSE test 12.668446238346258\n",
      "MAE train 1.7231660210610373 MAE test 2.4961344673941803\n",
      "Epoch 601 / 10000 loss: 16.51024603843689\n",
      "MSE train 6.157664143276327 MSE test 12.668196865851934\n",
      "MAE train 1.7231408478554129 MAE test 2.4961050790815906\n",
      "Epoch 602 / 10000 loss: 16.509548664093018\n",
      "MSE train 6.1574817706129465 MSE test 12.66808634957022\n",
      "MAE train 1.7231123532837436 MAE test 2.4960975416503155\n",
      "Epoch 603 / 10000 loss: 16.50891661643982\n",
      "MSE train 6.157312253728694 MSE test 12.66783694368929\n",
      "MAE train 1.7230871776915564 MAE test 2.4960681440482837\n",
      "Epoch 604 / 10000 loss: 16.508219003677368\n",
      "MSE train 6.157129933324444 MSE test 12.66772640764933\n",
      "MAE train 1.7230586837266788 MAE test 2.496060607099731\n",
      "Epoch 605 / 10000 loss: 16.507587909698486\n",
      "MSE train 6.156960424616473 MSE test 12.667477007516663\n",
      "MAE train 1.7230335060171278 MAE test 2.4960312106600178\n",
      "Epoch 606 / 10000 loss: 16.50688934326172\n",
      "MSE train 6.1567781611647305 MSE test 12.667366370681682\n",
      "MAE train 1.7230050116172826 MAE test 2.4960236495135777\n",
      "Epoch 607 / 10000 loss: 16.506259441375732\n",
      "MSE train 6.156608753193088 MSE test 12.667116883246816\n",
      "MAE train 1.7229798474664426 MAE test 2.495994228732152\n",
      "Epoch 608 / 10000 loss: 16.505561351776123\n",
      "MSE train 6.156426474588901 MSE test 12.667006216707959\n",
      "MAE train 1.72295133885598 MAE test 2.495986666180801\n",
      "Epoch 609 / 10000 loss: 16.50493049621582\n",
      "MSE train 6.156257137646741 MSE test 12.666756729174697\n",
      "MAE train 1.7229261741254025 MAE test 2.495957245931008\n",
      "Epoch 610 / 10000 loss: 16.50423240661621\n",
      "MSE train 6.156074890357636 MSE test 12.666646041444816\n",
      "MAE train 1.7228976640835154 MAE test 2.4959496710919473\n",
      "Epoch 611 / 10000 loss: 16.5036039352417\n",
      "MSE train 6.155905512365217 MSE test 12.666396356235467\n",
      "MAE train 1.7228724819427237 MAE test 2.4959202268565384\n",
      "Epoch 612 / 10000 loss: 16.502904891967773\n",
      "MSE train 6.155723300411453 MSE test 12.666285642369143\n",
      "MAE train 1.7228439666253192 MAE test 2.4959126438192425\n",
      "Epoch 613 / 10000 loss: 16.50227451324463\n",
      "MSE train 6.155553984464145 MSE test 12.66603601024286\n",
      "MAE train 1.7228187848649834 MAE test 2.4958832027653606\n",
      "Epoch 614 / 10000 loss: 16.5015766620636\n",
      "MSE train 6.155371727073292 MSE test 12.66592507038908\n",
      "MAE train 1.722790246808242 MAE test 2.495875589464362\n",
      "Epoch 615 / 10000 loss: 16.500946760177612\n",
      "MSE train 6.155202379677524 MSE test 12.665675277535398\n",
      "MAE train 1.722765051822972 MAE test 2.495846129286872\n",
      "Epoch 616 / 10000 loss: 16.500248908996582\n",
      "MSE train 6.155020162890451 MSE test 12.66556433168646\n",
      "MAE train 1.7227364962597052 MAE test 2.4958385148697455\n",
      "Epoch 617 / 10000 loss: 16.499619722366333\n",
      "MSE train 6.154850735451398 MSE test 12.665314369434974\n",
      "MAE train 1.722711264089365 MAE test 2.495809015438742\n",
      "Epoch 618 / 10000 loss: 16.498921155929565\n",
      "MSE train 6.154668551191193 MSE test 12.665203281422889\n",
      "MAE train 1.7226826996713336 MAE test 2.495801383717019\n",
      "Epoch 619 / 10000 loss: 16.498290300369263\n",
      "MSE train 6.154499086644404 MSE test 12.6649532323886\n",
      "MAE train 1.7226574448645524 MAE test 2.4957718785480125\n",
      "Epoch 620 / 10000 loss: 16.497592210769653\n",
      "MSE train 6.154316791445354 MSE test 12.664841888081428\n",
      "MAE train 1.7226288418504476 MAE test 2.4957642017115886\n",
      "Epoch 621 / 10000 loss: 16.496962070465088\n",
      "MSE train 6.154147315144591 MSE test 12.664591725418314\n",
      "MAE train 1.7226035589213313 MAE test 2.495734680805534\n",
      "Epoch 622 / 10000 loss: 16.496262788772583\n",
      "MSE train 6.1539649077712895 MSE test 12.664480192989537\n",
      "MAE train 1.7225749062262794 MAE test 2.4957269802833992\n",
      "Epoch 623 / 10000 loss: 16.495632886886597\n",
      "MSE train 6.153795333676529 MSE test 12.664229845686425\n",
      "MAE train 1.7225495834851376 MAE test 2.4956974390302005\n",
      "Epoch 624 / 10000 loss: 16.494933366775513\n",
      "MSE train 6.153612831097227 MSE test 12.664118128101226\n",
      "MAE train 1.72252088550253 MAE test 2.4956897095261654\n",
      "Epoch 625 / 10000 loss: 16.494301557540894\n",
      "MSE train 6.153443124671207 MSE test 12.663867606005322\n",
      "MAE train 1.7224955070564618 MAE test 2.495660138986702\n",
      "Epoch 626 / 10000 loss: 16.493602514266968\n",
      "MSE train 6.1532605581200945 MSE test 12.663755584048001\n",
      "MAE train 1.7224667571042243 MAE test 2.495652369862778\n",
      "Epoch 627 / 10000 loss: 16.49297070503235\n",
      "MSE train 6.153090630475755 MSE test 12.663504809299717\n",
      "MAE train 1.7224412979344217 MAE test 2.4956227686872996\n",
      "Epoch 628 / 10000 loss: 16.492270469665527\n",
      "MSE train 6.152907866166908 MSE test 12.66339255126152\n",
      "MAE train 1.7224124639226173 MAE test 2.4956149625731436\n",
      "Epoch 629 / 10000 loss: 16.49163794517517\n",
      "MSE train 6.152737804962576 MSE test 12.663141422471792\n",
      "MAE train 1.7223869313063604 MAE test 2.4955853211054846\n",
      "Epoch 630 / 10000 loss: 16.490936756134033\n",
      "MSE train 6.152554747539291 MSE test 12.663028934366409\n",
      "MAE train 1.7223580005468349 MAE test 2.4955774875603685\n",
      "Epoch 631 / 10000 loss: 16.490302801132202\n",
      "MSE train 6.152384404823575 MSE test 12.66277752640931\n",
      "MAE train 1.7223323596940467 MAE test 2.4955478091113257\n",
      "Epoch 632 / 10000 loss: 16.489599227905273\n",
      "MSE train 6.1522010283135 MSE test 12.662664503980125\n",
      "MAE train 1.7223033002995258 MAE test 2.495539898614943\n",
      "Epoch 633 / 10000 loss: 16.488964557647705\n",
      "MSE train 6.152030370482981 MSE test 12.662412744769039\n",
      "MAE train 1.7222775294848522 MAE test 2.4955101676363487\n",
      "Epoch 634 / 10000 loss: 16.48826026916504\n",
      "MSE train 6.151846611077846 MSE test 12.662299134695482\n",
      "MAE train 1.722248332371683 MAE test 2.495502195301087\n",
      "Epoch 635 / 10000 loss: 16.487624168395996\n",
      "MSE train 6.1516755115063 MSE test 12.662046917485565\n",
      "MAE train 1.722222403964917 MAE test 2.495472413341943\n",
      "Epoch 636 / 10000 loss: 16.486918449401855\n",
      "MSE train 6.151491237549842 MSE test 12.661932866002234\n",
      "MAE train 1.7221930133794627 MAE test 2.4954643732594013\n",
      "Epoch 637 / 10000 loss: 16.486279010772705\n",
      "MSE train 6.151319515789062 MSE test 12.661680008590949\n",
      "MAE train 1.722166874040225 MAE test 2.4954345162424985\n",
      "Epoch 638 / 10000 loss: 16.4855694770813\n",
      "MSE train 6.151134620759396 MSE test 12.661565330506747\n",
      "MAE train 1.722137250558991 MAE test 2.4954264149230765\n",
      "Epoch 639 / 10000 loss: 16.484928369522095\n",
      "MSE train 6.150962209906539 MSE test 12.661311835992525\n",
      "MAE train 1.7221108540937262 MAE test 2.495396473706504\n",
      "Epoch 640 / 10000 loss: 16.48421573638916\n",
      "MSE train 6.150776373916687 MSE test 12.661196468492463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7220809156613999 MAE test 2.4953882843424346\n",
      "Epoch 641 / 10000 loss: 16.48357081413269\n",
      "MSE train 6.150602939232002 MSE test 12.66094198242287\n",
      "MAE train 1.7220541625556485 MAE test 2.495358218057117\n",
      "Epoch 642 / 10000 loss: 16.482855319976807\n",
      "MSE train 6.150416078784129 MSE test 12.660825616080032\n",
      "MAE train 1.7220238395172036 MAE test 2.495349910728376\n",
      "Epoch 643 / 10000 loss: 16.4822039604187\n",
      "MSE train 6.150241311948442 MSE test 12.660570337741326\n",
      "MAE train 1.7219966138018203 MAE test 2.49531975774425\n",
      "Epoch 644 / 10000 loss: 16.481482982635498\n",
      "MSE train 6.150052926948516 MSE test 12.66045259403356\n",
      "MAE train 1.7219657431186683 MAE test 2.4953112725363558\n",
      "Epoch 645 / 10000 loss: 16.48082661628723\n",
      "MSE train 6.14987641780577 MSE test 12.660195855320108\n",
      "MAE train 1.7219379002661026 MAE test 2.495280922726155\n",
      "Epoch 646 / 10000 loss: 16.480098009109497\n",
      "MSE train 6.14968586833985 MSE test 12.660076660148464\n",
      "MAE train 1.721906279312949 MAE test 2.495272269051873\n",
      "Epoch 647 / 10000 loss: 16.479433059692383\n",
      "MSE train 6.149506985475192 MSE test 12.659818324246016\n",
      "MAE train 1.7218775847768264 MAE test 2.4952417300547314\n",
      "Epoch 648 / 10000 loss: 16.47869324684143\n",
      "MSE train 6.1493136110311575 MSE test 12.659697334749533\n",
      "MAE train 1.721844953668897 MAE test 2.4952328388228175\n",
      "Epoch 649 / 10000 loss: 16.47801637649536\n",
      "MSE train 6.149131245352472 MSE test 12.659436782609315\n",
      "MAE train 1.7218150210101255 MAE test 2.495202023376265\n",
      "Epoch 650 / 10000 loss: 16.477264404296875\n",
      "MSE train 6.148933859612729 MSE test 12.659313461873468\n",
      "MAE train 1.7217809237527526 MAE test 2.4951928627503057\n",
      "Epoch 651 / 10000 loss: 16.47657036781311\n",
      "MSE train 6.148746576222902 MSE test 12.659050119108397\n",
      "MAE train 1.7217492213317203 MAE test 2.4951617055757187\n",
      "Epoch 652 / 10000 loss: 16.47579789161682\n",
      "MSE train 6.148543278969793 MSE test 12.658923539460297\n",
      "MAE train 1.7217129822838704 MAE test 2.4951521287238743\n",
      "Epoch 653 / 10000 loss: 16.475080013275146\n",
      "MSE train 6.148349007648249 MSE test 12.658656472456636\n",
      "MAE train 1.721678735850465 MAE test 2.4951205092689315\n",
      "Epoch 654 / 10000 loss: 16.47427988052368\n",
      "MSE train 6.148137253511323 MSE test 12.658525733385764\n",
      "MAE train 1.7216393836687107 MAE test 2.4951104068321754\n",
      "Epoch 655 / 10000 loss: 16.473528623580933\n",
      "MSE train 6.147932898012904 MSE test 12.658254152011976\n",
      "MAE train 1.721601365777471 MAE test 2.4950782170533623\n",
      "Epoch 656 / 10000 loss: 16.472686767578125\n",
      "MSE train 6.147709173331222 MSE test 12.65811799356548\n",
      "MAE train 1.7215574981998283 MAE test 2.4950674095387186\n",
      "Epoch 657 / 10000 loss: 16.471886157989502\n",
      "MSE train 6.147490962431499 MSE test 12.657840525142902\n",
      "MAE train 1.7215142079457346 MAE test 2.4950344612479416\n",
      "Epoch 658 / 10000 loss: 16.47098731994629\n",
      "MSE train 6.147251890790732 MSE test 12.657698002326669\n",
      "MAE train 1.721464326218889 MAE test 2.4950228363235922\n",
      "Epoch 659 / 10000 loss: 16.47011971473694\n",
      "MSE train 6.14701769312349 MSE test 12.657414011422164\n",
      "MAE train 1.7214144373573452 MAE test 2.4949890317881938\n",
      "Epoch 660 / 10000 loss: 16.469146013259888\n",
      "MSE train 6.14676359545082 MSE test 12.657265373115452\n",
      "MAE train 1.7213580121260392 MAE test 2.4949766035387966\n",
      "Epoch 661 / 10000 loss: 16.46820044517517\n",
      "MSE train 6.146517841498466 MSE test 12.656975914246496\n",
      "MAE train 1.7213027182513596 MAE test 2.494942052933976\n",
      "Epoch 662 / 10000 loss: 16.467153549194336\n",
      "MSE train 6.146258555794288 MSE test 12.656824296378186\n",
      "MAE train 1.7212432719822421 MAE test 2.494929230251898\n",
      "Epoch 663 / 10000 loss: 16.46615219116211\n",
      "MSE train 6.146015981348937 MSE test 12.656534885072041\n",
      "MAE train 1.7211883754193824 MAE test 2.494894639257014\n",
      "Epoch 664 / 10000 loss: 16.465079069137573\n",
      "MSE train 6.145768200360914 MSE test 12.656386415105612\n",
      "MAE train 1.7211328172794031 MAE test 2.494882129908751\n",
      "Epoch 665 / 10000 loss: 16.464093446731567\n",
      "MSE train 6.145543195543762 MSE test 12.656103364441696\n",
      "MAE train 1.7210844576852855 MAE test 2.4948483039607603\n",
      "Epoch 666 / 10000 loss: 16.46307635307312\n",
      "MSE train 6.145315570910143 MSE test 12.655963641038193\n",
      "MAE train 1.721036844573989 MAE test 2.4948368517501276\n",
      "Epoch 667 / 10000 loss: 16.462176084518433\n",
      "MSE train 6.145110115659407 MSE test 12.655690480777311\n",
      "MAE train 1.7209963290784904 MAE test 2.49480425501334\n",
      "Epoch 668 / 10000 loss: 16.461257219314575\n",
      "MSE train 6.1448995738256285 MSE test 12.655560425836537\n",
      "MAE train 1.7209554622450325 MAE test 2.494794024193056\n",
      "Epoch 669 / 10000 loss: 16.46045207977295\n",
      "MSE train 6.1447081774134755 MSE test 12.655296384108873\n",
      "MAE train 1.720920758917998 MAE test 2.4947625513333462\n",
      "Epoch 670 / 10000 loss: 16.459617376327515\n",
      "MSE train 6.144508720278049 MSE test 12.655174513251383\n",
      "MAE train 1.7208848252089577 MAE test 2.494753362005292\n",
      "Epoch 671 / 10000 loss: 16.45888066291809\n",
      "MSE train 6.144325922921368 MSE test 12.654917426089366\n",
      "MAE train 1.7208538898478423 MAE test 2.494722766071266\n",
      "Epoch 672 / 10000 loss: 16.458099365234375\n",
      "MSE train 6.144133058056805 MSE test 12.654801401287488\n",
      "MAE train 1.720820684154624 MAE test 2.494714321100421\n",
      "Epoch 673 / 10000 loss: 16.457403898239136\n",
      "MSE train 6.143955443205445 MSE test 12.654549203924462\n",
      "MAE train 1.7207918350329332 MAE test 2.494684348782567\n",
      "Epoch 674 / 10000 loss: 16.4566547870636\n",
      "MSE train 6.1437666586178805 MSE test 12.654437247007898\n",
      "MAE train 1.7207603073652888 MAE test 2.494676423999504\n",
      "Epoch 675 / 10000 loss: 16.455985069274902\n",
      "MSE train 6.143592220782292 MSE test 12.654188551886557\n",
      "MAE train 1.7207327433379274 MAE test 2.4946469095407076\n",
      "Epoch 676 / 10000 loss: 16.455254793167114\n",
      "MSE train 6.143406002132743 MSE test 12.654079549199269\n",
      "MAE train 1.7207022687120104 MAE test 2.4946393487523015\n",
      "Epoch 677 / 10000 loss: 16.454599380493164\n",
      "MSE train 6.143233648225922 MSE test 12.65383314843168\n",
      "MAE train 1.720675599763577 MAE test 2.494610136467376\n",
      "Epoch 678 / 10000 loss: 16.45388102531433\n",
      "MSE train 6.143049114145905 MSE test 12.653725984760662\n",
      "MAE train 1.7206458070113966 MAE test 2.4946028208600524\n",
      "Epoch 679 / 10000 loss: 16.45323634147644\n",
      "MSE train 6.142878218664554 MSE test 12.6534813138731\n",
      "MAE train 1.720619694665547 MAE test 2.4945738220181033\n",
      "Epoch 680 / 10000 loss: 16.452527046203613\n",
      "MSE train 6.142694864867097 MSE test 12.653375469137234\n",
      "MAE train 1.720590353333158 MAE test 2.494566664442653\n",
      "Epoch 681 / 10000 loss: 16.451887845993042\n",
      "MSE train 6.142524931928101 MSE test 12.653131871524065\n",
      "MAE train 1.720564618961017 MAE test 2.4945377986322064\n",
      "Epoch 682 / 10000 loss: 16.45118284225464\n",
      "MSE train 6.14234254446319 MSE test 12.653026993976725\n",
      "MAE train 1.7205356011632165 MAE test 2.4945307824749507\n",
      "Epoch 683 / 10000 loss: 16.45054864883423\n",
      "MSE train 6.142173279012569 MSE test 12.652784370487627\n",
      "MAE train 1.7205101127701912 MAE test 2.494502044970906\n",
      "Epoch 684 / 10000 loss: 16.44984745979309\n",
      "MSE train 6.141991483843277 MSE test 12.652680047670868\n",
      "MAE train 1.7204812935246203 MAE test 2.494495092393904\n",
      "Epoch 685 / 10000 loss: 16.449217557907104\n",
      "MSE train 6.141822883533122 MSE test 12.652437711358473\n",
      "MAE train 1.720456026835328 MAE test 2.4944663863717684\n",
      "Epoch 686 / 10000 loss: 16.4485182762146\n",
      "MSE train 6.141641555561343 MSE test 12.652333938746661\n",
      "MAE train 1.7204273705358417 MAE test 2.49445949695276\n",
      "Epoch 687 / 10000 loss: 16.447891235351562\n",
      "MSE train 6.1414733398014585 MSE test 12.652092040634319\n",
      "MAE train 1.7204022265564225 MAE test 2.494430865432505\n",
      "Epoch 688 / 10000 loss: 16.44719433784485\n",
      "MSE train 6.141292438750881 MSE test 12.651988578600019\n",
      "MAE train 1.720373691211933 MAE test 2.4944240174312124\n",
      "Epoch 689 / 10000 loss: 16.44656753540039\n",
      "MSE train 6.141124573809005 MSE test 12.651746732262524\n",
      "MAE train 1.720348655422001 MAE test 2.494395390296199\n",
      "Epoch 690 / 10000 loss: 16.445873975753784\n",
      "MSE train 6.140943967124976 MSE test 12.651643386403675\n",
      "MAE train 1.7203202133965407 MAE test 2.4943885467230307\n",
      "Epoch 691 / 10000 loss: 16.445249319076538\n",
      "MSE train 6.140776430626912 MSE test 12.651401733453149\n",
      "MAE train 1.7202952690264954 MAE test 2.4943599584178258\n",
      "Epoch 692 / 10000 loss: 16.44455647468567\n",
      "MSE train 6.140596117631446 MSE test 12.65129841403987\n",
      "MAE train 1.7202669111096414 MAE test 2.4943531263892633\n",
      "Epoch 693 / 10000 loss: 16.44393253326416\n",
      "MSE train 6.1404288271412515 MSE test 12.651056747313643\n",
      "MAE train 1.7202420442724942 MAE test 2.4943245279378585\n",
      "Epoch 694 / 10000 loss: 16.443241834640503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.140248768712762 MSE test 12.650953342870213\n",
      "MAE train 1.7202137527878987 MAE test 2.4943176874797928\n",
      "Epoch 695 / 10000 loss: 16.44261884689331\n",
      "MSE train 6.14008167178386 MSE test 12.650711787065559\n",
      "MAE train 1.7201889359049918 MAE test 2.4942890972723633\n",
      "Epoch 696 / 10000 loss: 16.44192910194397\n",
      "MSE train 6.139901740424963 MSE test 12.650608320035746\n",
      "MAE train 1.7201606822779218 MAE test 2.4942822476778232\n",
      "Epoch 697 / 10000 loss: 16.441306114196777\n",
      "MSE train 6.1397348499978355 MSE test 12.650366594771427\n",
      "MAE train 1.720135927083024 MAE test 2.4942536186136754\n",
      "Epoch 698 / 10000 loss: 16.44061589241028\n",
      "MSE train 6.139555135933332 MSE test 12.650263037764732\n",
      "MAE train 1.7201077298520018 MAE test 2.494246773241307\n",
      "Epoch 699 / 10000 loss: 16.43999481201172\n",
      "MSE train 6.139388395541853 MSE test 12.650021016310003\n",
      "MAE train 1.7200830229685529 MAE test 2.494218123277371\n",
      "Epoch 700 / 10000 loss: 16.43930697441101\n",
      "MSE train 6.139208803490407 MSE test 12.649917290646464\n",
      "MAE train 1.720054852028078 MAE test 2.4942112392999563\n",
      "Epoch 701 / 10000 loss: 16.438685417175293\n",
      "MSE train 6.13904225586293 MSE test 12.64967509570192\n",
      "MAE train 1.7200301919874126 MAE test 2.4941825699312274\n",
      "Epoch 702 / 10000 loss: 16.437998294830322\n",
      "MSE train 6.138862789936629 MSE test 12.649571091749639\n",
      "MAE train 1.7200020554774549 MAE test 2.49417566498799\n",
      "Epoch 703 / 10000 loss: 16.43737816810608\n",
      "MSE train 6.138696346242045 MSE test 12.649328722330068\n",
      "MAE train 1.7199774250955753 MAE test 2.4941469612899905\n",
      "Epoch 704 / 10000 loss: 16.43669033050537\n",
      "MSE train 6.138517029035998 MSE test 12.649224384223063\n",
      "MAE train 1.7199493353817619 MAE test 2.494139995980847\n",
      "Epoch 705 / 10000 loss: 16.436070680618286\n",
      "MSE train 6.138350709945806 MSE test 12.648981749048449\n",
      "MAE train 1.719924744239149 MAE test 2.494111267761195\n",
      "Epoch 706 / 10000 loss: 16.435383558273315\n",
      "MSE train 6.138171506068804 MSE test 12.648877272550598\n",
      "MAE train 1.7198966836106742 MAE test 2.4941042978069667\n",
      "Epoch 707 / 10000 loss: 16.434765100479126\n",
      "MSE train 6.138005314420667 MSE test 12.648634418493048\n",
      "MAE train 1.7198721262243706 MAE test 2.494075550975723\n",
      "Epoch 708 / 10000 loss: 16.434077739715576\n",
      "MSE train 6.137826240373381 MSE test 12.648529485435043\n",
      "MAE train 1.7198440833220772 MAE test 2.494068516996898\n",
      "Epoch 709 / 10000 loss: 16.433460235595703\n",
      "MSE train 6.1376601120985255 MSE test 12.648286247298637\n",
      "MAE train 1.7198195497526945 MAE test 2.4940397146165347\n",
      "Epoch 710 / 10000 loss: 16.43277359008789\n",
      "MSE train 6.137481116215598 MSE test 12.64818121064705\n",
      "MAE train 1.7197915321166029 MAE test 2.4940326801103674\n",
      "Epoch 711 / 10000 loss: 16.432156085968018\n",
      "MSE train 6.137315055631871 MSE test 12.647937870689368\n",
      "MAE train 1.719767015687829 MAE test 2.4940038680243726\n",
      "Epoch 712 / 10000 loss: 16.431469917297363\n",
      "MSE train 6.137136153307428 MSE test 12.647832417704716\n",
      "MAE train 1.719739020437429 MAE test 2.4939967572931803\n",
      "Epoch 713 / 10000 loss: 16.43085289001465\n",
      "MSE train 6.136970231539436 MSE test 12.64758876029976\n",
      "MAE train 1.7197145377225664 MAE test 2.493967907334938\n",
      "Epoch 714 / 10000 loss: 16.430166482925415\n",
      "MSE train 6.136791451095472 MSE test 12.647482992133316\n",
      "MAE train 1.7196865676217545 MAE test 2.4939607789143396\n",
      "Epoch 715 / 10000 loss: 16.4295494556427\n",
      "MSE train 6.136625551375465 MSE test 12.647239123148838\n",
      "MAE train 1.71966209450308 MAE test 2.4939319067150016\n",
      "Epoch 716 / 10000 loss: 16.4288649559021\n",
      "MSE train 6.136446818705645 MSE test 12.647133089339212\n",
      "MAE train 1.7196341289116268 MAE test 2.4939247308266923\n",
      "Epoch 717 / 10000 loss: 16.428247928619385\n",
      "MSE train 6.136281047456043 MSE test 12.646889004776218\n",
      "MAE train 1.7196096892797987 MAE test 2.493895829698865\n",
      "Epoch 718 / 10000 loss: 16.427562713623047\n",
      "MSE train 6.136102342537733 MSE test 12.646782767322264\n",
      "MAE train 1.7195817364663368 MAE test 2.4938886353517575\n",
      "Epoch 719 / 10000 loss: 16.42694664001465\n",
      "MSE train 6.135936587718831 MSE test 12.646538291840887\n",
      "MAE train 1.7195573003612936 MAE test 2.4938596857348196\n",
      "Epoch 720 / 10000 loss: 16.426262378692627\n",
      "MSE train 6.135757911307214 MSE test 12.64643188843304\n",
      "MAE train 1.7195293560715181 MAE test 2.4938524714745127\n",
      "Epoch 721 / 10000 loss: 16.425645351409912\n",
      "MSE train 6.135592240250861 MSE test 12.646187139833822\n",
      "MAE train 1.7195049443927066 MAE test 2.4938234837726885\n",
      "Epoch 722 / 10000 loss: 16.42496109008789\n",
      "MSE train 6.135413624302823 MSE test 12.646080588078663\n",
      "MAE train 1.7194770138718476 MAE test 2.493816248146299\n",
      "Epoch 723 / 10000 loss: 16.424344778060913\n",
      "MSE train 6.13524800962925 MSE test 12.645835707791655\n",
      "MAE train 1.7194526128607224 MAE test 2.4937872606785403\n",
      "Epoch 724 / 10000 loss: 16.42366075515747\n",
      "MSE train 6.135069494364622 MSE test 12.645728888334961\n",
      "MAE train 1.7194246903570694 MAE test 2.4937799886171557\n",
      "Epoch 725 / 10000 loss: 16.42304539680481\n",
      "MSE train 6.134903905990062 MSE test 12.645483845387842\n",
      "MAE train 1.7194003029946499 MAE test 2.493750966859411\n",
      "Epoch 726 / 10000 loss: 16.42236089706421\n",
      "MSE train 6.134725410566521 MSE test 12.645376800978225\n",
      "MAE train 1.7193723938629653 MAE test 2.4937436694405073\n",
      "Epoch 727 / 10000 loss: 16.421745538711548\n",
      "MSE train 6.134559852143295 MSE test 12.645131696575381\n",
      "MAE train 1.7193480059768929 MAE test 2.493714651412255\n",
      "Epoch 728 / 10000 loss: 16.421061754226685\n",
      "MSE train 6.134381407817255 MSE test 12.645024371680803\n",
      "MAE train 1.7193201032315386 MAE test 2.493707314398271\n",
      "Epoch 729 / 10000 loss: 16.420445442199707\n",
      "MSE train 6.134215901923781 MSE test 12.644779031956755\n",
      "MAE train 1.7192957287067943 MAE test 2.4936782633621832\n",
      "Epoch 730 / 10000 loss: 16.41976261138916\n",
      "MSE train 6.134037497068271 MSE test 12.644671735116903\n",
      "MAE train 1.7192678324134616 MAE test 2.493670926614461\n",
      "Epoch 731 / 10000 loss: 16.419146060943604\n",
      "MSE train 6.133871993874071 MSE test 12.644426429778745\n",
      "MAE train 1.7192434653085897 MAE test 2.4936418885702945\n",
      "Epoch 732 / 10000 loss: 16.418463468551636\n",
      "MSE train 6.133693610786314 MSE test 12.644318889470552\n",
      "MAE train 1.7192155619930893 MAE test 2.4936345196018683\n",
      "Epoch 733 / 10000 loss: 16.417848110198975\n",
      "MSE train 6.1335281508006005 MSE test 12.644073399786652\n",
      "MAE train 1.719191212085003 MAE test 2.4936054517268866\n",
      "Epoch 734 / 10000 loss: 16.41716456413269\n",
      "MSE train 6.1333497774419055 MSE test 12.643965980031268\n",
      "MAE train 1.7191633055728852 MAE test 2.4935981162919516\n",
      "Epoch 735 / 10000 loss: 16.41654944419861\n",
      "MSE train 6.133184368060537 MSE test 12.64372038144706\n",
      "MAE train 1.7191389579047467 MAE test 2.4935690248748146\n",
      "Epoch 736 / 10000 loss: 16.41586661338806\n",
      "MSE train 6.133005934852668 MSE test 12.643612740160847\n",
      "MAE train 1.719111049306588 MAE test 2.4935616507380374\n",
      "Epoch 737 / 10000 loss: 16.41525101661682\n",
      "MSE train 6.13284056543848 MSE test 12.6433669653221\n",
      "MAE train 1.7190867045139926 MAE test 2.4935325405736477\n",
      "Epoch 738 / 10000 loss: 16.414568185806274\n",
      "MSE train 6.132662227256484 MSE test 12.643259476292133\n",
      "MAE train 1.7190588044218338 MAE test 2.493525192761387\n",
      "Epoch 739 / 10000 loss: 16.413952589035034\n",
      "MSE train 6.132496871374487 MSE test 12.643013763886794\n",
      "MAE train 1.719034469818772 MAE test 2.493496090976508\n",
      "Epoch 740 / 10000 loss: 16.413269519805908\n",
      "MSE train 6.132318515798432 MSE test 12.642906029645403\n",
      "MAE train 1.7190065639670145 MAE test 2.493488711334825\n",
      "Epoch 741 / 10000 loss: 16.412654638290405\n",
      "MSE train 6.132153173396758 MSE test 12.642660136779389\n",
      "MAE train 1.71898222960938 MAE test 2.4934595908249984\n",
      "Epoch 742 / 10000 loss: 16.411970853805542\n",
      "MSE train 6.13197484833851 MSE test 12.642552329212657\n",
      "MAE train 1.7189543337205477 MAE test 2.4934521882966982\n",
      "Epoch 743 / 10000 loss: 16.411356687545776\n",
      "MSE train 6.131809473241955 MSE test 12.642306581244819\n",
      "MAE train 1.7189299930355055 MAE test 2.493423094791412\n",
      "Epoch 744 / 10000 loss: 16.41067337989807\n",
      "MSE train 6.131631143031678 MSE test 12.64219870449032\n",
      "MAE train 1.7189020903994354 MAE test 2.4934156884294163\n",
      "Epoch 745 / 10000 loss: 16.41005802154541\n",
      "MSE train 6.131465804128111 MSE test 12.64195282097475\n",
      "MAE train 1.7188777600173322 MAE test 2.493386569882845\n",
      "Epoch 746 / 10000 loss: 16.409374713897705\n",
      "MSE train 6.131287523514796 MSE test 12.641844881052307\n",
      "MAE train 1.7188498574507276 MAE test 2.493379149769739\n",
      "Epoch 747 / 10000 loss: 16.40876054763794\n",
      "MSE train 6.131122159122506 MSE test 12.641599081410657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7188255262033094 MAE test 2.493350053480055\n",
      "Epoch 748 / 10000 loss: 16.408077478408813\n",
      "MSE train 6.1309438717662 MSE test 12.641491132724244\n",
      "MAE train 1.7187976191420309 MAE test 2.493342629018599\n",
      "Epoch 749 / 10000 loss: 16.40746283531189\n",
      "MSE train 6.130778535211116 MSE test 12.641245225126227\n",
      "MAE train 1.7187732898718382 MAE test 2.4933135081720836\n",
      "Epoch 750 / 10000 loss: 16.406780242919922\n",
      "MSE train 6.130600275103045 MSE test 12.641137151993242\n",
      "MAE train 1.718745385310537 MAE test 2.4933060768197937\n",
      "Epoch 751 / 10000 loss: 16.40616488456726\n",
      "MSE train 6.130434941460391 MSE test 12.640891275842469\n",
      "MAE train 1.7187210596014728 MAE test 2.493276958308246\n",
      "Epoch 752 / 10000 loss: 16.40548086166382\n",
      "MSE train 6.130256560991038 MSE test 12.640783325343968\n",
      "MAE train 1.7186931273431694 MAE test 2.493269536934565\n",
      "Epoch 753 / 10000 loss: 16.404866933822632\n",
      "MSE train 6.130091269724922 MSE test 12.64053733586789\n",
      "MAE train 1.7186688078477272 MAE test 2.4932404068201843\n",
      "Epoch 754 / 10000 loss: 16.40418314933777\n",
      "MSE train 6.129913026252347 MSE test 12.640429308519515\n",
      "MAE train 1.7186408991169926 MAE test 2.493232972560339\n",
      "Epoch 755 / 10000 loss: 16.403568267822266\n",
      "MSE train 6.129747648754813 MSE test 12.640183371555366\n",
      "MAE train 1.7186165609548665 MAE test 2.493203852599334\n",
      "Epoch 756 / 10000 loss: 16.402884483337402\n",
      "MSE train 6.129569380368309 MSE test 12.640075185168179\n",
      "MAE train 1.7185886402758905 MAE test 2.4931964072722015\n",
      "Epoch 757 / 10000 loss: 16.402270078659058\n",
      "MSE train 6.12940403127257 MSE test 12.639829252983647\n",
      "MAE train 1.7185643109761415 MAE test 2.493167281299979\n",
      "Epoch 758 / 10000 loss: 16.401586294174194\n",
      "MSE train 6.1292257326127375 MSE test 12.639721241572005\n",
      "MAE train 1.7185363750052163 MAE test 2.4931598519461238\n",
      "Epoch 759 / 10000 loss: 16.40097141265869\n",
      "MSE train 6.129060403604274 MSE test 12.639475292550193\n",
      "MAE train 1.7185120469280692 MAE test 2.493130732584283\n",
      "Epoch 760 / 10000 loss: 16.40028715133667\n",
      "MSE train 6.128882018751417 MSE test 12.639367105587953\n",
      "MAE train 1.7184841019634611 MAE test 2.493123288252365\n",
      "Epoch 761 / 10000 loss: 16.399672746658325\n",
      "MSE train 6.1287166788002185 MSE test 12.63912102346472\n",
      "MAE train 1.718459768647558 MAE test 2.493094142307092\n",
      "Epoch 762 / 10000 loss: 16.39898920059204\n",
      "MSE train 6.128538338137939 MSE test 12.639012989243685\n",
      "MAE train 1.7184318215289378 MAE test 2.493086707248979\n",
      "Epoch 763 / 10000 loss: 16.39837408065796\n",
      "MSE train 6.128372969383701 MSE test 12.63876685411263\n",
      "MAE train 1.7184074834831025 MAE test 2.4930575595787117\n",
      "Epoch 764 / 10000 loss: 16.397690773010254\n",
      "MSE train 6.128194626202556 MSE test 12.638658721392929\n",
      "MAE train 1.7183795320618493 MAE test 2.4930501116115464\n",
      "Epoch 765 / 10000 loss: 16.397074937820435\n",
      "MSE train 6.12802921532923 MSE test 12.638412496135569\n",
      "MAE train 1.718355191309442 MAE test 2.4930209454708776\n",
      "Epoch 766 / 10000 loss: 16.39639139175415\n",
      "MSE train 6.127850820128874 MSE test 12.63830434842722\n",
      "MAE train 1.7183272206710876 MAE test 2.4930135069241834\n",
      "Epoch 767 / 10000 loss: 16.395777225494385\n",
      "MSE train 6.127685451498676 MSE test 12.638058228533703\n",
      "MAE train 1.7183028845142263 MAE test 2.492984363811624\n",
      "Epoch 768 / 10000 loss: 16.395091772079468\n",
      "MSE train 6.127507008398762 MSE test 12.637950138007774\n",
      "MAE train 1.7182748967237271 MAE test 2.492976924291717\n",
      "Epoch 769 / 10000 loss: 16.39447569847107\n",
      "MSE train 6.1273415754736975 MSE test 12.637704055107525\n",
      "MAE train 1.7182505451122227 MAE test 2.4929477786741687\n",
      "Epoch 770 / 10000 loss: 16.393792629241943\n",
      "MSE train 6.127163144214213 MSE test 12.637595729908071\n",
      "MAE train 1.7182225610052067 MAE test 2.4929403070539022\n",
      "Epoch 771 / 10000 loss: 16.393177032470703\n",
      "MSE train 6.126997642238871 MSE test 12.63734964284585\n",
      "MAE train 1.718198196736689 MAE test 2.4929111634823165\n",
      "Epoch 772 / 10000 loss: 16.39249277114868\n",
      "MSE train 6.126819145077934 MSE test 12.637241315576373\n",
      "MAE train 1.7181701931777777 MAE test 2.4929036968545355\n",
      "Epoch 773 / 10000 loss: 16.391876459121704\n",
      "MSE train 6.126653641895184 MSE test 12.636995189253025\n",
      "MAE train 1.7181458238235097 MAE test 2.4928745476424967\n",
      "Epoch 774 / 10000 loss: 16.391191005706787\n",
      "MSE train 6.126475122852604 MSE test 12.636886916466429\n",
      "MAE train 1.7181178106267536 MAE test 2.492867083466967\n",
      "Epoch 775 / 10000 loss: 16.39057493209839\n",
      "MSE train 6.126309521077224 MSE test 12.636640559814634\n",
      "MAE train 1.7180934198742088 MAE test 2.492837905204369\n",
      "Epoch 776 / 10000 loss: 16.38988995552063\n",
      "MSE train 6.126130932004391 MSE test 12.636532374539863\n",
      "MAE train 1.7180653909197732 MAE test 2.49283044847904\n",
      "Epoch 777 / 10000 loss: 16.389273643493652\n",
      "MSE train 6.125965347268853 MSE test 12.636286194230625\n",
      "MAE train 1.7180410018045589 MAE test 2.4928012893111178\n",
      "Epoch 778 / 10000 loss: 16.388588666915894\n",
      "MSE train 6.12578670556854 MSE test 12.636177782463282\n",
      "MAE train 1.7180129546230183 MAE test 2.492793817198338\n",
      "Epoch 779 / 10000 loss: 16.387972116470337\n",
      "MSE train 6.125621035157088 MSE test 12.635931651891354\n",
      "MAE train 1.71798854336511 MAE test 2.492764670351395\n",
      "Epoch 780 / 10000 loss: 16.38728618621826\n",
      "MSE train 6.125442330979701 MSE test 12.635823089719324\n",
      "MAE train 1.717960480739346 MAE test 2.492757168529424\n",
      "Epoch 781 / 10000 loss: 16.38666868209839\n",
      "MSE train 6.125276547982837 MSE test 12.635576734495896\n",
      "MAE train 1.7179360480389596 MAE test 2.4927279814109\n",
      "Epoch 782 / 10000 loss: 16.385981798171997\n",
      "MSE train 6.1250977310652654 MSE test 12.635468417551063\n",
      "MAE train 1.717907959150785 MAE test 2.4927205182190546\n",
      "Epoch 783 / 10000 loss: 16.38536500930786\n",
      "MSE train 6.124931889845599 MSE test 12.635222102483928\n",
      "MAE train 1.717883515833108 MAE test 2.4926913404081747\n",
      "Epoch 784 / 10000 loss: 16.38467764854431\n",
      "MSE train 6.124753024601772 MSE test 12.635113635205933\n",
      "MAE train 1.7178554039530904 MAE test 2.492683854334123\n",
      "Epoch 785 / 10000 loss: 16.384061098098755\n",
      "MSE train 6.124587073149225 MSE test 12.634867240067257\n",
      "MAE train 1.717830945525445 MAE test 2.4926546687234437\n",
      "Epoch 786 / 10000 loss: 16.383373737335205\n",
      "MSE train 6.124408058108062 MSE test 12.634758697367682\n",
      "MAE train 1.7178027981604387 MAE test 2.49264716512406\n",
      "Epoch 787 / 10000 loss: 16.382756233215332\n",
      "MSE train 6.124242003230387 MSE test 12.63451238422157\n",
      "MAE train 1.717778311066506 MAE test 2.4926180127721165\n",
      "Epoch 788 / 10000 loss: 16.382067918777466\n",
      "MSE train 6.124062902047316 MSE test 12.634403815595359\n",
      "MAE train 1.7177501422259802 MAE test 2.492610498354366\n",
      "Epoch 789 / 10000 loss: 16.3814480304718\n",
      "MSE train 6.123896700837608 MSE test 12.634157285018599\n",
      "MAE train 1.7177256191854697 MAE test 2.492581303038044\n",
      "Epoch 790 / 10000 loss: 16.380760192871094\n",
      "MSE train 6.123717475907636 MSE test 12.63404864191603\n",
      "MAE train 1.717697417618656 MAE test 2.492573788009658\n",
      "Epoch 791 / 10000 loss: 16.38014054298401\n",
      "MSE train 6.123551171822422 MSE test 12.63380202263419\n",
      "MAE train 1.717672869485921 MAE test 2.4925445804723716\n",
      "Epoch 792 / 10000 loss: 16.379451513290405\n",
      "MSE train 6.123371741476523 MSE test 12.63369341402959\n",
      "MAE train 1.7176446234960927 MAE test 2.4925370744687863\n",
      "Epoch 793 / 10000 loss: 16.378830909729004\n",
      "MSE train 6.123205249829057 MSE test 12.63344688060135\n",
      "MAE train 1.7176200308933582 MAE test 2.4925078668468625\n",
      "Epoch 794 / 10000 loss: 16.378140926361084\n",
      "MSE train 6.123025727739315 MSE test 12.633338122355688\n",
      "MAE train 1.7175917542868855 MAE test 2.4925003386082345\n",
      "Epoch 795 / 10000 loss: 16.37751865386963\n",
      "MSE train 6.122859030783131 MSE test 12.633091611638207\n",
      "MAE train 1.717567115583538 MAE test 2.4924711474925076\n",
      "Epoch 796 / 10000 loss: 16.376828908920288\n",
      "MSE train 6.122679232793002 MSE test 12.632982644973856\n",
      "MAE train 1.7175387752084261 MAE test 2.4924635942289397\n",
      "Epoch 797 / 10000 loss: 16.376206398010254\n",
      "MSE train 6.122512317509775 MSE test 12.632735952015311\n",
      "MAE train 1.7175140927458519 MAE test 2.4924343614176316\n",
      "Epoch 798 / 10000 loss: 16.37551498413086\n",
      "MSE train 6.12233229100252 MSE test 12.632627019502712\n",
      "MAE train 1.7174857107951231 MAE test 2.49242681218805\n",
      "Epoch 799 / 10000 loss: 16.37489151954651\n",
      "MSE train 6.122165123191614 MSE test 12.632380321194574\n",
      "MAE train 1.7174609777315284 MAE test 2.492397605209589\n",
      "Epoch 800 / 10000 loss: 16.37419891357422\n",
      "MSE train 6.121984905387499 MSE test 12.632271393395008\n",
      "MAE train 1.7174325475873053 MAE test 2.492390052009014\n",
      "Epoch 801 / 10000 loss: 16.373574256896973\n",
      "MSE train 6.1218175172592195 MSE test 12.632024527538544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7174077630182814 MAE test 2.4923608109171123\n",
      "Epoch 802 / 10000 loss: 16.37287950515747\n",
      "MSE train 6.121636969056771 MSE test 12.631915365470421\n",
      "MAE train 1.717379255364092 MAE test 2.4923532222210727\n",
      "Epoch 803 / 10000 loss: 16.372254133224487\n",
      "MSE train 6.121469252644564 MSE test 12.631668407308283\n",
      "MAE train 1.7173543969889005 MAE test 2.4923239684762155\n",
      "Epoch 804 / 10000 loss: 16.371558904647827\n",
      "MSE train 6.121288364844039 MSE test 12.631559151543819\n",
      "MAE train 1.7173258033691572 MAE test 2.492316369623453\n",
      "Epoch 805 / 10000 loss: 16.370930671691895\n",
      "MSE train 6.121120325071528 MSE test 12.63131221529733\n",
      "MAE train 1.717300870088217 MAE test 2.492287121140924\n",
      "Epoch 806 / 10000 loss: 16.37023425102234\n",
      "MSE train 6.120939052245026 MSE test 12.631202719711313\n",
      "MAE train 1.717272185430863 MAE test 2.4922794787147056\n",
      "Epoch 807 / 10000 loss: 16.369603872299194\n",
      "MSE train 6.120770596191413 MSE test 12.630955724577392\n",
      "MAE train 1.7172471627405481 MAE test 2.492250218539025\n",
      "Epoch 808 / 10000 loss: 16.368905544281006\n",
      "MSE train 6.1205889088946215 MSE test 12.630846230149833\n",
      "MAE train 1.7172183866240678 MAE test 2.4922425738547513\n",
      "Epoch 809 / 10000 loss: 16.368274927139282\n",
      "MSE train 6.120420059315279 MSE test 12.630599042101379\n",
      "MAE train 1.717193275251168 MAE test 2.4922132769031253\n",
      "Epoch 810 / 10000 loss: 16.367575645446777\n",
      "MSE train 6.120237925328313 MSE test 12.630489287321828\n",
      "MAE train 1.7171643990196312 MAE test 2.4922055928239115\n",
      "Epoch 811 / 10000 loss: 16.366941928863525\n",
      "MSE train 6.120068535755227 MSE test 12.630241924862363\n",
      "MAE train 1.7171391741671969 MAE test 2.492176275208751\n",
      "Epoch 812 / 10000 loss: 16.36623978614807\n",
      "MSE train 6.119885905799417 MSE test 12.63013211769514\n",
      "MAE train 1.717110170048675 MAE test 2.4921685761834036\n",
      "Epoch 813 / 10000 loss: 16.36560297012329\n",
      "MSE train 6.119716008498341 MSE test 12.629884425398666\n",
      "MAE train 1.7170848287814222 MAE test 2.492139194520079\n",
      "Epoch 814 / 10000 loss: 16.364899158477783\n",
      "MSE train 6.119532806931544 MSE test 12.629774471994871\n",
      "MAE train 1.7170556943357491 MAE test 2.4921314594620614\n",
      "Epoch 815 / 10000 loss: 16.364261388778687\n",
      "MSE train 6.1193622834022525 MSE test 12.629526693448527\n",
      "MAE train 1.7170302169923326 MAE test 2.4921020510620138\n",
      "Epoch 816 / 10000 loss: 16.363555192947388\n",
      "MSE train 6.119178405066355 MSE test 12.629416508991593\n",
      "MAE train 1.7170009175574572 MAE test 2.4920942593905986\n",
      "Epoch 817 / 10000 loss: 16.362915515899658\n",
      "MSE train 6.119007135171339 MSE test 12.629168506390574\n",
      "MAE train 1.7169752754472527 MAE test 2.492064809056189\n",
      "Epoch 818 / 10000 loss: 16.362204790115356\n",
      "MSE train 6.118822529959947 MSE test 12.629057934948795\n",
      "MAE train 1.716945807046777 MAE test 2.4920569419507563\n",
      "Epoch 819 / 10000 loss: 16.361561059951782\n",
      "MSE train 6.118650435201078 MSE test 12.628809805728306\n",
      "MAE train 1.7169199586177475 MAE test 2.4920274535559748\n",
      "Epoch 820 / 10000 loss: 16.360848426818848\n",
      "MSE train 6.11846480098405 MSE test 12.628698906146733\n",
      "MAE train 1.716890246645444 MAE test 2.49201952243187\n",
      "Epoch 821 / 10000 loss: 16.360201358795166\n",
      "MSE train 6.118291632731185 MSE test 12.628450073737353\n",
      "MAE train 1.716864147420784 MAE test 2.49198989388841\n",
      "Epoch 822 / 10000 loss: 16.359485387802124\n",
      "MSE train 6.118104721957929 MSE test 12.628338916593204\n",
      "MAE train 1.7168341378806316 MAE test 2.49198188870225\n",
      "Epoch 823 / 10000 loss: 16.35883355140686\n",
      "MSE train 6.11792996794345 MSE test 12.628089837891126\n",
      "MAE train 1.716807664221624 MAE test 2.491952191114219\n",
      "Epoch 824 / 10000 loss: 16.358110904693604\n",
      "MSE train 6.117741200496784 MSE test 12.627978002360727\n",
      "MAE train 1.7167771927602764 MAE test 2.4919440397572306\n",
      "Epoch 825 / 10000 loss: 16.3574538230896\n",
      "MSE train 6.1175641706098345 MSE test 12.627728297916494\n",
      "MAE train 1.716750149547656 MAE test 2.491914198350925\n",
      "Epoch 826 / 10000 loss: 16.356722593307495\n",
      "MSE train 6.117372618714718 MSE test 12.627615892623425\n",
      "MAE train 1.7167189737023385 MAE test 2.491905893550789\n",
      "Epoch 827 / 10000 loss: 16.356056451797485\n",
      "MSE train 6.117192112886548 MSE test 12.627365272157665\n",
      "MAE train 1.7166910479409714 MAE test 2.491875847011705\n",
      "Epoch 828 / 10000 loss: 16.355313301086426\n",
      "MSE train 6.116996025293622 MSE test 12.627251840650446\n",
      "MAE train 1.716658719447584 MAE test 2.491867304095103\n",
      "Epoch 829 / 10000 loss: 16.35462999343872\n",
      "MSE train 6.116809857868158 MSE test 12.627000016161958\n",
      "MAE train 1.7166293250584757 MAE test 2.4918369810216774\n",
      "Epoch 830 / 10000 loss: 16.353867053985596\n",
      "MSE train 6.116606381832 MSE test 12.626885222514353\n",
      "MAE train 1.7165950666692977 MAE test 2.4918281203642043\n",
      "Epoch 831 / 10000 loss: 16.353159189224243\n",
      "MSE train 6.116410425589695 MSE test 12.626631836997669\n",
      "MAE train 1.716563138995417 MAE test 2.4917974314192715\n",
      "Epoch 832 / 10000 loss: 16.352362394332886\n",
      "MSE train 6.116194195212677 MSE test 12.626514847751134\n",
      "MAE train 1.7165255361326692 MAE test 2.491788097430829\n",
      "Epoch 833 / 10000 loss: 16.351609230041504\n",
      "MSE train 6.115981658496493 MSE test 12.62625899046047\n",
      "MAE train 1.7164892516210062 MAE test 2.491756855856635\n",
      "Epoch 834 / 10000 loss: 16.35075330734253\n",
      "MSE train 6.115744446810881 MSE test 12.626139033383328\n",
      "MAE train 1.7164461929583255 MAE test 2.4917468896294745\n",
      "Epoch 835 / 10000 loss: 16.34992241859436\n",
      "MSE train 6.1155068663921215 MSE test 12.625880045753165\n",
      "MAE train 1.7164033742056617 MAE test 2.491714966606525\n",
      "Epoch 836 / 10000 loss: 16.348968029022217\n",
      "MSE train 6.115243824677895 MSE test 12.625756862334221\n",
      "MAE train 1.7163532391121707 MAE test 2.4917043508955783\n",
      "Epoch 837 / 10000 loss: 16.348016262054443\n",
      "MSE train 6.1149868230193425 MSE test 12.625495462019325\n",
      "MAE train 1.7163045295020254 MAE test 2.4916720192667583\n",
      "Epoch 838 / 10000 loss: 16.346938371658325\n",
      "MSE train 6.114720360019951 MSE test 12.625372125977904\n",
      "MAE train 1.7162526353578393 MAE test 2.4916615215409808\n",
      "Epoch 839 / 10000 loss: 16.34589195251465\n",
      "MSE train 6.114480577674732 MSE test 12.625113715857617\n",
      "MAE train 1.7162082435139365 MAE test 2.4916300161324156\n",
      "Epoch 840 / 10000 loss: 16.344792366027832\n",
      "MSE train 6.114245224646732 MSE test 12.62499570106625\n",
      "MAE train 1.7161649708649478 MAE test 2.4916208541753426\n",
      "Epoch 841 / 10000 loss: 16.34382390975952\n",
      "MSE train 6.1140379938939 MSE test 12.624743469983374\n",
      "MAE train 1.7161296565211541 MAE test 2.4915907830474535\n",
      "Epoch 842 / 10000 loss: 16.342870473861694\n",
      "MSE train 6.113828570498244 MSE test 12.624630506680724\n",
      "MAE train 1.7160936779184728 MAE test 2.491582750561477\n",
      "Epoch 843 / 10000 loss: 16.34205913543701\n",
      "MSE train 6.113639366646634 MSE test 12.6243814105897\n",
      "MAE train 1.7160634502612877 MAE test 2.491553350431633\n",
      "Epoch 844 / 10000 loss: 16.341232776641846\n",
      "MSE train 6.113441946324021 MSE test 12.624270298218576\n",
      "MAE train 1.7160308042328773 MAE test 2.4915456549107575\n",
      "Epoch 845 / 10000 loss: 16.340508937835693\n",
      "MSE train 6.113260754990081 MSE test 12.624021951646732\n",
      "MAE train 1.716002858504073 MAE test 2.491516356881238\n",
      "Epoch 846 / 10000 loss: 16.339741945266724\n",
      "MSE train 6.113068741042306 MSE test 12.623910811432214\n",
      "MAE train 1.715971775659425 MAE test 2.4915086224087877\n",
      "Epoch 847 / 10000 loss: 16.33905863761902\n",
      "MSE train 6.1128913337171085 MSE test 12.623662328882958\n",
      "MAE train 1.7159449200185015 MAE test 2.4914792574276454\n",
      "Epoch 848 / 10000 loss: 16.338318824768066\n",
      "MSE train 6.112702091102546 MSE test 12.623550751463124\n",
      "MAE train 1.7159146029310899 MAE test 2.491471404399157\n",
      "Epoch 849 / 10000 loss: 16.337656021118164\n",
      "MSE train 6.112526637880186 MSE test 12.623301806542498\n",
      "MAE train 1.715888322768144 MAE test 2.4914419331063464\n",
      "Epoch 850 / 10000 loss: 16.336929082870483\n",
      "MSE train 6.112338770902004 MSE test 12.623189862232206\n",
      "MAE train 1.71585843175107 MAE test 2.4914339881273833\n",
      "Epoch 851 / 10000 loss: 16.336275815963745\n",
      "MSE train 6.11216442517672 MSE test 12.622940306505381\n",
      "MAE train 1.7158324999060466 MAE test 2.4914043937440584\n",
      "Epoch 852 / 10000 loss: 16.335556983947754\n",
      "MSE train 6.111977347791089 MSE test 12.622827964114956\n",
      "MAE train 1.7158028722125132 MAE test 2.491396362387132\n",
      "Epoch 853 / 10000 loss: 16.334909915924072\n",
      "MSE train 6.1118035733043605 MSE test 12.622578106996206\n",
      "MAE train 1.7157771197713145 MAE test 2.491366718253612\n",
      "Epoch 854 / 10000 loss: 16.33419632911682\n",
      "MSE train 6.111616888777222 MSE test 12.62246516332848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7157476150381463 MAE test 2.4913585969114638\n",
      "Epoch 855 / 10000 loss: 16.333552598953247\n",
      "MSE train 6.111443407004508 MSE test 12.622214884041396\n",
      "MAE train 1.7157219921519635 MAE test 2.491328864122044\n",
      "Epoch 856 / 10000 loss: 16.332841396331787\n",
      "MSE train 6.111256896635562 MSE test 12.622101655093038\n",
      "MAE train 1.7156925752767036 MAE test 2.491320704240489\n",
      "Epoch 857 / 10000 loss: 16.33219814300537\n",
      "MSE train 6.111083500416658 MSE test 12.621850978778385\n",
      "MAE train 1.7156670014602757 MAE test 2.4912909200931828\n",
      "Epoch 858 / 10000 loss: 16.331488370895386\n",
      "MSE train 6.110897136735072 MSE test 12.621737519728688\n",
      "MAE train 1.7156376191213711 MAE test 2.4912827010227647\n",
      "Epoch 859 / 10000 loss: 16.33084726333618\n",
      "MSE train 6.110723778271672 MSE test 12.621486585504819\n",
      "MAE train 1.7156120890506485 MAE test 2.4912528814693644\n",
      "Epoch 860 / 10000 loss: 16.330138444900513\n",
      "MSE train 6.110537340594931 MSE test 12.621372614141002\n",
      "MAE train 1.7155827337264564 MAE test 2.491244599780706\n",
      "Epoch 861 / 10000 loss: 16.329497814178467\n",
      "MSE train 6.110363890285141 MSE test 12.621121296292745\n",
      "MAE train 1.7155572154150098 MAE test 2.4912147207740034\n",
      "Epoch 862 / 10000 loss: 16.32878851890564\n",
      "MSE train 6.110177383942344 MSE test 12.62100719257413\n",
      "MAE train 1.7155278624872796 MAE test 2.491206440986729\n",
      "Epoch 863 / 10000 loss: 16.328147649765015\n",
      "MSE train 6.110003844632527 MSE test 12.620755705340803\n",
      "MAE train 1.7155023464734167 MAE test 2.4911765365550984\n",
      "Epoch 864 / 10000 loss: 16.32744002342224\n",
      "MSE train 6.109817258750913 MSE test 12.620641268880924\n",
      "MAE train 1.7154729808459752 MAE test 2.491168206683829\n",
      "Epoch 865 / 10000 loss: 16.326798915863037\n",
      "MSE train 6.109643674075015 MSE test 12.620389677684003\n",
      "MAE train 1.7154474585260795 MAE test 2.4911382930365984\n",
      "Epoch 866 / 10000 loss: 16.326090335845947\n",
      "MSE train 6.109456978824155 MSE test 12.620274836528537\n",
      "MAE train 1.715418082818254 MAE test 2.491129909852835\n",
      "Epoch 867 / 10000 loss: 16.32544994354248\n",
      "MSE train 6.109283353176356 MSE test 12.62002293189396\n",
      "MAE train 1.715392549393771 MAE test 2.491099968500739\n",
      "Epoch 868 / 10000 loss: 16.32474136352539\n",
      "MSE train 6.109096596297687 MSE test 12.619907969921943\n",
      "MAE train 1.715363146971346 MAE test 2.4910915635039186\n",
      "Epoch 869 / 10000 loss: 16.324100494384766\n",
      "MSE train 6.108922890421316 MSE test 12.619655732834735\n",
      "MAE train 1.7153376006207643 MAE test 2.491061579784549\n",
      "Epoch 870 / 10000 loss: 16.323391437530518\n",
      "MSE train 6.108736113070347 MSE test 12.619540592296799\n",
      "MAE train 1.7153081936236094 MAE test 2.491053160771796\n",
      "Epoch 871 / 10000 loss: 16.322751998901367\n",
      "MSE train 6.1085624026600795 MSE test 12.619288250391712\n",
      "MAE train 1.715282661060508 MAE test 2.4910231638130678\n",
      "Epoch 872 / 10000 loss: 16.322044134140015\n",
      "MSE train 6.1083757204522 MSE test 12.619172953197443\n",
      "MAE train 1.7152532595853625 MAE test 2.4910147335889046\n",
      "Epoch 873 / 10000 loss: 16.321403980255127\n",
      "MSE train 6.108202073533734 MSE test 12.61892049265994\n",
      "MAE train 1.7152277179946904 MAE test 2.490984742135058\n",
      "Epoch 874 / 10000 loss: 16.320695161819458\n",
      "MSE train 6.108015470480058 MSE test 12.61880496711147\n",
      "MAE train 1.715198308298082 MAE test 2.4909762902616155\n",
      "Epoch 875 / 10000 loss: 16.32005548477173\n",
      "MSE train 6.107841986996825 MSE test 12.618552176058826\n",
      "MAE train 1.7151727738405418 MAE test 2.490946242288332\n",
      "Epoch 876 / 10000 loss: 16.31934881210327\n",
      "MSE train 6.107655496979388 MSE test 12.618436381769962\n",
      "MAE train 1.7151433679950414 MAE test 2.490937760951954\n",
      "Epoch 877 / 10000 loss: 16.318710803985596\n",
      "MSE train 6.107482201038714 MSE test 12.618183452767227\n",
      "MAE train 1.7151178618396499 MAE test 2.4909077234107904\n",
      "Epoch 878 / 10000 loss: 16.318005084991455\n",
      "MSE train 6.1072960140299895 MSE test 12.61806751962806\n",
      "MAE train 1.7150885009317183 MAE test 2.4908992376105346\n",
      "Epoch 879 / 10000 loss: 16.31736707687378\n",
      "MSE train 6.107122912259897 MSE test 12.617814422983045\n",
      "MAE train 1.7150630432248144 MAE test 2.490869177190602\n",
      "Epoch 880 / 10000 loss: 16.316662311553955\n",
      "MSE train 6.106936991493474 MSE test 12.617698179067137\n",
      "MAE train 1.7150337178576325 MAE test 2.4908606555544717\n",
      "Epoch 881 / 10000 loss: 16.316025972366333\n",
      "MSE train 6.106764229833491 MSE test 12.617444812592893\n",
      "MAE train 1.7150082993179934 MAE test 2.490830570042132\n",
      "Epoch 882 / 10000 loss: 16.315322399139404\n",
      "MSE train 6.1065785689626955 MSE test 12.617328279375545\n",
      "MAE train 1.7149790232261986 MAE test 2.4908220371880208\n",
      "Epoch 883 / 10000 loss: 16.314687967300415\n",
      "MSE train 6.1064061147755355 MSE test 12.617074750447923\n",
      "MAE train 1.7149536482884113 MAE test 2.490791948027037\n",
      "Epoch 884 / 10000 loss: 16.313985586166382\n",
      "MSE train 6.106220862784966 MSE test 12.616958081032399\n",
      "MAE train 1.7149244156858836 MAE test 2.4907834001175253\n",
      "Epoch 885 / 10000 loss: 16.313353300094604\n",
      "MSE train 6.106048787981881 MSE test 12.616704062543812\n",
      "MAE train 1.7148991263304094 MAE test 2.490753268854012\n",
      "Epoch 886 / 10000 loss: 16.31265354156494\n",
      "MSE train 6.105863885302732 MSE test 12.616586895835773\n",
      "MAE train 1.7148699859806709 MAE test 2.490744665755181\n",
      "Epoch 887 / 10000 loss: 16.312021493911743\n",
      "MSE train 6.105692128908617 MSE test 12.616332570429048\n",
      "MAE train 1.7148447479305433 MAE test 2.490714519151275\n",
      "Epoch 888 / 10000 loss: 16.311322927474976\n",
      "MSE train 6.105507543108399 MSE test 12.616214980829165\n",
      "MAE train 1.7148156411812094 MAE test 2.4907058890678924\n",
      "Epoch 889 / 10000 loss: 16.310693979263306\n",
      "MSE train 6.105336086582612 MSE test 12.615960231265872\n",
      "MAE train 1.7147904382908299 MAE test 2.4906756936932237\n",
      "Epoch 890 / 10000 loss: 16.309996843338013\n",
      "MSE train 6.105151846092383 MSE test 12.615842125763463\n",
      "MAE train 1.7147613532926353 MAE test 2.490667023806718\n",
      "Epoch 891 / 10000 loss: 16.309369325637817\n",
      "MSE train 6.104980676000297 MSE test 12.615586750514696\n",
      "MAE train 1.7147361673907704 MAE test 2.4906367656090267\n",
      "Epoch 892 / 10000 loss: 16.30867338180542\n",
      "MSE train 6.104796645188449 MSE test 12.61546791275007\n",
      "MAE train 1.7147071104126486 MAE test 2.490628021490052\n",
      "Epoch 893 / 10000 loss: 16.308048009872437\n",
      "MSE train 6.104625725334215 MSE test 12.615211872829779\n",
      "MAE train 1.7146819662366375 MAE test 2.4905977213179527\n",
      "Epoch 894 / 10000 loss: 16.307353258132935\n",
      "MSE train 6.104441863888238 MSE test 12.615092322474982\n",
      "MAE train 1.7146529328871 MAE test 2.4905889282599687\n",
      "Epoch 895 / 10000 loss: 16.30672812461853\n",
      "MSE train 6.1042710880699715 MSE test 12.614835319276512\n",
      "MAE train 1.714627814011586 MAE test 2.4905585353785544\n",
      "Epoch 896 / 10000 loss: 16.306034803390503\n",
      "MSE train 6.104087332947298 MSE test 12.614714801858312\n",
      "MAE train 1.7145987987172637 MAE test 2.4905496579621325\n",
      "Epoch 897 / 10000 loss: 16.30541157722473\n",
      "MSE train 6.10391649757944 MSE test 12.614456751794254\n",
      "MAE train 1.7145736596888972 MAE test 2.490519160557837\n",
      "Epoch 898 / 10000 loss: 16.3047194480896\n",
      "MSE train 6.103732665459325 MSE test 12.614334851343799\n",
      "MAE train 1.7145446148459387 MAE test 2.4905101669710135\n",
      "Epoch 899 / 10000 loss: 16.30409574508667\n",
      "MSE train 6.10356171174841 MSE test 12.614075338575566\n",
      "MAE train 1.7145194521098583 MAE test 2.4904795456442557\n",
      "Epoch 900 / 10000 loss: 16.303403854370117\n",
      "MSE train 6.103377604770874 MSE test 12.613952068878383\n",
      "MAE train 1.7144903534415468 MAE test 2.490470424764242\n",
      "Epoch 901 / 10000 loss: 16.302781343460083\n",
      "MSE train 6.103206344823313 MSE test 12.6136907401163\n",
      "MAE train 1.7144651257257286 MAE test 2.4904396453788133\n",
      "Epoch 902 / 10000 loss: 16.302088499069214\n",
      "MSE train 6.1030217702895815 MSE test 12.613565472356656\n",
      "MAE train 1.7144359382182672 MAE test 2.490430349915064\n",
      "Epoch 903 / 10000 loss: 16.30146551132202\n",
      "MSE train 6.102849791845454 MSE test 12.613301852579378\n",
      "MAE train 1.714410571354675 MAE test 2.4903993562632865\n",
      "Epoch 904 / 10000 loss: 16.300772428512573\n",
      "MSE train 6.1026643581188935 MSE test 12.613173797790706\n",
      "MAE train 1.7143812176137394 MAE test 2.4903898073030573\n",
      "Epoch 905 / 10000 loss: 16.30014681816101\n",
      "MSE train 6.10249134735003 MSE test 12.612907370896007\n",
      "MAE train 1.7143556706707213 MAE test 2.4903585623823448\n",
      "Epoch 906 / 10000 loss: 16.299452304840088\n",
      "MSE train 6.102304638259642 MSE test 12.612775909136374\n",
      "MAE train 1.7143261003023547 MAE test 2.4903486926845195\n",
      "Epoch 907 / 10000 loss: 16.298824548721313\n",
      "MSE train 6.102129835161566 MSE test 12.612505533573685\n",
      "MAE train 1.7143002502153506 MAE test 2.490317102207773\n",
      "Epoch 908 / 10000 loss: 16.29812455177307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.101940858238009 MSE test 12.612369542760696\n",
      "MAE train 1.7142702955602853 MAE test 2.49030686210099\n",
      "Epoch 909 / 10000 loss: 16.2974910736084\n",
      "MSE train 6.101763374042809 MSE test 12.612093701530036\n",
      "MAE train 1.7142439733217392 MAE test 2.4902748020147913\n",
      "Epoch 910 / 10000 loss: 16.29678511619568\n",
      "MSE train 6.101570910880402 MSE test 12.611951391749601\n",
      "MAE train 1.7142134111391223 MAE test 2.490263991857486\n",
      "Epoch 911 / 10000 loss: 16.29614233970642\n",
      "MSE train 6.101388993755358 MSE test 12.611668370303233\n",
      "MAE train 1.7141863298794013 MAE test 2.4902313115789836\n",
      "Epoch 912 / 10000 loss: 16.29542589187622\n",
      "MSE train 6.101191020034719 MSE test 12.611517538033285\n",
      "MAE train 1.7141547934405987 MAE test 2.4902197518148457\n",
      "Epoch 913 / 10000 loss: 16.29476809501648\n",
      "MSE train 6.101002212723714 MSE test 12.611224690189642\n",
      "MAE train 1.7141265483560963 MAE test 2.490186170112779\n",
      "Epoch 914 / 10000 loss: 16.294031620025635\n",
      "MSE train 6.100795869982696 MSE test 12.611063019450151\n",
      "MAE train 1.7140936372563242 MAE test 2.4901736109827355\n",
      "Epoch 915 / 10000 loss: 16.293349742889404\n",
      "MSE train 6.100597517531622 MSE test 12.610758418067142\n",
      "MAE train 1.71406378228681 MAE test 2.490138949340112\n",
      "Epoch 916 / 10000 loss: 16.292582511901855\n",
      "MSE train 6.100381755128692 MSE test 12.610585796280493\n",
      "MAE train 1.7140293258501065 MAE test 2.490125385153457\n",
      "Epoch 917 / 10000 loss: 16.291863679885864\n",
      "MSE train 6.100176914306212 MSE test 12.61027352708186\n",
      "MAE train 1.7139984221053561 MAE test 2.4900900206921275\n",
      "Epoch 918 / 10000 loss: 16.291060209274292\n",
      "MSE train 6.099961696768906 MSE test 12.610100402375895\n",
      "MAE train 1.7139641451780003 MAE test 2.4900763841581894\n",
      "Epoch 919 / 10000 loss: 16.290316343307495\n",
      "MSE train 6.099767188915024 MSE test 12.60979897883311\n",
      "MAE train 1.713935405964398 MAE test 2.4900419582853117\n",
      "Epoch 920 / 10000 loss: 16.28951334953308\n",
      "MSE train 6.099570328034925 MSE test 12.609647931974862\n",
      "MAE train 1.7139045241140214 MAE test 2.4900303068065472\n",
      "Epoch 921 / 10000 loss: 16.288806200027466\n",
      "MSE train 6.099395720760031 MSE test 12.60937504867264\n",
      "MAE train 1.713879111189762 MAE test 2.4899984625740674\n",
      "Epoch 922 / 10000 loss: 16.288066387176514\n",
      "MSE train 6.099214515836928 MSE test 12.609251562799255\n",
      "MAE train 1.7138505945604867 MAE test 2.4899892857384978\n",
      "Epoch 923 / 10000 loss: 16.287424325942993\n",
      "MSE train 6.099049896528287 MSE test 12.609000212067889\n",
      "MAE train 1.7138265075025847 MAE test 2.4899593626862573\n",
      "Epoch 924 / 10000 loss: 16.286730766296387\n",
      "MSE train 6.0988741566919735 MSE test 12.608891432518005\n",
      "MAE train 1.7137987097143408 MAE test 2.489951503115349\n",
      "Epoch 925 / 10000 loss: 16.286116361618042\n",
      "MSE train 6.098712275118897 MSE test 12.60864935815956\n",
      "MAE train 1.7137749460418927 MAE test 2.48992242633045\n",
      "Epoch 926 / 10000 loss: 16.285436868667603\n",
      "MSE train 6.098537782051315 MSE test 12.608545820192749\n",
      "MAE train 1.7137472548255712 MAE test 2.4899150407985196\n",
      "Epoch 927 / 10000 loss: 16.284828424453735\n",
      "MSE train 6.098376289575172 MSE test 12.608306621784243\n",
      "MAE train 1.7137235025131086 MAE test 2.489886238655818\n",
      "Epoch 928 / 10000 loss: 16.28415298461914\n",
      "MSE train 6.0982018099968425 MSE test 12.60820446507724\n",
      "MAE train 1.7136957857465693 MAE test 2.489879005718305\n",
      "Epoch 929 / 10000 loss: 16.283546447753906\n",
      "MSE train 6.098040224908664 MSE test 12.607965675984886\n",
      "MAE train 1.713672002332996 MAE test 2.489850260502555\n",
      "Epoch 930 / 10000 loss: 16.282872676849365\n",
      "MSE train 6.097865523638892 MSE test 12.607863633541815\n",
      "MAE train 1.7136442381712464 MAE test 2.489843050852933\n",
      "Epoch 931 / 10000 loss: 16.282267332077026\n",
      "MSE train 6.097703669491122 MSE test 12.607624627512035\n",
      "MAE train 1.7136204077862782 MAE test 2.4898142965514705\n",
      "Epoch 932 / 10000 loss: 16.281592845916748\n",
      "MSE train 6.09752876758077 MSE test 12.607522336318937\n",
      "MAE train 1.7135926099570329 MAE test 2.489807103850431\n",
      "Epoch 933 / 10000 loss: 16.28098750114441\n",
      "MSE train 6.097366713597968 MSE test 12.607282882244215\n",
      "MAE train 1.7135687455273223 MAE test 2.4897783317248825\n",
      "Epoch 934 / 10000 loss: 16.280314207077026\n",
      "MSE train 6.097191680412272 MSE test 12.607180130326908\n",
      "MAE train 1.7135409205510794 MAE test 2.4897710954460894\n",
      "Epoch 935 / 10000 loss: 16.279710054397583\n",
      "MSE train 6.097029523218778 MSE test 12.606940530672722\n",
      "MAE train 1.713517036381141 MAE test 2.4897423334903603\n",
      "Epoch 936 / 10000 loss: 16.279037952423096\n",
      "MSE train 6.096854391638627 MSE test 12.606837440888135\n",
      "MAE train 1.7134891914363686 MAE test 2.4897350981629685\n",
      "Epoch 937 / 10000 loss: 16.278432369232178\n",
      "MSE train 6.0966922104109145 MSE test 12.606597661675915\n",
      "MAE train 1.713465297980101 MAE test 2.489706342070286\n",
      "Epoch 938 / 10000 loss: 16.27776074409485\n",
      "MSE train 6.096517017407562 MSE test 12.606494401537192\n",
      "MAE train 1.7134374419316183 MAE test 2.4896991192949045\n",
      "Epoch 939 / 10000 loss: 16.277156114578247\n",
      "MSE train 6.096354847128111 MSE test 12.60625434747699\n",
      "MAE train 1.713413548420253 MAE test 2.4896703462912173\n",
      "Epoch 940 / 10000 loss: 16.27648425102234\n",
      "MSE train 6.096179599705066 MSE test 12.60615090030305\n",
      "MAE train 1.7133856702273764 MAE test 2.489663102888992\n",
      "Epoch 941 / 10000 loss: 16.275880575180054\n",
      "MSE train 6.09601735026832 MSE test 12.605910522199451\n",
      "MAE train 1.7133617598908724 MAE test 2.4896343281204714\n",
      "Epoch 942 / 10000 loss: 16.275208950042725\n",
      "MSE train 6.095842082163776 MSE test 12.605807004496635\n",
      "MAE train 1.7133338796400752 MAE test 2.4896271021303527\n",
      "Epoch 943 / 10000 loss: 16.27460551261902\n",
      "MSE train 6.095679861589815 MSE test 12.60556653868975\n",
      "MAE train 1.7133099746009914 MAE test 2.4895983279262874\n",
      "Epoch 944 / 10000 loss: 16.27393341064453\n",
      "MSE train 6.095504615654741 MSE test 12.605462773627284\n",
      "MAE train 1.7132820872704204 MAE test 2.489591084152588\n",
      "Epoch 945 / 10000 loss: 16.273329973220825\n",
      "MSE train 6.095342415440634 MSE test 12.605222174115426\n",
      "MAE train 1.713258177439433 MAE test 2.4895623044776953\n",
      "Epoch 946 / 10000 loss: 16.272658109664917\n",
      "MSE train 6.095167195257824 MSE test 12.605118252008644\n",
      "MAE train 1.7132302932573984 MAE test 2.4895550369080435\n",
      "Epoch 947 / 10000 loss: 16.272054433822632\n",
      "MSE train 6.0950049333786245 MSE test 12.604877718357322\n",
      "MAE train 1.713206368215292 MAE test 2.4895262932164464\n",
      "Epoch 948 / 10000 loss: 16.27138352394104\n",
      "MSE train 6.094829756857699 MSE test 12.604773822978947\n",
      "MAE train 1.7131784795630003 MAE test 2.489519046852037\n",
      "Epoch 949 / 10000 loss: 16.27078080177307\n",
      "MSE train 6.094667539662614 MSE test 12.604532933525132\n",
      "MAE train 1.7131545496514369 MAE test 2.489490260188139\n",
      "Epoch 950 / 10000 loss: 16.270108222961426\n",
      "MSE train 6.094492319943462 MSE test 12.604428951378505\n",
      "MAE train 1.713126648500168 MAE test 2.489483030044405\n",
      "Epoch 951 / 10000 loss: 16.269505500793457\n",
      "MSE train 6.094330197056148 MSE test 12.604188316612026\n",
      "MAE train 1.7131027299490689 MAE test 2.489454272491774\n",
      "Epoch 952 / 10000 loss: 16.268834352493286\n",
      "MSE train 6.094154941396275 MSE test 12.604084094849336\n",
      "MAE train 1.7130748104987288 MAE test 2.4894470213695437\n",
      "Epoch 953 / 10000 loss: 16.26823115348816\n",
      "MSE train 6.093992742983728 MSE test 12.603843136589402\n",
      "MAE train 1.7130508748083952 MAE test 2.4894182477853777\n",
      "Epoch 954 / 10000 loss: 16.26756000518799\n",
      "MSE train 6.093817571435915 MSE test 12.603739040557333\n",
      "MAE train 1.713022961034745 MAE test 2.489411013804161\n",
      "Epoch 955 / 10000 loss: 16.26695728302002\n",
      "MSE train 6.093655342683091 MSE test 12.603498208657715\n",
      "MAE train 1.7129990061994207 MAE test 2.4893822546295454\n",
      "Epoch 956 / 10000 loss: 16.266286849975586\n",
      "MSE train 6.093480195854904 MSE test 12.603393968779741\n",
      "MAE train 1.7129710873441706 MAE test 2.4893750020207666\n",
      "Epoch 957 / 10000 loss: 16.26568365097046\n",
      "MSE train 6.0933180471341055 MSE test 12.603153031709846\n",
      "MAE train 1.7129471393845692 MAE test 2.4893462328351643\n",
      "Epoch 958 / 10000 loss: 16.265012502670288\n",
      "MSE train 6.093142864957137 MSE test 12.60304879862544\n",
      "MAE train 1.712919201155962 MAE test 2.489339001798753\n",
      "Epoch 959 / 10000 loss: 16.2644100189209\n",
      "MSE train 6.092980676090659 MSE test 12.602807745151376\n",
      "MAE train 1.7128952397944164 MAE test 2.489310230104656\n",
      "Epoch 960 / 10000 loss: 16.263739109039307\n",
      "MSE train 6.092805541390198 MSE test 12.602703326505512\n",
      "MAE train 1.7128672954370898 MAE test 2.489302959024453\n",
      "Epoch 961 / 10000 loss: 16.263136625289917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.092643358628851 MSE test 12.602462309636307\n",
      "MAE train 1.7128433219416492 MAE test 2.489274207326473\n",
      "Epoch 962 / 10000 loss: 16.262465953826904\n",
      "MSE train 6.09246824640497 MSE test 12.602357999311687\n",
      "MAE train 1.71281537616708 MAE test 2.489266973764157\n",
      "Epoch 963 / 10000 loss: 16.261862993240356\n",
      "MSE train 6.092306083914016 MSE test 12.6021169274148\n",
      "MAE train 1.7127913925386213 MAE test 2.4892382146342324\n",
      "Epoch 964 / 10000 loss: 16.261192798614502\n",
      "MSE train 6.092130899745269 MSE test 12.60201258658343\n",
      "MAE train 1.712763426325895 MAE test 2.489230969405961\n",
      "Epoch 965 / 10000 loss: 16.260590314865112\n",
      "MSE train 6.091968793812291 MSE test 12.601771570744395\n",
      "MAE train 1.7127394432517116 MAE test 2.4892022253755037\n",
      "Epoch 966 / 10000 loss: 16.25991988182068\n",
      "MSE train 6.091793662075297 MSE test 12.601667052721949\n",
      "MAE train 1.7127114730405655 MAE test 2.489194979125983\n",
      "Epoch 967 / 10000 loss: 16.25931739807129\n",
      "MSE train 6.091631491509883 MSE test 12.601425945274887\n",
      "MAE train 1.7126874662814846 MAE test 2.489166214235108\n",
      "Epoch 968 / 10000 loss: 16.25864577293396\n",
      "MSE train 6.091456362237148 MSE test 12.601321437337317\n",
      "MAE train 1.712659477764848 MAE test 2.4891589718251597\n",
      "Epoch 969 / 10000 loss: 16.258044958114624\n",
      "MSE train 6.0912942837472315 MSE test 12.601080385046634\n",
      "MAE train 1.7126354698196915 MAE test 2.489130217011325\n",
      "Epoch 970 / 10000 loss: 16.257373809814453\n",
      "MSE train 6.091119087403484 MSE test 12.60097594754974\n",
      "MAE train 1.712607455986568 MAE test 2.4891229848876932\n",
      "Epoch 971 / 10000 loss: 16.256771087646484\n",
      "MSE train 6.090956975899171 MSE test 12.600734839327155\n",
      "MAE train 1.7125834346539928 MAE test 2.4890942277531867\n",
      "Epoch 972 / 10000 loss: 16.256101369857788\n",
      "MSE train 6.090781809911033 MSE test 12.600630469718778\n",
      "MAE train 1.7125554063448356 MAE test 2.4890870138532173\n",
      "Epoch 973 / 10000 loss: 16.25549817085266\n",
      "MSE train 6.090619739280625 MSE test 12.600389291876118\n",
      "MAE train 1.7125313718391169 MAE test 2.4890582631349596\n",
      "Epoch 974 / 10000 loss: 16.25482749938965\n",
      "MSE train 6.090444571236397 MSE test 12.600284747379275\n",
      "MAE train 1.7125033323137175 MAE test 2.489051028660908\n",
      "Epoch 975 / 10000 loss: 16.254225254058838\n",
      "MSE train 6.090282444595704 MSE test 12.600043520294452\n",
      "MAE train 1.7124792752785254 MAE test 2.489022271671637\n",
      "Epoch 976 / 10000 loss: 16.253555059432983\n",
      "MSE train 6.090107289991985 MSE test 12.599939068570663\n",
      "MAE train 1.7124512123060605 MAE test 2.48901504474778\n",
      "Epoch 977 / 10000 loss: 16.252952814102173\n",
      "MSE train 6.089945160626191 MSE test 12.599697934276755\n",
      "MAE train 1.712427140410025 MAE test 2.488986304544163\n",
      "Epoch 978 / 10000 loss: 16.25228190422058\n",
      "MSE train 6.089769977274437 MSE test 12.599593299236565\n",
      "MAE train 1.7123990538379577 MAE test 2.488979055971035\n",
      "Epoch 979 / 10000 loss: 16.25168013572693\n",
      "MSE train 6.089607837817211 MSE test 12.599352128364577\n",
      "MAE train 1.7123749609157297 MAE test 2.488950307975249\n",
      "Epoch 980 / 10000 loss: 16.251010179519653\n",
      "MSE train 6.089432675380691 MSE test 12.59924764728954\n",
      "MAE train 1.7123468450402903 MAE test 2.488943092328423\n",
      "Epoch 981 / 10000 loss: 16.250407934188843\n",
      "MSE train 6.089270515528032 MSE test 12.599006402469808\n",
      "MAE train 1.7123227317835088 MAE test 2.4889143396385194\n",
      "Epoch 982 / 10000 loss: 16.249736547470093\n",
      "MSE train 6.0890953599883675 MSE test 12.598901873384948\n",
      "MAE train 1.7122946038699305 MAE test 2.4889071330090364\n",
      "Epoch 983 / 10000 loss: 16.249134063720703\n",
      "MSE train 6.088933139581885 MSE test 12.59866064004396\n",
      "MAE train 1.71227045089744 MAE test 2.488878370640813\n",
      "Epoch 984 / 10000 loss: 16.24846315383911\n",
      "MSE train 6.088757928600193 MSE test 12.598556033776614\n",
      "MAE train 1.7122422901619043 MAE test 2.4888711403207657\n",
      "Epoch 985 / 10000 loss: 16.24786114692688\n",
      "MSE train 6.088595716360104 MSE test 12.598314877460979\n",
      "MAE train 1.7122181185086605 MAE test 2.4888424075537112\n",
      "Epoch 986 / 10000 loss: 16.247190713882446\n",
      "MSE train 6.088420505413472 MSE test 12.598210190656593\n",
      "MAE train 1.7121899251722568 MAE test 2.488835163238205\n",
      "Epoch 987 / 10000 loss: 16.24658751487732\n",
      "MSE train 6.088258300467933 MSE test 12.597968928821658\n",
      "MAE train 1.7121657246731996 MAE test 2.4888064121467597\n",
      "Epoch 988 / 10000 loss: 16.245917081832886\n",
      "MSE train 6.088083055821457 MSE test 12.597864275212126\n",
      "MAE train 1.7121374931709137 MAE test 2.4887991829779397\n",
      "Epoch 989 / 10000 loss: 16.245314121246338\n",
      "MSE train 6.087920759463344 MSE test 12.597622956688584\n",
      "MAE train 1.712113255064174 MAE test 2.48877042836979\n",
      "Epoch 990 / 10000 loss: 16.244644165039062\n",
      "MSE train 6.0877453899863445 MSE test 12.597518500793159\n",
      "MAE train 1.7120849677893841 MAE test 2.488763223366451\n",
      "Epoch 991 / 10000 loss: 16.244040727615356\n",
      "MSE train 6.087583138625112 MSE test 12.597277293774955\n",
      "MAE train 1.712060699745273 MAE test 2.488734492107321\n",
      "Epoch 992 / 10000 loss: 16.243369340896606\n",
      "MSE train 6.087407754962596 MSE test 12.597172527166022\n",
      "MAE train 1.71203237121398 MAE test 2.4887272453174156\n",
      "Epoch 993 / 10000 loss: 16.242767333984375\n",
      "MSE train 6.087245441853895 MSE test 12.59693137474073\n",
      "MAE train 1.7120080577670242 MAE test 2.488698507235651\n",
      "Epoch 994 / 10000 loss: 16.242095470428467\n",
      "MSE train 6.087069982417023 MSE test 12.59682669104947\n",
      "MAE train 1.7119796771636766 MAE test 2.4886912893807294\n",
      "Epoch 995 / 10000 loss: 16.241493225097656\n",
      "MSE train 6.086907621725489 MSE test 12.59658526716096\n",
      "MAE train 1.7119553101436844 MAE test 2.488662520364499\n",
      "Epoch 996 / 10000 loss: 16.24082064628601\n",
      "MSE train 6.086732097034109 MSE test 12.596480774992362\n",
      "MAE train 1.711926873463431 MAE test 2.488655319784216\n",
      "Epoch 997 / 10000 loss: 16.240216970443726\n",
      "MSE train 6.086569529099655 MSE test 12.596239346436496\n",
      "MAE train 1.7119024268344176 MAE test 2.4886265634957017\n",
      "Epoch 998 / 10000 loss: 16.23954701423645\n",
      "MSE train 6.086393977542043 MSE test 12.596134564075637\n",
      "MAE train 1.7118739254742719 MAE test 2.488619316759453\n",
      "Epoch 999 / 10000 loss: 16.238940954208374\n",
      "MSE train 6.086231304429336 MSE test 12.595893263431359\n",
      "MAE train 1.711849402786218 MAE test 2.48859057720669\n",
      "Epoch 1000 / 10000 loss: 16.238269329071045\n",
      "MSE train 6.086055568501966 MSE test 12.59578846824085\n",
      "MAE train 1.7118208211777584 MAE test 2.4885833383014138\n",
      "Epoch 1001 / 10000 loss: 16.2376651763916\n",
      "MSE train 6.085892808031475 MSE test 12.595547262766642\n",
      "MAE train 1.7117962189212363 MAE test 2.4885546138353547\n",
      "Epoch 1002 / 10000 loss: 16.236992597579956\n",
      "MSE train 6.085716891499618 MSE test 12.595442321259405\n",
      "MAE train 1.711767529095133 MAE test 2.488547362584267\n",
      "Epoch 1003 / 10000 loss: 16.236387252807617\n",
      "MSE train 6.085553985986044 MSE test 12.595201133693912\n",
      "MAE train 1.7117428276124067 MAE test 2.4885186304259594\n",
      "Epoch 1004 / 10000 loss: 16.23571467399597\n",
      "MSE train 6.085377868154622 MSE test 12.595096355657365\n",
      "MAE train 1.711714019817906 MAE test 2.488511397418146\n",
      "Epoch 1005 / 10000 loss: 16.235108375549316\n",
      "MSE train 6.085214744421642 MSE test 12.594854948161649\n",
      "MAE train 1.7116891903961031 MAE test 2.488482652738657\n",
      "Epoch 1006 / 10000 loss: 16.23443365097046\n",
      "MSE train 6.085038356397672 MSE test 12.59475014253598\n",
      "MAE train 1.7116602409128618 MAE test 2.4884754169227374\n",
      "Epoch 1007 / 10000 loss: 16.23382830619812\n",
      "MSE train 6.08487486369984 MSE test 12.594508742251211\n",
      "MAE train 1.7116352470338574 MAE test 2.4884466700787233\n",
      "Epoch 1008 / 10000 loss: 16.233152389526367\n",
      "MSE train 6.084698131388594 MSE test 12.594403919758161\n",
      "MAE train 1.7116061195860324 MAE test 2.4884394371134473\n",
      "Epoch 1009 / 10000 loss: 16.232544898986816\n",
      "MSE train 6.084534256691513 MSE test 12.594162365935894\n",
      "MAE train 1.7115809313430124 MAE test 2.4884106654843645\n",
      "Epoch 1010 / 10000 loss: 16.23186731338501\n",
      "MSE train 6.084357038445739 MSE test 12.59405737393784\n",
      "MAE train 1.7115515852616887 MAE test 2.4884034174054626\n",
      "Epoch 1011 / 10000 loss: 16.23125648498535\n",
      "MSE train 6.084192516206522 MSE test 12.593815874820738\n",
      "MAE train 1.7115261349003918 MAE test 2.488374660545529\n",
      "Epoch 1012 / 10000 loss: 16.230576515197754\n",
      "MSE train 6.08401456968747 MSE test 12.593710962701264\n",
      "MAE train 1.711496489774605 MAE test 2.4883674233664492\n",
      "Epoch 1013 / 10000 loss: 16.229964017868042\n",
      "MSE train 6.0838491910773564 MSE test 12.593469192501043\n",
      "MAE train 1.7114707016302024 MAE test 2.4883386378522716\n",
      "Epoch 1014 / 10000 loss: 16.229281902313232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.083670095850549 MSE test 12.593364099314615\n",
      "MAE train 1.7114406349309628 MAE test 2.4883313763789197\n",
      "Epoch 1015 / 10000 loss: 16.22866439819336\n",
      "MSE train 6.083503266654071 MSE test 12.59312233500519\n",
      "MAE train 1.7114143378561735 MAE test 2.4883025891793014\n",
      "Epoch 1016 / 10000 loss: 16.227976083755493\n",
      "MSE train 6.083322486476275 MSE test 12.593016940785798\n",
      "MAE train 1.7113836834051945 MAE test 2.488295303577226\n",
      "Epoch 1017 / 10000 loss: 16.227352380752563\n",
      "MSE train 6.083153425619687 MSE test 12.592774985278774\n",
      "MAE train 1.7113566619578804 MAE test 2.4882665084958684\n",
      "Epoch 1018 / 10000 loss: 16.226656198501587\n",
      "MSE train 6.082969610778626 MSE test 12.592669416149876\n",
      "MAE train 1.711325102250096 MAE test 2.488259200910057\n",
      "Epoch 1019 / 10000 loss: 16.226022720336914\n",
      "MSE train 6.082796428290678 MSE test 12.592427115008057\n",
      "MAE train 1.7112969287604047 MAE test 2.4882303573030766\n",
      "Epoch 1020 / 10000 loss: 16.225311279296875\n",
      "MSE train 6.082606990623989 MSE test 12.592321040021687\n",
      "MAE train 1.7112638693224849 MAE test 2.488222992571028\n",
      "Epoch 1021 / 10000 loss: 16.224657773971558\n",
      "MSE train 6.0824259867876345 MSE test 12.592078068571778\n",
      "MAE train 1.7112337454597013 MAE test 2.4881940801777196\n",
      "Epoch 1022 / 10000 loss: 16.223920345306396\n",
      "MSE train 6.082225356937708 MSE test 12.591971311932852\n",
      "MAE train 1.711198140358624 MAE test 2.488186652353066\n",
      "Epoch 1023 / 10000 loss: 16.223227739334106\n",
      "MSE train 6.082028621692055 MSE test 12.591727570582293\n",
      "MAE train 1.7111646575090695 MAE test 2.4881576540042\n",
      "Epoch 1024 / 10000 loss: 16.222435474395752\n",
      "MSE train 6.081806998743492 MSE test 12.591619637711128\n",
      "MAE train 1.7111249420863472 MAE test 2.488150102151057\n",
      "Epoch 1025 / 10000 loss: 16.22166609764099\n",
      "MSE train 6.081586566448502 MSE test 12.59137468834857\n",
      "MAE train 1.7110873302265206 MAE test 2.4881209740288406\n",
      "Epoch 1026 / 10000 loss: 16.22077226638794\n",
      "MSE train 6.081349511859293 MSE test 12.591265728847189\n",
      "MAE train 1.7110449168013133 MAE test 2.4881133353621028\n",
      "Epoch 1027 / 10000 loss: 16.21988534927368\n",
      "MSE train 6.081138838284063 MSE test 12.591020788133767\n",
      "MAE train 1.7110093697756865 MAE test 2.4880842255620492\n",
      "Epoch 1028 / 10000 loss: 16.218913078308105\n",
      "MSE train 6.08093730048595 MSE test 12.590913735359194\n",
      "MAE train 1.7109747728394302 MAE test 2.488076812314075\n",
      "Epoch 1029 / 10000 loss: 16.21807074546814\n",
      "MSE train 6.080764173437697 MSE test 12.590671878156607\n",
      "MAE train 1.7109478823993567 MAE test 2.4880480858174714\n",
      "Epoch 1030 / 10000 loss: 16.2172691822052\n",
      "MSE train 6.080584834680554 MSE test 12.590567472653106\n",
      "MAE train 1.7109188356995673 MAE test 2.4880409875055336\n",
      "Epoch 1031 / 10000 loss: 16.216611623764038\n",
      "MSE train 6.080421047580566 MSE test 12.5903269851729\n",
      "MAE train 1.710894697106884 MAE test 2.488012405215068\n",
      "Epoch 1032 / 10000 loss: 16.215919971466064\n",
      "MSE train 6.080245292246719 MSE test 12.590223475889518\n",
      "MAE train 1.7108669306225355 MAE test 2.4880053924722705\n",
      "Epoch 1033 / 10000 loss: 16.21530795097351\n",
      "MSE train 6.080083002109009 MSE test 12.589983636398188\n",
      "MAE train 1.7108434658680696 MAE test 2.4879768785937895\n",
      "Epoch 1034 / 10000 loss: 16.214633226394653\n",
      "MSE train 6.079907891538474 MSE test 12.589880357508608\n",
      "MAE train 1.7108160496727862 MAE test 2.4879699001708966\n",
      "Epoch 1035 / 10000 loss: 16.214028120040894\n",
      "MSE train 6.079745975866827 MSE test 12.589640709029142\n",
      "MAE train 1.7107927803869427 MAE test 2.4879413943809916\n",
      "Epoch 1036 / 10000 loss: 16.2133572101593\n",
      "MSE train 6.079571054322931 MSE test 12.589537526424161\n",
      "MAE train 1.7107654703004525 MAE test 2.487934414614224\n",
      "Epoch 1037 / 10000 loss: 16.212754011154175\n",
      "MSE train 6.079409296219902 MSE test 12.589297885911106\n",
      "MAE train 1.7107422573016968 MAE test 2.4879059125844587\n",
      "Epoch 1038 / 10000 loss: 16.21208167076111\n",
      "MSE train 6.079234467063852 MSE test 12.589194798648904\n",
      "MAE train 1.7107149699061492 MAE test 2.487898931822555\n",
      "Epoch 1039 / 10000 loss: 16.21147871017456\n",
      "MSE train 6.079072838109387 MSE test 12.588955139865103\n",
      "MAE train 1.7106917789042229 MAE test 2.4878704356088273\n",
      "Epoch 1040 / 10000 loss: 16.21080708503723\n",
      "MSE train 6.078898048656671 MSE test 12.588851955320699\n",
      "MAE train 1.7106644928279244 MAE test 2.4878634453794533\n",
      "Epoch 1041 / 10000 loss: 16.210204601287842\n",
      "MSE train 6.078736474100453 MSE test 12.58861234333969\n",
      "MAE train 1.7106412948986165 MAE test 2.4878349356489387\n",
      "Epoch 1042 / 10000 loss: 16.209534168243408\n",
      "MSE train 6.078561712991485 MSE test 12.588509181928279\n",
      "MAE train 1.7106139930970308 MAE test 2.487827944781511\n",
      "Epoch 1043 / 10000 loss: 16.20893144607544\n",
      "MSE train 6.078400037110096 MSE test 12.588269648899972\n",
      "MAE train 1.7105907617549911 MAE test 2.4877994527692713\n",
      "Epoch 1044 / 10000 loss: 16.208259344100952\n",
      "MSE train 6.078225387955619 MSE test 12.588166404907424\n",
      "MAE train 1.710563459579917 MAE test 2.4877924466786765\n",
      "Epoch 1045 / 10000 loss: 16.20765709877014\n",
      "MSE train 6.078063821973664 MSE test 12.587926780282517\n",
      "MAE train 1.7105402298404524 MAE test 2.4877639239022766\n",
      "Epoch 1046 / 10000 loss: 16.206985235214233\n",
      "MSE train 6.0778891168439575 MSE test 12.587823443511917\n",
      "MAE train 1.7105128975522181 MAE test 2.4877569068632517\n",
      "Epoch 1047 / 10000 loss: 16.206382274627686\n",
      "MSE train 6.077727512084819 MSE test 12.587583864181877\n",
      "MAE train 1.7104896406821435 MAE test 2.487728386468556\n",
      "Epoch 1048 / 10000 loss: 16.205710649490356\n",
      "MSE train 6.077552872387259 MSE test 12.587480617817816\n",
      "MAE train 1.7104623045004324 MAE test 2.4877213823964186\n",
      "Epoch 1049 / 10000 loss: 16.205108165740967\n",
      "MSE train 6.077391275510203 MSE test 12.587240911862377\n",
      "MAE train 1.7104390373812226 MAE test 2.4876928484732335\n",
      "Epoch 1050 / 10000 loss: 16.20443606376648\n",
      "MSE train 6.077216624134949 MSE test 12.587137616393022\n",
      "MAE train 1.710411680980295 MAE test 2.487685826272517\n",
      "Epoch 1051 / 10000 loss: 16.20383310317993\n",
      "MSE train 6.077055027735821 MSE test 12.586898049232172\n",
      "MAE train 1.7103884017836926 MAE test 2.4876573077363537\n",
      "Epoch 1052 / 10000 loss: 16.203163146972656\n",
      "MSE train 6.076880380631844 MSE test 12.586794799193632\n",
      "MAE train 1.7103610332285548 MAE test 2.487650303500113\n",
      "Epoch 1053 / 10000 loss: 16.20255994796753\n",
      "MSE train 6.076718862043648 MSE test 12.586555066392693\n",
      "MAE train 1.7103377501457218 MAE test 2.4876217610612765\n",
      "Epoch 1054 / 10000 loss: 16.20188879966736\n",
      "MSE train 6.076544271172442 MSE test 12.586451691784486\n",
      "MAE train 1.7103103784788214 MAE test 2.487614723059145\n",
      "Epoch 1055 / 10000 loss: 16.20128560066223\n",
      "MSE train 6.076382698393434 MSE test 12.586212251747272\n",
      "MAE train 1.7102870801044805 MAE test 2.487586232369151\n",
      "Epoch 1056 / 10000 loss: 16.20061469078064\n",
      "MSE train 6.076208203724655 MSE test 12.586108758376772\n",
      "MAE train 1.7102597178570766 MAE test 2.4875791806538476\n",
      "Epoch 1057 / 10000 loss: 16.20001196861267\n",
      "MSE train 6.076046722245118 MSE test 12.58586931403771\n",
      "MAE train 1.7102364259563048 MAE test 2.4875506696599023\n",
      "Epoch 1058 / 10000 loss: 16.1993408203125\n",
      "MSE train 6.075872220927669 MSE test 12.585765968302308\n",
      "MAE train 1.7102090500749019 MAE test 2.487543645510961\n",
      "Epoch 1059 / 10000 loss: 16.19873833656311\n",
      "MSE train 6.07571081966312 MSE test 12.585526353486555\n",
      "MAE train 1.7101857657317079 MAE test 2.487515115780697\n",
      "Epoch 1060 / 10000 loss: 16.198068141937256\n",
      "MSE train 6.075536368381185 MSE test 12.585423184830288\n",
      "MAE train 1.710158382799756 MAE test 2.4875081225789275\n",
      "Epoch 1061 / 10000 loss: 16.19746494293213\n",
      "MSE train 6.075375061311092 MSE test 12.585183518936056\n",
      "MAE train 1.7101351016881687 MAE test 2.4874795775782785\n",
      "Epoch 1062 / 10000 loss: 16.19679546356201\n",
      "MSE train 6.075200646144125 MSE test 12.585080016728238\n",
      "MAE train 1.710107719740776 MAE test 2.4874725223972196\n",
      "Epoch 1063 / 10000 loss: 16.1961932182312\n",
      "MSE train 6.075039434157201 MSE test 12.58484076593913\n",
      "MAE train 1.7100844482761381 MAE test 2.4874440319322146\n",
      "Epoch 1064 / 10000 loss: 16.195523262023926\n",
      "MSE train 6.074865122189841 MSE test 12.584737271465258\n",
      "MAE train 1.7100570766329604 MAE test 2.4874369891904227\n",
      "Epoch 1065 / 10000 loss: 16.19492197036743\n",
      "MSE train 6.074703982254984 MSE test 12.58449775263581\n",
      "MAE train 1.7100338193044675 MAE test 2.4874084732749555\n",
      "Epoch 1066 / 10000 loss: 16.194252729415894\n",
      "MSE train 6.074529841271535 MSE test 12.584394366769706\n",
      "MAE train 1.7100064663101104 MAE test 2.4874014424215187\n",
      "Epoch 1067 / 10000 loss: 16.193650722503662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.074368843928663 MSE test 12.584154975445673\n",
      "MAE train 1.7099832214833353 MAE test 2.487372937121185\n",
      "Epoch 1068 / 10000 loss: 16.1929829120636\n",
      "MSE train 6.074194739457341 MSE test 12.584051625654626\n",
      "MAE train 1.7099558595793132 MAE test 2.487365909069367\n",
      "Epoch 1069 / 10000 loss: 16.192381143569946\n",
      "MSE train 6.074033867365194 MSE test 12.583812032183754\n",
      "MAE train 1.70993261815164 MAE test 2.487337376573001\n",
      "Epoch 1070 / 10000 loss: 16.19171380996704\n",
      "MSE train 6.073859887483958 MSE test 12.583708691809713\n",
      "MAE train 1.7099052609818852 MAE test 2.487330346148184\n",
      "Epoch 1071 / 10000 loss: 16.1911141872406\n",
      "MSE train 6.073699071939738 MSE test 12.583469193929911\n",
      "MAE train 1.7098820184950554 MAE test 2.487301821497337\n",
      "Epoch 1072 / 10000 loss: 16.19044518470764\n",
      "MSE train 6.073525268250664 MSE test 12.583366029159423\n",
      "MAE train 1.7098546735786695 MAE test 2.4872948090825058\n",
      "Epoch 1073 / 10000 loss: 16.18984580039978\n",
      "MSE train 6.073364608909163 MSE test 12.583126470955671\n",
      "MAE train 1.7098314472993104 MAE test 2.4872662899644986\n",
      "Epoch 1074 / 10000 loss: 16.189178466796875\n",
      "MSE train 6.073190839246873 MSE test 12.58302312017073\n",
      "MAE train 1.7098041001866435 MAE test 2.487259253505443\n",
      "Epoch 1075 / 10000 loss: 16.18857979774475\n",
      "MSE train 6.073030300953869 MSE test 12.582783627762907\n",
      "MAE train 1.7097808903564151 MAE test 2.4872307302363343\n",
      "Epoch 1076 / 10000 loss: 16.187912940979004\n",
      "MSE train 6.072856658131625 MSE test 12.58268045909382\n",
      "MAE train 1.7097535529775434 MAE test 2.487223720386217\n",
      "Epoch 1077 / 10000 loss: 16.18731379508972\n",
      "MSE train 6.072696215207801 MSE test 12.582440904295586\n",
      "MAE train 1.709730349133096 MAE test 2.4871951822452716\n",
      "Epoch 1078 / 10000 loss: 16.186647653579712\n",
      "MSE train 6.072522587766983 MSE test 12.582337561544279\n",
      "MAE train 1.7097030056000004 MAE test 2.487188149638966\n",
      "Epoch 1079 / 10000 loss: 16.186050176620483\n",
      "MSE train 6.072362227010527 MSE test 12.582098167635847\n",
      "MAE train 1.7096798134543396 MAE test 2.4871596333967716\n",
      "Epoch 1080 / 10000 loss: 16.185383558273315\n",
      "MSE train 6.0721887340290355 MSE test 12.581994800749133\n",
      "MAE train 1.7096524748273543 MAE test 2.4871525922805215\n",
      "Epoch 1081 / 10000 loss: 16.184785842895508\n",
      "MSE train 6.072028380573515 MSE test 12.581755413395648\n",
      "MAE train 1.709629274906271 MAE test 2.4871240839719837\n",
      "Epoch 1082 / 10000 loss: 16.18412160873413\n",
      "MSE train 6.071854999027882 MSE test 12.581652088008425\n",
      "MAE train 1.7096019369062943 MAE test 2.4871170490199845\n",
      "Epoch 1083 / 10000 loss: 16.183523416519165\n",
      "MSE train 6.071694708147206 MSE test 12.581412647640173\n",
      "MAE train 1.7095787403105158 MAE test 2.487088520695687\n",
      "Epoch 1084 / 10000 loss: 16.182859182357788\n",
      "MSE train 6.071521330092777 MSE test 12.581309321385968\n",
      "MAE train 1.70955139143273 MAE test 2.487081473732601\n",
      "Epoch 1085 / 10000 loss: 16.182262420654297\n",
      "MSE train 6.071361097823709 MSE test 12.581069885392631\n",
      "MAE train 1.709528193169516 MAE test 2.4870529526584115\n",
      "Epoch 1086 / 10000 loss: 16.181597232818604\n",
      "MSE train 6.0711877638486165 MSE test 12.580966531457893\n",
      "MAE train 1.7095008405000793 MAE test 2.4870459138036627\n",
      "Epoch 1087 / 10000 loss: 16.181000232696533\n",
      "MSE train 6.071027610710847 MSE test 12.580727141718375\n",
      "MAE train 1.7094776473444364 MAE test 2.4870173884589595\n",
      "Epoch 1088 / 10000 loss: 16.180335760116577\n",
      "MSE train 6.070854291665163 MSE test 12.580623707913729\n",
      "MAE train 1.7094502878398186 MAE test 2.4870103300289776\n",
      "Epoch 1089 / 10000 loss: 16.179738998413086\n",
      "MSE train 6.070694191331415 MSE test 12.580384389140079\n",
      "MAE train 1.7094270862096859 MAE test 2.486981812855715\n",
      "Epoch 1090 / 10000 loss: 16.179075479507446\n",
      "MSE train 6.070520934688502 MSE test 12.580280916762245\n",
      "MAE train 1.7093997304393527 MAE test 2.4869747566554237\n",
      "Epoch 1091 / 10000 loss: 16.178479194641113\n",
      "MSE train 6.070360868155338 MSE test 12.580041547969529\n",
      "MAE train 1.7093765282927538 MAE test 2.4869462357254575\n",
      "Epoch 1092 / 10000 loss: 16.177815198898315\n",
      "MSE train 6.070187550607346 MSE test 12.579938282285049\n",
      "MAE train 1.7093491466835178 MAE test 2.486939197466714\n",
      "Epoch 1093 / 10000 loss: 16.177218675613403\n",
      "MSE train 6.070027488328851 MSE test 12.579698825042588\n",
      "MAE train 1.709325943531488 MAE test 2.4869106587751753\n",
      "Epoch 1094 / 10000 loss: 16.176554918289185\n",
      "MSE train 6.069854261361597 MSE test 12.579595505484741\n",
      "MAE train 1.709298567654231 MAE test 2.486903613574192\n",
      "Epoch 1095 / 10000 loss: 16.17595887184143\n",
      "MSE train 6.069694172511878 MSE test 12.579356090732263\n",
      "MAE train 1.709275357459264 MAE test 2.486875070500786\n",
      "Epoch 1096 / 10000 loss: 16.17529559135437\n",
      "MSE train 6.069520998957184 MSE test 12.579252625602667\n",
      "MAE train 1.7092479849027666 MAE test 2.486868013652235\n",
      "Epoch 1097 / 10000 loss: 16.174699068069458\n",
      "MSE train 6.069360927443683 MSE test 12.579013296870574\n",
      "MAE train 1.7092247677892123 MAE test 2.486839493425572\n",
      "Epoch 1098 / 10000 loss: 16.17403531074524\n",
      "MSE train 6.069187715901017 MSE test 12.578909804375602\n",
      "MAE train 1.7091973806366905 MAE test 2.4868324143908977\n",
      "Epoch 1099 / 10000 loss: 16.173439979553223\n",
      "MSE train 6.069027701395085 MSE test 12.578670465960135\n",
      "MAE train 1.709174167638401 MAE test 2.4868038868484583\n",
      "Epoch 1100 / 10000 loss: 16.172776222229004\n",
      "MSE train 6.068854450671271 MSE test 12.578567208684325\n",
      "MAE train 1.709146769993391 MAE test 2.4867968590472733\n",
      "Epoch 1101 / 10000 loss: 16.172180891036987\n",
      "MSE train 6.068694469113393 MSE test 12.578327653916135\n",
      "MAE train 1.709123556551743 MAE test 2.4867682876908814\n",
      "Epoch 1102 / 10000 loss: 16.17151927947998\n",
      "MSE train 6.068521224458433 MSE test 12.57822417635464\n",
      "MAE train 1.7090961513015681 MAE test 2.486761220555234\n",
      "Epoch 1103 / 10000 loss: 16.170922994613647\n",
      "MSE train 6.068361156807565 MSE test 12.577984917198961\n",
      "MAE train 1.709072932350931 MAE test 2.48673270210955\n",
      "Epoch 1104 / 10000 loss: 16.170259952545166\n",
      "MSE train 6.068188060224969 MSE test 12.57788146128235\n",
      "MAE train 1.709045532220256 MAE test 2.486725634394885\n",
      "Epoch 1105 / 10000 loss: 16.169663906097412\n",
      "MSE train 6.06802807591792 MSE test 12.577642102013987\n",
      "MAE train 1.7090223179981738 MAE test 2.4866970884620314\n",
      "Epoch 1106 / 10000 loss: 16.16900062561035\n",
      "MSE train 6.067854905178648 MSE test 12.577538616055408\n",
      "MAE train 1.7089949062581637 MAE test 2.486690010288345\n",
      "Epoch 1107 / 10000 loss: 16.16840624809265\n",
      "MSE train 6.067694923278464 MSE test 12.577299284087585\n",
      "MAE train 1.7089716864847986 MAE test 2.4866614810373324\n",
      "Epoch 1108 / 10000 loss: 16.16774272918701\n",
      "MSE train 6.067521759527723 MSE test 12.57719584271761\n",
      "MAE train 1.7089442739429486 MAE test 2.48665441861182\n",
      "Epoch 1109 / 10000 loss: 16.167146921157837\n",
      "MSE train 6.067361803974513 MSE test 12.576956424400908\n",
      "MAE train 1.7089210571221745 MAE test 2.486625856820566\n",
      "Epoch 1110 / 10000 loss: 16.166484355926514\n",
      "MSE train 6.067188617876819 MSE test 12.576852991202266\n",
      "MAE train 1.7088936315476946 MAE test 2.486618797017031\n",
      "Epoch 1111 / 10000 loss: 16.165889501571655\n",
      "MSE train 6.067028678047525 MSE test 12.576613759216723\n",
      "MAE train 1.7088704166149462 MAE test 2.486590265280706\n",
      "Epoch 1112 / 10000 loss: 16.16522717475891\n",
      "MSE train 6.066855507947333 MSE test 12.57651024329105\n",
      "MAE train 1.7088429892780195 MAE test 2.486583186437098\n",
      "Epoch 1113 / 10000 loss: 16.164631128311157\n",
      "MSE train 6.066695596520924 MSE test 12.576270924615745\n",
      "MAE train 1.708819773096619 MAE test 2.4865546438999675\n",
      "Epoch 1114 / 10000 loss: 16.163968801498413\n",
      "MSE train 6.0665224271155935 MSE test 12.576167392971916\n",
      "MAE train 1.7087923423446083 MAE test 2.486547569888615\n",
      "Epoch 1115 / 10000 loss: 16.163374423980713\n",
      "MSE train 6.066362494220972 MSE test 12.575928060137072\n",
      "MAE train 1.7087691227227597 MAE test 2.486519012618606\n",
      "Epoch 1116 / 10000 loss: 16.16271138191223\n",
      "MSE train 6.066189386327177 MSE test 12.575824618660562\n",
      "MAE train 1.7087416915235751 MAE test 2.4865119594571934\n",
      "Epoch 1117 / 10000 loss: 16.16211700439453\n",
      "MSE train 6.066029469428447 MSE test 12.575585433847687\n",
      "MAE train 1.7087184748218274 MAE test 2.486483416202275\n",
      "Epoch 1118 / 10000 loss: 16.16145420074463\n",
      "MSE train 6.065856350847015 MSE test 12.575481874895901\n",
      "MAE train 1.7086910344808472 MAE test 2.4864763437680737\n",
      "Epoch 1119 / 10000 loss: 16.160860538482666\n",
      "MSE train 6.065696458699701 MSE test 12.575242711151615\n",
      "MAE train 1.708667820574354 MAE test 2.486447807923572\n",
      "Epoch 1120 / 10000 loss: 16.160197019577026\n",
      "MSE train 6.0655233209325665 MSE test 12.575139238430236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7086403758561672 MAE test 2.486440729537577\n",
      "Epoch 1121 / 10000 loss: 16.159602880477905\n",
      "MSE train 6.06536342409405 MSE test 12.574899973430547\n",
      "MAE train 1.708617160323653 MAE test 2.4864121851357295\n",
      "Epoch 1122 / 10000 loss: 16.158939361572266\n",
      "MSE train 6.06519032216281 MSE test 12.574796412104682\n",
      "MAE train 1.7085897132007803 MAE test 2.486405111965626\n",
      "Epoch 1123 / 10000 loss: 16.158345460891724\n",
      "MSE train 6.06503043543043 MSE test 12.574557340114872\n",
      "MAE train 1.7085664953302082 MAE test 2.48637658628612\n",
      "Epoch 1124 / 10000 loss: 16.15768313407898\n",
      "MSE train 6.064857397340782 MSE test 12.574453820562242\n",
      "MAE train 1.7085390504653886 MAE test 2.486369501415449\n",
      "Epoch 1125 / 10000 loss: 16.157089471817017\n",
      "MSE train 6.064697505039585 MSE test 12.574214621879028\n",
      "MAE train 1.7085158329044778 MAE test 2.4863409641713834\n",
      "Epoch 1126 / 10000 loss: 16.156425952911377\n",
      "MSE train 6.06452444487092 MSE test 12.574111057088949\n",
      "MAE train 1.70848838376781 MAE test 2.486333885570953\n",
      "Epoch 1127 / 10000 loss: 16.155832290649414\n",
      "MSE train 6.064364564723234 MSE test 12.573871910951848\n",
      "MAE train 1.7084651657240637 MAE test 2.486305338492589\n",
      "Epoch 1128 / 10000 loss: 16.15516972541809\n",
      "MSE train 6.064191498522544 MSE test 12.573768491586765\n",
      "MAE train 1.708437713475542 MAE test 2.486298277108371\n",
      "Epoch 1129 / 10000 loss: 16.154576063156128\n",
      "MSE train 6.064031616586799 MSE test 12.573529215533009\n",
      "MAE train 1.708414494240888 MAE test 2.4862697262346165\n",
      "Epoch 1130 / 10000 loss: 16.153913259506226\n",
      "MSE train 6.063858650335776 MSE test 12.573425814695907\n",
      "MAE train 1.708387048283176 MAE test 2.486262657925987\n",
      "Epoch 1131 / 10000 loss: 16.153319120407104\n",
      "MSE train 6.063698800215668 MSE test 12.573186681892606\n",
      "MAE train 1.7083638334618259 MAE test 2.486234112912736\n",
      "Epoch 1132 / 10000 loss: 16.15265679359436\n",
      "MSE train 6.063525739095307 MSE test 12.573083365185756\n",
      "MAE train 1.7083363695665896 MAE test 2.4862270789294136\n",
      "Epoch 1133 / 10000 loss: 16.152063369750977\n",
      "MSE train 6.063365946539092 MSE test 12.572844112243029\n",
      "MAE train 1.7083131633294966 MAE test 2.4861985030991107\n",
      "Epoch 1134 / 10000 loss: 16.15140175819397\n",
      "MSE train 6.063192954556453 MSE test 12.572740623588555\n",
      "MAE train 1.7082857012806258 MAE test 2.486191442786742\n",
      "Epoch 1135 / 10000 loss: 16.15080761909485\n",
      "MSE train 6.063033127371053 MSE test 12.572501628550501\n",
      "MAE train 1.708262494234653 MAE test 2.4861629033365995\n",
      "Epoch 1136 / 10000 loss: 16.150145053863525\n",
      "MSE train 6.062860126411587 MSE test 12.572398073133703\n",
      "MAE train 1.7082350257079508 MAE test 2.486155829653752\n",
      "Epoch 1137 / 10000 loss: 16.149551153182983\n",
      "MSE train 6.062700350768982 MSE test 12.572158976540399\n",
      "MAE train 1.708211822621543 MAE test 2.486127278830898\n",
      "Epoch 1138 / 10000 loss: 16.148889541625977\n",
      "MSE train 6.062527347864851 MSE test 12.572055449927678\n",
      "MAE train 1.708184352474221 MAE test 2.486120208905532\n",
      "Epoch 1139 / 10000 loss: 16.148295402526855\n",
      "MSE train 6.062367589529418 MSE test 12.5718164714163\n",
      "MAE train 1.7081611504598693 MAE test 2.4860916777252617\n",
      "Epoch 1140 / 10000 loss: 16.147634029388428\n",
      "MSE train 6.0621946379456535 MSE test 12.571713032988212\n",
      "MAE train 1.7081336782821699 MAE test 2.4860846108371923\n",
      "Epoch 1141 / 10000 loss: 16.14703941345215\n",
      "MSE train 6.062034829282112 MSE test 12.571473902257985\n",
      "MAE train 1.708110473720148 MAE test 2.486056059698643\n",
      "Epoch 1142 / 10000 loss: 16.146378755569458\n",
      "MSE train 6.061861934959501 MSE test 12.571370358768982\n",
      "MAE train 1.7080830070587822 MAE test 2.486048989647698\n",
      "Epoch 1143 / 10000 loss: 16.145785570144653\n",
      "MSE train 6.0617021981423544 MSE test 12.571131368340032\n",
      "MAE train 1.7080598131796298 MAE test 2.4860204466647535\n",
      "Epoch 1144 / 10000 loss: 16.14512324333191\n",
      "MSE train 6.06152919478637 MSE test 12.571027985394439\n",
      "MAE train 1.7080323250663954 MAE test 2.4860133982353894\n",
      "Epoch 1145 / 10000 loss: 16.144529104232788\n",
      "MSE train 6.061369504688343 MSE test 12.570788978625338\n",
      "MAE train 1.7080091324317148 MAE test 2.485984848334206\n",
      "Epoch 1146 / 10000 loss: 16.14386820793152\n",
      "MSE train 6.061196544339579 MSE test 12.570685562552589\n",
      "MAE train 1.7079816507681016 MAE test 2.4859777990817546\n",
      "Epoch 1147 / 10000 loss: 16.143274307250977\n",
      "MSE train 6.061036874535701 MSE test 12.570446623194766\n",
      "MAE train 1.7079584621345132 MAE test 2.485949261515465\n",
      "Epoch 1148 / 10000 loss: 16.142613649368286\n",
      "MSE train 6.060863927821954 MSE test 12.570343067523227\n",
      "MAE train 1.707930977042987 MAE test 2.4859421845464746\n",
      "Epoch 1149 / 10000 loss: 16.142019271850586\n",
      "MSE train 6.060704255401132 MSE test 12.57010408175671\n",
      "MAE train 1.707907793424547 MAE test 2.485913630153545\n",
      "Epoch 1150 / 10000 loss: 16.141357898712158\n",
      "MSE train 6.060531320299364 MSE test 12.570000649676839\n",
      "MAE train 1.707880300506355 MAE test 2.4859065795902286\n",
      "Epoch 1151 / 10000 loss: 16.140764713287354\n",
      "MSE train 6.060371630013631 MSE test 12.569761707130995\n",
      "MAE train 1.7078571135453455 MAE test 2.485878035871811\n",
      "Epoch 1152 / 10000 loss: 16.140103578567505\n",
      "MSE train 6.060198756414644 MSE test 12.56965832195723\n",
      "MAE train 1.707829628406284 MAE test 2.485870978042905\n",
      "Epoch 1153 / 10000 loss: 16.13951086997986\n",
      "MSE train 6.060039103774045 MSE test 12.56941928355423\n",
      "MAE train 1.7078064419806818 MAE test 2.485842431191768\n",
      "Epoch 1154 / 10000 loss: 16.138849020004272\n",
      "MSE train 6.059866241482192 MSE test 12.56931585919783\n",
      "MAE train 1.7077789581276075 MAE test 2.48583536863053\n",
      "Epoch 1155 / 10000 loss: 16.138255834579468\n",
      "MSE train 6.059706601921836 MSE test 12.569077049590437\n",
      "MAE train 1.7077557736768973 MAE test 2.485806847264263\n",
      "Epoch 1156 / 10000 loss: 16.1375949382782\n",
      "MSE train 6.059533764335757 MSE test 12.568973557215129\n",
      "MAE train 1.7077282859876686 MAE test 2.4857997830653105\n",
      "Epoch 1157 / 10000 loss: 16.137001991271973\n",
      "MSE train 6.059374129162152 MSE test 12.568734650436037\n",
      "MAE train 1.707705103104897 MAE test 2.4857712448531544\n",
      "Epoch 1158 / 10000 loss: 16.136341333389282\n",
      "MSE train 6.059201228055646 MSE test 12.568631143927218\n",
      "MAE train 1.7076776031205425 MAE test 2.485764173977305\n",
      "Epoch 1159 / 10000 loss: 16.13574743270874\n",
      "MSE train 6.059041654966041 MSE test 12.568392315615878\n",
      "MAE train 1.7076544328728898 MAE test 2.4857356435271676\n",
      "Epoch 1160 / 10000 loss: 16.135087251663208\n",
      "MSE train 6.058868866103266 MSE test 12.568288886084336\n",
      "MAE train 1.7076269404982505 MAE test 2.4857285831362907\n",
      "Epoch 1161 / 10000 loss: 16.134493350982666\n",
      "MSE train 6.058709235242859 MSE test 12.568050069377666\n",
      "MAE train 1.7076037574217142 MAE test 2.4857000535145763\n",
      "Epoch 1162 / 10000 loss: 16.133832693099976\n",
      "MSE train 6.058536443780848 MSE test 12.567946524743975\n",
      "MAE train 1.7075762643894907 MAE test 2.48569298063426\n",
      "Epoch 1163 / 10000 loss: 16.13323950767517\n",
      "MSE train 6.058376848431288 MSE test 12.567707771018068\n",
      "MAE train 1.7075530929358318 MAE test 2.485664463662553\n",
      "Epoch 1164 / 10000 loss: 16.13257908821106\n",
      "MSE train 6.058204049775528 MSE test 12.567604407407394\n",
      "MAE train 1.7075255886473675 MAE test 2.485657403232775\n",
      "Epoch 1165 / 10000 loss: 16.13198733329773\n",
      "MSE train 6.058044426986908 MSE test 12.567365551091441\n",
      "MAE train 1.7075024148079778 MAE test 2.485628871696738\n",
      "Epoch 1166 / 10000 loss: 16.131325483322144\n",
      "MSE train 6.057871680182776 MSE test 12.567262112767105\n",
      "MAE train 1.707474917355566 MAE test 2.485621804448088\n",
      "Epoch 1167 / 10000 loss: 16.130733013153076\n",
      "MSE train 6.057712158920104 MSE test 12.567023429276187\n",
      "MAE train 1.7074517540255592 MAE test 2.4855932993374505\n",
      "Epoch 1168 / 10000 loss: 16.130072116851807\n",
      "MSE train 6.0575393743401476 MSE test 12.56692006436234\n",
      "MAE train 1.7074242473082804 MAE test 2.4855862372942354\n",
      "Epoch 1169 / 10000 loss: 16.12947964668274\n",
      "MSE train 6.057379889119915 MSE test 12.566681185503828\n",
      "MAE train 1.7074010910682762 MAE test 2.485557694140106\n",
      "Epoch 1170 / 10000 loss: 16.128819704055786\n",
      "MSE train 6.057207107450535 MSE test 12.5665777346654\n",
      "MAE train 1.707373581894922 MAE test 2.4855506349328333\n",
      "Epoch 1171 / 10000 loss: 16.128226041793823\n",
      "MSE train 6.057047649035583 MSE test 12.566339138319352\n",
      "MAE train 1.7073504251988765 MAE test 2.4855221281784954\n",
      "Epoch 1172 / 10000 loss: 16.12756609916687\n",
      "MSE train 6.056874934132614 MSE test 12.566235727539596\n",
      "MAE train 1.7073229223520077 MAE test 2.4855150667599255\n",
      "Epoch 1173 / 10000 loss: 16.126973867416382\n",
      "MSE train 6.056715420957096 MSE test 12.565996932806012\n",
      "MAE train 1.7072997655596986 MAE test 2.485486537985272\n",
      "Epoch 1174 / 10000 loss: 16.12631392478943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.056542693410387 MSE test 12.565893498442826\n",
      "MAE train 1.7072722539300516 MAE test 2.4854794785448746\n",
      "Epoch 1175 / 10000 loss: 16.125720024108887\n",
      "MSE train 6.05638318914012 MSE test 12.565654894588485\n",
      "MAE train 1.707249098965714 MAE test 2.4854509603088224\n",
      "Epoch 1176 / 10000 loss: 16.125060081481934\n",
      "MSE train 6.056210470992575 MSE test 12.565551404819335\n",
      "MAE train 1.7072215853145891 MAE test 2.4854438971083463\n",
      "Epoch 1177 / 10000 loss: 16.124467611312866\n",
      "MSE train 6.056051031725512 MSE test 12.565312716067723\n",
      "MAE train 1.707198435356925 MAE test 2.4854153759783837\n",
      "Epoch 1178 / 10000 loss: 16.123807668685913\n",
      "MSE train 6.055878350732262 MSE test 12.565209362832\n",
      "MAE train 1.7071709265269612 MAE test 2.4854083255002544\n",
      "Epoch 1179 / 10000 loss: 16.123215436935425\n",
      "MSE train 6.055718927106226 MSE test 12.56497064137573\n",
      "MAE train 1.7071477809334001 MAE test 2.485379786397748\n",
      "Epoch 1180 / 10000 loss: 16.122555017471313\n",
      "MSE train 6.055546232485108 MSE test 12.564867166609115\n",
      "MAE train 1.7071202653549788 MAE test 2.4853727234013254\n",
      "Epoch 1181 / 10000 loss: 16.121962547302246\n",
      "MSE train 6.0553868035347165 MSE test 12.564628533601809\n",
      "MAE train 1.7070971237076071 MAE test 2.485344200354486\n",
      "Epoch 1182 / 10000 loss: 16.121301651000977\n",
      "MSE train 6.05521414841501 MSE test 12.564525262395076\n",
      "MAE train 1.707069605757404 MAE test 2.4853371661199137\n",
      "Epoch 1183 / 10000 loss: 16.120710372924805\n",
      "MSE train 6.0550547740483 MSE test 12.564286519131871\n",
      "MAE train 1.7070464683658653 MAE test 2.485308625711979\n",
      "Epoch 1184 / 10000 loss: 16.120050191879272\n",
      "MSE train 6.0548820752514 MSE test 12.564183238877884\n",
      "MAE train 1.707018945954119 MAE test 2.4853015830572294\n",
      "Epoch 1185 / 10000 loss: 16.119458436965942\n",
      "MSE train 6.054722710731882 MSE test 12.563944555956775\n",
      "MAE train 1.706995808241738 MAE test 2.485273049805762\n",
      "Epoch 1186 / 10000 loss: 16.11879825592041\n",
      "MSE train 6.054550109457691 MSE test 12.563841028347381\n",
      "MAE train 1.7069682981591732 MAE test 2.485265977947257\n",
      "Epoch 1187 / 10000 loss: 16.1182062625885\n",
      "MSE train 6.054390708111432 MSE test 12.563602610691701\n",
      "MAE train 1.7069451538538112 MAE test 2.4852374768189676\n",
      "Epoch 1188 / 10000 loss: 16.117547035217285\n",
      "MSE train 6.0542181211421395 MSE test 12.563499086181928\n",
      "MAE train 1.706917640553458 MAE test 2.4852304063323194\n",
      "Epoch 1189 / 10000 loss: 16.116955041885376\n",
      "MSE train 6.0540587507322075 MSE test 12.563260433967953\n",
      "MAE train 1.7068945066825998 MAE test 2.48520186872947\n",
      "Epoch 1190 / 10000 loss: 16.116295337677002\n",
      "MSE train 6.053886131695905 MSE test 12.56315710710708\n",
      "MAE train 1.7068669808303318 MAE test 2.4851948275762257\n",
      "Epoch 1191 / 10000 loss: 16.115703105926514\n",
      "MSE train 6.053726804854771 MSE test 12.562918564248633\n",
      "MAE train 1.7068438503490921 MAE test 2.4851662919424617\n",
      "Epoch 1192 / 10000 loss: 16.11504316329956\n",
      "MSE train 6.0535542149456285 MSE test 12.562815224503398\n",
      "MAE train 1.7068163284668674 MAE test 2.4851592631847885\n",
      "Epoch 1193 / 10000 loss: 16.114450931549072\n",
      "MSE train 6.053394926809864 MSE test 12.562576741431585\n",
      "MAE train 1.706793208854428 MAE test 2.4851307491759314\n",
      "Epoch 1194 / 10000 loss: 16.113791942596436\n",
      "MSE train 6.053222398297599 MSE test 12.562473307142001\n",
      "MAE train 1.7067656955350843 MAE test 2.485123679140586\n",
      "Epoch 1195 / 10000 loss: 16.113200902938843\n",
      "MSE train 6.053063059998125 MSE test 12.5622348265151\n",
      "MAE train 1.706742562996539 MAE test 2.4850951699645036\n",
      "Epoch 1196 / 10000 loss: 16.11254072189331\n",
      "MSE train 6.052890511361371 MSE test 12.562131413398376\n",
      "MAE train 1.706715040523387 MAE test 2.485088109103965\n",
      "Epoch 1197 / 10000 loss: 16.11194920539856\n",
      "MSE train 6.052731238373817 MSE test 12.561892767998053\n",
      "MAE train 1.7066919156905036 MAE test 2.4850595708274956\n",
      "Epoch 1198 / 10000 loss: 16.111289262771606\n",
      "MSE train 6.05255868955544 MSE test 12.56178945533473\n",
      "MAE train 1.7066643928929253 MAE test 2.4850525356035633\n",
      "Epoch 1199 / 10000 loss: 16.110697507858276\n",
      "MSE train 6.052399392310945 MSE test 12.5615510402664\n",
      "MAE train 1.7066412692763144 MAE test 2.4850240196183346\n",
      "Epoch 1200 / 10000 loss: 16.11003828048706\n",
      "MSE train 6.052226940427778 MSE test 12.561447650684597\n",
      "MAE train 1.7066137516021638 MAE test 2.485016964311512\n",
      "Epoch 1201 / 10000 loss: 16.10944652557373\n",
      "MSE train 6.0520676924162435 MSE test 12.561209131523713\n",
      "MAE train 1.7065906307316439 MAE test 2.48498843938671\n",
      "Epoch 1202 / 10000 loss: 16.108787298202515\n",
      "MSE train 6.051895152295758 MSE test 12.561105726767453\n",
      "MAE train 1.706563104831064 MAE test 2.4849813896576953\n",
      "Epoch 1203 / 10000 loss: 16.1081964969635\n",
      "MSE train 6.051735950718838 MSE test 12.560867500324623\n",
      "MAE train 1.7065399954841984 MAE test 2.4849529013017095\n",
      "Epoch 1204 / 10000 loss: 16.107537269592285\n",
      "MSE train 6.051563450508085 MSE test 12.560764037033728\n",
      "MAE train 1.7065124644266016 MAE test 2.4849458364778303\n",
      "Epoch 1205 / 10000 loss: 16.106945753097534\n",
      "MSE train 6.051404302635319 MSE test 12.56052545910276\n",
      "MAE train 1.70648936096752 MAE test 2.4849172990819\n",
      "Epoch 1206 / 10000 loss: 16.106287002563477\n",
      "MSE train 6.051231818897309 MSE test 12.56042219648451\n",
      "MAE train 1.706461833354378 MAE test 2.484910271236735\n",
      "Epoch 1207 / 10000 loss: 16.10569453239441\n",
      "MSE train 6.051072658422313 MSE test 12.56018387322907\n",
      "MAE train 1.7064387328197197 MAE test 2.484881765318258\n",
      "Epoch 1208 / 10000 loss: 16.10503602027893\n",
      "MSE train 6.050900134862852 MSE test 12.56008040755589\n",
      "MAE train 1.7064111987011858 MAE test 2.484874710791178\n",
      "Epoch 1209 / 10000 loss: 16.1044442653656\n",
      "MSE train 6.050741000947621 MSE test 12.559842023358836\n",
      "MAE train 1.7063880966014924 MAE test 2.484846196318079\n",
      "Epoch 1210 / 10000 loss: 16.10378646850586\n",
      "MSE train 6.050568601288725 MSE test 12.559738676983105\n",
      "MAE train 1.7063605739445804 MAE test 2.484839146762021\n",
      "Epoch 1211 / 10000 loss: 16.103193759918213\n",
      "MSE train 6.050409427771936 MSE test 12.559500277526789\n",
      "MAE train 1.7063374727215848 MAE test 2.484810633481965\n",
      "Epoch 1212 / 10000 loss: 16.102535724639893\n",
      "MSE train 6.050237000837545 MSE test 12.559397002430169\n",
      "MAE train 1.7063099429131987 MAE test 2.484803598006795\n",
      "Epoch 1213 / 10000 loss: 16.1019446849823\n",
      "MSE train 6.050077886191505 MSE test 12.559158566113233\n",
      "MAE train 1.7062868489621423 MAE test 2.484775078250824\n",
      "Epoch 1214 / 10000 loss: 16.10128617286682\n",
      "MSE train 6.049905421592347 MSE test 12.559055314435705\n",
      "MAE train 1.706259308178298 MAE test 2.484768046492582\n",
      "Epoch 1215 / 10000 loss: 16.10069489479065\n",
      "MSE train 6.049746346837484 MSE test 12.558816891458315\n",
      "MAE train 1.7062362247081007 MAE test 2.4847395243896635\n",
      "Epoch 1216 / 10000 loss: 16.100036144256592\n",
      "MSE train 6.049573952808517 MSE test 12.558713545311436\n",
      "MAE train 1.7062086932657934 MAE test 2.4847324769509\n",
      "Epoch 1217 / 10000 loss: 16.09944486618042\n",
      "MSE train 6.0494148484875865 MSE test 12.558475194845858\n",
      "MAE train 1.7061856020484787 MAE test 2.484703953112696\n",
      "Epoch 1218 / 10000 loss: 16.098786115646362\n",
      "MSE train 6.049242496467099 MSE test 12.558371773339365\n",
      "MAE train 1.7061580773931266 MAE test 2.484696897385122\n",
      "Epoch 1219 / 10000 loss: 16.09819531440735\n",
      "MSE train 6.049083417506453 MSE test 12.558133618129574\n",
      "MAE train 1.7061349887424824 MAE test 2.484668417918489\n",
      "Epoch 1220 / 10000 loss: 16.09753680229187\n",
      "MSE train 6.048911071658246 MSE test 12.558030126531884\n",
      "MAE train 1.706107460131067 MAE test 2.4846613548609504\n",
      "Epoch 1221 / 10000 loss: 16.096946477890015\n",
      "MSE train 6.048752048170675 MSE test 12.557791929641887\n",
      "MAE train 1.7060843815814792 MAE test 2.4846328486249423\n",
      "Epoch 1222 / 10000 loss: 16.096288204193115\n",
      "MSE train 6.048579666931209 MSE test 12.557688478932285\n",
      "MAE train 1.7060568430772496 MAE test 2.4846257969494894\n",
      "Epoch 1223 / 10000 loss: 16.095696687698364\n",
      "MSE train 6.048420662764911 MSE test 12.557450169166612\n",
      "MAE train 1.706033769569631 MAE test 2.484597291343464\n",
      "Epoch 1224 / 10000 loss: 16.095038414001465\n",
      "MSE train 6.0482483208314095 MSE test 12.557346927782067\n",
      "MAE train 1.7060062340081117 MAE test 2.484590257851869\n",
      "Epoch 1225 / 10000 loss: 16.094447135925293\n",
      "MSE train 6.048089289971698 MSE test 12.557108618199749\n",
      "MAE train 1.7059831547078226 MAE test 2.484561731872758\n",
      "Epoch 1226 / 10000 loss: 16.09378957748413\n",
      "MSE train 6.047917012497992 MSE test 12.557005149510397\n",
      "MAE train 1.7059556282486312 MAE test 2.484554675130119\n",
      "Epoch 1227 / 10000 loss: 16.093198537826538\n",
      "MSE train 6.04775803465091 MSE test 12.556766938051409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7059325616608705 MAE test 2.4845261794064246\n",
      "Epoch 1228 / 10000 loss: 16.09254002571106\n",
      "MSE train 6.047585717697223 MSE test 12.556663586945088\n",
      "MAE train 1.705905020277428 MAE test 2.4845191408936698\n",
      "Epoch 1229 / 10000 loss: 16.091949939727783\n",
      "MSE train 6.047426726944137 MSE test 12.55642529223275\n",
      "MAE train 1.7058819533906209 MAE test 2.484490614545756\n",
      "Epoch 1230 / 10000 loss: 16.09129238128662\n",
      "MSE train 6.047254447694397 MSE test 12.556321904166609\n",
      "MAE train 1.7058544149398012 MAE test 2.4844835744218354\n",
      "Epoch 1231 / 10000 loss: 16.09070086479187\n",
      "MSE train 6.047095462256737 MSE test 12.556083701746239\n",
      "MAE train 1.7058313494802073 MAE test 2.484455061849681\n",
      "Epoch 1232 / 10000 loss: 16.090043306350708\n",
      "MSE train 6.046923189186573 MSE test 12.5559803461835\n",
      "MAE train 1.7058038102640598 MAE test 2.484448026383225\n",
      "Epoch 1233 / 10000 loss: 16.089452981948853\n",
      "MSE train 6.046764301412267 MSE test 12.555742296709235\n",
      "MAE train 1.705780755600134 MAE test 2.484419533060382\n",
      "Epoch 1234 / 10000 loss: 16.088794469833374\n",
      "MSE train 6.046592049217921 MSE test 12.555638780943374\n",
      "MAE train 1.7057532178567287 MAE test 2.4844124735175064\n",
      "Epoch 1235 / 10000 loss: 16.088204383850098\n",
      "MSE train 6.046433166798157 MSE test 12.555400738812073\n",
      "MAE train 1.7057301718355402 MAE test 2.484383988234575\n",
      "Epoch 1236 / 10000 loss: 16.087546586990356\n",
      "MSE train 6.046260906213334 MSE test 12.55529737863263\n",
      "MAE train 1.7057026228683747 MAE test 2.484376951776288\n",
      "Epoch 1237 / 10000 loss: 16.086955785751343\n",
      "MSE train 6.046102032140911 MSE test 12.555059218048939\n",
      "MAE train 1.7056795760186994 MAE test 2.4843484388328596\n",
      "Epoch 1238 / 10000 loss: 16.08629822731018\n",
      "MSE train 6.045929827248302 MSE test 12.554955731871114\n",
      "MAE train 1.7056520343307624 MAE test 2.484341384805021\n",
      "Epoch 1239 / 10000 loss: 16.085708618164062\n",
      "MSE train 6.045770866592962 MSE test 12.554717665035255\n",
      "MAE train 1.705628981016599 MAE test 2.484312881481812\n",
      "Epoch 1240 / 10000 loss: 16.0850510597229\n",
      "MSE train 6.045598679058363 MSE test 12.55461432553057\n",
      "MAE train 1.7056014381107145 MAE test 2.4843058520220955\n",
      "Epoch 1241 / 10000 loss: 16.084460496902466\n",
      "MSE train 6.045439856653255 MSE test 12.554376203234673\n",
      "MAE train 1.705578401366056 MAE test 2.484277346718177\n",
      "Epoch 1242 / 10000 loss: 16.083802938461304\n",
      "MSE train 6.045267662359751 MSE test 12.554272820046029\n",
      "MAE train 1.705550858386787 MAE test 2.4842703111441726\n",
      "Epoch 1243 / 10000 loss: 16.083213567733765\n",
      "MSE train 6.045108836359047 MSE test 12.554034711409582\n",
      "MAE train 1.7055278233858424 MAE test 2.484241797190847\n",
      "Epoch 1244 / 10000 loss: 16.082555055618286\n",
      "MSE train 6.044936681190396 MSE test 12.553931343560773\n",
      "MAE train 1.7055002796226297 MAE test 2.484234756797439\n",
      "Epoch 1245 / 10000 loss: 16.081966161727905\n",
      "MSE train 6.044777857327274 MSE test 12.553693362902122\n",
      "MAE train 1.705477248926959 MAE test 2.4842062692900093\n",
      "Epoch 1246 / 10000 loss: 16.081307888031006\n",
      "MSE train 6.044605700477841 MSE test 12.553589973079267\n",
      "MAE train 1.7054497003762992 MAE test 2.4841992251978384\n",
      "Epoch 1247 / 10000 loss: 16.080718755722046\n",
      "MSE train 6.044446872537089 MSE test 12.553351856634842\n",
      "MAE train 1.7054266692720046 MAE test 2.484170718213417\n",
      "Epoch 1248 / 10000 loss: 16.080060958862305\n",
      "MSE train 6.044274793409367 MSE test 12.553248537162776\n",
      "MAE train 1.7053991295590678 MAE test 2.484163685906322\n",
      "Epoch 1249 / 10000 loss: 16.07947087287903\n",
      "MSE train 6.044115966134738 MSE test 12.553010437360062\n",
      "MAE train 1.7053760963913638 MAE test 2.4841351705852324\n",
      "Epoch 1250 / 10000 loss: 16.078814268112183\n",
      "MSE train 6.0439438741300595 MSE test 12.552907011826976\n",
      "MAE train 1.7053485570943268 MAE test 2.48412812894878\n",
      "Epoch 1251 / 10000 loss: 16.078224420547485\n",
      "MSE train 6.043785154219478 MSE test 12.552669054838674\n",
      "MAE train 1.70532554279811 MAE test 2.4840996463125204\n",
      "Epoch 1252 / 10000 loss: 16.07756733894348\n",
      "MSE train 6.04361307018443 MSE test 12.552565613156652\n",
      "MAE train 1.7052979993876474 MAE test 2.4840926016271987\n",
      "Epoch 1253 / 10000 loss: 16.076977252960205\n",
      "MSE train 6.043454316423436 MSE test 12.55232756974289\n",
      "MAE train 1.7052749869721378 MAE test 2.4840640824047497\n",
      "Epoch 1254 / 10000 loss: 16.076319932937622\n",
      "MSE train 6.04328220270066 MSE test 12.552224339072117\n",
      "MAE train 1.7052474361392962 MAE test 2.484057084914851\n",
      "Epoch 1255 / 10000 loss: 16.075730800628662\n",
      "MSE train 6.043123393019329 MSE test 12.551986254701147\n",
      "MAE train 1.7052244118912159 MAE test 2.484028564900964\n",
      "Epoch 1256 / 10000 loss: 16.075072765350342\n",
      "MSE train 6.042951415902745 MSE test 12.551882815051096\n",
      "MAE train 1.705196880423159 MAE test 2.4840215290302283\n",
      "Epoch 1257 / 10000 loss: 16.074483156204224\n",
      "MSE train 6.0427927020749745 MSE test 12.551644886142052\n",
      "MAE train 1.7051738697619636 MAE test 2.483993024498821\n",
      "Epoch 1258 / 10000 loss: 16.073826551437378\n",
      "MSE train 6.042620685056496 MSE test 12.551541445618891\n",
      "MAE train 1.7051463267535574 MAE test 2.4839859910843938\n",
      "Epoch 1259 / 10000 loss: 16.073237419128418\n",
      "MSE train 6.0424619713188905 MSE test 12.551303556755615\n",
      "MAE train 1.7051233206027783 MAE test 2.4839574965753197\n",
      "Epoch 1260 / 10000 loss: 16.072582006454468\n",
      "MSE train 6.0422899392206695 MSE test 12.551200148823645\n",
      "MAE train 1.7050957750222258 MAE test 2.4839504703640416\n",
      "Epoch 1261 / 10000 loss: 16.07199215888977\n",
      "MSE train 6.042131256977808 MSE test 12.550962135952018\n",
      "MAE train 1.705072774620742 MAE test 2.4839219498612897\n",
      "Epoch 1262 / 10000 loss: 16.071335315704346\n",
      "MSE train 6.041959237395925 MSE test 12.550858907544985\n",
      "MAE train 1.7050452280497865 MAE test 2.483914946896039\n",
      "Epoch 1263 / 10000 loss: 16.07074546813965\n",
      "MSE train 6.041800598852265 MSE test 12.550620945933158\n",
      "MAE train 1.7050222320833015 MAE test 2.483886436924873\n",
      "Epoch 1264 / 10000 loss: 16.070088624954224\n",
      "MSE train 6.041628617230615 MSE test 12.550517565245377\n",
      "MAE train 1.7049946899161461 MAE test 2.4838793976190625\n",
      "Epoch 1265 / 10000 loss: 16.069499492645264\n",
      "MSE train 6.041470043253125 MSE test 12.550279518571168\n",
      "MAE train 1.704971702231649 MAE test 2.483850881598516\n",
      "Epoch 1266 / 10000 loss: 16.068843126296997\n",
      "MSE train 6.041298005246241 MSE test 12.550176172756066\n",
      "MAE train 1.7049441514243489 MAE test 2.483843853396683\n",
      "Epoch 1267 / 10000 loss: 16.068254709243774\n",
      "MSE train 6.041139386234586 MSE test 12.549938286076035\n",
      "MAE train 1.7049211619115385 MAE test 2.483815359002568\n",
      "Epoch 1268 / 10000 loss: 16.06759738922119\n",
      "MSE train 6.0409674227335275 MSE test 12.54983487191828\n",
      "MAE train 1.7048936169559104 MAE test 2.48380832472516\n",
      "Epoch 1269 / 10000 loss: 16.067009449005127\n",
      "MSE train 6.040808852521614 MSE test 12.549596998110719\n",
      "MAE train 1.704870637341166 MAE test 2.4837798315411455\n",
      "Epoch 1270 / 10000 loss: 16.06635308265686\n",
      "MSE train 6.0406369282407395 MSE test 12.54949360396869\n",
      "MAE train 1.7048430939530534 MAE test 2.483772801740779\n",
      "Epoch 1271 / 10000 loss: 16.065762996673584\n",
      "MSE train 6.040478347300307 MSE test 12.54925579865777\n",
      "MAE train 1.7048201143570378 MAE test 2.4837443172733455\n",
      "Epoch 1272 / 10000 loss: 16.065107107162476\n",
      "MSE train 6.040306417473709 MSE test 12.549152426132487\n",
      "MAE train 1.7047925671875641 MAE test 2.4837372839517493\n",
      "Epoch 1273 / 10000 loss: 16.064518451690674\n",
      "MSE train 6.040147892648307 MSE test 12.548914458840688\n",
      "MAE train 1.7047695964649348 MAE test 2.4837087730385212\n",
      "Epoch 1274 / 10000 loss: 16.063862085342407\n",
      "MSE train 6.039975982103699 MSE test 12.548811025303802\n",
      "MAE train 1.70474205175526 MAE test 2.48370175163965\n",
      "Epoch 1275 / 10000 loss: 16.063273668289185\n",
      "MSE train 6.039817414916928 MSE test 12.548573225424763\n",
      "MAE train 1.7047190750769268 MAE test 2.4836732550928753\n",
      "Epoch 1276 / 10000 loss: 16.06261682510376\n",
      "MSE train 6.039645537378928 MSE test 12.548469787156977\n",
      "MAE train 1.7046915311059827 MAE test 2.483666226622704\n",
      "Epoch 1277 / 10000 loss: 16.062028408050537\n",
      "MSE train 6.039487040820549 MSE test 12.54823188358755\n",
      "MAE train 1.7046685672206752 MAE test 2.483637717768899\n",
      "Epoch 1278 / 10000 loss: 16.06137251853943\n",
      "MSE train 6.039315149873638 MSE test 12.548128503344484\n",
      "MAE train 1.7046410165560082 MAE test 2.4836306917224493\n",
      "Epoch 1279 / 10000 loss: 16.060783863067627\n",
      "MSE train 6.039156673930841 MSE test 12.547890581611618\n",
      "MAE train 1.7046180610569048 MAE test 2.483602187188384\n",
      "Epoch 1280 / 10000 loss: 16.06012749671936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.0389848134288515 MSE test 12.547787293588817\n",
      "MAE train 1.7045905131446941 MAE test 2.4835951684758455\n",
      "Epoch 1281 / 10000 loss: 16.059539079666138\n",
      "MSE train 6.038826298398199 MSE test 12.5475493319028\n",
      "MAE train 1.7045675476435258 MAE test 2.4835666493004145\n",
      "Epoch 1282 / 10000 loss: 16.058883905410767\n",
      "MSE train 6.0386544945522225 MSE test 12.547445874127874\n",
      "MAE train 1.7045400082605429 MAE test 2.4835596152500607\n",
      "Epoch 1283 / 10000 loss: 16.058295488357544\n",
      "MSE train 6.038496050991724 MSE test 12.54720814208165\n",
      "MAE train 1.704517057480149 MAE test 2.483531128033968\n",
      "Epoch 1284 / 10000 loss: 16.05763864517212\n",
      "MSE train 6.038324233274928 MSE test 12.547104553579771\n",
      "MAE train 1.7044895115443954 MAE test 2.483524080172517\n",
      "Epoch 1285 / 10000 loss: 16.057051181793213\n",
      "MSE train 6.038165749003599 MSE test 12.546866775714184\n",
      "MAE train 1.704466555504328 MAE test 2.4834955864441124\n",
      "Epoch 1286 / 10000 loss: 16.056395292282104\n",
      "MSE train 6.037993957773917 MSE test 12.546763370480011\n",
      "MAE train 1.7044390100544615 MAE test 2.483488564195537\n",
      "Epoch 1287 / 10000 loss: 16.05580711364746\n",
      "MSE train 6.037835545537729 MSE test 12.546525467247367\n",
      "MAE train 1.7044160666429167 MAE test 2.483460050989034\n",
      "Epoch 1288 / 10000 loss: 16.055151224136353\n",
      "MSE train 6.037663724861517 MSE test 12.54642198786156\n",
      "MAE train 1.7043885199424973 MAE test 2.4834530123398184\n",
      "Epoch 1289 / 10000 loss: 16.054563522338867\n",
      "MSE train 6.037505363408449 MSE test 12.54618427741858\n",
      "MAE train 1.7043655800290103 MAE test 2.4834245262477164\n",
      "Epoch 1290 / 10000 loss: 16.0539071559906\n",
      "MSE train 6.037333571621464 MSE test 12.546080791575495\n",
      "MAE train 1.7043380362350944 MAE test 2.483417485737639\n",
      "Epoch 1291 / 10000 loss: 16.053319215774536\n",
      "MSE train 6.037175188179739 MSE test 12.545842945290234\n",
      "MAE train 1.704315099867765 MAE test 2.483388971859843\n",
      "Epoch 1292 / 10000 loss: 16.052663326263428\n",
      "MSE train 6.037003426886971 MSE test 12.545739523555838\n",
      "MAE train 1.7042875573537228 MAE test 2.4833819536388715\n",
      "Epoch 1293 / 10000 loss: 16.05207586288452\n",
      "MSE train 6.036845035358833 MSE test 12.545501649709678\n",
      "MAE train 1.7042646154938488 MAE test 2.4833534385445613\n",
      "Epoch 1294 / 10000 loss: 16.05142068862915\n",
      "MSE train 6.036673287486436 MSE test 12.545398180276752\n",
      "MAE train 1.704237073925886 MAE test 2.483346421811707\n",
      "Epoch 1295 / 10000 loss: 16.05083179473877\n",
      "MSE train 6.036514970351734 MSE test 12.545160413536388\n",
      "MAE train 1.7042141502013441 MAE test 2.483317909502448\n",
      "Epoch 1296 / 10000 loss: 16.050177335739136\n",
      "MSE train 6.036343179208016 MSE test 12.545056982865592\n",
      "MAE train 1.7041865945837775 MAE test 2.483310877914994\n",
      "Epoch 1297 / 10000 loss: 16.04958963394165\n",
      "MSE train 6.036184896092351 MSE test 12.544819194096664\n",
      "MAE train 1.704163675288198 MAE test 2.483282375327422\n",
      "Epoch 1298 / 10000 loss: 16.04893398284912\n",
      "MSE train 6.036013202742096 MSE test 12.54471559290512\n",
      "MAE train 1.7041361352637667 MAE test 2.483275325333027\n",
      "Epoch 1299 / 10000 loss: 16.04834532737732\n",
      "MSE train 6.035854902645727 MSE test 12.544478006927585\n",
      "MAE train 1.7041132172915492 MAE test 2.4832468484104564\n",
      "Epoch 1300 / 10000 loss: 16.047690868377686\n",
      "MSE train 6.035683183538608 MSE test 12.544374517311182\n",
      "MAE train 1.70408566281616 MAE test 2.483239815185825\n",
      "Epoch 1301 / 10000 loss: 16.0471031665802\n",
      "MSE train 6.035524905091475 MSE test 12.544136695207476\n",
      "MAE train 1.704062753851532 MAE test 2.4832112997278424\n",
      "Epoch 1302 / 10000 loss: 16.046448230743408\n",
      "MSE train 6.0353531992819756 MSE test 12.544033267870185\n",
      "MAE train 1.704035201014976 MAE test 2.483204280637307\n",
      "Epoch 1303 / 10000 loss: 16.045860528945923\n",
      "MSE train 6.0351949092441775 MSE test 12.543795498289022\n",
      "MAE train 1.7040122915116143 MAE test 2.4831757641115644\n",
      "Epoch 1304 / 10000 loss: 16.045204877853394\n",
      "MSE train 6.035023244204107 MSE test 12.543691887634843\n",
      "MAE train 1.7039847467981195 MAE test 2.4831687227716843\n",
      "Epoch 1305 / 10000 loss: 16.044618129730225\n",
      "MSE train 6.034864982330228 MSE test 12.543454224998403\n",
      "MAE train 1.7039618351541066 MAE test 2.4831402277560732\n",
      "Epoch 1306 / 10000 loss: 16.043962717056274\n",
      "MSE train 6.034693360250028 MSE test 12.543350662898188\n",
      "MAE train 1.7039342980697114 MAE test 2.4831331934302323\n",
      "Epoch 1307 / 10000 loss: 16.043375492095947\n",
      "MSE train 6.034535093163256 MSE test 12.54311291668922\n",
      "MAE train 1.7039113857875168 MAE test 2.4831046760747304\n",
      "Epoch 1308 / 10000 loss: 16.042721033096313\n",
      "MSE train 6.034363457098511 MSE test 12.543009521205244\n",
      "MAE train 1.7038838387771142 MAE test 2.483097666913606\n",
      "Epoch 1309 / 10000 loss: 16.04213237762451\n",
      "MSE train 6.034205238075472 MSE test 12.542771555296028\n",
      "MAE train 1.7038609414791142 MAE test 2.4830691292389098\n",
      "Epoch 1310 / 10000 loss: 16.0414776802063\n",
      "MSE train 6.034033643188592 MSE test 12.542668263216171\n",
      "MAE train 1.7038333991981338 MAE test 2.4830621206066126\n",
      "Epoch 1311 / 10000 loss: 16.040891647338867\n",
      "MSE train 6.03387543737783 MSE test 12.542430422005335\n",
      "MAE train 1.703810503769928 MAE test 2.4830335915433652\n",
      "Epoch 1312 / 10000 loss: 16.040236473083496\n",
      "MSE train 6.033703847387653 MSE test 12.542326925450743\n",
      "MAE train 1.7037829624350291 MAE test 2.483026568103315\n",
      "Epoch 1313 / 10000 loss: 16.039648294448853\n",
      "MSE train 6.033545628128442 MSE test 12.542089051068766\n",
      "MAE train 1.703760059847819 MAE test 2.4829980345337304\n",
      "Epoch 1314 / 10000 loss: 16.038994073867798\n",
      "MSE train 6.033374030527708 MSE test 12.541985547126838\n",
      "MAE train 1.7037325180101768 MAE test 2.482991002740462\n",
      "Epoch 1315 / 10000 loss: 16.03840732574463\n",
      "MSE train 6.033215871403732 MSE test 12.54174784308893\n",
      "MAE train 1.703709630741366 MAE test 2.4829624991313106\n",
      "Epoch 1316 / 10000 loss: 16.037752628326416\n",
      "MSE train 6.033044316283391 MSE test 12.541644298785865\n",
      "MAE train 1.703682088277199 MAE test 2.482955459399672\n",
      "Epoch 1317 / 10000 loss: 16.03716516494751\n",
      "MSE train 6.032886183791653 MSE test 12.54140663075458\n",
      "MAE train 1.7036592051140058 MAE test 2.4829269568509664\n",
      "Epoch 1318 / 10000 loss: 16.03650999069214\n",
      "MSE train 6.032714611923004 MSE test 12.541303049684686\n",
      "MAE train 1.703631654499416 MAE test 2.4829199149257652\n",
      "Epoch 1319 / 10000 loss: 16.03592324256897\n",
      "MSE train 6.032556449338512 MSE test 12.541065218112337\n",
      "MAE train 1.7036087738945733 MAE test 2.4828913932920975\n",
      "Epoch 1320 / 10000 loss: 16.03527021408081\n",
      "MSE train 6.032384920809725 MSE test 12.540961626882714\n",
      "MAE train 1.7035812307986782 MAE test 2.4828843578466078\n",
      "Epoch 1321 / 10000 loss: 16.034681797027588\n",
      "MSE train 6.032226817565254 MSE test 12.540723983820856\n",
      "MAE train 1.7035583592962316 MAE test 2.482855846826662\n",
      "Epoch 1322 / 10000 loss: 16.034027814865112\n",
      "MSE train 6.032055263642546 MSE test 12.540620315928214\n",
      "MAE train 1.703530809792367 MAE test 2.482848789178165\n",
      "Epoch 1323 / 10000 loss: 16.033440828323364\n",
      "MSE train 6.031897132818037 MSE test 12.540382712236084\n",
      "MAE train 1.7035079315120476 MAE test 2.482820293921355\n",
      "Epoch 1324 / 10000 loss: 16.032787322998047\n",
      "MSE train 6.031725622591302 MSE test 12.540279020981087\n",
      "MAE train 1.7034803809302577 MAE test 2.4828132344614744\n",
      "Epoch 1325 / 10000 loss: 16.032198667526245\n",
      "MSE train 6.031567589999223 MSE test 12.540041348355516\n",
      "MAE train 1.7034575242601326 MAE test 2.4827847289090617\n",
      "Epoch 1326 / 10000 loss: 16.03154492378235\n",
      "MSE train 6.031396089860462 MSE test 12.539937748054864\n",
      "MAE train 1.7034299761221963 MAE test 2.4827776829794055\n",
      "Epoch 1327 / 10000 loss: 16.03095817565918\n",
      "MSE train 6.031237998860331 MSE test 12.539700011301118\n",
      "MAE train 1.703407111168028 MAE test 2.4827491590975863\n",
      "Epoch 1328 / 10000 loss: 16.030303716659546\n",
      "MSE train 6.031066494000192 MSE test 12.539596439908108\n",
      "MAE train 1.7033795640937568 MAE test 2.4827421091476145\n",
      "Epoch 1329 / 10000 loss: 16.029717683792114\n",
      "MSE train 6.030908485142947 MSE test 12.539358592335713\n",
      "MAE train 1.703356710172163 MAE test 2.482713588897546\n",
      "Epoch 1330 / 10000 loss: 16.02906322479248\n",
      "MSE train 6.030736943739162 MSE test 12.539255068741642\n",
      "MAE train 1.7033291542255722 MAE test 2.4827065390452967\n",
      "Epoch 1331 / 10000 loss: 16.02847695350647\n",
      "MSE train 6.030578969393796 MSE test 12.539017333837837\n",
      "MAE train 1.7033063091501095 MAE test 2.4826780346850637\n",
      "Epoch 1332 / 10000 loss: 16.027822732925415\n",
      "MSE train 6.0304074772142116 MSE test 12.53891361261313\n",
      "MAE train 1.7032787540276573 MAE test 2.482670979464675\n",
      "Epoch 1333 / 10000 loss: 16.027235507965088\n",
      "MSE train 6.030249473295188 MSE test 12.538676041801663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.7032559127798457 MAE test 2.4826424698335514\n",
      "Epoch 1334 / 10000 loss: 16.026581525802612\n",
      "MSE train 6.030078024871145 MSE test 12.538572403851022\n",
      "MAE train 1.7032283585890802 MAE test 2.482635430406614\n",
      "Epoch 1335 / 10000 loss: 16.025994777679443\n",
      "MSE train 6.029920015689508 MSE test 12.538334513028788\n",
      "MAE train 1.7032055185252435 MAE test 2.482606876095833\n",
      "Epoch 1336 / 10000 loss: 16.02534055709839\n",
      "MSE train 6.029748591092315 MSE test 12.538230995154386\n",
      "MAE train 1.7031779691642424 MAE test 2.48259984437582\n",
      "Epoch 1337 / 10000 loss: 16.024754524230957\n",
      "MSE train 6.029590605307513 MSE test 12.53799327825078\n",
      "MAE train 1.7031551327275702 MAE test 2.48257133252051\n",
      "Epoch 1338 / 10000 loss: 16.024101734161377\n",
      "MSE train 6.02941918846091 MSE test 12.537889643700032\n",
      "MAE train 1.7031275829516548 MAE test 2.482564278676058\n",
      "Epoch 1339 / 10000 loss: 16.02351427078247\n",
      "MSE train 6.029261198909718 MSE test 12.537651848279081\n",
      "MAE train 1.7031047459968829 MAE test 2.4825357478677734\n",
      "Epoch 1340 / 10000 loss: 16.022860288619995\n",
      "MSE train 6.029089773280991 MSE test 12.537548195527313\n",
      "MAE train 1.7030771887989034 MAE test 2.482528698074955\n",
      "Epoch 1341 / 10000 loss: 16.02227520942688\n",
      "MSE train 6.028931826378362 MSE test 12.537310509739614\n",
      "MAE train 1.703054362426767 MAE test 2.482500177823115\n",
      "Epoch 1342 / 10000 loss: 16.021621227264404\n",
      "MSE train 6.0287604284646665 MSE test 12.537206779828725\n",
      "MAE train 1.703026806762632 MAE test 2.4824931112129605\n",
      "Epoch 1343 / 10000 loss: 16.021034002304077\n",
      "MSE train 6.028602503779074 MSE test 12.536969029336792\n",
      "MAE train 1.703003987127905 MAE test 2.4824645844998257\n",
      "Epoch 1344 / 10000 loss: 16.02038073539734\n",
      "MSE train 6.028431120183753 MSE test 12.536865234958125\n",
      "MAE train 1.7029764342170304 MAE test 2.4824575119547085\n",
      "Epoch 1345 / 10000 loss: 16.01979422569275\n",
      "MSE train 6.028273144069333 MSE test 12.536627513985678\n",
      "MAE train 1.7029536038640771 MAE test 2.4824289864021307\n",
      "Epoch 1346 / 10000 loss: 16.019140481948853\n",
      "MSE train 6.028101796237795 MSE test 12.53652375436221\n",
      "MAE train 1.7029260557165322 MAE test 2.4824219159644683\n",
      "Epoch 1347 / 10000 loss: 16.018555164337158\n",
      "MSE train 6.027943869713064 MSE test 12.5362860677798\n",
      "MAE train 1.7029032313684662 MAE test 2.4823933923397283\n",
      "Epoch 1348 / 10000 loss: 16.01790165901184\n",
      "MSE train 6.02777255095178 MSE test 12.53618231434951\n",
      "MAE train 1.7028756830667187 MAE test 2.482386325286865\n",
      "Epoch 1349 / 10000 loss: 16.017314434051514\n",
      "MSE train 6.027614628351 MSE test 12.535944609565735\n",
      "MAE train 1.7028528674592494 MAE test 2.4823578045095407\n",
      "Epoch 1350 / 10000 loss: 16.016661882400513\n",
      "MSE train 6.027443286721115 MSE test 12.53584081654727\n",
      "MAE train 1.70282530916369 MAE test 2.482350740289249\n",
      "Epoch 1351 / 10000 loss: 16.016075134277344\n",
      "MSE train 6.027285452883469 MSE test 12.535603016641895\n",
      "MAE train 1.7028025074137831 MAE test 2.482322196155048\n",
      "Epoch 1352 / 10000 loss: 16.015421628952026\n",
      "MSE train 6.027114117132753 MSE test 12.535499323150086\n",
      "MAE train 1.702774949525887 MAE test 2.4823151351753183\n",
      "Epoch 1353 / 10000 loss: 16.014836072921753\n",
      "MSE train 6.026956232904605 MSE test 12.535261589102783\n",
      "MAE train 1.7027521397536842 MAE test 2.4822865999832464\n",
      "Epoch 1354 / 10000 loss: 16.014182806015015\n",
      "MSE train 6.026784956510517 MSE test 12.535157700184634\n",
      "MAE train 1.7027245903230475 MAE test 2.482279509952958\n",
      "Epoch 1355 / 10000 loss: 16.0135977268219\n",
      "MSE train 6.026627072233793 MSE test 12.534920057091705\n",
      "MAE train 1.7027017823631567 MAE test 2.482250997096883\n",
      "Epoch 1356 / 10000 loss: 16.012943029403687\n",
      "MSE train 6.0264558012668585 MSE test 12.534816084257189\n",
      "MAE train 1.702674231042171 MAE test 2.4822439011982653\n",
      "Epoch 1357 / 10000 loss: 16.012356519699097\n",
      "MSE train 6.026297910020134 MSE test 12.534578377387346\n",
      "MAE train 1.7026514235295578 MAE test 2.4822153688681095\n",
      "Epoch 1358 / 10000 loss: 16.011704444885254\n",
      "MSE train 6.026126649340206 MSE test 12.5344744966932\n",
      "MAE train 1.7026238681252615 MAE test 2.4822082997600536\n",
      "Epoch 1359 / 10000 loss: 16.011118412017822\n",
      "MSE train 6.025968755020283 MSE test 12.534236794419181\n",
      "MAE train 1.7026010631562607 MAE test 2.4821797616603885\n",
      "Epoch 1360 / 10000 loss: 16.010464191436768\n",
      "MSE train 6.025797534521749 MSE test 12.534132990089812\n",
      "MAE train 1.7025735081967543 MAE test 2.482172679097168\n",
      "Epoch 1361 / 10000 loss: 16.00987935066223\n",
      "MSE train 6.025639716593794 MSE test 12.533895158642249\n",
      "MAE train 1.7025507184680506 MAE test 2.4821441388591605\n",
      "Epoch 1362 / 10000 loss: 16.009225368499756\n",
      "MSE train 6.025468418919154 MSE test 12.533791266870116\n",
      "MAE train 1.7025231522525368 MAE test 2.482137058877552\n",
      "Epoch 1363 / 10000 loss: 16.008641481399536\n",
      "MSE train 6.025310676977744 MSE test 12.533553686557104\n",
      "MAE train 1.702500374994037 MAE test 2.4821085581865727\n",
      "Epoch 1364 / 10000 loss: 16.00798726081848\n",
      "MSE train 6.025139389986983 MSE test 12.533449636561757\n",
      "MAE train 1.7024728046774358 MAE test 2.4821014367695464\n",
      "Epoch 1365 / 10000 loss: 16.00740122795105\n",
      "MSE train 6.024981628416639 MSE test 12.533211774540495\n",
      "MAE train 1.7024500249289267 MAE test 2.4820728809064567\n",
      "Epoch 1366 / 10000 loss: 16.00674867630005\n",
      "MSE train 6.024810361937624 MSE test 12.533107829153298\n",
      "MAE train 1.7024224592589332 MAE test 2.4820657943047966\n",
      "Epoch 1367 / 10000 loss: 16.006162643432617\n",
      "MSE train 6.0246525579799775 MSE test 12.53287004193451\n",
      "MAE train 1.7023996746656462 MAE test 2.4820372510895217\n",
      "Epoch 1368 / 10000 loss: 16.0055091381073\n",
      "MSE train 6.0244813414079355 MSE test 12.532766118696264\n",
      "MAE train 1.702372111464698 MAE test 2.4820301567207896\n",
      "Epoch 1369 / 10000 loss: 16.004924535751343\n",
      "MSE train 6.024323617166198 MSE test 12.532528344312267\n",
      "MAE train 1.7023493413837656 MAE test 2.482001625900131\n",
      "Epoch 1370 / 10000 loss: 16.004270553588867\n",
      "MSE train 6.024152361776747 MSE test 12.532424348181415\n",
      "MAE train 1.7023217705242286 MAE test 2.481994528565045\n",
      "Epoch 1371 / 10000 loss: 16.00368642807007\n",
      "MSE train 6.0239946029133815 MSE test 12.53218651901459\n",
      "MAE train 1.7022989934531634 MAE test 2.4819659692166134\n",
      "Epoch 1372 / 10000 loss: 16.003032684326172\n",
      "MSE train 6.023823364124667 MSE test 12.532082589153662\n",
      "MAE train 1.70227142010446 MAE test 2.4819588786774904\n",
      "Epoch 1373 / 10000 loss: 16.00244688987732\n",
      "MSE train 6.023665683424063 MSE test 12.531844769742804\n",
      "MAE train 1.702248657607982 MAE test 2.4819303290033368\n",
      "Epoch 1374 / 10000 loss: 16.001795530319214\n",
      "MSE train 6.0234944520869105 MSE test 12.531740700574314\n",
      "MAE train 1.7022210840364311 MAE test 2.4819232109237324\n",
      "Epoch 1375 / 10000 loss: 16.001208782196045\n",
      "MSE train 6.023336732784218 MSE test 12.531502862845983\n",
      "MAE train 1.7021983148321547 MAE test 2.4818946600430403\n",
      "Epoch 1376 / 10000 loss: 16.000556707382202\n",
      "MSE train 6.023165566583383 MSE test 12.53139879865952\n",
      "MAE train 1.702170747387129 MAE test 2.4818875559670825\n",
      "Epoch 1377 / 10000 loss: 15.99997091293335\n",
      "MSE train 6.023007855607825 MSE test 12.531160911511005\n",
      "MAE train 1.702147982729094 MAE test 2.481858988661942\n",
      "Epoch 1378 / 10000 loss: 15.999317407608032\n",
      "MSE train 6.02283666009396 MSE test 12.531056791261435\n",
      "MAE train 1.7021204078643528 MAE test 2.4818518801337195\n",
      "Epoch 1379 / 10000 loss: 15.998732566833496\n",
      "MSE train 6.022678995136298 MSE test 12.530819014248886\n",
      "MAE train 1.7020976557432994 MAE test 2.481823334617124\n",
      "Epoch 1380 / 10000 loss: 15.998080253601074\n",
      "MSE train 6.022507818729073 MSE test 12.53071480208753\n",
      "MAE train 1.7020700744534478 MAE test 2.4818162040396294\n",
      "Epoch 1381 / 10000 loss: 15.99749493598938\n",
      "MSE train 6.022350155931446 MSE test 12.530476905123678\n",
      "MAE train 1.702047324802659 MAE test 2.481787641603243\n",
      "Epoch 1382 / 10000 loss: 15.996841669082642\n",
      "MSE train 6.022178947648852 MSE test 12.530372723770006\n",
      "MAE train 1.7020197385316598 MAE test 2.481780517966402\n",
      "Epoch 1383 / 10000 loss: 15.996256113052368\n",
      "MSE train 6.022021232658173 MSE test 12.530134943252474\n",
      "MAE train 1.7019969788056357 MAE test 2.48175196120985\n",
      "Epoch 1384 / 10000 loss: 15.995603561401367\n",
      "MSE train 6.021850075571354 MSE test 12.530030680494386\n",
      "MAE train 1.7019693985433455 MAE test 2.481744837148522\n",
      "Epoch 1385 / 10000 loss: 15.995018243789673\n",
      "MSE train 6.021692442354891 MSE test 12.52979281807352\n",
      "MAE train 1.701946653618338 MAE test 2.4817162570924314\n",
      "Epoch 1386 / 10000 loss: 15.994365930557251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.02152132140598 MSE test 12.529688530799213\n",
      "MAE train 1.7019190733514453 MAE test 2.4817091248702297\n",
      "Epoch 1387 / 10000 loss: 15.993780374526978\n",
      "MSE train 6.021363664914474 MSE test 12.529450749797332\n",
      "MAE train 1.7018963287896038 MAE test 2.4816805836449403\n",
      "Epoch 1388 / 10000 loss: 15.993128061294556\n",
      "MSE train 6.021192549127125 MSE test 12.529346443116875\n",
      "MAE train 1.7018687411720321 MAE test 2.4816734343735014\n",
      "Epoch 1389 / 10000 loss: 15.992542505264282\n",
      "MSE train 6.021034893987262 MSE test 12.529108463248596\n",
      "MAE train 1.7018460024544169 MAE test 2.4816448559665316\n",
      "Epoch 1390 / 10000 loss: 15.99189043045044\n",
      "MSE train 6.020863742205118 MSE test 12.529004176216121\n",
      "MAE train 1.7018184116503419 MAE test 2.481637721878809\n",
      "Epoch 1391 / 10000 loss: 15.991305589675903\n",
      "MSE train 6.020706108840607 MSE test 12.528766274486124\n",
      "MAE train 1.7017956751917547 MAE test 2.481609160160786\n",
      "Epoch 1392 / 10000 loss: 15.990653276443481\n",
      "MSE train 6.020534956092275 MSE test 12.528661867631802\n",
      "MAE train 1.701768078986485 MAE test 2.4816019881872005\n",
      "Epoch 1393 / 10000 loss: 15.99006700515747\n",
      "MSE train 6.020377397240051 MSE test 12.528424024672066\n",
      "MAE train 1.701745353012933 MAE test 2.4815734239284186\n",
      "Epoch 1394 / 10000 loss: 15.989415407180786\n",
      "MSE train 6.020206232697411 MSE test 12.528319554658609\n",
      "MAE train 1.7017177540543884 MAE test 2.481566265359922\n",
      "Epoch 1395 / 10000 loss: 15.988829612731934\n",
      "MSE train 6.02004865049482 MSE test 12.528081612794464\n",
      "MAE train 1.7016950290326593 MAE test 2.4815376932052624\n",
      "Epoch 1396 / 10000 loss: 15.988177061080933\n",
      "MSE train 6.019877511384916 MSE test 12.527977140594398\n",
      "MAE train 1.7016674285870779 MAE test 2.481530524502834\n",
      "Epoch 1397 / 10000 loss: 15.987592220306396\n",
      "MSE train 6.01971987610503 MSE test 12.527739170402665\n",
      "MAE train 1.7016447016611915 MAE test 2.4815019420845066\n",
      "Epoch 1398 / 10000 loss: 15.986939668655396\n",
      "MSE train 6.019548789584613 MSE test 12.527634691768647\n",
      "MAE train 1.7016171060213616 MAE test 2.4814947913409457\n",
      "Epoch 1399 / 10000 loss: 15.986355304718018\n",
      "MSE train 6.019391198895 MSE test 12.527396677325195\n",
      "MAE train 1.7015943799023547 MAE test 2.4814661887925364\n",
      "Epoch 1400 / 10000 loss: 15.985702753067017\n",
      "MSE train 6.019220044754443 MSE test 12.527292048590494\n",
      "MAE train 1.701566771199909 MAE test 2.481459007215345\n",
      "Epoch 1401 / 10000 loss: 15.985116720199585\n",
      "MSE train 6.01906248425034 MSE test 12.527054072317021\n",
      "MAE train 1.7015440506474397 MAE test 2.481430426060945\n",
      "Epoch 1402 / 10000 loss: 15.984464168548584\n",
      "MSE train 6.018891409081466 MSE test 12.526949573199026\n",
      "MAE train 1.7015164573743946 MAE test 2.481423268235725\n",
      "Epoch 1403 / 10000 loss: 15.983879327774048\n",
      "MSE train 6.018733786992566 MSE test 12.526711526342334\n",
      "MAE train 1.7014937284987608 MAE test 2.4813946647000504\n",
      "Epoch 1404 / 10000 loss: 15.983227729797363\n",
      "MSE train 6.018562678602002 MSE test 12.526606981014083\n",
      "MAE train 1.7014661208994835 MAE test 2.481387486159567\n",
      "Epoch 1405 / 10000 loss: 15.982642412185669\n",
      "MSE train 6.018405102589108 MSE test 12.52636878538377\n",
      "MAE train 1.7014434039127493 MAE test 2.481358871969766\n",
      "Epoch 1406 / 10000 loss: 15.981990575790405\n",
      "MSE train 6.018233950976886 MSE test 12.526264209016503\n",
      "MAE train 1.7014157895753554 MAE test 2.481351693462178\n",
      "Epoch 1407 / 10000 loss: 15.981405258178711\n",
      "MSE train 6.018076373693979 MSE test 12.526026158322269\n",
      "MAE train 1.701393073153071 MAE test 2.481323099149904\n",
      "Epoch 1408 / 10000 loss: 15.980751991271973\n",
      "MSE train 6.017905253554709 MSE test 12.525921360923899\n",
      "MAE train 1.7013654534733906 MAE test 2.4813158829544464\n",
      "Epoch 1409 / 10000 loss: 15.980168342590332\n",
      "MSE train 6.017747698614362 MSE test 12.525683276881146\n",
      "MAE train 1.701342740300017 MAE test 2.4812872779412696\n",
      "Epoch 1410 / 10000 loss: 15.979514837265015\n",
      "MSE train 6.017576617799479 MSE test 12.525578463686031\n",
      "MAE train 1.7013151307303538 MAE test 2.481280072951591\n",
      "Epoch 1411 / 10000 loss: 15.9789297580719\n",
      "MSE train 6.0174190578035045 MSE test 12.52534031981382\n",
      "MAE train 1.7012924187951481 MAE test 2.48125146888219\n",
      "Epoch 1412 / 10000 loss: 15.978278160095215\n",
      "MSE train 6.017247971275876 MSE test 12.525235596974296\n",
      "MAE train 1.7012648003871151 MAE test 2.481244264970497\n",
      "Epoch 1413 / 10000 loss: 15.977692127227783\n",
      "MSE train 6.017090384401219 MSE test 12.524997359646393\n",
      "MAE train 1.7012420906066605 MAE test 2.481215635064702\n",
      "Epoch 1414 / 10000 loss: 15.97704005241394\n",
      "MSE train 6.0169192464119625 MSE test 12.524892493336424\n",
      "MAE train 1.7012144631214692 MAE test 2.4812084179240714\n",
      "Epoch 1415 / 10000 loss: 15.976455688476562\n",
      "MSE train 6.01676168716179 MSE test 12.524654264618212\n",
      "MAE train 1.701191756067329 MAE test 2.4811797892554543\n",
      "Epoch 1416 / 10000 loss: 15.975803136825562\n",
      "MSE train 6.016590576947909 MSE test 12.524549314893733\n",
      "MAE train 1.7011641298365714 MAE test 2.4811725588648135\n",
      "Epoch 1417 / 10000 loss: 15.975217342376709\n",
      "MSE train 6.016432977033614 MSE test 12.524310937764287\n",
      "MAE train 1.7011414198512378 MAE test 2.48114391229902\n",
      "Epoch 1418 / 10000 loss: 15.974565982818604\n",
      "MSE train 6.016261880420703 MSE test 12.524205977876122\n",
      "MAE train 1.7011137932591376 MAE test 2.4811366764832785\n",
      "Epoch 1419 / 10000 loss: 15.973980188369751\n",
      "MSE train 6.016104318675127 MSE test 12.523967676028164\n",
      "MAE train 1.7010910848400853 MAE test 2.481108037295186\n",
      "Epoch 1420 / 10000 loss: 15.973327875137329\n",
      "MSE train 6.015933164489252 MSE test 12.52386266479033\n",
      "MAE train 1.701063451167132 MAE test 2.4811008077195433\n",
      "Epoch 1421 / 10000 loss: 15.972742557525635\n",
      "MSE train 6.015775588391498 MSE test 12.52362428927103\n",
      "MAE train 1.7010407358476085 MAE test 2.4810721479539204\n",
      "Epoch 1422 / 10000 loss: 15.972090482711792\n",
      "MSE train 6.015604498197657 MSE test 12.523519205779708\n",
      "MAE train 1.701013111160737 MAE test 2.4810649067532884\n",
      "Epoch 1423 / 10000 loss: 15.971505403518677\n",
      "MSE train 6.015446880902275 MSE test 12.523280803658443\n",
      "MAE train 1.700990400394953 MAE test 2.4810362578274705\n",
      "Epoch 1424 / 10000 loss: 15.970852375030518\n",
      "MSE train 6.015275766784033 MSE test 12.523175626422965\n",
      "MAE train 1.7009627602702027 MAE test 2.481028989990257\n",
      "Epoch 1425 / 10000 loss: 15.970267534255981\n",
      "MSE train 6.015118158467854 MSE test 12.522937057549393\n",
      "MAE train 1.7009400449550376 MAE test 2.4810003160666545\n",
      "Epoch 1426 / 10000 loss: 15.96961522102356\n",
      "MSE train 6.014947012469448 MSE test 12.522831841378483\n",
      "MAE train 1.7009124075176738 MAE test 2.480993045376774\n",
      "Epoch 1427 / 10000 loss: 15.969029426574707\n",
      "MSE train 6.014789440386006 MSE test 12.522593382516575\n",
      "MAE train 1.7008896996302585 MAE test 2.4809643844347744\n",
      "Epoch 1428 / 10000 loss: 15.968377590179443\n",
      "MSE train 6.014618305275242 MSE test 12.522488128029755\n",
      "MAE train 1.7008620578456668 MAE test 2.4809571120871228\n",
      "Epoch 1429 / 10000 loss: 15.967791557312012\n",
      "MSE train 6.014460690735257 MSE test 12.522249493197602\n",
      "MAE train 1.7008393434157754 MAE test 2.480928424734055\n",
      "Epoch 1430 / 10000 loss: 15.96713924407959\n",
      "MSE train 6.014289549166784 MSE test 12.52214413749389\n",
      "MAE train 1.7008116963597535 MAE test 2.480921132660985\n",
      "Epoch 1431 / 10000 loss: 15.966553449630737\n",
      "MSE train 6.014131865102104 MSE test 12.521905443481694\n",
      "MAE train 1.7007889781887418 MAE test 2.48089243202897\n",
      "Epoch 1432 / 10000 loss: 15.965901136398315\n",
      "MSE train 6.013960683415281 MSE test 12.521799884297861\n",
      "MAE train 1.7007613189429474 MAE test 2.48088511566456\n",
      "Epoch 1433 / 10000 loss: 15.965315103530884\n",
      "MSE train 6.013803057593447 MSE test 12.521561265128138\n",
      "MAE train 1.7007386089931735 MAE test 2.4808564324637223\n",
      "Epoch 1434 / 10000 loss: 15.964662790298462\n",
      "MSE train 6.013631872332139 MSE test 12.52145576211114\n",
      "MAE train 1.7007109492636476 MAE test 2.4808491270661377\n",
      "Epoch 1435 / 10000 loss: 15.964077711105347\n",
      "MSE train 6.013474202004495 MSE test 12.521217016681904\n",
      "MAE train 1.7006882348638723 MAE test 2.480820415520671\n",
      "Epoch 1436 / 10000 loss: 15.96342420578003\n",
      "MSE train 6.013302979319011 MSE test 12.521111354172609\n",
      "MAE train 1.7006605606465286 MAE test 2.480813074912973\n",
      "Epoch 1437 / 10000 loss: 15.962838411331177\n",
      "MSE train 6.013145307331163 MSE test 12.520872322554261\n",
      "MAE train 1.7006378467926133 MAE test 2.48078433688914\n",
      "Epoch 1438 / 10000 loss: 15.962186813354492\n",
      "MSE train 6.012974087576902 MSE test 12.52076678090163\n",
      "MAE train 1.7006101732499905 MAE test 2.4807770139637606\n",
      "Epoch 1439 / 10000 loss: 15.961600065231323\n",
      "MSE train 6.0128163484068695 MSE test 12.520527827979203\n",
      "MAE train 1.7005874502980345 MAE test 2.4807482850823246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1440 / 10000 loss: 15.960947036743164\n",
      "MSE train 6.0126451017415645 MSE test 12.520421874187168\n",
      "MAE train 1.7005597689864955 MAE test 2.480740902524313\n",
      "Epoch 1441 / 10000 loss: 15.96036171913147\n",
      "MSE train 6.0124873965446195 MSE test 12.520182839317018\n",
      "MAE train 1.7005370537307027 MAE test 2.4807121430862105\n",
      "Epoch 1442 / 10000 loss: 15.959707736968994\n",
      "MSE train 6.01231612707279 MSE test 12.52007688708848\n",
      "MAE train 1.7005093668565316 MAE test 2.4807047670213977\n",
      "Epoch 1443 / 10000 loss: 15.959120750427246\n",
      "MSE train 6.012158351606889 MSE test 12.519837734593205\n",
      "MAE train 1.7004866440944453 MAE test 2.480675998792512\n",
      "Epoch 1444 / 10000 loss: 15.958468675613403\n",
      "MSE train 6.011987045347811 MSE test 12.519731710989863\n",
      "MAE train 1.7004589444353337 MAE test 2.4806686096629385\n",
      "Epoch 1445 / 10000 loss: 15.957882404327393\n",
      "MSE train 6.011829200014297 MSE test 12.519492466959948\n",
      "MAE train 1.7004362119887506 MAE test 2.480639828460578\n",
      "Epoch 1446 / 10000 loss: 15.957228660583496\n",
      "MSE train 6.011657903273919 MSE test 12.51938631397092\n",
      "MAE train 1.7004085124695596 MAE test 2.480632418895288\n",
      "Epoch 1447 / 10000 loss: 15.956641912460327\n",
      "MSE train 6.011500057330024 MSE test 12.519147011861389\n",
      "MAE train 1.7003857758539265 MAE test 2.480603619878352\n",
      "Epoch 1448 / 10000 loss: 15.955989122390747\n",
      "MSE train 6.011328660302755 MSE test 12.51904070011186\n",
      "MAE train 1.7003580605854212 MAE test 2.4805961990891396\n",
      "Epoch 1449 / 10000 loss: 15.95540189743042\n",
      "MSE train 6.0111707489775466 MSE test 12.518801204583525\n",
      "MAE train 1.7003353179139404 MAE test 2.480567369663647\n",
      "Epoch 1450 / 10000 loss: 15.95474910736084\n",
      "MSE train 6.01099935400046 MSE test 12.51869482265156\n",
      "MAE train 1.7003075968301355 MAE test 2.4805599384325094\n",
      "Epoch 1451 / 10000 loss: 15.954160451889038\n",
      "MSE train 6.0108413991293785 MSE test 12.518455149466064\n",
      "MAE train 1.7002848448453471 MAE test 2.480531083410115\n",
      "Epoch 1452 / 10000 loss: 15.9535071849823\n",
      "MSE train 6.010669867334368 MSE test 12.518348629754852\n",
      "MAE train 1.7002571091114287 MAE test 2.480523624973024\n",
      "Epoch 1453 / 10000 loss: 15.95292043685913\n",
      "MSE train 6.010511935248263 MSE test 12.518108863256662\n",
      "MAE train 1.7002343569024387 MAE test 2.4804947615172086\n",
      "Epoch 1454 / 10000 loss: 15.952266693115234\n",
      "MSE train 6.010340394166031 MSE test 12.518002061970709\n",
      "MAE train 1.7002066123726123 MAE test 2.4804872686196644\n",
      "Epoch 1455 / 10000 loss: 15.95167851448059\n",
      "MSE train 6.010182300638961 MSE test 12.517762222455461\n",
      "MAE train 1.7001838412328822 MAE test 2.480458390078154\n",
      "Epoch 1456 / 10000 loss: 15.951024532318115\n",
      "MSE train 6.010010666552755 MSE test 12.517655344532386\n",
      "MAE train 1.7001560795990323 MAE test 2.480450882755269\n",
      "Epoch 1457 / 10000 loss: 15.950436353683472\n",
      "MSE train 6.009852607624833 MSE test 12.517415187094628\n",
      "MAE train 1.700133314175543 MAE test 2.480421946182747\n",
      "Epoch 1458 / 10000 loss: 15.949781894683838\n",
      "MSE train 6.00968087821349 MSE test 12.517308102190015\n",
      "MAE train 1.700105533810178 MAE test 2.4804144080234827\n",
      "Epoch 1459 / 10000 loss: 15.949193239212036\n",
      "MSE train 6.0095226960569 MSE test 12.517067913175932\n",
      "MAE train 1.7000827510868066 MAE test 2.480385480701658\n",
      "Epoch 1460 / 10000 loss: 15.948538064956665\n",
      "MSE train 6.009350895195486 MSE test 12.516960584523128\n",
      "MAE train 1.700054956825621 MAE test 2.480377908627992\n",
      "Epoch 1461 / 10000 loss: 15.947949647903442\n",
      "MSE train 6.00919266468885 MSE test 12.516720139079258\n",
      "MAE train 1.70003216393515 MAE test 2.48034893590552\n",
      "Epoch 1462 / 10000 loss: 15.947293758392334\n",
      "MSE train 6.00902070929408 MSE test 12.51661272749029\n",
      "MAE train 1.7000043450219078 MAE test 2.4803413543278277\n",
      "Epoch 1463 / 10000 loss: 15.946705102920532\n",
      "MSE train 6.008862362248358 MSE test 12.516372059114067\n",
      "MAE train 1.6999815374614293 MAE test 2.480312344737786\n",
      "Epoch 1464 / 10000 loss: 15.946048259735107\n",
      "MSE train 6.008690343322883 MSE test 12.516264281949788\n",
      "MAE train 1.6999537044923907 MAE test 2.480304702725694\n",
      "Epoch 1465 / 10000 loss: 15.945458889007568\n",
      "MSE train 6.0085318486262045 MSE test 12.516023432628634\n",
      "MAE train 1.6999308755532478 MAE test 2.480275686336282\n",
      "Epoch 1466 / 10000 loss: 15.944802522659302\n",
      "MSE train 6.008359785969899 MSE test 12.515915409317088\n",
      "MAE train 1.6999030356644467 MAE test 2.4802680082210915\n",
      "Epoch 1467 / 10000 loss: 15.944212913513184\n",
      "MSE train 6.008201133596201 MSE test 12.515674282404342\n",
      "MAE train 1.6998801780072577 MAE test 2.480238955373814\n",
      "Epoch 1468 / 10000 loss: 15.943556070327759\n",
      "MSE train 6.008028854731788 MSE test 12.515566062510523\n",
      "MAE train 1.6998523060131492 MAE test 2.4802312326164837\n",
      "Epoch 1469 / 10000 loss: 15.942964792251587\n",
      "MSE train 6.007870129256334 MSE test 12.51532473763733\n",
      "MAE train 1.6998294401878409 MAE test 2.480202153012751\n",
      "Epoch 1470 / 10000 loss: 15.942307949066162\n",
      "MSE train 6.0076977137223295 MSE test 12.515216171968603\n",
      "MAE train 1.6998015411305352 MAE test 2.480194389441328\n",
      "Epoch 1471 / 10000 loss: 15.941715717315674\n",
      "MSE train 6.007538777271184 MSE test 12.514974619551968\n",
      "MAE train 1.6997786357215863 MAE test 2.4801652688241247\n",
      "Epoch 1472 / 10000 loss: 15.941056966781616\n",
      "MSE train 6.007366167997562 MSE test 12.514865527115951\n",
      "MAE train 1.6997507034313022 MAE test 2.480157430907701\n",
      "Epoch 1473 / 10000 loss: 15.940464496612549\n",
      "MSE train 6.007207111113432 MSE test 12.514623670489646\n",
      "MAE train 1.6997277807950613 MAE test 2.4801282643282816\n",
      "Epoch 1474 / 10000 loss: 15.939805269241333\n",
      "MSE train 6.007034348137112 MSE test 12.514514403748402\n",
      "MAE train 1.69969982418654 MAE test 2.4801204092283853\n",
      "Epoch 1475 / 10000 loss: 15.939212560653687\n",
      "MSE train 6.006875013666948 MSE test 12.514272082061757\n",
      "MAE train 1.6996768568998606 MAE test 2.480091168486901\n",
      "Epoch 1476 / 10000 loss: 15.938551425933838\n",
      "MSE train 6.00670203608278 MSE test 12.514162572797213\n",
      "MAE train 1.6996488612497762 MAE test 2.4800832734772276\n",
      "Epoch 1477 / 10000 loss: 15.937957763671875\n",
      "MSE train 6.00654246763338 MSE test 12.513919852198782\n",
      "MAE train 1.6996258605693058 MAE test 2.4800539725326125\n",
      "Epoch 1478 / 10000 loss: 15.937296390533447\n",
      "MSE train 6.0063692568382026 MSE test 12.513809779777759\n",
      "MAE train 1.6995978326795176 MAE test 2.480045993800998\n",
      "Epoch 1479 / 10000 loss: 15.93670129776001\n",
      "MSE train 6.006209419193762 MSE test 12.513566745621032\n",
      "MAE train 1.699574784968094 MAE test 2.4800166470582874\n",
      "Epoch 1480 / 10000 loss: 15.936038970947266\n",
      "MSE train 6.0060359100834955 MSE test 12.513456285780709\n",
      "MAE train 1.699546705404082 MAE test 2.480008614842396\n",
      "Epoch 1481 / 10000 loss: 15.935442209243774\n",
      "MSE train 6.005875797286527 MSE test 12.513212739321235\n",
      "MAE train 1.6995236165883612 MAE test 2.479979196938227\n",
      "Epoch 1482 / 10000 loss: 15.934778928756714\n",
      "MSE train 6.005701979568679 MSE test 12.513101749557388\n",
      "MAE train 1.6994954867340948 MAE test 2.479971099588519\n",
      "Epoch 1483 / 10000 loss: 15.93418025970459\n",
      "MSE train 6.005541552263444 MSE test 12.512857806106203\n",
      "MAE train 1.6994723471701996 MAE test 2.4799416247328403\n",
      "Epoch 1484 / 10000 loss: 15.933515071868896\n",
      "MSE train 6.0053673789873505 MSE test 12.512746358427766\n",
      "MAE train 1.6994441531875284 MAE test 2.479933438535522\n",
      "Epoch 1485 / 10000 loss: 15.932915687561035\n",
      "MSE train 6.005206566261943 MSE test 12.512501777747126\n",
      "MAE train 1.6994209582939914 MAE test 2.4799038625020584\n",
      "Epoch 1486 / 10000 loss: 15.932248830795288\n",
      "MSE train 6.005032000593723 MSE test 12.512389867742103\n",
      "MAE train 1.6993927160690927 MAE test 2.4798956191896377\n",
      "Epoch 1487 / 10000 loss: 15.931647539138794\n",
      "MSE train 6.004870832942498 MSE test 12.512144827469935\n",
      "MAE train 1.6993694693203796 MAE test 2.479865977214085\n",
      "Epoch 1488 / 10000 loss: 15.930978536605835\n",
      "MSE train 6.004695787597104 MSE test 12.512032348294094\n",
      "MAE train 1.6993411455691652 MAE test 2.47985764136455\n",
      "Epoch 1489 / 10000 loss: 15.930375099182129\n",
      "MSE train 6.00453416505764 MSE test 12.511786554640418\n",
      "MAE train 1.6993178186792997 MAE test 2.4798278900565736\n",
      "Epoch 1490 / 10000 loss: 15.929705381393433\n",
      "MSE train 6.004358748257751 MSE test 12.511673378294914\n",
      "MAE train 1.699289435977455 MAE test 2.4798194626119012\n",
      "Epoch 1491 / 10000 loss: 15.929099559783936\n",
      "MSE train 6.004196675999363 MSE test 12.511427153279337\n",
      "MAE train 1.6992660404258544 MAE test 2.479789649378207\n",
      "Epoch 1492 / 10000 loss: 15.928426742553711\n",
      "MSE train 6.004020723118263 MSE test 12.511313489104053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6992375870386034 MAE test 2.479781140841416\n",
      "Epoch 1493 / 10000 loss: 15.927818775177002\n",
      "MSE train 6.003858222806452 MSE test 12.511066665223789\n",
      "MAE train 1.6992141531185674 MAE test 2.4797512438879536\n",
      "Epoch 1494 / 10000 loss: 15.92714262008667\n",
      "MSE train 6.0036818338092965 MSE test 12.510952252064072\n",
      "MAE train 1.6991856381503636 MAE test 2.479742631089831\n",
      "Epoch 1495 / 10000 loss: 15.926533699035645\n",
      "MSE train 6.0035188112575515 MSE test 12.51070490287103\n",
      "MAE train 1.6991621232632517 MAE test 2.4797126345825626\n",
      "Epoch 1496 / 10000 loss: 15.925856590270996\n",
      "MSE train 6.003341934987672 MSE test 12.510590050344842\n",
      "MAE train 1.699133530384184 MAE test 2.4797039667353675\n",
      "Epoch 1497 / 10000 loss: 15.925244569778442\n",
      "MSE train 6.00317848690332 MSE test 12.510342229706264\n",
      "MAE train 1.6991099396151486 MAE test 2.479673917967031\n",
      "Epoch 1498 / 10000 loss: 15.924565076828003\n",
      "MSE train 6.0030012551597185 MSE test 12.510226722741042\n",
      "MAE train 1.6990812793406809 MAE test 2.47966515593809\n",
      "Epoch 1499 / 10000 loss: 15.9239501953125\n",
      "MSE train 6.002837437597009 MSE test 12.509978540577444\n",
      "MAE train 1.699057628257278 MAE test 2.4796350434505228\n",
      "Epoch 1500 / 10000 loss: 15.923269033432007\n",
      "MSE train 6.00265992010128 MSE test 12.509862744975726\n",
      "MAE train 1.6990289171813076 MAE test 2.4796262334576666\n",
      "Epoch 1501 / 10000 loss: 15.922653198242188\n",
      "MSE train 6.002495900600057 MSE test 12.50961427952736\n",
      "MAE train 1.6990052534735491 MAE test 2.4795960744103698\n",
      "Epoch 1502 / 10000 loss: 15.921970844268799\n",
      "MSE train 6.002318213920505 MSE test 12.509498337844025\n",
      "MAE train 1.6989765392619582 MAE test 2.4795872440506312\n",
      "Epoch 1503 / 10000 loss: 15.92135500907898\n",
      "MSE train 6.002154114240431 MSE test 12.509249719502389\n",
      "MAE train 1.6989528545231782 MAE test 2.4795570627635097\n",
      "Epoch 1504 / 10000 loss: 15.920669555664062\n",
      "MSE train 6.001976475956067 MSE test 12.509133730677977\n",
      "MAE train 1.6989241333682779 MAE test 2.4795482241588265\n",
      "Epoch 1505 / 10000 loss: 15.920054197311401\n",
      "MSE train 6.001812435264324 MSE test 12.508885453263833\n",
      "MAE train 1.6989004676718948 MAE test 2.479518080523155\n",
      "Epoch 1506 / 10000 loss: 15.919370651245117\n",
      "MSE train 6.001635018324569 MSE test 12.50876971311015\n",
      "MAE train 1.6988717932041446 MAE test 2.4795092710227538\n",
      "Epoch 1507 / 10000 loss: 15.918755054473877\n",
      "MSE train 6.001471336629371 MSE test 12.508521632977997\n",
      "MAE train 1.6988482086215764 MAE test 2.479479173508499\n",
      "Epoch 1508 / 10000 loss: 15.91807246208191\n",
      "MSE train 6.001294312732538 MSE test 12.508406566037124\n",
      "MAE train 1.6988196107220093 MAE test 2.479470447468236\n",
      "Epoch 1509 / 10000 loss: 15.917457342147827\n",
      "MSE train 6.0011311742261615 MSE test 12.508159265310397\n",
      "MAE train 1.6987961107441087 MAE test 2.4794404581793033\n",
      "Epoch 1510 / 10000 loss: 15.91677737236023\n",
      "MSE train 6.000954668130716 MSE test 12.508044937123753\n",
      "MAE train 1.6987676151682127 MAE test 2.479431843829063\n",
      "Epoch 1511 / 10000 loss: 15.916165590286255\n",
      "MSE train 6.00079211672164 MSE test 12.507798500603267\n",
      "MAE train 1.6987442015662932 MAE test 2.479401962062529\n",
      "Epoch 1512 / 10000 loss: 15.91548776626587\n",
      "MSE train 6.000616340969391 MSE test 12.507685090048883\n",
      "MAE train 1.6987157709613687 MAE test 2.4793934847660406\n",
      "Epoch 1513 / 10000 loss: 15.914878606796265\n",
      "MSE train 6.000454417080021 MSE test 12.507439843189047\n",
      "MAE train 1.6986924223997828 MAE test 2.479363778384066\n",
      "Epoch 1514 / 10000 loss: 15.914204359054565\n",
      "MSE train 6.000279345185373 MSE test 12.507327545754563\n",
      "MAE train 1.6986641021631341 MAE test 2.4793554598543115\n",
      "Epoch 1515 / 10000 loss: 15.913598775863647\n",
      "MSE train 6.000118095929738 MSE test 12.507083271115096\n",
      "MAE train 1.6986408629201697 MAE test 2.479325887522961\n",
      "Epoch 1516 / 10000 loss: 15.912927865982056\n",
      "MSE train 5.999943637688277 MSE test 12.50697213945207\n",
      "MAE train 1.6986126289707673 MAE test 2.479317748849276\n",
      "Epoch 1517 / 10000 loss: 15.912325859069824\n",
      "MSE train 5.99978298048561 MSE test 12.50672910344415\n",
      "MAE train 1.6985894983536787 MAE test 2.479288361986893\n",
      "Epoch 1518 / 10000 loss: 15.91165804862976\n",
      "MSE train 5.999609061436366 MSE test 12.506619093250395\n",
      "MAE train 1.6985613778059359 MAE test 2.4792803702642745\n",
      "Epoch 1519 / 10000 loss: 15.911058187484741\n",
      "MSE train 5.999448988968468 MSE test 12.50637709947076\n",
      "MAE train 1.6985383499574438 MAE test 2.47925113700858\n",
      "Epoch 1520 / 10000 loss: 15.910394191741943\n",
      "MSE train 5.999275567264992 MSE test 12.506268240791782\n",
      "MAE train 1.6985103283836047 MAE test 2.4792433186241936\n",
      "Epoch 1521 / 10000 loss: 15.909797668457031\n",
      "MSE train 5.99911593497367 MSE test 12.506027355748483\n",
      "MAE train 1.6984873849749371 MAE test 2.479214249697925\n",
      "Epoch 1522 / 10000 loss: 15.90913462638855\n",
      "MSE train 5.99894287904062 MSE test 12.505919295339906\n",
      "MAE train 1.6984594177252375 MAE test 2.479206563389905\n",
      "Epoch 1523 / 10000 loss: 15.908540725708008\n",
      "MSE train 5.998783612905588 MSE test 12.5056793634516\n",
      "MAE train 1.6984365250019138 MAE test 2.4791776456873214\n",
      "Epoch 1524 / 10000 loss: 15.90787935256958\n",
      "MSE train 5.998610888739466 MSE test 12.50557210069044\n",
      "MAE train 1.6984086058196906 MAE test 2.479170077574815\n",
      "Epoch 1525 / 10000 loss: 15.907286643981934\n",
      "MSE train 5.998451941725185 MSE test 12.505332942188575\n",
      "MAE train 1.69838577433373 MAE test 2.4791412508076025\n",
      "Epoch 1526 / 10000 loss: 15.906627893447876\n",
      "MSE train 5.998279424925281 MSE test 12.50522653579265\n",
      "MAE train 1.6983578880065282 MAE test 2.4791338261899583\n",
      "Epoch 1527 / 10000 loss: 15.906035661697388\n",
      "MSE train 5.998120663915993 MSE test 12.504988071510011\n",
      "MAE train 1.6983350718038792 MAE test 2.4791051181865784\n",
      "Epoch 1528 / 10000 loss: 15.905378103256226\n",
      "MSE train 5.997948365901076 MSE test 12.504882231969297\n",
      "MAE train 1.6983072151921248 MAE test 2.479097777540113\n",
      "Epoch 1529 / 10000 loss: 15.904787540435791\n",
      "MSE train 5.997789752642308 MSE test 12.504644192197441\n",
      "MAE train 1.6982844175239848 MAE test 2.479069140768592\n",
      "Epoch 1530 / 10000 loss: 15.904130697250366\n",
      "MSE train 5.997617679927793 MSE test 12.50453896993671\n",
      "MAE train 1.6982565857306027 MAE test 2.4790618997062417\n",
      "Epoch 1531 / 10000 loss: 15.90354061126709\n",
      "MSE train 5.997459184841323 MSE test 12.504301333672194\n",
      "MAE train 1.6982338062427709 MAE test 2.479033315874734\n",
      "Epoch 1532 / 10000 loss: 15.902883768081665\n",
      "MSE train 5.997287214700242 MSE test 12.504196473313524\n",
      "MAE train 1.6982059800186107 MAE test 2.4790261295245477\n",
      "Epoch 1533 / 10000 loss: 15.902294397354126\n",
      "MSE train 5.997128882130145 MSE test 12.503959271746334\n",
      "MAE train 1.6981832155469312 MAE test 2.4789976093564996\n",
      "Epoch 1534 / 10000 loss: 15.901639461517334\n",
      "MSE train 5.996956897318498 MSE test 12.503854726915131\n",
      "MAE train 1.698155377229559 MAE test 2.4789904836014243\n",
      "Epoch 1535 / 10000 loss: 15.901049613952637\n",
      "MSE train 5.996798634966313 MSE test 12.503617936880985\n",
      "MAE train 1.698132621656189 MAE test 2.4789620462409916\n",
      "Epoch 1536 / 10000 loss: 15.900395393371582\n",
      "MSE train 5.996626749462855 MSE test 12.503513578083842\n",
      "MAE train 1.6981047984500321 MAE test 2.478954939892615\n",
      "Epoch 1537 / 10000 loss: 15.89980673789978\n",
      "MSE train 5.996468570766304 MSE test 12.50327695102828\n",
      "MAE train 1.698082056313453 MAE test 2.478926524415264\n",
      "Epoch 1538 / 10000 loss: 15.89915132522583\n",
      "MSE train 5.996296745584758 MSE test 12.50317270855458\n",
      "MAE train 1.698054236239863 MAE test 2.478919449913014\n",
      "Epoch 1539 / 10000 loss: 15.898562908172607\n",
      "MSE train 5.996138467081634 MSE test 12.50293633042871\n",
      "MAE train 1.6980314750024164 MAE test 2.4788910788160714\n",
      "Epoch 1540 / 10000 loss: 15.897907733917236\n",
      "MSE train 5.995966641368693 MSE test 12.502832178625978\n",
      "MAE train 1.6980036501845943 MAE test 2.47888402448891\n",
      "Epoch 1541 / 10000 loss: 15.897319078445435\n",
      "MSE train 5.9958084093195625 MSE test 12.502595949300868\n",
      "MAE train 1.6979808939098902 MAE test 2.4788556757018267\n",
      "Epoch 1542 / 10000 loss: 15.896664381027222\n",
      "MSE train 5.9956365476716496 MSE test 12.502491909923275\n",
      "MAE train 1.6979530614366865 MAE test 2.4788486597874027\n",
      "Epoch 1543 / 10000 loss: 15.89607548713684\n",
      "MSE train 5.995478307329149 MSE test 12.502255609022164\n",
      "MAE train 1.6979303019861136 MAE test 2.478820292738365\n",
      "Epoch 1544 / 10000 loss: 15.89542007446289\n",
      "MSE train 5.995306378660903 MSE test 12.50215170317729\n",
      "MAE train 1.6979024548918569 MAE test 2.4788132861578394\n",
      "Epoch 1545 / 10000 loss: 15.894831418991089\n",
      "MSE train 5.995148045167458 MSE test 12.501915427854602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6978796783914085 MAE test 2.478784951337363\n",
      "Epoch 1546 / 10000 loss: 15.89417552947998\n",
      "MSE train 5.994976030820388 MSE test 12.50181156131563\n",
      "MAE train 1.6978518057485608 MAE test 2.4787779539511368\n",
      "Epoch 1547 / 10000 loss: 15.893585920333862\n",
      "MSE train 5.994817517625868 MSE test 12.501575298272044\n",
      "MAE train 1.6978290000210563 MAE test 2.4787496251006615\n",
      "Epoch 1548 / 10000 loss: 15.892929792404175\n",
      "MSE train 5.994645351066386 MSE test 12.501471429193167\n",
      "MAE train 1.697801093671525 MAE test 2.4787426497058265\n",
      "Epoch 1549 / 10000 loss: 15.89233946800232\n",
      "MSE train 5.99448663142867 MSE test 12.501235210020068\n",
      "MAE train 1.6977782413140938 MAE test 2.478714313886918\n",
      "Epoch 1550 / 10000 loss: 15.891682147979736\n",
      "MSE train 5.994314238296318 MSE test 12.501131185571426\n",
      "MAE train 1.6977502937162798 MAE test 2.478707326816913\n",
      "Epoch 1551 / 10000 loss: 15.891091346740723\n",
      "MSE train 5.994155255226596 MSE test 12.500894875489797\n",
      "MAE train 1.6977273890187914 MAE test 2.4786790017491867\n",
      "Epoch 1552 / 10000 loss: 15.890432834625244\n",
      "MSE train 5.993982488184722 MSE test 12.500790676257845\n",
      "MAE train 1.697699376314242 MAE test 2.4786719882756434\n",
      "Epoch 1553 / 10000 loss: 15.88983941078186\n",
      "MSE train 5.993823141114973 MSE test 12.500554263045741\n",
      "MAE train 1.6976764082593814 MAE test 2.4786436676173302\n",
      "Epoch 1554 / 10000 loss: 15.889180183410645\n",
      "MSE train 5.99364987931132 MSE test 12.500450104339755\n",
      "MAE train 1.6976483110360194 MAE test 2.478636683508472\n",
      "Epoch 1555 / 10000 loss: 15.888585329055786\n",
      "MSE train 5.993490023890927 MSE test 12.50021343834884\n",
      "MAE train 1.6976252563152896 MAE test 2.4786083305361513\n",
      "Epoch 1556 / 10000 loss: 15.887922763824463\n",
      "MSE train 5.993316125302678 MSE test 12.500109197789262\n",
      "MAE train 1.697597049066248 MAE test 2.4786013495744434\n",
      "Epoch 1557 / 10000 loss: 15.887324333190918\n",
      "MSE train 5.993155513102919 MSE test 12.499872247157466\n",
      "MAE train 1.6975738570239627 MAE test 2.478572967981003\n",
      "Epoch 1558 / 10000 loss: 15.886659622192383\n",
      "MSE train 5.992980718412862 MSE test 12.499767715707286\n",
      "MAE train 1.6975454906280942 MAE test 2.478565963196964\n",
      "Epoch 1559 / 10000 loss: 15.886057615280151\n",
      "MSE train 5.992819021328998 MSE test 12.499530668452941\n",
      "MAE train 1.6975221264207223 MAE test 2.4785375911745686\n",
      "Epoch 1560 / 10000 loss: 15.885387659072876\n",
      "MSE train 5.992643015105464 MSE test 12.499425803165472\n",
      "MAE train 1.697493546745236 MAE test 2.4785305677984777\n",
      "Epoch 1561 / 10000 loss: 15.88478136062622\n",
      "MSE train 5.992479837242913 MSE test 12.499188447766251\n",
      "MAE train 1.6974699163671005 MAE test 2.4785021651269727\n",
      "Epoch 1562 / 10000 loss: 15.884105205535889\n",
      "MSE train 5.99230215760696 MSE test 12.499083194710186\n",
      "MAE train 1.6974410464875525 MAE test 2.478495110520768\n",
      "Epoch 1563 / 10000 loss: 15.883492469787598\n",
      "MSE train 5.992136912305193 MSE test 12.498845335744257\n",
      "MAE train 1.6974170800642088 MAE test 2.478466668139137\n",
      "Epoch 1564 / 10000 loss: 15.88280701637268\n",
      "MSE train 5.9919567036234875 MSE test 12.498739596897243\n",
      "MAE train 1.6973878016874067 MAE test 2.478459578716281\n",
      "Epoch 1565 / 10000 loss: 15.882183313369751\n",
      "MSE train 5.991788474814799 MSE test 12.498501193869396\n",
      "MAE train 1.69736333361597 MAE test 2.478431092179392\n",
      "Epoch 1566 / 10000 loss: 15.881487131118774\n",
      "MSE train 5.991604646859281 MSE test 12.498394768401592\n",
      "MAE train 1.697333439495541 MAE test 2.478423938714165\n",
      "Epoch 1567 / 10000 loss: 15.880847692489624\n",
      "MSE train 5.991432049165862 MSE test 12.498155695749794\n",
      "MAE train 1.6973082417538377 MAE test 2.4783954112710815\n",
      "Epoch 1568 / 10000 loss: 15.880133152008057\n",
      "MSE train 5.9912429561413845 MSE test 12.498048449439487\n",
      "MAE train 1.6972774926716994 MAE test 2.478388187236807\n",
      "Epoch 1569 / 10000 loss: 15.879473447799683\n",
      "MSE train 5.991064120261351 MSE test 12.497808431450709\n",
      "MAE train 1.6972512775815176 MAE test 2.478359576385397\n",
      "Epoch 1570 / 10000 loss: 15.878734111785889\n",
      "MSE train 5.990867703954851 MSE test 12.497700177651796\n",
      "MAE train 1.6972193364170916 MAE test 2.4783522849328645\n",
      "Epoch 1571 / 10000 loss: 15.878044366836548\n",
      "MSE train 5.99068039743804 MSE test 12.497459100648937\n",
      "MAE train 1.6971917202711013 MAE test 2.4783235828549572\n",
      "Epoch 1572 / 10000 loss: 15.877269268035889\n",
      "MSE train 5.990474809048938 MSE test 12.497349856810413\n",
      "MAE train 1.6971582657835913 MAE test 2.4783162133220915\n",
      "Epoch 1573 / 10000 loss: 15.876537799835205\n",
      "MSE train 5.990278333907558 MSE test 12.497107992683286\n",
      "MAE train 1.697129185295767 MAE test 2.4782874502161234\n",
      "Epoch 1574 / 10000 loss: 15.875718116760254\n",
      "MSE train 5.990064912234133 MSE test 12.496998263441176\n",
      "MAE train 1.697094343461182 MAE test 2.4782800471789734\n",
      "Epoch 1575 / 10000 loss: 15.874942064285278\n",
      "MSE train 5.989863744819283 MSE test 12.496756281965531\n",
      "MAE train 1.697064312396494 MAE test 2.478251266881819\n",
      "Epoch 1576 / 10000 loss: 15.874082803726196\n",
      "MSE train 5.989650625089227 MSE test 12.496647331815186\n",
      "MAE train 1.6970292309891288 MAE test 2.478243946216882\n",
      "Epoch 1577 / 10000 loss: 15.873284339904785\n",
      "MSE train 5.989455589404168 MSE test 12.496407050191193\n",
      "MAE train 1.6969999007704337 MAE test 2.4782153492560095\n",
      "Epoch 1578 / 10000 loss: 15.872426748275757\n",
      "MSE train 5.9892534518284 MSE test 12.49630069833486\n",
      "MAE train 1.696966667633928 MAE test 2.478208265871328\n",
      "Epoch 1579 / 10000 loss: 15.871655464172363\n",
      "MSE train 5.989072020028097 MSE test 12.496063571440192\n",
      "MAE train 1.6969398459504752 MAE test 2.4781799680396532\n",
      "Epoch 1580 / 10000 loss: 15.870850563049316\n",
      "MSE train 5.988883387967214 MSE test 12.495960079095173\n",
      "MAE train 1.6969090686194495 MAE test 2.4781731231442103\n",
      "Epoch 1581 / 10000 loss: 15.870144605636597\n",
      "MSE train 5.988713643372444 MSE test 12.495726021632715\n",
      "MAE train 1.6968841860462 MAE test 2.478145089568256\n",
      "Epoch 1582 / 10000 loss: 15.869404077529907\n",
      "MSE train 5.988534289147638 MSE test 12.495624768220924\n",
      "MAE train 1.696854928822183 MAE test 2.478138453619393\n",
      "Epoch 1583 / 10000 loss: 15.86875581741333\n",
      "MSE train 5.988371459389536 MSE test 12.495392414818372\n",
      "MAE train 1.6968312507211494 MAE test 2.478110566757999\n",
      "Epoch 1584 / 10000 loss: 15.868059635162354\n",
      "MSE train 5.98819704619473 MSE test 12.495292640110701\n",
      "MAE train 1.696802799827492 MAE test 2.4781040591189063\n",
      "Epoch 1585 / 10000 loss: 15.867442607879639\n",
      "MSE train 5.988037883758491 MSE test 12.495061057440076\n",
      "MAE train 1.6967797442099573 MAE test 2.4780762287510054\n",
      "Epoch 1586 / 10000 loss: 15.866771221160889\n",
      "MSE train 5.987866110820024 MSE test 12.494961728870937\n",
      "MAE train 1.6967517238178726 MAE test 2.4780697571589276\n",
      "Epoch 1587 / 10000 loss: 15.866174459457397\n",
      "MSE train 5.987708770019023 MSE test 12.494730354069263\n",
      "MAE train 1.696728965369699 MAE test 2.478041940834902\n",
      "Epoch 1588 / 10000 loss: 15.865513324737549\n",
      "MSE train 5.987538337138644 MSE test 12.49463109740047\n",
      "MAE train 1.6967011849607971 MAE test 2.478035466141825\n",
      "Epoch 1589 / 10000 loss: 15.864924430847168\n",
      "MSE train 5.987381990678404 MSE test 12.494399501338561\n",
      "MAE train 1.6966785927139159 MAE test 2.4780076034841727\n",
      "Epoch 1590 / 10000 loss: 15.86427116394043\n",
      "MSE train 5.987212313784267 MSE test 12.494300087729368\n",
      "MAE train 1.696650949263226 MAE test 2.478001101385807\n",
      "Epoch 1591 / 10000 loss: 15.863686800003052\n",
      "MSE train 5.987056510841779 MSE test 12.49406834809726\n",
      "MAE train 1.6966284753415222 MAE test 2.4779732377504526\n",
      "Epoch 1592 / 10000 loss: 15.863037109375\n",
      "MSE train 5.986887216583802 MSE test 12.493968583720532\n",
      "MAE train 1.6966009157503312 MAE test 2.477966686300179\n",
      "Epoch 1593 / 10000 loss: 15.86245584487915\n",
      "MSE train 5.9867317053189835 MSE test 12.493736581835702\n",
      "MAE train 1.6965784870071108 MAE test 2.477938802804996\n",
      "Epoch 1594 / 10000 loss: 15.861809015274048\n",
      "MSE train 5.98656274438979 MSE test 12.493636672334873\n",
      "MAE train 1.6965509687764033 MAE test 2.4779322554774375\n",
      "Epoch 1595 / 10000 loss: 15.861228704452515\n",
      "MSE train 5.986407487284541 MSE test 12.493404379750144\n",
      "MAE train 1.6965285803037422 MAE test 2.4779043196383257\n",
      "Epoch 1596 / 10000 loss: 15.860582828521729\n",
      "MSE train 5.986238629813664 MSE test 12.493304049054858\n",
      "MAE train 1.6965010709499284 MAE test 2.47789772061586\n",
      "Epoch 1597 / 10000 loss: 15.860003471374512\n",
      "MSE train 5.986083442327188 MSE test 12.493071644851389\n",
      "MAE train 1.6964786989439242 MAE test 2.477869776734237\n",
      "Epoch 1598 / 10000 loss: 15.859359502792358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.985914658699295 MSE test 12.492971142867779\n",
      "MAE train 1.6964511983051649 MAE test 2.477863175709876\n",
      "Epoch 1599 / 10000 loss: 15.8587806224823\n",
      "MSE train 5.985759603875336 MSE test 12.492738521690084\n",
      "MAE train 1.6964288479244922 MAE test 2.4778352120501377\n",
      "Epoch 1600 / 10000 loss: 15.858136415481567\n",
      "MSE train 5.985590919806748 MSE test 12.492637914853868\n",
      "MAE train 1.6964013597507064 MAE test 2.4778285857543576\n",
      "Epoch 1601 / 10000 loss: 15.857560157775879\n",
      "MSE train 5.985435838351821 MSE test 12.492404961530848\n",
      "MAE train 1.6963790070604072 MAE test 2.47780058134452\n",
      "Epoch 1602 / 10000 loss: 15.856914520263672\n",
      "MSE train 5.985267191102396 MSE test 12.492304218761795\n",
      "MAE train 1.696351531326992 MAE test 2.4777939475170556\n",
      "Epoch 1603 / 10000 loss: 15.856337308883667\n",
      "MSE train 5.985112162305679 MSE test 12.492071221999886\n",
      "MAE train 1.696329190417209 MAE test 2.477765936746207\n",
      "Epoch 1604 / 10000 loss: 15.85569429397583\n",
      "MSE train 5.984943514888496 MSE test 12.49197034286177\n",
      "MAE train 1.6963017116258252 MAE test 2.47775927662931\n",
      "Epoch 1605 / 10000 loss: 15.855116844177246\n",
      "MSE train 5.984788468274389 MSE test 12.491737220608103\n",
      "MAE train 1.6962793684589657 MAE test 2.4777312545000547\n",
      "Epoch 1606 / 10000 loss: 15.854474544525146\n",
      "MSE train 5.984619889093676 MSE test 12.491636093447013\n",
      "MAE train 1.6962519009108397 MAE test 2.477724586902012\n",
      "Epoch 1607 / 10000 loss: 15.853897094726562\n",
      "MSE train 5.984464890410572 MSE test 12.491402771531803\n",
      "MAE train 1.696229568540979 MAE test 2.477696530714273\n",
      "Epoch 1608 / 10000 loss: 15.853253841400146\n",
      "MSE train 5.984296273576557 MSE test 12.49130171869582\n",
      "MAE train 1.6962020931108368 MAE test 2.4776898772526024\n",
      "Epoch 1609 / 10000 loss: 15.8526771068573\n",
      "MSE train 5.984141280119872 MSE test 12.491068433178063\n",
      "MAE train 1.6961797630880564 MAE test 2.4776618241079014\n",
      "Epoch 1610 / 10000 loss: 15.852034091949463\n",
      "MSE train 5.983972661751961 MSE test 12.490967206152606\n",
      "MAE train 1.6961522866949854 MAE test 2.477655136884448\n",
      "Epoch 1611 / 10000 loss: 15.851457834243774\n",
      "MSE train 5.983817666806971 MSE test 12.490733819280704\n",
      "MAE train 1.696129958656761 MAE test 2.477627089797556\n",
      "Epoch 1612 / 10000 loss: 15.850815057754517\n",
      "MSE train 5.983649101902989 MSE test 12.490632469909375\n",
      "MAE train 1.6961024868586536 MAE test 2.4776203802443626\n",
      "Epoch 1613 / 10000 loss: 15.850238561630249\n",
      "MSE train 5.983494031547218 MSE test 12.490398993950274\n",
      "MAE train 1.696080148531221 MAE test 2.4775923117637535\n",
      "Epoch 1614 / 10000 loss: 15.849596500396729\n",
      "MSE train 5.983325442113172 MSE test 12.490297639963542\n",
      "MAE train 1.6960526786601062 MAE test 2.4775856234928266\n",
      "Epoch 1615 / 10000 loss: 15.849020004272461\n",
      "MSE train 5.983170390327854 MSE test 12.490064119748663\n",
      "MAE train 1.6960303473122726 MAE test 2.477557536026676\n",
      "Epoch 1616 / 10000 loss: 15.848377227783203\n",
      "MSE train 5.9830018118720885 MSE test 12.489962684516424\n",
      "MAE train 1.696002872080588 MAE test 2.4775508268723683\n",
      "Epoch 1617 / 10000 loss: 15.847801446914673\n",
      "MSE train 5.982846816509927 MSE test 12.48972917099526\n",
      "MAE train 1.6959805495245686 MAE test 2.477522743690269\n",
      "Epoch 1618 / 10000 loss: 15.847159147262573\n",
      "MSE train 5.982678194003673 MSE test 12.48962755276173\n",
      "MAE train 1.6959530676023233 MAE test 2.4775160118867277\n",
      "Epoch 1619 / 10000 loss: 15.846582651138306\n",
      "MSE train 5.982523215915885 MSE test 12.489394098195898\n",
      "MAE train 1.6959307518262148 MAE test 2.477487956240348\n",
      "Epoch 1620 / 10000 loss: 15.845941305160522\n",
      "MSE train 5.982354617223465 MSE test 12.489292480865158\n",
      "MAE train 1.6959032716444422 MAE test 2.477481212715511\n",
      "Epoch 1621 / 10000 loss: 15.845365047454834\n",
      "MSE train 5.982199588014815 MSE test 12.489058775157995\n",
      "MAE train 1.6958809438043483 MAE test 2.47745311842626\n",
      "Epoch 1622 / 10000 loss: 15.844722986221313\n",
      "MSE train 5.982030960206585 MSE test 12.488956980172379\n",
      "MAE train 1.695853461830355 MAE test 2.4774463681877346\n",
      "Epoch 1623 / 10000 loss: 15.844147443771362\n",
      "MSE train 5.9818759955766705 MSE test 12.48872348184465\n",
      "MAE train 1.6958311491383502 MAE test 2.4774182830781015\n",
      "Epoch 1624 / 10000 loss: 15.843504667282104\n",
      "MSE train 5.981707337350224 MSE test 12.488621669549557\n",
      "MAE train 1.6958036617765293 MAE test 2.477411526857113\n",
      "Epoch 1625 / 10000 loss: 15.84292984008789\n",
      "MSE train 5.981552364358319 MSE test 12.488388002168435\n",
      "MAE train 1.6957813411374343 MAE test 2.477383432027669\n",
      "Epoch 1626 / 10000 loss: 15.84228777885437\n",
      "MSE train 5.981383773694904 MSE test 12.488286244159623\n",
      "MAE train 1.6957538628736084 MAE test 2.4773766906026213\n",
      "Epoch 1627 / 10000 loss: 15.841712236404419\n",
      "MSE train 5.981228754252606 MSE test 12.488052579838575\n",
      "MAE train 1.6957315429143243 MAE test 2.4773485953906293\n",
      "Epoch 1628 / 10000 loss: 15.84106993675232\n",
      "MSE train 5.981060133851054 MSE test 12.487950787245138\n",
      "MAE train 1.6957040588350738 MAE test 2.477341843943986\n",
      "Epoch 1629 / 10000 loss: 15.840494394302368\n",
      "MSE train 5.980905118695076 MSE test 12.487716979461057\n",
      "MAE train 1.6956817387168224 MAE test 2.4773137159748164\n",
      "Epoch 1630 / 10000 loss: 15.839853048324585\n",
      "MSE train 5.980736498817208 MSE test 12.487615189713317\n",
      "MAE train 1.6956542572383495 MAE test 2.477306978221812\n",
      "Epoch 1631 / 10000 loss: 15.839276313781738\n",
      "MSE train 5.980581489983156 MSE test 12.487381383111206\n",
      "MAE train 1.6956319377043108 MAE test 2.4772788514012274\n",
      "Epoch 1632 / 10000 loss: 15.838634729385376\n",
      "MSE train 5.980412946061021 MSE test 12.487279555901559\n",
      "MAE train 1.6956044632503244 MAE test 2.477272107868189\n",
      "Epoch 1633 / 10000 loss: 15.838059902191162\n",
      "MSE train 5.98025793039884 MSE test 12.487045568198123\n",
      "MAE train 1.6955821470771935 MAE test 2.4772439563281154\n",
      "Epoch 1634 / 10000 loss: 15.83741807937622\n",
      "MSE train 5.98008925754607 MSE test 12.486943678435741\n",
      "MAE train 1.6955546572245657 MAE test 2.477237201425951\n",
      "Epoch 1635 / 10000 loss: 15.836843252182007\n",
      "MSE train 5.9799343025847955 MSE test 12.486709714592894\n",
      "MAE train 1.6955323447359139 MAE test 2.4772090511183604\n",
      "Epoch 1636 / 10000 loss: 15.836201190948486\n",
      "MSE train 5.979765702304685 MSE test 12.486607806314236\n",
      "MAE train 1.6955048660987244 MAE test 2.4772022875428403\n",
      "Epoch 1637 / 10000 loss: 15.835626125335693\n",
      "MSE train 5.979610683240548 MSE test 12.486373920499897\n",
      "MAE train 1.69548254961091 MAE test 2.47717414866118\n",
      "Epoch 1638 / 10000 loss: 15.834984302520752\n",
      "MSE train 5.979442084620038 MSE test 12.486271961659526\n",
      "MAE train 1.69545506815493 MAE test 2.4771673925269604\n",
      "Epoch 1639 / 10000 loss: 15.834409475326538\n",
      "MSE train 5.979287064152395 MSE test 12.486038051179943\n",
      "MAE train 1.6954327542808174 MAE test 2.477139248921603\n",
      "Epoch 1640 / 10000 loss: 15.833768129348755\n",
      "MSE train 5.979118496358001 MSE test 12.485935894304253\n",
      "MAE train 1.6954052744562487 MAE test 2.4771324599393507\n",
      "Epoch 1641 / 10000 loss: 15.833193063735962\n",
      "MSE train 5.97896349738324 MSE test 12.485702036968435\n",
      "MAE train 1.6953829636339017 MAE test 2.4771043208226144\n",
      "Epoch 1642 / 10000 loss: 15.83255124092102\n",
      "MSE train 5.978794887343471 MSE test 12.485599938996302\n",
      "MAE train 1.6953554796445593 MAE test 2.477097539187485\n",
      "Epoch 1643 / 10000 loss: 15.831976652145386\n",
      "MSE train 5.978639877871422 MSE test 12.485366025059376\n",
      "MAE train 1.6953331732091466 MAE test 2.4770693992471458\n",
      "Epoch 1644 / 10000 loss: 15.831334829330444\n",
      "MSE train 5.978471264992644 MSE test 12.485263821898716\n",
      "MAE train 1.6953056859536821 MAE test 2.47706259878693\n",
      "Epoch 1645 / 10000 loss: 15.830759525299072\n",
      "MSE train 5.97831631216724 MSE test 12.485029946458155\n",
      "MAE train 1.6952833868467054 MAE test 2.4770344635795185\n",
      "Epoch 1646 / 10000 loss: 15.830118656158447\n",
      "MSE train 5.978147654894066 MSE test 12.484927788325797\n",
      "MAE train 1.695255892998759 MAE test 2.477027673955022\n",
      "Epoch 1647 / 10000 loss: 15.829544305801392\n",
      "MSE train 5.977992707654635 MSE test 12.484693729240522\n",
      "MAE train 1.6952335943272698 MAE test 2.4769995043375297\n",
      "Epoch 1648 / 10000 loss: 15.82890248298645\n",
      "MSE train 5.977824135007034 MSE test 12.484591612641948\n",
      "MAE train 1.6952061148799207 MAE test 2.4769927277159325\n",
      "Epoch 1649 / 10000 loss: 15.828326940536499\n",
      "MSE train 5.977669105239821 MSE test 12.484357588544977\n",
      "MAE train 1.6951838051915211 MAE test 2.47696455919723\n",
      "Epoch 1650 / 10000 loss: 15.827686548233032\n",
      "MSE train 5.977500492302979 MSE test 12.484255406740493\n",
      "MAE train 1.6951563158676604 MAE test 2.476957775798469\n",
      "Epoch 1651 / 10000 loss: 15.827110767364502\n",
      "MSE train 5.977345520686981 MSE test 12.484021468325542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6951340157023567 MAE test 2.4769296226426945\n",
      "Epoch 1652 / 10000 loss: 15.826470375061035\n",
      "MSE train 5.977176911026289 MSE test 12.483919259143189\n",
      "MAE train 1.6951065271255255 MAE test 2.476922831852952\n",
      "Epoch 1653 / 10000 loss: 15.825895071029663\n",
      "MSE train 5.9770219100960205 MSE test 12.483685166450083\n",
      "MAE train 1.6950842235079064 MAE test 2.4768946490133352\n",
      "Epoch 1654 / 10000 loss: 15.825255155563354\n",
      "MSE train 5.976853315943523 MSE test 12.483582866302733\n",
      "MAE train 1.695056734796589 MAE test 2.4768878558057392\n",
      "Epoch 1655 / 10000 loss: 15.824678659439087\n",
      "MSE train 5.976698340458775 MSE test 12.483348955502546\n",
      "MAE train 1.6950344356172669 MAE test 2.4768597073054006\n",
      "Epoch 1656 / 10000 loss: 15.824038982391357\n",
      "MSE train 5.976529687580522 MSE test 12.483246793244255\n",
      "MAE train 1.6950069417585898 MAE test 2.476852924413469\n",
      "Epoch 1657 / 10000 loss: 15.82346487045288\n",
      "MSE train 5.976374755478314 MSE test 12.483012643095167\n",
      "MAE train 1.6949846470611638 MAE test 2.4768247346168786\n",
      "Epoch 1658 / 10000 loss: 15.82282304763794\n",
      "MSE train 5.976206112012499 MSE test 12.482910402929306\n",
      "MAE train 1.6949571472478373 MAE test 2.4768179529455554\n",
      "Epoch 1659 / 10000 loss: 15.822248220443726\n",
      "MSE train 5.976051225391108 MSE test 12.482676325802352\n",
      "MAE train 1.6949348637236623 MAE test 2.4767897772577485\n",
      "Epoch 1660 / 10000 loss: 15.8216073513031\n",
      "MSE train 5.97588256374648 MSE test 12.482573996706876\n",
      "MAE train 1.6949073607077711 MAE test 2.4767829697394954\n",
      "Epoch 1661 / 10000 loss: 15.821033000946045\n",
      "MSE train 5.975727640085422 MSE test 12.482339930297467\n",
      "MAE train 1.6948850727923515 MAE test 2.4767547925578217\n",
      "Epoch 1662 / 10000 loss: 15.82039213180542\n",
      "MSE train 5.975559023881764 MSE test 12.48223765172218\n",
      "MAE train 1.6948575747658496 MAE test 2.476748008351411\n",
      "Epoch 1663 / 10000 loss: 15.819817543029785\n",
      "MSE train 5.9754040062911615 MSE test 12.48200358772869\n",
      "MAE train 1.6948352796364836 MAE test 2.476719822982311\n",
      "Epoch 1664 / 10000 loss: 15.81917691230774\n",
      "MSE train 5.975235383216523 MSE test 12.481901255530252\n",
      "MAE train 1.6948077761605078 MAE test 2.4767130327695157\n",
      "Epoch 1665 / 10000 loss: 15.818601369857788\n",
      "MSE train 5.975080477062622 MSE test 12.481667267276995\n",
      "MAE train 1.6947854954788697 MAE test 2.476684850039202\n",
      "Epoch 1666 / 10000 loss: 15.8179612159729\n",
      "MSE train 5.974911879187084 MSE test 12.481564789406784\n",
      "MAE train 1.6947579950219882 MAE test 2.4766780381375773\n",
      "Epoch 1667 / 10000 loss: 15.817385911941528\n",
      "MSE train 5.97475686806436 MSE test 12.481330637385081\n",
      "MAE train 1.6947356978220804 MAE test 2.476649847013335\n",
      "Epoch 1668 / 10000 loss: 15.816746473312378\n",
      "MSE train 5.97458825881475 MSE test 12.481228425556353\n",
      "MAE train 1.6947081958240053 MAE test 2.4766430598441755\n",
      "Epoch 1669 / 10000 loss: 15.816170692443848\n",
      "MSE train 5.974433271753978 MSE test 12.480994314321276\n",
      "MAE train 1.6946859007380162 MAE test 2.476614865081722\n",
      "Epoch 1670 / 10000 loss: 15.815530776977539\n",
      "MSE train 5.9742646962088495 MSE test 12.480891878414004\n",
      "MAE train 1.6946584015284194 MAE test 2.4766080617641855\n",
      "Epoch 1671 / 10000 loss: 15.814956426620483\n",
      "MSE train 5.974109703811649 MSE test 12.480657718176687\n",
      "MAE train 1.6946361095753553 MAE test 2.476579865068623\n",
      "Epoch 1672 / 10000 loss: 15.81431531906128\n",
      "MSE train 5.973941147511632 MSE test 12.480555453059722\n",
      "MAE train 1.6946086137831506 MAE test 2.476573079762849\n",
      "Epoch 1673 / 10000 loss: 15.813740968704224\n",
      "MSE train 5.973786179580698 MSE test 12.480321355085458\n",
      "MAE train 1.6945863203627989 MAE test 2.4765448812924884\n",
      "Epoch 1674 / 10000 loss: 15.813100337982178\n",
      "MSE train 5.973617567104236 MSE test 12.480218915247994\n",
      "MAE train 1.6945588140283774 MAE test 2.4765380731450226\n",
      "Epoch 1675 / 10000 loss: 15.812526226043701\n",
      "MSE train 5.973462587723734 MSE test 12.47998489322349\n",
      "MAE train 1.6945365258670573 MAE test 2.476509900935009\n",
      "Epoch 1676 / 10000 loss: 15.811884880065918\n",
      "MSE train 5.9732939466773605 MSE test 12.479882273034987\n",
      "MAE train 1.694509012740313 MAE test 2.4765030689281184\n",
      "Epoch 1677 / 10000 loss: 15.811310052871704\n",
      "MSE train 5.97313895620941 MSE test 12.479648231712602\n",
      "MAE train 1.694486724200856 MAE test 2.476474882851098\n",
      "Epoch 1678 / 10000 loss: 15.810669898986816\n",
      "MSE train 5.97297040930946 MSE test 12.47954577641727\n",
      "MAE train 1.6944592169119954 MAE test 2.4764680802049073\n",
      "Epoch 1679 / 10000 loss: 15.810095071792603\n",
      "MSE train 5.972815393178585 MSE test 12.479311728645849\n",
      "MAE train 1.6944369313140573 MAE test 2.4764398994193124\n",
      "Epoch 1680 / 10000 loss: 15.809455156326294\n",
      "MSE train 5.972646802914716 MSE test 12.479209311474051\n",
      "MAE train 1.6944094195632233 MAE test 2.4764331011295835\n",
      "Epoch 1681 / 10000 loss: 15.808881044387817\n",
      "MSE train 5.972491816933506 MSE test 12.478975076517436\n",
      "MAE train 1.6943871343750692 MAE test 2.476404889849425\n",
      "Epoch 1682 / 10000 loss: 15.808240175247192\n",
      "MSE train 5.9723232360402205 MSE test 12.478872614226498\n",
      "MAE train 1.6943596236848335 MAE test 2.4763980689482943\n",
      "Epoch 1683 / 10000 loss: 15.807665586471558\n",
      "MSE train 5.972168250125789 MSE test 12.478638537775522\n",
      "MAE train 1.69433733705614 MAE test 2.476369884474378\n",
      "Epoch 1684 / 10000 loss: 15.807025671005249\n",
      "MSE train 5.971999616811518 MSE test 12.478535924718933\n",
      "MAE train 1.6943098182024603 MAE test 2.476363064462719\n",
      "Epoch 1685 / 10000 loss: 15.806450605392456\n",
      "MSE train 5.971844630526728 MSE test 12.478301965107415\n",
      "MAE train 1.6942875298657418 MAE test 2.4763348799750236\n",
      "Epoch 1686 / 10000 loss: 15.80580997467041\n",
      "MSE train 5.971676040092428 MSE test 12.478199378236223\n",
      "MAE train 1.6942600161415236 MAE test 2.4763280636485736\n",
      "Epoch 1687 / 10000 loss: 15.805236101150513\n",
      "MSE train 5.971521019978898 MSE test 12.477965237909853\n",
      "MAE train 1.6942377298718776 MAE test 2.4762998590888805\n",
      "Epoch 1688 / 10000 loss: 15.804596424102783\n",
      "MSE train 5.971352383021254 MSE test 12.47786272329347\n",
      "MAE train 1.6942102070086904 MAE test 2.4762930523137925\n",
      "Epoch 1689 / 10000 loss: 15.80402159690857\n",
      "MSE train 5.971197400201622 MSE test 12.47762843157243\n",
      "MAE train 1.6941879227745267 MAE test 2.4762648248413974\n",
      "Epoch 1690 / 10000 loss: 15.803380727767944\n",
      "MSE train 5.97102880290311 MSE test 12.477525929079295\n",
      "MAE train 1.6941604044124896 MAE test 2.476258012639814\n",
      "Epoch 1691 / 10000 loss: 15.802806615829468\n",
      "MSE train 5.97087378557442 MSE test 12.477291812185497\n",
      "MAE train 1.6941381174776744 MAE test 2.476229809997248\n",
      "Epoch 1692 / 10000 loss: 15.802165985107422\n",
      "MSE train 5.9707051211682725 MSE test 12.477189190200253\n",
      "MAE train 1.6941105861710686 MAE test 2.4762229840451546\n",
      "Epoch 1693 / 10000 loss: 15.801591873168945\n",
      "MSE train 5.970550154347977 MSE test 12.476954994206539\n",
      "MAE train 1.6940883095034633 MAE test 2.4761947697581297\n",
      "Epoch 1694 / 10000 loss: 15.800951480865479\n",
      "MSE train 5.970381462222542 MSE test 12.47685242258236\n",
      "MAE train 1.6940607746293281 MAE test 2.476187955919153\n",
      "Epoch 1695 / 10000 loss: 15.800376653671265\n",
      "MSE train 5.970226470967923 MSE test 12.476618300093223\n",
      "MAE train 1.6940384950175655 MAE test 2.4761597479387234\n",
      "Epoch 1696 / 10000 loss: 15.799736022949219\n",
      "MSE train 5.970057833711522 MSE test 12.476515738349395\n",
      "MAE train 1.6940109621517196 MAE test 2.4761529454689732\n",
      "Epoch 1697 / 10000 loss: 15.799161911010742\n",
      "MSE train 5.969902807040159 MSE test 12.476281582858238\n",
      "MAE train 1.6939886790891634 MAE test 2.4761247339444425\n",
      "Epoch 1698 / 10000 loss: 15.798521757125854\n",
      "MSE train 5.969734138997467 MSE test 12.47617886856043\n",
      "MAE train 1.6939611383737783 MAE test 2.4761179045921744\n",
      "Epoch 1699 / 10000 loss: 15.797947645187378\n",
      "MSE train 5.969579139994659 MSE test 12.475944777150398\n",
      "MAE train 1.6939388596622686 MAE test 2.4760896929556866\n",
      "Epoch 1700 / 10000 loss: 15.797307014465332\n",
      "MSE train 5.969410458987937 MSE test 12.475842132706747\n",
      "MAE train 1.6939113196368916 MAE test 2.4760828712997665\n",
      "Epoch 1701 / 10000 loss: 15.796732664108276\n",
      "MSE train 5.96925542859209 MSE test 12.475607995644129\n",
      "MAE train 1.693889039834654 MAE test 2.476054647815984\n",
      "Epoch 1702 / 10000 loss: 15.796092987060547\n",
      "MSE train 5.969086798339669 MSE test 12.475505210370185\n",
      "MAE train 1.6938614991888141 MAE test 2.4760478194531417\n",
      "Epoch 1703 / 10000 loss: 15.795517683029175\n",
      "MSE train 5.968931733823102 MSE test 12.47527116821195\n",
      "MAE train 1.6938392162080083 MAE test 2.476019614124235\n",
      "Epoch 1704 / 10000 loss: 15.794878005981445\n",
      "MSE train 5.968763121695006 MSE test 12.475168478868866\n",
      "MAE train 1.6938116775721592 MAE test 2.476012791270131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1705 / 10000 loss: 15.79430365562439\n",
      "MSE train 5.968607988724 MSE test 12.47493425098931\n",
      "MAE train 1.6937893851572514 MAE test 2.4759845605486994\n",
      "Epoch 1706 / 10000 loss: 15.793663263320923\n",
      "MSE train 5.96843933542993 MSE test 12.474831709672795\n",
      "MAE train 1.6937618378644255 MAE test 2.4759777615821954\n",
      "Epoch 1707 / 10000 loss: 15.793088912963867\n",
      "MSE train 5.968284247876172 MSE test 12.474597533194606\n",
      "MAE train 1.6937395558763948 MAE test 2.475949543098472\n",
      "Epoch 1708 / 10000 loss: 15.7924485206604\n",
      "MSE train 5.968115553451309 MSE test 12.474494850581744\n",
      "MAE train 1.693712002037398 MAE test 2.4759427223404806\n",
      "Epoch 1709 / 10000 loss: 15.791873931884766\n",
      "MSE train 5.967960485245281 MSE test 12.474260570449776\n",
      "MAE train 1.6936897261084525 MAE test 2.4759144758415506\n",
      "Epoch 1710 / 10000 loss: 15.791234254837036\n",
      "MSE train 5.967791773393802 MSE test 12.474157892677317\n",
      "MAE train 1.6936621705932229 MAE test 2.475907666295964\n",
      "Epoch 1711 / 10000 loss: 15.790659666061401\n",
      "MSE train 5.967636695481198 MSE test 12.473923768317281\n",
      "MAE train 1.6936398900267875 MAE test 2.4758794439371843\n",
      "Epoch 1712 / 10000 loss: 15.790018320083618\n",
      "MSE train 5.967467988134074 MSE test 12.473821013366626\n",
      "MAE train 1.6936123335308153 MAE test 2.475872622545957\n",
      "Epoch 1713 / 10000 loss: 15.789443969726562\n",
      "MSE train 5.9673128944957625 MSE test 12.473586858611739\n",
      "MAE train 1.6935900513951 MAE test 2.475844400542821\n",
      "Epoch 1714 / 10000 loss: 15.788804054260254\n",
      "MSE train 5.967144134815278 MSE test 12.473484112452306\n",
      "MAE train 1.6935624845984056 MAE test 2.475837574731188\n",
      "Epoch 1715 / 10000 loss: 15.78822946548462\n",
      "MSE train 5.966989037061861 MSE test 12.473249964400361\n",
      "MAE train 1.693540209375175 MAE test 2.4758093500062333\n",
      "Epoch 1716 / 10000 loss: 15.787589311599731\n",
      "MSE train 5.96682028934702 MSE test 12.47314717052274\n",
      "MAE train 1.693512641362409 MAE test 2.475802519273824\n",
      "Epoch 1717 / 10000 loss: 15.787014484405518\n",
      "MSE train 5.9666651888508815 MSE test 12.472912946785463\n",
      "MAE train 1.6934903647505735 MAE test 2.47577427819218\n",
      "Epoch 1718 / 10000 loss: 15.786374568939209\n",
      "MSE train 5.966496428420297 MSE test 12.47281005570625\n",
      "MAE train 1.6934627963969464 MAE test 2.4757674374015344\n",
      "Epoch 1719 / 10000 loss: 15.785800457000732\n",
      "MSE train 5.966341266307838 MSE test 12.472576003964644\n",
      "MAE train 1.693440510993048 MAE test 2.4757392198503827\n",
      "Epoch 1720 / 10000 loss: 15.785160303115845\n",
      "MSE train 5.966172489690808 MSE test 12.47247312971026\n",
      "MAE train 1.693412939411028 MAE test 2.4757323782842495\n",
      "Epoch 1721 / 10000 loss: 15.78458547592163\n",
      "MSE train 5.966017314389322 MSE test 12.472238867271079\n",
      "MAE train 1.6933906522340276 MAE test 2.4757041508040762\n",
      "Epoch 1722 / 10000 loss: 15.783944845199585\n",
      "MSE train 5.9658485615285315 MSE test 12.472136028069064\n",
      "MAE train 1.6933630841542866 MAE test 2.475697316497306\n",
      "Epoch 1723 / 10000 loss: 15.783370733261108\n",
      "MSE train 5.965693363808986 MSE test 12.471901828777042\n",
      "MAE train 1.6933407991030847 MAE test 2.4756690885813213\n",
      "Epoch 1724 / 10000 loss: 15.782729864120483\n",
      "MSE train 5.965524523257479 MSE test 12.471798982348902\n",
      "MAE train 1.693313215669381 MAE test 2.47566224104068\n",
      "Epoch 1725 / 10000 loss: 15.782156229019165\n",
      "MSE train 5.965369356043844 MSE test 12.471564576599595\n",
      "MAE train 1.693290935382635 MAE test 2.4756339857027467\n",
      "Epoch 1726 / 10000 loss: 15.781516075134277\n",
      "MSE train 5.965200496192887 MSE test 12.471461690088\n",
      "MAE train 1.6932633424706152 MAE test 2.4756271378914954\n",
      "Epoch 1727 / 10000 loss: 15.780941486358643\n",
      "MSE train 5.9650452532139 MSE test 12.471227424678984\n",
      "MAE train 1.693241057333791 MAE test 2.475598902138167\n",
      "Epoch 1728 / 10000 loss: 15.780300855636597\n",
      "MSE train 5.9648764272805215 MSE test 12.471124621740072\n",
      "MAE train 1.6932134693468317 MAE test 2.4755920785134733\n",
      "Epoch 1729 / 10000 loss: 15.779726266860962\n",
      "MSE train 5.964721171730476 MSE test 12.470890208444708\n",
      "MAE train 1.6931911850623538 MAE test 2.4755638054295925\n",
      "Epoch 1730 / 10000 loss: 15.779086828231812\n",
      "MSE train 5.964552338587634 MSE test 12.470787344691683\n",
      "MAE train 1.6931635916857168 MAE test 2.475556965401256\n",
      "Epoch 1731 / 10000 loss: 15.77851152420044\n",
      "MSE train 5.964397094859891 MSE test 12.470552968257211\n",
      "MAE train 1.6931413101659822 MAE test 2.475528720466907\n",
      "Epoch 1732 / 10000 loss: 15.777871131896973\n",
      "MSE train 5.964228181817164 MSE test 12.470450051345873\n",
      "MAE train 1.693113704573146 MAE test 2.47552187944797\n",
      "Epoch 1733 / 10000 loss: 15.777297019958496\n",
      "MSE train 5.964072913265341 MSE test 12.470215656385738\n",
      "MAE train 1.6930914150150942 MAE test 2.475493609287255\n",
      "Epoch 1734 / 10000 loss: 15.77665662765503\n",
      "MSE train 5.963903985612448 MSE test 12.470112680347524\n",
      "MAE train 1.6930638072498938 MAE test 2.4754867579724507\n",
      "Epoch 1735 / 10000 loss: 15.776082038879395\n",
      "MSE train 5.963748689319365 MSE test 12.46987836842171\n",
      "MAE train 1.6930415169624509 MAE test 2.4754585085843064\n",
      "Epoch 1736 / 10000 loss: 15.775441884994507\n",
      "MSE train 5.96357977491312 MSE test 12.469775430544688\n",
      "MAE train 1.6930139076542516 MAE test 2.4754516707757945\n",
      "Epoch 1737 / 10000 loss: 15.77486801147461\n",
      "MSE train 5.96342445904224 MSE test 12.4695409772568\n",
      "MAE train 1.6929916207227393 MAE test 2.475423394716841\n",
      "Epoch 1738 / 10000 loss: 15.774226427078247\n",
      "MSE train 5.963255513345561 MSE test 12.469438009135281\n",
      "MAE train 1.6929640047134884 MAE test 2.4754165362950182\n",
      "Epoch 1739 / 10000 loss: 15.773652791976929\n",
      "MSE train 5.96310017159284 MSE test 12.469203674482374\n",
      "MAE train 1.6929417166818357 MAE test 2.4753882968447845\n",
      "Epoch 1740 / 10000 loss: 15.773011445999146\n",
      "MSE train 5.962931147822842 MSE test 12.469100732719808\n",
      "MAE train 1.6929140928415565 MAE test 2.4753814449945652\n",
      "Epoch 1741 / 10000 loss: 15.772436618804932\n",
      "MSE train 5.962775795135623 MSE test 12.468866262408891\n",
      "MAE train 1.6928918046672035 MAE test 2.475353179159188\n",
      "Epoch 1742 / 10000 loss: 15.771796703338623\n",
      "MSE train 5.962606817678783 MSE test 12.468763063183363\n",
      "MAE train 1.6928641839895966 MAE test 2.4753463038617736\n",
      "Epoch 1743 / 10000 loss: 15.771222352981567\n",
      "MSE train 5.962451397363784 MSE test 12.468528795749886\n",
      "MAE train 1.6928418811424797 MAE test 2.4753180560481423\n",
      "Epoch 1744 / 10000 loss: 15.770581007003784\n",
      "MSE train 5.962282357624681 MSE test 12.46842569646718\n",
      "MAE train 1.6928142582996586 MAE test 2.4753111931821508\n",
      "Epoch 1745 / 10000 loss: 15.770007848739624\n",
      "MSE train 5.962126927517471 MSE test 12.468191163805447\n",
      "MAE train 1.69279195474053 MAE test 2.475282908170253\n",
      "Epoch 1746 / 10000 loss: 15.769366979598999\n",
      "MSE train 5.9619578744820485 MSE test 12.468088214760886\n",
      "MAE train 1.6927643276338917 MAE test 2.475276058299683\n",
      "Epoch 1747 / 10000 loss: 15.768791913986206\n",
      "MSE train 5.961802477037987 MSE test 12.467853800184932\n",
      "MAE train 1.6927420298603024 MAE test 2.475247796519014\n",
      "Epoch 1748 / 10000 loss: 15.768151998519897\n",
      "MSE train 5.961633360609204 MSE test 12.46775061364233\n",
      "MAE train 1.6927143913957616 MAE test 2.4752409180499684\n",
      "Epoch 1749 / 10000 loss: 15.767576932907104\n",
      "MSE train 5.96147786697186 MSE test 12.46751609666371\n",
      "MAE train 1.6926920815513105 MAE test 2.4752126528835627\n",
      "Epoch 1750 / 10000 loss: 15.766936302185059\n",
      "MSE train 5.961308830794494 MSE test 12.467412933401166\n",
      "MAE train 1.692664449779554 MAE test 2.475205765590439\n",
      "Epoch 1751 / 10000 loss: 15.76636266708374\n",
      "MSE train 5.9611532787971875 MSE test 12.467178393024076\n",
      "MAE train 1.692642134848063 MAE test 2.475177492708782\n",
      "Epoch 1752 / 10000 loss: 15.765721797943115\n",
      "MSE train 5.960984095975823 MSE test 12.46707525207574\n",
      "MAE train 1.692614480218934 MAE test 2.4751706206522903\n",
      "Epoch 1753 / 10000 loss: 15.76514720916748\n",
      "MSE train 5.960828619627702 MSE test 12.466840674055884\n",
      "MAE train 1.6925921731505889 MAE test 2.4751423377515227\n",
      "Epoch 1754 / 10000 loss: 15.764507293701172\n",
      "MSE train 5.960659490343547 MSE test 12.466737570696441\n",
      "MAE train 1.6925645218203618 MAE test 2.47513546561361\n",
      "Epoch 1755 / 10000 loss: 15.763932466506958\n",
      "MSE train 5.960503927730811 MSE test 12.466502873727046\n",
      "MAE train 1.6925422042714724 MAE test 2.475107184485075\n",
      "Epoch 1756 / 10000 loss: 15.763293027877808\n",
      "MSE train 5.960334750111558 MSE test 12.466399626132342\n",
      "MAE train 1.6925145427269546 MAE test 2.4751002885124285\n",
      "Epoch 1757 / 10000 loss: 15.762717962265015\n",
      "MSE train 5.960179134761157 MSE test 12.466164992506172\n",
      "MAE train 1.6924922185399056 MAE test 2.47507200565242\n",
      "Epoch 1758 / 10000 loss: 15.762078046798706\n",
      "MSE train 5.960009900607624 MSE test 12.46606173667726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6924645474245412 MAE test 2.4750651093048304\n",
      "Epoch 1759 / 10000 loss: 15.761502981185913\n",
      "MSE train 5.9598542780921635 MSE test 12.465827092987707\n",
      "MAE train 1.6924422219003457 MAE test 2.475036825671796\n",
      "Epoch 1760 / 10000 loss: 15.760862588882446\n",
      "MSE train 5.959685116256751 MSE test 12.46572376957447\n",
      "MAE train 1.6924145597340836 MAE test 2.475029926297219\n",
      "Epoch 1761 / 10000 loss: 15.760288715362549\n",
      "MSE train 5.959529423921287 MSE test 12.465489102090917\n",
      "MAE train 1.6923922217014806 MAE test 2.4750016392676297\n",
      "Epoch 1762 / 10000 loss: 15.759648084640503\n",
      "MSE train 5.959360208873886 MSE test 12.465385715801878\n",
      "MAE train 1.6923645569506285 MAE test 2.4749947351384374\n",
      "Epoch 1763 / 10000 loss: 15.759073734283447\n",
      "MSE train 5.9592045116562415 MSE test 12.465151025663282\n",
      "MAE train 1.6923422209847432 MAE test 2.4749664487001137\n",
      "Epoch 1764 / 10000 loss: 15.758434057235718\n",
      "MSE train 5.959035234316896 MSE test 12.465047673728101\n",
      "MAE train 1.6923145417222667 MAE test 2.47495955025805\n",
      "Epoch 1765 / 10000 loss: 15.757859230041504\n",
      "MSE train 5.958879524567026 MSE test 12.464812839251595\n",
      "MAE train 1.6922922071787883 MAE test 2.4749312409694233\n",
      "Epoch 1766 / 10000 loss: 15.757218599319458\n",
      "MSE train 5.9587102289160585 MSE test 12.46470934894261\n",
      "MAE train 1.6922645234763918 MAE test 2.4749243076514933\n",
      "Epoch 1767 / 10000 loss: 15.75664496421814\n",
      "MSE train 5.958554459031369 MSE test 12.464474584223115\n",
      "MAE train 1.6922421781723247 MAE test 2.474896025584296\n",
      "Epoch 1768 / 10000 loss: 15.756005048751831\n",
      "MSE train 5.958385135329336 MSE test 12.464371036070029\n",
      "MAE train 1.6922144903058813 MAE test 2.4748890915704016\n",
      "Epoch 1769 / 10000 loss: 15.755430221557617\n",
      "MSE train 5.95822935093463 MSE test 12.464136268739136\n",
      "MAE train 1.6921921425846849 MAE test 2.4748608026154533\n",
      "Epoch 1770 / 10000 loss: 15.754790782928467\n",
      "MSE train 5.958059994896536 MSE test 12.464032719086644\n",
      "MAE train 1.6921644425072238 MAE test 2.474853875672092\n",
      "Epoch 1771 / 10000 loss: 15.75421667098999\n",
      "MSE train 5.957904215020284 MSE test 12.463797960633668\n",
      "MAE train 1.6921420966799352 MAE test 2.4748255963186456\n",
      "Epoch 1772 / 10000 loss: 15.75357699394226\n",
      "MSE train 5.957734777783928 MSE test 12.46369431701547\n",
      "MAE train 1.6921143812566204 MAE test 2.47481864557349\n",
      "Epoch 1773 / 10000 loss: 15.753002405166626\n",
      "MSE train 5.957578929066319 MSE test 12.463459345078949\n",
      "MAE train 1.6920920203020517 MAE test 2.4747903322713922\n",
      "Epoch 1774 / 10000 loss: 15.752362728118896\n",
      "MSE train 5.957409503022 MSE test 12.463355673367236\n",
      "MAE train 1.6920643040056171 MAE test 2.4747834042839756\n",
      "Epoch 1775 / 10000 loss: 15.75178837776184\n",
      "MSE train 5.957253593870565 MSE test 12.463120743653803\n",
      "MAE train 1.6920419320212667 MAE test 2.4747550892762677\n",
      "Epoch 1776 / 10000 loss: 15.751148700714111\n",
      "MSE train 5.957084124612498 MSE test 12.463016979439708\n",
      "MAE train 1.6920142088295587 MAE test 2.474748138457387\n",
      "Epoch 1777 / 10000 loss: 15.750574588775635\n",
      "MSE train 5.956928194432417 MSE test 12.462781965364643\n",
      "MAE train 1.691991826493081 MAE test 2.4747198145425924\n",
      "Epoch 1778 / 10000 loss: 15.749934911727905\n",
      "MSE train 5.956758693826787 MSE test 12.462678149672971\n",
      "MAE train 1.6919641017518976 MAE test 2.474712851450517\n",
      "Epoch 1779 / 10000 loss: 15.749361753463745\n",
      "MSE train 5.956602790109992 MSE test 12.462442985435844\n",
      "MAE train 1.6919417274778292 MAE test 2.4746845209537\n",
      "Epoch 1780 / 10000 loss: 15.748721361160278\n",
      "MSE train 5.956433187475166 MSE test 12.462339162098734\n",
      "MAE train 1.6919139780869923 MAE test 2.474677567401824\n",
      "Epoch 1781 / 10000 loss: 15.748147964477539\n",
      "MSE train 5.9562772350992335 MSE test 12.462104136133023\n",
      "MAE train 1.691891595995757 MAE test 2.4746492441885835\n",
      "Epoch 1782 / 10000 loss: 15.74750828742981\n",
      "MSE train 5.95610759129317 MSE test 12.462000083566688\n",
      "MAE train 1.6918638455592596 MAE test 2.4746422596797\n",
      "Epoch 1783 / 10000 loss: 15.746934175491333\n",
      "MSE train 5.955951562728791 MSE test 12.461764893226476\n",
      "MAE train 1.6918414557491266 MAE test 2.4746139323733645\n",
      "Epoch 1784 / 10000 loss: 15.746294975280762\n",
      "MSE train 5.955781918649723 MSE test 12.461660844216473\n",
      "MAE train 1.6918137035532943 MAE test 2.4746069378958313\n",
      "Epoch 1785 / 10000 loss: 15.745720863342285\n",
      "MSE train 5.955625813444996 MSE test 12.461425553367338\n",
      "MAE train 1.6917913000593712 MAE test 2.4745785951515873\n",
      "Epoch 1786 / 10000 loss: 15.74508261680603\n",
      "MSE train 5.955456197357587 MSE test 12.461321467687945\n",
      "MAE train 1.6917635498056869 MAE test 2.474571607913385\n",
      "Epoch 1787 / 10000 loss: 15.744508028030396\n",
      "MSE train 5.9553000139737176 MSE test 12.461086079263865\n",
      "MAE train 1.6917411358701282 MAE test 2.474543256604911\n",
      "Epoch 1788 / 10000 loss: 15.743869543075562\n",
      "MSE train 5.955130265194852 MSE test 12.460981847771738\n",
      "MAE train 1.691713362179999 MAE test 2.474536242329632\n",
      "Epoch 1789 / 10000 loss: 15.743296146392822\n",
      "MSE train 5.954974084933817 MSE test 12.460746355636493\n",
      "MAE train 1.6916909477508477 MAE test 2.4745078798684594\n",
      "Epoch 1790 / 10000 loss: 15.742656946182251\n",
      "MSE train 5.95480427850599 MSE test 12.460642124340925\n",
      "MAE train 1.6916631631344383 MAE test 2.474500873197273\n",
      "Epoch 1791 / 10000 loss: 15.742082834243774\n",
      "MSE train 5.954647998635939 MSE test 12.46040651782421\n",
      "MAE train 1.6916407385049461 MAE test 2.4744724976968984\n",
      "Epoch 1792 / 10000 loss: 15.741443634033203\n",
      "MSE train 5.954478112462418 MSE test 12.460302015363418\n",
      "MAE train 1.6916129326524139 MAE test 2.4744654742604464\n",
      "Epoch 1793 / 10000 loss: 15.740870475769043\n",
      "MSE train 5.954321815656998 MSE test 12.460066503064832\n",
      "MAE train 1.6915904983774857 MAE test 2.474437098611288\n",
      "Epoch 1794 / 10000 loss: 15.74023151397705\n",
      "MSE train 5.954151893285093 MSE test 12.459961851025586\n",
      "MAE train 1.6915626929345295 MAE test 2.474430048141788\n",
      "Epoch 1795 / 10000 loss: 15.73965835571289\n",
      "MSE train 5.953995501622306 MSE test 12.459726177248212\n",
      "MAE train 1.6915402496717107 MAE test 2.4744016770224015\n",
      "Epoch 1796 / 10000 loss: 15.739018678665161\n",
      "MSE train 5.9538254751119215 MSE test 12.459621602294897\n",
      "MAE train 1.6915124261417671 MAE test 2.4743946305883893\n",
      "Epoch 1797 / 10000 loss: 15.738445281982422\n",
      "MSE train 5.953668966146255 MSE test 12.459385743107749\n",
      "MAE train 1.6914899635177363 MAE test 2.4743662360368868\n",
      "Epoch 1798 / 10000 loss: 15.737806797027588\n",
      "MSE train 5.953498889113495 MSE test 12.459280904230875\n",
      "MAE train 1.691462124675661 MAE test 2.474359173320002\n",
      "Epoch 1799 / 10000 loss: 15.73723316192627\n",
      "MSE train 5.95334229197529 MSE test 12.459044909855766\n",
      "MAE train 1.6914396417965845 MAE test 2.4743307621097728\n",
      "Epoch 1800 / 10000 loss: 15.736594200134277\n",
      "MSE train 5.953172067601578 MSE test 12.4589400344622\n",
      "MAE train 1.6914117809663607 MAE test 2.4743236936732167\n",
      "Epoch 1801 / 10000 loss: 15.736021041870117\n",
      "MSE train 5.953015381025181 MSE test 12.45870390098536\n",
      "MAE train 1.691389285146268 MAE test 2.474295268731533\n",
      "Epoch 1802 / 10000 loss: 15.735381603240967\n",
      "MSE train 5.952845094297741 MSE test 12.458598852629565\n",
      "MAE train 1.6913614080102912 MAE test 2.4742881892319986\n",
      "Epoch 1803 / 10000 loss: 15.734808444976807\n",
      "MSE train 5.9526883192184625 MSE test 12.45836263445239\n",
      "MAE train 1.6913389005119284 MAE test 2.4742597545254843\n",
      "Epoch 1804 / 10000 loss: 15.734169244766235\n",
      "MSE train 5.952517860471767 MSE test 12.458257493743616\n",
      "MAE train 1.69131099027938 MAE test 2.4742526724098974\n",
      "Epoch 1805 / 10000 loss: 15.733595371246338\n",
      "MSE train 5.952360958655878 MSE test 12.458020954150918\n",
      "MAE train 1.6912884596828506 MAE test 2.4742241935575113\n",
      "Epoch 1806 / 10000 loss: 15.732958555221558\n",
      "MSE train 5.952190378252687 MSE test 12.457915649300501\n",
      "MAE train 1.6912605313960904 MAE test 2.4742170970775077\n",
      "Epoch 1807 / 10000 loss: 15.732383966445923\n",
      "MSE train 5.952033342876255 MSE test 12.457679164707331\n",
      "MAE train 1.6912379787909142 MAE test 2.474188638036161\n",
      "Epoch 1808 / 10000 loss: 15.73174500465393\n",
      "MSE train 5.951862579850129 MSE test 12.457573543646669\n",
      "MAE train 1.6912100209516767 MAE test 2.474181508559416\n",
      "Epoch 1809 / 10000 loss: 15.731171131134033\n",
      "MSE train 5.951705394622925 MSE test 12.457336838250635\n",
      "MAE train 1.6911874433796428 MAE test 2.474153009160987\n",
      "Epoch 1810 / 10000 loss: 15.730532169342041\n",
      "MSE train 5.951534484500442 MSE test 12.457231145958097\n",
      "MAE train 1.6911594606607314 MAE test 2.47414587983644\n",
      "Epoch 1811 / 10000 loss: 15.729957818984985\n",
      "MSE train 5.95137713514058 MSE test 12.456994173480682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6911368584332411 MAE test 2.474117365651318\n",
      "Epoch 1812 / 10000 loss: 15.729319095611572\n",
      "MSE train 5.951206030155726 MSE test 12.456888264765041\n",
      "MAE train 1.6911088436043828 MAE test 2.4741102092343517\n",
      "Epoch 1813 / 10000 loss: 15.728745937347412\n",
      "MSE train 5.951048464413181 MSE test 12.456651050488498\n",
      "MAE train 1.691086201072094 MAE test 2.474081664938265\n",
      "Epoch 1814 / 10000 loss: 15.728105783462524\n",
      "MSE train 5.9508771481208775 MSE test 12.456544971627856\n",
      "MAE train 1.69105815540426 MAE test 2.474074507236498\n",
      "Epoch 1815 / 10000 loss: 15.727531671524048\n",
      "MSE train 5.950719340409402 MSE test 12.456307500551398\n",
      "MAE train 1.6910354781039443 MAE test 2.474045938594831\n",
      "Epoch 1816 / 10000 loss: 15.726892232894897\n",
      "MSE train 5.9505478506422325 MSE test 12.456201114795439\n",
      "MAE train 1.6910074028779807 MAE test 2.4740387518542764\n",
      "Epoch 1817 / 10000 loss: 15.726318359375\n",
      "MSE train 5.950389715569339 MSE test 12.455963360812406\n",
      "MAE train 1.6909846740236052 MAE test 2.4740101457828296\n",
      "Epoch 1818 / 10000 loss: 15.725677728652954\n",
      "MSE train 5.950218006449698 MSE test 12.455856697819536\n",
      "MAE train 1.6909565591834124 MAE test 2.474002929474802\n",
      "Epoch 1819 / 10000 loss: 15.725103378295898\n",
      "MSE train 5.9500596558525265 MSE test 12.455618799353315\n",
      "MAE train 1.6909337978072043 MAE test 2.4739743190770467\n",
      "Epoch 1820 / 10000 loss: 15.72446322441101\n",
      "MSE train 5.949887616748219 MSE test 12.45551177057577\n",
      "MAE train 1.690905635353295 MAE test 2.473967060911064\n",
      "Epoch 1821 / 10000 loss: 15.723889589309692\n",
      "MSE train 5.94972895159409 MSE test 12.455273407189821\n",
      "MAE train 1.6908828241210223 MAE test 2.473938401065659\n",
      "Epoch 1822 / 10000 loss: 15.72324800491333\n",
      "MSE train 5.949556517457778 MSE test 12.455165998237002\n",
      "MAE train 1.690854601824788 MAE test 2.4739311149307537\n",
      "Epoch 1823 / 10000 loss: 15.722673177719116\n",
      "MSE train 5.949397480823153 MSE test 12.454927352827545\n",
      "MAE train 1.6908317344348023 MAE test 2.473902438266324\n",
      "Epoch 1824 / 10000 loss: 15.722031593322754\n",
      "MSE train 5.94922475726182 MSE test 12.454819609713772\n",
      "MAE train 1.6908034587734093 MAE test 2.473895116050326\n",
      "Epoch 1825 / 10000 loss: 15.721455812454224\n",
      "MSE train 5.949065299181997 MSE test 12.454580473527985\n",
      "MAE train 1.6907805252564923 MAE test 2.4738663865796964\n",
      "Epoch 1826 / 10000 loss: 15.720814943313599\n",
      "MSE train 5.9488921169003754 MSE test 12.454472323589286\n",
      "MAE train 1.6907521789541478 MAE test 2.473859027347201\n",
      "Epoch 1827 / 10000 loss: 15.720238208770752\n",
      "MSE train 5.94873222608399 MSE test 12.45423271060343\n",
      "MAE train 1.6907291752473441 MAE test 2.4738302573022324\n",
      "Epoch 1828 / 10000 loss: 15.719597101211548\n",
      "MSE train 5.948558469961083 MSE test 12.454123952576404\n",
      "MAE train 1.6907007317060583 MAE test 2.47382283999972\n",
      "Epoch 1829 / 10000 loss: 15.719019889831543\n",
      "MSE train 5.948398042303417 MSE test 12.453883924133558\n",
      "MAE train 1.6906776452336245 MAE test 2.4737940363602013\n",
      "Epoch 1830 / 10000 loss: 15.718377113342285\n",
      "MSE train 5.948223719054806 MSE test 12.453774530022109\n",
      "MAE train 1.690649108462692 MAE test 2.4737865593855988\n",
      "Epoch 1831 / 10000 loss: 15.71779990196228\n",
      "MSE train 5.94806261283313 MSE test 12.45353385919634\n",
      "MAE train 1.6906259116529074 MAE test 2.4737576855851833\n",
      "Epoch 1832 / 10000 loss: 15.717156171798706\n",
      "MSE train 5.947887550459983 MSE test 12.45342388025078\n",
      "MAE train 1.6905972563882163 MAE test 2.4737501497373957\n",
      "Epoch 1833 / 10000 loss: 15.716576337814331\n",
      "MSE train 5.947725710290003 MSE test 12.45318234537492\n",
      "MAE train 1.6905739381472888 MAE test 2.4737212059512754\n",
      "Epoch 1834 / 10000 loss: 15.715932369232178\n",
      "MSE train 5.947549823950686 MSE test 12.453071409182378\n",
      "MAE train 1.6905451411076544 MAE test 2.4737135822120164\n",
      "Epoch 1835 / 10000 loss: 15.715352535247803\n",
      "MSE train 5.947387093096232 MSE test 12.452829174121772\n",
      "MAE train 1.6905216778842251 MAE test 2.4736845672867553\n",
      "Epoch 1836 / 10000 loss: 15.714706897735596\n",
      "MSE train 5.947210181800796 MSE test 12.452717306851328\n",
      "MAE train 1.6904927137913606 MAE test 2.4736768595385774\n",
      "Epoch 1837 / 10000 loss: 15.714125394821167\n",
      "MSE train 5.947046255914293 MSE test 12.45247381225038\n",
      "MAE train 1.690469047701593 MAE test 2.473647706734336\n",
      "Epoch 1838 / 10000 loss: 15.713478088378906\n",
      "MSE train 5.946868060094747 MSE test 12.452360812889676\n",
      "MAE train 1.6904398703941987 MAE test 2.4736398948976754\n",
      "Epoch 1839 / 10000 loss: 15.71289587020874\n",
      "MSE train 5.9467027136260775 MSE test 12.452116047423214\n",
      "MAE train 1.6904159681545403 MAE test 2.4736106296847287\n",
      "Epoch 1840 / 10000 loss: 15.712245464324951\n",
      "MSE train 5.946522943418207 MSE test 12.452001537159665\n",
      "MAE train 1.6903865207714928 MAE test 2.4736026713600854\n",
      "Epoch 1841 / 10000 loss: 15.711660623550415\n",
      "MSE train 5.946355715591408 MSE test 12.451755007850712\n",
      "MAE train 1.690362302240665 MAE test 2.4735732287994425\n",
      "Epoch 1842 / 10000 loss: 15.711008310317993\n",
      "MSE train 5.946173828882318 MSE test 12.451638549834149\n",
      "MAE train 1.69033248975783 MAE test 2.473565083982837\n",
      "Epoch 1843 / 10000 loss: 15.710418939590454\n",
      "MSE train 5.946004171185007 MSE test 12.451389791429412\n",
      "MAE train 1.690307839477745 MAE test 2.473535444068615\n",
      "Epoch 1844 / 10000 loss: 15.709763050079346\n",
      "MSE train 5.945819291570521 MSE test 12.45127080164027\n",
      "MAE train 1.6902774948519825 MAE test 2.4735270524313795\n",
      "Epoch 1845 / 10000 loss: 15.70917010307312\n",
      "MSE train 5.945646112818813 MSE test 12.451019153197521\n",
      "MAE train 1.6902522192336504 MAE test 2.473497143530631\n",
      "Epoch 1846 / 10000 loss: 15.708507299423218\n",
      "MSE train 5.945457068559779 MSE test 12.450896461797695\n",
      "MAE train 1.6902211253134176 MAE test 2.473488397616198\n",
      "Epoch 1847 / 10000 loss: 15.70790696144104\n",
      "MSE train 5.945278652997179 MSE test 12.450640452495536\n",
      "MAE train 1.6901948885171498 MAE test 2.4734580840359364\n",
      "Epoch 1848 / 10000 loss: 15.707236528396606\n",
      "MSE train 5.9450829410613215 MSE test 12.45051258397212\n",
      "MAE train 1.690162583558946 MAE test 2.473448866964753\n",
      "Epoch 1849 / 10000 loss: 15.70662522315979\n",
      "MSE train 5.944895999737091 MSE test 12.450249984451263\n",
      "MAE train 1.690134789023723 MAE test 2.473417932783947\n",
      "Epoch 1850 / 10000 loss: 15.705939531326294\n",
      "MSE train 5.9446887834274165 MSE test 12.450113720851723\n",
      "MAE train 1.6901003510907149 MAE test 2.473407920648419\n",
      "Epoch 1851 / 10000 loss: 15.705307483673096\n",
      "MSE train 5.94448583405609 MSE test 12.449840249592517\n",
      "MAE train 1.6900695490164015 MAE test 2.473375995766692\n",
      "Epoch 1852 / 10000 loss: 15.704591512680054\n",
      "MSE train 5.94425548244717 MSE test 12.449689387488771\n",
      "MAE train 1.6900306303159045 MAE test 2.4733646805262066\n",
      "Epoch 1853 / 10000 loss: 15.703915119171143\n",
      "MSE train 5.944017388633174 MSE test 12.449395964604347\n",
      "MAE train 1.6899928170605034 MAE test 2.4733309011294593\n",
      "Epoch 1854 / 10000 loss: 15.703130006790161\n",
      "MSE train 5.943731673928382 MSE test 12.449217600797327\n",
      "MAE train 1.6899423674263232 MAE test 2.473317007072601\n",
      "Epoch 1855 / 10000 loss: 15.702341318130493\n",
      "MSE train 5.943407289571623 MSE test 12.448886528317974\n",
      "MAE train 1.6898861405223309 MAE test 2.4732797183830817\n",
      "Epoch 1856 / 10000 loss: 15.70136284828186\n",
      "MSE train 5.943014400251613 MSE test 12.448664450290122\n",
      "MAE train 1.6898120714566667 MAE test 2.4732617303089923\n",
      "Epoch 1857 / 10000 loss: 15.700246095657349\n",
      "MSE train 5.942653079312635 MSE test 12.448312495956646\n",
      "MAE train 1.689746243390907 MAE test 2.473222523485035\n",
      "Epoch 1858 / 10000 loss: 15.698829174041748\n",
      "MSE train 5.942380717630861 MSE test 12.44814104559569\n",
      "MAE train 1.6896977737766168 MAE test 2.4732092111135806\n",
      "Epoch 1859 / 10000 loss: 15.69752025604248\n",
      "MSE train 5.942184719120649 MSE test 12.44788759313749\n",
      "MAE train 1.689667426142874 MAE test 2.473178958852757\n",
      "Epoch 1860 / 10000 loss: 15.696518421173096\n",
      "MSE train 5.941995285638677 MSE test 12.447784947550746\n",
      "MAE train 1.6896358044719508 MAE test 2.4731718664277884\n",
      "Epoch 1861 / 10000 loss: 15.695796251296997\n",
      "MSE train 5.941825922872269 MSE test 12.447556624451316\n",
      "MAE train 1.6896108540446488 MAE test 2.4731438689059075\n",
      "Epoch 1862 / 10000 loss: 15.695068836212158\n",
      "MSE train 5.941644534281281 MSE test 12.447458224448798\n",
      "MAE train 1.6895808298786714 MAE test 2.473137093903713\n",
      "Epoch 1863 / 10000 loss: 15.694424390792847\n",
      "MSE train 5.94147497557576 MSE test 12.447223566708708\n",
      "MAE train 1.6895559179439628 MAE test 2.473108372060385\n",
      "Epoch 1864 / 10000 loss: 15.693719625473022\n",
      "MSE train 5.941285428949876 MSE test 12.447109466402642\n",
      "MAE train 1.6895244229219164 MAE test 2.4730998035824365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1865 / 10000 loss: 15.693076372146606\n",
      "MSE train 5.941085142367574 MSE test 12.44684266245266\n",
      "MAE train 1.6894934067333967 MAE test 2.4730672316631543\n",
      "Epoch 1866 / 10000 loss: 15.692345380783081\n",
      "MSE train 5.94067475846056 MSE test 12.446638786886616\n",
      "MAE train 1.6894135420014558 MAE test 2.4730476957614806\n",
      "Epoch 1867 / 10000 loss: 15.691591262817383\n",
      "MSE train 5.9400622130068905 MSE test 12.445873770352547\n",
      "MAE train 1.6892951099115778 MAE test 2.4729534441654897\n",
      "Epoch 1868 / 10000 loss: 15.690008878707886\n",
      "MSE train 5.939861014751803 MSE test 12.44589507826223\n",
      "MAE train 1.6892603441546241 MAE test 2.4729624375301382\n",
      "Epoch 1869 / 10000 loss: 15.687337636947632\n",
      "MSE train 5.939679544582366 MSE test 12.44576893294076\n",
      "MAE train 1.6892323956300488 MAE test 2.472947913002946\n",
      "Epoch 1870 / 10000 loss: 15.686497926712036\n",
      "MSE train 5.939486800192883 MSE test 12.445757715360488\n",
      "MAE train 1.6891994625164242 MAE test 2.4729530029782456\n",
      "Epoch 1871 / 10000 loss: 15.68575668334961\n",
      "MSE train 5.939305395534384 MSE test 12.44560133787846\n",
      "MAE train 1.6891715278856894 MAE test 2.47293504734703\n",
      "Epoch 1872 / 10000 loss: 15.684966802597046\n",
      "MSE train 5.93910167760192 MSE test 12.445566881429048\n",
      "MAE train 1.6891362285288445 MAE test 2.472937171139021\n",
      "Epoch 1873 / 10000 loss: 15.684237241744995\n",
      "MSE train 5.938899029586741 MSE test 12.445401136275073\n",
      "MAE train 1.6891034076006401 MAE test 2.4729178257036173\n",
      "Epoch 1874 / 10000 loss: 15.683403491973877\n",
      "MSE train 5.938711191830811 MSE test 12.445328949313081\n",
      "MAE train 1.6890729138259115 MAE test 2.472915025535025\n",
      "Epoch 1875 / 10000 loss: 15.682565212249756\n",
      "MSE train 5.938510915239122 MSE test 12.44494655229814\n",
      "MAE train 1.6890470696492805 MAE test 2.4728683718961566\n",
      "Epoch 1876 / 10000 loss: 15.681776523590088\n",
      "MSE train 5.938281883063823 MSE test 12.44493546243681\n",
      "MAE train 1.6890064330240142 MAE test 2.4728734214937362\n",
      "Epoch 1877 / 10000 loss: 15.681103229522705\n",
      "MSE train 5.9380714602765705 MSE test 12.444662883727966\n",
      "MAE train 1.68897615479894 MAE test 2.4728405741261508\n",
      "Epoch 1878 / 10000 loss: 15.68013620376587\n",
      "MSE train 5.937851367615037 MSE test 12.444565671352175\n",
      "MAE train 1.6889404748065107 MAE test 2.4728346898445666\n",
      "Epoch 1879 / 10000 loss: 15.679332733154297\n",
      "MSE train 5.937635699807961 MSE test 12.444263255672066\n",
      "MAE train 1.6889103521113746 MAE test 2.472797989671449\n",
      "Epoch 1880 / 10000 loss: 15.678451299667358\n",
      "MSE train 5.93742512022974 MSE test 12.444223648505634\n",
      "MAE train 1.6888753044777518 MAE test 2.472799227052258\n",
      "Epoch 1881 / 10000 loss: 15.677641153335571\n",
      "MSE train 5.937219573294893 MSE test 12.443827760575646\n",
      "MAE train 1.688849083043821 MAE test 2.472750575726488\n",
      "Epoch 1882 / 10000 loss: 15.67676591873169\n",
      "MSE train 5.9369820278470415 MSE test 12.443825600760745\n",
      "MAE train 1.6888061397594742 MAE test 2.472756235568176\n",
      "Epoch 1883 / 10000 loss: 15.67606496810913\n",
      "MSE train 5.936803774673506 MSE test 12.443627037819542\n",
      "MAE train 1.6887796729902873 MAE test 2.4727320601604106\n",
      "Epoch 1884 / 10000 loss: 15.67506742477417\n",
      "MSE train 5.936610173467467 MSE test 12.443404586231635\n",
      "MAE train 1.6887508407379535 MAE test 2.472709706626213\n",
      "Epoch 1885 / 10000 loss: 15.674353837966919\n",
      "MSE train 5.936430667917592 MSE test 12.443272926744287\n",
      "MAE train 1.6887210904316243 MAE test 2.472693962002751\n",
      "Epoch 1886 / 10000 loss: 15.673681735992432\n",
      "MSE train 5.936246790005631 MSE test 12.443107381882513\n",
      "MAE train 1.6886920276683115 MAE test 2.472678704550165\n",
      "Epoch 1887 / 10000 loss: 15.672943115234375\n",
      "MSE train 5.936099281869367 MSE test 12.442946819375035\n",
      "MAE train 1.6886697922249707 MAE test 2.4726593293926378\n",
      "Epoch 1888 / 10000 loss: 15.672279119491577\n",
      "MSE train 5.935926870475734 MSE test 12.442695042613396\n",
      "MAE train 1.6886451045942457 MAE test 2.4726333566246663\n",
      "Epoch 1889 / 10000 loss: 15.671689987182617\n",
      "MSE train 5.935744342436337 MSE test 12.442570746178113\n",
      "MAE train 1.6886140647398387 MAE test 2.472618649888862\n",
      "Epoch 1890 / 10000 loss: 15.671135902404785\n",
      "MSE train 5.935581197792153 MSE test 12.44250497440574\n",
      "MAE train 1.6885867150160068 MAE test 2.472616118395704\n",
      "Epoch 1891 / 10000 loss: 15.670389175415039\n",
      "MSE train 5.93542027990183 MSE test 12.442170574591142\n",
      "MAE train 1.6885659563834234 MAE test 2.4725748952551987\n",
      "Epoch 1892 / 10000 loss: 15.669742345809937\n",
      "MSE train 5.93524530102439 MSE test 12.442171555552466\n",
      "MAE train 1.6885342272428538 MAE test 2.472580966396666\n",
      "Epoch 1893 / 10000 loss: 15.66921091079712\n",
      "MSE train 5.935083311838723 MSE test 12.441847724513364\n",
      "MAE train 1.6885129638887302 MAE test 2.472541104718143\n",
      "Epoch 1894 / 10000 loss: 15.668483018875122\n",
      "MSE train 5.934914556780309 MSE test 12.441843971164745\n",
      "MAE train 1.6884828166384318 MAE test 2.4725466219742844\n",
      "Epoch 1895 / 10000 loss: 15.667940616607666\n",
      "MSE train 5.934754467743832 MSE test 12.441493484680615\n",
      "MAE train 1.6884626576966326 MAE test 2.472503455749376\n",
      "Epoch 1896 / 10000 loss: 15.667242050170898\n",
      "MSE train 5.934569610765103 MSE test 12.441498465242121\n",
      "MAE train 1.6884286712191998 MAE test 2.472510098251495\n",
      "Epoch 1897 / 10000 loss: 15.66672658920288\n",
      "MSE train 5.934404608534859 MSE test 12.441221209847374\n",
      "MAE train 1.688405522431915 MAE test 2.472476172206323\n",
      "Epoch 1898 / 10000 loss: 15.66596007347107\n",
      "MSE train 5.934243379899046 MSE test 12.441176189587189\n",
      "MAE train 1.6883782527240694 MAE test 2.472476455878508\n",
      "Epoch 1899 / 10000 loss: 15.665374040603638\n",
      "MSE train 5.9340843297626655 MSE test 12.440818695447083\n",
      "MAE train 1.6883585401094057 MAE test 2.4724324908229054\n",
      "Epoch 1900 / 10000 loss: 15.664732217788696\n",
      "MSE train 5.933893474288722 MSE test 12.440826204901224\n",
      "MAE train 1.6883233268550837 MAE test 2.472439484000501\n",
      "Epoch 1901 / 10000 loss: 15.66422700881958\n",
      "MSE train 5.9337290933876945 MSE test 12.440576897626478\n",
      "MAE train 1.6882995978969944 MAE test 2.472409106525344\n",
      "Epoch 1902 / 10000 loss: 15.663437604904175\n",
      "MSE train 5.933555366317056 MSE test 12.440488023271698\n",
      "MAE train 1.6882707674486612 MAE test 2.4724038535998023\n",
      "Epoch 1903 / 10000 loss: 15.662838459014893\n",
      "MSE train 5.93338985426303 MSE test 12.440221613376313\n",
      "MAE train 1.6882474001707868 MAE test 2.472371366669975\n",
      "Epoch 1904 / 10000 loss: 15.66217565536499\n",
      "MSE train 5.933224989557222 MSE test 12.440173400225943\n",
      "MAE train 1.6882196088013137 MAE test 2.472371302368386\n",
      "Epoch 1905 / 10000 loss: 15.661584377288818\n",
      "MSE train 5.933064113871822 MSE test 12.439826108631639\n",
      "MAE train 1.688199449845268 MAE test 2.472328636354961\n",
      "Epoch 1906 / 10000 loss: 15.66093635559082\n",
      "MSE train 5.932874845565977 MSE test 12.439832983594684\n",
      "MAE train 1.6881647844583447 MAE test 2.472335582755379\n",
      "Epoch 1907 / 10000 loss: 15.660417318344116\n",
      "MSE train 5.932706927960397 MSE test 12.43956000409971\n",
      "MAE train 1.6881411324193993 MAE test 2.4723022466396793\n",
      "Epoch 1908 / 10000 loss: 15.659638404846191\n",
      "MSE train 5.932541420917493 MSE test 12.439510807270258\n",
      "MAE train 1.6881132737473146 MAE test 2.472302068645547\n",
      "Epoch 1909 / 10000 loss: 15.659042596817017\n",
      "MSE train 5.932379232133591 MSE test 12.439161832433703\n",
      "MAE train 1.6880929055954956 MAE test 2.47225920168688\n",
      "Epoch 1910 / 10000 loss: 15.65839171409607\n",
      "MSE train 5.932189372448033 MSE test 12.43916836798102\n",
      "MAE train 1.6880581409074826 MAE test 2.472266121787382\n",
      "Epoch 1911 / 10000 loss: 15.657870531082153\n",
      "MSE train 5.932021544196864 MSE test 12.438897409842204\n",
      "MAE train 1.6880344415571433 MAE test 2.4722330497041884\n",
      "Epoch 1912 / 10000 loss: 15.657089233398438\n",
      "MSE train 5.931856070274979 MSE test 12.43884539452488\n",
      "MAE train 1.6880066367582554 MAE test 2.4722325261814952\n",
      "Epoch 1913 / 10000 loss: 15.656492948532104\n",
      "MSE train 5.931695086595383 MSE test 12.438502584083977\n",
      "MAE train 1.6879863009785478 MAE test 2.4721904220357476\n",
      "Epoch 1914 / 10000 loss: 15.655844449996948\n",
      "MSE train 5.931510651552115 MSE test 12.438508773289854\n",
      "MAE train 1.687952620469552 MAE test 2.4721973468974863\n",
      "Epoch 1915 / 10000 loss: 15.655322074890137\n",
      "MSE train 5.931346074201842 MSE test 12.438221461264854\n",
      "MAE train 1.6879299168332393 MAE test 2.472162196195955\n",
      "Epoch 1916 / 10000 loss: 15.65456223487854\n",
      "MSE train 5.931188067345302 MSE test 12.438191020629269\n",
      "MAE train 1.6879029765578235 MAE test 2.4721644399913862\n",
      "Epoch 1917 / 10000 loss: 15.653987169265747\n",
      "MSE train 5.931032508546158 MSE test 12.437816243807621\n",
      "MAE train 1.6878842091178723 MAE test 2.4721183412211203\n",
      "Epoch 1918 / 10000 loss: 15.653351068496704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.930840516713518 MSE test 12.437824795175944\n",
      "MAE train 1.6878485590771997 MAE test 2.472125544700085\n",
      "Epoch 1919 / 10000 loss: 15.652871131896973\n",
      "MSE train 5.930692250876482 MSE test 12.437621246731268\n",
      "MAE train 1.6878269273534816 MAE test 2.472100983091029\n",
      "Epoch 1920 / 10000 loss: 15.652077198028564\n",
      "MSE train 5.930521419531627 MSE test 12.437437995396559\n",
      "MAE train 1.687800809142263 MAE test 2.472083851046015\n",
      "Epoch 1921 / 10000 loss: 15.651505708694458\n",
      "MSE train 5.930375192205367 MSE test 12.437300967490893\n",
      "MAE train 1.6877778527188738 MAE test 2.472067787000224\n",
      "Epoch 1922 / 10000 loss: 15.650906562805176\n",
      "MSE train 5.930209242697145 MSE test 12.437069954043938\n",
      "MAE train 1.6877538225389526 MAE test 2.4720446531444145\n",
      "Epoch 1923 / 10000 loss: 15.650308847427368\n",
      "MSE train 5.930039202456787 MSE test 12.436946899071142\n",
      "MAE train 1.6877251094903731 MAE test 2.4720303636847474\n",
      "Epoch 1924 / 10000 loss: 15.64976191520691\n",
      "MSE train 5.929871955699126 MSE test 12.43683956152149\n",
      "MAE train 1.6876975105568557 MAE test 2.4720227953281224\n",
      "Epoch 1925 / 10000 loss: 15.649058103561401\n",
      "MSE train 5.929718309076034 MSE test 12.436601257156106\n",
      "MAE train 1.687675349724918 MAE test 2.4719938595197415\n",
      "Epoch 1926 / 10000 loss: 15.648420572280884\n",
      "MSE train 5.929553268837141 MSE test 12.436506567110376\n",
      "MAE train 1.6876479465864749 MAE test 2.471987931981622\n",
      "Epoch 1927 / 10000 loss: 15.64784860610962\n",
      "MSE train 5.929399467745563 MSE test 12.436261283066017\n",
      "MAE train 1.6876259198151753 MAE test 2.4719581240729767\n",
      "Epoch 1928 / 10000 loss: 15.647214412689209\n",
      "MSE train 5.929238522857046 MSE test 12.436186292138164\n",
      "MAE train 1.687598953318491 MAE test 2.4719546911079835\n",
      "Epoch 1929 / 10000 loss: 15.646645069122314\n",
      "MSE train 5.929085062004371 MSE test 12.4359033306548\n",
      "MAE train 1.6875780809344338 MAE test 2.4719201349558664\n",
      "Epoch 1930 / 10000 loss: 15.646016597747803\n",
      "MSE train 5.928935183312786 MSE test 12.435880107539335\n",
      "MAE train 1.6875522922443924 MAE test 2.4719232763154637\n",
      "Epoch 1931 / 10000 loss: 15.645470380783081\n",
      "MSE train 5.928787631351421 MSE test 12.435501592459557\n",
      "MAE train 1.68753496518367 MAE test 2.4718767277441374\n",
      "Epoch 1932 / 10000 loss: 15.64485478401184\n",
      "MSE train 5.9286009079523785 MSE test 12.435510890949388\n",
      "MAE train 1.6875001634806932 MAE test 2.4718839925369696\n",
      "Epoch 1933 / 10000 loss: 15.644398927688599\n",
      "MSE train 5.928461235446592 MSE test 12.435319313405856\n",
      "MAE train 1.6874798953178496 MAE test 2.4718609290462012\n",
      "Epoch 1934 / 10000 loss: 15.643615007400513\n",
      "MSE train 5.92829610524577 MSE test 12.435112031008476\n",
      "MAE train 1.6874554154051125 MAE test 2.471840779519602\n",
      "Epoch 1935 / 10000 loss: 15.643061876296997\n",
      "MSE train 5.928140300710941 MSE test 12.434984777783992\n",
      "MAE train 1.687429845209608 MAE test 2.4718259604581148\n",
      "Epoch 1936 / 10000 loss: 15.642497062683105\n",
      "MSE train 5.927972544692144 MSE test 12.434809286514149\n",
      "MAE train 1.68740398375385 MAE test 2.4718098026422632\n",
      "Epoch 1937 / 10000 loss: 15.64184856414795\n",
      "MSE train 5.92783384568443 MSE test 12.434665427128293\n",
      "MAE train 1.687382759031979 MAE test 2.4717928568638166\n",
      "Epoch 1938 / 10000 loss: 15.641249418258667\n",
      "MSE train 5.927671287296798 MSE test 12.434422256248778\n",
      "MAE train 1.6873595946371158 MAE test 2.471768252805721\n",
      "Epoch 1939 / 10000 loss: 15.640676975250244\n",
      "MSE train 5.92749974260491 MSE test 12.43429959876161\n",
      "MAE train 1.6873305346681262 MAE test 2.4717540047069293\n",
      "Epoch 1940 / 10000 loss: 15.640149593353271\n",
      "MSE train 5.927342055966682 MSE test 12.434223271557341\n",
      "MAE train 1.6873042485742817 MAE test 2.4717503841426245\n",
      "Epoch 1941 / 10000 loss: 15.639437913894653\n",
      "MSE train 5.927188475825714 MSE test 12.433917387862577\n",
      "MAE train 1.6872839777926152 MAE test 2.471712926388912\n",
      "Epoch 1942 / 10000 loss: 15.638813972473145\n",
      "MSE train 5.927035590086911 MSE test 12.43390635480268\n",
      "MAE train 1.6872571524642526 MAE test 2.471717646193143\n",
      "Epoch 1943 / 10000 loss: 15.638282537460327\n",
      "MSE train 5.926886589234103 MSE test 12.433533591164704\n",
      "MAE train 1.6872394148071552 MAE test 2.4716718193984817\n",
      "Epoch 1944 / 10000 loss: 15.637644290924072\n",
      "MSE train 5.926701671434952 MSE test 12.433542037576311\n",
      "MAE train 1.6872049563210658 MAE test 2.471679016776518\n",
      "Epoch 1945 / 10000 loss: 15.63718056678772\n",
      "MSE train 5.926556781426862 MSE test 12.43333268195108\n",
      "MAE train 1.6871840113744363 MAE test 2.471653729613442\n",
      "Epoch 1946 / 10000 loss: 15.636404275894165\n",
      "MSE train 5.926389366081963 MSE test 12.433162664014139\n",
      "MAE train 1.6871581193499054 MAE test 2.4716383229359042\n",
      "Epoch 1947 / 10000 loss: 15.63584280014038\n",
      "MSE train 5.92625140084694 MSE test 12.433017351570806\n",
      "MAE train 1.6871371565664997 MAE test 2.471621213490722\n",
      "Epoch 1948 / 10000 loss: 15.63524341583252\n",
      "MSE train 5.9260891451240925 MSE test 12.432771529785631\n",
      "MAE train 1.6871141284845723 MAE test 2.471596337527873\n",
      "Epoch 1949 / 10000 loss: 15.634677410125732\n",
      "MSE train 5.925916731847774 MSE test 12.432649203460953\n",
      "MAE train 1.6870849448967413 MAE test 2.4715821534073146\n",
      "Epoch 1950 / 10000 loss: 15.634153604507446\n",
      "MSE train 5.925761094453355 MSE test 12.432580479927232\n",
      "MAE train 1.6870589569042835 MAE test 2.4715795188417573\n",
      "Epoch 1951 / 10000 loss: 15.63343858718872\n",
      "MSE train 5.925608286136303 MSE test 12.432258303498033\n",
      "MAE train 1.6870392938880787 MAE test 2.471540024924282\n",
      "Epoch 1952 / 10000 loss: 15.63281798362732\n",
      "MSE train 5.925447712819988 MSE test 12.432256186568626\n",
      "MAE train 1.6870104848641827 MAE test 2.4715459225396934\n",
      "Epoch 1953 / 10000 loss: 15.632302045822144\n",
      "MSE train 5.925296448867232 MSE test 12.431910646537085\n",
      "MAE train 1.6869917178936016 MAE test 2.47150351201087\n",
      "Epoch 1954 / 10000 loss: 15.631627559661865\n",
      "MSE train 5.925122596275519 MSE test 12.431916140572447\n",
      "MAE train 1.6869597188218346 MAE test 2.4715103736463906\n",
      "Epoch 1955 / 10000 loss: 15.631135940551758\n",
      "MSE train 5.92496708457692 MSE test 12.431631276172517\n",
      "MAE train 1.6869384369416858 MAE test 2.4714755959099266\n",
      "Epoch 1956 / 10000 loss: 15.630403757095337\n",
      "MSE train 5.9248171200341035 MSE test 12.43159843790363\n",
      "MAE train 1.6869128773665438 MAE test 2.4714775758939527\n",
      "Epoch 1957 / 10000 loss: 15.629852771759033\n",
      "MSE train 5.924668275601121 MSE test 12.431227756469173\n",
      "MAE train 1.6868951810871093 MAE test 2.471432069550433\n",
      "Epoch 1958 / 10000 loss: 15.629239082336426\n",
      "MSE train 5.9244831310113755 MSE test 12.431236919529715\n",
      "MAE train 1.6868606859634236 MAE test 2.4714394091841236\n",
      "Epoch 1959 / 10000 loss: 15.628775119781494\n",
      "MSE train 5.924337085983729 MSE test 12.431025339095536\n",
      "MAE train 1.6868395874688047 MAE test 2.4714138633651817\n",
      "Epoch 1960 / 10000 loss: 15.62799859046936\n",
      "MSE train 5.92416905283809 MSE test 12.430861346357286\n",
      "MAE train 1.6868134173901885 MAE test 2.4713992740849426\n",
      "Epoch 1961 / 10000 loss: 15.62743592262268\n",
      "MSE train 5.924031920820705 MSE test 12.430711699266912\n",
      "MAE train 1.6867928225416977 MAE test 2.471381631319222\n",
      "Epoch 1962 / 10000 loss: 15.6268310546875\n",
      "MSE train 5.923869484017512 MSE test 12.430463903412885\n",
      "MAE train 1.6867698337556165 MAE test 2.471356552493168\n",
      "Epoch 1963 / 10000 loss: 15.626272916793823\n",
      "MSE train 5.923696186079377 MSE test 12.430341496711108\n",
      "MAE train 1.6867405191502434 MAE test 2.471342378335281\n",
      "Epoch 1964 / 10000 loss: 15.625749111175537\n",
      "MSE train 5.9235417052208295 MSE test 12.430278217052015\n",
      "MAE train 1.6867146825103017 MAE test 2.4713404666428067\n",
      "Epoch 1965 / 10000 loss: 15.62503170967102\n",
      "MSE train 5.923388983893274 MSE test 12.429945346704654\n",
      "MAE train 1.6866953639739817 MAE test 2.471299670747575\n",
      "Epoch 1966 / 10000 loss: 15.624413251876831\n",
      "MSE train 5.923221913066263 MSE test 12.429947378197461\n",
      "MAE train 1.6866649950551544 MAE test 2.4713061144576964\n",
      "Epoch 1967 / 10000 loss: 15.623906373977661\n",
      "MSE train 5.923067917528719 MSE test 12.429627471976595\n",
      "MAE train 1.6866450539357267 MAE test 2.4712669406464185\n",
      "Epoch 1968 / 10000 loss: 15.623203754425049\n",
      "MSE train 5.922908630189517 MSE test 12.429623325803435\n",
      "MAE train 1.686616634460126 MAE test 2.471272589763039\n",
      "Epoch 1969 / 10000 loss: 15.622682094573975\n",
      "MSE train 5.922757175625717 MSE test 12.4292705776373\n",
      "MAE train 1.6865980442757305 MAE test 2.4712293026687315\n",
      "Epoch 1970 / 10000 loss: 15.622014045715332\n",
      "MSE train 5.92257900152671 MSE test 12.429277402231076\n",
      "MAE train 1.6865650992415775 MAE test 2.4712363675021205\n",
      "Epoch 1971 / 10000 loss: 15.621527433395386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.922422909973947 MSE test 12.429013100735453\n",
      "MAE train 1.68654315144577 MAE test 2.4712041962877334\n",
      "Epoch 1972 / 10000 loss: 15.62077808380127\n",
      "MSE train 5.922266278438302 MSE test 12.428952476696844\n",
      "MAE train 1.6865168317464516 MAE test 2.471202674080014\n",
      "Epoch 1973 / 10000 loss: 15.620212078094482\n",
      "MSE train 5.922113998858 MSE test 12.428630183176809\n",
      "MAE train 1.686497393296277 MAE test 2.471163250149884\n",
      "Epoch 1974 / 10000 loss: 15.619590520858765\n",
      "MSE train 5.9219501680061555 MSE test 12.428631397502054\n",
      "MAE train 1.6864678390360064 MAE test 2.4711695903633246\n",
      "Epoch 1975 / 10000 loss: 15.6190767288208\n",
      "MSE train 5.921797593094356 MSE test 12.428293292287744\n",
      "MAE train 1.6864487081038813 MAE test 2.4711281443589472\n",
      "Epoch 1976 / 10000 loss: 15.618389129638672\n",
      "MSE train 5.9216263965745215 MSE test 12.428297406209493\n",
      "MAE train 1.6864174002276082 MAE test 2.471134858673316\n",
      "Epoch 1977 / 10000 loss: 15.617886066436768\n",
      "MSE train 5.921470547711562 MSE test 12.427993078648635\n",
      "MAE train 1.686396690108463 MAE test 2.4710976511040283\n",
      "Epoch 1978 / 10000 loss: 15.617166757583618\n",
      "MSE train 5.921317309245205 MSE test 12.427978807549254\n",
      "MAE train 1.6863699759887922 MAE test 2.471102020106078\n",
      "Epoch 1979 / 10000 loss: 15.616627931594849\n",
      "MSE train 5.9211665218746825 MSE test 12.427603581723973\n",
      "MAE train 1.6863520310335491 MAE test 2.4710559641004686\n",
      "Epoch 1980 / 10000 loss: 15.615989923477173\n",
      "MSE train 5.920979351203443 MSE test 12.42761195527523\n",
      "MAE train 1.6863172057092801 MAE test 2.4710632273423374\n",
      "Epoch 1981 / 10000 loss: 15.615522146224976\n",
      "MSE train 5.920834136941911 MSE test 12.427407768090205\n",
      "MAE train 1.6862962126678176 MAE test 2.471038623792913\n",
      "Epoch 1982 / 10000 loss: 15.614738941192627\n",
      "MSE train 5.920665293926557 MSE test 12.427226121594146\n",
      "MAE train 1.6862704125027996 MAE test 2.4710218559003216\n",
      "Epoch 1983 / 10000 loss: 15.614174127578735\n",
      "MSE train 5.920520989342967 MSE test 12.42708810155032\n",
      "MAE train 1.6862479657634055 MAE test 2.4710056879456963\n",
      "Epoch 1984 / 10000 loss: 15.613577842712402\n",
      "MSE train 5.920355391631945 MSE test 12.426855510387913\n",
      "MAE train 1.6862240676432496 MAE test 2.4709825394215157\n",
      "Epoch 1985 / 10000 loss: 15.612981796264648\n",
      "MSE train 5.920184352840392 MSE test 12.426732218364208\n",
      "MAE train 1.6861952734341248 MAE test 2.4709682587842163\n",
      "Epoch 1986 / 10000 loss: 15.612435340881348\n",
      "MSE train 5.920017180233303 MSE test 12.426629995998436\n",
      "MAE train 1.6861676760975874 MAE test 2.4709614590885893\n",
      "Epoch 1987 / 10000 loss: 15.61172604560852\n",
      "MSE train 5.919860714175569 MSE test 12.426380940036594\n",
      "MAE train 1.6861453459118234 MAE test 2.470931247023156\n",
      "Epoch 1988 / 10000 loss: 15.611083269119263\n",
      "MSE train 5.919697403742815 MSE test 12.426304477951815\n",
      "MAE train 1.6861180598165484 MAE test 2.470927758739728\n",
      "Epoch 1989 / 10000 loss: 15.610505819320679\n",
      "MSE train 5.91954080200085 MSE test 12.426019977816177\n",
      "MAE train 1.6860967628763692 MAE test 2.4708931162687655\n",
      "Epoch 1990 / 10000 loss: 15.609867811203003\n",
      "MSE train 5.91938766247507 MSE test 12.425996303690523\n",
      "MAE train 1.6860704857896713 MAE test 2.4708962949749447\n",
      "Epoch 1991 / 10000 loss: 15.609310626983643\n",
      "MSE train 5.919236239071266 MSE test 12.425618034027504\n",
      "MAE train 1.6860525772301629 MAE test 2.4708498927646882\n",
      "Epoch 1992 / 10000 loss: 15.608680725097656\n",
      "MSE train 5.919045809284971 MSE test 12.425626826305368\n",
      "MAE train 1.686017194064364 MAE test 2.470857210091051\n",
      "Epoch 1993 / 10000 loss: 15.608211040496826\n",
      "MSE train 5.918901462628604 MSE test 12.425432858084397\n",
      "MAE train 1.6859962701326376 MAE test 2.4708339283881213\n",
      "Epoch 1994 / 10000 loss: 15.607413291931152\n",
      "MSE train 5.9187314416574734 MSE test 12.425228717640202\n",
      "MAE train 1.6859709073863924 MAE test 2.4708143325571674\n",
      "Epoch 1995 / 10000 loss: 15.6068434715271\n",
      "MSE train 5.9185728271472 MSE test 12.425099372067741\n",
      "MAE train 1.685945116259616 MAE test 2.4707992872167397\n",
      "Epoch 1996 / 10000 loss: 15.60625672340393\n",
      "MSE train 5.918400535050893 MSE test 12.424913866020379\n",
      "MAE train 1.6859188067368274 MAE test 2.470782030897104\n",
      "Epoch 1997 / 10000 loss: 15.605597257614136\n",
      "MSE train 5.918252292598475 MSE test 12.424775178192057\n",
      "MAE train 1.6858956889080392 MAE test 2.4707658137666884\n",
      "Epoch 1998 / 10000 loss: 15.604987621307373\n",
      "MSE train 5.918082888864709 MSE test 12.424544338805106\n",
      "MAE train 1.6858711148161316 MAE test 2.470742874784746\n",
      "Epoch 1999 / 10000 loss: 15.604373931884766\n",
      "MSE train 5.917909290468789 MSE test 12.424419364573367\n",
      "MAE train 1.6858419916016312 MAE test 2.470728406464699\n",
      "Epoch 2000 / 10000 loss: 15.603809833526611\n",
      "MSE train 5.917736619540615 MSE test 12.424307648441339\n",
      "MAE train 1.6858135983794955 MAE test 2.4707204351375234\n",
      "Epoch 2001 / 10000 loss: 15.603087425231934\n",
      "MSE train 5.917578012114363 MSE test 12.42407343078664\n",
      "MAE train 1.6857906634215243 MAE test 2.470692133480445\n",
      "Epoch 2002 / 10000 loss: 15.602425813674927\n",
      "MSE train 5.917404758067922 MSE test 12.423965547254655\n",
      "MAE train 1.6857621386666568 MAE test 2.4706847090243853\n",
      "Epoch 2003 / 10000 loss: 15.60182809829712\n",
      "MSE train 5.917246516609338 MSE test 12.423740228432758\n",
      "MAE train 1.685739147296558 MAE test 2.470657532946889\n",
      "Epoch 2004 / 10000 loss: 15.601163864135742\n",
      "MSE train 5.917071334350153 MSE test 12.423620785559084\n",
      "MAE train 1.6857105295819526 MAE test 2.47064868341831\n",
      "Epoch 2005 / 10000 loss: 15.600562334060669\n",
      "MSE train 5.916916810739181 MSE test 12.423417203706327\n",
      "MAE train 1.6856878618169449 MAE test 2.4706242418598916\n",
      "Epoch 2006 / 10000 loss: 15.59989595413208\n",
      "MSE train 5.916741417710701 MSE test 12.423249893302026\n",
      "MAE train 1.6856606244413082 MAE test 2.4706093624320755\n",
      "Epoch 2007 / 10000 loss: 15.59929871559143\n",
      "MSE train 5.916593525646588 MSE test 12.42310219077828\n",
      "MAE train 1.685638102575643 MAE test 2.4705919994629553\n",
      "Epoch 2008 / 10000 loss: 15.598657369613647\n",
      "MSE train 5.916421356132663 MSE test 12.422850202479808\n",
      "MAE train 1.6856135767771785 MAE test 2.4705665182890106\n",
      "Epoch 2009 / 10000 loss: 15.598050355911255\n",
      "MSE train 5.91623708252862 MSE test 12.422722996728817\n",
      "MAE train 1.6855824924578313 MAE test 2.4705517934887165\n",
      "Epoch 2010 / 10000 loss: 15.597482919692993\n",
      "MSE train 5.916071426621685 MSE test 12.42265491962716\n",
      "MAE train 1.6855548361304984 MAE test 2.4705493677550248\n",
      "Epoch 2011 / 10000 loss: 15.59671664237976\n",
      "MSE train 5.915906441118432 MSE test 12.422313411886238\n",
      "MAE train 1.6855335894562595 MAE test 2.4705075856661716\n",
      "Epoch 2012 / 10000 loss: 15.596044778823853\n",
      "MSE train 5.915725018215241 MSE test 12.42230836503254\n",
      "MAE train 1.6855008162950669 MAE test 2.470513238772482\n",
      "Epoch 2013 / 10000 loss: 15.595484733581543\n",
      "MSE train 5.915556070566394 MSE test 12.421985277397182\n",
      "MAE train 1.6854783198120096 MAE test 2.4704737681626745\n",
      "Epoch 2014 / 10000 loss: 15.59471607208252\n",
      "MSE train 5.915383891152593 MSE test 12.42196838482315\n",
      "MAE train 1.6854480707449995 MAE test 2.4704779186271564\n",
      "Epoch 2015 / 10000 loss: 15.594123363494873\n",
      "MSE train 5.915215830120771 MSE test 12.421595136349522\n",
      "MAE train 1.6854270345008555 MAE test 2.4704321910217693\n",
      "Epoch 2016 / 10000 loss: 15.59339714050293\n",
      "MSE train 5.915014641938091 MSE test 12.421590858401784\n",
      "MAE train 1.685390054783704 MAE test 2.4704379734214355\n",
      "Epoch 2017 / 10000 loss: 15.592840433120728\n",
      "MSE train 5.914841184247777 MSE test 12.421340451015924\n",
      "MAE train 1.685364703508829 MAE test 2.4704076545407183\n",
      "Epoch 2018 / 10000 loss: 15.591987133026123\n",
      "MSE train 5.914651260219249 MSE test 12.421215313538145\n",
      "MAE train 1.6853334002936133 MAE test 2.4703981118013756\n",
      "Epoch 2019 / 10000 loss: 15.591320276260376\n",
      "MSE train 5.914475869196555 MSE test 12.42097812877761\n",
      "MAE train 1.6853073816321902 MAE test 2.4703694886434757\n",
      "Epoch 2020 / 10000 loss: 15.590579748153687\n",
      "MSE train 5.914281175891001 MSE test 12.420835060805166\n",
      "MAE train 1.6852755077671608 MAE test 2.4703576565748726\n",
      "Epoch 2021 / 10000 loss: 15.589894771575928\n",
      "MSE train 5.914109648460865 MSE test 12.42062557619862\n",
      "MAE train 1.6852496104919839 MAE test 2.4703324160729765\n",
      "Epoch 2022 / 10000 loss: 15.589142322540283\n",
      "MSE train 5.913915836482807 MSE test 12.420414302417017\n",
      "MAE train 1.6852196781763416 MAE test 2.470311889177909\n",
      "Epoch 2023 / 10000 loss: 15.5884530544281\n",
      "MSE train 5.913736955359499 MSE test 12.420260461416861\n",
      "MAE train 1.6851904534818158 MAE test 2.4702935354061637\n",
      "Epoch 2024 / 10000 loss: 15.587742567062378\n",
      "MSE train 5.913543125054448 MSE test 12.42002486241102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6851606761053355 MAE test 2.470269690580075\n",
      "Epoch 2025 / 10000 loss: 15.586987972259521\n",
      "MSE train 5.913357090076725 MSE test 12.419868010566846\n",
      "MAE train 1.6851291534976 MAE test 2.4702506725502773\n",
      "Epoch 2026 / 10000 loss: 15.58629322052002\n",
      "MSE train 5.913160638373073 MSE test 12.41966500815898\n",
      "MAE train 1.6850971125352092 MAE test 2.4702305146844723\n",
      "Epoch 2027 / 10000 loss: 15.585509538650513\n",
      "MSE train 5.912994159027781 MSE test 12.419473069884729\n",
      "MAE train 1.685070090710253 MAE test 2.4702065416504557\n",
      "Epoch 2028 / 10000 loss: 15.58478307723999\n",
      "MSE train 5.91279743622479 MSE test 12.419173306859273\n",
      "MAE train 1.6850389423176675 MAE test 2.4701736173601456\n",
      "Epoch 2029 / 10000 loss: 15.584096193313599\n",
      "MSE train 5.912577376336088 MSE test 12.418979122766986\n",
      "MAE train 1.6849978009665882 MAE test 2.470148452430097\n",
      "Epoch 2030 / 10000 loss: 15.583430051803589\n",
      "MSE train 5.912339049005071 MSE test 12.418807401584543\n",
      "MAE train 1.6849496786357656 MAE test 2.4701299777206827\n",
      "Epoch 2031 / 10000 loss: 15.582519054412842\n",
      "MSE train 5.91199359140167 MSE test 12.418308057959202\n",
      "MAE train 1.684876971432965 MAE test 2.4700633702315047\n",
      "Epoch 2032 / 10000 loss: 15.581557512283325\n",
      "MSE train 5.911398813886827 MSE test 12.41799279459496\n",
      "MAE train 1.6847216916803065 MAE test 2.4700206677811183\n",
      "Epoch 2033 / 10000 loss: 15.580247163772583\n",
      "MSE train 5.911063254175651 MSE test 12.417392816455097\n",
      "MAE train 1.6846497218512313 MAE test 2.469937488720377\n",
      "Epoch 2034 / 10000 loss: 15.577559232711792\n",
      "MSE train 5.910888752781668 MSE test 12.41747109358119\n",
      "MAE train 1.6846174765449375 MAE test 2.469953856006062\n",
      "Epoch 2035 / 10000 loss: 15.576087236404419\n",
      "MSE train 5.91073178310787 MSE test 12.417208571422504\n",
      "MAE train 1.684596455105423 MAE test 2.469922104086689\n",
      "Epoch 2036 / 10000 loss: 15.575324296951294\n",
      "MSE train 5.910577536001774 MSE test 12.417234305925744\n",
      "MAE train 1.6845691249652233 MAE test 2.469931655100842\n",
      "Epoch 2037 / 10000 loss: 15.574768304824829\n",
      "MSE train 5.910427686042046 MSE test 12.4168946466179\n",
      "MAE train 1.6845511865330067 MAE test 2.469890164216111\n",
      "Epoch 2038 / 10000 loss: 15.574111700057983\n",
      "MSE train 5.910244040787337 MSE test 12.416928774002855\n",
      "MAE train 1.6845168532127444 MAE test 2.469900728930176\n",
      "Epoch 2039 / 10000 loss: 15.573636531829834\n",
      "MSE train 5.9100978449540875 MSE test 12.416735853130799\n",
      "MAE train 1.6844957850285665 MAE test 2.469877576893008\n",
      "Epoch 2040 / 10000 loss: 15.572859525680542\n",
      "MSE train 5.909930893185349 MSE test 12.416602612361594\n",
      "MAE train 1.6844694151197779 MAE test 2.469866949937622\n",
      "Epoch 2041 / 10000 loss: 15.572294235229492\n",
      "MSE train 5.909796011450647 MSE test 12.416463737406042\n",
      "MAE train 1.6844494958966167 MAE test 2.4698506315704285\n",
      "Epoch 2042 / 10000 loss: 15.571681499481201\n",
      "MSE train 5.9096356725640105 MSE test 12.41623842289725\n",
      "MAE train 1.6844267554394763 MAE test 2.4698284550678435\n",
      "Epoch 2043 / 10000 loss: 15.571133613586426\n",
      "MSE train 5.90946488054837 MSE test 12.416133618460451\n",
      "MAE train 1.684397854210326 MAE test 2.4698164518969583\n",
      "Epoch 2044 / 10000 loss: 15.57061219215393\n",
      "MSE train 5.909310506189532 MSE test 12.416079405630569\n",
      "MAE train 1.6843720677366598 MAE test 2.4698156515019782\n",
      "Epoch 2045 / 10000 loss: 15.56990098953247\n",
      "MSE train 5.909159189798052 MSE test 12.415777356200863\n",
      "MAE train 1.6843525619550321 MAE test 2.469778716936731\n",
      "Epoch 2046 / 10000 loss: 15.569283246994019\n",
      "MSE train 5.90900291028338 MSE test 12.415787417886541\n",
      "MAE train 1.6843246469342257 MAE test 2.4697860917341514\n",
      "Epoch 2047 / 10000 loss: 15.568769693374634\n",
      "MSE train 5.908854203748209 MSE test 12.415447028656564\n",
      "MAE train 1.6843065788562188 MAE test 2.4697443143271522\n",
      "Epoch 2048 / 10000 loss: 15.56810998916626\n",
      "MSE train 5.908677968506244 MSE test 12.415466598510827\n",
      "MAE train 1.6842738796605397 MAE test 2.4697528986368793\n",
      "Epoch 2049 / 10000 loss: 15.567633390426636\n",
      "MSE train 5.90852506251597 MSE test 12.415220278381927\n",
      "MAE train 1.6842523284326945 MAE test 2.469722901836084\n",
      "Epoch 2050 / 10000 loss: 15.566890239715576\n",
      "MSE train 5.9083689725983 MSE test 12.41516228407793\n",
      "MAE train 1.684226166638035 MAE test 2.4697216269460425\n",
      "Epoch 2051 / 10000 loss: 15.566331386566162\n",
      "MSE train 5.908218257418434 MSE test 12.414870340153096\n",
      "MAE train 1.6842064491061761 MAE test 2.469685906381718\n",
      "Epoch 2052 / 10000 loss: 15.565714836120605\n",
      "MSE train 5.908066848823643 MSE test 12.414871668930534\n",
      "MAE train 1.684179791898802 MAE test 2.4696921256440927\n",
      "Epoch 2053 / 10000 loss: 15.565192937850952\n",
      "MSE train 5.907919922716432 MSE test 12.414509955564812\n",
      "MAE train 1.6841624663462138 MAE test 2.4696476524120765\n",
      "Epoch 2054 / 10000 loss: 15.564560174942017\n",
      "MSE train 5.907737051051938 MSE test 12.414527992583423\n",
      "MAE train 1.6841283132701315 MAE test 2.469655996770672\n",
      "Epoch 2055 / 10000 loss: 15.564104318618774\n",
      "MSE train 5.907594030158145 MSE test 12.414328142953023\n",
      "MAE train 1.684107746759705 MAE test 2.46963178623899\n",
      "Epoch 2056 / 10000 loss: 15.563336372375488\n",
      "MSE train 5.907428617706245 MSE test 12.414167246300885\n",
      "MAE train 1.6840821394986103 MAE test 2.4696175223677117\n",
      "Epoch 2057 / 10000 loss: 15.562784433364868\n",
      "MSE train 5.907292710876057 MSE test 12.414030178154208\n",
      "MAE train 1.6840615888131296 MAE test 2.4696012824372313\n",
      "Epoch 2058 / 10000 loss: 15.562192440032959\n",
      "MSE train 5.907132309561087 MSE test 12.41379302180233\n",
      "MAE train 1.6840388328534173 MAE test 2.469577468605315\n",
      "Epoch 2059 / 10000 loss: 15.561635494232178\n",
      "MSE train 5.906962104652364 MSE test 12.413678475343774\n",
      "MAE train 1.6840100430268006 MAE test 2.4695641011988907\n",
      "Epoch 2060 / 10000 loss: 15.561118364334106\n",
      "MSE train 5.906808352616225 MSE test 12.413615899021545\n",
      "MAE train 1.683984357181814 MAE test 2.4695621469546567\n",
      "Epoch 2061 / 10000 loss: 15.560412883758545\n",
      "MSE train 5.9066572978266585 MSE test 12.413303873141059\n",
      "MAE train 1.6839649367384333 MAE test 2.4695238266744957\n",
      "Epoch 2062 / 10000 loss: 15.559800386428833\n",
      "MSE train 5.906500356326099 MSE test 12.413307251714652\n",
      "MAE train 1.6839368319267294 MAE test 2.4695302597312216\n",
      "Epoch 2063 / 10000 loss: 15.55929183959961\n",
      "MSE train 5.906351474718236 MSE test 12.412963718202633\n",
      "MAE train 1.6839186133165123 MAE test 2.469487984741198\n",
      "Epoch 2064 / 10000 loss: 15.558631658554077\n",
      "MSE train 5.9061772991683705 MSE test 12.41297642584907\n",
      "MAE train 1.68388636623988 MAE test 2.469495613483128\n",
      "Epoch 2065 / 10000 loss: 15.558154344558716\n",
      "MSE train 5.906023930526097 MSE test 12.412713162810434\n",
      "MAE train 1.6838650142974256 MAE test 2.469463401429317\n",
      "Epoch 2066 / 10000 loss: 15.557422399520874\n",
      "MSE train 5.905872537396717 MSE test 12.412666656088614\n",
      "MAE train 1.6838394606454419 MAE test 2.4694634827080777\n",
      "Epoch 2067 / 10000 loss: 15.556869268417358\n",
      "MSE train 5.905724469942973 MSE test 12.412334094543352\n",
      "MAE train 1.6838211889791457 MAE test 2.469422597770401\n",
      "Epoch 2068 / 10000 loss: 15.556263446807861\n",
      "MSE train 5.905554416276148 MSE test 12.412345522288176\n",
      "MAE train 1.6837898724669853 MAE test 2.469430062747299\n",
      "Epoch 2069 / 10000 loss: 15.555778980255127\n",
      "MSE train 5.905401534361684 MSE test 12.412057568289498\n",
      "MAE train 1.6837693464622479 MAE test 2.4693947260968265\n",
      "Epoch 2070 / 10000 loss: 15.55506420135498\n",
      "MSE train 5.905253843128221 MSE test 12.4120403801443\n",
      "MAE train 1.6837438858779714 MAE test 2.4693985328031998\n",
      "Epoch 2071 / 10000 loss: 15.554530382156372\n",
      "MSE train 5.905107097557018 MSE test 12.41166827826325\n",
      "MAE train 1.683726695843003 MAE test 2.469352679359579\n",
      "Epoch 2072 / 10000 loss: 15.553921222686768\n",
      "MSE train 5.9049231134783255 MSE test 12.411681843321759\n",
      "MAE train 1.6836923479888142 MAE test 2.469360423205449\n",
      "Epoch 2073 / 10000 loss: 15.55347228050232\n",
      "MSE train 5.904783907297794 MSE test 12.411489957169003\n",
      "MAE train 1.6836723111446217 MAE test 2.4693371483155806\n",
      "Epoch 2074 / 10000 loss: 15.552701711654663\n",
      "MSE train 5.904619896766859 MSE test 12.41129852688817\n",
      "MAE train 1.6836476968284646 MAE test 2.469318982055993\n",
      "Epoch 2075 / 10000 loss: 15.552156686782837\n",
      "MSE train 5.9044721299750735 MSE test 12.41117227682991\n",
      "MAE train 1.683624013836413 MAE test 2.4693040824793013\n",
      "Epoch 2076 / 10000 loss: 15.551591157913208\n",
      "MSE train 5.904308387708791 MSE test 12.41097449938245\n",
      "MAE train 1.6835995982425376 MAE test 2.469285119371386\n",
      "Epoch 2077 / 10000 loss: 15.550979137420654\n",
      "MSE train 5.904157512406799 MSE test 12.410850007355087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6835751472966867 MAE test 2.4692704302344017\n",
      "Epoch 2078 / 10000 loss: 15.550418853759766\n",
      "MSE train 5.903992509600069 MSE test 12.410666008590413\n",
      "MAE train 1.6835500991687464 MAE test 2.469253193421146\n",
      "Epoch 2079 / 10000 loss: 15.549792051315308\n",
      "MSE train 5.903849777266045 MSE test 12.410535016825335\n",
      "MAE train 1.6835276925974252 MAE test 2.469237675662803\n",
      "Epoch 2080 / 10000 loss: 15.549217700958252\n",
      "MSE train 5.903687508204963 MSE test 12.410317151647986\n",
      "MAE train 1.6835040418771892 MAE test 2.4692162070146777\n",
      "Epoch 2081 / 10000 loss: 15.548628091812134\n",
      "MSE train 5.903525534753792 MSE test 12.410197038795099\n",
      "MAE train 1.6834770140361583 MAE test 2.4692020731356354\n",
      "Epoch 2082 / 10000 loss: 15.548089027404785\n",
      "MSE train 5.903358999884817 MSE test 12.410069489215287\n",
      "MAE train 1.6834500113825388 MAE test 2.469191923302513\n",
      "Epoch 2083 / 10000 loss: 15.547415971755981\n",
      "MSE train 5.903218131196258 MSE test 12.409879679658319\n",
      "MAE train 1.683429578146298 MAE test 2.469168952857361\n",
      "Epoch 2084 / 10000 loss: 15.546797037124634\n",
      "MSE train 5.903055018730457 MSE test 12.409697726558425\n",
      "MAE train 1.6834049029588578 MAE test 2.4691520120495625\n",
      "Epoch 2085 / 10000 loss: 15.546252489089966\n",
      "MSE train 5.902910734280701 MSE test 12.40956959936563\n",
      "MAE train 1.6833820912878947 MAE test 2.4691368550154142\n",
      "Epoch 2086 / 10000 loss: 15.545682668685913\n",
      "MSE train 5.902748761924813 MSE test 12.409354753551282\n",
      "MAE train 1.6833584240852972 MAE test 2.4691157780544652\n",
      "Epoch 2087 / 10000 loss: 15.545086145401001\n",
      "MSE train 5.902587995771294 MSE test 12.409234510081005\n",
      "MAE train 1.683331667812029 MAE test 2.469101612719502\n",
      "Epoch 2088 / 10000 loss: 15.544545412063599\n",
      "MSE train 5.902421169389536 MSE test 12.409098753348783\n",
      "MAE train 1.683304821991629 MAE test 2.4690904469351054\n",
      "Epoch 2089 / 10000 loss: 15.543877601623535\n",
      "MSE train 5.902283417023758 MSE test 12.408920594952537\n",
      "MAE train 1.6832847922796133 MAE test 2.4690689382699427\n",
      "Epoch 2090 / 10000 loss: 15.54326343536377\n",
      "MSE train 5.902122056213256 MSE test 12.408714163368698\n",
      "MAE train 1.68326108394994 MAE test 2.4690489236389697\n",
      "Epoch 2091 / 10000 loss: 15.542723655700684\n",
      "MSE train 5.9019643067459295 MSE test 12.408593483129511\n",
      "MAE train 1.6832350049089517 MAE test 2.46903471127679\n",
      "Epoch 2092 / 10000 loss: 15.54217791557312\n",
      "MSE train 5.901797673678846 MSE test 12.408439802793453\n",
      "MAE train 1.6832087366390425 MAE test 2.469021302878121\n",
      "Epoch 2093 / 10000 loss: 15.541523456573486\n",
      "MSE train 5.9016636795684665 MSE test 12.408284395785998\n",
      "MAE train 1.6831889799506174 MAE test 2.4690026563611016\n",
      "Epoch 2094 / 10000 loss: 15.540920495986938\n",
      "MSE train 5.901503533339529 MSE test 12.40804438580082\n",
      "MAE train 1.6831662298863563 MAE test 2.4689784560498484\n",
      "Epoch 2095 / 10000 loss: 15.540382385253906\n",
      "MSE train 5.901333384843134 MSE test 12.407925803279516\n",
      "MAE train 1.683137438926141 MAE test 2.4689645238079074\n",
      "Epoch 2096 / 10000 loss: 15.539867162704468\n",
      "MSE train 5.901178861171792 MSE test 12.407856995126638\n",
      "MAE train 1.6831116231432446 MAE test 2.4689617777210775\n",
      "Epoch 2097 / 10000 loss: 15.539163827896118\n",
      "MSE train 5.901027487646085 MSE test 12.407546687832047\n",
      "MAE train 1.6830919957715285 MAE test 2.4689236079286845\n",
      "Epoch 2098 / 10000 loss: 15.538551568984985\n",
      "MSE train 5.900873087992067 MSE test 12.407543654542453\n",
      "MAE train 1.6830645340993826 MAE test 2.4689292259830675\n",
      "Epoch 2099 / 10000 loss: 15.538038492202759\n",
      "MSE train 5.900724897514448 MSE test 12.40718698946758\n",
      "MAE train 1.6830466746074024 MAE test 2.468885259845455\n",
      "Epoch 2100 / 10000 loss: 15.537393808364868\n",
      "MSE train 5.900546118167434 MSE test 12.407197571825316\n",
      "MAE train 1.6830133948818355 MAE test 2.4688926324908382\n",
      "Epoch 2101 / 10000 loss: 15.536927700042725\n",
      "MSE train 5.900395414538295 MSE test 12.406959851906167\n",
      "MAE train 1.6829918681752987 MAE test 2.468863563744599\n",
      "Epoch 2102 / 10000 loss: 15.536177396774292\n",
      "MSE train 5.900232377072324 MSE test 12.406861947498292\n",
      "MAE train 1.6829649038056826 MAE test 2.4688571898984866\n",
      "Epoch 2103 / 10000 loss: 15.535619974136353\n",
      "MSE train 5.900081921761048 MSE test 12.40662805301988\n",
      "MAE train 1.6829433803011342 MAE test 2.4688286534653328\n",
      "Epoch 2104 / 10000 loss: 15.534997463226318\n",
      "MSE train 5.899920214977903 MSE test 12.40653991760522\n",
      "MAE train 1.6829164956850067 MAE test 2.468823538840877\n",
      "Epoch 2105 / 10000 loss: 15.534440517425537\n",
      "MSE train 5.899768701986194 MSE test 12.406293988566908\n",
      "MAE train 1.6828950545442891 MAE test 2.4687935007471977\n",
      "Epoch 2106 / 10000 loss: 15.533819675445557\n",
      "MSE train 5.899612243547768 MSE test 12.406230047920387\n",
      "MAE train 1.682868754837923 MAE test 2.4687914300632774\n",
      "Epoch 2107 / 10000 loss: 15.533265590667725\n",
      "MSE train 5.89946205144862 MSE test 12.40593324203862\n",
      "MAE train 1.6828490521387043 MAE test 2.468754992609914\n",
      "Epoch 2108 / 10000 loss: 15.532652854919434\n",
      "MSE train 5.899310903344133 MSE test 12.405927334460374\n",
      "MAE train 1.6828224470592361 MAE test 2.468760265068163\n",
      "Epoch 2109 / 10000 loss: 15.532134532928467\n",
      "MSE train 5.899164326536946 MSE test 12.405557404841971\n",
      "MAE train 1.6828052185345588 MAE test 2.468714658991487\n",
      "Epoch 2110 / 10000 loss: 15.531507015228271\n",
      "MSE train 5.898980881027799 MSE test 12.40556898368022\n",
      "MAE train 1.6827709302514153 MAE test 2.4687221595757936\n",
      "Epoch 2111 / 10000 loss: 15.531055450439453\n",
      "MSE train 5.898839261499522 MSE test 12.405368097998942\n",
      "MAE train 1.682750552773913 MAE test 2.4686977287250955\n",
      "Epoch 2112 / 10000 loss: 15.530287742614746\n",
      "MSE train 5.898674264784247 MSE test 12.40519120726793\n",
      "MAE train 1.6827252900791299 MAE test 2.468681437315248\n",
      "Epoch 2113 / 10000 loss: 15.529740810394287\n",
      "MSE train 5.898534773754177 MSE test 12.405055580191283\n",
      "MAE train 1.6827037202350315 MAE test 2.4686653061087593\n",
      "Epoch 2114 / 10000 loss: 15.529160022735596\n",
      "MSE train 5.898373492153793 MSE test 12.404824056747835\n",
      "MAE train 1.682680533879752 MAE test 2.468642167912004\n",
      "Epoch 2115 / 10000 loss: 15.52858591079712\n",
      "MSE train 5.898206238694181 MSE test 12.404704328940008\n",
      "MAE train 1.6826523328407068 MAE test 2.468628074393953\n",
      "Epoch 2116 / 10000 loss: 15.528061389923096\n",
      "MSE train 5.898044796171735 MSE test 12.404610575678946\n",
      "MAE train 1.6826255853578358 MAE test 2.4686222048428195\n",
      "Epoch 2117 / 10000 loss: 15.52736783027649\n",
      "MSE train 5.897892311252644 MSE test 12.404353576089056\n",
      "MAE train 1.6826042010040403 MAE test 2.4685907515406034\n",
      "Epoch 2118 / 10000 loss: 15.526747226715088\n",
      "MSE train 5.897738709735815 MSE test 12.404297901771427\n",
      "MAE train 1.6825783136565713 MAE test 2.468589731888101\n",
      "Epoch 2119 / 10000 loss: 15.52619481086731\n",
      "MSE train 5.897589822917185 MSE test 12.40397804220892\n",
      "MAE train 1.6825594858891337 MAE test 2.4685503773178414\n",
      "Epoch 2120 / 10000 loss: 15.525587558746338\n",
      "MSE train 5.897428077672154 MSE test 12.403982625739754\n",
      "MAE train 1.682530147291996 MAE test 2.4685570180634833\n",
      "Epoch 2121 / 10000 loss: 15.525088787078857\n",
      "MSE train 5.897278184097311 MSE test 12.403652521617898\n",
      "MAE train 1.6825113387175301 MAE test 2.4685163484846004\n",
      "Epoch 2122 / 10000 loss: 15.52441120147705\n",
      "MSE train 5.897113080776452 MSE test 12.403657740983222\n",
      "MAE train 1.6824811925299625 MAE test 2.468523047353708\n",
      "Epoch 2123 / 10000 loss: 15.52391767501831\n",
      "MSE train 5.89696134410325 MSE test 12.403344502987613\n",
      "MAE train 1.6824615489905537 MAE test 2.4684844874196137\n",
      "Epoch 2124 / 10000 loss: 15.523225545883179\n",
      "MSE train 5.896806398712593 MSE test 12.403341094289813\n",
      "MAE train 1.6824339508861683 MAE test 2.46849008050257\n",
      "Epoch 2125 / 10000 loss: 15.522713899612427\n",
      "MSE train 5.896657811063191 MSE test 12.40298634866249\n",
      "MAE train 1.6824159762557649 MAE test 2.468446350035102\n",
      "Epoch 2126 / 10000 loss: 15.522064924240112\n",
      "MSE train 5.896480062854536 MSE test 12.402996202611021\n",
      "MAE train 1.6823829205801009 MAE test 2.4684536496547445\n",
      "Epoch 2127 / 10000 loss: 15.52159595489502\n",
      "MSE train 5.896328247998918 MSE test 12.402751135588575\n",
      "MAE train 1.6823613220976128 MAE test 2.468423658629464\n",
      "Epoch 2128 / 10000 loss: 15.52085018157959\n",
      "MSE train 5.896167610143802 MSE test 12.402665961712511\n",
      "MAE train 1.6823345935626388 MAE test 2.468418919783537\n",
      "Epoch 2129 / 10000 loss: 15.520292043685913\n",
      "MSE train 5.896015395229222 MSE test 12.402404891396195\n",
      "MAE train 1.6823134170285559 MAE test 2.468386952057712\n",
      "Epoch 2130 / 10000 loss: 15.519672632217407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.895864053752707 MSE test 12.402359425981954\n",
      "MAE train 1.682287795776324 MAE test 2.468387225206217\n",
      "Epoch 2131 / 10000 loss: 15.519123792648315\n",
      "MSE train 5.895716687064852 MSE test 12.402020638099682\n",
      "MAE train 1.6822697657991164 MAE test 2.468345514232498\n",
      "Epoch 2132 / 10000 loss: 15.518520593643188\n",
      "MSE train 5.895543952563163 MSE test 12.40203067336432\n",
      "MAE train 1.6822378253426278 MAE test 2.468352843755334\n",
      "Epoch 2133 / 10000 loss: 15.518041610717773\n",
      "MSE train 5.895390611139385 MSE test 12.401752822345722\n",
      "MAE train 1.682216850694698 MAE test 2.468318747290501\n",
      "Epoch 2134 / 10000 loss: 15.517317533493042\n",
      "MSE train 5.895242460654923 MSE test 12.401719882258291\n",
      "MAE train 1.682191610372138 MAE test 2.4683205881287034\n",
      "Epoch 2135 / 10000 loss: 15.516773700714111\n",
      "MSE train 5.895095479852556 MSE test 12.401356780321391\n",
      "MAE train 1.6821741719553056 MAE test 2.468275832694023\n",
      "Epoch 2136 / 10000 loss: 15.516172885894775\n",
      "MSE train 5.8949136659670485 MSE test 12.40136822211581\n",
      "MAE train 1.6821402129858312 MAE test 2.4682833455600566\n",
      "Epoch 2137 / 10000 loss: 15.515715599060059\n",
      "MSE train 5.894767239260876 MSE test 12.401150745248925\n",
      "MAE train 1.6821191826624735 MAE test 2.4682568366496898\n",
      "Epoch 2138 / 10000 loss: 15.514954566955566\n",
      "MSE train 5.894600915447999 MSE test 12.40100991769764\n",
      "MAE train 1.682092631427065 MAE test 2.4682450771960545\n",
      "Epoch 2139 / 10000 loss: 15.514398574829102\n",
      "MSE train 5.89446524322779 MSE test 12.400842552659881\n",
      "MAE train 1.6820728105379157 MAE test 2.4682249174463964\n",
      "Epoch 2140 / 10000 loss: 15.513788938522339\n",
      "MSE train 5.89430492503646 MSE test 12.400616972560657\n",
      "MAE train 1.6820497203637166 MAE test 2.4682025653540234\n",
      "Epoch 2141 / 10000 loss: 15.513252019882202\n",
      "MSE train 5.894138473435595 MSE test 12.400498027140713\n",
      "MAE train 1.6820217025155024 MAE test 2.468188583393834\n",
      "Epoch 2142 / 10000 loss: 15.51272463798523\n",
      "MSE train 5.893974982988248 MSE test 12.400395215780211\n",
      "MAE train 1.681994722023596 MAE test 2.4681815885430205\n",
      "Epoch 2143 / 10000 loss: 15.512034893035889\n",
      "MSE train 5.893824022906656 MSE test 12.400158102379743\n",
      "MAE train 1.6819731742880177 MAE test 2.4681526480857663\n",
      "Epoch 2144 / 10000 loss: 15.511411666870117\n",
      "MSE train 5.893662473891613 MSE test 12.400070280541847\n",
      "MAE train 1.6819463028000516 MAE test 2.4681475883049706\n",
      "Epoch 2145 / 10000 loss: 15.510854482650757\n",
      "MSE train 5.893510566550533 MSE test 12.39982009491976\n",
      "MAE train 1.6819249099732252 MAE test 2.468117014321045\n",
      "Epoch 2146 / 10000 loss: 15.510232925415039\n",
      "MSE train 5.893355396174228 MSE test 12.3997610445159\n",
      "MAE train 1.68189877550299 MAE test 2.4681155976408338\n",
      "Epoch 2147 / 10000 loss: 15.509678840637207\n",
      "MSE train 5.8932059089308275 MSE test 12.399451781242044\n",
      "MAE train 1.6818795726920448 MAE test 2.4680775823434247\n",
      "Epoch 2148 / 10000 loss: 15.509068489074707\n",
      "MSE train 5.893049273547233 MSE test 12.39945239461516\n",
      "MAE train 1.6818515427092537 MAE test 2.468083727101465\n",
      "Epoch 2149 / 10000 loss: 15.5085608959198\n",
      "MSE train 5.892901156261609 MSE test 12.3991004137957\n",
      "MAE train 1.6818336124327744 MAE test 2.468040333970615\n",
      "Epoch 2150 / 10000 loss: 15.507907152175903\n",
      "MSE train 5.892723832133699 MSE test 12.399110587703285\n",
      "MAE train 1.681800652972748 MAE test 2.468047710957876\n",
      "Epoch 2151 / 10000 loss: 15.50743556022644\n",
      "MSE train 5.892571405968883 MSE test 12.398861045829312\n",
      "MAE train 1.6817790433664221 MAE test 2.4680171614684108\n",
      "Epoch 2152 / 10000 loss: 15.506693601608276\n",
      "MSE train 5.892412664015839 MSE test 12.398784496356406\n",
      "MAE train 1.6817525355478065 MAE test 2.468013526496006\n",
      "Epoch 2153 / 10000 loss: 15.506134748458862\n",
      "MSE train 5.892260627998822 MSE test 12.398505534639451\n",
      "MAE train 1.6817319158481276 MAE test 2.4679793248738893\n",
      "Epoch 2154 / 10000 loss: 15.505518436431885\n",
      "MSE train 5.8921127468430665 MSE test 12.398481175600153\n",
      "MAE train 1.6817065673845522 MAE test 2.4679822892509145\n",
      "Epoch 2155 / 10000 loss: 15.504979848861694\n",
      "MSE train 5.891966507644579 MSE test 12.398109917581849\n",
      "MAE train 1.681689443734422 MAE test 2.467936516733255\n",
      "Epoch 2156 / 10000 loss: 15.504377365112305\n",
      "MSE train 5.8917824311328495 MSE test 12.39812162740245\n",
      "MAE train 1.6816550565130628 MAE test 2.467944093441389\n",
      "Epoch 2157 / 10000 loss: 15.503928899765015\n",
      "MSE train 5.891641927170598 MSE test 12.397924573198184\n",
      "MAE train 1.6816348426777006 MAE test 2.46792015475131\n",
      "Epoch 2158 / 10000 loss: 15.503159523010254\n",
      "MSE train 5.8914773402138225 MSE test 12.397738174738617\n",
      "MAE train 1.681609914381181 MAE test 2.4679026859480504\n",
      "Epoch 2159 / 10000 loss: 15.502613067626953\n",
      "MSE train 5.891333333691794 MSE test 12.397607111896326\n",
      "MAE train 1.6815872033249895 MAE test 2.467887149309127\n",
      "Epoch 2160 / 10000 loss: 15.502041578292847\n",
      "MSE train 5.891170749504175 MSE test 12.397391281649913\n",
      "MAE train 1.6815633922641446 MAE test 2.4678659807937953\n",
      "Epoch 2161 / 10000 loss: 15.501445531845093\n",
      "MSE train 5.891010473212947 MSE test 12.397269267078768\n",
      "MAE train 1.681536766177122 MAE test 2.4678516230730434\n",
      "Epoch 2162 / 10000 loss: 15.500903606414795\n",
      "MSE train 5.890843386001357 MSE test 12.397129475793067\n",
      "MAE train 1.6815099666324265 MAE test 2.4678399847480375\n",
      "Epoch 2163 / 10000 loss: 15.500239372253418\n",
      "MSE train 5.890706446805394 MSE test 12.396953939151917\n",
      "MAE train 1.681490038787992 MAE test 2.467818814364826\n",
      "Epoch 2164 / 10000 loss: 15.499626636505127\n",
      "MSE train 5.890545203173336 MSE test 12.39673943741295\n",
      "MAE train 1.6814664933936176 MAE test 2.46779784527547\n",
      "Epoch 2165 / 10000 loss: 15.4990873336792\n",
      "MSE train 5.890383921803207 MSE test 12.3966189797167\n",
      "MAE train 1.681439616319198 MAE test 2.467783686045121\n",
      "Epoch 2166 / 10000 loss: 15.49854826927185\n",
      "MSE train 5.890217072481768 MSE test 12.396483185239179\n",
      "MAE train 1.6814127253222992 MAE test 2.46777256158759\n",
      "Epoch 2167 / 10000 loss: 15.49787974357605\n",
      "MSE train 5.8900788745618335 MSE test 12.396302846240564\n",
      "MAE train 1.6813926238310148 MAE test 2.4677507851270852\n",
      "Epoch 2168 / 10000 loss: 15.497265338897705\n",
      "MSE train 5.889917133386244 MSE test 12.396098077771438\n",
      "MAE train 1.681368745815244 MAE test 2.4677310356825273\n",
      "Epoch 2169 / 10000 loss: 15.496725797653198\n",
      "MSE train 5.889760787848161 MSE test 12.395975742160664\n",
      "MAE train 1.6813429822336434 MAE test 2.4677166399578554\n",
      "Epoch 2170 / 10000 loss: 15.496176719665527\n",
      "MSE train 5.889594411268629 MSE test 12.395813382148337\n",
      "MAE train 1.6813169578723668 MAE test 2.46770217994908\n",
      "Epoch 2171 / 10000 loss: 15.495528936386108\n",
      "MSE train 5.889459767230534 MSE test 12.395664499016432\n",
      "MAE train 1.6812968432791593 MAE test 2.467684394287231\n",
      "Epoch 2172 / 10000 loss: 15.49493408203125\n",
      "MSE train 5.889299204622095 MSE test 12.395420332352876\n",
      "MAE train 1.681274019168225 MAE test 2.4676597208457896\n",
      "Epoch 2173 / 10000 loss: 15.49438762664795\n",
      "MSE train 5.889128656151719 MSE test 12.395300625885067\n",
      "MAE train 1.6812451107953046 MAE test 2.4676456740815973\n",
      "Epoch 2174 / 10000 loss: 15.493874311447144\n",
      "MSE train 5.888975568528136 MSE test 12.39523576913893\n",
      "MAE train 1.681219474178434 MAE test 2.467643486743691\n",
      "Epoch 2175 / 10000 loss: 15.493171453475952\n",
      "MSE train 5.888824556990794 MSE test 12.394913327797335\n",
      "MAE train 1.6812001503368814 MAE test 2.467603800651635\n",
      "Epoch 2176 / 10000 loss: 15.492562770843506\n",
      "MSE train 5.88866442743287 MSE test 12.394914336020507\n",
      "MAE train 1.68117118388839 MAE test 2.467610012550822\n",
      "Epoch 2177 / 10000 loss: 15.492059707641602\n",
      "MSE train 5.888514158420955 MSE test 12.394579470839707\n",
      "MAE train 1.681152303454287 MAE test 2.4675687663223758\n",
      "Epoch 2178 / 10000 loss: 15.491389036178589\n",
      "MSE train 5.888346941942385 MSE test 12.394584588835606\n",
      "MAE train 1.681121618947368 MAE test 2.4675755105703336\n",
      "Epoch 2179 / 10000 loss: 15.490898370742798\n",
      "MSE train 5.8881941364654855 MSE test 12.394280697207389\n",
      "MAE train 1.6811013793473117 MAE test 2.4675381318768657\n",
      "Epoch 2180 / 10000 loss: 15.490196943283081\n",
      "MSE train 5.888043356939674 MSE test 12.394269842866171\n",
      "MAE train 1.6810748812829892 MAE test 2.467542851116719\n",
      "Epoch 2181 / 10000 loss: 15.48967432975769\n",
      "MSE train 5.8878954259183915 MSE test 12.393900507963833\n",
      "MAE train 1.6810572101051349 MAE test 2.4674973084320597\n",
      "Epoch 2182 / 10000 loss: 15.48904800415039\n",
      "MSE train 5.887712522380073 MSE test 12.393910588415842\n",
      "MAE train 1.6810229704829673 MAE test 2.467504711072684\n",
      "Epoch 2183 / 10000 loss: 15.48859190940857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.887568518919591 MSE test 12.39370192393508\n",
      "MAE train 1.6810021475077568 MAE test 2.467479316851328\n",
      "Epoch 2184 / 10000 loss: 15.487828016281128\n",
      "MSE train 5.8874022975939475 MSE test 12.393538812980385\n",
      "MAE train 1.6809761196894555 MAE test 2.4674648071893963\n",
      "Epoch 2185 / 10000 loss: 15.487276315689087\n",
      "MSE train 5.887266792375711 MSE test 12.3933921106222\n",
      "MAE train 1.6809556844137588 MAE test 2.46744731201422\n",
      "Epoch 2186 / 10000 loss: 15.486681461334229\n",
      "MSE train 5.887105906572591 MSE test 12.393147711259454\n",
      "MAE train 1.6809327100473428 MAE test 2.4674226165330206\n",
      "Epoch 2187 / 10000 loss: 15.486131191253662\n",
      "MSE train 5.886934758725445 MSE test 12.39302756582284\n",
      "MAE train 1.6809036044000032 MAE test 2.467408517250552\n",
      "Epoch 2188 / 10000 loss: 15.485616445541382\n",
      "MSE train 5.886781191304965 MSE test 12.392962871952193\n",
      "MAE train 1.6808777891914468 MAE test 2.467406370104434\n",
      "Epoch 2189 / 10000 loss: 15.484909534454346\n",
      "MSE train 5.886629498974248 MSE test 12.392639562175525\n",
      "MAE train 1.680858242091908 MAE test 2.467366585473368\n",
      "Epoch 2190 / 10000 loss: 15.484297275543213\n",
      "MSE train 5.886468111226988 MSE test 12.392640478447568\n",
      "MAE train 1.680828932265888 MAE test 2.4673728147493987\n",
      "Epoch 2191 / 10000 loss: 15.48379373550415\n",
      "MSE train 5.886316783485868 MSE test 12.392307153229824\n",
      "MAE train 1.6808096841978886 MAE test 2.467331763633896\n",
      "Epoch 2192 / 10000 loss: 15.48311734199524\n",
      "MSE train 5.886149624179172 MSE test 12.39231143602878\n",
      "MAE train 1.6807789496161802 MAE test 2.4673384320114122\n",
      "Epoch 2193 / 10000 loss: 15.482620477676392\n",
      "MSE train 5.885995914780456 MSE test 12.392002504613481\n",
      "MAE train 1.68075853767225 MAE test 2.4673004258671165\n",
      "Epoch 2194 / 10000 loss: 15.481918573379517\n",
      "MSE train 5.88584200133059 MSE test 12.391994658770605\n",
      "MAE train 1.6807311400886993 MAE test 2.467305541609771\n",
      "Epoch 2195 / 10000 loss: 15.48139500617981\n",
      "MSE train 5.88569208492428 MSE test 12.391630830763694\n",
      "MAE train 1.6807128075313065 MAE test 2.4672606871000884\n",
      "Epoch 2196 / 10000 loss: 15.480752944946289\n",
      "MSE train 5.88550925426171 MSE test 12.391640234757073\n",
      "MAE train 1.6806784636177898 MAE test 2.4672680220047445\n",
      "Epoch 2197 / 10000 loss: 15.480284929275513\n",
      "MSE train 5.8853593059197475 MSE test 12.391417015813552\n",
      "MAE train 1.6806565368347945 MAE test 2.467240828241148\n",
      "Epoch 2198 / 10000 loss: 15.479518413543701\n",
      "MSE train 5.885190450539209 MSE test 12.391285184029996\n",
      "MAE train 1.6806288955428987 MAE test 2.467230274543542\n",
      "Epoch 2199 / 10000 loss: 15.478951454162598\n",
      "MSE train 5.88504867228382 MSE test 12.391103696515751\n",
      "MAE train 1.680607786147744 MAE test 2.4672083972286356\n",
      "Epoch 2200 / 10000 loss: 15.478325366973877\n",
      "MSE train 5.884883450873093 MSE test 12.390901427434876\n",
      "MAE train 1.6805828058546062 MAE test 2.4671890173458086\n",
      "Epoch 2201 / 10000 loss: 15.47777009010315\n",
      "MSE train 5.884724245564444 MSE test 12.390778125953775\n",
      "MAE train 1.680556159363991 MAE test 2.467174535489439\n",
      "Epoch 2202 / 10000 loss: 15.477202653884888\n",
      "MSE train 5.8845534456628155 MSE test 12.390607817977234\n",
      "MAE train 1.6805290449227315 MAE test 2.4671591184250765\n",
      "Epoch 2203 / 10000 loss: 15.476542234420776\n",
      "MSE train 5.884411283864885 MSE test 12.390464230457141\n",
      "MAE train 1.680506749598954 MAE test 2.467142055239774\n",
      "Epoch 2204 / 10000 loss: 15.475930213928223\n",
      "MSE train 5.884243488073924 MSE test 12.390221645916204\n",
      "MAE train 1.6804818462272024 MAE test 2.4671176241525212\n",
      "Epoch 2205 / 10000 loss: 15.475346565246582\n",
      "MSE train 5.884065141066426 MSE test 12.39010081862692\n",
      "MAE train 1.6804507545122394 MAE test 2.467103499185727\n",
      "Epoch 2206 / 10000 loss: 15.474798202514648\n",
      "MSE train 5.883899837278848 MSE test 12.390028106352913\n",
      "MAE train 1.6804220294734957 MAE test 2.467100392196785\n",
      "Epoch 2207 / 10000 loss: 15.474057674407959\n",
      "MSE train 5.883735475691062 MSE test 12.389718529899218\n",
      "MAE train 1.6803987235485673 MAE test 2.4670624031352744\n",
      "Epoch 2208 / 10000 loss: 15.47339916229248\n",
      "MSE train 5.883566535891832 MSE test 12.38971107630003\n",
      "MAE train 1.6803672789287483 MAE test 2.4670676394379862\n",
      "Epoch 2209 / 10000 loss: 15.472823858261108\n",
      "MSE train 5.883398216370829 MSE test 12.389347436553798\n",
      "MAE train 1.6803439484717677 MAE test 2.4670228818913182\n",
      "Epoch 2210 / 10000 loss: 15.472111225128174\n",
      "MSE train 5.883191658142886 MSE test 12.389355120896123\n",
      "MAE train 1.680303177903094 MAE test 2.4670301087521844\n",
      "Epoch 2211 / 10000 loss: 15.47155475616455\n",
      "MSE train 5.8830082178991665 MSE test 12.3891253428266\n",
      "MAE train 1.6802723525777372 MAE test 2.467002198156444\n",
      "Epoch 2212 / 10000 loss: 15.470678567886353\n",
      "MSE train 5.8827952391267235 MSE test 12.388999622227084\n",
      "MAE train 1.680232467915247 MAE test 2.466992566138532\n",
      "Epoch 2213 / 10000 loss: 15.469957828521729\n",
      "MSE train 5.8825873578044705 MSE test 12.388801213019423\n",
      "MAE train 1.6801938396536604 MAE test 2.466968751200732\n",
      "Epoch 2214 / 10000 loss: 15.469118118286133\n",
      "MSE train 5.882331845544572 MSE test 12.38862203033498\n",
      "MAE train 1.680143252529778 MAE test 2.4669524911934686\n",
      "Epoch 2215 / 10000 loss: 15.468262672424316\n",
      "MSE train 5.8820656029709415 MSE test 12.388481044232345\n",
      "MAE train 1.6800857221587364 MAE test 2.466936049119819\n",
      "Epoch 2216 / 10000 loss: 15.467249870300293\n",
      "MSE train 5.881744707722825 MSE test 12.388239789760227\n",
      "MAE train 1.6800168758064602 MAE test 2.4669121098514615\n",
      "Epoch 2217 / 10000 loss: 15.466077089309692\n",
      "MSE train 5.881408218463551 MSE test 12.388110403911945\n",
      "MAE train 1.6799392408880556 MAE test 2.4668972445012423\n",
      "Epoch 2218 / 10000 loss: 15.46478796005249\n",
      "MSE train 5.881113711642251 MSE test 12.388010125919894\n",
      "MAE train 1.679872879291416 MAE test 2.4668909365176073\n",
      "Epoch 2219 / 10000 loss: 15.463281154632568\n",
      "MSE train 5.880879190084767 MSE test 12.387738059625452\n",
      "MAE train 1.6798272728906776 MAE test 2.4668577982867244\n",
      "Epoch 2220 / 10000 loss: 15.462010622024536\n",
      "MSE train 5.880683565269569 MSE test 12.387686140665236\n",
      "MAE train 1.67978867808784 MAE test 2.4668574127628413\n",
      "Epoch 2221 / 10000 loss: 15.461061716079712\n",
      "MSE train 5.880510989461679 MSE test 12.387342255744745\n",
      "MAE train 1.6797631069251582 MAE test 2.466815072244876\n",
      "Epoch 2222 / 10000 loss: 15.460240840911865\n",
      "MSE train 5.880323502468418 MSE test 12.387349261074222\n",
      "MAE train 1.6797266831066593 MAE test 2.4668220323111076\n",
      "Epoch 2223 / 10000 loss: 15.459639549255371\n",
      "MSE train 5.880160624642203 MSE test 12.387071060120222\n",
      "MAE train 1.6797027243413232 MAE test 2.4667878210985403\n",
      "Epoch 2224 / 10000 loss: 15.458841800689697\n",
      "MSE train 5.880006083082757 MSE test 12.387035394293124\n",
      "MAE train 1.6796756185665798 MAE test 2.4667892979632704\n",
      "Epoch 2225 / 10000 loss: 15.458250999450684\n",
      "MSE train 5.879854779589579 MSE test 12.386675194432565\n",
      "MAE train 1.6796566888985405 MAE test 2.4667447817461676\n",
      "Epoch 2226 / 10000 loss: 15.457617044448853\n",
      "MSE train 5.879671037034397 MSE test 12.386686991919639\n",
      "MAE train 1.679622011180034 MAE test 2.4667522819740397\n",
      "Epoch 2227 / 10000 loss: 15.457134485244751\n",
      "MSE train 5.879520964703944 MSE test 12.386463984258906\n",
      "MAE train 1.679600049091716 MAE test 2.4667249604093744\n",
      "Epoch 2228 / 10000 loss: 15.45635986328125\n",
      "MSE train 5.8793537492899 MSE test 12.386338953913256\n",
      "MAE train 1.6795726085735858 MAE test 2.466715119639257\n",
      "Epoch 2229 / 10000 loss: 15.455790281295776\n",
      "MSE train 5.879212412458828 MSE test 12.38615355827835\n",
      "MAE train 1.6795518039189161 MAE test 2.4666925864647045\n",
      "Epoch 2230 / 10000 loss: 15.455164194107056\n",
      "MSE train 5.879049444347856 MSE test 12.385967330722861\n",
      "MAE train 1.6795270391998032 MAE test 2.4666750598946137\n",
      "Epoch 2231 / 10000 loss: 15.454612970352173\n",
      "MSE train 5.878902004096678 MSE test 12.385842637561671\n",
      "MAE train 1.6795032673795596 MAE test 2.4666602370414576\n",
      "Epoch 2232 / 10000 loss: 15.454042673110962\n",
      "MSE train 5.878739078269606 MSE test 12.385639853839837\n",
      "MAE train 1.679478886587468 MAE test 2.466640602990404\n",
      "Epoch 2233 / 10000 loss: 15.45343017578125\n",
      "MSE train 5.878584784664089 MSE test 12.385517921286317\n",
      "MAE train 1.679453456153296 MAE test 2.4666261330937633\n",
      "Epoch 2234 / 10000 loss: 15.452874183654785\n",
      "MSE train 5.87841896810542 MSE test 12.385349923002659\n",
      "MAE train 1.6794275707414048 MAE test 2.466610853969036\n",
      "Epoch 2235 / 10000 loss: 15.45223069190979\n",
      "MSE train 5.878283264173336 MSE test 12.385209027436524\n",
      "MAE train 1.6794069053908274 MAE test 2.4665939602647025\n",
      "Epoch 2236 / 10000 loss: 15.451639890670776\n",
      "MSE train 5.878122809573921 MSE test 12.384969661680174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6793838373753214 MAE test 2.46656976282436\n",
      "Epoch 2237 / 10000 loss: 15.45108151435852\n",
      "MSE train 5.8779536383539055 MSE test 12.384852080093555\n",
      "MAE train 1.6793550822787242 MAE test 2.466555856209117\n",
      "Epoch 2238 / 10000 loss: 15.450565338134766\n",
      "MSE train 5.8777990874524235 MSE test 12.384782025601424\n",
      "MAE train 1.6793291595079276 MAE test 2.466552923658026\n",
      "Epoch 2239 / 10000 loss: 15.449861764907837\n",
      "MSE train 5.8776479033413 MSE test 12.384477475404003\n",
      "MAE train 1.6793092379644323 MAE test 2.466515383327348\n",
      "Epoch 2240 / 10000 loss: 15.449249029159546\n",
      "MSE train 5.877496198681939 MSE test 12.384472801575736\n",
      "MAE train 1.6792823160221901 MAE test 2.4665207767052246\n",
      "Epoch 2241 / 10000 loss: 15.448732137680054\n",
      "MSE train 5.877348956678891 MSE test 12.384111382836826\n",
      "MAE train 1.6792645454988524 MAE test 2.4664760944239643\n",
      "Epoch 2242 / 10000 loss: 15.44809603691101\n",
      "MSE train 5.8771688080673705 MSE test 12.384123420780186\n",
      "MAE train 1.6792308152730733 MAE test 2.4664836247770823\n",
      "Epoch 2243 / 10000 loss: 15.447636365890503\n",
      "MSE train 5.877022206564369 MSE test 12.38390360946808\n",
      "MAE train 1.679209656358491 MAE test 2.46645673191055\n",
      "Epoch 2244 / 10000 loss: 15.446879863739014\n",
      "MSE train 5.876856868393028 MSE test 12.383772506883703\n",
      "MAE train 1.6791828674287392 MAE test 2.466446163533457\n",
      "Epoch 2245 / 10000 loss: 15.446324110031128\n",
      "MSE train 5.876719565855533 MSE test 12.383595971446015\n",
      "MAE train 1.6791627924605448 MAE test 2.46642478962535\n",
      "Epoch 2246 / 10000 loss: 15.445711374282837\n",
      "MSE train 5.876559056209619 MSE test 12.383391663827496\n",
      "MAE train 1.6791390210505224 MAE test 2.466405019506808\n",
      "Epoch 2247 / 10000 loss: 15.445172786712646\n",
      "MSE train 5.876402601371347 MSE test 12.383272008881509\n",
      "MAE train 1.679113114427842 MAE test 2.4663908839903184\n",
      "Epoch 2248 / 10000 loss: 15.444627285003662\n",
      "MSE train 5.876236922852912 MSE test 12.383116112846933\n",
      "MAE train 1.6790869456682003 MAE test 2.4663771689129677\n",
      "Epoch 2249 / 10000 loss: 15.443976402282715\n",
      "MSE train 5.876103535507064 MSE test 12.382964464933355\n",
      "MAE train 1.6790671413258382 MAE test 2.4663589667854513\n",
      "Epoch 2250 / 10000 loss: 15.443378210067749\n",
      "MSE train 5.875943992316651 MSE test 12.382723738211784\n",
      "MAE train 1.6790443288754753 MAE test 2.466334635085865\n",
      "Epoch 2251 / 10000 loss: 15.442838430404663\n",
      "MSE train 5.875774594228899 MSE test 12.38260600781515\n",
      "MAE train 1.6790155842681889 MAE test 2.4663207545899732\n",
      "Epoch 2252 / 10000 loss: 15.442325353622437\n",
      "MSE train 5.875621556281739 MSE test 12.382540020259366\n",
      "MAE train 1.6789899289271184 MAE test 2.4663183742208985\n",
      "Epoch 2253 / 10000 loss: 15.441622972488403\n",
      "MSE train 5.875471092774958 MSE test 12.382225696103186\n",
      "MAE train 1.6789704399063061 MAE test 2.4662796400799536\n",
      "Epoch 2254 / 10000 loss: 15.441013097763062\n",
      "MSE train 5.875315189987046 MSE test 12.382225791137847\n",
      "MAE train 1.6789424581871872 MAE test 2.466285669686736\n",
      "Epoch 2255 / 10000 loss: 15.440507173538208\n",
      "MSE train 5.87516688171074 MSE test 12.381879436567827\n",
      "MAE train 1.6789241770856747 MAE test 2.466242917996131\n",
      "Epoch 2256 / 10000 loss: 15.439852476119995\n",
      "MSE train 5.874993348179289 MSE test 12.38188937995887\n",
      "MAE train 1.6788919673049134 MAE test 2.4662502133830833\n",
      "Epoch 2257 / 10000 loss: 15.439376592636108\n",
      "MSE train 5.874840654424031 MSE test 12.381625557484846\n",
      "MAE train 1.6788705582099144 MAE test 2.466217807553752\n",
      "Epoch 2258 / 10000 loss: 15.438647031784058\n",
      "MSE train 5.87468950861065 MSE test 12.381574852930344\n",
      "MAE train 1.678845014390396 MAE test 2.4662174014248825\n",
      "Epoch 2259 / 10000 loss: 15.43809700012207\n",
      "MSE train 5.874541582051326 MSE test 12.38124496335675\n",
      "MAE train 1.678826480356294 MAE test 2.466176756244423\n",
      "Epoch 2260 / 10000 loss: 15.437493085861206\n",
      "MSE train 5.874375037197569 MSE test 12.381253408462593\n",
      "MAE train 1.6787958750023084 MAE test 2.466183852152736\n",
      "Epoch 2261 / 10000 loss: 15.437005758285522\n",
      "MSE train 5.874223469235093 MSE test 12.380951630575723\n",
      "MAE train 1.6787758214078068 MAE test 2.466146711117891\n",
      "Epoch 2262 / 10000 loss: 15.436305522918701\n",
      "MSE train 5.874073585254792 MSE test 12.380943055214248\n",
      "MAE train 1.6787494627033683 MAE test 2.466151637721898\n",
      "Epoch 2263 / 10000 loss: 15.435785055160522\n",
      "MSE train 5.87392667817218 MSE test 12.38057591584815\n",
      "MAE train 1.6787319147721755 MAE test 2.4661063056726835\n",
      "Epoch 2264 / 10000 loss: 15.43515920639038\n",
      "MSE train 5.873745141764671 MSE test 12.380587787342607\n",
      "MAE train 1.678697918055837 MAE test 2.466113859832218\n",
      "Epoch 2265 / 10000 loss: 15.434705018997192\n",
      "MSE train 5.873601989458632 MSE test 12.38038004570504\n",
      "MAE train 1.678677280117798 MAE test 2.466088552837155\n",
      "Epoch 2266 / 10000 loss: 15.433943748474121\n",
      "MSE train 5.8734369361906085 MSE test 12.380220684529602\n",
      "MAE train 1.6786513755420476 MAE test 2.4660744370673338\n",
      "Epoch 2267 / 10000 loss: 15.433393478393555\n",
      "MSE train 5.873303073581311 MSE test 12.380074023602191\n",
      "MAE train 1.678631360292764 MAE test 2.466056902200656\n",
      "Epoch 2268 / 10000 loss: 15.432801008224487\n",
      "MSE train 5.873143473089188 MSE test 12.379831305083373\n",
      "MAE train 1.678608577703976 MAE test 2.466032339171892\n",
      "Epoch 2269 / 10000 loss: 15.432255029678345\n",
      "MSE train 5.872973843588139 MSE test 12.37971337864566\n",
      "MAE train 1.6785798137631023 MAE test 2.4660184625711707\n",
      "Epoch 2270 / 10000 loss: 15.431743144989014\n",
      "MSE train 5.872821774823136 MSE test 12.379650234692145\n",
      "MAE train 1.6785543213822154 MAE test 2.4660164545935768\n",
      "Epoch 2271 / 10000 loss: 15.43104100227356\n",
      "MSE train 5.8726717115995095 MSE test 12.379329212435525\n",
      "MAE train 1.678535092927926 MAE test 2.465976924749122\n",
      "Epoch 2272 / 10000 loss: 15.430433750152588\n",
      "MSE train 5.872512415240113 MSE test 12.379331791428044\n",
      "MAE train 1.6785062701413862 MAE test 2.465983282101023\n",
      "Epoch 2273 / 10000 loss: 15.429932594299316\n",
      "MSE train 5.8723630057897545 MSE test 12.378999193001098\n",
      "MAE train 1.6784874594370374 MAE test 2.4659422734674887\n",
      "Epoch 2274 / 10000 loss: 15.429262638092041\n",
      "MSE train 5.872197452754473 MSE test 12.379005618860226\n",
      "MAE train 1.6784571004937354 MAE test 2.465949132987975\n",
      "Epoch 2275 / 10000 loss: 15.428772449493408\n",
      "MSE train 5.872045760089765 MSE test 12.378701268135327\n",
      "MAE train 1.6784370802813748 MAE test 2.4659116759203945\n",
      "Epoch 2276 / 10000 loss: 15.428075551986694\n",
      "MSE train 5.8718954396888146 MSE test 12.378693415778917\n",
      "MAE train 1.6784105970755696 MAE test 2.465916718772435\n",
      "Epoch 2277 / 10000 loss: 15.42755651473999\n",
      "MSE train 5.87174833792228 MSE test 12.378328251464103\n",
      "MAE train 1.6783929666554784 MAE test 2.4658716508992353\n",
      "Epoch 2278 / 10000 loss: 15.426928520202637\n",
      "MSE train 5.871567567426007 MSE test 12.378339911781328\n",
      "MAE train 1.678359131924677 MAE test 2.4658791896282497\n",
      "Epoch 2279 / 10000 loss: 15.426471948623657\n",
      "MSE train 5.8714229958125745 MSE test 12.378126419655585\n",
      "MAE train 1.678338312775171 MAE test 2.4658531703623545\n",
      "Epoch 2280 / 10000 loss: 15.425713777542114\n",
      "MSE train 5.871257754623696 MSE test 12.377979393008948\n",
      "MAE train 1.6783120170169596 MAE test 2.465840603276572\n",
      "Epoch 2281 / 10000 loss: 15.425162315368652\n",
      "MSE train 5.871124201642027 MSE test 12.37782076186268\n",
      "MAE train 1.678292381530356 MAE test 2.4658215948853317\n",
      "Epoch 2282 / 10000 loss: 15.424560070037842\n",
      "MSE train 5.870965137360097 MSE test 12.377585816233148\n",
      "MAE train 1.6782695439889588 MAE test 2.4657980146615412\n",
      "Epoch 2283 / 10000 loss: 15.424024105072021\n",
      "MSE train 5.870796980063453 MSE test 12.377468158644007\n",
      "MAE train 1.6782410602185622 MAE test 2.4657842196774857\n",
      "Epoch 2284 / 10000 loss: 15.423507928848267\n",
      "MSE train 5.870640528030035 MSE test 12.37739009882622\n",
      "MAE train 1.678214938926019 MAE test 2.4657803163802128\n",
      "Epoch 2285 / 10000 loss: 15.422811031341553\n",
      "MSE train 5.870489002038746 MSE test 12.377102273940512\n",
      "MAE train 1.6781945246592205 MAE test 2.4657449855982208\n",
      "Epoch 2286 / 10000 loss: 15.422197103500366\n",
      "MSE train 5.870342262830242 MSE test 12.377084396986392\n",
      "MAE train 1.6781691389438655 MAE test 2.4657487664864557\n",
      "Epoch 2287 / 10000 loss: 15.421668291091919\n",
      "MSE train 5.870196378553834 MSE test 12.37671166144017\n",
      "MAE train 1.6781519296264467 MAE test 2.465702777624511\n",
      "Epoch 2288 / 10000 loss: 15.421061992645264\n",
      "MSE train 5.870013734172649 MSE test 12.376723686195648\n",
      "MAE train 1.6781177237959783 MAE test 2.4657103704113976\n",
      "Epoch 2289 / 10000 loss: 15.420615911483765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.869875297863395 MSE test 12.37653042032347\n",
      "MAE train 1.6780977861081012 MAE test 2.4656869347170893\n",
      "Epoch 2290 / 10000 loss: 15.41985034942627\n",
      "MSE train 5.8697121937629495 MSE test 12.376339396973867\n",
      "MAE train 1.6780731014262542 MAE test 2.465668835846316\n",
      "Epoch 2291 / 10000 loss: 15.419308423995972\n",
      "MSE train 5.8695666224762935 MSE test 12.376211736720231\n",
      "MAE train 1.678049852839355 MAE test 2.4656537661088764\n",
      "Epoch 2292 / 10000 loss: 15.418745040893555\n",
      "MSE train 5.86940423467245 MSE test 12.37600891368675\n",
      "MAE train 1.678025597067714 MAE test 2.4656341705321307\n",
      "Epoch 2293 / 10000 loss: 15.418140411376953\n",
      "MSE train 5.869252214903532 MSE test 12.375885212825647\n",
      "MAE train 1.67800077156787 MAE test 2.46561962395665\n",
      "Epoch 2294 / 10000 loss: 15.41758942604065\n",
      "MSE train 5.869087531948435 MSE test 12.375711383285193\n",
      "MAE train 1.6779752842227535 MAE test 2.465603660164427\n",
      "Epoch 2295 / 10000 loss: 15.416956901550293\n",
      "MSE train 5.868951086250266 MSE test 12.37557293758172\n",
      "MAE train 1.6779544200963303 MAE test 2.4655872393958447\n",
      "Epoch 2296 / 10000 loss: 15.416375637054443\n",
      "MSE train 5.868791078719673 MSE test 12.375337059066371\n",
      "MAE train 1.677931364019013 MAE test 2.465563511884249\n",
      "Epoch 2297 / 10000 loss: 15.415813684463501\n",
      "MSE train 5.868623863518986 MSE test 12.37521843308201\n",
      "MAE train 1.677903051909541 MAE test 2.465549613899214\n",
      "Epoch 2298 / 10000 loss: 15.41529631614685\n",
      "MSE train 5.86846673173384 MSE test 12.375136476526908\n",
      "MAE train 1.6778768440929763 MAE test 2.465545230419622\n",
      "Epoch 2299 / 10000 loss: 15.414603233337402\n",
      "MSE train 5.868315199395065 MSE test 12.374855691297748\n",
      "MAE train 1.6778562022700516 MAE test 2.4655107858084593\n",
      "Epoch 2300 / 10000 loss: 15.413990020751953\n",
      "MSE train 5.868168936621189 MSE test 12.374830697973012\n",
      "MAE train 1.6778310874094302 MAE test 2.4655136758418026\n",
      "Epoch 2301 / 10000 loss: 15.413455724716187\n",
      "MSE train 5.868023480820463 MSE test 12.374461922775891\n",
      "MAE train 1.6778138621128202 MAE test 2.4654682123844\n",
      "Epoch 2302 / 10000 loss: 15.412856578826904\n",
      "MSE train 5.867841708708075 MSE test 12.37447407404635\n",
      "MAE train 1.6777797956152518 MAE test 2.46547581333457\n",
      "Epoch 2303 / 10000 loss: 15.412408590316772\n",
      "MSE train 5.867701087366276 MSE test 12.374273255559595\n",
      "MAE train 1.6777595343244078 MAE test 2.4654514418006994\n",
      "Epoch 2304 / 10000 loss: 15.411646604537964\n",
      "MSE train 5.867537364564541 MSE test 12.374098782051655\n",
      "MAE train 1.6777342834147049 MAE test 2.465435424433274\n",
      "Epoch 2305 / 10000 loss: 15.411102771759033\n",
      "MSE train 5.867400003251503 MSE test 12.373962878513558\n",
      "MAE train 1.6777131289180576 MAE test 2.4654193197256764\n",
      "Epoch 2306 / 10000 loss: 15.410524845123291\n",
      "MSE train 5.867240123507312 MSE test 12.373729788344889\n",
      "MAE train 1.677690030854891 MAE test 2.465395957468718\n",
      "Epoch 2307 / 10000 loss: 15.40995979309082\n",
      "MSE train 5.8670737490782106 MSE test 12.373611254755108\n",
      "MAE train 1.6776618989903052 MAE test 2.465382071337047\n",
      "Epoch 2308 / 10000 loss: 15.409440755844116\n",
      "MSE train 5.866915040819462 MSE test 12.373522989519534\n",
      "MAE train 1.6776354703112388 MAE test 2.4653768922259562\n",
      "Epoch 2309 / 10000 loss: 15.408751487731934\n",
      "MSE train 5.866763560526946 MSE test 12.37325643342749\n",
      "MAE train 1.6776144252748078 MAE test 2.465344233050963\n",
      "Epoch 2310 / 10000 loss: 15.408136367797852\n",
      "MSE train 5.866615121097825 MSE test 12.373215569097454\n",
      "MAE train 1.67758919504023 MAE test 2.4653451236834183\n",
      "Epoch 2311 / 10000 loss: 15.407594203948975\n",
      "MSE train 5.866469148657913 MSE test 12.372869041255809\n",
      "MAE train 1.6775714003652316 MAE test 2.4653024541591524\n",
      "Epoch 2312 / 10000 loss: 15.406996726989746\n",
      "MSE train 5.866294469167331 MSE test 12.372880736017883\n",
      "MAE train 1.6775388696001416 MAE test 2.4653099972356656\n",
      "Epoch 2313 / 10000 loss: 15.406530141830444\n",
      "MSE train 5.866143099790213 MSE test 12.372626218758622\n",
      "MAE train 1.6775174630637673 MAE test 2.465278842438518\n",
      "Epoch 2314 / 10000 loss: 15.405796766281128\n",
      "MSE train 5.86598895009043 MSE test 12.372561964321166\n",
      "MAE train 1.6774915155041656 MAE test 2.465276748653819\n",
      "Epoch 2315 / 10000 loss: 15.405247688293457\n",
      "MSE train 5.865839807906188 MSE test 12.372260250722729\n",
      "MAE train 1.6774719753503051 MAE test 2.465239711702078\n",
      "Epoch 2316 / 10000 loss: 15.404641151428223\n",
      "MSE train 5.865688696695409 MSE test 12.372256518872119\n",
      "MAE train 1.6774451778745851 MAE test 2.4652452878678472\n",
      "Epoch 2317 / 10000 loss: 15.40412974357605\n",
      "MSE train 5.865542664848528 MSE test 12.371893641180835\n",
      "MAE train 1.677427685122261 MAE test 2.4652005723595947\n",
      "Epoch 2318 / 10000 loss: 15.403499603271484\n",
      "MSE train 5.865362839122942 MSE test 12.371905691489117\n",
      "MAE train 1.6773939933516273 MAE test 2.4652081424014827\n",
      "Epoch 2319 / 10000 loss: 15.403047323226929\n",
      "MSE train 5.8652178891857405 MSE test 12.371689303288708\n",
      "MAE train 1.6773731202745306 MAE test 2.465181812960018\n",
      "Epoch 2320 / 10000 loss: 15.402292728424072\n",
      "MSE train 5.865053194397318 MSE test 12.371549410523079\n",
      "MAE train 1.677346681979564 MAE test 2.465170131195428\n",
      "Epoch 2321 / 10000 loss: 15.40174412727356\n",
      "MSE train 5.864918943863561 MSE test 12.37138292491065\n",
      "MAE train 1.6773270431210747 MAE test 2.4651501863583034\n",
      "Epoch 2322 / 10000 loss: 15.401139974594116\n",
      "MSE train 5.864760112334126 MSE test 12.371159466324459\n",
      "MAE train 1.677303958861469 MAE test 2.465128042579681\n",
      "Epoch 2323 / 10000 loss: 15.400609016418457\n",
      "MSE train 5.864595819563432 MSE test 12.371041995152996\n",
      "MAE train 1.6772762911197514 MAE test 2.46511429762214\n",
      "Epoch 2324 / 10000 loss: 15.400086164474487\n",
      "MSE train 5.864433493836345 MSE test 12.370936650669236\n",
      "MAE train 1.677249398959389 MAE test 2.465106938605277\n",
      "Epoch 2325 / 10000 loss: 15.399405479431152\n",
      "MSE train 5.864285076423027 MSE test 12.3707079125352\n",
      "MAE train 1.6772280652240696 MAE test 2.465079091402146\n",
      "Epoch 2326 / 10000 loss: 15.398789405822754\n",
      "MSE train 5.864123180142752 MSE test 12.370608303390789\n",
      "MAE train 1.677201179065082 MAE test 2.4650725220985628\n",
      "Epoch 2327 / 10000 loss: 15.398236989974976\n",
      "MSE train 5.863975351465254 MSE test 12.370385385216325\n",
      "MAE train 1.6771798657623074 MAE test 2.4650454230554124\n",
      "Epoch 2328 / 10000 loss: 15.397622346878052\n",
      "MSE train 5.863812920250831 MSE test 12.37028184745835\n",
      "MAE train 1.6771529417561835 MAE test 2.4650383656431623\n",
      "Epoch 2329 / 10000 loss: 15.39707088470459\n",
      "MSE train 5.8636669083514 MSE test 12.370069486748053\n",
      "MAE train 1.6771317904069205 MAE test 2.4650125982119953\n",
      "Epoch 2330 / 10000 loss: 15.396455764770508\n",
      "MSE train 5.863503270108377 MSE test 12.369946225651503\n",
      "MAE train 1.6771051275320688 MAE test 2.4650030491280974\n",
      "Epoch 2331 / 10000 loss: 15.395906448364258\n",
      "MSE train 5.863365160515634 MSE test 12.36976695657226\n",
      "MAE train 1.6770849654277358 MAE test 2.464981492798869\n",
      "Epoch 2332 / 10000 loss: 15.395297288894653\n",
      "MSE train 5.863205198411291 MSE test 12.369572189026814\n",
      "MAE train 1.6770610155877874 MAE test 2.464962966158706\n",
      "Epoch 2333 / 10000 loss: 15.39476203918457\n",
      "MSE train 5.86305426063544 MSE test 12.369451162791103\n",
      "MAE train 1.6770363880622599 MAE test 2.4649487537256545\n",
      "Epoch 2334 / 10000 loss: 15.394213438034058\n",
      "MSE train 5.862890995319229 MSE test 12.369270640920039\n",
      "MAE train 1.6770113335695218 MAE test 2.4649319603318127\n",
      "Epoch 2335 / 10000 loss: 15.39358925819397\n",
      "MSE train 5.8627510786345525 MSE test 12.369138992413076\n",
      "MAE train 1.6769894791063136 MAE test 2.464916421762781\n",
      "Epoch 2336 / 10000 loss: 15.393019914627075\n",
      "MSE train 5.8625906474762095 MSE test 12.368915347675408\n",
      "MAE train 1.6769660215349786 MAE test 2.46489422633733\n",
      "Epoch 2337 / 10000 loss: 15.39244294166565\n",
      "MSE train 5.86242769976811 MSE test 12.368796777169997\n",
      "MAE train 1.6769386404806965 MAE test 2.464880306598181\n",
      "Epoch 2338 / 10000 loss: 15.391916513442993\n",
      "MSE train 5.862264202220019 MSE test 12.368684447506762\n",
      "MAE train 1.6769116282595073 MAE test 2.4648720696007094\n",
      "Epoch 2339 / 10000 loss: 15.39124059677124\n",
      "MSE train 5.8621180096992855 MSE test 12.36846867244717\n",
      "MAE train 1.6768905018057578 MAE test 2.4648458477061714\n",
      "Epoch 2340 / 10000 loss: 15.390625238418579\n",
      "MSE train 5.861953977530874 MSE test 12.368343913757895\n",
      "MAE train 1.6768637741567451 MAE test 2.4648360963656835\n",
      "Epoch 2341 / 10000 loss: 15.39007568359375\n",
      "MSE train 5.861815790332444 MSE test 12.368163559396876\n",
      "MAE train 1.6768436103058517 MAE test 2.4648143766378197\n",
      "Epoch 2342 / 10000 loss: 15.389467477798462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.861655521279324 MSE test 12.367969880815712\n",
      "MAE train 1.6768195667802355 MAE test 2.464795983918823\n",
      "Epoch 2343 / 10000 loss: 15.388932228088379\n",
      "MSE train 5.861505166115103 MSE test 12.367848347388472\n",
      "MAE train 1.6767950887599639 MAE test 2.464781698581989\n",
      "Epoch 2344 / 10000 loss: 15.38838267326355\n",
      "MSE train 5.861341915175732 MSE test 12.367665400566509\n",
      "MAE train 1.6767701135949746 MAE test 2.464764596901747\n",
      "Epoch 2345 / 10000 loss: 15.387760639190674\n",
      "MSE train 5.861200481941877 MSE test 12.367535347035044\n",
      "MAE train 1.676747874812166 MAE test 2.4647492372712683\n",
      "Epoch 2346 / 10000 loss: 15.38719391822815\n",
      "MSE train 5.861039563335725 MSE test 12.367317293922792\n",
      "MAE train 1.6767242018081205 MAE test 2.46472773975637\n",
      "Epoch 2347 / 10000 loss: 15.386610746383667\n",
      "MSE train 5.860878845156024 MSE test 12.367198280697188\n",
      "MAE train 1.6766973349340992 MAE test 2.4647137520586293\n",
      "Epoch 2348 / 10000 loss: 15.38607931137085\n",
      "MSE train 5.860713698083657 MSE test 12.367071444345743\n",
      "MAE train 1.676670357967858 MAE test 2.464703662538595\n",
      "Epoch 2349 / 10000 loss: 15.38541316986084\n",
      "MSE train 5.860573742887631 MSE test 12.366881744499223\n",
      "MAE train 1.6766500215274607 MAE test 2.4646807496506904\n",
      "Epoch 2350 / 10000 loss: 15.384801387786865\n",
      "MSE train 5.860411598483497 MSE test 12.36670237467136\n",
      "MAE train 1.6766252215223614 MAE test 2.4646641433874867\n",
      "Epoch 2351 / 10000 loss: 15.384262323379517\n",
      "MSE train 5.860269809532164 MSE test 12.366574010895167\n",
      "MAE train 1.676602902115931 MAE test 2.4646489766252047\n",
      "Epoch 2352 / 10000 loss: 15.383696794509888\n",
      "MSE train 5.860109212621332 MSE test 12.366355500526705\n",
      "MAE train 1.6765793318460513 MAE test 2.4646274257650482\n",
      "Epoch 2353 / 10000 loss: 15.383112668991089\n",
      "MSE train 5.85994766511008 MSE test 12.366237163435876\n",
      "MAE train 1.6765522804753172 MAE test 2.464613507079362\n",
      "Epoch 2354 / 10000 loss: 15.382582664489746\n",
      "MSE train 5.859782717776275 MSE test 12.366114304066103\n",
      "MAE train 1.6765252466396057 MAE test 2.464603914982762\n",
      "Epoch 2355 / 10000 loss: 15.381914138793945\n",
      "MSE train 5.85964097894851 MSE test 12.365918847354097\n",
      "MAE train 1.6765046837265642 MAE test 2.464580270701213\n",
      "Epoch 2356 / 10000 loss: 15.381301403045654\n",
      "MSE train 5.859477758941944 MSE test 12.365752825305151\n",
      "MAE train 1.6764793238935785 MAE test 2.4645653010733355\n",
      "Epoch 2357 / 10000 loss: 15.38075852394104\n",
      "MSE train 5.8593413715843194 MSE test 12.36561687923924\n",
      "MAE train 1.676458495905099 MAE test 2.464549199686862\n",
      "Epoch 2358 / 10000 loss: 15.380179643630981\n",
      "MSE train 5.859181993404065 MSE test 12.365379506915174\n",
      "MAE train 1.6764355876733115 MAE test 2.464525302903795\n",
      "Epoch 2359 / 10000 loss: 15.37962293624878\n",
      "MSE train 5.859013465172473 MSE test 12.365262823464118\n",
      "MAE train 1.6764070124822423 MAE test 2.4645115644801825\n",
      "Epoch 2360 / 10000 loss: 15.379112720489502\n",
      "MSE train 5.858858630930381 MSE test 12.365191191081232\n",
      "MAE train 1.6763810719087406 MAE test 2.4645084749979262\n",
      "Epoch 2361 / 10000 loss: 15.378416538238525\n",
      "MSE train 5.858707475472469 MSE test 12.364892635802219\n",
      "MAE train 1.6763610557842508 MAE test 2.464471773301975\n",
      "Epoch 2362 / 10000 loss: 15.377809524536133\n",
      "MSE train 5.85855799717724 MSE test 12.36488525882738\n",
      "MAE train 1.6763347699882551 MAE test 2.464476863245298\n",
      "Epoch 2363 / 10000 loss: 15.37729287147522\n",
      "MSE train 5.8584112206089145 MSE test 12.364518401900012\n",
      "MAE train 1.6763172776327973 MAE test 2.464431643656987\n",
      "Epoch 2364 / 10000 loss: 15.37667179107666\n",
      "MSE train 5.858229596127445 MSE test 12.364531690990392\n",
      "MAE train 1.6762832005208996 MAE test 2.4644392553891104\n",
      "Epoch 2365 / 10000 loss: 15.376223087310791\n",
      "MSE train 5.8580870208029605 MSE test 12.364327387683334\n",
      "MAE train 1.6762626889399457 MAE test 2.4644144333266844\n",
      "Epoch 2366 / 10000 loss: 15.375464677810669\n",
      "MSE train 5.857922102397471 MSE test 12.36416458896358\n",
      "MAE train 1.6762368688055276 MAE test 2.4643998378449194\n",
      "Epoch 2367 / 10000 loss: 15.374918937683105\n",
      "MSE train 5.857787220297292 MSE test 12.364023172363789\n",
      "MAE train 1.6762165899021686 MAE test 2.4643830370884054\n",
      "Epoch 2368 / 10000 loss: 15.374332427978516\n",
      "MSE train 5.857627222662091 MSE test 12.363782965776368\n",
      "MAE train 1.676193646395053 MAE test 2.4643587604682056\n",
      "Epoch 2369 / 10000 loss: 15.373785018920898\n",
      "MSE train 5.857457707039166 MSE test 12.363666654743309\n",
      "MAE train 1.6761649377879886 MAE test 2.464345044908557\n",
      "Epoch 2370 / 10000 loss: 15.373274326324463\n",
      "MSE train 5.8573043001553815 MSE test 12.36360151185867\n",
      "MAE train 1.6761392038670397 MAE test 2.4643427570858942\n",
      "Epoch 2371 / 10000 loss: 15.372574806213379\n",
      "MSE train 5.857153277383775 MSE test 12.36328974571336\n",
      "MAE train 1.6761196156782747 MAE test 2.4643043911840885\n",
      "Epoch 2372 / 10000 loss: 15.371968984603882\n",
      "MSE train 5.856997675546059 MSE test 12.363290680285276\n",
      "MAE train 1.6760917408917155 MAE test 2.464310514199306\n",
      "Epoch 2373 / 10000 loss: 15.371462106704712\n",
      "MSE train 5.856848839644994 MSE test 12.362943792299566\n",
      "MAE train 1.6760734546101828 MAE test 2.4642677525639094\n",
      "Epoch 2374 / 10000 loss: 15.370812892913818\n",
      "MSE train 5.856673858979644 MSE test 12.362955823371536\n",
      "MAE train 1.676040928988453 MAE test 2.464275222202907\n",
      "Epoch 2375 / 10000 loss: 15.370341062545776\n",
      "MSE train 5.856520754616777 MSE test 12.362700021573708\n",
      "MAE train 1.6760193432770503 MAE test 2.464243842786272\n",
      "Epoch 2376 / 10000 loss: 15.369607925415039\n",
      "MSE train 5.8563663019067205 MSE test 12.362641758804621\n",
      "MAE train 1.675993315695433 MAE test 2.464242454052725\n",
      "Epoch 2377 / 10000 loss: 15.369056224822998\n",
      "MSE train 5.856216047609529 MSE test 12.36233332728836\n",
      "MAE train 1.675973891558643 MAE test 2.4642045320640653\n",
      "Epoch 2378 / 10000 loss: 15.368448734283447\n",
      "MSE train 5.856059416531357 MSE test 12.362336399833309\n",
      "MAE train 1.6759458217316556 MAE test 2.46421090710536\n",
      "Epoch 2379 / 10000 loss: 15.367941617965698\n",
      "MSE train 5.855910390159483 MSE test 12.36199010285053\n",
      "MAE train 1.6759275537037561 MAE test 2.4641682069406654\n",
      "Epoch 2380 / 10000 loss: 15.36728835105896\n",
      "MSE train 5.85573427036615 MSE test 12.362003062130634\n",
      "MAE train 1.6758948391982804 MAE test 2.4641757937889213\n",
      "Epoch 2381 / 10000 loss: 15.366815567016602\n",
      "MSE train 5.855580576420327 MSE test 12.361749785714037\n",
      "MAE train 1.6758731503316522 MAE test 2.4641447105908836\n",
      "Epoch 2382 / 10000 loss: 15.36607813835144\n",
      "MSE train 5.855424564535057 MSE test 12.361689136225051\n",
      "MAE train 1.6758469275918395 MAE test 2.464143010020262\n",
      "Epoch 2383 / 10000 loss: 15.365522146224976\n",
      "MSE train 5.855272967121139 MSE test 12.361387613991573\n",
      "MAE train 1.6758271471276265 MAE test 2.464105942972223\n",
      "Epoch 2384 / 10000 loss: 15.364909410476685\n",
      "MSE train 5.855118295370973 MSE test 12.361387978517332\n",
      "MAE train 1.6757997413143668 MAE test 2.464111965302395\n",
      "Epoch 2385 / 10000 loss: 15.364391565322876\n",
      "MSE train 5.854969010230031 MSE test 12.361031332480087\n",
      "MAE train 1.6757817561553356 MAE test 2.464067966352961\n",
      "Epoch 2386 / 10000 loss: 15.363749980926514\n",
      "MSE train 5.854787281483457 MSE test 12.361046227679521\n",
      "MAE train 1.675747926810247 MAE test 2.4640757707450414\n",
      "Epoch 2387 / 10000 loss: 15.363282442092896\n",
      "MSE train 5.8546367360439255 MSE test 12.36082359408969\n",
      "MAE train 1.675726388776688 MAE test 2.4640485859571175\n",
      "Epoch 2388 / 10000 loss: 15.362521648406982\n",
      "MSE train 5.854469222202541 MSE test 12.36070712902512\n",
      "MAE train 1.6756990417599706 MAE test 2.4640397606103988\n",
      "Epoch 2389 / 10000 loss: 15.361958026885986\n",
      "MSE train 5.854324026415032 MSE test 12.360516075943034\n",
      "MAE train 1.675678083887981 MAE test 2.4640166420672567\n",
      "Epoch 2390 / 10000 loss: 15.361331462860107\n",
      "MSE train 5.854157467912093 MSE test 12.360351926794133\n",
      "MAE train 1.6756523661182567 MAE test 2.4640018592378716\n",
      "Epoch 2391 / 10000 loss: 15.360774517059326\n",
      "MSE train 5.8540166606612365 MSE test 12.360219957203242\n",
      "MAE train 1.6756309898684663 MAE test 2.4639862085828113\n",
      "Epoch 2392 / 10000 loss: 15.360181093215942\n",
      "MSE train 5.853853074228746 MSE test 12.359986077044695\n",
      "MAE train 1.6756075496459963 MAE test 2.463962671977167\n",
      "Epoch 2393 / 10000 loss: 15.35960578918457\n",
      "MSE train 5.8536804081784535 MSE test 12.359872082863308\n",
      "MAE train 1.6755785186520311 MAE test 2.4639492390083957\n",
      "Epoch 2394 / 10000 loss: 15.359075784683228\n",
      "MSE train 5.853520327088898 MSE test 12.359800654404575\n",
      "MAE train 1.675551940321058 MAE test 2.4639461015081756\n",
      "Epoch 2395 / 10000 loss: 15.358361959457397\n",
      "MSE train 5.853364278704272 MSE test 12.359509970649986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6755312104680147 MAE test 2.4639103332721253\n",
      "Epoch 2396 / 10000 loss: 15.357734203338623\n",
      "MSE train 5.853211588140637 MSE test 12.359501186441092\n",
      "MAE train 1.6755048523174283 MAE test 2.4639152042081998\n",
      "Epoch 2397 / 10000 loss: 15.357192516326904\n",
      "MSE train 5.853060408715425 MSE test 12.359133392864027\n",
      "MAE train 1.6754870021089792 MAE test 2.463869799805359\n",
      "Epoch 2398 / 10000 loss: 15.356561183929443\n",
      "MSE train 5.852873417065315 MSE test 12.35914894617898\n",
      "MAE train 1.675452286162855 MAE test 2.463877689516363\n",
      "Epoch 2399 / 10000 loss: 15.356096267700195\n",
      "MSE train 5.852728972676233 MSE test 12.358955238080615\n",
      "MAE train 1.6754317229171984 MAE test 2.46385420562794\n",
      "Epoch 2400 / 10000 loss: 15.355316638946533\n",
      "MSE train 5.852560826979227 MSE test 12.358775950581302\n",
      "MAE train 1.6754061666700955 MAE test 2.4638374683000275\n",
      "Epoch 2401 / 10000 loss: 15.354756593704224\n",
      "MSE train 5.852415433151485 MSE test 12.358647712314548\n",
      "MAE train 1.6753836693226336 MAE test 2.463822343543737\n",
      "Epoch 2402 / 10000 loss: 15.354171514511108\n",
      "MSE train 5.852250332707709 MSE test 12.358429747288838\n",
      "MAE train 1.6753595561165142 MAE test 2.463800764820141\n",
      "Epoch 2403 / 10000 loss: 15.353576421737671\n",
      "MSE train 5.852084870255757 MSE test 12.358312888018892\n",
      "MAE train 1.675332123303407 MAE test 2.4637870738472376\n",
      "Epoch 2404 / 10000 loss: 15.353033542633057\n",
      "MSE train 5.851916413600772 MSE test 12.358192349872738\n",
      "MAE train 1.6753046289892508 MAE test 2.4637777225787523\n",
      "Epoch 2405 / 10000 loss: 15.352354526519775\n",
      "MSE train 5.8517706666327705 MSE test 12.357995318971936\n",
      "MAE train 1.6752836465893204 MAE test 2.463753912376827\n",
      "Epoch 2406 / 10000 loss: 15.351731061935425\n",
      "MSE train 5.851603933829507 MSE test 12.357834682560126\n",
      "MAE train 1.6752576788885307 MAE test 2.4637395913650906\n",
      "Epoch 2407 / 10000 loss: 15.351180076599121\n",
      "MSE train 5.851465894604454 MSE test 12.35769540819711\n",
      "MAE train 1.6752370060647974 MAE test 2.4637231334728797\n",
      "Epoch 2408 / 10000 loss: 15.350592136383057\n",
      "MSE train 5.851303664511737 MSE test 12.357454269699025\n",
      "MAE train 1.6752138432019594 MAE test 2.4636987046436674\n",
      "Epoch 2409 / 10000 loss: 15.350039958953857\n",
      "MSE train 5.851131391129309 MSE test 12.357337468948012\n",
      "MAE train 1.6751848410650827 MAE test 2.463685033641592\n",
      "Epoch 2410 / 10000 loss: 15.349530458450317\n",
      "MSE train 5.850975878742294 MSE test 12.357273264008345\n",
      "MAE train 1.6751588787472778 MAE test 2.4636829113818783\n",
      "Epoch 2411 / 10000 loss: 15.348829507827759\n",
      "MSE train 5.850822436761556 MSE test 12.356956476829842\n",
      "MAE train 1.675139151471886 MAE test 2.4636439321061454\n",
      "Epoch 2412 / 10000 loss: 15.348222732543945\n",
      "MSE train 5.85066223396922 MSE test 12.356957884619806\n",
      "MAE train 1.6751104808594903 MAE test 2.463650182668663\n",
      "Epoch 2413 / 10000 loss: 15.347720384597778\n",
      "MSE train 5.850510062004279 MSE test 12.356616817432847\n",
      "MAE train 1.675091592124584 MAE test 2.463608157365055\n",
      "Epoch 2414 / 10000 loss: 15.347061395645142\n",
      "MSE train 5.850336218053078 MSE test 12.356625726481267\n",
      "MAE train 1.6750596282330017 MAE test 2.4636153272916697\n",
      "Epoch 2415 / 10000 loss: 15.34658145904541\n",
      "MSE train 5.8501796060291 MSE test 12.356346075322998\n",
      "MAE train 1.6750382170866098 MAE test 2.4635809772025477\n",
      "Epoch 2416 / 10000 loss: 15.345866203308105\n",
      "MSE train 5.850028732295349 MSE test 12.356315583927973\n",
      "MAE train 1.675012585230573 MAE test 2.463583195603239\n",
      "Epoch 2417 / 10000 loss: 15.345326900482178\n",
      "MSE train 5.849877966940186 MSE test 12.355952096146641\n",
      "MAE train 1.6749945338569585 MAE test 2.463538367665795\n",
      "Epoch 2418 / 10000 loss: 15.344727516174316\n",
      "MSE train 5.849692721930183 MSE test 12.355964406870722\n",
      "MAE train 1.6749600635031368 MAE test 2.4635459591209314\n",
      "Epoch 2419 / 10000 loss: 15.344271421432495\n",
      "MSE train 5.8495429005391 MSE test 12.35575059060399\n",
      "MAE train 1.6749386022964179 MAE test 2.4635199866332935\n",
      "Epoch 2420 / 10000 loss: 15.34351134300232\n",
      "MSE train 5.849372397206287 MSE test 12.355605458836125\n",
      "MAE train 1.674911475317867 MAE test 2.4635075589753135\n",
      "Epoch 2421 / 10000 loss: 15.342956781387329\n",
      "MSE train 5.849232752214116 MSE test 12.355444964162217\n",
      "MAE train 1.6748911536356756 MAE test 2.463488449797579\n",
      "Epoch 2422 / 10000 loss: 15.342350482940674\n",
      "MSE train 5.849067354110306 MSE test 12.355212893752725\n",
      "MAE train 1.6748673240074252 MAE test 2.463465141657608\n",
      "Epoch 2423 / 10000 loss: 15.341810464859009\n",
      "MSE train 5.848893443419495 MSE test 12.355095708227351\n",
      "MAE train 1.6748381970761614 MAE test 2.463451439305141\n",
      "Epoch 2424 / 10000 loss: 15.341285705566406\n",
      "MSE train 5.848727606487033 MSE test 12.3550097977496\n",
      "MAE train 1.6748107690714882 MAE test 2.463446521227639\n",
      "Epoch 2425 / 10000 loss: 15.340584993362427\n",
      "MSE train 5.848567881727599 MSE test 12.35473954136841\n",
      "MAE train 1.6747887653334825 MAE test 2.4634133780988465\n",
      "Epoch 2426 / 10000 loss: 15.33996057510376\n",
      "MSE train 5.848411427015137 MSE test 12.354703588873477\n",
      "MAE train 1.6747624243970838 MAE test 2.4634148886434986\n",
      "Epoch 2427 / 10000 loss: 15.339406251907349\n",
      "MSE train 5.8482559166833825 MSE test 12.354349488861315\n",
      "MAE train 1.6747435791159364 MAE test 2.463371246661239\n",
      "Epoch 2428 / 10000 loss: 15.33879542350769\n",
      "MSE train 5.848067826453755 MSE test 12.35436201806853\n",
      "MAE train 1.6747089738434944 MAE test 2.4633788334656526\n",
      "Epoch 2429 / 10000 loss: 15.338320016860962\n",
      "MSE train 5.847907265863988 MSE test 12.35412742296343\n",
      "MAE train 1.6746861319719761 MAE test 2.4633501872892416\n",
      "Epoch 2430 / 10000 loss: 15.33755373954773\n",
      "MSE train 5.847732807885956 MSE test 12.354027218654942\n",
      "MAE train 1.6746575794463832 MAE test 2.4633434659388542\n",
      "Epoch 2431 / 10000 loss: 15.336977243423462\n",
      "MSE train 5.8475706606002635 MSE test 12.353799868189121\n",
      "MAE train 1.6746344806251026 MAE test 2.4633158039940626\n",
      "Epoch 2432 / 10000 loss: 15.3363356590271\n",
      "MSE train 5.847393883930541 MSE test 12.353702049940214\n",
      "MAE train 1.6746056116687178 MAE test 2.4633093958311414\n",
      "Epoch 2433 / 10000 loss: 15.335752964019775\n",
      "MSE train 5.847229159550319 MSE test 12.353477144087755\n",
      "MAE train 1.6745821463541166 MAE test 2.463282046679796\n",
      "Epoch 2434 / 10000 loss: 15.33510136604309\n",
      "MSE train 5.847049077446395 MSE test 12.353378129699156\n",
      "MAE train 1.6745528354228798 MAE test 2.4632754806540573\n",
      "Epoch 2435 / 10000 loss: 15.334510326385498\n",
      "MSE train 5.84688145300958 MSE test 12.3531571796149\n",
      "MAE train 1.6745289195891886 MAE test 2.463248636899021\n",
      "Epoch 2436 / 10000 loss: 15.333849906921387\n",
      "MSE train 5.846696960590835 MSE test 12.353051047358868\n",
      "MAE train 1.6744990862193179 MAE test 2.463241166016604\n",
      "Epoch 2437 / 10000 loss: 15.33324670791626\n",
      "MSE train 5.846527896933883 MSE test 12.352843271093874\n",
      "MAE train 1.6744749403391443 MAE test 2.463216008831554\n",
      "Epoch 2438 / 10000 loss: 15.332574367523193\n",
      "MSE train 5.8463383310311094 MSE test 12.352709849734262\n",
      "MAE train 1.6744451089743961 MAE test 2.4632050722187877\n",
      "Epoch 2439 / 10000 loss: 15.331960439682007\n",
      "MSE train 5.846175463932147 MSE test 12.352543179158534\n",
      "MAE train 1.674421724968925 MAE test 2.463185163041458\n",
      "Epoch 2440 / 10000 loss: 15.331283807754517\n",
      "MSE train 5.845987456164635 MSE test 12.352322678740512\n",
      "MAE train 1.6743946230966429 MAE test 2.4631632766467155\n",
      "Epoch 2441 / 10000 loss: 15.330672264099121\n",
      "MSE train 5.8457932916104545 MSE test 12.35220551065115\n",
      "MAE train 1.6743630602130681 MAE test 2.463149567191983\n",
      "Epoch 2442 / 10000 loss: 15.330061197280884\n",
      "MSE train 5.845598543821299 MSE test 12.352092625343873\n",
      "MAE train 1.674331854111627 MAE test 2.4631411590691736\n",
      "Epoch 2443 / 10000 loss: 15.329293966293335\n",
      "MSE train 5.845421552276394 MSE test 12.351877754393902\n",
      "MAE train 1.674306659989437 MAE test 2.46311506211137\n",
      "Epoch 2444 / 10000 loss: 15.328585624694824\n",
      "MSE train 5.845227669448672 MSE test 12.35174938443147\n",
      "MAE train 1.6742760191526425 MAE test 2.463104735080997\n",
      "Epoch 2445 / 10000 loss: 15.327943563461304\n",
      "MSE train 5.845062702428838 MSE test 12.351571896344932\n",
      "MAE train 1.6742524583285865 MAE test 2.4630834177189613\n",
      "Epoch 2446 / 10000 loss: 15.327247619628906\n",
      "MSE train 5.8448781385526765 MSE test 12.35136942914999\n",
      "MAE train 1.6742254799500038 MAE test 2.4630637630210295\n",
      "Epoch 2447 / 10000 loss: 15.326631307601929\n",
      "MSE train 5.844702281655484 MSE test 12.351249082118539\n",
      "MAE train 1.6741974071899344 MAE test 2.4630496638078894\n",
      "Epoch 2448 / 10000 loss: 15.326018333435059\n",
      "MSE train 5.8445196606637095 MSE test 12.351084250004494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6741692907203132 MAE test 2.4630346449168985\n",
      "Epoch 2449 / 10000 loss: 15.325319290161133\n",
      "MSE train 5.844371095070637 MSE test 12.350939261837533\n",
      "MAE train 1.674147405046913 MAE test 2.4630174810292873\n",
      "Epoch 2450 / 10000 loss: 15.324685335159302\n",
      "MSE train 5.844200008339101 MSE test 12.35069660576196\n",
      "MAE train 1.674123050265173 MAE test 2.4629927111665104\n",
      "Epoch 2451 / 10000 loss: 15.324102878570557\n",
      "MSE train 5.844022139500068 MSE test 12.350578311798072\n",
      "MAE train 1.6740933067174264 MAE test 2.4629788297699675\n",
      "Epoch 2452 / 10000 loss: 15.323566436767578\n",
      "MSE train 5.843862539480932 MSE test 12.350510820550141\n",
      "MAE train 1.6740667652658394 MAE test 2.4629761826529726\n",
      "Epoch 2453 / 10000 loss: 15.322848796844482\n",
      "MSE train 5.843706959483231 MSE test 12.350196979052239\n",
      "MAE train 1.6740465764738925 MAE test 2.4629374587901216\n",
      "Epoch 2454 / 10000 loss: 15.322229862213135\n",
      "MSE train 5.843548691971223 MSE test 12.350195464135151\n",
      "MAE train 1.6740183887556057 MAE test 2.462943272668457\n",
      "Epoch 2455 / 10000 loss: 15.321715593338013\n",
      "MSE train 5.843398086750579 MSE test 12.349845407914579\n",
      "MAE train 1.6739998928311342 MAE test 2.462900022005085\n",
      "Epoch 2456 / 10000 loss: 15.321065187454224\n",
      "MSE train 5.843222115347918 MSE test 12.34985527590561\n",
      "MAE train 1.6739671844674082 MAE test 2.4629072086015613\n",
      "Epoch 2457 / 10000 loss: 15.320592641830444\n",
      "MSE train 5.843069149092612 MSE test 12.349598503116844\n",
      "MAE train 1.6739455634001055 MAE test 2.4628756777714265\n",
      "Epoch 2458 / 10000 loss: 15.319861888885498\n",
      "MSE train 5.84291472670956 MSE test 12.349534960201886\n",
      "MAE train 1.6739195011991135 MAE test 2.4628735608396615\n",
      "Epoch 2459 / 10000 loss: 15.319314002990723\n",
      "MSE train 5.842765203512105 MSE test 12.349230102786064\n",
      "MAE train 1.673899948842039 MAE test 2.462836007830288\n",
      "Epoch 2460 / 10000 loss: 15.318711757659912\n",
      "MSE train 5.842613356981021 MSE test 12.34922722569788\n",
      "MAE train 1.673872841880213 MAE test 2.462841633796946\n",
      "Epoch 2461 / 10000 loss: 15.318205833435059\n",
      "MSE train 5.8424671716814185 MSE test 12.348867250278929\n",
      "MAE train 1.6738551971800615 MAE test 2.462797143192142\n",
      "Epoch 2462 / 10000 loss: 15.317576169967651\n",
      "MSE train 5.842289333303793 MSE test 12.34887874648274\n",
      "MAE train 1.673821790309483 MAE test 2.4628045173726196\n",
      "Epoch 2463 / 10000 loss: 15.31712293624878\n",
      "MSE train 5.842142809460249 MSE test 12.348652066620955\n",
      "MAE train 1.6738007017584273 MAE test 2.4627768351395316\n",
      "Epoch 2464 / 10000 loss: 15.316380023956299\n",
      "MSE train 5.8419799385329 MSE test 12.34853325213136\n",
      "MAE train 1.6737738207232606 MAE test 2.462767642701983\n",
      "Epoch 2465 / 10000 loss: 15.315833330154419\n",
      "MSE train 5.841839141133971 MSE test 12.348336664904581\n",
      "MAE train 1.6737533554686745 MAE test 2.4627438591258564\n",
      "Epoch 2466 / 10000 loss: 15.315225839614868\n",
      "MSE train 5.841677616443853 MSE test 12.348173150407437\n",
      "MAE train 1.673728021498046 MAE test 2.4627290181029986\n",
      "Epoch 2467 / 10000 loss: 15.314686298370361\n",
      "MSE train 5.841543862165164 MSE test 12.348034294451148\n",
      "MAE train 1.6737077088592334 MAE test 2.4627126118671945\n",
      "Epoch 2468 / 10000 loss: 15.314111948013306\n",
      "MSE train 5.841386532105946 MSE test 12.347792793830317\n",
      "MAE train 1.6736850543736086 MAE test 2.462687979749038\n",
      "Epoch 2469 / 10000 loss: 15.31356692314148\n",
      "MSE train 5.84121937332106 MSE test 12.347675357549477\n",
      "MAE train 1.6736566125452796 MAE test 2.4626741884138554\n",
      "Epoch 2470 / 10000 loss: 15.313064575195312\n",
      "MSE train 5.841068432506413 MSE test 12.34760826079731\n",
      "MAE train 1.6736311393884709 MAE test 2.4626715740921328\n",
      "Epoch 2471 / 10000 loss: 15.312373161315918\n",
      "MSE train 5.840919949137274 MSE test 12.34729531109409\n",
      "MAE train 1.673611819309428 MAE test 2.4626329546477597\n",
      "Epoch 2472 / 10000 loss: 15.311774492263794\n",
      "MSE train 5.8407674877373195 MSE test 12.347294111379526\n",
      "MAE train 1.67358435236576 MAE test 2.462638808367242\n",
      "Epoch 2473 / 10000 loss: 15.311275959014893\n",
      "MSE train 5.8406214819853375 MSE test 12.346943994795406\n",
      "MAE train 1.6735664117171412 MAE test 2.462595526660426\n",
      "Epoch 2474 / 10000 loss: 15.310637474060059\n",
      "MSE train 5.840449078256903 MSE test 12.346954399055459\n",
      "MAE train 1.6735341096855 MAE test 2.4626027921998936\n",
      "Epoch 2475 / 10000 loss: 15.31017518043518\n",
      "MSE train 5.8402992412058286 MSE test 12.346699653086706\n",
      "MAE train 1.673512854202157 MAE test 2.462571517191096\n",
      "Epoch 2476 / 10000 loss: 15.309449672698975\n",
      "MSE train 5.840146717193023 MSE test 12.346634516676463\n",
      "MAE train 1.6734870096354237 MAE test 2.462569187944082\n",
      "Epoch 2477 / 10000 loss: 15.308906316757202\n",
      "MSE train 5.83999893200368 MSE test 12.346334372576619\n",
      "MAE train 1.673467529966467 MAE test 2.4625322155779106\n",
      "Epoch 2478 / 10000 loss: 15.30830717086792\n",
      "MSE train 5.839850490309312 MSE test 12.346329522577415\n",
      "MAE train 1.6734411023887112 MAE test 2.4625375958015248\n",
      "Epoch 2479 / 10000 loss: 15.307800769805908\n",
      "MSE train 5.839706059939661 MSE test 12.345964332803916\n",
      "MAE train 1.6734238282051155 MAE test 2.4624924545408544\n",
      "Epoch 2480 / 10000 loss: 15.30718183517456\n",
      "MSE train 5.839527569335791 MSE test 12.345976835287987\n",
      "MAE train 1.6733901235990483 MAE test 2.4624999645705272\n",
      "Epoch 2481 / 10000 loss: 15.306736469268799\n",
      "MSE train 5.839385637791961 MSE test 12.345765272123936\n",
      "MAE train 1.6733696578252502 MAE test 2.462474206178072\n",
      "Epoch 2482 / 10000 loss: 15.305988073348999\n",
      "MSE train 5.839222768529984 MSE test 12.345615266118358\n",
      "MAE train 1.6733435688817002 MAE test 2.462461037035171\n",
      "Epoch 2483 / 10000 loss: 15.30544638633728\n",
      "MSE train 5.83909162565343 MSE test 12.345460259690666\n",
      "MAE train 1.6733242388533291 MAE test 2.4624425611031246\n",
      "Epoch 2484 / 10000 loss: 15.304856777191162\n",
      "MSE train 5.838934586995434 MSE test 12.345222458953835\n",
      "MAE train 1.6733015328213088 MAE test 2.462418365220884\n",
      "Epoch 2485 / 10000 loss: 15.30432939529419\n",
      "MSE train 5.8387682916851515 MSE test 12.34510543476828\n",
      "MAE train 1.6732732415009512 MAE test 2.4624046614588417\n",
      "Epoch 2486 / 10000 loss: 15.303824663162231\n",
      "MSE train 5.838615518920006 MSE test 12.345032428638332\n",
      "MAE train 1.6732474865593787 MAE test 2.4624012698261044\n",
      "Epoch 2487 / 10000 loss: 15.303134441375732\n",
      "MSE train 5.8384664717647246 MSE test 12.344734352442561\n",
      "MAE train 1.6732276693018595 MAE test 2.462364523452679\n",
      "Epoch 2488 / 10000 loss: 15.302533864974976\n",
      "MSE train 5.83831979228053 MSE test 12.344724907963107\n",
      "MAE train 1.6732017508300403 MAE test 2.462369302707502\n",
      "Epoch 2489 / 10000 loss: 15.302022457122803\n",
      "MSE train 5.8381752225994505 MSE test 12.344356176929109\n",
      "MAE train 1.6731845322540873 MAE test 2.4623236902004453\n",
      "Epoch 2490 / 10000 loss: 15.301411390304565\n",
      "MSE train 5.837995966811429 MSE test 12.344368767480454\n",
      "MAE train 1.6731506561115337 MAE test 2.4623312201669734\n",
      "Epoch 2491 / 10000 loss: 15.300968647003174\n",
      "MSE train 5.837856247357122 MSE test 12.344165030017317\n",
      "MAE train 1.6731305257916076 MAE test 2.4623064672936463\n",
      "Epoch 2492 / 10000 loss: 15.300217390060425\n",
      "MSE train 5.83769389834717 MSE test 12.343997843018892\n",
      "MAE train 1.6731050133081593 MAE test 2.462291096738702\n",
      "Epoch 2493 / 10000 loss: 15.299678564071655\n",
      "MSE train 5.8375606449428945 MSE test 12.343857839992317\n",
      "MAE train 1.6730848243496401 MAE test 2.4622745417328225\n",
      "Epoch 2494 / 10000 loss: 15.299102783203125\n",
      "MSE train 5.837402870629231 MSE test 12.343618257640264\n",
      "MAE train 1.6730619734534435 MAE test 2.4622500711074875\n",
      "Epoch 2495 / 10000 loss: 15.298556566238403\n",
      "MSE train 5.837236543877481 MSE test 12.343501011647044\n",
      "MAE train 1.6730336954231197 MAE test 2.4622363566895027\n",
      "Epoch 2496 / 10000 loss: 15.29805064201355\n",
      "MSE train 5.837084156462511 MSE test 12.343429148786768\n",
      "MAE train 1.6730080036508796 MAE test 2.462233113306812\n",
      "Epoch 2497 / 10000 loss: 15.297361612319946\n",
      "MSE train 5.836935052884892 MSE test 12.343128191906063\n",
      "MAE train 1.672988243032405 MAE test 2.4621959922315977\n",
      "Epoch 2498 / 10000 loss: 15.296760320663452\n",
      "MSE train 5.8367874898226075 MSE test 12.343120872579792\n",
      "MAE train 1.6729620809629118 MAE test 2.462201042137284\n",
      "Epoch 2499 / 10000 loss: 15.296250581741333\n",
      "MSE train 5.836642595496267 MSE test 12.342754648685839\n",
      "MAE train 1.6729447305363212 MAE test 2.462155709930574\n",
      "Epoch 2500 / 10000 loss: 15.295635223388672\n",
      "MSE train 5.836463945335749 MSE test 12.342767265539441\n",
      "MAE train 1.6729109825346964 MAE test 2.4621632522650674\n",
      "Epoch 2501 / 10000 loss: 15.295189142227173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.836322295217129 MSE test 12.342557697581348\n",
      "MAE train 1.6728905708658666 MAE test 2.462137754353946\n",
      "Epoch 2502 / 10000 loss: 15.294439315795898\n",
      "MSE train 5.836159387750486 MSE test 12.342403942788785\n",
      "MAE train 1.6728645658871144 MAE test 2.4621240846660024\n",
      "Epoch 2503 / 10000 loss: 15.293898105621338\n",
      "MSE train 5.836028061424328 MSE test 12.342252986960817\n",
      "MAE train 1.6728451415948848 MAE test 2.4621061299873195\n",
      "Epoch 2504 / 10000 loss: 15.293310403823853\n",
      "MSE train 5.835870804017975 MSE test 12.342012432652684\n",
      "MAE train 1.6728224176088653 MAE test 2.4620815184964675\n",
      "Epoch 2505 / 10000 loss: 15.29278016090393\n",
      "MSE train 5.835703886543953 MSE test 12.3418956798008\n",
      "MAE train 1.6727940271192192 MAE test 2.4620678916232817\n",
      "Epoch 2506 / 10000 loss: 15.292277097702026\n",
      "MSE train 5.835552594038061 MSE test 12.341828160059437\n",
      "MAE train 1.6727684696949134 MAE test 2.4620651746602196\n",
      "Epoch 2507 / 10000 loss: 15.291585683822632\n",
      "MSE train 5.835403944525483 MSE test 12.341518440482558\n",
      "MAE train 1.6727490539852905 MAE test 2.462026959954033\n",
      "Epoch 2508 / 10000 loss: 15.29098629951477\n",
      "MSE train 5.835252681051033 MSE test 12.341516516694563\n",
      "MAE train 1.6727218663947856 MAE test 2.46203268544533\n",
      "Epoch 2509 / 10000 loss: 15.290484189987183\n",
      "MSE train 5.835106895961855 MSE test 12.34116242648926\n",
      "MAE train 1.6727040822083372 MAE test 2.4619888568572357\n",
      "Epoch 2510 / 10000 loss: 15.289850234985352\n",
      "MSE train 5.834932429931065 MSE test 12.34117414252809\n",
      "MAE train 1.6726712763835818 MAE test 2.461996304432767\n",
      "Epoch 2511 / 10000 loss: 15.289392709732056\n",
      "MSE train 5.834783817488976 MSE test 12.340932751632511\n",
      "MAE train 1.6726499958741476 MAE test 2.461966742017123\n",
      "Epoch 2512 / 10000 loss: 15.288658618927002\n",
      "MSE train 5.834625855001459 MSE test 12.340845762687819\n",
      "MAE train 1.6726234127770294 MAE test 2.4619615812443945\n",
      "Epoch 2513 / 10000 loss: 15.288111925125122\n",
      "MSE train 5.834476681031597 MSE test 12.340593307622262\n",
      "MAE train 1.6726023400026344 MAE test 2.461930673022088\n",
      "Epoch 2514 / 10000 loss: 15.287504196166992\n",
      "MSE train 5.834326064904119 MSE test 12.340539577550569\n",
      "MAE train 1.6725766575262857 MAE test 2.461929761129022\n",
      "Epoch 2515 / 10000 loss: 15.28696322441101\n",
      "MSE train 5.834179872844764 MSE test 12.340223562496861\n",
      "MAE train 1.6725579714699277 MAE test 2.4618907920051227\n",
      "Epoch 2516 / 10000 loss: 15.286366701126099\n",
      "MSE train 5.834022641270137 MSE test 12.340229442396637\n",
      "MAE train 1.6725292343091631 MAE test 2.4618974967543825\n",
      "Epoch 2517 / 10000 loss: 15.285878658294678\n",
      "MSE train 5.8338758380713935 MSE test 12.339896755169852\n",
      "MAE train 1.6725107812871152 MAE test 2.461856380970681\n",
      "Epoch 2518 / 10000 loss: 15.285218715667725\n",
      "MSE train 5.833711834277482 MSE test 12.33990502598451\n",
      "MAE train 1.6724804049555189 MAE test 2.4618633950421445\n",
      "Epoch 2519 / 10000 loss: 15.284740209579468\n",
      "MSE train 5.833562097660103 MSE test 12.339605284645883\n",
      "MAE train 1.6724604560722862 MAE test 2.461826424792469\n",
      "Epoch 2520 / 10000 loss: 15.284050226211548\n",
      "MSE train 5.833415392341731 MSE test 12.339595617210541\n",
      "MAE train 1.6724345602071122 MAE test 2.4618311535062762\n",
      "Epoch 2521 / 10000 loss: 15.283538818359375\n",
      "MSE train 5.833270515108042 MSE test 12.3392274579552\n",
      "MAE train 1.6724172352825966 MAE test 2.461785540193335\n",
      "Epoch 2522 / 10000 loss: 15.282927989959717\n",
      "MSE train 5.833091501955541 MSE test 12.33924031102694\n",
      "MAE train 1.6723834202476147 MAE test 2.461793123414189\n",
      "Epoch 2523 / 10000 loss: 15.28248381614685\n",
      "MSE train 5.832951194085656 MSE test 12.33903509867614\n",
      "MAE train 1.6723631983984824 MAE test 2.4617681919876855\n",
      "Epoch 2524 / 10000 loss: 15.281734466552734\n",
      "MSE train 5.832788626952371 MSE test 12.338872380500112\n",
      "MAE train 1.6723375287156186 MAE test 2.4617533645543137\n",
      "Epoch 2525 / 10000 loss: 15.281195163726807\n",
      "MSE train 5.832656366553486 MSE test 12.338729695102652\n",
      "MAE train 1.6723176552734391 MAE test 2.461736458670317\n",
      "Epoch 2526 / 10000 loss: 15.280616998672485\n",
      "MSE train 5.832498901068338 MSE test 12.338488670001148\n",
      "MAE train 1.672294893963939 MAE test 2.461711725144617\n",
      "Epoch 2527 / 10000 loss: 15.2800772190094\n",
      "MSE train 5.832332236759059 MSE test 12.338371738885398\n",
      "MAE train 1.6722665573298394 MAE test 2.4616981271143783\n",
      "Epoch 2528 / 10000 loss: 15.279575824737549\n",
      "MSE train 5.832181398756496 MSE test 12.338305233268766\n",
      "MAE train 1.6722410964614367 MAE test 2.4616955124782023\n",
      "Epoch 2529 / 10000 loss: 15.278885841369629\n",
      "MSE train 5.832032952087914 MSE test 12.33799413570997\n",
      "MAE train 1.6722217336576863 MAE test 2.4616571280849584\n",
      "Epoch 2530 / 10000 loss: 15.278289079666138\n",
      "MSE train 5.831881291705053 MSE test 12.337993421025015\n",
      "MAE train 1.6721944525796422 MAE test 2.4616629837799064\n",
      "Epoch 2531 / 10000 loss: 15.27778959274292\n",
      "MSE train 5.831735517170696 MSE test 12.33764223263211\n",
      "MAE train 1.672176583337703 MAE test 2.461619508267012\n",
      "Epoch 2532 / 10000 loss: 15.277154207229614\n",
      "MSE train 5.831562445831623 MSE test 12.33765411050362\n",
      "MAE train 1.6721441147185696 MAE test 2.4616269767478793\n",
      "Epoch 2533 / 10000 loss: 15.27669644355774\n",
      "MSE train 5.831413154385866 MSE test 12.337405342013119\n",
      "MAE train 1.6721228324434696 MAE test 2.4615964920597007\n",
      "Epoch 2534 / 10000 loss: 15.275969982147217\n",
      "MSE train 5.8312585141053175 MSE test 12.337332397719706\n",
      "MAE train 1.6720966985078185 MAE test 2.4615930869924125\n",
      "Epoch 2535 / 10000 loss: 15.275425910949707\n",
      "MSE train 5.83110979626728 MSE test 12.337052354210945\n",
      "MAE train 1.672076485199098 MAE test 2.4615586802588276\n",
      "Epoch 2536 / 10000 loss: 15.274824380874634\n",
      "MSE train 5.830965480116739 MSE test 12.33703316841798\n",
      "MAE train 1.672051440444486 MAE test 2.461562162566901\n",
      "Epoch 2537 / 10000 loss: 15.274303197860718\n",
      "MSE train 5.83082194561926 MSE test 12.33666286707801\n",
      "MAE train 1.6720344671571163 MAE test 2.461516291849696\n",
      "Epoch 2538 / 10000 loss: 15.273712873458862\n",
      "MSE train 5.8306420120105535 MSE test 12.336677004142292\n",
      "MAE train 1.6720004704626217 MAE test 2.4615240704072114\n",
      "Epoch 2539 / 10000 loss: 15.273276567459106\n",
      "MSE train 5.830504799008536 MSE test 12.33648268517821\n",
      "MAE train 1.6719807089764067 MAE test 2.461500512615287\n",
      "Epoch 2540 / 10000 loss: 15.272523403167725\n",
      "MSE train 5.830343541979611 MSE test 12.336298633509283\n",
      "MAE train 1.6719558740833973 MAE test 2.4614829707158887\n",
      "Epoch 2541 / 10000 loss: 15.27199125289917\n",
      "MSE train 5.830203358539541 MSE test 12.336170190715878\n",
      "MAE train 1.671933798186812 MAE test 2.4614679056711877\n",
      "Epoch 2542 / 10000 loss: 15.271433115005493\n",
      "MSE train 5.830044066862847 MSE test 12.33595553716961\n",
      "MAE train 1.6719100876214317 MAE test 2.461446467756672\n",
      "Epoch 2543 / 10000 loss: 15.270855188369751\n",
      "MSE train 5.829887286427555 MSE test 12.335836693636377\n",
      "MAE train 1.6718839645522992 MAE test 2.4614326323535054\n",
      "Epoch 2544 / 10000 loss: 15.2703275680542\n",
      "MSE train 5.829723714104115 MSE test 12.335700090218944\n",
      "MAE train 1.6718573171288562 MAE test 2.461421089197677\n",
      "Epoch 2545 / 10000 loss: 15.269677639007568\n",
      "MSE train 5.829589546146528 MSE test 12.335525644984433\n",
      "MAE train 1.6718378232493494 MAE test 2.461400118750074\n",
      "Epoch 2546 / 10000 loss: 15.269078731536865\n",
      "MSE train 5.8294313047858495 MSE test 12.335317542031332\n",
      "MAE train 1.6718142374527538 MAE test 2.4613795374984684\n",
      "Epoch 2547 / 10000 loss: 15.268552780151367\n",
      "MSE train 5.829275941381329 MSE test 12.335199418655515\n",
      "MAE train 1.6717884352139412 MAE test 2.461365796984847\n",
      "Epoch 2548 / 10000 loss: 15.268023490905762\n",
      "MSE train 5.829112449125743 MSE test 12.335053347380276\n",
      "MAE train 1.6717620859269506 MAE test 2.4613530679771634\n",
      "Epoch 2549 / 10000 loss: 15.267379760742188\n",
      "MSE train 5.828980817857171 MSE test 12.334892608717276\n",
      "MAE train 1.671742857973637 MAE test 2.4613338321604616\n",
      "Epoch 2550 / 10000 loss: 15.266788482666016\n",
      "MSE train 5.828823458196268 MSE test 12.334663286481955\n",
      "MAE train 1.6717198932563913 MAE test 2.4613105503717185\n",
      "Epoch 2551 / 10000 loss: 15.266264200210571\n",
      "MSE train 5.828659282702867 MSE test 12.334547351917633\n",
      "MAE train 1.671692110485853 MAE test 2.4612971116511457\n",
      "Epoch 2552 / 10000 loss: 15.265755653381348\n",
      "MSE train 5.8285016771059635 MSE test 12.334457672516733\n",
      "MAE train 1.6716656681837203 MAE test 2.4612915253696332\n",
      "Epoch 2553 / 10000 loss: 15.265075445175171\n",
      "MSE train 5.828352118506239 MSE test 12.334200087269434\n",
      "MAE train 1.67164465708791 MAE test 2.461259981957991\n",
      "Epoch 2554 / 10000 loss: 15.26447081565857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.828203048440335 MSE test 12.334151141831628\n",
      "MAE train 1.6716192548758138 MAE test 2.4612596161614895\n",
      "Epoch 2555 / 10000 loss: 15.26393437385559\n",
      "MSE train 5.8280574277590915 MSE test 12.333825416834015\n",
      "MAE train 1.6716009564997918 MAE test 2.4612194082558934\n",
      "Epoch 2556 / 10000 loss: 15.263343811035156\n",
      "MSE train 5.8278949244428295 MSE test 12.333835261962362\n",
      "MAE train 1.6715709584797296 MAE test 2.4612266047974143\n",
      "Epoch 2557 / 10000 loss: 15.262866497039795\n",
      "MSE train 5.827746174454116 MSE test 12.333527712044384\n",
      "MAE train 1.6715514770504882 MAE test 2.4611886707593458\n",
      "Epoch 2558 / 10000 loss: 15.262186765670776\n",
      "MSE train 5.827595880319665 MSE test 12.33352583740701\n",
      "MAE train 1.6715246075376011 MAE test 2.461194353233985\n",
      "Epoch 2559 / 10000 loss: 15.261685132980347\n",
      "MSE train 5.82745029683417 MSE test 12.333169537176307\n",
      "MAE train 1.671506916685859 MAE test 2.4611502236883678\n",
      "Epoch 2560 / 10000 loss: 15.261058807373047\n",
      "MSE train 5.827274760455103 MSE test 12.333182821533393\n",
      "MAE train 1.6714739277761124 MAE test 2.461157872149851\n",
      "Epoch 2561 / 10000 loss: 15.26060676574707\n",
      "MSE train 5.827127473739612 MSE test 12.332950095583225\n",
      "MAE train 1.6714528002582052 MAE test 2.46112943463198\n",
      "Epoch 2562 / 10000 loss: 15.259873151779175\n",
      "MSE train 5.8269669192079085 MSE test 12.332848749059652\n",
      "MAE train 1.6714260082400543 MAE test 2.4611224125290843\n",
      "Epoch 2563 / 10000 loss: 15.259326934814453\n",
      "MSE train 5.8268207438324415 MSE test 12.332627369105348\n",
      "MAE train 1.6714049277620964 MAE test 2.4610954563536263\n",
      "Epoch 2564 / 10000 loss: 15.258721113204956\n",
      "MSE train 5.826659624696334 MSE test 12.33252174970361\n",
      "MAE train 1.6713781066645874 MAE test 2.4610879044142178\n",
      "Epoch 2565 / 10000 loss: 15.258178472518921\n",
      "MSE train 5.826516005438036 MSE test 12.33231538491416\n",
      "MAE train 1.6713572966479602 MAE test 2.4610628517596305\n",
      "Epoch 2566 / 10000 loss: 15.25757384300232\n",
      "MSE train 5.8263538654714715 MSE test 12.332182788197764\n",
      "MAE train 1.6713309950835227 MAE test 2.4610518863942885\n",
      "Epoch 2567 / 10000 loss: 15.257033109664917\n",
      "MSE train 5.8262204317110395 MSE test 12.332018486204747\n",
      "MAE train 1.6713115046864815 MAE test 2.461032194067176\n",
      "Epoch 2568 / 10000 loss: 15.256438970565796\n",
      "MSE train 5.826063296955497 MSE test 12.331798759451898\n",
      "MAE train 1.6712884559968464 MAE test 2.4610101104874516\n",
      "Epoch 2569 / 10000 loss: 15.255914688110352\n",
      "MSE train 5.825901195175804 MSE test 12.331683608590989\n",
      "MAE train 1.671261172106512 MAE test 2.4609967793944847\n",
      "Epoch 2570 / 10000 loss: 15.255399942398071\n",
      "MSE train 5.825739547485424 MSE test 12.33157443889844\n",
      "MAE train 1.6712342953621782 MAE test 2.460988719040787\n",
      "Epoch 2571 / 10000 loss: 15.254730701446533\n",
      "MSE train 5.82559433408797 MSE test 12.33135801368907\n",
      "MAE train 1.6712133415673784 MAE test 2.4609623794857827\n",
      "Epoch 2572 / 10000 loss: 15.254123210906982\n",
      "MSE train 5.825431906335342 MSE test 12.33123881451028\n",
      "MAE train 1.67118659471285 MAE test 2.460953098960692\n",
      "Epoch 2573 / 10000 loss: 15.253580570220947\n",
      "MSE train 5.825293260523526 MSE test 12.33105310827905\n",
      "MAE train 1.6711664545771427 MAE test 2.4609306497864556\n",
      "Epoch 2574 / 10000 loss: 15.252978563308716\n",
      "MSE train 5.825133126955464 MSE test 12.330874523083068\n",
      "MAE train 1.6711418453878364 MAE test 2.4609138275805877\n",
      "Epoch 2575 / 10000 loss: 15.25244665145874\n",
      "MSE train 5.824992098172869 MSE test 12.330748559736703\n",
      "MAE train 1.6711196409408784 MAE test 2.460899062805806\n",
      "Epoch 2576 / 10000 loss: 15.251889944076538\n",
      "MSE train 5.824832870445656 MSE test 12.330532585755355\n",
      "MAE train 1.6710960507646335 MAE test 2.4608774142802807\n",
      "Epoch 2577 / 10000 loss: 15.251310586929321\n",
      "MSE train 5.824673811072817 MSE test 12.33041507019253\n",
      "MAE train 1.671069499870814 MAE test 2.460863772444712\n",
      "Epoch 2578 / 10000 loss: 15.250786781311035\n",
      "MSE train 5.824509912537208 MSE test 12.330286694734035\n",
      "MAE train 1.6710426251628598 MAE test 2.4608532689856464\n",
      "Epoch 2579 / 10000 loss: 15.250131130218506\n",
      "MSE train 5.824372072198105 MSE test 12.33010148790676\n",
      "MAE train 1.6710226602389748 MAE test 2.4608308799162084\n",
      "Epoch 2580 / 10000 loss: 15.249528169631958\n",
      "MSE train 5.824211559075403 MSE test 12.329915561403384\n",
      "MAE train 1.6709981710366932 MAE test 2.4608130859295216\n",
      "Epoch 2581 / 10000 loss: 15.248996019363403\n",
      "MSE train 5.824067231483011 MSE test 12.329791281836759\n",
      "MAE train 1.6709751684523622 MAE test 2.4607985282929468\n",
      "Epoch 2582 / 10000 loss: 15.248444557189941\n",
      "MSE train 5.823906437720218 MSE test 12.32958800590911\n",
      "MAE train 1.67095099491711 MAE test 2.460778489674806\n",
      "Epoch 2583 / 10000 loss: 15.2478506565094\n",
      "MSE train 5.823754304715522 MSE test 12.329467475718406\n",
      "MAE train 1.6709261105116449 MAE test 2.4607644243034015\n",
      "Epoch 2584 / 10000 loss: 15.24731183052063\n",
      "MSE train 5.823590256947921 MSE test 12.329300679692496\n",
      "MAE train 1.6709003095899928 MAE test 2.460749041172441\n",
      "Epoch 2585 / 10000 loss: 15.246684551239014\n",
      "MSE train 5.823456394760784 MSE test 12.329159691207593\n",
      "MAE train 1.6708802028655871 MAE test 2.460732305758975\n",
      "Epoch 2586 / 10000 loss: 15.246107578277588\n",
      "MSE train 5.823297308080258 MSE test 12.328920781600667\n",
      "MAE train 1.6708571510925545 MAE test 2.4607077162593773\n",
      "Epoch 2587 / 10000 loss: 15.245563983917236\n",
      "MSE train 5.823129888129507 MSE test 12.328804447201607\n",
      "MAE train 1.6708287949321419 MAE test 2.460694255596767\n",
      "Epoch 2588 / 10000 loss: 15.245059490203857\n",
      "MSE train 5.822976093091374 MSE test 12.328733248379177\n",
      "MAE train 1.6708029501779513 MAE test 2.460690974661499\n",
      "Epoch 2589 / 10000 loss: 15.244370222091675\n",
      "MSE train 5.822825480563469 MSE test 12.328433480643493\n",
      "MAE train 1.6707830071542822 MAE test 2.460654011750016\n",
      "Epoch 2590 / 10000 loss: 15.243769645690918\n",
      "MSE train 5.822676555002184 MSE test 12.32842666587568\n",
      "MAE train 1.6707567468637647 MAE test 2.4606590084599964\n",
      "Epoch 2591 / 10000 loss: 15.243258714675903\n",
      "MSE train 5.8225299233058205 MSE test 12.328060859325566\n",
      "MAE train 1.6707391776101252 MAE test 2.4606136229287086\n",
      "Epoch 2592 / 10000 loss: 15.242643117904663\n",
      "MSE train 5.82234948883347 MSE test 12.328074273495755\n",
      "MAE train 1.6707052451163273 MAE test 2.460621285238835\n",
      "Epoch 2593 / 10000 loss: 15.242196083068848\n",
      "MSE train 5.822205987134767 MSE test 12.327865613065407\n",
      "MAE train 1.670684635294837 MAE test 2.4605958640723045\n",
      "Epoch 2594 / 10000 loss: 15.241446256637573\n",
      "MSE train 5.822040994715191 MSE test 12.327711869818035\n",
      "MAE train 1.6706583945013098 MAE test 2.4605821319503556\n",
      "Epoch 2595 / 10000 loss: 15.24090313911438\n",
      "MSE train 5.821907343776659 MSE test 12.327562024956231\n",
      "MAE train 1.6706387049273566 MAE test 2.460564243688523\n",
      "Epoch 2596 / 10000 loss: 15.24031400680542\n",
      "MSE train 5.821747439992278 MSE test 12.327322200657008\n",
      "MAE train 1.6706156256022529 MAE test 2.460539520357935\n",
      "Epoch 2597 / 10000 loss: 15.23978042602539\n",
      "MSE train 5.821577939794193 MSE test 12.327205926145655\n",
      "MAE train 1.6705869529622663 MAE test 2.4605260579818835\n",
      "Epoch 2598 / 10000 loss: 15.239272594451904\n",
      "MSE train 5.821423559854436 MSE test 12.32713833200712\n",
      "MAE train 1.6705610364464458 MAE test 2.4605232047813286\n",
      "Epoch 2599 / 10000 loss: 15.238576889038086\n",
      "MSE train 5.8212714232445615 MSE test 12.326830017822823\n",
      "MAE train 1.670541128077677 MAE test 2.4604851157014758\n",
      "Epoch 2600 / 10000 loss: 15.237972259521484\n",
      "MSE train 5.821117162233834 MSE test 12.326827892008252\n",
      "MAE train 1.6705136974058794 MAE test 2.460490700998799\n",
      "Epoch 2601 / 10000 loss: 15.237462759017944\n",
      "MSE train 5.820967341732202 MSE test 12.326471835962233\n",
      "MAE train 1.6704953993265976 MAE test 2.460446499678783\n",
      "Epoch 2602 / 10000 loss: 15.23682427406311\n",
      "MSE train 5.820787765187144 MSE test 12.326484036572559\n",
      "MAE train 1.6704619100271574 MAE test 2.4604539688809988\n",
      "Epoch 2603 / 10000 loss: 15.236358880996704\n",
      "MSE train 5.820634961934005 MSE test 12.326247484166732\n",
      "MAE train 1.6704400600232692 MAE test 2.460424968000601\n",
      "Epoch 2604 / 10000 loss: 15.235612392425537\n",
      "MSE train 5.8204696019410695 MSE test 12.326150699284408\n",
      "MAE train 1.670412552573739 MAE test 2.460418427145965\n",
      "Epoch 2605 / 10000 loss: 15.235052347183228\n",
      "MSE train 5.820315588430474 MSE test 12.325917350614382\n",
      "MAE train 1.6703904942253083 MAE test 2.4603898656134136\n",
      "Epoch 2606 / 10000 loss: 15.23442792892456\n",
      "MSE train 5.820150211157333 MSE test 12.325831173147177\n",
      "MAE train 1.6703628926548368 MAE test 2.4603846754031484\n",
      "Epoch 2607 / 10000 loss: 15.233864784240723\n",
      "MSE train 5.8199932875507 MSE test 12.325583533140868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.670340670820749 MAE test 2.460354287979022\n",
      "Epoch 2608 / 10000 loss: 15.233235597610474\n",
      "MSE train 5.8198318168289696 MSE test 12.325524125234246\n",
      "MAE train 1.670313527414843 MAE test 2.4603524747429764\n",
      "Epoch 2609 / 10000 loss: 15.23266863822937\n",
      "MSE train 5.819674014979861 MSE test 12.325219439109452\n",
      "MAE train 1.670292858286866 MAE test 2.46031480315438\n",
      "Epoch 2610 / 10000 loss: 15.232040166854858\n",
      "MSE train 5.819510519193192 MSE test 12.325218827501164\n",
      "MAE train 1.670264026121019 MAE test 2.4603205158602592\n",
      "Epoch 2611 / 10000 loss: 15.231503009796143\n",
      "MSE train 5.8193509203203275 MSE test 12.324860195757509\n",
      "MAE train 1.6702443908260256 MAE test 2.460275908837366\n",
      "Epoch 2612 / 10000 loss: 15.230830192565918\n",
      "MSE train 5.81915775104342 MSE test 12.324871495953696\n",
      "MAE train 1.670208842091421 MAE test 2.4602831769690776\n",
      "Epoch 2613 / 10000 loss: 15.230326652526855\n",
      "MSE train 5.818990776152589 MSE test 12.324638749137387\n",
      "MAE train 1.6701848675472075 MAE test 2.460254523165214\n",
      "Epoch 2614 / 10000 loss: 15.229526042938232\n",
      "MSE train 5.818805609813645 MSE test 12.324528712459509\n",
      "MAE train 1.6701545474947708 MAE test 2.4602461814737886\n",
      "Epoch 2615 / 10000 loss: 15.228903770446777\n",
      "MSE train 5.8186329043972425 MSE test 12.324312930138595\n",
      "MAE train 1.6701295198724655 MAE test 2.4602196799544696\n",
      "Epoch 2616 / 10000 loss: 15.228204488754272\n",
      "MSE train 5.818437414976048 MSE test 12.324183710117518\n",
      "MAE train 1.6700980947726882 MAE test 2.460208872364802\n",
      "Epoch 2617 / 10000 loss: 15.227551221847534\n",
      "MSE train 5.818262888052857 MSE test 12.32400213954324\n",
      "MAE train 1.6700726055094388 MAE test 2.4601866589661565\n",
      "Epoch 2618 / 10000 loss: 15.226818561553955\n",
      "MSE train 5.818061618330499 MSE test 12.323799151739177\n",
      "MAE train 1.6700422757192013 MAE test 2.460166359977709\n",
      "Epoch 2619 / 10000 loss: 15.226134061813354\n",
      "MSE train 5.817865318894881 MSE test 12.323673923893873\n",
      "MAE train 1.6700106930964476 MAE test 2.460151382879963\n",
      "Epoch 2620 / 10000 loss: 15.225422382354736\n",
      "MSE train 5.817658245089771 MSE test 12.323496102330784\n",
      "MAE train 1.6699786100704503 MAE test 2.4601342436087674\n",
      "Epoch 2621 / 10000 loss: 15.224611043930054\n",
      "MSE train 5.817483764072851 MSE test 12.32335377937291\n",
      "MAE train 1.6699520774026766 MAE test 2.4601169910315948\n",
      "Epoch 2622 / 10000 loss: 15.223860025405884\n",
      "MSE train 5.8172932460045494 MSE test 12.323113315163043\n",
      "MAE train 1.669924104613122 MAE test 2.460091885625365\n",
      "Epoch 2623 / 10000 loss: 15.223148107528687\n",
      "MSE train 5.817104134233297 MSE test 12.322992036285648\n",
      "MAE train 1.6698928299169518 MAE test 2.4600774809324095\n",
      "Epoch 2624 / 10000 loss: 15.222513675689697\n",
      "MSE train 5.816931912602424 MSE test 12.322906556280742\n",
      "MAE train 1.6698645440151225 MAE test 2.46007215037373\n",
      "Epoch 2625 / 10000 loss: 15.221739053726196\n",
      "MSE train 5.816770656115423 MSE test 12.322627383697716\n",
      "MAE train 1.6698426413280794 MAE test 2.4600376146250182\n",
      "Epoch 2626 / 10000 loss: 15.221076011657715\n",
      "MSE train 5.816618510115671 MSE test 12.322598958368266\n",
      "MAE train 1.6698168682399004 MAE test 2.4600396771501685\n",
      "Epoch 2627 / 10000 loss: 15.220510959625244\n",
      "MSE train 5.816469323276343 MSE test 12.32223450286014\n",
      "MAE train 1.6697990825163063 MAE test 2.459994340493586\n",
      "Epoch 2628 / 10000 loss: 15.219899892807007\n",
      "MSE train 5.816287363116188 MSE test 12.32224864827093\n",
      "MAE train 1.6697650139410216 MAE test 2.460002054489687\n",
      "Epoch 2629 / 10000 loss: 15.219442129135132\n",
      "MSE train 5.816143196987386 MSE test 12.322039290636168\n",
      "MAE train 1.6697443576210353 MAE test 2.459976471075009\n",
      "Epoch 2630 / 10000 loss: 15.21868634223938\n",
      "MSE train 5.815978917942785 MSE test 12.321890400634556\n",
      "MAE train 1.6697181211673706 MAE test 2.459963339849408\n",
      "Epoch 2631 / 10000 loss: 15.218141555786133\n",
      "MSE train 5.815846700628058 MSE test 12.321738414809696\n",
      "MAE train 1.6696987541437398 MAE test 2.4599451536762156\n",
      "Epoch 2632 / 10000 loss: 15.217552900314331\n",
      "MSE train 5.8156889713404105 MSE test 12.32150277334371\n",
      "MAE train 1.6696759170686357 MAE test 2.459920982791446\n",
      "Epoch 2633 / 10000 loss: 15.217025756835938\n",
      "MSE train 5.815522438162916 MSE test 12.321388754145703\n",
      "MAE train 1.6696476888704823 MAE test 2.4599078230538742\n",
      "Epoch 2634 / 10000 loss: 15.216522932052612\n",
      "MSE train 5.815369671634883 MSE test 12.321318675126404\n",
      "MAE train 1.6696219664228855 MAE test 2.459904719215265\n",
      "Epoch 2635 / 10000 loss: 15.215836763381958\n",
      "MSE train 5.815220561104452 MSE test 12.321023476948069\n",
      "MAE train 1.6696021351232169 MAE test 2.4598683537496924\n",
      "Epoch 2636 / 10000 loss: 15.215238094329834\n",
      "MSE train 5.815074141415746 MSE test 12.32101711791823\n",
      "MAE train 1.6695763279252127 MAE test 2.459873442339104\n",
      "Epoch 2637 / 10000 loss: 15.214730978012085\n",
      "MSE train 5.8149295915403645 MSE test 12.320651694533025\n",
      "MAE train 1.6695590581926427 MAE test 2.4598281220843834\n",
      "Epoch 2638 / 10000 loss: 15.214124202728271\n",
      "MSE train 5.814750924823713 MSE test 12.32066756461218\n",
      "MAE train 1.6695253009377815 MAE test 2.459836188671449\n",
      "Epoch 2639 / 10000 loss: 15.213685989379883\n",
      "MSE train 5.814611262855712 MSE test 12.320466266687786\n",
      "MAE train 1.669505212347737 MAE test 2.4598117446710437\n",
      "Epoch 2640 / 10000 loss: 15.212939500808716\n",
      "MSE train 5.81444926648559 MSE test 12.320304286653\n",
      "MAE train 1.669479623504829 MAE test 2.4597970198246135\n",
      "Epoch 2641 / 10000 loss: 15.21240496635437\n",
      "MSE train 5.81431699290853 MSE test 12.320165912726011\n",
      "MAE train 1.669459727552088 MAE test 2.4597806626196324\n",
      "Epoch 2642 / 10000 loss: 15.211833000183105\n",
      "MSE train 5.814159765120856 MSE test 12.319928644974643\n",
      "MAE train 1.669436885262771 MAE test 2.4597563189129295\n",
      "Epoch 2643 / 10000 loss: 15.211294174194336\n",
      "MSE train 5.813993878185324 MSE test 12.319814717354934\n",
      "MAE train 1.6694087011529934 MAE test 2.4597432218838047\n",
      "Epoch 2644 / 10000 loss: 15.210795879364014\n",
      "MSE train 5.813842600868907 MSE test 12.319747743023028\n",
      "MAE train 1.6693831498629457 MAE test 2.4597405331709363\n",
      "Epoch 2645 / 10000 loss: 15.210111141204834\n",
      "MSE train 5.813694145793136 MSE test 12.319446076639295\n",
      "MAE train 1.66936356257956 MAE test 2.4597033654418734\n",
      "Epoch 2646 / 10000 loss: 15.209516525268555\n",
      "MSE train 5.813545856016633 MSE test 12.319444339488607\n",
      "MAE train 1.6693371159492365 MAE test 2.459709075003811\n",
      "Epoch 2647 / 10000 loss: 15.209014654159546\n",
      "MSE train 5.813401050437339 MSE test 12.319085686406192\n",
      "MAE train 1.669319586469665 MAE test 2.459664610131223\n",
      "Epoch 2648 / 10000 loss: 15.20839810371399\n",
      "MSE train 5.813224596384506 MSE test 12.31910119343164\n",
      "MAE train 1.6692862964884176 MAE test 2.4596726226689762\n",
      "Epoch 2649 / 10000 loss: 15.207953214645386\n",
      "MSE train 5.813080320518288 MSE test 12.318882325718148\n",
      "MAE train 1.6692655013291429 MAE test 2.459645959611947\n",
      "Epoch 2650 / 10000 loss: 15.207215070724487\n",
      "MSE train 5.812918200025964 MSE test 12.318758455248469\n",
      "MAE train 1.6692388169433843 MAE test 2.4596360706612406\n",
      "Epoch 2651 / 10000 loss: 15.20667576789856\n",
      "MSE train 5.812781960737488 MSE test 12.318578907255239\n",
      "MAE train 1.6692190086122074 MAE test 2.4596144477648876\n",
      "Epoch 2652 / 10000 loss: 15.206077575683594\n",
      "MSE train 5.81262327338239 MSE test 12.31839095950605\n",
      "MAE train 1.6691948088401813 MAE test 2.459596407687444\n",
      "Epoch 2653 / 10000 loss: 15.205551385879517\n",
      "MSE train 5.812477848893533 MSE test 12.318271036094886\n",
      "MAE train 1.669171352202014 MAE test 2.4595824524535956\n",
      "Epoch 2654 / 10000 loss: 15.205008029937744\n",
      "MSE train 5.812317629962612 MSE test 12.318080042970946\n",
      "MAE train 1.669146859784259 MAE test 2.459563999326191\n",
      "Epoch 2655 / 10000 loss: 15.204408884048462\n",
      "MSE train 5.812172968645331 MSE test 12.317957907713845\n",
      "MAE train 1.669123605131068 MAE test 2.45954974981552\n",
      "Epoch 2656 / 10000 loss: 15.20386290550232\n",
      "MSE train 5.812012373394889 MSE test 12.317765469334429\n",
      "MAE train 1.6690990640904502 MAE test 2.4595311087715603\n",
      "Epoch 2657 / 10000 loss: 15.203264951705933\n",
      "MSE train 5.811867442116592 MSE test 12.317643055943606\n",
      "MAE train 1.6690757507517193 MAE test 2.4595168168848365\n",
      "Epoch 2658 / 10000 loss: 15.202720880508423\n",
      "MSE train 5.811706652776202 MSE test 12.317452108239989\n",
      "MAE train 1.669051117038508 MAE test 2.4594983733433193\n",
      "Epoch 2659 / 10000 loss: 15.202122926712036\n",
      "MSE train 5.811562734404205 MSE test 12.317328736254865\n",
      "MAE train 1.6690280668009654 MAE test 2.459483954861701\n",
      "Epoch 2660 / 10000 loss: 15.201574563980103\n",
      "MSE train 5.811402234847876 MSE test 12.317133248899777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6690036067189045 MAE test 2.4594649154272235\n",
      "Epoch 2661 / 10000 loss: 15.200981140136719\n",
      "MSE train 5.8112557337216435 MSE test 12.317011701861352\n",
      "MAE train 1.6689799167075365 MAE test 2.4594507396846472\n",
      "Epoch 2662 / 10000 loss: 15.200438022613525\n",
      "MSE train 5.811094357658685 MSE test 12.316827557846354\n",
      "MAE train 1.6689549757599436 MAE test 2.45943314800135\n",
      "Epoch 2663 / 10000 loss: 15.199832916259766\n",
      "MSE train 5.8109543459702735 MSE test 12.31670088913424\n",
      "MAE train 1.668932932030638 MAE test 2.4594182945797547\n",
      "Epoch 2664 / 10000 loss: 15.19927978515625\n",
      "MSE train 5.810795030544077 MSE test 12.316489117363803\n",
      "MAE train 1.668909070723119 MAE test 2.4593971639936423\n",
      "Epoch 2665 / 10000 loss: 15.198701620101929\n",
      "MSE train 5.810639379107621 MSE test 12.31637188844977\n",
      "MAE train 1.6688832036448298 MAE test 2.4593835748533968\n",
      "Epoch 2666 / 10000 loss: 15.198177099227905\n",
      "MSE train 5.810476116943771 MSE test 12.316232445094833\n",
      "MAE train 1.6688566346618998 MAE test 2.45937167277534\n",
      "Epoch 2667 / 10000 loss: 15.19753360748291\n",
      "MSE train 5.810343512778487 MSE test 12.316065801363312\n",
      "MAE train 1.6688373367337916 MAE test 2.4593516692596626\n",
      "Epoch 2668 / 10000 loss: 15.196941375732422\n",
      "MSE train 5.810185870924346 MSE test 12.315849093142996\n",
      "MAE train 1.6688139598976972 MAE test 2.45932991438907\n",
      "Epoch 2669 / 10000 loss: 15.196420192718506\n",
      "MSE train 5.810026226104835 MSE test 12.315734096792392\n",
      "MAE train 1.6687871681255502 MAE test 2.4593166361119576\n",
      "Epoch 2670 / 10000 loss: 15.19590449333191\n",
      "MSE train 5.809864117635648 MSE test 12.315616313027707\n",
      "MAE train 1.6687602554031769 MAE test 2.4593074567909636\n",
      "Epoch 2671 / 10000 loss: 15.195245027542114\n",
      "MSE train 5.809723313174808 MSE test 12.315417737614649\n",
      "MAE train 1.6687398497041221 MAE test 2.459283383906806\n",
      "Epoch 2672 / 10000 loss: 15.194643020629883\n",
      "MSE train 5.809561880008445 MSE test 12.315264530189127\n",
      "MAE train 1.6687141222138537 MAE test 2.4592697419034004\n",
      "Epoch 2673 / 10000 loss: 15.194109201431274\n",
      "MSE train 5.8094304624658255 MSE test 12.31512164499099\n",
      "MAE train 1.6686945397633934 MAE test 2.4592527883454802\n",
      "Epoch 2674 / 10000 loss: 15.193533420562744\n",
      "MSE train 5.809273812820892 MSE test 12.314881511629034\n",
      "MAE train 1.668671845600776 MAE test 2.4592280426691384\n",
      "Epoch 2675 / 10000 loss: 15.193005084991455\n",
      "MSE train 5.809107050472449 MSE test 12.314767201276206\n",
      "MAE train 1.6686434889026633 MAE test 2.459214880141443\n",
      "Epoch 2676 / 10000 loss: 15.192510843276978\n",
      "MSE train 5.808957491894072 MSE test 12.31470588901426\n",
      "MAE train 1.6686181624438565 MAE test 2.4592128746057327\n",
      "Epoch 2677 / 10000 loss: 15.191825151443481\n",
      "MSE train 5.808809508670042 MSE test 12.314389761417258\n",
      "MAE train 1.6685990170822373 MAE test 2.459173810614259\n",
      "Epoch 2678 / 10000 loss: 15.191233396530151\n",
      "MSE train 5.808654818342033 MSE test 12.314393964930996\n",
      "MAE train 1.668570891176284 MAE test 2.459180252701779\n",
      "Epoch 2679 / 10000 loss: 15.19074535369873\n",
      "MSE train 5.80850800058557 MSE test 12.314057393852893\n",
      "MAE train 1.6685524631403843 MAE test 2.4591385756865005\n",
      "Epoch 2680 / 10000 loss: 15.190100908279419\n",
      "MSE train 5.808342063911138 MSE test 12.314068219631826\n",
      "MAE train 1.6685215905654474 MAE test 2.4591458904414734\n",
      "Epoch 2681 / 10000 loss: 15.189631462097168\n",
      "MSE train 5.808191728079893 MSE test 12.313782592452036\n",
      "MAE train 1.668501097666532 MAE test 2.459110695168051\n",
      "Epoch 2682 / 10000 loss: 15.188938856124878\n",
      "MSE train 5.808047724940478 MSE test 12.313762893486341\n",
      "MAE train 1.6684760848777451 MAE test 2.4591140263105076\n",
      "Epoch 2683 / 10000 loss: 15.18842077255249\n",
      "MSE train 5.80790327713799 MSE test 12.313395043067423\n",
      "MAE train 1.6684588162545742 MAE test 2.45906836149665\n",
      "Epoch 2684 / 10000 loss: 15.187832593917847\n",
      "MSE train 5.807724104940693 MSE test 12.31340959893362\n",
      "MAE train 1.66842491934423 MAE test 2.4590762132188404\n",
      "Epoch 2685 / 10000 loss: 15.187396764755249\n",
      "MSE train 5.807585149990891 MSE test 12.313210382959376\n",
      "MAE train 1.6684048995643703 MAE test 2.459051997088528\n",
      "Epoch 2686 / 10000 loss: 15.186651468276978\n",
      "MSE train 5.807423127700219 MSE test 12.313039460881217\n",
      "MAE train 1.668379468584211 MAE test 2.4590360282428216\n",
      "Epoch 2687 / 10000 loss: 15.186118841171265\n",
      "MSE train 5.807288348318055 MSE test 12.312904778407418\n",
      "MAE train 1.668358858915751 MAE test 2.459020117893064\n",
      "Epoch 2688 / 10000 loss: 15.185553789138794\n",
      "MSE train 5.807130146030184 MSE test 12.31267166898343\n",
      "MAE train 1.6683356605441626 MAE test 2.4589961999724457\n",
      "Epoch 2689 / 10000 loss: 15.18500566482544\n",
      "MSE train 5.806965431020094 MSE test 12.312555773631052\n",
      "MAE train 1.66830774790185 MAE test 2.458982802329381\n",
      "Epoch 2690 / 10000 loss: 15.184502124786377\n",
      "MSE train 5.806809370687047 MSE test 12.312472078460907\n",
      "MAE train 1.6682814436587887 MAE test 2.4589779128681624\n",
      "Epoch 2691 / 10000 loss: 15.183824300765991\n",
      "MSE train 5.806659423737911 MSE test 12.312201562329541\n",
      "MAE train 1.668260665171115 MAE test 2.4589446496849203\n",
      "Epoch 2692 / 10000 loss: 15.18322467803955\n",
      "MSE train 5.806514056824987 MSE test 12.312169148827262\n",
      "MAE train 1.668235664791976 MAE test 2.458946337484655\n",
      "Epoch 2693 / 10000 loss: 15.182698726654053\n",
      "MSE train 5.806369556141529 MSE test 12.31181408201281\n",
      "MAE train 1.6682181284543705 MAE test 2.458902266738707\n",
      "Epoch 2694 / 10000 loss: 15.18211579322815\n",
      "MSE train 5.806193342648506 MSE test 12.31182850558143\n",
      "MAE train 1.6681849072932744 MAE test 2.4589100623070617\n",
      "Epoch 2695 / 10000 loss: 15.18166971206665\n",
      "MSE train 5.8060466995003 MSE test 12.311600083700167\n",
      "MAE train 1.6681637839973689 MAE test 2.4588821143927353\n",
      "Epoch 2696 / 10000 loss: 15.180936813354492\n",
      "MSE train 5.805885263537196 MSE test 12.311491656715628\n",
      "MAE train 1.668136823769347 MAE test 2.4588741044135\n",
      "Epoch 2697 / 10000 loss: 15.180396318435669\n",
      "MSE train 5.80574140659862 MSE test 12.311282992604317\n",
      "MAE train 1.6681159516407496 MAE test 2.4588487100783585\n",
      "Epoch 2698 / 10000 loss: 15.179794788360596\n",
      "MSE train 5.805579063659869 MSE test 12.311151442285947\n",
      "MAE train 1.6680894342743586 MAE test 2.4588377716965457\n",
      "Epoch 2699 / 10000 loss: 15.1792573928833\n",
      "MSE train 5.8054449684036795 MSE test 12.310983892310858\n",
      "MAE train 1.6680698398951823 MAE test 2.4588176063891183\n",
      "Epoch 2700 / 10000 loss: 15.17866587638855\n",
      "MSE train 5.805287316280945 MSE test 12.310769203815502\n",
      "MAE train 1.6680464107225392 MAE test 2.4587960287560215\n",
      "Epoch 2701 / 10000 loss: 15.178144454956055\n",
      "MSE train 5.805127611693954 MSE test 12.310653161061778\n",
      "MAE train 1.6680196300120558 MAE test 2.458782556490616\n",
      "Epoch 2702 / 10000 loss: 15.177627325057983\n",
      "MSE train 5.8049643553811086 MSE test 12.310528131048017\n",
      "MAE train 1.6679926431950542 MAE test 2.4587723933392076\n",
      "Epoch 2703 / 10000 loss: 15.176971197128296\n",
      "MSE train 5.804825231414179 MSE test 12.310338038825396\n",
      "MAE train 1.6679724293296507 MAE test 2.458749329449242\n",
      "Epoch 2704 / 10000 loss: 15.176372051239014\n",
      "MSE train 5.804664254683617 MSE test 12.310162034125812\n",
      "MAE train 1.6679473888386522 MAE test 2.4587326936877543\n",
      "Epoch 2705 / 10000 loss: 15.17584228515625\n",
      "MSE train 5.804525557963375 MSE test 12.310032498023425\n",
      "MAE train 1.6679257556690066 MAE test 2.4587174066461426\n",
      "Epoch 2706 / 10000 loss: 15.17528510093689\n",
      "MSE train 5.80436652091161 MSE test 12.309807767649207\n",
      "MAE train 1.6679021999661874 MAE test 2.458694509812872\n",
      "Epoch 2707 / 10000 loss: 15.174720525741577\n",
      "MSE train 5.804204123630815 MSE test 12.309690597148398\n",
      "MAE train 1.6678748559767815 MAE test 2.458680890239502\n",
      "Epoch 2708 / 10000 loss: 15.17420768737793\n",
      "MSE train 5.80404239092288 MSE test 12.309582490664438\n",
      "MAE train 1.667847815380655 MAE test 2.4586728390706267\n",
      "Epoch 2709 / 10000 loss: 15.17354154586792\n",
      "MSE train 5.80389568085845 MSE test 12.309359530968102\n",
      "MAE train 1.667826598230172 MAE test 2.458645574096304\n",
      "Epoch 2710 / 10000 loss: 15.172937631607056\n",
      "MSE train 5.803733555317692 MSE test 12.309249488032052\n",
      "MAE train 1.6677995331691826 MAE test 2.458637313338535\n",
      "Epoch 2711 / 10000 loss: 15.172396898269653\n",
      "MSE train 5.8035901047983 MSE test 12.309045871458691\n",
      "MAE train 1.667778668671599 MAE test 2.458612513927812\n",
      "Epoch 2712 / 10000 loss: 15.17179560661316\n",
      "MSE train 5.803427200345327 MSE test 12.308903119206425\n",
      "MAE train 1.6677523341531513 MAE test 2.4586000931053436\n",
      "Epoch 2713 / 10000 loss: 15.171258449554443\n",
      "MSE train 5.803294351638572 MSE test 12.308747436983062\n",
      "MAE train 1.667732780509489 MAE test 2.4585814074574843\n",
      "Epoch 2714 / 10000 loss: 15.170673847198486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.80313656322988 MSE test 12.308512593162957\n",
      "MAE train 1.6677097193641648 MAE test 2.4585571993893005\n",
      "Epoch 2715 / 10000 loss: 15.170151472091675\n",
      "MSE train 5.802969551768497 MSE test 12.308396524843847\n",
      "MAE train 1.6676813373396793 MAE test 2.458543733717846\n",
      "Epoch 2716 / 10000 loss: 15.169650077819824\n",
      "MSE train 5.802814025460169 MSE test 12.308318448615886\n",
      "MAE train 1.6676550754599264 MAE test 2.4585394641064595\n",
      "Epoch 2717 / 10000 loss: 15.168967723846436\n",
      "MSE train 5.802662911669382 MSE test 12.30803182882692\n",
      "MAE train 1.6676344784652446 MAE test 2.4585040607201787\n",
      "Epoch 2718 / 10000 loss: 15.168369054794312\n",
      "MSE train 5.802516983457371 MSE test 12.308013076556692\n",
      "MAE train 1.6676090575628801 MAE test 2.4585074053975435\n",
      "Epoch 2719 / 10000 loss: 15.167851448059082\n",
      "MSE train 5.8023709471650085 MSE test 12.307641464572763\n",
      "MAE train 1.6675915342930125 MAE test 2.458461137139938\n",
      "Epoch 2720 / 10000 loss: 15.16726016998291\n",
      "MSE train 5.802189628428704 MSE test 12.30765397881515\n",
      "MAE train 1.6675572590728125 MAE test 2.4584686472215767\n",
      "Epoch 2721 / 10000 loss: 15.166823863983154\n",
      "MSE train 5.802049815629927 MSE test 12.30745603664932\n",
      "MAE train 1.6675370531483837 MAE test 2.458444473158659\n",
      "Epoch 2722 / 10000 loss: 15.166074514389038\n",
      "MSE train 5.801886100131563 MSE test 12.307274878260145\n",
      "MAE train 1.6675115360757218 MAE test 2.4584270904380117\n",
      "Epoch 2723 / 10000 loss: 15.165542125701904\n",
      "MSE train 5.80174595709209 MSE test 12.307142523449203\n",
      "MAE train 1.6674896790702347 MAE test 2.4584113773654397\n",
      "Epoch 2724 / 10000 loss: 15.164981126785278\n",
      "MSE train 5.80158472041532 MSE test 12.306917723773893\n",
      "MAE train 1.6674656799695649 MAE test 2.4583884030288576\n",
      "Epoch 2725 / 10000 loss: 15.164413452148438\n",
      "MSE train 5.801421660643941 MSE test 12.306798604832533\n",
      "MAE train 1.6674382824669929 MAE test 2.458374470764378\n",
      "Epoch 2726 / 10000 loss: 15.163893699645996\n",
      "MSE train 5.801257294232737 MSE test 12.306682931154727\n",
      "MAE train 1.667410853367394 MAE test 2.458365394968082\n",
      "Epoch 2727 / 10000 loss: 15.163228511810303\n",
      "MSE train 5.801110846478167 MSE test 12.306469535259506\n",
      "MAE train 1.6673895696648673 MAE test 2.458339279431924\n",
      "Epoch 2728 / 10000 loss: 15.16262149810791\n",
      "MSE train 5.800945711902505 MSE test 12.306335602199017\n",
      "MAE train 1.6673625371150118 MAE test 2.458327928707174\n",
      "Epoch 2729 / 10000 loss: 15.162079811096191\n",
      "MSE train 5.800808530787074 MSE test 12.30616384013691\n",
      "MAE train 1.6673424431509436 MAE test 2.4583071312504527\n",
      "Epoch 2730 / 10000 loss: 15.1614830493927\n",
      "MSE train 5.80064770410609 MSE test 12.30594965059749\n",
      "MAE train 1.6673183838586867 MAE test 2.4582854860696743\n",
      "Epoch 2731 / 10000 loss: 15.160956859588623\n",
      "MSE train 5.80048647374183 MSE test 12.30583074958109\n",
      "MAE train 1.6672914325427326 MAE test 2.458271555783101\n",
      "Epoch 2732 / 10000 loss: 15.16042947769165\n",
      "MSE train 5.80031950087958 MSE test 12.305694232914204\n",
      "MAE train 1.6672640381374888 MAE test 2.458259801022613\n",
      "Epoch 2733 / 10000 loss: 15.1597740650177\n",
      "MSE train 5.800180544324932 MSE test 12.30551502866905\n",
      "MAE train 1.6672437270721414 MAE test 2.458238012760717\n",
      "Epoch 2734 / 10000 loss: 15.159172296524048\n",
      "MSE train 5.800017745328245 MSE test 12.305309440576123\n",
      "MAE train 1.66721908898412 MAE test 2.458217452090641\n",
      "Epoch 2735 / 10000 loss: 15.158641338348389\n",
      "MSE train 5.799860714952617 MSE test 12.305187656481124\n",
      "MAE train 1.6671932087515904 MAE test 2.4582030755550055\n",
      "Epoch 2736 / 10000 loss: 15.158103227615356\n",
      "MSE train 5.799692965688481 MSE test 12.305023173344983\n",
      "MAE train 1.667166426622599 MAE test 2.458187735228825\n",
      "Epoch 2737 / 10000 loss: 15.15746545791626\n",
      "MSE train 5.799556205650323 MSE test 12.304875050799293\n",
      "MAE train 1.6671459352234164 MAE test 2.458169901104437\n",
      "Epoch 2738 / 10000 loss: 15.156879901885986\n",
      "MSE train 5.799393112371902 MSE test 12.304631275743395\n",
      "MAE train 1.6671220285590127 MAE test 2.458144400607377\n",
      "Epoch 2739 / 10000 loss: 15.156338930130005\n",
      "MSE train 5.799220959705897 MSE test 12.30451186863239\n",
      "MAE train 1.667092788600396 MAE test 2.4581303817824645\n",
      "Epoch 2740 / 10000 loss: 15.155829906463623\n",
      "MSE train 5.799063528438844 MSE test 12.304440121151028\n",
      "MAE train 1.6670661429520741 MAE test 2.458126770915864\n",
      "Epoch 2741 / 10000 loss: 15.155134677886963\n",
      "MSE train 5.798908012680326 MSE test 12.30412996920201\n",
      "MAE train 1.6670453945665364 MAE test 2.4580882257961343\n",
      "Epoch 2742 / 10000 loss: 15.154528856277466\n",
      "MSE train 5.798751374944181 MSE test 12.304123265016482\n",
      "MAE train 1.667017408119428 MAE test 2.458092976261097\n",
      "Epoch 2743 / 10000 loss: 15.15401577949524\n",
      "MSE train 5.798598145961354 MSE test 12.303761814057376\n",
      "MAE train 1.6669983383170541 MAE test 2.45804782130287\n",
      "Epoch 2744 / 10000 loss: 15.153379678726196\n",
      "MSE train 5.79841468616418 MSE test 12.30377052043464\n",
      "MAE train 1.6669639199356978 MAE test 2.4580546390671607\n",
      "Epoch 2745 / 10000 loss: 15.15291428565979\n",
      "MSE train 5.798259315421255 MSE test 12.3035354490429\n",
      "MAE train 1.6669413347477378 MAE test 2.4580255647366482\n",
      "Epoch 2746 / 10000 loss: 15.152164697647095\n",
      "MSE train 5.798089195245627 MSE test 12.303424624818936\n",
      "MAE train 1.6669128477256077 MAE test 2.458016946215644\n",
      "Epoch 2747 / 10000 loss: 15.151604175567627\n",
      "MSE train 5.797934672233275 MSE test 12.303205841235473\n",
      "MAE train 1.6668902113823394 MAE test 2.4579899568506773\n",
      "Epoch 2748 / 10000 loss: 15.150980710983276\n",
      "MSE train 5.79776212187279 MSE test 12.303079493617266\n",
      "MAE train 1.6668616638732343 MAE test 2.457979353617054\n",
      "Epoch 2749 / 10000 loss: 15.150418519973755\n",
      "MSE train 5.797613322372033 MSE test 12.302892207187833\n",
      "MAE train 1.6668396982619276 MAE test 2.4579563515976943\n",
      "Epoch 2750 / 10000 loss: 15.149795293807983\n",
      "MSE train 5.797441895887464 MSE test 12.302700620428844\n",
      "MAE train 1.666813197492506 MAE test 2.4579373540386658\n",
      "Epoch 2751 / 10000 loss: 15.149240732192993\n",
      "MSE train 5.797284549423513 MSE test 12.302572034897702\n",
      "MAE train 1.6667878578678195 MAE test 2.4579218774619864\n",
      "Epoch 2752 / 10000 loss: 15.148664712905884\n",
      "MSE train 5.797110350049674 MSE test 12.30236494349166\n",
      "MAE train 1.6667611578942307 MAE test 2.457900845682984\n",
      "Epoch 2753 / 10000 loss: 15.14803957939148\n",
      "MSE train 5.796945159884277 MSE test 12.302237696078635\n",
      "MAE train 1.666734075304092 MAE test 2.457885502023455\n",
      "Epoch 2754 / 10000 loss: 15.147467374801636\n",
      "MSE train 5.796766135289744 MSE test 12.30205784791741\n",
      "MAE train 1.666705714061 MAE test 2.4578679085858286\n",
      "Epoch 2755 / 10000 loss: 15.14681077003479\n",
      "MSE train 5.796613652769167 MSE test 12.301915116847935\n",
      "MAE train 1.6666821228114048 MAE test 2.457850492680072\n",
      "Epoch 2756 / 10000 loss: 15.146200895309448\n",
      "MSE train 5.796436292844303 MSE test 12.301674387518172\n",
      "MAE train 1.6666556130155736 MAE test 2.457825055312088\n",
      "Epoch 2757 / 10000 loss: 15.145604610443115\n",
      "MSE train 5.79625138223723 MSE test 12.301550675416653\n",
      "MAE train 1.666624313410771 MAE test 2.457810174045154\n",
      "Epoch 2758 / 10000 loss: 15.145048379898071\n",
      "MSE train 5.796073264897387 MSE test 12.301457511975448\n",
      "MAE train 1.6665942725208605 MAE test 2.4578035319211673\n",
      "Epoch 2759 / 10000 loss: 15.144316673278809\n",
      "MSE train 5.795900032980526 MSE test 12.301181730006617\n",
      "MAE train 1.6665694423421278 MAE test 2.4577690445087876\n",
      "Epoch 2760 / 10000 loss: 15.143656015396118\n",
      "MSE train 5.795729446784051 MSE test 12.301137131799214\n",
      "MAE train 1.6665401871265086 MAE test 2.457768585050184\n",
      "Epoch 2761 / 10000 loss: 15.143062591552734\n",
      "MSE train 5.795558706388021 MSE test 12.300779587301685\n",
      "MAE train 1.6665180115949467 MAE test 2.457723598440282\n",
      "Epoch 2762 / 10000 loss: 15.142411231994629\n",
      "MSE train 5.795357752059949 MSE test 12.30078503084001\n",
      "MAE train 1.6664807225772442 MAE test 2.4577296342668182\n",
      "Epoch 2763 / 10000 loss: 15.14188528060913\n",
      "MSE train 5.795180422159788 MSE test 12.300531940990965\n",
      "MAE train 1.6664545819250858 MAE test 2.457697922670321\n",
      "Epoch 2764 / 10000 loss: 15.14108395576477\n",
      "MSE train 5.7949952986963265 MSE test 12.300445476654533\n",
      "MAE train 1.6664232193816697 MAE test 2.4576920601790326\n",
      "Epoch 2765 / 10000 loss: 15.140462636947632\n",
      "MSE train 5.794816254672679 MSE test 12.30016897395179\n",
      "MAE train 1.6663974047428551 MAE test 2.4576574217948894\n",
      "Epoch 2766 / 10000 loss: 15.139779806137085\n",
      "MSE train 5.7946410633499985 MSE test 12.300129146442318\n",
      "MAE train 1.6663671971437262 MAE test 2.457657541957227\n",
      "Epoch 2767 / 10000 loss: 15.139168500900269\n",
      "MSE train 5.794467373046022 MSE test 12.299765468548099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.666344600211848 MAE test 2.4576117525056187\n",
      "Epoch 2768 / 10000 loss: 15.138501167297363\n",
      "MSE train 5.794262243003739 MSE test 12.299771946094024\n",
      "MAE train 1.6663063917091965 MAE test 2.4576179834021126\n",
      "Epoch 2769 / 10000 loss: 15.137970447540283\n",
      "MSE train 5.7940883512358 MSE test 12.299537565187842\n",
      "MAE train 1.6662805277125745 MAE test 2.4575887132134357\n",
      "Epoch 2770 / 10000 loss: 15.137152194976807\n",
      "MSE train 5.793900554397212 MSE test 12.299418442588864\n",
      "MAE train 1.6662491509073256 MAE test 2.457578804848513\n",
      "Epoch 2771 / 10000 loss: 15.136533260345459\n",
      "MSE train 5.793733730026073 MSE test 12.299208617366828\n",
      "MAE train 1.6662243465080029 MAE test 2.457552742927435\n",
      "Epoch 2772 / 10000 loss: 15.135858535766602\n",
      "MSE train 5.793549338307429 MSE test 12.299058604389106\n",
      "MAE train 1.6661943816534226 MAE test 2.4575389597793826\n",
      "Epoch 2773 / 10000 loss: 15.135253429412842\n",
      "MSE train 5.7933972691733535 MSE test 12.298899271241758\n",
      "MAE train 1.666171579915426 MAE test 2.4575194360882966\n",
      "Epoch 2774 / 10000 loss: 15.134607791900635\n",
      "MSE train 5.793222193576023 MSE test 12.29865899270194\n",
      "MAE train 1.666145576995473 MAE test 2.4574941668970767\n",
      "Epoch 2775 / 10000 loss: 15.134031534194946\n",
      "MSE train 5.793039933538119 MSE test 12.298539294868707\n",
      "MAE train 1.6661146560646116 MAE test 2.4574799573066612\n",
      "Epoch 2776 / 10000 loss: 15.133481979370117\n",
      "MSE train 5.7928720667336915 MSE test 12.298460287426634\n",
      "MAE train 1.6660862842623194 MAE test 2.4574753221592007\n",
      "Epoch 2777 / 10000 loss: 15.132755994796753\n",
      "MSE train 5.792709959003189 MSE test 12.29816655609622\n",
      "MAE train 1.6660639488215065 MAE test 2.4574387918586624\n",
      "Epoch 2778 / 10000 loss: 15.13212251663208\n",
      "MSE train 5.792554280494083 MSE test 12.298149510217563\n",
      "MAE train 1.6660367570882806 MAE test 2.457442193100071\n",
      "Epoch 2779 / 10000 loss: 15.131576538085938\n",
      "MSE train 5.792400256556116 MSE test 12.297776206675481\n",
      "MAE train 1.6660178909188745 MAE test 2.4573955267166716\n",
      "Epoch 2780 / 10000 loss: 15.130955696105957\n",
      "MSE train 5.7922127442702465 MSE test 12.297787485250483\n",
      "MAE train 1.665982590388218 MAE test 2.4574027867370862\n",
      "Epoch 2781 / 10000 loss: 15.130496501922607\n",
      "MSE train 5.792067835415118 MSE test 12.297588560467947\n",
      "MAE train 1.6659615212390664 MAE test 2.457378406769578\n",
      "Epoch 2782 / 10000 loss: 15.129729986190796\n",
      "MSE train 5.791900245940052 MSE test 12.297407798781903\n",
      "MAE train 1.665935268289413 MAE test 2.4573609728422268\n",
      "Epoch 2783 / 10000 loss: 15.129181385040283\n",
      "MSE train 5.791757783746558 MSE test 12.297274950561086\n",
      "MAE train 1.6659130295283875 MAE test 2.4573451808000866\n",
      "Epoch 2784 / 10000 loss: 15.128608226776123\n",
      "MSE train 5.7915947632796465 MSE test 12.297049004297277\n",
      "MAE train 1.6658886786895248 MAE test 2.4573219953701964\n",
      "Epoch 2785 / 10000 loss: 15.12803316116333\n",
      "MSE train 5.79143022425348 MSE test 12.296930610911328\n",
      "MAE train 1.6658609802934379 MAE test 2.4573081834542205\n",
      "Epoch 2786 / 10000 loss: 15.127508878707886\n",
      "MSE train 5.791266206445433 MSE test 12.296819489863655\n",
      "MAE train 1.6658335183850084 MAE test 2.4572996952073427\n",
      "Epoch 2787 / 10000 loss: 15.12683629989624\n",
      "MSE train 5.791118807370028 MSE test 12.29660050272138\n",
      "MAE train 1.6658121009656133 MAE test 2.457272914457776\n",
      "Epoch 2788 / 10000 loss: 15.126225709915161\n",
      "MSE train 5.790955230396475 MSE test 12.296481570947764\n",
      "MAE train 1.6657849035229606 MAE test 2.4572635062113006\n",
      "Epoch 2789 / 10000 loss: 15.125680208206177\n",
      "MSE train 5.79081472901162 MSE test 12.296291611351531\n",
      "MAE train 1.6657643983821517 MAE test 2.457240454546553\n",
      "Epoch 2790 / 10000 loss: 15.125076532363892\n",
      "MSE train 5.79065347401674 MSE test 12.296119259362543\n",
      "MAE train 1.6657391249205589 MAE test 2.4572242525425123\n",
      "Epoch 2791 / 10000 loss: 15.12454080581665\n",
      "MSE train 5.790515968434431 MSE test 12.295988348814744\n",
      "MAE train 1.6657177971097166 MAE test 2.45720883279113\n",
      "Epoch 2792 / 10000 loss: 15.123978853225708\n",
      "MSE train 5.790357618187916 MSE test 12.29575855272898\n",
      "MAE train 1.6656943706303444 MAE test 2.4571852488387287\n",
      "Epoch 2793 / 10000 loss: 15.12341833114624\n",
      "MSE train 5.790193964386663 MSE test 12.295642050354259\n",
      "MAE train 1.6656666787220233 MAE test 2.4571717959790043\n",
      "Epoch 2794 / 10000 loss: 15.1229088306427\n",
      "MSE train 5.790035683296652 MSE test 12.295547494007343\n",
      "MAE train 1.6656399947600542 MAE test 2.457165501962368\n",
      "Epoch 2795 / 10000 loss: 15.122233867645264\n",
      "MSE train 5.789886629405584 MSE test 12.295297806612005\n",
      "MAE train 1.6656187407598388 MAE test 2.4571348742196997\n",
      "Epoch 2796 / 10000 loss: 15.12162971496582\n",
      "MSE train 5.7897348791054135 MSE test 12.295235721887943\n",
      "MAE train 1.6655928435955258 MAE test 2.4571327964439678\n",
      "Epoch 2797 / 10000 loss: 15.121091842651367\n",
      "MSE train 5.789587722800635 MSE test 12.29493581426838\n",
      "MAE train 1.6655733497741265 MAE test 2.457095772294013\n",
      "Epoch 2798 / 10000 loss: 15.120498657226562\n",
      "MSE train 5.7894396327731625 MSE test 12.29493306377769\n",
      "MAE train 1.6655468246736038 MAE test 2.457101337916785\n",
      "Epoch 2799 / 10000 loss: 15.11999773979187\n",
      "MSE train 5.789295466247245 MSE test 12.29457087664957\n",
      "MAE train 1.6655293150450354 MAE test 2.457056310240395\n",
      "Epoch 2800 / 10000 loss: 15.119383096694946\n",
      "MSE train 5.789119088786961 MSE test 12.29458410695997\n",
      "MAE train 1.665495914779472 MAE test 2.4570640573483455\n",
      "Epoch 2801 / 10000 loss: 15.118939399719238\n",
      "MSE train 5.788976325181289 MSE test 12.294367140094977\n",
      "MAE train 1.6654752573181024 MAE test 2.4570375900052737\n",
      "Epoch 2802 / 10000 loss: 15.11820125579834\n",
      "MSE train 5.788814592788702 MSE test 12.29423170772442\n",
      "MAE train 1.6654487475686783 MAE test 2.4570261792235684\n",
      "Epoch 2803 / 10000 loss: 15.117662191390991\n",
      "MSE train 5.788681903012484 MSE test 12.294061186667744\n",
      "MAE train 1.6654293751131206 MAE test 2.457005703208239\n",
      "Epoch 2804 / 10000 loss: 15.117071390151978\n",
      "MSE train 5.788525140809409 MSE test 12.29384760543154\n",
      "MAE train 1.6654058959457378 MAE test 2.456984285131383\n",
      "Epoch 2805 / 10000 loss: 15.116548776626587\n",
      "MSE train 5.788368543079945 MSE test 12.293730357724922\n",
      "MAE train 1.6653796953284685 MAE test 2.4569707669263234\n",
      "Epoch 2806 / 10000 loss: 15.116029262542725\n",
      "MSE train 5.788206582412564 MSE test 12.293597119643419\n",
      "MAE train 1.6653530278665127 MAE test 2.4569596205934574\n",
      "Epoch 2807 / 10000 loss: 15.115379571914673\n",
      "MSE train 5.788072285774001 MSE test 12.293417842816158\n",
      "MAE train 1.6653334693050514 MAE test 2.456938015191439\n",
      "Epoch 2808 / 10000 loss: 15.114784002304077\n",
      "MSE train 5.787914645272737 MSE test 12.293218306737478\n",
      "MAE train 1.6653095063432763 MAE test 2.4569184150308554\n",
      "Epoch 2809 / 10000 loss: 15.114259958267212\n",
      "MSE train 5.787765886436938 MSE test 12.293097615659235\n",
      "MAE train 1.6652851548684753 MAE test 2.4569044229543926\n",
      "Epoch 2810 / 10000 loss: 15.113725185394287\n",
      "MSE train 5.787604851561185 MSE test 12.292923617614727\n",
      "MAE train 1.6652597808352254 MAE test 2.45688807289209\n",
      "Epoch 2811 / 10000 loss: 15.113107442855835\n",
      "MSE train 5.787471343540584 MSE test 12.292787139081387\n",
      "MAE train 1.6652393581345082 MAE test 2.4568720043295933\n",
      "Epoch 2812 / 10000 loss: 15.112542867660522\n",
      "MSE train 5.787314246780666 MSE test 12.292552823319962\n",
      "MAE train 1.6652161892950794 MAE test 2.4568479253616538\n",
      "Epoch 2813 / 10000 loss: 15.11199426651001\n",
      "MSE train 5.787151291972059 MSE test 12.292435609599782\n",
      "MAE train 1.665188575287895 MAE test 2.456834456869146\n",
      "Epoch 2814 / 10000 loss: 15.11148977279663\n",
      "MSE train 5.786996157828735 MSE test 12.292347761965583\n",
      "MAE train 1.665162364476424 MAE test 2.4568291068620756\n",
      "Epoch 2815 / 10000 loss: 15.11081314086914\n",
      "MSE train 5.786847511189216 MSE test 12.292080716695864\n",
      "MAE train 1.6651415914468735 MAE test 2.456796298979375\n",
      "Epoch 2816 / 10000 loss: 15.1102135181427\n",
      "MSE train 5.786702423771815 MSE test 12.29204045820586\n",
      "MAE train 1.6651166475330412 MAE test 2.4567970854146983\n",
      "Epoch 2817 / 10000 loss: 15.109683990478516\n",
      "MSE train 5.786558763732056 MSE test 12.291694169158815\n",
      "MAE train 1.6650989265187013 MAE test 2.4567541248266056\n",
      "Epoch 2818 / 10000 loss: 15.109100818634033\n",
      "MSE train 5.786388295062719 MSE test 12.291705926920274\n",
      "MAE train 1.6650668599608887 MAE test 2.4567617105614565\n",
      "Epoch 2819 / 10000 loss: 15.108644485473633\n",
      "MSE train 5.786239434918103 MSE test 12.291448406687701\n",
      "MAE train 1.6650457416455184 MAE test 2.4567301030122164\n",
      "Epoch 2820 / 10000 loss: 15.107928276062012\n",
      "MSE train 5.786089712282106 MSE test 12.29138832198836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6650201894340322 MAE test 2.4567283561268347\n",
      "Epoch 2821 / 10000 loss: 15.107391119003296\n",
      "MSE train 5.785943392147118 MSE test 12.291077359601813\n",
      "MAE train 1.6650011163840284 MAE test 2.456689918773995\n",
      "Epoch 2822 / 10000 loss: 15.106799840927124\n",
      "MSE train 5.785791838990521 MSE test 12.29107795196217\n",
      "MAE train 1.6649736534417798 MAE test 2.456696004766933\n",
      "Epoch 2823 / 10000 loss: 15.10630750656128\n",
      "MSE train 5.785646784502646 MSE test 12.290728717008738\n",
      "MAE train 1.6649556764062894 MAE test 2.4566526542414526\n",
      "Epoch 2824 / 10000 loss: 15.105672597885132\n",
      "MSE train 5.785476387693177 MSE test 12.29073883359502\n",
      "MAE train 1.6649236500520939 MAE test 2.4566600317087337\n",
      "Epoch 2825 / 10000 loss: 15.105212926864624\n",
      "MSE train 5.785327083606472 MSE test 12.29048015357881\n",
      "MAE train 1.6649024778070924 MAE test 2.4566282637770263\n",
      "Epoch 2826 / 10000 loss: 15.104496955871582\n",
      "MSE train 5.785176975664399 MSE test 12.290419202683985\n",
      "MAE train 1.6648768638867113 MAE test 2.4566264050435445\n",
      "Epoch 2827 / 10000 loss: 15.103958129882812\n",
      "MSE train 5.785030218445491 MSE test 12.290107774075071\n",
      "MAE train 1.6648577144260985 MAE test 2.4565879029514104\n",
      "Epoch 2828 / 10000 loss: 15.103366136550903\n",
      "MSE train 5.784878351378341 MSE test 12.290107520314352\n",
      "MAE train 1.6648302139441362 MAE test 2.4565938941944596\n",
      "Epoch 2829 / 10000 loss: 15.10287094116211\n",
      "MSE train 5.784732709462665 MSE test 12.289757123485872\n",
      "MAE train 1.6648121615294986 MAE test 2.4565503855143946\n",
      "Epoch 2830 / 10000 loss: 15.10223388671875\n",
      "MSE train 5.784561522732839 MSE test 12.289766696617768\n",
      "MAE train 1.6647799961795522 MAE test 2.456557677958468\n",
      "Epoch 2831 / 10000 loss: 15.101773500442505\n",
      "MSE train 5.78441169135963 MSE test 12.289508781418995\n",
      "MAE train 1.6647587107269808 MAE test 2.456526004391898\n",
      "Epoch 2832 / 10000 loss: 15.10105299949646\n",
      "MSE train 5.784260223697791 MSE test 12.289444867923008\n",
      "MAE train 1.6647328995052384 MAE test 2.4565237571885037\n",
      "Epoch 2833 / 10000 loss: 15.100510120391846\n",
      "MSE train 5.784112346395621 MSE test 12.289137214558757\n",
      "MAE train 1.664713440952328 MAE test 2.456485737346315\n",
      "Epoch 2834 / 10000 loss: 15.099912881851196\n",
      "MSE train 5.783961592885357 MSE test 12.289133684595928\n",
      "MAE train 1.6646863432550298 MAE test 2.4564912837886586\n",
      "Epoch 2835 / 10000 loss: 15.099409103393555\n",
      "MSE train 5.783815446787166 MSE test 12.288774856193065\n",
      "MAE train 1.6646683962186124 MAE test 2.4564466986002427\n",
      "Epoch 2836 / 10000 loss: 15.098778009414673\n",
      "MSE train 5.783639659447133 MSE test 12.28878463546803\n",
      "MAE train 1.6646352940833624 MAE test 2.456454026931099\n",
      "Epoch 2837 / 10000 loss: 15.098318576812744\n",
      "MSE train 5.783491009695973 MSE test 12.288547280506954\n",
      "MAE train 1.6646138833473192 MAE test 2.4564249564457437\n",
      "Epoch 2838 / 10000 loss: 15.097578048706055\n",
      "MSE train 5.783329444758965 MSE test 12.288443836843374\n",
      "MAE train 1.6645867517902364 MAE test 2.4564176305853875\n",
      "Epoch 2839 / 10000 loss: 15.097023487091064\n",
      "MSE train 5.7831806894628865 MSE test 12.288214508930384\n",
      "MAE train 1.664565243275277 MAE test 2.4563896467127493\n",
      "Epoch 2840 / 10000 loss: 15.096406698226929\n",
      "MSE train 5.783018221717711 MSE test 12.288112359585616\n",
      "MAE train 1.6645379513404692 MAE test 2.4563825103497554\n",
      "Epoch 2841 / 10000 loss: 15.095849514007568\n",
      "MSE train 5.782868787374261 MSE test 12.287886880958004\n",
      "MAE train 1.6645163018194895 MAE test 2.4563550214149674\n",
      "Epoch 2842 / 10000 loss: 15.095227003097534\n",
      "MSE train 5.782704232504743 MSE test 12.287779653545865\n",
      "MAE train 1.6644887459450217 MAE test 2.456347222188992\n",
      "Epoch 2843 / 10000 loss: 15.09466290473938\n",
      "MSE train 5.7825548165863 MSE test 12.287564184952865\n",
      "MAE train 1.6644670262831749 MAE test 2.456321020120628\n",
      "Epoch 2844 / 10000 loss: 15.094033479690552\n",
      "MSE train 5.782386839123799 MSE test 12.287436352470825\n",
      "MAE train 1.6644393751935613 MAE test 2.4563106002842927\n",
      "Epoch 2845 / 10000 loss: 15.093462228775024\n",
      "MSE train 5.782242692273294 MSE test 12.287253198810424\n",
      "MAE train 1.6644183101289234 MAE test 2.456288512837976\n",
      "Epoch 2846 / 10000 loss: 15.092827081680298\n",
      "MSE train 5.782074793146432 MSE test 12.287054461553849\n",
      "MAE train 1.6643927491081787 MAE test 2.4562689852804525\n",
      "Epoch 2847 / 10000 loss: 15.092254638671875\n",
      "MSE train 5.781915057054086 MSE test 12.286928725537104\n",
      "MAE train 1.6643669286577523 MAE test 2.4562543087967383\n",
      "Epoch 2848 / 10000 loss: 15.091661214828491\n",
      "MSE train 5.781739343414095 MSE test 12.286739260018212\n",
      "MAE train 1.664339747667494 MAE test 2.4562359469247426\n",
      "Epoch 2849 / 10000 loss: 15.090983152389526\n",
      "MSE train 5.781582444975833 MSE test 12.286604255396332\n",
      "MAE train 1.6643153046340884 MAE test 2.456220050016505\n",
      "Epoch 2850 / 10000 loss: 15.0903480052948\n",
      "MSE train 5.781402264749384 MSE test 12.286380385012906\n",
      "MAE train 1.6642883581220476 MAE test 2.456197264868085\n",
      "Epoch 2851 / 10000 loss: 15.08967661857605\n",
      "MSE train 5.7812200586935765 MSE test 12.286255140596378\n",
      "MAE train 1.6642584740436157 MAE test 2.456182644302099\n",
      "Epoch 2852 / 10000 loss: 15.089041233062744\n",
      "MSE train 5.781028883069332 MSE test 12.286116251808439\n",
      "MAE train 1.664227605356596 MAE test 2.456170699904682\n",
      "Epoch 2853 / 10000 loss: 15.088254928588867\n",
      "MSE train 5.780862588534356 MSE test 12.285926218535552\n",
      "MAE train 1.6642035125708896 MAE test 2.456147656920517\n",
      "Epoch 2854 / 10000 loss: 15.087507247924805\n",
      "MSE train 5.780673557042268 MSE test 12.285725733497365\n",
      "MAE train 1.6641750058377305 MAE test 2.4561278419872288\n",
      "Epoch 2855 / 10000 loss: 15.08681869506836\n",
      "MSE train 5.780500767860701 MSE test 12.285595769829634\n",
      "MAE train 1.66414781360096 MAE test 2.456112558217194\n",
      "Epoch 2856 / 10000 loss: 15.086117506027222\n",
      "MSE train 5.780318745567999 MSE test 12.285398149450128\n",
      "MAE train 1.664120096709459 MAE test 2.4560930807201613\n",
      "Epoch 2857 / 10000 loss: 15.085370779037476\n",
      "MSE train 5.780161203753987 MSE test 12.285264818337344\n",
      "MAE train 1.664095274540209 MAE test 2.4560773601815535\n",
      "Epoch 2858 / 10000 loss: 15.084707021713257\n",
      "MSE train 5.779991592260662 MSE test 12.285054434333453\n",
      "MAE train 1.6640693713690593 MAE test 2.4560562403291835\n",
      "Epoch 2859 / 10000 loss: 15.084036350250244\n",
      "MSE train 5.779836002562939 MSE test 12.284926998614923\n",
      "MAE train 1.6640439049970128 MAE test 2.4560413134336483\n",
      "Epoch 2860 / 10000 loss: 15.083447217941284\n",
      "MSE train 5.779670302110354 MSE test 12.284750853638943\n",
      "MAE train 1.6640176816004397 MAE test 2.456024590599121\n",
      "Epoch 2861 / 10000 loss: 15.082794427871704\n",
      "MSE train 5.7795354835044135 MSE test 12.28460651328903\n",
      "MAE train 1.6639972179776856 MAE test 2.456007446943411\n",
      "Epoch 2862 / 10000 loss: 15.082207679748535\n",
      "MSE train 5.779376671427247 MSE test 12.284364589721251\n",
      "MAE train 1.66397379313654 MAE test 2.455982337243548\n",
      "Epoch 2863 / 10000 loss: 15.081655740737915\n",
      "MSE train 5.779211337182563 MSE test 12.284243561665214\n",
      "MAE train 1.663945703048358 MAE test 2.4559683021510006\n",
      "Epoch 2864 / 10000 loss: 15.081149816513062\n",
      "MSE train 5.779057236118119 MSE test 12.284160335954544\n",
      "MAE train 1.6639195863345349 MAE test 2.4559634620703976\n",
      "Epoch 2865 / 10000 loss: 15.080469131469727\n",
      "MSE train 5.778907505819042 MSE test 12.28387228682222\n",
      "MAE train 1.663899082095298 MAE test 2.4559279426320786\n",
      "Epoch 2866 / 10000 loss: 15.079872846603394\n",
      "MSE train 5.778763734374357 MSE test 12.283847986364211\n",
      "MAE train 1.663874025826295 MAE test 2.455930712488476\n",
      "Epoch 2867 / 10000 loss: 15.079356670379639\n",
      "MSE train 5.778619333327822 MSE test 12.283475095288532\n",
      "MAE train 1.663856654194031 MAE test 2.4558843511042854\n",
      "Epoch 2868 / 10000 loss: 15.078772783279419\n",
      "MSE train 5.778440724669932 MSE test 12.28348472038578\n",
      "MAE train 1.6638227916253034 MAE test 2.455891599369076\n",
      "Epoch 2869 / 10000 loss: 15.078338384628296\n",
      "MSE train 5.778301972911816 MSE test 12.283280665244455\n",
      "MAE train 1.6638027407351055 MAE test 2.455866785961932\n",
      "Epoch 2870 / 10000 loss: 15.077597618103027\n",
      "MSE train 5.778140227538464 MSE test 12.283104529085382\n",
      "MAE train 1.6637772150141692 MAE test 2.455850115814746\n",
      "Epoch 2871 / 10000 loss: 15.077068567276001\n",
      "MSE train 5.778005779728027 MSE test 12.282964648264478\n",
      "MAE train 1.6637566375300443 MAE test 2.4558336207958384\n",
      "Epoch 2872 / 10000 loss: 15.076506853103638\n",
      "MSE train 5.777847750444545 MSE test 12.282726561655473\n",
      "MAE train 1.6637332970221512 MAE test 2.4558090300032616\n",
      "Epoch 2873 / 10000 loss: 15.075961351394653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.777683711331034 MSE test 12.282605797449198\n",
      "MAE train 1.6637054887881164 MAE test 2.4557950772243986\n",
      "Epoch 2874 / 10000 loss: 15.07546091079712\n",
      "MSE train 5.777527845541831 MSE test 12.282515370479809\n",
      "MAE train 1.663679121634836 MAE test 2.4557893417397896\n",
      "Epoch 2875 / 10000 loss: 15.074787855148315\n",
      "MSE train 5.777378118226846 MSE test 12.282242634781621\n",
      "MAE train 1.6636582151709893 MAE test 2.455755820892716\n",
      "Epoch 2876 / 10000 loss: 15.074191808700562\n",
      "MSE train 5.77723259059131 MSE test 12.282201171155823\n",
      "MAE train 1.6636331555728663 MAE test 2.4557564095341484\n",
      "Epoch 2877 / 10000 loss: 15.073667526245117\n",
      "MSE train 5.777087979079778 MSE test 12.281846947887928\n",
      "MAE train 1.663615359963223 MAE test 2.4557124715617813\n",
      "Epoch 2878 / 10000 loss: 15.07308840751648\n",
      "MSE train 5.776914967921161 MSE test 12.281855314459305\n",
      "MAE train 1.6635827386667519 MAE test 2.455719559299262\n",
      "Epoch 2879 / 10000 loss: 15.072639226913452\n",
      "MSE train 5.776766128727108 MSE test 12.281604748100168\n",
      "MAE train 1.6635613891893042 MAE test 2.45568883239474\n",
      "Epoch 2880 / 10000 loss: 15.071920156478882\n",
      "MSE train 5.776610911226479 MSE test 12.281522300231519\n",
      "MAE train 1.6635350182001263 MAE test 2.455684164116744\n",
      "Epoch 2881 / 10000 loss: 15.071383953094482\n",
      "MSE train 5.77646181807506 MSE test 12.281246199441526\n",
      "MAE train 1.6635143341141045 MAE test 2.4556502547244716\n",
      "Epoch 2882 / 10000 loss: 15.07079029083252\n",
      "MSE train 5.776317230786038 MSE test 12.281211426456009\n",
      "MAE train 1.6634893323868063 MAE test 2.4556517080028044\n",
      "Epoch 2883 / 10000 loss: 15.070269346237183\n",
      "MSE train 5.77617315173586 MSE test 12.280846436486485\n",
      "MAE train 1.6634718398781314 MAE test 2.4556064142712977\n",
      "Epoch 2884 / 10000 loss: 15.069691181182861\n",
      "MSE train 5.775996332236353 MSE test 12.28085455235073\n",
      "MAE train 1.663438367038215 MAE test 2.455613482550507\n",
      "Epoch 2885 / 10000 loss: 15.069251298904419\n",
      "MSE train 5.775852117140414 MSE test 12.280629229818155\n",
      "MAE train 1.663417489401844 MAE test 2.455586009731717\n",
      "Epoch 2886 / 10000 loss: 15.068517208099365\n",
      "MSE train 5.775689700752533 MSE test 12.280493502550366\n",
      "MAE train 1.6633907057664694 MAE test 2.4555745340017827\n",
      "Epoch 2887 / 10000 loss: 15.067981481552124\n",
      "MSE train 5.775554164316368 MSE test 12.280309035260894\n",
      "MAE train 1.6633709183691145 MAE test 2.4555523413774094\n",
      "Epoch 2888 / 10000 loss: 15.06739068031311\n",
      "MSE train 5.77539550063536 MSE test 12.280103437129478\n",
      "MAE train 1.6633467664974078 MAE test 2.4555319351385423\n",
      "Epoch 2889 / 10000 loss: 15.066869497299194\n",
      "MSE train 5.775245233051576 MSE test 12.279976455688027\n",
      "MAE train 1.6633221438963077 MAE test 2.455517186688659\n",
      "Epoch 2890 / 10000 loss: 15.066338539123535\n",
      "MSE train 5.775082937108798 MSE test 12.279796311790628\n",
      "MAE train 1.6632965187399196 MAE test 2.4555000111909777\n",
      "Epoch 2891 / 10000 loss: 15.065721273422241\n",
      "MSE train 5.774948188458385 MSE test 12.279652329685725\n",
      "MAE train 1.6632759046706014 MAE test 2.4554830501681835\n",
      "Epoch 2892 / 10000 loss: 15.065159559249878\n",
      "MSE train 5.774789693555257 MSE test 12.279410297271307\n",
      "MAE train 1.6632524782200173 MAE test 2.455457962953874\n",
      "Epoch 2893 / 10000 loss: 15.064613580703735\n",
      "MSE train 5.774625184845015 MSE test 12.279285372038578\n",
      "MAE train 1.6632245737261708 MAE test 2.4554435538384567\n",
      "Epoch 2894 / 10000 loss: 15.064111232757568\n",
      "MSE train 5.774468817400838 MSE test 12.279190756457261\n",
      "MAE train 1.663198112940904 MAE test 2.4554373097395517\n",
      "Epoch 2895 / 10000 loss: 15.063437461853027\n",
      "MSE train 5.77431839670313 MSE test 12.27891350590298\n",
      "MAE train 1.6631770772839318 MAE test 2.4554032473883263\n",
      "Epoch 2896 / 10000 loss: 15.06283974647522\n",
      "MSE train 5.774172263775004 MSE test 12.278867293591468\n",
      "MAE train 1.6631519023144143 MAE test 2.45540326363378\n",
      "Epoch 2897 / 10000 loss: 15.062311887741089\n",
      "MSE train 5.774026835122271 MSE test 12.278508213847681\n",
      "MAE train 1.6631339502311469 MAE test 2.455358744998909\n",
      "Epoch 2898 / 10000 loss: 15.061731338500977\n",
      "MSE train 5.7738530930442415 MSE test 12.278511401230228\n",
      "MAE train 1.663101191530494 MAE test 2.455365203066699\n",
      "Epoch 2899 / 10000 loss: 15.061279535293579\n",
      "MSE train 5.773703249356152 MSE test 12.278254940965718\n",
      "MAE train 1.6630796593655848 MAE test 2.45533379768292\n",
      "Epoch 2900 / 10000 loss: 15.060557842254639\n",
      "MSE train 5.77354709103811 MSE test 12.278167320078014\n",
      "MAE train 1.6630531090113336 MAE test 2.4553285141992114\n",
      "Epoch 2901 / 10000 loss: 15.060018301010132\n",
      "MSE train 5.773396785100564 MSE test 12.277883534389984\n",
      "MAE train 1.6630322421547303 MAE test 2.4552936638565352\n",
      "Epoch 2902 / 10000 loss: 15.059420585632324\n",
      "MSE train 5.7732511393153345 MSE test 12.27784386761831\n",
      "MAE train 1.6630070054339074 MAE test 2.455294545600006\n",
      "Epoch 2903 / 10000 loss: 15.058894872665405\n",
      "MSE train 5.773105510634441 MSE test 12.277469989158657\n",
      "MAE train 1.6629892775220454 MAE test 2.455248182902012\n",
      "Epoch 2904 / 10000 loss: 15.058311223983765\n",
      "MSE train 5.772926592576945 MSE test 12.277470768869248\n",
      "MAE train 1.6629553664125583 MAE test 2.455254381664356\n",
      "Epoch 2905 / 10000 loss: 15.05786681175232\n",
      "MSE train 5.772781627940315 MSE test 12.277242125467055\n",
      "MAE train 1.6629342944748982 MAE test 2.455226573733707\n",
      "Epoch 2906 / 10000 loss: 15.057124853134155\n",
      "MSE train 5.772616789876264 MSE test 12.277088153424325\n",
      "MAE train 1.6629073036516238 MAE test 2.455212801895647\n",
      "Epoch 2907 / 10000 loss: 15.056582927703857\n",
      "MSE train 5.772481796385337 MSE test 12.276907354914401\n",
      "MAE train 1.6628874588461815 MAE test 2.4551911960652757\n",
      "Epoch 2908 / 10000 loss: 15.05598783493042\n",
      "MSE train 5.772321503296854 MSE test 12.276669193292074\n",
      "MAE train 1.6628634774581559 MAE test 2.4551666684323243\n",
      "Epoch 2909 / 10000 loss: 15.055460214614868\n",
      "MSE train 5.77215726744272 MSE test 12.276535676815385\n",
      "MAE train 1.6628357287135382 MAE test 2.4551512378197775\n",
      "Epoch 2910 / 10000 loss: 15.054938793182373\n",
      "MSE train 5.771992448176233 MSE test 12.276405590798944\n",
      "MAE train 1.6628080128955307 MAE test 2.4551405379383224\n",
      "Epoch 2911 / 10000 loss: 15.054264307022095\n",
      "MSE train 5.771843820596143 MSE test 12.276171106863218\n",
      "MAE train 1.6627862384629684 MAE test 2.4551120632777512\n",
      "Epoch 2912 / 10000 loss: 15.05364990234375\n",
      "MSE train 5.771677124552625 MSE test 12.276025465230488\n",
      "MAE train 1.6627585257271216 MAE test 2.4550994473841246\n",
      "Epoch 2913 / 10000 loss: 15.053096532821655\n",
      "MSE train 5.771534981469777 MSE test 12.275822852117148\n",
      "MAE train 1.6627375125964758 MAE test 2.455075120136852\n",
      "Epoch 2914 / 10000 loss: 15.052484035491943\n",
      "MSE train 5.771369775749381 MSE test 12.27560691792505\n",
      "MAE train 1.662711954916039 MAE test 2.455053526070167\n",
      "Epoch 2915 / 10000 loss: 15.051936626434326\n",
      "MSE train 5.7712155994334 MSE test 12.275459668943562\n",
      "MAE train 1.662686740348996 MAE test 2.4550363980764316\n",
      "Epoch 2916 / 10000 loss: 15.051371335983276\n",
      "MSE train 5.771045957359275 MSE test 12.275243026531431\n",
      "MAE train 1.662660173035806 MAE test 2.4550147362220502\n",
      "Epoch 2917 / 10000 loss: 15.050737857818604\n",
      "MSE train 5.770893747533429 MSE test 12.27508694036948\n",
      "MAE train 1.6626355697961874 MAE test 2.4549965003808523\n",
      "Epoch 2918 / 10000 loss: 15.050154209136963\n",
      "MSE train 5.770722322161598 MSE test 12.27484949727223\n",
      "MAE train 1.662608981770256 MAE test 2.454972198654405\n",
      "Epoch 2919 / 10000 loss: 15.049526453018188\n",
      "MSE train 5.770558421451435 MSE test 12.274695020432958\n",
      "MAE train 1.6625816307946029 MAE test 2.4549542428089404\n",
      "Epoch 2920 / 10000 loss: 15.048946142196655\n",
      "MSE train 5.770381614930956 MSE test 12.274495406353509\n",
      "MAE train 1.6625528216671055 MAE test 2.4549348095548784\n",
      "Epoch 2921 / 10000 loss: 15.048267841339111\n",
      "MSE train 5.770235252920142 MSE test 12.274315267846937\n",
      "MAE train 1.6625301061421307 MAE test 2.4549135276278187\n",
      "Epoch 2922 / 10000 loss: 15.047634840011597\n",
      "MSE train 5.770062851846348 MSE test 12.274039370216453\n",
      "MAE train 1.6625039040407195 MAE test 2.4548843494113997\n",
      "Epoch 2923 / 10000 loss: 15.047038555145264\n",
      "MSE train 5.769883419425396 MSE test 12.273887785567238\n",
      "MAE train 1.662472845209037 MAE test 2.454866815715073\n",
      "Epoch 2924 / 10000 loss: 15.046478509902954\n",
      "MSE train 5.769719403560734 MSE test 12.273783035059626\n",
      "MAE train 1.6624444212231586 MAE test 2.4548594974877442\n",
      "Epoch 2925 / 10000 loss: 15.045737266540527\n",
      "MSE train 5.769560092840492 MSE test 12.273454339332975\n",
      "MAE train 1.662422088307978 MAE test 2.4548190531094556\n",
      "Epoch 2926 / 10000 loss: 15.045093059539795\n",
      "MSE train 5.769405885006813 MSE test 12.273420743828387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6623942492840922 MAE test 2.454820853114192\n",
      "Epoch 2927 / 10000 loss: 15.044548273086548\n",
      "MSE train 5.769254634762847 MSE test 12.273033272433382\n",
      "MAE train 1.6623751304916314 MAE test 2.4547728086285137\n",
      "Epoch 2928 / 10000 loss: 15.043914079666138\n",
      "MSE train 5.769072573677299 MSE test 12.273028202327223\n",
      "MAE train 1.662340317024111 MAE test 2.454778257327866\n",
      "Epoch 2929 / 10000 loss: 15.043453454971313\n",
      "MSE train 5.76892734892979 MSE test 12.272803043236793\n",
      "MAE train 1.6623188778928026 MAE test 2.454750931454288\n",
      "Epoch 2930 / 10000 loss: 15.042701005935669\n",
      "MSE train 5.768761613712324 MSE test 12.272637773503652\n",
      "MAE train 1.6622917830955803 MAE test 2.454735686707063\n",
      "Epoch 2931 / 10000 loss: 15.042158126831055\n",
      "MSE train 5.768627612590676 MSE test 12.27247268263179\n",
      "MAE train 1.6622717311084045 MAE test 2.454716098275662\n",
      "Epoch 2932 / 10000 loss: 15.041572332382202\n",
      "MSE train 5.768467300819646 MSE test 12.272222986810535\n",
      "MAE train 1.6622478922046742 MAE test 2.4546900663646456\n",
      "Epoch 2933 / 10000 loss: 15.041044473648071\n",
      "MSE train 5.768298589703621 MSE test 12.272094670213017\n",
      "MAE train 1.6622190435630029 MAE test 2.4546753385122053\n",
      "Epoch 2934 / 10000 loss: 15.040543556213379\n",
      "MSE train 5.768142239403044 MSE test 12.27200720582868\n",
      "MAE train 1.6621923648298522 MAE test 2.4546700394367553\n",
      "Epoch 2935 / 10000 loss: 15.039858341217041\n",
      "MSE train 5.767988704436057 MSE test 12.271700707252718\n",
      "MAE train 1.6621713157658422 MAE test 2.454632395156437\n",
      "Epoch 2936 / 10000 loss: 15.039260149002075\n",
      "MSE train 5.767839145564002 MSE test 12.27167311470294\n",
      "MAE train 1.6621448520502133 MAE test 2.4546349298835333\n",
      "Epoch 2937 / 10000 loss: 15.038743734359741\n",
      "MSE train 5.767688738340151 MSE test 12.271287202769896\n",
      "MAE train 1.6621262757349542 MAE test 2.4545871477905736\n",
      "Epoch 2938 / 10000 loss: 15.038141250610352\n",
      "MSE train 5.7675036915920534 MSE test 12.271282557644874\n",
      "MAE train 1.6620911075976423 MAE test 2.4545928107668167\n",
      "Epoch 2939 / 10000 loss: 15.037696361541748\n",
      "MSE train 5.767357029393836 MSE test 12.271062254968507\n",
      "MAE train 1.662069481110205 MAE test 2.4545663169620218\n",
      "Epoch 2940 / 10000 loss: 15.036939859390259\n",
      "MSE train 5.76718550644174 MSE test 12.270868324406697\n",
      "MAE train 1.66204196268843 MAE test 2.4545476728897326\n",
      "Epoch 2941 / 10000 loss: 15.036391496658325\n",
      "MSE train 5.767039357692073 MSE test 12.270707253382625\n",
      "MAE train 1.6620190387585076 MAE test 2.454528959063586\n",
      "Epoch 2942 / 10000 loss: 15.035804986953735\n",
      "MSE train 5.766866247069019 MSE test 12.270444917946126\n",
      "MAE train 1.6619925826656021 MAE test 2.454501659157545\n",
      "Epoch 2943 / 10000 loss: 15.035226345062256\n",
      "MSE train 5.766682941433435 MSE test 12.270296040912925\n",
      "MAE train 1.6619607790693078 MAE test 2.454484775126878\n",
      "Epoch 2944 / 10000 loss: 15.03468132019043\n",
      "MSE train 5.766501617225945 MSE test 12.270173036701243\n",
      "MAE train 1.6619290243133815 MAE test 2.45447551106063\n",
      "Epoch 2945 / 10000 loss: 15.03394865989685\n",
      "MSE train 5.766316657043981 MSE test 12.26986042835701\n",
      "MAE train 1.661900571840506 MAE test 2.454437796923544\n",
      "Epoch 2946 / 10000 loss: 15.033270359039307\n",
      "MSE train 5.766121073790961 MSE test 12.269771955272164\n",
      "MAE train 1.661864570146055 MAE test 2.4544334669642756\n",
      "Epoch 2947 / 10000 loss: 15.032624244689941\n",
      "MSE train 5.765901243665589 MSE test 12.269358758899445\n",
      "MAE train 1.6618300926795286 MAE test 2.454383542787258\n",
      "Epoch 2948 / 10000 loss: 15.031863451004028\n",
      "MSE train 5.765613855906498 MSE test 12.269295527622612\n",
      "MAE train 1.6617713988684522 MAE test 2.4543831756329118\n",
      "Epoch 2949 / 10000 loss: 15.031131029129028\n",
      "MSE train 5.765301736766538 MSE test 12.268961657719286\n",
      "MAE train 1.6617115856483544 MAE test 2.454343962615175\n",
      "Epoch 2950 / 10000 loss: 15.029959440231323\n",
      "MSE train 5.764969778578731 MSE test 12.268789305590277\n",
      "MAE train 1.6616429630544727 MAE test 2.45432993871063\n",
      "Epoch 2951 / 10000 loss: 15.02875018119812\n",
      "MSE train 5.764710542453362 MSE test 12.26845412966068\n",
      "MAE train 1.661596510333231 MAE test 2.4542900713993543\n",
      "Epoch 2952 / 10000 loss: 15.027411222457886\n",
      "MSE train 5.764520712106976 MSE test 12.26838127841536\n",
      "MAE train 1.6615612308902168 MAE test 2.4542871926296637\n",
      "Epoch 2953 / 10000 loss: 15.026419878005981\n",
      "MSE train 5.764358420403116 MSE test 12.268012428886546\n",
      "MAE train 1.6615393121156021 MAE test 2.454241471431085\n",
      "Epoch 2954 / 10000 loss: 15.025654792785645\n",
      "MSE train 5.764176906365345 MSE test 12.268014702304702\n",
      "MAE train 1.6615046635618795 MAE test 2.4542476201538057\n",
      "Epoch 2955 / 10000 loss: 15.025129795074463\n",
      "MSE train 5.764024021166656 MSE test 12.267763513626615\n",
      "MAE train 1.6614822462423466 MAE test 2.4542166803868213\n",
      "Epoch 2956 / 10000 loss: 15.024374723434448\n",
      "MSE train 5.763866240180955 MSE test 12.267678793390779\n",
      "MAE train 1.6614551920241647 MAE test 2.454211420595247\n",
      "Epoch 2957 / 10000 loss: 15.023819208145142\n",
      "MSE train 5.763716481798323 MSE test 12.267411467286811\n",
      "MAE train 1.6614340610870355 MAE test 2.454178382967572\n",
      "Epoch 2958 / 10000 loss: 15.023214340209961\n",
      "MSE train 5.763571174104209 MSE test 12.267373867237357\n",
      "MAE train 1.661408855243209 MAE test 2.454179139739254\n",
      "Epoch 2959 / 10000 loss: 15.02268362045288\n",
      "MSE train 5.763427737055091 MSE test 12.2670255755517\n",
      "MAE train 1.661391140170066 MAE test 2.454135709787841\n",
      "Epoch 2960 / 10000 loss: 15.022100448608398\n",
      "MSE train 5.763256708958048 MSE test 12.267039516511117\n",
      "MAE train 1.661358721239819 MAE test 2.4541431631188635\n",
      "Epoch 2961 / 10000 loss: 15.021649360656738\n",
      "MSE train 5.763109509555544 MSE test 12.266792686814693\n",
      "MAE train 1.6613375964805204 MAE test 2.454112692647567\n",
      "Epoch 2962 / 10000 loss: 15.020932674407959\n",
      "MSE train 5.76295753433449 MSE test 12.266721065492066\n",
      "MAE train 1.6613116106238164 MAE test 2.4541090333300195\n",
      "Epoch 2963 / 10000 loss: 15.020396709442139\n",
      "MSE train 5.762810979058732 MSE test 12.266443087531227\n",
      "MAE train 1.6612915140263498 MAE test 2.454074613679328\n",
      "Epoch 2964 / 10000 loss: 15.019806146621704\n",
      "MSE train 5.7626697067043935 MSE test 12.266424771707452\n",
      "MAE train 1.661266786415597 MAE test 2.4540778197679742\n",
      "Epoch 2965 / 10000 loss: 15.019293546676636\n",
      "MSE train 5.762528219135853 MSE test 12.26605782681878\n",
      "MAE train 1.6612498033725789 MAE test 2.4540319783403315\n",
      "Epoch 2966 / 10000 loss: 15.018715143203735\n",
      "MSE train 5.762352415326516 MSE test 12.26607372937665\n",
      "MAE train 1.66121628239644 MAE test 2.454039687002598\n",
      "Epoch 2967 / 10000 loss: 15.018286228179932\n",
      "MSE train 5.762216744559487 MSE test 12.265876249617378\n",
      "MAE train 1.6611966529062272 MAE test 2.4540155329689535\n",
      "Epoch 2968 / 10000 loss: 15.01754903793335\n",
      "MSE train 5.762057930990466 MSE test 12.265704555521607\n",
      "MAE train 1.6611715224552854 MAE test 2.4539990273878933\n",
      "Epoch 2969 / 10000 loss: 15.017024755477905\n",
      "MSE train 5.761926017005046 MSE test 12.265571342083176\n",
      "MAE train 1.661151246282061 MAE test 2.4539831987331637\n",
      "Epoch 2970 / 10000 loss: 15.016469240188599\n",
      "MSE train 5.761770770184662 MSE test 12.265340857548649\n",
      "MAE train 1.6611281875299737 MAE test 2.453959146228715\n",
      "Epoch 2971 / 10000 loss: 15.015926361083984\n",
      "MSE train 5.761610486540433 MSE test 12.265225660087157\n",
      "MAE train 1.66110095789369 MAE test 2.453945714306116\n",
      "Epoch 2972 / 10000 loss: 15.015428304672241\n",
      "MSE train 5.7614566612202145 MSE test 12.265136411391637\n",
      "MAE train 1.6610748595963234 MAE test 2.4539397406767502\n",
      "Epoch 2973 / 10000 loss: 15.014762878417969\n",
      "MSE train 5.761310233909332 MSE test 12.264879762204757\n",
      "MAE train 1.6610541375987022 MAE test 2.4539080272780143\n",
      "Epoch 2974 / 10000 loss: 15.014172554016113\n",
      "MSE train 5.761164927499591 MSE test 12.264831047083254\n",
      "MAE train 1.6610291229290755 MAE test 2.4539072951957244\n",
      "Epoch 2975 / 10000 loss: 15.01364803314209\n",
      "MSE train 5.761021963959737 MSE test 12.26450752374331\n",
      "MAE train 1.6610109284652594 MAE test 2.45386699770986\n",
      "Epoch 2976 / 10000 loss: 15.013071537017822\n",
      "MSE train 5.760864771585096 MSE test 12.264517207892801\n",
      "MAE train 1.6609816979449032 MAE test 2.453873842468313\n",
      "Epoch 2977 / 10000 loss: 15.012604236602783\n",
      "MSE train 5.760719262872043 MSE test 12.26420550518881\n",
      "MAE train 1.660962614561949 MAE test 2.453835039212989\n",
      "Epoch 2978 / 10000 loss: 15.01194429397583\n",
      "MSE train 5.7605710314228755 MSE test 12.264206427861334\n",
      "MAE train 1.6609356808212363 MAE test 2.4538407236547477\n",
      "Epoch 2979 / 10000 loss: 15.011460065841675\n",
      "MSE train 5.760427694661526 MSE test 12.263858936617405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6609178591884384 MAE test 2.4537973312628534\n",
      "Epoch 2980 / 10000 loss: 15.010839700698853\n",
      "MSE train 5.76026047611253 MSE test 12.263871044801556\n",
      "MAE train 1.6608862749636362 MAE test 2.453804481679277\n",
      "Epoch 2981 / 10000 loss: 15.010390758514404\n",
      "MSE train 5.760113535262249 MSE test 12.263613372834234\n",
      "MAE train 1.66086540606079 MAE test 2.453772606484603\n",
      "Epoch 2982 / 10000 loss: 15.009688377380371\n",
      "MSE train 5.759966704558518 MSE test 12.263556299940877\n",
      "MAE train 1.6608402314793786 MAE test 2.4537707690749317\n",
      "Epoch 2983 / 10000 loss: 15.009162902832031\n",
      "MSE train 5.759822635158108 MSE test 12.263243986785726\n",
      "MAE train 1.6608215066459888 MAE test 2.453731902524804\n",
      "Epoch 2984 / 10000 loss: 15.008584022521973\n",
      "MSE train 5.759672385361393 MSE test 12.26324754433691\n",
      "MAE train 1.6607940475004248 MAE test 2.4537379043585807\n",
      "Epoch 2985 / 10000 loss: 15.008105754852295\n",
      "MSE train 5.759528987915513 MSE test 12.262905439208975\n",
      "MAE train 1.6607761032302606 MAE test 2.4536951830060616\n",
      "Epoch 2986 / 10000 loss: 15.007477283477783\n",
      "MSE train 5.7593643247324655 MSE test 12.262916548772667\n",
      "MAE train 1.6607451140711935 MAE test 2.453702192792772\n",
      "Epoch 2987 / 10000 loss: 15.007023811340332\n",
      "MSE train 5.759216879497626 MSE test 12.262643157512374\n",
      "MAE train 1.6607245434167255 MAE test 2.4536682858841092\n",
      "Epoch 2988 / 10000 loss: 15.006334066390991\n",
      "MSE train 5.759075088445925 MSE test 12.262607181863343\n",
      "MAE train 1.660700061110404 MAE test 2.4536691379776996\n",
      "Epoch 2989 / 10000 loss: 15.005816221237183\n",
      "MSE train 5.7589331034174025 MSE test 12.262254873212632\n",
      "MAE train 1.660682626899656 MAE test 2.4536251139832785\n",
      "Epoch 2990 / 10000 loss: 15.005245208740234\n",
      "MSE train 5.758762895362843 MSE test 12.262267928183908\n",
      "MAE train 1.6606503838705715 MAE test 2.45363237502352\n",
      "Epoch 2991 / 10000 loss: 15.004804611206055\n",
      "MSE train 5.758617609698456 MSE test 12.262026651179205\n",
      "MAE train 1.660629474053985 MAE test 2.4536025603568334\n",
      "Epoch 2992 / 10000 loss: 15.004091739654541\n",
      "MSE train 5.758463763433593 MSE test 12.261940675895508\n",
      "MAE train 1.6606033414230197 MAE test 2.4535969661031505\n",
      "Epoch 2993 / 10000 loss: 15.003562927246094\n",
      "MSE train 5.7583178994410185 MSE test 12.26168693326383\n",
      "MAE train 1.6605826450562593 MAE test 2.453565600913143\n",
      "Epoch 2994 / 10000 loss: 15.002975225448608\n",
      "MSE train 5.758171666853511 MSE test 12.261634912120234\n",
      "MAE train 1.6605575141138271 MAE test 2.4535643806901044\n",
      "Epoch 2995 / 10000 loss: 15.002451658248901\n",
      "MSE train 5.758028530627968 MSE test 12.261315642560618\n",
      "MAE train 1.6605391595119148 MAE test 2.453524592444297\n",
      "Epoch 2996 / 10000 loss: 15.001877069473267\n",
      "MSE train 5.75787410114585 MSE test 12.261322303954667\n",
      "MAE train 1.6605106460422732 MAE test 2.45353096047475\n",
      "Epoch 2997 / 10000 loss: 15.0014066696167\n",
      "MSE train 5.757729555752685 MSE test 12.260995872108602\n",
      "MAE train 1.660492114328476 MAE test 2.453490226235116\n",
      "Epoch 2998 / 10000 loss: 15.000761270523071\n",
      "MSE train 5.757573863158772 MSE test 12.261001610214409\n",
      "MAE train 1.6604632956777683 MAE test 2.4534964658523664\n",
      "Epoch 2999 / 10000 loss: 15.0002920627594\n",
      "MSE train 5.7574282378744535 MSE test 12.260682689371931\n",
      "MAE train 1.660444329796644 MAE test 2.45345668702006\n",
      "Epoch 3000 / 10000 loss: 14.999640226364136\n",
      "MSE train 5.757277571428205 MSE test 12.260683996064518\n",
      "MAE train 1.6604167979082771 MAE test 2.4534623217794858\n",
      "Epoch 3001 / 10000 loss: 14.999161958694458\n",
      "MSE train 5.757133311214978 MSE test 12.260344006680828\n",
      "MAE train 1.6603986021117114 MAE test 2.453419824981643\n",
      "Epoch 3002 / 10000 loss: 14.998533010482788\n",
      "MSE train 5.75697096447693 MSE test 12.26035283017424\n",
      "MAE train 1.6603681960309102 MAE test 2.4534264629781877\n",
      "Epoch 3003 / 10000 loss: 14.998075485229492\n",
      "MSE train 5.756823458852617 MSE test 12.260066122023408\n",
      "MAE train 1.6603479273354151 MAE test 2.453390798303357\n",
      "Epoch 3004 / 10000 loss: 14.997395992279053\n",
      "MSE train 5.756682966680812 MSE test 12.260042392631767\n",
      "MAE train 1.6603234444425217 MAE test 2.453393160522386\n",
      "Epoch 3005 / 10000 loss: 14.996886968612671\n",
      "MSE train 5.756540935945492 MSE test 12.259673894580343\n",
      "MAE train 1.6603063072251405 MAE test 2.4533470133460242\n",
      "Epoch 3006 / 10000 loss: 14.996313333511353\n",
      "MSE train 5.7563661967478215 MSE test 12.25968626038307\n",
      "MAE train 1.660273046573243 MAE test 2.4533541072760836\n",
      "Epoch 3007 / 10000 loss: 14.995887279510498\n",
      "MSE train 5.756228838406499 MSE test 12.259479524634846\n",
      "MAE train 1.660253188446967 MAE test 2.453328675468354\n",
      "Epoch 3008 / 10000 loss: 14.995157241821289\n",
      "MSE train 5.756069549221019 MSE test 12.259318076686354\n",
      "MAE train 1.660227632074637 MAE test 2.4533133274119456\n",
      "Epoch 3009 / 10000 loss: 14.994635105133057\n",
      "MSE train 5.7559410618712255 MSE test 12.259172013166944\n",
      "MAE train 1.6602084465989515 MAE test 2.453295739340667\n",
      "Epoch 3010 / 10000 loss: 14.994072914123535\n",
      "MSE train 5.755786520919572 MSE test 12.258930342480605\n",
      "MAE train 1.660185762589915 MAE test 2.453270102710091\n",
      "Epoch 3011 / 10000 loss: 14.993554592132568\n",
      "MSE train 5.755623808806666 MSE test 12.258812784101156\n",
      "MAE train 1.6601579963692137 MAE test 2.4532562666979407\n",
      "Epoch 3012 / 10000 loss: 14.993069410324097\n",
      "MSE train 5.755475560543268 MSE test 12.258741195333263\n",
      "MAE train 1.6601327723746484 MAE test 2.453252385806669\n",
      "Epoch 3013 / 10000 loss: 14.992398500442505\n",
      "MSE train 5.7553293335522415 MSE test 12.258436761097833\n",
      "MAE train 1.660113284571346 MAE test 2.4532144104133855\n",
      "Epoch 3014 / 10000 loss: 14.99181842803955\n",
      "MSE train 5.755185010839666 MSE test 12.258429486418997\n",
      "MAE train 1.6600874583416458 MAE test 2.453218863434823\n",
      "Epoch 3015 / 10000 loss: 14.991327285766602\n",
      "MSE train 5.755042347417323 MSE test 12.258065284779173\n",
      "MAE train 1.6600700699653916 MAE test 2.4531732215614688\n",
      "Epoch 3016 / 10000 loss: 14.990729331970215\n",
      "MSE train 5.754869258134148 MSE test 12.258076748369083\n",
      "MAE train 1.660037176345353 MAE test 2.4531801532691433\n",
      "Epoch 3017 / 10000 loss: 14.990295886993408\n",
      "MSE train 5.75472821337378 MSE test 12.257855232084935\n",
      "MAE train 1.6600167479828363 MAE test 2.453152757000519\n",
      "Epoch 3018 / 10000 loss: 14.98957347869873\n",
      "MSE train 5.754568842774606 MSE test 12.257723016855689\n",
      "MAE train 1.6599904025836738 MAE test 2.453141103532312\n",
      "Epoch 3019 / 10000 loss: 14.989046335220337\n",
      "MSE train 5.75443666757201 MSE test 12.25754383391346\n",
      "MAE train 1.659971113012832 MAE test 2.453119208171763\n",
      "Epoch 3020 / 10000 loss: 14.98846435546875\n",
      "MSE train 5.754281137746045 MSE test 12.257341726101197\n",
      "MAE train 1.6599474350958452 MAE test 2.453098584747274\n",
      "Epoch 3021 / 10000 loss: 14.987953901290894\n",
      "MSE train 5.754133674075505 MSE test 12.25721987441976\n",
      "MAE train 1.659923174008742 MAE test 2.453084103546856\n",
      "Epoch 3022 / 10000 loss: 14.987433433532715\n",
      "MSE train 5.753974391400975 MSE test 12.257048406163614\n",
      "MAE train 1.6598978496592103 MAE test 2.4530673907905127\n",
      "Epoch 3023 / 10000 loss: 14.98682427406311\n",
      "MSE train 5.7538441887911 MSE test 12.256907272224511\n",
      "MAE train 1.659878079214988 MAE test 2.453050362746767\n",
      "Epoch 3024 / 10000 loss: 14.986269235610962\n",
      "MSE train 5.753689047507713 MSE test 12.256668214678541\n",
      "MAE train 1.6598551782839612 MAE test 2.453024988023075\n",
      "Epoch 3025 / 10000 loss: 14.98573899269104\n",
      "MSE train 5.753527399032386 MSE test 12.256549497207518\n",
      "MAE train 1.659827628095786 MAE test 2.4530109176339794\n",
      "Epoch 3026 / 10000 loss: 14.985249280929565\n",
      "MSE train 5.753376353712965 MSE test 12.256467541195253\n",
      "MAE train 1.6598019698338329 MAE test 2.453005630375795\n",
      "Epoch 3027 / 10000 loss: 14.984583377838135\n",
      "MSE train 5.753229473536787 MSE test 12.256182818808265\n",
      "MAE train 1.6597817696525725 MAE test 2.452970127008797\n",
      "Epoch 3028 / 10000 loss: 14.983999252319336\n",
      "MSE train 5.753088848965485 MSE test 12.25615831728298\n",
      "MAE train 1.659757254055645 MAE test 2.452972265773088\n",
      "Epoch 3029 / 10000 loss: 14.983491659164429\n",
      "MSE train 5.752947023877702 MSE test 12.25578830319923\n",
      "MAE train 1.6597401482477645 MAE test 2.452925826767448\n",
      "Epoch 3030 / 10000 loss: 14.982919216156006\n",
      "MSE train 5.752772093481429 MSE test 12.255799480105201\n",
      "MAE train 1.6597068338675025 MAE test 2.452932622386115\n",
      "Epoch 3031 / 10000 loss: 14.982492923736572\n",
      "MSE train 5.7526350308972605 MSE test 12.2555924209842\n",
      "MAE train 1.6596870008396798 MAE test 2.4529070246811027\n",
      "Epoch 3032 / 10000 loss: 14.981764078140259\n",
      "MSE train 5.752475775947546 MSE test 12.255427055364292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6596615058002302 MAE test 2.4528910383918645\n",
      "Epoch 3033 / 10000 loss: 14.981242418289185\n",
      "MSE train 5.752346857149101 MSE test 12.25528125869516\n",
      "MAE train 1.659642153719538 MAE test 2.452873350939635\n",
      "Epoch 3034 / 10000 loss: 14.980682373046875\n",
      "MSE train 5.752192079913524 MSE test 12.255038599262033\n",
      "MAE train 1.659619387558541 MAE test 2.4528474520954746\n",
      "Epoch 3035 / 10000 loss: 14.980160474777222\n",
      "MSE train 5.752029471120124 MSE test 12.254919341946618\n",
      "MAE train 1.6595916267755395 MAE test 2.4528332415582903\n",
      "Epoch 3036 / 10000 loss: 14.97967529296875\n",
      "MSE train 5.751880798043671 MSE test 12.254844945457126\n",
      "MAE train 1.659566329207715 MAE test 2.4528288684558968\n",
      "Epoch 3037 / 10000 loss: 14.979005336761475\n",
      "MSE train 5.751734372710699 MSE test 12.254541788865387\n",
      "MAE train 1.6595466932406802 MAE test 2.452790907112009\n",
      "Epoch 3038 / 10000 loss: 14.978424310684204\n",
      "MSE train 5.751590958343823 MSE test 12.254531131504844\n",
      "MAE train 1.6595211221421882 MAE test 2.452794777712321\n",
      "Epoch 3039 / 10000 loss: 14.977931499481201\n",
      "MSE train 5.751448317508086 MSE test 12.254162427168284\n",
      "MAE train 1.6595037818886689 MAE test 2.452748413154577\n",
      "Epoch 3040 / 10000 loss: 14.977337837219238\n",
      "MSE train 5.7512743917722196 MSE test 12.254172258057691\n",
      "MAE train 1.6594706724514685 MAE test 2.452754966737218\n",
      "Epoch 3041 / 10000 loss: 14.976907730102539\n",
      "MSE train 5.751135044498737 MSE test 12.253956514980562\n",
      "MAE train 1.659450461097981 MAE test 2.4527281762679154\n",
      "Epoch 3042 / 10000 loss: 14.976181745529175\n",
      "MSE train 5.750975408672784 MSE test 12.253807177698086\n",
      "MAE train 1.6594244309801283 MAE test 2.4527141681247397\n",
      "Epoch 3043 / 10000 loss: 14.975656747817993\n",
      "MSE train 5.75084690006388 MSE test 12.253645001936274\n",
      "MAE train 1.6594055609581855 MAE test 2.4526942766940856\n",
      "Epoch 3044 / 10000 loss: 14.975085258483887\n",
      "MSE train 5.750692413568149 MSE test 12.253410266007085\n",
      "MAE train 1.6593826924299009 MAE test 2.452669321455129\n",
      "Epoch 3045 / 10000 loss: 14.97457480430603\n",
      "MSE train 5.750531693886229 MSE test 12.25329077414636\n",
      "MAE train 1.6593553072595995 MAE test 2.452654986514418\n",
      "Epoch 3046 / 10000 loss: 14.974082708358765\n",
      "MSE train 5.750377898470697 MSE test 12.25319744500927\n",
      "MAE train 1.6593292106601003 MAE test 2.452648091167339\n",
      "Epoch 3047 / 10000 loss: 14.973419427871704\n",
      "MSE train 5.7502310779638695 MSE test 12.25293387232608\n",
      "MAE train 1.6593084211021785 MAE test 2.4526151320089973\n",
      "Epoch 3048 / 10000 loss: 14.972832202911377\n",
      "MSE train 5.750086050280138 MSE test 12.252881898648313\n",
      "MAE train 1.6592834468793651 MAE test 2.4526135881090116\n",
      "Epoch 3049 / 10000 loss: 14.972310066223145\n",
      "MSE train 5.749942841961571 MSE test 12.252548967598456\n",
      "MAE train 1.6592652756674837 MAE test 2.4525717025239766\n",
      "Epoch 3050 / 10000 loss: 14.971736669540405\n",
      "MSE train 5.74978336969309 MSE test 12.252554620555435\n",
      "MAE train 1.6592355026890444 MAE test 2.4525776045279915\n",
      "Epoch 3051 / 10000 loss: 14.971275568008423\n",
      "MSE train 5.74963670020255 MSE test 12.252247545472407\n",
      "MAE train 1.6592158610017693 MAE test 2.452538979848105\n",
      "Epoch 3052 / 10000 loss: 14.970608949661255\n",
      "MSE train 5.74949264641082 MSE test 12.252236459092058\n",
      "MAE train 1.6591900928928276 MAE test 2.452542669656209\n",
      "Epoch 3053 / 10000 loss: 14.97011661529541\n",
      "MSE train 5.749349625862247 MSE test 12.251868314606707\n",
      "MAE train 1.6591726181392321 MAE test 2.4524962266886123\n",
      "Epoch 3054 / 10000 loss: 14.969518423080444\n",
      "MSE train 5.7491762397209225 MSE test 12.251876904836106\n",
      "MAE train 1.6591396097159519 MAE test 2.452502487455551\n",
      "Epoch 3055 / 10000 loss: 14.969085693359375\n",
      "MSE train 5.749035384573754 MSE test 12.251654447064343\n",
      "MAE train 1.6591191476007439 MAE test 2.452474653666506\n",
      "Epoch 3056 / 10000 loss: 14.968361616134644\n",
      "MSE train 5.748875676508035 MSE test 12.25151492323225\n",
      "MAE train 1.6590928018247744 MAE test 2.4524617633087833\n",
      "Epoch 3057 / 10000 loss: 14.967833280563354\n",
      "MSE train 5.748744531740054 MSE test 12.251338216963124\n",
      "MAE train 1.659073599230879 MAE test 2.452439832309121\n",
      "Epoch 3058 / 10000 loss: 14.9672532081604\n",
      "MSE train 5.748589220832153 MSE test 12.25112262939665\n",
      "MAE train 1.6590501389523955 MAE test 2.4524171495172666\n",
      "Epoch 3059 / 10000 loss: 14.966741800308228\n",
      "MSE train 5.748436317993278 MSE test 12.250999874330178\n",
      "MAE train 1.6590245238784078 MAE test 2.452402212137753\n",
      "Epoch 3060 / 10000 loss: 14.966230392456055\n",
      "MSE train 5.7482758567458605 MSE test 12.250852214209583\n",
      "MAE train 1.6589981674955439 MAE test 2.4523881779026535\n",
      "Epoch 3061 / 10000 loss: 14.96559762954712\n",
      "MSE train 5.748145987911732 MSE test 12.2506798150239\n",
      "MAE train 1.6589791462777368 MAE test 2.452366746815835\n",
      "Epoch 3062 / 10000 loss: 14.965018510818481\n",
      "MSE train 5.747990679154078 MSE test 12.250453761441277\n",
      "MAE train 1.6589558696003834 MAE test 2.452342652553563\n",
      "Epoch 3063 / 10000 loss: 14.964507102966309\n",
      "MSE train 5.747833540874856 MSE test 12.25033126778147\n",
      "MAE train 1.6589292888455274 MAE test 2.4523276830992873\n",
      "Epoch 3064 / 10000 loss: 14.964002847671509\n",
      "MSE train 5.747674420258218 MSE test 12.250208087076846\n",
      "MAE train 1.6589025597191633 MAE test 2.452316707249221\n",
      "Epoch 3065 / 10000 loss: 14.963353157043457\n",
      "MSE train 5.747534872364735 MSE test 12.249996697922573\n",
      "MAE train 1.658882160723439 MAE test 2.452290172102234\n",
      "Epoch 3066 / 10000 loss: 14.962762594223022\n",
      "MSE train 5.747375567569376 MSE test 12.249845334568564\n",
      "MAE train 1.6588561876194192 MAE test 2.452275587924916\n",
      "Epoch 3067 / 10000 loss: 14.96223759651184\n",
      "MSE train 5.747246664623845 MSE test 12.249683942932403\n",
      "MAE train 1.6588371330328286 MAE test 2.4522554807507584\n",
      "Epoch 3068 / 10000 loss: 14.961663722991943\n",
      "MSE train 5.747091939909603 MSE test 12.249443045897635\n",
      "MAE train 1.6588142582270506 MAE test 2.4522293994671003\n",
      "Epoch 3069 / 10000 loss: 14.961150646209717\n",
      "MSE train 5.746929553097245 MSE test 12.249320665171224\n",
      "MAE train 1.6587864688446712 MAE test 2.452214312778987\n",
      "Epoch 3070 / 10000 loss: 14.960659265518188\n",
      "MSE train 5.746777460079711 MSE test 12.249233289881783\n",
      "MAE train 1.658760543505288 MAE test 2.452207810788883\n",
      "Epoch 3071 / 10000 loss: 14.959988594055176\n",
      "MSE train 5.7466297267050255 MSE test 12.24894681949394\n",
      "MAE train 1.6587400153351315 MAE test 2.4521714960329994\n",
      "Epoch 3072 / 10000 loss: 14.959399223327637\n",
      "MSE train 5.74648824876584 MSE test 12.248914489018896\n",
      "MAE train 1.658715335163964 MAE test 2.4521720732473966\n",
      "Epoch 3073 / 10000 loss: 14.958885908126831\n",
      "MSE train 5.746345354685171 MSE test 12.248541632513872\n",
      "MAE train 1.6586979067414769 MAE test 2.4521246605383724\n",
      "Epoch 3074 / 10000 loss: 14.958309888839722\n",
      "MSE train 5.746170174091999 MSE test 12.248547797256663\n",
      "MAE train 1.6586644638916903 MAE test 2.4521301830688187\n",
      "Epoch 3075 / 10000 loss: 14.957877159118652\n",
      "MSE train 5.746030398679834 MSE test 12.248329444401968\n",
      "MAE train 1.6586440630450334 MAE test 2.452102473676131\n",
      "Epoch 3076 / 10000 loss: 14.957144021987915\n",
      "MSE train 5.745869693057836 MSE test 12.248170783879505\n",
      "MAE train 1.6586178811361059 MAE test 2.452086644039514\n",
      "Epoch 3077 / 10000 loss: 14.956615209579468\n",
      "MSE train 5.745740292717195 MSE test 12.248008020443464\n",
      "MAE train 1.6585986605700158 MAE test 2.4520660875533395\n",
      "Epoch 3078 / 10000 loss: 14.956039190292358\n",
      "MSE train 5.7455845305434 MSE test 12.247763092559389\n",
      "MAE train 1.6585755778063107 MAE test 2.452039178000305\n",
      "Epoch 3079 / 10000 loss: 14.95552134513855\n",
      "MSE train 5.745421245613471 MSE test 12.247637850712291\n",
      "MAE train 1.6585475547085153 MAE test 2.4520234096023423\n",
      "Epoch 3080 / 10000 loss: 14.955026149749756\n",
      "MSE train 5.7452688287822795 MSE test 12.247549369048611\n",
      "MAE train 1.6585215176836114 MAE test 2.4520164444934722\n",
      "Epoch 3081 / 10000 loss: 14.954349756240845\n",
      "MSE train 5.7451201150825115 MSE test 12.247256230483435\n",
      "MAE train 1.6585008608356657 MAE test 2.4519789329691464\n",
      "Epoch 3082 / 10000 loss: 14.953758478164673\n",
      "MSE train 5.744977746318561 MSE test 12.247224624927881\n",
      "MAE train 1.6584758817274654 MAE test 2.4519792602447295\n",
      "Epoch 3083 / 10000 loss: 14.953242778778076\n",
      "MSE train 5.7448336573531185 MSE test 12.246845682597996\n",
      "MAE train 1.658458235493468 MAE test 2.4519307019536316\n",
      "Epoch 3084 / 10000 loss: 14.952659368515015\n",
      "MSE train 5.744656663256575 MSE test 12.246848448793312\n",
      "MAE train 1.6584243822002775 MAE test 2.4519354096565253\n",
      "Epoch 3085 / 10000 loss: 14.952222347259521\n",
      "MSE train 5.744517379514767 MSE test 12.246633360174243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6584039701526623 MAE test 2.4519077263985873\n",
      "Epoch 3086 / 10000 loss: 14.951481580734253\n",
      "MSE train 5.744355611845083 MSE test 12.246456966248488\n",
      "MAE train 1.6583779144780153 MAE test 2.4518892082557073\n",
      "Epoch 3087 / 10000 loss: 14.950947761535645\n",
      "MSE train 5.744223612774313 MSE test 12.24630304405512\n",
      "MAE train 1.65835775625021 MAE test 2.4518693516540675\n",
      "Epoch 3088 / 10000 loss: 14.9503755569458\n",
      "MSE train 5.744065590103484 MSE test 12.246050811345164\n",
      "MAE train 1.658334247025884 MAE test 2.451841052712693\n",
      "Epoch 3089 / 10000 loss: 14.949837446212769\n",
      "MSE train 5.743900106390425 MSE test 12.245921284971589\n",
      "MAE train 1.6583057444464637 MAE test 2.4518242635308796\n",
      "Epoch 3090 / 10000 loss: 14.94933557510376\n",
      "MSE train 5.743747434585 MSE test 12.245833978047031\n",
      "MAE train 1.658279561859459 MAE test 2.4518169526690046\n",
      "Epoch 3091 / 10000 loss: 14.948648691177368\n",
      "MSE train 5.743596932728316 MSE test 12.245524204506644\n",
      "MAE train 1.6582588300614018 MAE test 2.4517767909128914\n",
      "Epoch 3092 / 10000 loss: 14.948049545288086\n",
      "MSE train 5.7434508375760025 MSE test 12.245498593010886\n",
      "MAE train 1.6582327380565665 MAE test 2.4517773425815252\n",
      "Epoch 3093 / 10000 loss: 14.947533369064331\n",
      "MSE train 5.743303849090253 MSE test 12.245114830506223\n",
      "MAE train 1.6582144442238818 MAE test 2.451727586697321\n",
      "Epoch 3094 / 10000 loss: 14.94692587852478\n",
      "MSE train 5.743124518597734 MSE test 12.24511234305139\n",
      "MAE train 1.65818008681416 MAE test 2.451731003871772\n",
      "Epoch 3095 / 10000 loss: 14.946476697921753\n",
      "MSE train 5.742982260068923 MSE test 12.244891101980977\n",
      "MAE train 1.6581590361890663 MAE test 2.4517019173016776\n",
      "Epoch 3096 / 10000 loss: 14.945723295211792\n",
      "MSE train 5.742817411822868 MSE test 12.244712191166013\n",
      "MAE train 1.6581322488960069 MAE test 2.4516824455260418\n",
      "Epoch 3097 / 10000 loss: 14.945176124572754\n",
      "MSE train 5.742682757232463 MSE test 12.244551137478567\n",
      "MAE train 1.6581115955621408 MAE test 2.451660996707605\n",
      "Epoch 3098 / 10000 loss: 14.94458794593811\n",
      "MSE train 5.742521580744082 MSE test 12.244293276726015\n",
      "MAE train 1.6580873977775306 MAE test 2.4516312747456928\n",
      "Epoch 3099 / 10000 loss: 14.944037437438965\n",
      "MSE train 5.742352484635086 MSE test 12.244158821741227\n",
      "MAE train 1.6580581163113046 MAE test 2.4516131440070095\n",
      "Epoch 3100 / 10000 loss: 14.943519353866577\n",
      "MSE train 5.7421967550401956 MSE test 12.244068141006627\n",
      "MAE train 1.65803122159276 MAE test 2.451604678100062\n",
      "Epoch 3101 / 10000 loss: 14.942816019058228\n",
      "MSE train 5.74204268219065 MSE test 12.24374986658588\n",
      "MAE train 1.6580098147482638 MAE test 2.4515627124348605\n",
      "Epoch 3102 / 10000 loss: 14.942200183868408\n",
      "MSE train 5.7418919065914364 MSE test 12.243722280508866\n",
      "MAE train 1.657982612592705 MAE test 2.4515623085633043\n",
      "Epoch 3103 / 10000 loss: 14.941668033599854\n",
      "MSE train 5.741740942834116 MSE test 12.243336484589543\n",
      "MAE train 1.6579633853327684 MAE test 2.4515115995737538\n",
      "Epoch 3104 / 10000 loss: 14.941037654876709\n",
      "MSE train 5.741558613270369 MSE test 12.243330074498784\n",
      "MAE train 1.6579284031104202 MAE test 2.451513854667091\n",
      "Epoch 3105 / 10000 loss: 14.940565586090088\n",
      "MSE train 5.741410999841853 MSE test 12.243099395290718\n",
      "MAE train 1.6579062943766183 MAE test 2.451482927522463\n",
      "Epoch 3106 / 10000 loss: 14.939797163009644\n",
      "MSE train 5.741242503430955 MSE test 12.242931171529676\n",
      "MAE train 1.657878328913459 MAE test 2.4514642587488327\n",
      "Epoch 3107 / 10000 loss: 14.939228773117065\n",
      "MSE train 5.7411053722136325 MSE test 12.242756243784228\n",
      "MAE train 1.6578574622041382 MAE test 2.4514405474431964\n",
      "Epoch 3108 / 10000 loss: 14.938614130020142\n",
      "MSE train 5.740941805164688 MSE test 12.242503348893521\n",
      "MAE train 1.6578326499770817 MAE test 2.451411087899396\n",
      "Epoch 3109 / 10000 loss: 14.938056707382202\n",
      "MSE train 5.740771645120678 MSE test 12.242369722913184\n",
      "MAE train 1.6578032064218085 MAE test 2.451392783856711\n",
      "Epoch 3110 / 10000 loss: 14.937521696090698\n",
      "MSE train 5.7406109429928085 MSE test 12.242269397933034\n",
      "MAE train 1.657775479036587 MAE test 2.451382927962585\n",
      "Epoch 3111 / 10000 loss: 14.936810731887817\n",
      "MSE train 5.740455384368184 MSE test 12.241979311227103\n",
      "MAE train 1.657753154662763 MAE test 2.45134455755188\n",
      "Epoch 3112 / 10000 loss: 14.936180830001831\n",
      "MSE train 5.740306090059537 MSE test 12.241933221314275\n",
      "MAE train 1.6577269810660349 MAE test 2.451341866931238\n",
      "Epoch 3113 / 10000 loss: 14.93562388420105\n",
      "MSE train 5.740156190814507 MSE test 12.241561089902545\n",
      "MAE train 1.6577078849958078 MAE test 2.4512931972865433\n",
      "Epoch 3114 / 10000 loss: 14.935011625289917\n",
      "MSE train 5.739976707595008 MSE test 12.241562161809831\n",
      "MAE train 1.6576736030039048 MAE test 2.4512968134546567\n",
      "Epoch 3115 / 10000 loss: 14.934536457061768\n",
      "MSE train 5.739827084624342 MSE test 12.241324348707922\n",
      "MAE train 1.6576513909352242 MAE test 2.451265527552522\n",
      "Epoch 3116 / 10000 loss: 14.933778762817383\n",
      "MSE train 5.739662326443236 MSE test 12.241198587853702\n",
      "MAE train 1.6576234532404854 MAE test 2.4512529974819555\n",
      "Epoch 3117 / 10000 loss: 14.933213233947754\n",
      "MSE train 5.739518145622926 MSE test 12.240989742093738\n",
      "MAE train 1.657601984894727 MAE test 2.4512257047387314\n",
      "Epoch 3118 / 10000 loss: 14.932592630386353\n",
      "MSE train 5.73935409960139 MSE test 12.240828815425619\n",
      "MAE train 1.6575752314708405 MAE test 2.4512089093693166\n",
      "Epoch 3119 / 10000 loss: 14.932038307189941\n",
      "MSE train 5.739220516747907 MSE test 12.240675503725386\n",
      "MAE train 1.6575550339866834 MAE test 2.451188978913091\n",
      "Epoch 3120 / 10000 loss: 14.931445598602295\n",
      "MSE train 5.739061392563597 MSE test 12.240428778748006\n",
      "MAE train 1.657531383661203 MAE test 2.4511614299725304\n",
      "Epoch 3121 / 10000 loss: 14.930901765823364\n",
      "MSE train 5.738893922047857 MSE test 12.240308048184653\n",
      "MAE train 1.6575026075206416 MAE test 2.451145932732084\n",
      "Epoch 3122 / 10000 loss: 14.930393934249878\n",
      "MSE train 5.73874203416139 MSE test 12.24023583662487\n",
      "MAE train 1.6574766010353836 MAE test 2.4511408571394506\n",
      "Epoch 3123 / 10000 loss: 14.92969799041748\n",
      "MSE train 5.738591709312669 MSE test 12.239924970381693\n",
      "MAE train 1.6574563576205588 MAE test 2.4511010232674875\n",
      "Epoch 3124 / 10000 loss: 14.929097652435303\n",
      "MSE train 5.738442212902403 MSE test 12.23991864088703\n",
      "MAE train 1.6574294045693287 MAE test 2.451104652405016\n",
      "Epoch 3125 / 10000 loss: 14.928589344024658\n",
      "MSE train 5.738295045796387 MSE test 12.239558439005771\n",
      "MAE train 1.6574109702667748 MAE test 2.4510586648724066\n",
      "Epoch 3126 / 10000 loss: 14.927964448928833\n",
      "MSE train 5.738120647518935 MSE test 12.239568943001782\n",
      "MAE train 1.657377890165425 MAE test 2.4510645963495183\n",
      "Epoch 3127 / 10000 loss: 14.927509069442749\n",
      "MSE train 5.7379729477980215 MSE test 12.239333015198348\n",
      "MAE train 1.657356340233163 MAE test 2.4510346059920898\n",
      "Epoch 3128 / 10000 loss: 14.926778316497803\n",
      "MSE train 5.7378129961069835 MSE test 12.239230628276257\n",
      "MAE train 1.657329241607197 MAE test 2.451026084764216\n",
      "Epoch 3129 / 10000 loss: 14.92623257637024\n",
      "MSE train 5.737666253167216 MSE test 12.239004491596573\n",
      "MAE train 1.6573077854968778 MAE test 2.450997505789103\n",
      "Epoch 3130 / 10000 loss: 14.925629615783691\n",
      "MSE train 5.737506133378273 MSE test 12.23890257819551\n",
      "MAE train 1.6572806855229398 MAE test 2.4509891470531455\n",
      "Epoch 3131 / 10000 loss: 14.925088882446289\n",
      "MSE train 5.737360304664948 MSE test 12.238684213127819\n",
      "MAE train 1.657259323607994 MAE test 2.450961646944303\n",
      "Epoch 3132 / 10000 loss: 14.924486637115479\n",
      "MSE train 5.737198929340345 MSE test 12.238572046036177\n",
      "MAE train 1.6572322000705422 MAE test 2.4509520670863347\n",
      "Epoch 3133 / 10000 loss: 14.923945426940918\n",
      "MSE train 5.73705691378585 MSE test 12.238374075933962\n",
      "MAE train 1.6572113140686249 MAE test 2.4509272622506737\n",
      "Epoch 3134 / 10000 loss: 14.92334508895874\n",
      "MSE train 5.736894748228995 MSE test 12.238220635633699\n",
      "MAE train 1.6571851350937734 MAE test 2.4509124467743217\n",
      "Epoch 3135 / 10000 loss: 14.922810316085815\n",
      "MSE train 5.736761839829329 MSE test 12.238075777681743\n",
      "MAE train 1.6571651816100914 MAE test 2.4508945770046466\n",
      "Epoch 3136 / 10000 loss: 14.922232627868652\n",
      "MSE train 5.73660276566533 MSE test 12.237834068179554\n",
      "MAE train 1.6571417233813572 MAE test 2.450868554987497\n",
      "Epoch 3137 / 10000 loss: 14.921701669692993\n",
      "MSE train 5.736434115348236 MSE test 12.237718492535922\n",
      "MAE train 1.6571128349022977 MAE test 2.4508545304613456\n",
      "Epoch 3138 / 10000 loss: 14.921202659606934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.736280638237601 MSE test 12.237651696330868\n",
      "MAE train 1.6570866112892662 MAE test 2.450850904328718\n",
      "Epoch 3139 / 10000 loss: 14.920510053634644\n",
      "MSE train 5.7361269094553835 MSE test 12.237341309029025\n",
      "MAE train 1.6570659090981257 MAE test 2.450811853775194\n",
      "Epoch 3140 / 10000 loss: 14.919910907745361\n",
      "MSE train 5.7359712197069195 MSE test 12.237339375761652\n",
      "MAE train 1.6570377381449197 MAE test 2.4508166933454953\n",
      "Epoch 3141 / 10000 loss: 14.919400691986084\n",
      "MSE train 5.735816467189235 MSE test 12.236985388089247\n",
      "MAE train 1.6570178876606594 MAE test 2.4507721360369374\n",
      "Epoch 3142 / 10000 loss: 14.91875696182251\n",
      "MSE train 5.73563401401672 MSE test 12.236996590749776\n",
      "MAE train 1.6569833802970706 MAE test 2.450778743150547\n",
      "Epoch 3143 / 10000 loss: 14.918275356292725\n",
      "MSE train 5.735470357888573 MSE test 12.236749285135003\n",
      "MAE train 1.6569590521648108 MAE test 2.4507478550489634\n",
      "Epoch 3144 / 10000 loss: 14.91751742362976\n",
      "MSE train 5.735294965506617 MSE test 12.23666937946643\n",
      "MAE train 1.6569286825360297 MAE test 2.450742734960688\n",
      "Epoch 3145 / 10000 loss: 14.916924476623535\n",
      "MSE train 5.7351159977290225 MSE test 12.236397467151505\n",
      "MAE train 1.6569019652119013 MAE test 2.4507088164776367\n",
      "Epoch 3146 / 10000 loss: 14.916250228881836\n",
      "MSE train 5.734927152186147 MSE test 12.236363776513299\n",
      "MAE train 1.6568681254866238 MAE test 2.450709730753963\n",
      "Epoch 3147 / 10000 loss: 14.915607929229736\n",
      "MSE train 5.7347118403313475 MSE test 12.23600306141008\n",
      "MAE train 1.6568361143491384 MAE test 2.4506645271495073\n",
      "Epoch 3148 / 10000 loss: 14.91484546661377\n",
      "MSE train 5.734421113504553 MSE test 12.236011672826377\n",
      "MAE train 1.6567794232564315 MAE test 2.450670982662661\n",
      "Epoch 3149 / 10000 loss: 14.914104461669922\n",
      "MSE train 5.734088317923379 MSE test 12.235775146164972\n",
      "MAE train 1.6567197350158334 MAE test 2.4506417628713746\n",
      "Epoch 3150 / 10000 loss: 14.912875413894653\n",
      "MSE train 5.733693005948675 MSE test 12.235654493303107\n",
      "MAE train 1.6566444352769696 MAE test 2.450631688890128\n",
      "Epoch 3151 / 10000 loss: 14.911514282226562\n",
      "MSE train 5.733390747914835 MSE test 12.235435794814954\n",
      "MAE train 1.6565912668644291 MAE test 2.45060486597905\n",
      "Epoch 3152 / 10000 loss: 14.909858703613281\n",
      "MSE train 5.733170699673641 MSE test 12.235293859890582\n",
      "MAE train 1.6565535109224343 MAE test 2.4505920235250813\n",
      "Epoch 3153 / 10000 loss: 14.908595323562622\n",
      "MSE train 5.733015809405001 MSE test 12.23512284723552\n",
      "MAE train 1.6565301127416794 MAE test 2.4505712612491277\n",
      "Epoch 3154 / 10000 loss: 14.907740116119385\n",
      "MSE train 5.73284893570396 MSE test 12.234901441188757\n",
      "MAE train 1.6565048446717345 MAE test 2.450548254649597\n",
      "Epoch 3155 / 10000 loss: 14.90711784362793\n",
      "MSE train 5.732685919091662 MSE test 12.234783102469512\n",
      "MAE train 1.6564773664667276 MAE test 2.4505343085726587\n",
      "Epoch 3156 / 10000 loss: 14.906556606292725\n",
      "MSE train 5.732522752580797 MSE test 12.234659176388252\n",
      "MAE train 1.6564500708265042 MAE test 2.450523754881985\n",
      "Epoch 3157 / 10000 loss: 14.905878067016602\n",
      "MSE train 5.732383195277405 MSE test 12.234461228260868\n",
      "MAE train 1.6564296803464722 MAE test 2.450499560574327\n",
      "Epoch 3158 / 10000 loss: 14.905271530151367\n",
      "MSE train 5.732223465740131 MSE test 12.234297509548043\n",
      "MAE train 1.6564041803437222 MAE test 2.45048396531327\n",
      "Epoch 3159 / 10000 loss: 14.904738187789917\n",
      "MSE train 5.732092965625747 MSE test 12.234158218668751\n",
      "MAE train 1.6563844320447378 MAE test 2.450467378807011\n",
      "Epoch 3160 / 10000 loss: 14.904174089431763\n",
      "MSE train 5.7319376964956135 MSE test 12.233917992808912\n",
      "MAE train 1.6563615808330598 MAE test 2.4504420494353547\n",
      "Epoch 3161 / 10000 loss: 14.903643608093262\n",
      "MSE train 5.731775130479503 MSE test 12.233802466588928\n",
      "MAE train 1.6563338009814423 MAE test 2.450428515564289\n",
      "Epoch 3162 / 10000 loss: 14.903155326843262\n",
      "MSE train 5.731626402235304 MSE test 12.23373053702198\n",
      "MAE train 1.65630848102057 MAE test 2.450424667544936\n",
      "Epoch 3163 / 10000 loss: 14.902484893798828\n",
      "MSE train 5.731479666298325 MSE test 12.23343262369513\n",
      "MAE train 1.6562887143141956 MAE test 2.4503876827990445\n",
      "Epoch 3164 / 10000 loss: 14.901904821395874\n",
      "MSE train 5.731337274284913 MSE test 12.233424549120715\n",
      "MAE train 1.6562633787360321 MAE test 2.4503921445250634\n",
      "Epoch 3165 / 10000 loss: 14.901410818099976\n",
      "MSE train 5.731194298736009 MSE test 12.233058460128204\n",
      "MAE train 1.6562459689408142 MAE test 2.4503464982351493\n",
      "Epoch 3166 / 10000 loss: 14.900822162628174\n",
      "MSE train 5.731020672948247 MSE test 12.233072849462348\n",
      "MAE train 1.6562128781977932 MAE test 2.4503538383284775\n",
      "Epoch 3167 / 10000 loss: 14.900394916534424\n",
      "MSE train 5.730882023522265 MSE test 12.232864203866974\n",
      "MAE train 1.6561927479886522 MAE test 2.450328303269726\n",
      "Epoch 3168 / 10000 loss: 14.89967131614685\n",
      "MSE train 5.730722366984087 MSE test 12.2327138899943\n",
      "MAE train 1.6561668164178454 MAE test 2.4503144840770466\n",
      "Epoch 3169 / 10000 loss: 14.899149656295776\n",
      "MSE train 5.730594137382688 MSE test 12.232562284524327\n",
      "MAE train 1.6561478811447816 MAE test 2.4502963362566956\n",
      "Epoch 3170 / 10000 loss: 14.898584127426147\n",
      "MSE train 5.730438990590594 MSE test 12.232326923357816\n",
      "MAE train 1.6561249660939166 MAE test 2.450271703134142\n",
      "Epoch 3171 / 10000 loss: 14.898075103759766\n",
      "MSE train 5.730276786476909 MSE test 12.232212965097466\n",
      "MAE train 1.6560972548576347 MAE test 2.450258425162062\n",
      "Epoch 3172 / 10000 loss: 14.897589206695557\n",
      "MSE train 5.7301253742168585 MSE test 12.23213557785939\n",
      "MAE train 1.6560714789690452 MAE test 2.450253955971319\n",
      "Epoch 3173 / 10000 loss: 14.896923303604126\n",
      "MSE train 5.729977018318107 MSE test 12.231853770820802\n",
      "MAE train 1.6560510027963624 MAE test 2.4502191196762175\n",
      "Epoch 3174 / 10000 loss: 14.896342992782593\n",
      "MSE train 5.729835283130124 MSE test 12.231834411681259\n",
      "MAE train 1.6560262429593486 MAE test 2.4502221654197838\n",
      "Epoch 3175 / 10000 loss: 14.895837783813477\n",
      "MSE train 5.729690820260877 MSE test 12.23146817776046\n",
      "MAE train 1.6560086486046925 MAE test 2.4501766083386\n",
      "Epoch 3176 / 10000 loss: 14.895265340805054\n",
      "MSE train 5.729514064886003 MSE test 12.231483752542562\n",
      "MAE train 1.655974978101616 MAE test 2.4501841790511074\n",
      "Epoch 3177 / 10000 loss: 14.894838571548462\n",
      "MSE train 5.729373555416963 MSE test 12.231280804384134\n",
      "MAE train 1.655954518683257 MAE test 2.450159441764013\n",
      "Epoch 3178 / 10000 loss: 14.894108772277832\n",
      "MSE train 5.729210104343843 MSE test 12.231120838449911\n",
      "MAE train 1.655928220464143 MAE test 2.4501444679754285\n",
      "Epoch 3179 / 10000 loss: 14.893583059310913\n",
      "MSE train 5.729076181421512 MSE test 12.230979025944455\n",
      "MAE train 1.6559080316288761 MAE test 2.4501276882522616\n",
      "Epoch 3180 / 10000 loss: 14.89301872253418\n",
      "MSE train 5.728914075890877 MSE test 12.230740394395047\n",
      "MAE train 1.655883948342105 MAE test 2.4501027375328945\n",
      "Epoch 3181 / 10000 loss: 14.892491102218628\n",
      "MSE train 5.728742497943808 MSE test 12.2306263591826\n",
      "MAE train 1.6558545823003983 MAE test 2.4500895300496723\n",
      "Epoch 3182 / 10000 loss: 14.891993284225464\n",
      "MSE train 5.728580856427223 MSE test 12.23055552206837\n",
      "MAE train 1.6558269574119338 MAE test 2.4500859863180207\n",
      "Epoch 3183 / 10000 loss: 14.89130687713623\n",
      "MSE train 5.728415279162481 MSE test 12.230259147558701\n",
      "MAE train 1.6558038225731222 MAE test 2.4500494074934194\n",
      "Epoch 3184 / 10000 loss: 14.890699863433838\n",
      "MSE train 5.728244492826972 MSE test 12.230251087434008\n",
      "MAE train 1.6557733276292705 MAE test 2.450054047404852\n",
      "Epoch 3185 / 10000 loss: 14.890161514282227\n",
      "MSE train 5.728053063292305 MSE test 12.229885085941644\n",
      "MAE train 1.6557469372809672 MAE test 2.4500087031251745\n",
      "Epoch 3186 / 10000 loss: 14.889500141143799\n",
      "MSE train 5.727783836373794 MSE test 12.229898837350621\n",
      "MAE train 1.6556955557897457 MAE test 2.450016241540456\n",
      "Epoch 3187 / 10000 loss: 14.888933658599854\n",
      "MSE train 5.7274054509459225 MSE test 12.229688928399232\n",
      "MAE train 1.6556277810811646 MAE test 2.4499909910205933\n",
      "Epoch 3188 / 10000 loss: 14.887902975082397\n",
      "MSE train 5.726598609952451 MSE test 12.22953309162549\n",
      "MAE train 1.6554662341552555 MAE test 2.4499772225249816\n",
      "Epoch 3189 / 10000 loss: 14.886516571044922\n",
      "MSE train 5.7260946802539925 MSE test 12.229385723406937\n",
      "MAE train 1.6553695457911148 MAE test 2.449960926221872\n",
      "Epoch 3190 / 10000 loss: 14.883435010910034\n",
      "MSE train 5.725931543408752 MSE test 12.229164797926918\n",
      "MAE train 1.6553450603537838 MAE test 2.4499395272024493\n",
      "Epoch 3191 / 10000 loss: 14.881740808486938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.725766469053939 MSE test 12.229062076251141\n",
      "MAE train 1.655316733048543 MAE test 2.449928626347892\n",
      "Epoch 3192 / 10000 loss: 14.881227493286133\n",
      "MSE train 5.725615183029937 MSE test 12.228994571547238\n",
      "MAE train 1.6552909000066653 MAE test 2.4499260504406934\n",
      "Epoch 3193 / 10000 loss: 14.880547046661377\n",
      "MSE train 5.725467937295648 MSE test 12.22871447209344\n",
      "MAE train 1.6552707149993053 MAE test 2.449891873456934\n",
      "Epoch 3194 / 10000 loss: 14.879958391189575\n",
      "MSE train 5.7253280235581645 MSE test 12.228703326985338\n",
      "MAE train 1.6552461250535166 MAE test 2.4498962645205546\n",
      "Epoch 3195 / 10000 loss: 14.879451036453247\n",
      "MSE train 5.725186322915444 MSE test 12.228339069063244\n",
      "MAE train 1.6552290154359977 MAE test 2.4498512203262544\n",
      "Epoch 3196 / 10000 loss: 14.878874063491821\n",
      "MSE train 5.725013186416989 MSE test 12.228357783872063\n",
      "MAE train 1.6551959346362273 MAE test 2.4498593247365443\n",
      "Epoch 3197 / 10000 loss: 14.878448724746704\n",
      "MSE train 5.724878321636246 MSE test 12.22816069686474\n",
      "MAE train 1.655176428976137 MAE test 2.449835502450408\n",
      "Epoch 3198 / 10000 loss: 14.877720594406128\n",
      "MSE train 5.724720711230463 MSE test 12.227996965488778\n",
      "MAE train 1.6551512976865335 MAE test 2.4498201705381732\n",
      "Epoch 3199 / 10000 loss: 14.877202272415161\n",
      "MSE train 5.724592709125866 MSE test 12.22786264883588\n",
      "MAE train 1.655131906698251 MAE test 2.4498044406993404\n",
      "Epoch 3200 / 10000 loss: 14.876648902893066\n",
      "MSE train 5.7244391536465695 MSE test 12.22762886815668\n",
      "MAE train 1.6551092174593065 MAE test 2.4497802200631047\n",
      "Epoch 3201 / 10000 loss: 14.876123189926147\n",
      "MSE train 5.724279760494517 MSE test 12.227517329004133\n",
      "MAE train 1.655081988468333 MAE test 2.449767403944477\n",
      "Epoch 3202 / 10000 loss: 14.875638484954834\n",
      "MSE train 5.724131052621219 MSE test 12.227441920486152\n",
      "MAE train 1.6550566479914937 MAE test 2.449763329763823\n",
      "Epoch 3203 / 10000 loss: 14.874975681304932\n",
      "MSE train 5.7239857993247565 MSE test 12.227163444063226\n",
      "MAE train 1.6550366809901098 MAE test 2.44972909097574\n",
      "Epoch 3204 / 10000 loss: 14.874396800994873\n",
      "MSE train 5.723847628181416 MSE test 12.227145536194282\n",
      "MAE train 1.655012509911744 MAE test 2.4497324634592226\n",
      "Epoch 3205 / 10000 loss: 14.873893976211548\n",
      "MSE train 5.72370698854768 MSE test 12.22678225049624\n",
      "MAE train 1.6549955479213132 MAE test 2.4496874534859545\n",
      "Epoch 3206 / 10000 loss: 14.873325109481812\n",
      "MSE train 5.723535078406091 MSE test 12.226800083753577\n",
      "MAE train 1.6549626565800346 MAE test 2.449695387106458\n",
      "Epoch 3207 / 10000 loss: 14.872902631759644\n",
      "MSE train 5.723399508477737 MSE test 12.226597845651016\n",
      "MAE train 1.6549430243113057 MAE test 2.449670848499345\n",
      "Epoch 3208 / 10000 loss: 14.872179508209229\n",
      "MSE train 5.72324207445488 MSE test 12.226442798269574\n",
      "MAE train 1.6549176183310816 MAE test 2.449656623855084\n",
      "Epoch 3209 / 10000 loss: 14.87166166305542\n",
      "MSE train 5.723116004799177 MSE test 12.22630043868811\n",
      "MAE train 1.6548988466334862 MAE test 2.449639825625004\n",
      "Epoch 3210 / 10000 loss: 14.871103525161743\n",
      "MSE train 5.722962881883148 MSE test 12.226063645427315\n",
      "MAE train 1.6548762812995472 MAE test 2.4496152110933997\n",
      "Epoch 3211 / 10000 loss: 14.870589971542358\n",
      "MSE train 5.722802870117035 MSE test 12.225951909730876\n",
      "MAE train 1.654848885161696 MAE test 2.449602330872724\n",
      "Epoch 3212 / 10000 loss: 14.87010931968689\n",
      "MSE train 5.722656222855669 MSE test 12.22588264322795\n",
      "MAE train 1.6548238389957224 MAE test 2.449599024879175\n",
      "Epoch 3213 / 10000 loss: 14.869444370269775\n",
      "MSE train 5.722511248508023 MSE test 12.225588855250106\n",
      "MAE train 1.6548043058719641 MAE test 2.4495627926556756\n",
      "Epoch 3214 / 10000 loss: 14.868868350982666\n",
      "MSE train 5.72237119790816 MSE test 12.225582497960254\n",
      "MAE train 1.6547793413158203 MAE test 2.449567597504443\n",
      "Epoch 3215 / 10000 loss: 14.868376970291138\n",
      "MSE train 5.722229892236599 MSE test 12.22521870349643\n",
      "MAE train 1.6547622015878933 MAE test 2.449522496941668\n",
      "Epoch 3216 / 10000 loss: 14.867793083190918\n",
      "MSE train 5.722058241192514 MSE test 12.225235229966035\n",
      "MAE train 1.6547293631096216 MAE test 2.4495302276511373\n",
      "Epoch 3217 / 10000 loss: 14.86736798286438\n",
      "MSE train 5.721921850646087 MSE test 12.225029898273137\n",
      "MAE train 1.6547095787721608 MAE test 2.4495052650041704\n",
      "Epoch 3218 / 10000 loss: 14.866646766662598\n",
      "MSE train 5.721764115384275 MSE test 12.224879186046662\n",
      "MAE train 1.6546839727731173 MAE test 2.449491549794005\n",
      "Epoch 3219 / 10000 loss: 14.866127014160156\n",
      "MSE train 5.721638096005671 MSE test 12.224731537345217\n",
      "MAE train 1.6546653259688666 MAE test 2.449474022425674\n",
      "Epoch 3220 / 10000 loss: 14.865564346313477\n",
      "MSE train 5.72148488598534 MSE test 12.224496271273138\n",
      "MAE train 1.654642693196758 MAE test 2.4494495814033512\n",
      "Epoch 3221 / 10000 loss: 14.865056276321411\n",
      "MSE train 5.721325071203888 MSE test 12.224383952310083\n",
      "MAE train 1.6546153391988918 MAE test 2.4494365822629933\n",
      "Epoch 3222 / 10000 loss: 14.864572525024414\n",
      "MSE train 5.721176875765174 MSE test 12.224309910952151\n",
      "MAE train 1.654590030249946 MAE test 2.4494326185820614\n",
      "Epoch 3223 / 10000 loss: 14.863909006118774\n",
      "MSE train 5.7210314114042085 MSE test 12.224025132551148\n",
      "MAE train 1.6545701286328287 MAE test 2.449397505691947\n",
      "Epoch 3224 / 10000 loss: 14.863330841064453\n",
      "MSE train 5.720892723737812 MSE test 12.224010488116937\n",
      "MAE train 1.654545699801244 MAE test 2.4494011994705525\n",
      "Epoch 3225 / 10000 loss: 14.862831115722656\n",
      "MSE train 5.72075151393046 MSE test 12.223643765053483\n",
      "MAE train 1.6545286266298538 MAE test 2.4493557089805646\n",
      "Epoch 3226 / 10000 loss: 14.862257480621338\n",
      "MSE train 5.720578855165107 MSE test 12.22366035185509\n",
      "MAE train 1.6544955667392731 MAE test 2.449363422023282\n",
      "Epoch 3227 / 10000 loss: 14.86183476448059\n",
      "MSE train 5.7204439274404955 MSE test 12.223460720458858\n",
      "MAE train 1.6544759980699362 MAE test 2.4493391392191133\n",
      "Epoch 3228 / 10000 loss: 14.861109972000122\n",
      "MSE train 5.720286101210177 MSE test 12.223295995325433\n",
      "MAE train 1.6544507356986253 MAE test 2.4493236005574435\n",
      "Epoch 3229 / 10000 loss: 14.860591888427734\n",
      "MSE train 5.720158123897688 MSE test 12.223159124229042\n",
      "MAE train 1.6544313380906077 MAE test 2.4493074304090547\n",
      "Epoch 3230 / 10000 loss: 14.860038757324219\n",
      "MSE train 5.72000399850969 MSE test 12.222922591285482\n",
      "MAE train 1.6544085237961574 MAE test 2.4492827782903848\n",
      "Epoch 3231 / 10000 loss: 14.859514713287354\n",
      "MSE train 5.71984396532372 MSE test 12.222809550715295\n",
      "MAE train 1.6543811260956702 MAE test 2.449269653166253\n",
      "Epoch 3232 / 10000 loss: 14.859028339385986\n",
      "MSE train 5.719695066978136 MSE test 12.222733835271583\n",
      "MAE train 1.654355695857334 MAE test 2.449265447215361\n",
      "Epoch 3233 / 10000 loss: 14.858364343643188\n",
      "MSE train 5.719548999638847 MSE test 12.22245028699344\n",
      "MAE train 1.6543356281040902 MAE test 2.4492304715513775\n",
      "Epoch 3234 / 10000 loss: 14.857784271240234\n",
      "MSE train 5.719410043138671 MSE test 12.222433457680228\n",
      "MAE train 1.654311199856279 MAE test 2.449233852026144\n",
      "Epoch 3235 / 10000 loss: 14.85728144645691\n",
      "MSE train 5.719268236458763 MSE test 12.222066881176215\n",
      "MAE train 1.6542940160223483 MAE test 2.449188354571709\n",
      "Epoch 3236 / 10000 loss: 14.856708765029907\n",
      "MSE train 5.7190952019256 MSE test 12.22208280941388\n",
      "MAE train 1.6542608890250008 MAE test 2.449195934671784\n",
      "Epoch 3237 / 10000 loss: 14.85628342628479\n",
      "MSE train 5.718959281774031 MSE test 12.221881703818317\n",
      "MAE train 1.6542411489483841 MAE test 2.449171446443218\n",
      "Epoch 3238 / 10000 loss: 14.855556726455688\n",
      "MSE train 5.718800798276468 MSE test 12.221719066702434\n",
      "MAE train 1.6542156923418803 MAE test 2.449156149642049\n",
      "Epoch 3239 / 10000 loss: 14.855036497116089\n",
      "MSE train 5.718672737712012 MSE test 12.221579766338918\n",
      "MAE train 1.654196370333654 MAE test 2.4491396272722428\n",
      "Epoch 3240 / 10000 loss: 14.854478359222412\n",
      "MSE train 5.718517936176837 MSE test 12.22134158652124\n",
      "MAE train 1.6541734602820855 MAE test 2.449114766521064\n",
      "Epoch 3241 / 10000 loss: 14.853956460952759\n",
      "MSE train 5.718356860381252 MSE test 12.221228120177964\n",
      "MAE train 1.654145870125664 MAE test 2.449101554775801\n",
      "Epoch 3242 / 10000 loss: 14.853468894958496\n",
      "MSE train 5.718208014788512 MSE test 12.221154844311249\n",
      "MAE train 1.6541204313584683 MAE test 2.449097641545311\n",
      "Epoch 3243 / 10000 loss: 14.852801322937012\n",
      "MSE train 5.718061236909453 MSE test 12.220864590033726\n",
      "MAE train 1.6541004144336546 MAE test 2.4490617831183408\n",
      "Epoch 3244 / 10000 loss: 14.852219104766846\n",
      "MSE train 5.717920665025286 MSE test 12.220852729977068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.654075520609462 MAE test 2.4490657906408453\n",
      "Epoch 3245 / 10000 loss: 14.851718187332153\n",
      "MSE train 5.717777568786735 MSE test 12.220484938879238\n",
      "MAE train 1.654058102563183 MAE test 2.4490201186574914\n",
      "Epoch 3246 / 10000 loss: 14.851135969161987\n",
      "MSE train 5.71760352029095 MSE test 12.220500346943112\n",
      "MAE train 1.654024805357629 MAE test 2.4490276169761005\n",
      "Epoch 3247 / 10000 loss: 14.850706577301025\n",
      "MSE train 5.717466545354267 MSE test 12.220298595548126\n",
      "MAE train 1.6540048816247959 MAE test 2.4490030279902086\n",
      "Epoch 3248 / 10000 loss: 14.849976778030396\n",
      "MSE train 5.717306762370461 MSE test 12.220135047783593\n",
      "MAE train 1.6539792085422549 MAE test 2.448987630300302\n",
      "Epoch 3249 / 10000 loss: 14.849452257156372\n",
      "MSE train 5.717177340868033 MSE test 12.219995634885445\n",
      "MAE train 1.6539596439921311 MAE test 2.44897106405066\n",
      "Epoch 3250 / 10000 loss: 14.848889827728271\n",
      "MSE train 5.717021010894725 MSE test 12.219756913877141\n",
      "MAE train 1.6539364680769058 MAE test 2.448946137223736\n",
      "Epoch 3251 / 10000 loss: 14.848361730575562\n",
      "MSE train 5.716858573239714 MSE test 12.21964303061505\n",
      "MAE train 1.6539086475524867 MAE test 2.4489328568479505\n",
      "Epoch 3252 / 10000 loss: 14.847869157791138\n",
      "MSE train 5.716707864073872 MSE test 12.219568435525153\n",
      "MAE train 1.6538828926138789 MAE test 2.448928775409895\n",
      "Epoch 3253 / 10000 loss: 14.847195386886597\n",
      "MSE train 5.716559186708679 MSE test 12.219278846504864\n",
      "MAE train 1.65386252145328 MAE test 2.448892996594534\n",
      "Epoch 3254 / 10000 loss: 14.846606969833374\n",
      "MSE train 5.716416773871921 MSE test 12.219265220478237\n",
      "MAE train 1.6538373590354118 MAE test 2.448896778897129\n",
      "Epoch 3255 / 10000 loss: 14.846097946166992\n",
      "MSE train 5.716271543244352 MSE test 12.218896744740011\n",
      "MAE train 1.6538195890739078 MAE test 2.4488510076461454\n",
      "Epoch 3256 / 10000 loss: 14.845509767532349\n",
      "MSE train 5.7160950884488955 MSE test 12.21891132457941\n",
      "MAE train 1.6537858718820104 MAE test 2.448858416915022\n",
      "Epoch 3257 / 10000 loss: 14.845072746276855\n",
      "MSE train 5.715955724641499 MSE test 12.218709651904065\n",
      "MAE train 1.6537655365065729 MAE test 2.4488338313477214\n",
      "Epoch 3258 / 10000 loss: 14.844333171844482\n",
      "MSE train 5.7157929612122045 MSE test 12.218544078935544\n",
      "MAE train 1.6537393873183672 MAE test 2.4488181714709927\n",
      "Epoch 3259 / 10000 loss: 14.843799352645874\n",
      "MSE train 5.7156601758857635 MSE test 12.218404605030338\n",
      "MAE train 1.6537192084780081 MAE test 2.4488016017622143\n",
      "Epoch 3260 / 10000 loss: 14.843226909637451\n",
      "MSE train 5.715500089788193 MSE test 12.218165409364296\n",
      "MAE train 1.653695381052012 MAE test 2.448776645588554\n",
      "Epoch 3261 / 10000 loss: 14.842685222625732\n",
      "MSE train 5.715333882795721 MSE test 12.218050801261143\n",
      "MAE train 1.6536669171353413 MAE test 2.4487632681420313\n",
      "Epoch 3262 / 10000 loss: 14.842177629470825\n",
      "MSE train 5.715178361952444 MSE test 12.217973834792938\n",
      "MAE train 1.653640336674121 MAE test 2.4487588998247247\n",
      "Epoch 3263 / 10000 loss: 14.841489791870117\n",
      "MSE train 5.715024618805686 MSE test 12.217685982383967\n",
      "MAE train 1.6536189985765648 MAE test 2.448723365198075\n",
      "Epoch 3264 / 10000 loss: 14.840883731842041\n",
      "MSE train 5.7148770305180285 MSE test 12.217668689741407\n",
      "MAE train 1.653593030071144 MAE test 2.4487266942822266\n",
      "Epoch 3265 / 10000 loss: 14.840353012084961\n",
      "MSE train 5.714725562723261 MSE test 12.21729910872023\n",
      "MAE train 1.6535741855648494 MAE test 2.448680818223333\n",
      "Epoch 3266 / 10000 loss: 14.839745283126831\n",
      "MSE train 5.7145420637379125 MSE test 12.217312470449066\n",
      "MAE train 1.6535392317346436 MAE test 2.4486880749937234\n",
      "Epoch 3267 / 10000 loss: 14.839283466339111\n",
      "MSE train 5.714394720996024 MSE test 12.2171090671788\n",
      "MAE train 1.6535174947737266 MAE test 2.448663294562656\n",
      "Epoch 3268 / 10000 loss: 14.838515520095825\n",
      "MSE train 5.714222930575283 MSE test 12.216942345861701\n",
      "MAE train 1.6534897461210183 MAE test 2.4486475448681198\n",
      "Epoch 3269 / 10000 loss: 14.837950229644775\n",
      "MSE train 5.714080355105343 MSE test 12.216800725035386\n",
      "MAE train 1.6534678859223684 MAE test 2.4486307053387617\n",
      "Epoch 3270 / 10000 loss: 14.837341070175171\n",
      "MSE train 5.713908982973161 MSE test 12.216559287982665\n",
      "MAE train 1.6534421069526908 MAE test 2.448605502362328\n",
      "Epoch 3271 / 10000 loss: 14.836758613586426\n",
      "MSE train 5.713730561652158 MSE test 12.216442565815305\n",
      "MAE train 1.6534115098715476 MAE test 2.4485918672977554\n",
      "Epoch 3272 / 10000 loss: 14.83620548248291\n",
      "MSE train 5.713561588107354 MSE test 12.21636378885868\n",
      "MAE train 1.6533825720837574 MAE test 2.4485873098117206\n",
      "Epoch 3273 / 10000 loss: 14.835467338562012\n",
      "MSE train 5.713393625608705 MSE test 12.216072830842263\n",
      "MAE train 1.6533587701655503 MAE test 2.4485514046432884\n",
      "Epoch 3274 / 10000 loss: 14.83480453491211\n",
      "MSE train 5.7132310396016 MSE test 12.216054134543832\n",
      "MAE train 1.653330132647635 MAE test 2.4485545705572536\n",
      "Epoch 3275 / 10000 loss: 14.834214687347412\n",
      "MSE train 5.713064936359611 MSE test 12.2156822205847\n",
      "MAE train 1.653308707444103 MAE test 2.4485083935190097\n",
      "Epoch 3276 / 10000 loss: 14.833543300628662\n",
      "MSE train 5.712867648765675 MSE test 12.215693662527018\n",
      "MAE train 1.6532712792230497 MAE test 2.448515404697453\n",
      "Epoch 3277 / 10000 loss: 14.83301830291748\n",
      "MSE train 5.7127089022424755 MSE test 12.215488792788838\n",
      "MAE train 1.6532474873474319 MAE test 2.448490381557419\n",
      "Epoch 3278 / 10000 loss: 14.832190990447998\n",
      "MSE train 5.712528527828061 MSE test 12.215321376483226\n",
      "MAE train 1.653218139934938 MAE test 2.4484745106152808\n",
      "Epoch 3279 / 10000 loss: 14.831573247909546\n",
      "MSE train 5.712381852453495 MSE test 12.21517987084117\n",
      "MAE train 1.6531954151112203 MAE test 2.448457561702249\n",
      "Epoch 3280 / 10000 loss: 14.83092451095581\n",
      "MSE train 5.712210668912893 MSE test 12.214939556958718\n",
      "MAE train 1.6531695277075662 MAE test 2.4484324147248446\n",
      "Epoch 3281 / 10000 loss: 14.830318927764893\n",
      "MSE train 5.712037868753461 MSE test 12.214824904358908\n",
      "MAE train 1.6531396781391439 MAE test 2.448418864460952\n",
      "Epoch 3282 / 10000 loss: 14.829760074615479\n",
      "MSE train 5.711878956673631 MSE test 12.214749055073359\n",
      "MAE train 1.653112211625914 MAE test 2.448414497224187\n",
      "Epoch 3283 / 10000 loss: 14.829035758972168\n",
      "MSE train 5.711725482521164 MSE test 12.214462281759056\n",
      "MAE train 1.6530905912094058 MAE test 2.4483789273960306\n",
      "Epoch 3284 / 10000 loss: 14.828406572341919\n",
      "MSE train 5.711580889112596 MSE test 12.214447527065879\n",
      "MAE train 1.653064785702024 MAE test 2.448382388886573\n",
      "Epoch 3285 / 10000 loss: 14.827867269515991\n",
      "MSE train 5.711435019278428 MSE test 12.214080223502906\n",
      "MAE train 1.6530466001762643 MAE test 2.4483366198403114\n",
      "Epoch 3286 / 10000 loss: 14.827260971069336\n",
      "MSE train 5.711259544518612 MSE test 12.214096901985336\n",
      "MAE train 1.6530127651889486 MAE test 2.4483440996638035\n",
      "Epoch 3287 / 10000 loss: 14.82681131362915\n",
      "MSE train 5.711122179756801 MSE test 12.213896255988676\n",
      "MAE train 1.65299251794885 MAE test 2.4483194767193086\n",
      "Epoch 3288 / 10000 loss: 14.826065301895142\n",
      "MSE train 5.710962279531071 MSE test 12.213733794312281\n",
      "MAE train 1.6529665755634897 MAE test 2.4483041046398952\n",
      "Epoch 3289 / 10000 loss: 14.825528621673584\n",
      "MSE train 5.710833795558994 MSE test 12.21359513983582\n",
      "MAE train 1.6529469844074969 MAE test 2.448287482846329\n",
      "Epoch 3290 / 10000 loss: 14.82495665550232\n",
      "MSE train 5.7106781739343315 MSE test 12.213356980911376\n",
      "MAE train 1.6529237315181071 MAE test 2.4482625735594064\n",
      "Epoch 3291 / 10000 loss: 14.824421882629395\n",
      "MSE train 5.710517309921618 MSE test 12.213244384486735\n",
      "MAE train 1.652896013162566 MAE test 2.4482493267041283\n",
      "Epoch 3292 / 10000 loss: 14.823923826217651\n",
      "MSE train 5.710368190467024 MSE test 12.213169902175032\n",
      "MAE train 1.6528703660878081 MAE test 2.448245177453107\n",
      "Epoch 3293 / 10000 loss: 14.823247194290161\n",
      "MSE train 5.710221080196271 MSE test 12.21288209386774\n",
      "MAE train 1.6528500915597568 MAE test 2.4482096038476673\n",
      "Epoch 3294 / 10000 loss: 14.822656869888306\n",
      "MSE train 5.710081190765236 MSE test 12.212868130669733\n",
      "MAE train 1.6528252691528085 MAE test 2.4482132536247994\n",
      "Epoch 3295 / 10000 loss: 14.822145700454712\n",
      "MSE train 5.709937794403634 MSE test 12.21250026942245\n",
      "MAE train 1.6528077038591136 MAE test 2.4481676030312234\n",
      "Epoch 3296 / 10000 loss: 14.82155728340149\n",
      "MSE train 5.70976442904612 MSE test 12.212515382576164\n",
      "MAE train 1.652774389360445 MAE test 2.4481749864834486\n",
      "Epoch 3297 / 10000 loss: 14.821120977401733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.709627594621666 MSE test 12.21231389345008\n",
      "MAE train 1.6527544017157805 MAE test 2.448150428130617\n",
      "Epoch 3298 / 10000 loss: 14.820383787155151\n",
      "MSE train 5.709468089467845 MSE test 12.212149554405029\n",
      "MAE train 1.6527286506103394 MAE test 2.448134927010109\n",
      "Epoch 3299 / 10000 loss: 14.819852828979492\n",
      "MSE train 5.709339220284595 MSE test 12.212009971007006\n",
      "MAE train 1.6527091249520254 MAE test 2.448118332503338\n",
      "Epoch 3300 / 10000 loss: 14.819284439086914\n",
      "MSE train 5.709183078759092 MSE test 12.211770135163908\n",
      "MAE train 1.6526858777034241 MAE test 2.448093351498139\n",
      "Epoch 3301 / 10000 loss: 14.81874966621399\n",
      "MSE train 5.709021408614392 MSE test 12.211656323003295\n",
      "MAE train 1.65265811262225 MAE test 2.4480800489807186\n",
      "Epoch 3302 / 10000 loss: 14.81825065612793\n",
      "MSE train 5.708871472883098 MSE test 12.211580293783676\n",
      "MAE train 1.6526323959164624 MAE test 2.4480758052866256\n",
      "Epoch 3303 / 10000 loss: 14.81757378578186\n",
      "MSE train 5.708723161022045 MSE test 12.211291645020038\n",
      "MAE train 1.6526119597526177 MAE test 2.4480402040547706\n",
      "Epoch 3304 / 10000 loss: 14.816980361938477\n",
      "MSE train 5.708582357312683 MSE test 12.211275990662203\n",
      "MAE train 1.6525870602453556 MAE test 2.448043746653911\n",
      "Epoch 3305 / 10000 loss: 14.816465854644775\n",
      "MSE train 5.7084377372190085 MSE test 12.210906613163797\n",
      "MAE train 1.652569336586646 MAE test 2.447997986328052\n",
      "Epoch 3306 / 10000 loss: 14.81587553024292\n",
      "MSE train 5.708263267217243 MSE test 12.210920599448915\n",
      "MAE train 1.652535895600223 MAE test 2.448005295716352\n",
      "Epoch 3307 / 10000 loss: 14.815434217453003\n",
      "MSE train 5.708125131546506 MSE test 12.210717591266313\n",
      "MAE train 1.6525157239708173 MAE test 2.4479806061264235\n",
      "Epoch 3308 / 10000 loss: 14.81469440460205\n",
      "MSE train 5.707964326288248 MSE test 12.210552485030657\n",
      "MAE train 1.6524897703592627 MAE test 2.4479651170684726\n",
      "Epoch 3309 / 10000 loss: 14.814159393310547\n",
      "MSE train 5.707834305465459 MSE test 12.210411123227962\n",
      "MAE train 1.6524700969146124 MAE test 2.4479483394351442\n",
      "Epoch 3310 / 10000 loss: 14.813585758209229\n",
      "MSE train 5.707676819532602 MSE test 12.210169577276691\n",
      "MAE train 1.652446658525956 MAE test 2.447923209365949\n",
      "Epoch 3311 / 10000 loss: 14.813047885894775\n",
      "MSE train 5.707513872763728 MSE test 12.210054691368494\n",
      "MAE train 1.6524186888074095 MAE test 2.4479098191300976\n",
      "Epoch 3312 / 10000 loss: 14.812544822692871\n",
      "MSE train 5.70736264774316 MSE test 12.209977198216471\n",
      "MAE train 1.6523927895361037 MAE test 2.44790544389853\n",
      "Epoch 3313 / 10000 loss: 14.811861991882324\n",
      "MSE train 5.707212971239838 MSE test 12.209686683789734\n",
      "MAE train 1.6523721291322369 MAE test 2.447869682702164\n",
      "Epoch 3314 / 10000 loss: 14.811264038085938\n",
      "MSE train 5.707070813830454 MSE test 12.20966941895267\n",
      "MAE train 1.6523470179638793 MAE test 2.4478730386384115\n",
      "Epoch 3315 / 10000 loss: 14.810743808746338\n",
      "MSE train 5.706924650898477 MSE test 12.209298806707697\n",
      "MAE train 1.6523290203304901 MAE test 2.4478271940555083\n",
      "Epoch 3316 / 10000 loss: 14.810149431228638\n",
      "MSE train 5.7067488818103325 MSE test 12.209311014617395\n",
      "MAE train 1.6522953772455098 MAE test 2.4478343117189483\n",
      "Epoch 3317 / 10000 loss: 14.809702396392822\n",
      "MSE train 5.706609158804614 MSE test 12.20910584693624\n",
      "MAE train 1.6522749414100764 MAE test 2.447809386043219\n",
      "Epoch 3318 / 10000 loss: 14.808957576751709\n",
      "MSE train 5.706446804359561 MSE test 12.208939769298576\n",
      "MAE train 1.652248708257285 MAE test 2.4477937983254066\n",
      "Epoch 3319 / 10000 loss: 14.808417081832886\n",
      "MSE train 5.706315447635393 MSE test 12.20879551531933\n",
      "MAE train 1.652228861628737 MAE test 2.4477766863593446\n",
      "Epoch 3320 / 10000 loss: 14.80783724784851\n",
      "MSE train 5.706156307628062 MSE test 12.20855178108895\n",
      "MAE train 1.6522051906495436 MAE test 2.447751334337101\n",
      "Epoch 3321 / 10000 loss: 14.807295799255371\n",
      "MSE train 5.705991751611038 MSE test 12.208434729712287\n",
      "MAE train 1.6521769811797917 MAE test 2.44773768321535\n",
      "Epoch 3322 / 10000 loss: 14.806786060333252\n",
      "MSE train 5.705838937712797 MSE test 12.208355218230581\n",
      "MAE train 1.6521508590295009 MAE test 2.4477330877748904\n",
      "Epoch 3323 / 10000 loss: 14.806097507476807\n",
      "MSE train 5.705687431714791 MSE test 12.208061573394362\n",
      "MAE train 1.6521299527760458 MAE test 2.447696962564757\n",
      "Epoch 3324 / 10000 loss: 14.8054940700531\n",
      "MSE train 5.70554336152842 MSE test 12.208042126122992\n",
      "MAE train 1.6521045402229113 MAE test 2.447700062718205\n",
      "Epoch 3325 / 10000 loss: 14.804969310760498\n",
      "MSE train 5.705394946623033 MSE test 12.207668238766798\n",
      "MAE train 1.652086218935565 MAE test 2.4476538406438015\n",
      "Epoch 3326 / 10000 loss: 14.804365873336792\n",
      "MSE train 5.705217104633743 MSE test 12.207677082002125\n",
      "MAE train 1.652052281595846 MAE test 2.4476605347681124\n",
      "Epoch 3327 / 10000 loss: 14.803911209106445\n",
      "MSE train 5.705074871982043 MSE test 12.207467596003829\n",
      "MAE train 1.6520314817754147 MAE test 2.4476350714053163\n",
      "Epoch 3328 / 10000 loss: 14.80315899848938\n",
      "MSE train 5.704909702082894 MSE test 12.207297769098515\n",
      "MAE train 1.652004833486383 MAE test 2.4476190221222716\n",
      "Epoch 3329 / 10000 loss: 14.802609920501709\n",
      "MSE train 5.704775491726178 MSE test 12.207148262559393\n",
      "MAE train 1.651984601002902 MAE test 2.447601239237954\n",
      "Epoch 3330 / 10000 loss: 14.802018880844116\n",
      "MSE train 5.7046127231865835 MSE test 12.206898391293622\n",
      "MAE train 1.6519603705610306 MAE test 2.447575126221785\n",
      "Epoch 3331 / 10000 loss: 14.801466703414917\n",
      "MSE train 5.704444147373415 MSE test 12.206774722175041\n",
      "MAE train 1.6519315247572182 MAE test 2.4475606190438763\n",
      "Epoch 3332 / 10000 loss: 14.800945520401001\n",
      "MSE train 5.704286530372925 MSE test 12.206687300020992\n",
      "MAE train 1.6519046451445 MAE test 2.4475550173623697\n",
      "Epoch 3333 / 10000 loss: 14.800241708755493\n",
      "MSE train 5.704129108034494 MSE test 12.206384007447447\n",
      "MAE train 1.6518828176788416 MAE test 2.4475176403883965\n",
      "Epoch 3334 / 10000 loss: 14.799619197845459\n",
      "MSE train 5.703978012295961 MSE test 12.206353419267103\n",
      "MAE train 1.6518562976659976 MAE test 2.4475192949593882\n",
      "Epoch 3335 / 10000 loss: 14.799071550369263\n",
      "MSE train 5.703820715921125 MSE test 12.205965822828897\n",
      "MAE train 1.6518365620237763 MAE test 2.4474713292054284\n",
      "Epoch 3336 / 10000 loss: 14.798440933227539\n",
      "MSE train 5.703631891571649 MSE test 12.205957699150577\n",
      "MAE train 1.651800849238067 MAE test 2.447475823117179\n",
      "Epoch 3337 / 10000 loss: 14.797952890396118\n",
      "MSE train 5.703475233723268 MSE test 12.205727315899672\n",
      "MAE train 1.6517777021200382 MAE test 2.4474476656331974\n",
      "Epoch 3338 / 10000 loss: 14.79715633392334\n",
      "MSE train 5.703290947952283 MSE test 12.205531594456414\n",
      "MAE train 1.6517478789287985 MAE test 2.447428306731868\n",
      "Epoch 3339 / 10000 loss: 14.796549320220947\n",
      "MSE train 5.703130925360165 MSE test 12.205348020261976\n",
      "MAE train 1.6517233492407295 MAE test 2.4474061342215454\n",
      "Epoch 3340 / 10000 loss: 14.795880794525146\n",
      "MSE train 5.702931836497057 MSE test 12.20505377763734\n",
      "MAE train 1.651693017465334 MAE test 2.4473743478103493\n",
      "Epoch 3341 / 10000 loss: 14.795221328735352\n",
      "MSE train 5.702711774482297 MSE test 12.204872282040762\n",
      "MAE train 1.6516554079081314 MAE test 2.4473523999835956\n",
      "Epoch 3342 / 10000 loss: 14.794547080993652\n",
      "MSE train 5.702480931432266 MSE test 12.204708134850637\n",
      "MAE train 1.6516158461484527 MAE test 2.4473369513445307\n",
      "Epoch 3343 / 10000 loss: 14.793623208999634\n",
      "MSE train 5.702225319043667 MSE test 12.204306021079104\n",
      "MAE train 1.6515771353817619 MAE test 2.4472868799476633\n",
      "Epoch 3344 / 10000 loss: 14.79268217086792\n",
      "MSE train 5.701964466119739 MSE test 12.204159596466834\n",
      "MAE train 1.651531837245453 MAE test 2.4472735065544717\n",
      "Epoch 3345 / 10000 loss: 14.791702508926392\n",
      "MSE train 5.701720705875113 MSE test 12.203664583420737\n",
      "MAE train 1.6514970980605754 MAE test 2.44721158508574\n",
      "Epoch 3346 / 10000 loss: 14.79058027267456\n",
      "MSE train 5.70149136997124 MSE test 12.203591091950685\n",
      "MAE train 1.6514537526847006 MAE test 2.4472074858453916\n",
      "Epoch 3347 / 10000 loss: 14.789698839187622\n",
      "MSE train 5.7013285022991065 MSE test 12.203344811190684\n",
      "MAE train 1.6514287062675073 MAE test 2.4471770268303477\n",
      "Epoch 3348 / 10000 loss: 14.788706064224243\n",
      "MSE train 5.701157748406558 MSE test 12.203172146477437\n",
      "MAE train 1.6514005211288925 MAE test 2.447160345237432\n",
      "Epoch 3349 / 10000 loss: 14.78804612159729\n",
      "MSE train 5.701025332411856 MSE test 12.203037151700338\n",
      "MAE train 1.6513800037480888 MAE test 2.4471440931659583\n",
      "Epoch 3350 / 10000 loss: 14.787406206130981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.70086757510305 MSE test 12.20281398586525\n",
      "MAE train 1.6513559523361787 MAE test 2.4471211324071254\n",
      "Epoch 3351 / 10000 loss: 14.786832809448242\n",
      "MSE train 5.70070662454261 MSE test 12.202724556158405\n",
      "MAE train 1.6513276692176548 MAE test 2.4471106848086746\n",
      "Epoch 3352 / 10000 loss: 14.786303997039795\n",
      "MSE train 5.700558261674664 MSE test 12.202674989157694\n",
      "MAE train 1.65130163786954 MAE test 2.447109633235731\n",
      "Epoch 3353 / 10000 loss: 14.785603284835815\n",
      "MSE train 5.700411526273953 MSE test 12.20241244430409\n",
      "MAE train 1.651280918919444 MAE test 2.4470772420205487\n",
      "Epoch 3354 / 10000 loss: 14.784992456436157\n",
      "MSE train 5.700273030105146 MSE test 12.202424359291\n",
      "MAE train 1.6512558447601806 MAE test 2.4470840180057154\n",
      "Epoch 3355 / 10000 loss: 14.784464597702026\n",
      "MSE train 5.7001299983392455 MSE test 12.202081355795867\n",
      "MAE train 1.6512378741165528 MAE test 2.447041513501863\n",
      "Epoch 3356 / 10000 loss: 14.783862352371216\n",
      "MSE train 5.699958617106463 MSE test 12.202120265905503\n",
      "MAE train 1.6512044602874905 MAE test 2.4470517127131144\n",
      "Epoch 3357 / 10000 loss: 14.783413648605347\n",
      "MSE train 5.699822684650595 MSE test 12.201939522384448\n",
      "MAE train 1.6511842165863115 MAE test 2.4470296111916534\n",
      "Epoch 3358 / 10000 loss: 14.782670259475708\n",
      "MSE train 5.699664215186253 MSE test 12.201799715130976\n",
      "MAE train 1.6511581752057043 MAE test 2.4470171191957046\n",
      "Epoch 3359 / 10000 loss: 14.782132625579834\n",
      "MSE train 5.699537770048013 MSE test 12.20167692961217\n",
      "MAE train 1.6511388663596325 MAE test 2.44700239274259\n",
      "Epoch 3360 / 10000 loss: 14.781556844711304\n",
      "MSE train 5.699382788596743 MSE test 12.201454326688042\n",
      "MAE train 1.6511155512254183 MAE test 2.446979512486478\n",
      "Epoch 3361 / 10000 loss: 14.781025648117065\n",
      "MSE train 5.699223422264107 MSE test 12.201358778936646\n",
      "MAE train 1.651087882454576 MAE test 2.4469682033625078\n",
      "Epoch 3362 / 10000 loss: 14.780528783798218\n",
      "MSE train 5.6990758045266094 MSE test 12.201298913639912\n",
      "MAE train 1.6510623244949758 MAE test 2.446965755774166\n",
      "Epoch 3363 / 10000 loss: 14.77985405921936\n",
      "MSE train 5.6989295029820735 MSE test 12.201025536126789\n",
      "MAE train 1.6510420236105008 MAE test 2.4469319088197716\n",
      "Epoch 3364 / 10000 loss: 14.779265642166138\n",
      "MSE train 5.698791662920254 MSE test 12.201024449905308\n",
      "MAE train 1.651017423014484 MAE test 2.4469369443439404\n",
      "Epoch 3365 / 10000 loss: 14.778757333755493\n",
      "MSE train 5.698648974592739 MSE test 12.200669003604057\n",
      "MAE train 1.6509998551477187 MAE test 2.4468927835031176\n",
      "Epoch 3366 / 10000 loss: 14.778175592422485\n",
      "MSE train 5.698478364857693 MSE test 12.200696450812512\n",
      "MAE train 1.6509668721646027 MAE test 2.4469014044730253\n",
      "Epoch 3367 / 10000 loss: 14.777745485305786\n",
      "MSE train 5.698343081425579 MSE test 12.200504854228702\n",
      "MAE train 1.6509470119184382 MAE test 2.4468778254288988\n",
      "Epoch 3368 / 10000 loss: 14.777017593383789\n",
      "MSE train 5.698185475720262 MSE test 12.200355361355566\n",
      "MAE train 1.650921331003207 MAE test 2.4468640308239937\n",
      "Epoch 3369 / 10000 loss: 14.776495933532715\n",
      "MSE train 5.698060142545324 MSE test 12.200223002422014\n",
      "MAE train 1.6509024282141735 MAE test 2.446847971794525\n",
      "Epoch 3370 / 10000 loss: 14.77593445777893\n",
      "MSE train 5.697906151602245 MSE test 12.199992158790902\n",
      "MAE train 1.650879469094822 MAE test 2.4468239724785987\n",
      "Epoch 3371 / 10000 loss: 14.77541732788086\n",
      "MSE train 5.697747921402347 MSE test 12.199889418121181\n",
      "MAE train 1.6508521425685045 MAE test 2.4468116625913954\n",
      "Epoch 3372 / 10000 loss: 14.77493166923523\n",
      "MSE train 5.697601268650571 MSE test 12.199822372436907\n",
      "MAE train 1.6508268611734447 MAE test 2.4468082292232665\n",
      "Epoch 3373 / 10000 loss: 14.774269342422485\n",
      "MSE train 5.697455921562188 MSE test 12.19954356836769\n",
      "MAE train 1.650806805822184 MAE test 2.4467736122303627\n",
      "Epoch 3374 / 10000 loss: 14.773691177368164\n",
      "MSE train 5.697319235058301 MSE test 12.199536335529256\n",
      "MAE train 1.6507824881031836 MAE test 2.4467777919666203\n",
      "Epoch 3375 / 10000 loss: 14.773192167282104\n",
      "MSE train 5.697177341374715 MSE test 12.199176063498863\n",
      "MAE train 1.6507651303793183 MAE test 2.446732974844043\n",
      "Epoch 3376 / 10000 loss: 14.772620677947998\n",
      "MSE train 5.697007673382228 MSE test 12.199198959965072\n",
      "MAE train 1.6507323511426033 MAE test 2.446740952976417\n",
      "Epoch 3377 / 10000 loss: 14.772196531295776\n",
      "MSE train 5.696873099997268 MSE test 12.199002628229936\n",
      "MAE train 1.6507126761228188 MAE test 2.4467167245144816\n",
      "Epoch 3378 / 10000 loss: 14.771477937698364\n",
      "MSE train 5.696716078486867 MSE test 12.198850510668045\n",
      "MAE train 1.6506871189800845 MAE test 2.446702542706937\n",
      "Epoch 3379 / 10000 loss: 14.770961284637451\n",
      "MSE train 5.696591492571327 MSE test 12.198713847263157\n",
      "MAE train 1.6506684381402774 MAE test 2.4466859117402033\n",
      "Epoch 3380 / 10000 loss: 14.770404577255249\n",
      "MSE train 5.696437847500864 MSE test 12.198479618666973\n",
      "MAE train 1.6506455989986626 MAE test 2.446661457841804\n",
      "Epoch 3381 / 10000 loss: 14.76989483833313\n",
      "MSE train 5.696280310388163 MSE test 12.198374146024328\n",
      "MAE train 1.6506184303834064 MAE test 2.446648754257933\n",
      "Epoch 3382 / 10000 loss: 14.769413232803345\n",
      "MSE train 5.696133789470929 MSE test 12.19830395507192\n",
      "MAE train 1.6505932284664913 MAE test 2.44664488841122\n",
      "Epoch 3383 / 10000 loss: 14.768754243850708\n",
      "MSE train 5.69598870176481 MSE test 12.198023621912903\n",
      "MAE train 1.6505732445668833 MAE test 2.4466100666400092\n",
      "Epoch 3384 / 10000 loss: 14.76818037033081\n",
      "MSE train 5.695852356165186 MSE test 12.198013003415173\n",
      "MAE train 1.6505490642110348 MAE test 2.446613781359033\n",
      "Epoch 3385 / 10000 loss: 14.767683267593384\n",
      "MSE train 5.695710546255858 MSE test 12.197650522675161\n",
      "MAE train 1.650531779107569 MAE test 2.44656866723385\n",
      "Epoch 3386 / 10000 loss: 14.767114877700806\n",
      "MSE train 5.6955411668293845 MSE test 12.197671685220342\n",
      "MAE train 1.6504990800582544 MAE test 2.4465763908885707\n",
      "Epoch 3387 / 10000 loss: 14.766693115234375\n",
      "MSE train 5.695406447211894 MSE test 12.197472962397221\n",
      "MAE train 1.650479421139367 MAE test 2.44655183267978\n",
      "Epoch 3388 / 10000 loss: 14.765976428985596\n",
      "MSE train 5.695249389861373 MSE test 12.197319918214612\n",
      "MAE train 1.6504538577370893 MAE test 2.4465375508073564\n",
      "Epoch 3389 / 10000 loss: 14.765461206436157\n",
      "MSE train 5.695124909744996 MSE test 12.197180701218707\n",
      "MAE train 1.650435253300501 MAE test 2.4465205438855335\n",
      "Epoch 3390 / 10000 loss: 14.76490569114685\n",
      "MSE train 5.694971124376587 MSE test 12.196945106064508\n",
      "MAE train 1.6504124032139458 MAE test 2.446495907966752\n",
      "Epoch 3391 / 10000 loss: 14.764397621154785\n",
      "MSE train 5.694813605664298 MSE test 12.19683834735689\n",
      "MAE train 1.6503852504313994 MAE test 2.446483019606095\n",
      "Epoch 3392 / 10000 loss: 14.763916492462158\n",
      "MSE train 5.6946668568360055 MSE test 12.196765893868088\n",
      "MAE train 1.650360014806263 MAE test 2.4464788513957716\n",
      "Epoch 3393 / 10000 loss: 14.763258457183838\n",
      "MSE train 5.694521516842519 MSE test 12.196486067106147\n",
      "MAE train 1.6503399566581884 MAE test 2.446444089338957\n",
      "Epoch 3394 / 10000 loss: 14.762684345245361\n",
      "MSE train 5.694385159271197 MSE test 12.196472607910183\n",
      "MAE train 1.650315819431709 MAE test 2.4464474096246867\n",
      "Epoch 3395 / 10000 loss: 14.76218581199646\n",
      "MSE train 5.6942430679851075 MSE test 12.196109622238332\n",
      "MAE train 1.650298492646901 MAE test 2.446402236348436\n",
      "Epoch 3396 / 10000 loss: 14.761620044708252\n",
      "MSE train 5.694073606757568 MSE test 12.196129695357952\n",
      "MAE train 1.6502657785773174 MAE test 2.4464098106895404\n",
      "Epoch 3397 / 10000 loss: 14.761197805404663\n",
      "MSE train 5.693938370292434 MSE test 12.195928865621571\n",
      "MAE train 1.650246039197706 MAE test 2.4463849689572132\n",
      "Epoch 3398 / 10000 loss: 14.760481119155884\n",
      "MSE train 5.693781007957241 MSE test 12.195777162791288\n",
      "MAE train 1.6502203562396545 MAE test 2.4463708383200085\n",
      "Epoch 3399 / 10000 loss: 14.759965181350708\n",
      "MSE train 5.693656370640349 MSE test 12.195634995673329\n",
      "MAE train 1.6502017803713351 MAE test 2.4463534393109803\n",
      "Epoch 3400 / 10000 loss: 14.759406328201294\n",
      "MSE train 5.693502237716821 MSE test 12.195399120859912\n",
      "MAE train 1.6501788550377818 MAE test 2.4463287726352667\n",
      "Epoch 3401 / 10000 loss: 14.758899211883545\n",
      "MSE train 5.693344643629945 MSE test 12.195291841411745\n",
      "MAE train 1.650151694965606 MAE test 2.446315773205878\n",
      "Epoch 3402 / 10000 loss: 14.758416891098022\n",
      "MSE train 5.693196880206075 MSE test 12.195216355657779\n",
      "MAE train 1.650126287388381 MAE test 2.4463112053146783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3403 / 10000 loss: 14.75775933265686\n",
      "MSE train 5.693051132725781 MSE test 12.194940340293655\n",
      "MAE train 1.650106023177524 MAE test 2.4462769135344398\n",
      "Epoch 3404 / 10000 loss: 14.75718355178833\n",
      "MSE train 5.69291436770036 MSE test 12.194921751169094\n",
      "MAE train 1.6500819141295757 MAE test 2.4462795686326078\n",
      "Epoch 3405 / 10000 loss: 14.756681680679321\n",
      "MSE train 5.6927719209653755 MSE test 12.194560527415026\n",
      "MAE train 1.6500644701508658 MAE test 2.4462346016612675\n",
      "Epoch 3406 / 10000 loss: 14.756116151809692\n",
      "MSE train 5.692602655675732 MSE test 12.194580146966388\n",
      "MAE train 1.650031801843926 MAE test 2.4462420689798905\n",
      "Epoch 3407 / 10000 loss: 14.755690574645996\n",
      "MSE train 5.692465247915415 MSE test 12.194372958557867\n",
      "MAE train 1.6500116833963387 MAE test 2.4462164065665943\n",
      "Epoch 3408 / 10000 loss: 14.754974126815796\n",
      "MSE train 5.692307521003268 MSE test 12.194232863454022\n",
      "MAE train 1.6499856005516202 MAE test 2.4462037177282263\n",
      "Epoch 3409 / 10000 loss: 14.754454612731934\n",
      "MSE train 5.6921810829553685 MSE test 12.194077121654896\n",
      "MAE train 1.6499669179558578 MAE test 2.446184576765393\n",
      "Epoch 3410 / 10000 loss: 14.753886461257935\n",
      "MSE train 5.692026587446645 MSE test 12.193853854216746\n",
      "MAE train 1.6499436511779562 MAE test 2.4461614668118834\n",
      "Epoch 3411 / 10000 loss: 14.753381729125977\n",
      "MSE train 5.69187232067597 MSE test 12.193746059333542\n",
      "MAE train 1.6499172544193477 MAE test 2.446148367226021\n",
      "Epoch 3412 / 10000 loss: 14.752886056900024\n",
      "MSE train 5.691716699527363 MSE test 12.193637959215105\n",
      "MAE train 1.649890787034929 MAE test 2.446139658130871\n",
      "Epoch 3413 / 10000 loss: 14.752240419387817\n",
      "MSE train 5.691576710195283 MSE test 12.193426746116359\n",
      "MAE train 1.6498702103395082 MAE test 2.4461134936031765\n",
      "Epoch 3414 / 10000 loss: 14.751657485961914\n",
      "MSE train 5.691419957539944 MSE test 12.193308229880111\n",
      "MAE train 1.6498437859768826 MAE test 2.4461035062290173\n",
      "Epoch 3415 / 10000 loss: 14.751134395599365\n",
      "MSE train 5.691286669097519 MSE test 12.193127833704\n",
      "MAE train 1.6498241185338356 MAE test 2.446081230143383\n",
      "Epoch 3416 / 10000 loss: 14.75055480003357\n",
      "MSE train 5.691130286949592 MSE test 12.19295125754973\n",
      "MAE train 1.6497993519758767 MAE test 2.4460639779716766\n",
      "Epoch 3417 / 10000 loss: 14.750040054321289\n",
      "MSE train 5.69099758232486 MSE test 12.192830825859422\n",
      "MAE train 1.6497782939753807 MAE test 2.4460492414487667\n",
      "Epoch 3418 / 10000 loss: 14.749501943588257\n",
      "MSE train 5.690841445442532 MSE test 12.192608549511949\n",
      "MAE train 1.6497545994901208 MAE test 2.446026221136945\n",
      "Epoch 3419 / 10000 loss: 14.74894905090332\n",
      "MSE train 5.690687932766712 MSE test 12.192499493599168\n",
      "MAE train 1.6497283929623283 MAE test 2.4460129201056664\n",
      "Epoch 3420 / 10000 loss: 14.748446226119995\n",
      "MSE train 5.6905300534104954 MSE test 12.192380746886476\n",
      "MAE train 1.6497016550822912 MAE test 2.446002828584592\n",
      "Epoch 3421 / 10000 loss: 14.747803688049316\n",
      "MSE train 5.690393114397522 MSE test 12.192185608560683\n",
      "MAE train 1.6496814502618649 MAE test 2.445978654334\n",
      "Epoch 3422 / 10000 loss: 14.747217893600464\n",
      "MSE train 5.690234665285425 MSE test 12.192031779900008\n",
      "MAE train 1.6496555935785107 MAE test 2.4459642182729047\n",
      "Epoch 3423 / 10000 loss: 14.74669599533081\n",
      "MSE train 5.690107538050757 MSE test 12.191892363053856\n",
      "MAE train 1.6496364040999885 MAE test 2.445947044049204\n",
      "Epoch 3424 / 10000 loss: 14.746131896972656\n",
      "MSE train 5.689951569937368 MSE test 12.191651425507452\n",
      "MAE train 1.6496131573667934 MAE test 2.445921655410645\n",
      "Epoch 3425 / 10000 loss: 14.745614290237427\n",
      "MSE train 5.6897907770822425 MSE test 12.191543353453069\n",
      "MAE train 1.6495852997553166 MAE test 2.4459084540399685\n",
      "Epoch 3426 / 10000 loss: 14.745125532150269\n",
      "MSE train 5.6896422371414594 MSE test 12.191472300559782\n",
      "MAE train 1.6495596410415667 MAE test 2.4459043337069115\n",
      "Epoch 3427 / 10000 loss: 14.744453430175781\n",
      "MSE train 5.68949390487962 MSE test 12.191180264328905\n",
      "MAE train 1.6495392220802225 MAE test 2.4458679336847373\n",
      "Epoch 3428 / 10000 loss: 14.743869543075562\n",
      "MSE train 5.689353247075544 MSE test 12.191172237842316\n",
      "MAE train 1.64951395615667 MAE test 2.445871775301075\n",
      "Epoch 3429 / 10000 loss: 14.743365287780762\n",
      "MSE train 5.689207421308634 MSE test 12.190804405841048\n",
      "MAE train 1.6494958701211169 MAE test 2.445825853663325\n",
      "Epoch 3430 / 10000 loss: 14.742774963378906\n",
      "MSE train 5.689034218884044 MSE test 12.190822209245\n",
      "MAE train 1.649462377843567 MAE test 2.445832964803355\n",
      "Epoch 3431 / 10000 loss: 14.74233865737915\n",
      "MSE train 5.688894967865622 MSE test 12.190618707854965\n",
      "MAE train 1.6494418040928447 MAE test 2.4458076128071013\n",
      "Epoch 3432 / 10000 loss: 14.74160623550415\n",
      "MSE train 5.688733403773514 MSE test 12.190462537159682\n",
      "MAE train 1.6494152841306937 MAE test 2.4457927744783063\n",
      "Epoch 3433 / 10000 loss: 14.7410728931427\n",
      "MSE train 5.68860419145239 MSE test 12.190318467726499\n",
      "MAE train 1.6493957365328935 MAE test 2.4457749088206944\n",
      "Epoch 3434 / 10000 loss: 14.74049711227417\n",
      "MSE train 5.68844548109325 MSE test 12.190077313498971\n",
      "MAE train 1.6493718911722128 MAE test 2.4457493962338286\n",
      "Epoch 3435 / 10000 loss: 14.739970207214355\n",
      "MSE train 5.688282409162561 MSE test 12.189968093096493\n",
      "MAE train 1.6493435866283632 MAE test 2.4457359345842877\n",
      "Epoch 3436 / 10000 loss: 14.739468812942505\n",
      "MSE train 5.688129773546472 MSE test 12.189890854712164\n",
      "MAE train 1.649317142424587 MAE test 2.4457309288751357\n",
      "Epoch 3437 / 10000 loss: 14.738786458969116\n",
      "MSE train 5.687978323279265 MSE test 12.189606871536164\n",
      "MAE train 1.6492958241360907 MAE test 2.445695428760207\n",
      "Epoch 3438 / 10000 loss: 14.73818826675415\n",
      "MSE train 5.687835340605266 MSE test 12.189589306162823\n",
      "MAE train 1.6492703213271362 MAE test 2.445697918256926\n",
      "Epoch 3439 / 10000 loss: 14.737663269042969\n",
      "MSE train 5.6876864789286845 MSE test 12.189220021638295\n",
      "MAE train 1.6492516256296568 MAE test 2.445651679252109\n",
      "Epoch 3440 / 10000 loss: 14.73706865310669\n",
      "MSE train 5.687509326285731 MSE test 12.18923669511227\n",
      "MAE train 1.6492173112112918 MAE test 2.445658506186145\n",
      "Epoch 3441 / 10000 loss: 14.73661756515503\n",
      "MSE train 5.687366366758598 MSE test 12.18903247567038\n",
      "MAE train 1.64919595754996 MAE test 2.445632905122016\n",
      "Epoch 3442 / 10000 loss: 14.735867261886597\n",
      "MSE train 5.687200673742767 MSE test 12.188872697897546\n",
      "MAE train 1.6491686476336582 MAE test 2.4456174518454157\n",
      "Epoch 3443 / 10000 loss: 14.73531699180603\n",
      "MSE train 5.6870668842192025 MSE test 12.188728634957794\n",
      "MAE train 1.6491481171750566 MAE test 2.4455994174326507\n",
      "Epoch 3444 / 10000 loss: 14.734723329544067\n",
      "MSE train 5.6869034455539955 MSE test 12.188484424732275\n",
      "MAE train 1.6491233456756689 MAE test 2.445573359860336\n",
      "Epoch 3445 / 10000 loss: 14.734175205230713\n",
      "MSE train 5.686735095413235 MSE test 12.18837318276183\n",
      "MAE train 1.6490939486579617 MAE test 2.4455594639525446\n",
      "Epoch 3446 / 10000 loss: 14.73365306854248\n",
      "MSE train 5.686577521728374 MSE test 12.188295603721931\n",
      "MAE train 1.649066473222014 MAE test 2.445554221921407\n",
      "Epoch 3447 / 10000 loss: 14.73294734954834\n",
      "MSE train 5.686420379342144 MSE test 12.188005459377377\n",
      "MAE train 1.649044100617619 MAE test 2.4455177513645836\n",
      "Epoch 3448 / 10000 loss: 14.732325553894043\n",
      "MSE train 5.686271090630879 MSE test 12.1879888981227\n",
      "MAE train 1.6490172171534956 MAE test 2.4455201578956203\n",
      "Epoch 3449 / 10000 loss: 14.73177695274353\n",
      "MSE train 5.686115827409377 MSE test 12.187615672551212\n",
      "MAE train 1.648997233428814 MAE test 2.4454732149291156\n",
      "Epoch 3450 / 10000 loss: 14.731151819229126\n",
      "MSE train 5.685931730203208 MSE test 12.187629838898028\n",
      "MAE train 1.6489614918666076 MAE test 2.4454794971981326\n",
      "Epoch 3451 / 10000 loss: 14.73067307472229\n",
      "MSE train 5.685782261742606 MSE test 12.187425077560933\n",
      "MAE train 1.6489387955944015 MAE test 2.445453612415677\n",
      "Epoch 3452 / 10000 loss: 14.729891538619995\n",
      "MSE train 5.6856092847796615 MSE test 12.187257345411243\n",
      "MAE train 1.648910129160137 MAE test 2.4454369437028705\n",
      "Epoch 3453 / 10000 loss: 14.729309320449829\n",
      "MSE train 5.685467243297438 MSE test 12.187114758015747\n",
      "MAE train 1.6488877982084456 MAE test 2.4454188277088735\n",
      "Epoch 3454 / 10000 loss: 14.728686571121216\n",
      "MSE train 5.685295648611772 MSE test 12.186866363382594\n",
      "MAE train 1.6488613505360472 MAE test 2.445391969367866\n",
      "Epoch 3455 / 10000 loss: 14.728098630905151\n",
      "MSE train 5.685118901174121 MSE test 12.186752087912307\n",
      "MAE train 1.6488302001816508 MAE test 2.4453774249850344\n",
      "Epoch 3456 / 10000 loss: 14.727539300918579\n",
      "MSE train 5.684953042973877 MSE test 12.186671876608191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.64880097094863 MAE test 2.4453715852896134\n",
      "Epoch 3457 / 10000 loss: 14.726796627044678\n",
      "MSE train 5.684787289022804 MSE test 12.186376380392469\n",
      "MAE train 1.6487768400290683 MAE test 2.4453341758255327\n",
      "Epoch 3458 / 10000 loss: 14.72613525390625\n",
      "MSE train 5.684629025449447 MSE test 12.18635797984496\n",
      "MAE train 1.648748023884583 MAE test 2.445336044487841\n",
      "Epoch 3459 / 10000 loss: 14.725549221038818\n",
      "MSE train 5.684464903635597 MSE test 12.185981029018693\n",
      "MAE train 1.6487261992377344 MAE test 2.445288341180567\n",
      "Epoch 3460 / 10000 loss: 14.724882125854492\n",
      "MSE train 5.684272144206771 MSE test 12.185991540362915\n",
      "MAE train 1.6486886435638188 MAE test 2.4452938439781264\n",
      "Epoch 3461 / 10000 loss: 14.724362850189209\n",
      "MSE train 5.684114120304352 MSE test 12.185783144168436\n",
      "MAE train 1.6486641423906927 MAE test 2.4452671824964147\n",
      "Epoch 3462 / 10000 loss: 14.723540782928467\n",
      "MSE train 5.683932997493782 MSE test 12.185611694019236\n",
      "MAE train 1.648633723990852 MAE test 2.4452497650291187\n",
      "Epoch 3463 / 10000 loss: 14.722919225692749\n",
      "MSE train 5.683783158283769 MSE test 12.185465374315909\n",
      "MAE train 1.6486096867514008 MAE test 2.4452308978002093\n",
      "Epoch 3464 / 10000 loss: 14.722258567810059\n",
      "MSE train 5.683604511793432 MSE test 12.185213315408934\n",
      "MAE train 1.6485817021039209 MAE test 2.4452032957929983\n",
      "Epoch 3465 / 10000 loss: 14.72163462638855\n",
      "MSE train 5.6834212653380884 MSE test 12.185095623508152\n",
      "MAE train 1.6485491718559784 MAE test 2.4451880242921096\n",
      "Epoch 3466 / 10000 loss: 14.72104263305664\n",
      "MSE train 5.683249873374171 MSE test 12.18501221519044\n",
      "MAE train 1.6485187775346954 MAE test 2.4451814808147767\n",
      "Epoch 3467 / 10000 loss: 14.720269441604614\n",
      "MSE train 5.6830795155061775 MSE test 12.184713069481228\n",
      "MAE train 1.6484936522771159 MAE test 2.445143338131713\n",
      "Epoch 3468 / 10000 loss: 14.719581365585327\n",
      "MSE train 5.682917554517508 MSE test 12.184692373942932\n",
      "MAE train 1.6484640361964473 MAE test 2.4451446530397076\n",
      "Epoch 3469 / 10000 loss: 14.71897268295288\n",
      "MSE train 5.68275093617617 MSE test 12.18431308405655\n",
      "MAE train 1.6484416787679586 MAE test 2.4450964191820446\n",
      "Epoch 3470 / 10000 loss: 14.71828818321228\n",
      "MSE train 5.682556874297417 MSE test 12.184321517342935\n",
      "MAE train 1.648403883592241 MAE test 2.445101446750738\n",
      "Epoch 3471 / 10000 loss: 14.717756032943726\n",
      "MSE train 5.682398806760099 MSE test 12.184111601389187\n",
      "MAE train 1.648379405523874 MAE test 2.445074428452184\n",
      "Epoch 3472 / 10000 loss: 14.716925621032715\n",
      "MSE train 5.6822189381185515 MSE test 12.183939550416428\n",
      "MAE train 1.648349295404843 MAE test 2.445056777602592\n",
      "Epoch 3473 / 10000 loss: 14.71630334854126\n",
      "MSE train 5.682071524236365 MSE test 12.183793085293777\n",
      "MAE train 1.6483258778681062 MAE test 2.4450378091345684\n",
      "Epoch 3474 / 10000 loss: 14.71564507484436\n",
      "MSE train 5.68189652891407 MSE test 12.183541683911644\n",
      "MAE train 1.6482987365519886 MAE test 2.445010252385598\n",
      "Epoch 3475 / 10000 loss: 14.71502947807312\n",
      "MSE train 5.681717894874292 MSE test 12.183425497917192\n",
      "MAE train 1.6482672401717533 MAE test 2.444995192866013\n",
      "Epoch 3476 / 10000 loss: 14.714451313018799\n",
      "MSE train 5.681552133350051 MSE test 12.183344525909368\n",
      "MAE train 1.6482380863264896 MAE test 2.444989028314196\n",
      "Epoch 3477 / 10000 loss: 14.713695287704468\n",
      "MSE train 5.6813883342453675 MSE test 12.183048579551313\n",
      "MAE train 1.6482144338795484 MAE test 2.444951430818601\n",
      "Epoch 3478 / 10000 loss: 14.713030099868774\n",
      "MSE train 5.681233623946968 MSE test 12.183031667954415\n",
      "MAE train 1.648186355495867 MAE test 2.4449534360888747\n",
      "Epoch 3479 / 10000 loss: 14.712448596954346\n",
      "MSE train 5.6810749284843 MSE test 12.182657189792684\n",
      "MAE train 1.6481656917459968 MAE test 2.444906087216404\n",
      "Epoch 3480 / 10000 loss: 14.711792707443237\n",
      "MSE train 5.680889084863461 MSE test 12.18267121800859\n",
      "MAE train 1.6481296581612936 MAE test 2.4449121451265294\n",
      "Epoch 3481 / 10000 loss: 14.711291551589966\n",
      "MSE train 5.680739557698547 MSE test 12.182467510206758\n",
      "MAE train 1.6481070528831965 MAE test 2.4448862623659404\n",
      "Epoch 3482 / 10000 loss: 14.710495233535767\n",
      "MSE train 5.680568222234809 MSE test 12.18230211380292\n",
      "MAE train 1.648078881087188 MAE test 2.4448698560399764\n",
      "Epoch 3483 / 10000 loss: 14.709906339645386\n",
      "MSE train 5.680429282605324 MSE test 12.182162936345064\n",
      "MAE train 1.6480574252758322 MAE test 2.4448521964938785\n",
      "Epoch 3484 / 10000 loss: 14.709283113479614\n",
      "MSE train 5.680262629913192 MSE test 12.181918682307366\n",
      "MAE train 1.6480322277102786 MAE test 2.4448259699050476\n",
      "Epoch 3485 / 10000 loss: 14.708701372146606\n",
      "MSE train 5.680092196924126 MSE test 12.18181004669744\n",
      "MAE train 1.6480027011979064 MAE test 2.444812300676259\n",
      "Epoch 3486 / 10000 loss: 14.708157777786255\n",
      "MSE train 5.6799343859706335 MSE test 12.181736138482602\n",
      "MAE train 1.6479754558909803 MAE test 2.444807491150006\n",
      "Epoch 3487 / 10000 loss: 14.707433938980103\n",
      "MSE train 5.67977820502558 MSE test 12.181447821298772\n",
      "MAE train 1.6479536779296693 MAE test 2.4447713210202355\n",
      "Epoch 3488 / 10000 loss: 14.706800937652588\n",
      "MSE train 5.679631090692974 MSE test 12.181437802862492\n",
      "MAE train 1.6479275373920228 MAE test 2.4447746543213986\n",
      "Epoch 3489 / 10000 loss: 14.706250190734863\n",
      "MSE train 5.679479920508689 MSE test 12.181069954433289\n",
      "MAE train 1.6479088154257355 MAE test 2.444728576070448\n",
      "Epoch 3490 / 10000 loss: 14.705625295639038\n",
      "MSE train 5.679301784642152 MSE test 12.181090030797277\n",
      "MAE train 1.647874659232267 MAE test 2.444735852222384\n",
      "Epoch 3491 / 10000 loss: 14.705156087875366\n",
      "MSE train 5.679160095614996 MSE test 12.180891818538305\n",
      "MAE train 1.6478538677434644 MAE test 2.4447111048375367\n",
      "Epoch 3492 / 10000 loss: 14.704392910003662\n",
      "MSE train 5.678997052893904 MSE test 12.180731480901603\n",
      "MAE train 1.6478275136732945 MAE test 2.444695748670278\n",
      "Epoch 3493 / 10000 loss: 14.703837633132935\n",
      "MSE train 5.678866855028562 MSE test 12.180596383955324\n",
      "MAE train 1.6478078875804056 MAE test 2.4446790532128695\n",
      "Epoch 3494 / 10000 loss: 14.703250885009766\n",
      "MSE train 5.678709359611858 MSE test 12.180355954724\n",
      "MAE train 1.6477845755689575 MAE test 2.4446537437377036\n",
      "Epoch 3495 / 10000 loss: 14.702708721160889\n",
      "MSE train 5.678548498915243 MSE test 12.180250460326933\n",
      "MAE train 1.647756881756741 MAE test 2.4446409019969173\n",
      "Epoch 3496 / 10000 loss: 14.702205896377563\n",
      "MSE train 5.678400516068326 MSE test 12.18017932672871\n",
      "MAE train 1.6477314568814596 MAE test 2.4446368714906144\n",
      "Epoch 3497 / 10000 loss: 14.70152735710144\n",
      "MSE train 5.678254373623256 MSE test 12.179893129803212\n",
      "MAE train 1.6477114380972984 MAE test 2.4446013842062433\n",
      "Epoch 3498 / 10000 loss: 14.700939655303955\n",
      "MSE train 5.678117131540997 MSE test 12.179884944070706\n",
      "MAE train 1.647686940978429 MAE test 2.4446053473822333\n",
      "Epoch 3499 / 10000 loss: 14.700434446334839\n",
      "MSE train 5.677975546001447 MSE test 12.179518824000798\n",
      "MAE train 1.6476697556658058 MAE test 2.4445599048735027\n",
      "Epoch 3500 / 10000 loss: 14.69985580444336\n",
      "MSE train 5.677806580330746 MSE test 12.179540124014773\n",
      "MAE train 1.647637023912859 MAE test 2.44456771662711\n",
      "Epoch 3501 / 10000 loss: 14.699431896209717\n",
      "MSE train 5.677673328494408 MSE test 12.179343214966082\n",
      "MAE train 1.6476175489404277 MAE test 2.4445435101886046\n",
      "Epoch 3502 / 10000 loss: 14.698711156845093\n",
      "MSE train 5.677517974712479 MSE test 12.179184359245388\n",
      "MAE train 1.6475923616505106 MAE test 2.4445287144411605\n",
      "Epoch 3503 / 10000 loss: 14.69819712638855\n",
      "MSE train 5.677394609763955 MSE test 12.17905019173891\n",
      "MAE train 1.647573727060138 MAE test 2.4445124701534255\n",
      "Epoch 3504 / 10000 loss: 14.697645664215088\n",
      "MSE train 5.6772430723238365 MSE test 12.178810837974194\n",
      "MAE train 1.64755124778917 MAE test 2.4444876165231832\n",
      "Epoch 3505 / 10000 loss: 14.697136163711548\n",
      "MSE train 5.677087233768698 MSE test 12.17870665461316\n",
      "MAE train 1.6475242498457947 MAE test 2.444475253893399\n",
      "Epoch 3506 / 10000 loss: 14.696662425994873\n",
      "MSE train 5.676943465218756 MSE test 12.178636740032395\n",
      "MAE train 1.647499401298833 MAE test 2.4444716426216866\n",
      "Epoch 3507 / 10000 loss: 14.696006298065186\n",
      "MSE train 5.676800817695857 MSE test 12.178351831443496\n",
      "MAE train 1.6474799062000578 MAE test 2.444436576758399\n",
      "Epoch 3508 / 10000 loss: 14.695439100265503\n",
      "MSE train 5.676666483849257 MSE test 12.17834488299054\n",
      "MAE train 1.6474558182274897 MAE test 2.4444409436835577\n",
      "Epoch 3509 / 10000 loss: 14.694951057434082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.67652737399822 MSE test 12.177980043467777\n",
      "MAE train 1.6474389759382841 MAE test 2.444395874697385\n",
      "Epoch 3510 / 10000 loss: 14.694387197494507\n",
      "MSE train 5.676360447649344 MSE test 12.178002485548177\n",
      "MAE train 1.6474065194812246 MAE test 2.444404030148554\n",
      "Epoch 3511 / 10000 loss: 14.693973779678345\n",
      "MSE train 5.6762288725437 MSE test 12.1778068760257\n",
      "MAE train 1.6473872883119942 MAE test 2.444380173630788\n",
      "Epoch 3512 / 10000 loss: 14.693263292312622\n",
      "MSE train 5.676074901787682 MSE test 12.177648605739414\n",
      "MAE train 1.6473623033358982 MAE test 2.4443656184129656\n",
      "Epoch 3513 / 10000 loss: 14.692756652832031\n",
      "MSE train 5.675952687708513 MSE test 12.177515951670554\n",
      "MAE train 1.6473438101752 MAE test 2.4443497044119953\n",
      "Epoch 3514 / 10000 loss: 14.69221305847168\n",
      "MSE train 5.675802150596849 MSE test 12.177277540588797\n",
      "MAE train 1.6473214636270064 MAE test 2.4443250956101967\n",
      "Epoch 3515 / 10000 loss: 14.691708326339722\n",
      "MSE train 5.675647240358717 MSE test 12.177174575878821\n",
      "MAE train 1.6472946020926154 MAE test 2.4443130139190674\n",
      "Epoch 3516 / 10000 loss: 14.691239356994629\n",
      "MSE train 5.675504157345205 MSE test 12.17710512184128\n",
      "MAE train 1.6472698482220502 MAE test 2.4443095787897633\n",
      "Epoch 3517 / 10000 loss: 14.690587520599365\n",
      "MSE train 5.675362136730229 MSE test 12.176821423572212\n",
      "MAE train 1.64725043476405 MAE test 2.4442747656913966\n",
      "Epoch 3518 / 10000 loss: 14.690024137496948\n",
      "MSE train 5.675228462959743 MSE test 12.176814780838468\n",
      "MAE train 1.6472264440216942 MAE test 2.444279243501078\n",
      "Epoch 3519 / 10000 loss: 14.689540386199951\n",
      "MSE train 5.675089832870962 MSE test 12.176450739874864\n",
      "MAE train 1.6472096715629436 MAE test 2.444234350482968\n",
      "Epoch 3520 / 10000 loss: 14.688979387283325\n",
      "MSE train 5.6749233902685265 MSE test 12.17647378105563\n",
      "MAE train 1.6471772924850696 MAE test 2.444242676750568\n",
      "Epoch 3521 / 10000 loss: 14.68856954574585\n",
      "MSE train 5.6747921935113155 MSE test 12.17627871920277\n",
      "MAE train 1.647158109152161 MAE test 2.444218948275503\n",
      "Epoch 3522 / 10000 loss: 14.68786096572876\n",
      "MSE train 5.6746385938419115 MSE test 12.176121166185684\n",
      "MAE train 1.6471331675819323 MAE test 2.4442045331932967\n",
      "Epoch 3523 / 10000 loss: 14.687355995178223\n",
      "MSE train 5.674516760604883 MSE test 12.175988605745667\n",
      "MAE train 1.6471147559157258 MAE test 2.4441886862218896\n",
      "Epoch 3524 / 10000 loss: 14.686814308166504\n",
      "MSE train 5.674366551291528 MSE test 12.175750671145826\n",
      "MAE train 1.6470924578530985 MAE test 2.444164184875597\n",
      "Epoch 3525 / 10000 loss: 14.686311960220337\n",
      "MSE train 5.674211833850097 MSE test 12.175647808433153\n",
      "MAE train 1.6470656325378126 MAE test 2.4441521734348424\n",
      "Epoch 3526 / 10000 loss: 14.68584418296814\n",
      "MSE train 5.674069039359828 MSE test 12.175578645171905\n",
      "MAE train 1.64704092402438 MAE test 2.444148808074958\n",
      "Epoch 3527 / 10000 loss: 14.685195207595825\n",
      "MSE train 5.673927241128713 MSE test 12.175295261383832\n",
      "MAE train 1.6470215426152963 MAE test 2.4441140688521337\n",
      "Epoch 3528 / 10000 loss: 14.684632301330566\n",
      "MSE train 5.673793716997986 MSE test 12.175288600084018\n",
      "MAE train 1.6469975871851412 MAE test 2.4441185941110772\n",
      "Epoch 3529 / 10000 loss: 14.684149742126465\n",
      "MSE train 5.673655272999674 MSE test 12.174924710425202\n",
      "MAE train 1.6469808455402937 MAE test 2.4440737510492756\n",
      "Epoch 3530 / 10000 loss: 14.683589935302734\n",
      "MSE train 5.673488882256915 MSE test 12.174947837932713\n",
      "MAE train 1.6469484673868267 MAE test 2.444082110295739\n",
      "Epoch 3531 / 10000 loss: 14.683181047439575\n",
      "MSE train 5.673357782545573 MSE test 12.174752976600361\n",
      "MAE train 1.6469293091706327 MAE test 2.4440584316958915\n",
      "Epoch 3532 / 10000 loss: 14.682472944259644\n",
      "MSE train 5.6732043024550025 MSE test 12.174595477913497\n",
      "MAE train 1.6469043774997612 MAE test 2.444044051142072\n",
      "Epoch 3533 / 10000 loss: 14.681970357894897\n",
      "MSE train 5.673082442859242 MSE test 12.17446304414593\n",
      "MAE train 1.646885967561458 MAE test 2.4440282498569315\n",
      "Epoch 3534 / 10000 loss: 14.681429147720337\n",
      "MSE train 5.672932289362825 MSE test 12.174225139539402\n",
      "MAE train 1.6468636592710197 MAE test 2.444003770079775\n",
      "Epoch 3535 / 10000 loss: 14.680927515029907\n",
      "MSE train 5.672777684010144 MSE test 12.174122404465306\n",
      "MAE train 1.6468368628892494 MAE test 2.443991796223596\n",
      "Epoch 3536 / 10000 loss: 14.680460929870605\n",
      "MSE train 5.672634839537669 MSE test 12.174053039099137\n",
      "MAE train 1.6468121467552657 MAE test 2.4439884282110174\n",
      "Epoch 3537 / 10000 loss: 14.67981243133545\n",
      "MSE train 5.6724930131464335 MSE test 12.17377005323579\n",
      "MAE train 1.646792759418607 MAE test 2.443953754577405\n",
      "Epoch 3538 / 10000 loss: 14.679250240325928\n",
      "MSE train 5.672359550608458 MSE test 12.17376324448931\n",
      "MAE train 1.646768810565351 MAE test 2.443958258657364\n",
      "Epoch 3539 / 10000 loss: 14.678767442703247\n",
      "MSE train 5.672221060498228 MSE test 12.173399503018214\n",
      "MAE train 1.6467520597598244 MAE test 2.443913452529747\n",
      "Epoch 3540 / 10000 loss: 14.678208351135254\n",
      "MSE train 5.672054712168747 MSE test 12.173422571982977\n",
      "MAE train 1.6467196937047475 MAE test 2.4439218152635727\n",
      "Epoch 3541 / 10000 loss: 14.677799463272095\n",
      "MSE train 5.6719235729696145 MSE test 12.173227443004032\n",
      "MAE train 1.6467005317529204 MAE test 2.443898124571058\n",
      "Epoch 3542 / 10000 loss: 14.677093029022217\n",
      "MSE train 5.6717700251784455 MSE test 12.173070307623234\n",
      "MAE train 1.64667557827798 MAE test 2.4438837927789447\n",
      "Epoch 3543 / 10000 loss: 14.676589965820312\n",
      "MSE train 5.671648194833021 MSE test 12.172937622056327\n",
      "MAE train 1.6466571812406463 MAE test 2.4438679782908963\n",
      "Epoch 3544 / 10000 loss: 14.676048278808594\n",
      "MSE train 5.671497939307128 MSE test 12.172699656765534\n",
      "MAE train 1.646634851249341 MAE test 2.443843501180016\n",
      "Epoch 3545 / 10000 loss: 14.67554783821106\n",
      "MSE train 5.671343251705213 MSE test 12.17259684339192\n",
      "MAE train 1.6466080463951407 MAE test 2.443831526639234\n",
      "Epoch 3546 / 10000 loss: 14.675081253051758\n",
      "MSE train 5.671200361409436 MSE test 12.172527532704748\n",
      "MAE train 1.646583310797584 MAE test 2.4438281711300216\n",
      "Epoch 3547 / 10000 loss: 14.674432754516602\n",
      "MSE train 5.6710584437088825 MSE test 12.17224479162675\n",
      "MAE train 1.646563902453355 MAE test 2.4437935444641763\n",
      "Epoch 3548 / 10000 loss: 14.673871278762817\n",
      "MSE train 5.670924882446293 MSE test 12.172237705640253\n",
      "MAE train 1.6465399398945035 MAE test 2.4437980393452454\n",
      "Epoch 3549 / 10000 loss: 14.6733877658844\n",
      "MSE train 5.670786320092777 MSE test 12.171874061090074\n",
      "MAE train 1.646523177737133 MAE test 2.4437532516848024\n",
      "Epoch 3550 / 10000 loss: 14.672829151153564\n",
      "MSE train 5.670619849654651 MSE test 12.171897176486052\n",
      "MAE train 1.6464907850072754 MAE test 2.4437616260160824\n",
      "Epoch 3551 / 10000 loss: 14.672420740127563\n",
      "MSE train 5.670488505656465 MSE test 12.171701928799685\n",
      "MAE train 1.6464715978664226 MAE test 2.443737923444097\n",
      "Epoch 3552 / 10000 loss: 14.67171335220337\n",
      "MSE train 5.670334858269097 MSE test 12.171544994788801\n",
      "MAE train 1.646446617623607 MAE test 2.443723634377476\n",
      "Epoch 3553 / 10000 loss: 14.671209812164307\n",
      "MSE train 5.670212941009179 MSE test 12.171412295651642\n",
      "MAE train 1.6464282136583714 MAE test 2.4437078225866005\n",
      "Epoch 3554 / 10000 loss: 14.670669317245483\n",
      "MSE train 5.670062603803099 MSE test 12.171174466268601\n",
      "MAE train 1.64640586169517 MAE test 2.4436833770922903\n",
      "Epoch 3555 / 10000 loss: 14.670168399810791\n",
      "MSE train 5.6699076718006065 MSE test 12.17107169272308\n",
      "MAE train 1.6463790268699594 MAE test 2.4436714063415694\n",
      "Epoch 3556 / 10000 loss: 14.66970181465149\n",
      "MSE train 5.669764614519799 MSE test 12.171002241191266\n",
      "MAE train 1.6463542638879538 MAE test 2.4436680525520944\n",
      "Epoch 3557 / 10000 loss: 14.66905164718628\n",
      "MSE train 5.669622545756596 MSE test 12.1707195890511\n",
      "MAE train 1.6463348343880042 MAE test 2.4436334267370303\n",
      "Epoch 3558 / 10000 loss: 14.668489933013916\n",
      "MSE train 5.669488815998651 MSE test 12.170712468548281\n",
      "MAE train 1.6463108493228706 MAE test 2.4436379274066433\n",
      "Epoch 3559 / 10000 loss: 14.668007612228394\n",
      "MSE train 5.669350012360016 MSE test 12.170348834321787\n",
      "MAE train 1.6462940425193113 MAE test 2.4435931400116524\n",
      "Epoch 3560 / 10000 loss: 14.66744875907898\n",
      "MSE train 5.669183387444331 MSE test 12.170371888982727\n",
      "MAE train 1.646261633177849 MAE test 2.4436015261694926\n",
      "Epoch 3561 / 10000 loss: 14.667039394378662\n",
      "MSE train 5.669051862197515 MSE test 12.17017686900421\n",
      "MAE train 1.6462424115357874 MAE test 2.443577859938887\n",
      "Epoch 3562 / 10000 loss: 14.666332006454468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.668897961526911 MSE test 12.170020091369247\n",
      "MAE train 1.6462173909277584 MAE test 2.443563590951315\n",
      "Epoch 3563 / 10000 loss: 14.665827751159668\n",
      "MSE train 5.668775835738044 MSE test 12.16988714180269\n",
      "MAE train 1.6461989602884686 MAE test 2.443547754673133\n",
      "Epoch 3564 / 10000 loss: 14.665286540985107\n",
      "MSE train 5.6686252167898 MSE test 12.16964942659734\n",
      "MAE train 1.6461765467564515 MAE test 2.4435233224395807\n",
      "Epoch 3565 / 10000 loss: 14.664785623550415\n",
      "MSE train 5.668470133445882 MSE test 12.169546736190929\n",
      "MAE train 1.6461496949887358 MAE test 2.4435113740613086\n",
      "Epoch 3566 / 10000 loss: 14.664317607879639\n",
      "MSE train 5.66832672551765 MSE test 12.16947709954905\n",
      "MAE train 1.6461248750534034 MAE test 2.443507988559915\n",
      "Epoch 3567 / 10000 loss: 14.663667917251587\n",
      "MSE train 5.668184336049681 MSE test 12.169195015620266\n",
      "MAE train 1.64610538573781 MAE test 2.443473447175023\n",
      "Epoch 3568 / 10000 loss: 14.663105010986328\n",
      "MSE train 5.668050404922784 MSE test 12.169187558756182\n",
      "MAE train 1.646081379292772 MAE test 2.4434779123512733\n",
      "Epoch 3569 / 10000 loss: 14.66262149810791\n",
      "MSE train 5.667911273396917 MSE test 12.168824307085247\n",
      "MAE train 1.6460645073776017 MAE test 2.443433183308799\n",
      "Epoch 3570 / 10000 loss: 14.6620614528656\n",
      "MSE train 5.667744387906667 MSE test 12.168847304866363\n",
      "MAE train 1.6460320631157614 MAE test 2.443441547162854\n",
      "Epoch 3571 / 10000 loss: 14.661651611328125\n",
      "MSE train 5.667612440892061 MSE test 12.16865205775095\n",
      "MAE train 1.6460127774702578 MAE test 2.443417863591038\n",
      "Epoch 3572 / 10000 loss: 14.660943269729614\n",
      "MSE train 5.667458271705359 MSE test 12.168495934656946\n",
      "MAE train 1.645987691591344 MAE test 2.4434036858670396\n",
      "Epoch 3573 / 10000 loss: 14.660439014434814\n",
      "MSE train 5.667335820819458 MSE test 12.168362671602457\n",
      "MAE train 1.6459692296323651 MAE test 2.44338781938929\n",
      "Epoch 3574 / 10000 loss: 14.659894943237305\n",
      "MSE train 5.667184856818829 MSE test 12.168125058852537\n",
      "MAE train 1.6459467504254481 MAE test 2.4433634007670935\n",
      "Epoch 3575 / 10000 loss: 14.659394264221191\n",
      "MSE train 5.667029442285894 MSE test 12.168022607181813\n",
      "MAE train 1.6459198549495537 MAE test 2.443351492756679\n",
      "Epoch 3576 / 10000 loss: 14.658926010131836\n",
      "MSE train 5.666885572105511 MSE test 12.167952978603779\n",
      "MAE train 1.6458949613178953 MAE test 2.443348111971032\n",
      "Epoch 3577 / 10000 loss: 14.658275604248047\n",
      "MSE train 5.666742829436357 MSE test 12.167671338584407\n",
      "MAE train 1.6458754080433755 MAE test 2.4433136321552937\n",
      "Epoch 3578 / 10000 loss: 14.65771198272705\n",
      "MSE train 5.666608475569457 MSE test 12.167663814978606\n",
      "MAE train 1.6458513435581843 MAE test 2.4433180917646915\n",
      "Epoch 3579 / 10000 loss: 14.657225131988525\n",
      "MSE train 5.666468978360328 MSE test 12.167300691994138\n",
      "MAE train 1.6458344154238707 MAE test 2.4432733849196073\n",
      "Epoch 3580 / 10000 loss: 14.656665086746216\n",
      "MSE train 5.666301625485578 MSE test 12.167323906008063\n",
      "MAE train 1.6458019046348815 MAE test 2.443281798657749\n",
      "Epoch 3581 / 10000 loss: 14.656253576278687\n",
      "MSE train 5.6661692541349 MSE test 12.167128861600272\n",
      "MAE train 1.645782558922276 MAE test 2.4432581340002\n",
      "Epoch 3582 / 10000 loss: 14.655545473098755\n",
      "MSE train 5.666014615131019 MSE test 12.166972785511502\n",
      "MAE train 1.6457574008497524 MAE test 2.4432439642075496\n",
      "Epoch 3583 / 10000 loss: 14.655039072036743\n",
      "MSE train 5.665891607460573 MSE test 12.166839723929115\n",
      "MAE train 1.645738864037207 MAE test 2.443228124913692\n",
      "Epoch 3584 / 10000 loss: 14.654494047164917\n",
      "MSE train 5.665740143560005 MSE test 12.166602451449736\n",
      "MAE train 1.645716302082893 MAE test 2.443203761472525\n",
      "Epoch 3585 / 10000 loss: 14.653991460800171\n",
      "MSE train 5.665584183468015 MSE test 12.166500220050942\n",
      "MAE train 1.6456893403959996 MAE test 2.443191879163755\n",
      "Epoch 3586 / 10000 loss: 14.653520584106445\n",
      "MSE train 5.6654398066148755 MSE test 12.166430669376021\n",
      "MAE train 1.6456643685475814 MAE test 2.443188520438173\n",
      "Epoch 3587 / 10000 loss: 14.652868747711182\n",
      "MSE train 5.665296467320755 MSE test 12.1661496011112\n",
      "MAE train 1.6456447239377539 MAE test 2.44315410609263\n",
      "Epoch 3588 / 10000 loss: 14.65230417251587\n",
      "MSE train 5.665161539245946 MSE test 12.166142028241248\n",
      "MAE train 1.6456205797495924 MAE test 2.443158581924217\n",
      "Epoch 3589 / 10000 loss: 14.651814937591553\n",
      "MSE train 5.6650214200502775 MSE test 12.165779379439472\n",
      "MAE train 1.6456035499308304 MAE test 2.4431139302293925\n",
      "Epoch 3590 / 10000 loss: 14.65125322341919\n",
      "MSE train 5.664853495840523 MSE test 12.1658027089323\n",
      "MAE train 1.6455709533406093 MAE test 2.4431223533938495\n",
      "Epoch 3591 / 10000 loss: 14.650839567184448\n",
      "MSE train 5.664720378979793 MSE test 12.165607791962131\n",
      "MAE train 1.6455515006832446 MAE test 2.4430987228471683\n",
      "Epoch 3592 / 10000 loss: 14.65012812614441\n",
      "MSE train 5.664565029498082 MSE test 12.165452583912247\n",
      "MAE train 1.6455262154168813 MAE test 2.4430846573081975\n",
      "Epoch 3593 / 10000 loss: 14.649619102478027\n",
      "MSE train 5.664441455961286 MSE test 12.165319494850193\n",
      "MAE train 1.6455076155449186 MAE test 2.4430688231736193\n",
      "Epoch 3594 / 10000 loss: 14.64907193183899\n",
      "MSE train 5.664289271836652 MSE test 12.16508262014235\n",
      "MAE train 1.6454849356795482 MAE test 2.443044499487953\n",
      "Epoch 3595 / 10000 loss: 14.648566961288452\n",
      "MSE train 5.664132618866141 MSE test 12.164980789837124\n",
      "MAE train 1.6454578739450931 MAE test 2.443032672329343\n",
      "Epoch 3596 / 10000 loss: 14.648093938827515\n",
      "MSE train 5.663987463672718 MSE test 12.16491159373018\n",
      "MAE train 1.6454327763408834 MAE test 2.4430293611218548\n",
      "Epoch 3597 / 10000 loss: 14.647439956665039\n",
      "MSE train 5.66384331400327 MSE test 12.164631185316964\n",
      "MAE train 1.645413002650986 MAE test 2.4429950241448317\n",
      "Epoch 3598 / 10000 loss: 14.646870851516724\n",
      "MSE train 5.66370766692987 MSE test 12.164623686766669\n",
      "MAE train 1.6453887490367705 MAE test 2.4429995104758593\n",
      "Epoch 3599 / 10000 loss: 14.646379947662354\n",
      "MSE train 5.663566728359547 MSE test 12.164261595152\n",
      "MAE train 1.6453715981032782 MAE test 2.442954917326299\n",
      "Epoch 3600 / 10000 loss: 14.645816326141357\n",
      "MSE train 5.663398007423174 MSE test 12.16428557586188\n",
      "MAE train 1.645338877144252 MAE test 2.4429634278244987\n",
      "Epoch 3601 / 10000 loss: 14.645398139953613\n",
      "MSE train 5.663263953598255 MSE test 12.164091059962702\n",
      "MAE train 1.6453192914596886 MAE test 2.4429398322626317\n",
      "Epoch 3602 / 10000 loss: 14.644684076309204\n",
      "MSE train 5.663107763574198 MSE test 12.163936717651085\n",
      "MAE train 1.645293871861654 MAE test 2.4429258761486055\n",
      "Epoch 3603 / 10000 loss: 14.64417290687561\n",
      "MSE train 5.662983264053368 MSE test 12.16380382198903\n",
      "MAE train 1.6452751516722814 MAE test 2.4429100579937675\n",
      "Epoch 3604 / 10000 loss: 14.64362120628357\n",
      "MSE train 5.662830277951571 MSE test 12.163567728300016\n",
      "MAE train 1.6452523526210916 MAE test 2.4428858187585036\n",
      "Epoch 3605 / 10000 loss: 14.643112897872925\n",
      "MSE train 5.662672721047133 MSE test 12.163466466021765\n",
      "MAE train 1.6452251539987242 MAE test 2.4428740628443744\n",
      "Epoch 3606 / 10000 loss: 14.64263653755188\n",
      "MSE train 5.66252655396591 MSE test 12.163397492162265\n",
      "MAE train 1.6451999127097048 MAE test 2.442870764965942\n",
      "Epoch 3607 / 10000 loss: 14.641977548599243\n",
      "MSE train 5.662381526823108 MSE test 12.163118358703688\n",
      "MAE train 1.6451800121582747 MAE test 2.4428365849379747\n",
      "Epoch 3608 / 10000 loss: 14.641406059265137\n",
      "MSE train 5.662245038035465 MSE test 12.163111008093583\n",
      "MAE train 1.645155675744107 MAE test 2.442841085506579\n",
      "Epoch 3609 / 10000 loss: 14.640910863876343\n",
      "MSE train 5.66210324797119 MSE test 12.162749706124433\n",
      "MAE train 1.645138425557028 MAE test 2.442796577691012\n",
      "Epoch 3610 / 10000 loss: 14.640343427658081\n",
      "MSE train 5.66193376388408 MSE test 12.162774120058698\n",
      "MAE train 1.6451056147541427 MAE test 2.442805137969337\n",
      "Epoch 3611 / 10000 loss: 14.639922618865967\n",
      "MSE train 5.661798992663913 MSE test 12.16257976629984\n",
      "MAE train 1.6450859578508674 MAE test 2.4427815655737857\n",
      "Epoch 3612 / 10000 loss: 14.639204740524292\n",
      "MSE train 5.661642225479149 MSE test 12.162426555904553\n",
      "MAE train 1.6450604879928137 MAE test 2.442767727580406\n",
      "Epoch 3613 / 10000 loss: 14.638689994812012\n",
      "MSE train 5.661517309990992 MSE test 12.1622937111412\n",
      "MAE train 1.6450417810900275 MAE test 2.442751922019211\n",
      "Epoch 3614 / 10000 loss: 14.638136386871338\n",
      "MSE train 5.66136404120466 MSE test 12.162057864366716\n",
      "MAE train 1.6450190044361708 MAE test 2.4427276934835773\n",
      "Epoch 3615 / 10000 loss: 14.637625694274902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.661206433889931 MSE test 12.161956850175576\n",
      "MAE train 1.6449918793863607 MAE test 2.442715966334743\n",
      "Epoch 3616 / 10000 loss: 14.637148141860962\n",
      "MSE train 5.661060415609424 MSE test 12.161887854563997\n",
      "MAE train 1.6449667282525993 MAE test 2.4427126802220265\n",
      "Epoch 3617 / 10000 loss: 14.636489868164062\n",
      "MSE train 5.660915848051039 MSE test 12.16160905176708\n",
      "MAE train 1.6449469557892407 MAE test 2.4426785393330923\n",
      "Epoch 3618 / 10000 loss: 14.635918617248535\n",
      "MSE train 5.660780109464683 MSE test 12.16160121813984\n",
      "MAE train 1.6449228051439313 MAE test 2.442682971681648\n",
      "Epoch 3619 / 10000 loss: 14.635424137115479\n",
      "MSE train 5.660639210214558 MSE test 12.1612398651537\n",
      "MAE train 1.6449057363158512 MAE test 2.4426384778022654\n",
      "Epoch 3620 / 10000 loss: 14.634860277175903\n",
      "MSE train 5.66047105276535 MSE test 12.16126379477768\n",
      "MAE train 1.6448731801130898 MAE test 2.4426469953666223\n",
      "Epoch 3621 / 10000 loss: 14.634443283081055\n",
      "MSE train 5.660337612600831 MSE test 12.161068775803397\n",
      "MAE train 1.6448537676102406 MAE test 2.4426233623863847\n",
      "Epoch 3622 / 10000 loss: 14.633731603622437\n",
      "MSE train 5.660182415758225 MSE test 12.160915206805681\n",
      "MAE train 1.644828526167253 MAE test 2.4426094959370848\n",
      "Epoch 3623 / 10000 loss: 14.633223295211792\n",
      "MSE train 5.660059277884999 MSE test 12.160781033375791\n",
      "MAE train 1.6448100956772655 MAE test 2.442593554009415\n",
      "Epoch 3624 / 10000 loss: 14.632675170898438\n",
      "MSE train 5.65990778588068 MSE test 12.160544637451283\n",
      "MAE train 1.6447875608905422 MAE test 2.442569320741397\n",
      "Epoch 3625 / 10000 loss: 14.632173776626587\n",
      "MSE train 5.659752124063176 MSE test 12.16044275350294\n",
      "MAE train 1.6447606962838448 MAE test 2.442557515861416\n",
      "Epoch 3626 / 10000 loss: 14.63170313835144\n",
      "MSE train 5.659607845061812 MSE test 12.160372477898248\n",
      "MAE train 1.6447357768535533 MAE test 2.4425541083662914\n",
      "Epoch 3627 / 10000 loss: 14.631052017211914\n",
      "MSE train 5.65946500942359 MSE test 12.160093493655047\n",
      "MAE train 1.644716205775987 MAE test 2.4425199682989978\n",
      "Epoch 3628 / 10000 loss: 14.630488872528076\n",
      "MSE train 5.6593309797383125 MSE test 12.160084041235635\n",
      "MAE train 1.644692288289415 MAE test 2.4425242624721344\n",
      "Epoch 3629 / 10000 loss: 14.630001783370972\n",
      "MSE train 5.659191772644469 MSE test 12.159722074404636\n",
      "MAE train 1.6446754258557326 MAE test 2.442479709871801\n",
      "Epoch 3630 / 10000 loss: 14.62944507598877\n",
      "MSE train 5.659025047400555 MSE test 12.159745271738778\n",
      "MAE train 1.6446430449004825 MAE test 2.4424881745554767\n",
      "Epoch 3631 / 10000 loss: 14.629034757614136\n",
      "MSE train 5.6588927943702805 MSE test 12.159549303842507\n",
      "MAE train 1.6446237565286927 MAE test 2.4424644339404806\n",
      "Epoch 3632 / 10000 loss: 14.628329038619995\n",
      "MSE train 5.658738837227725 MSE test 12.159395926236211\n",
      "MAE train 1.644598640085795 MAE test 2.442450615671396\n",
      "Epoch 3633 / 10000 loss: 14.627825498580933\n",
      "MSE train 5.658616886267894 MSE test 12.159260848227643\n",
      "MAE train 1.6445803860967785 MAE test 2.44243459148282\n",
      "Epoch 3634 / 10000 loss: 14.627281188964844\n",
      "MSE train 5.658466491728303 MSE test 12.159024173769604\n",
      "MAE train 1.6445579738970522 MAE test 2.44241029716434\n",
      "Epoch 3635 / 10000 loss: 14.626785039901733\n",
      "MSE train 5.658311775023623 MSE test 12.15892225744327\n",
      "MAE train 1.6445312402516892 MAE test 2.4423985129365904\n",
      "Epoch 3636 / 10000 loss: 14.626319169998169\n",
      "MSE train 5.65816826328594 MSE test 12.158851150039375\n",
      "MAE train 1.6445064099339703 MAE test 2.4423950060772373\n",
      "Epoch 3637 / 10000 loss: 14.625672340393066\n",
      "MSE train 5.658026256167307 MSE test 12.158573537649279\n",
      "MAE train 1.644486903440079 MAE test 2.442361033842933\n",
      "Epoch 3638 / 10000 loss: 14.62511157989502\n",
      "MSE train 5.657893063992219 MSE test 12.158562908283605\n",
      "MAE train 1.6444631247982744 MAE test 2.4423651577978625\n",
      "Epoch 3639 / 10000 loss: 14.624627113342285\n",
      "MSE train 5.657754668533657 MSE test 12.158201585556471\n",
      "MAE train 1.644446361568545 MAE test 2.442320676989763\n",
      "Epoch 3640 / 10000 loss: 14.624075174331665\n",
      "MSE train 5.657588723364052 MSE test 12.158224793473135\n",
      "MAE train 1.644414084687389 MAE test 2.442329140695403\n",
      "Epoch 3641 / 10000 loss: 14.623667240142822\n",
      "MSE train 5.657456938948472 MSE test 12.158028123304963\n",
      "MAE train 1.6443948552200975 MAE test 2.4423053072445047\n",
      "Epoch 3642 / 10000 loss: 14.622964143753052\n",
      "MSE train 5.657303676990881 MSE test 12.15787696572775\n",
      "MAE train 1.6443697665980757 MAE test 2.4422917534700312\n",
      "Epoch 3643 / 10000 loss: 14.622463464736938\n",
      "MSE train 5.6571824175887695 MSE test 12.157740143884068\n",
      "MAE train 1.6443516529361029 MAE test 2.4422754853309243\n",
      "Epoch 3644 / 10000 loss: 14.621921062469482\n",
      "MSE train 5.657032707434255 MSE test 12.157504717722714\n",
      "MAE train 1.6443293279682343 MAE test 2.4422513431571113\n",
      "Epoch 3645 / 10000 loss: 14.62142825126648\n",
      "MSE train 5.656878743114448 MSE test 12.1574030350438\n",
      "MAE train 1.6443027056260948 MAE test 2.4422395661318625\n",
      "Epoch 3646 / 10000 loss: 14.620964050292969\n",
      "MSE train 5.656735370366667 MSE test 12.157330563049669\n",
      "MAE train 1.644277884116871 MAE test 2.4422358688221166\n",
      "Epoch 3647 / 10000 loss: 14.620320558547974\n",
      "MSE train 5.656593884664745 MSE test 12.157056472135093\n",
      "MAE train 1.6442583550917194 MAE test 2.442202315949963\n",
      "Epoch 3648 / 10000 loss: 14.61976146697998\n",
      "MSE train 5.656461378504846 MSE test 12.157043016434796\n",
      "MAE train 1.644234757972353 MAE test 2.4422060949343134\n",
      "Epoch 3649 / 10000 loss: 14.619277954101562\n",
      "MSE train 5.656323504815399 MSE test 12.15668367676857\n",
      "MAE train 1.644218035314783 MAE test 2.4421618299922434\n",
      "Epoch 3650 / 10000 loss: 14.61872911453247\n",
      "MSE train 5.656158459889786 MSE test 12.156707214322152\n",
      "MAE train 1.6441859212419159 MAE test 2.4421703344549335\n",
      "Epoch 3651 / 10000 loss: 14.618322610855103\n",
      "MSE train 5.65602618301238 MSE test 12.156507536119152\n",
      "MAE train 1.6441665974738322 MAE test 2.4421461033597636\n",
      "Epoch 3652 / 10000 loss: 14.61762285232544\n",
      "MSE train 5.655873321340923 MSE test 12.156364045896618\n",
      "MAE train 1.6441413796359063 MAE test 2.4421334913491974\n",
      "Epoch 3653 / 10000 loss: 14.617122411727905\n",
      "MSE train 5.655752197830517 MSE test 12.156220240414113\n",
      "MAE train 1.644123442379666 MAE test 2.4421163415048\n",
      "Epoch 3654 / 10000 loss: 14.6165771484375\n",
      "MSE train 5.655603042077544 MSE test 12.155990889056088\n",
      "MAE train 1.6441011012718587 MAE test 2.4420929515586134\n",
      "Epoch 3655 / 10000 loss: 14.616090297698975\n",
      "MSE train 5.655450882617156 MSE test 12.155889570248528\n",
      "MAE train 1.644074846224907 MAE test 2.442081219882568\n",
      "Epoch 3656 / 10000 loss: 14.615622520446777\n",
      "MSE train 5.655304448795033 MSE test 12.155804417148085\n",
      "MAE train 1.6440495700648357 MAE test 2.4420759080089174\n",
      "Epoch 3657 / 10000 loss: 14.614985942840576\n",
      "MSE train 5.655164143829031 MSE test 12.155558618275268\n",
      "MAE train 1.6440295245448677 MAE test 2.442045921325387\n",
      "Epoch 3658 / 10000 loss: 14.61442494392395\n",
      "MSE train 5.655025701360845 MSE test 12.155512142317944\n",
      "MAE train 1.6440053184955967 MAE test 2.442045511225887\n",
      "Epoch 3659 / 10000 loss: 14.613926649093628\n",
      "MSE train 5.654886954716914 MSE test 12.155204854892418\n",
      "MAE train 1.6439872709708585 MAE test 2.44200778715242\n",
      "Epoch 3660 / 10000 loss: 14.61337661743164\n",
      "MSE train 5.654744180014299 MSE test 12.155219250739693\n",
      "MAE train 1.6439604964041297 MAE test 2.4420150895019708\n",
      "Epoch 3661 / 10000 loss: 14.612926721572876\n",
      "MSE train 5.654604930550191 MSE test 12.154891012742757\n",
      "MAE train 1.6439428023834781 MAE test 2.4419747110504884\n",
      "Epoch 3662 / 10000 loss: 14.612320899963379\n",
      "MSE train 5.654453517549426 MSE test 12.154909907088099\n",
      "MAE train 1.643913852456249 MAE test 2.4419826009461887\n",
      "Epoch 3663 / 10000 loss: 14.61188530921936\n",
      "MSE train 5.6543118579320915 MSE test 12.154624611958022\n",
      "MAE train 1.6438945227310067 MAE test 2.4419475952038425\n",
      "Epoch 3664 / 10000 loss: 14.611241102218628\n",
      "MSE train 5.654179176918335 MSE test 12.154618636151985\n",
      "MAE train 1.6438706635020892 MAE test 2.44195230590209\n",
      "Epoch 3665 / 10000 loss: 14.610764503479004\n",
      "MSE train 5.654041119277676 MSE test 12.15425769171389\n",
      "MAE train 1.6438538879125222 MAE test 2.441907818570629\n",
      "Epoch 3666 / 10000 loss: 14.610209465026855\n",
      "MSE train 5.653876308843894 MSE test 12.154280729114591\n",
      "MAE train 1.64382180938572 MAE test 2.441916238526373\n",
      "Epoch 3667 / 10000 loss: 14.609804391860962\n",
      "MSE train 5.65374481901944 MSE test 12.154083228684485\n",
      "MAE train 1.6438026052833181 MAE test 2.441892285805122\n",
      "Epoch 3668 / 10000 loss: 14.609105348587036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.653592293656542 MSE test 12.153935062995787\n",
      "MAE train 1.6437775456269097 MAE test 2.441879078062717\n",
      "Epoch 3669 / 10000 loss: 14.608607530593872\n",
      "MSE train 5.653471642550752 MSE test 12.153796094738155\n",
      "MAE train 1.6437595846732909 MAE test 2.441862530973167\n",
      "Epoch 3670 / 10000 loss: 14.608066082000732\n",
      "MSE train 5.6533225869458805 MSE test 12.153562750841996\n",
      "MAE train 1.6437373220073122 MAE test 2.441838606890549\n",
      "Epoch 3671 / 10000 loss: 14.60757827758789\n",
      "MSE train 5.653169608411209 MSE test 12.153461585955338\n",
      "MAE train 1.6437108608460291 MAE test 2.441826887617449\n",
      "Epoch 3672 / 10000 loss: 14.607114553451538\n",
      "MSE train 5.653025627335377 MSE test 12.153385386406406\n",
      "MAE train 1.6436859354873705 MAE test 2.4418227089328557\n",
      "Epoch 3673 / 10000 loss: 14.60647463798523\n",
      "MSE train 5.652884727357186 MSE test 12.153120690255196\n",
      "MAE train 1.6436662407894247 MAE test 2.4417903084730574\n",
      "Epoch 3674 / 10000 loss: 14.60591745376587\n",
      "MSE train 5.652751782001628 MSE test 12.153098233124949\n",
      "MAE train 1.6436427388842845 MAE test 2.4417929369565936\n",
      "Epoch 3675 / 10000 loss: 14.60542893409729\n",
      "MSE train 5.652614413768326 MSE test 12.152748763003553\n",
      "MAE train 1.6436258992622812 MAE test 2.4417498877225325\n",
      "Epoch 3676 / 10000 loss: 14.604886531829834\n",
      "MSE train 5.652452303220688 MSE test 12.152772429600837\n",
      "MAE train 1.643594408302717 MAE test 2.4417583946986667\n",
      "Epoch 3677 / 10000 loss: 14.60447382926941\n",
      "MSE train 5.652315185471775 MSE test 12.15255183826513\n",
      "MAE train 1.643574433401814 MAE test 2.441731535298035\n",
      "Epoch 3678 / 10000 loss: 14.60378646850586\n",
      "MSE train 5.65216579505495 MSE test 12.152453141486522\n",
      "MAE train 1.6435488431235545 MAE test 2.441724555081878\n",
      "Epoch 3679 / 10000 loss: 14.60328221321106\n",
      "MSE train 5.652030463012598 MSE test 12.152246546070447\n",
      "MAE train 1.643528985167669 MAE test 2.4416994656189295\n",
      "Epoch 3680 / 10000 loss: 14.602722644805908\n",
      "MSE train 5.651880001995626 MSE test 12.1521382618448\n",
      "MAE train 1.643503395965351 MAE test 2.4416913047790696\n",
      "Epoch 3681 / 10000 loss: 14.602219820022583\n",
      "MSE train 5.651749520227591 MSE test 12.151955157350923\n",
      "MAE train 1.6434841733316665 MAE test 2.441669186673805\n",
      "Epoch 3682 / 10000 loss: 14.601662397384644\n",
      "MSE train 5.651598422887915 MSE test 12.151801541425751\n",
      "MAE train 1.6434596412693157 MAE test 2.4416553076112057\n",
      "Epoch 3683 / 10000 loss: 14.601166725158691\n",
      "MSE train 5.651476777574318 MSE test 12.15167461118263\n",
      "MAE train 1.6434411749906723 MAE test 2.4416402894162794\n",
      "Epoch 3684 / 10000 loss: 14.600634813308716\n",
      "MSE train 5.651327995809974 MSE test 12.15143713684292\n",
      "MAE train 1.6434190359907623 MAE test 2.441615860666674\n",
      "Epoch 3685 / 10000 loss: 14.600137948989868\n",
      "MSE train 5.6511738187093075 MSE test 12.151336295339819\n",
      "MAE train 1.6433923121385767 MAE test 2.4416041987509125\n",
      "Epoch 3686 / 10000 loss: 14.599678754806519\n",
      "MSE train 5.651032626348196 MSE test 12.151270514010463\n",
      "MAE train 1.6433678151159754 MAE test 2.4416013372910412\n",
      "Epoch 3687 / 10000 loss: 14.599034547805786\n",
      "MSE train 5.650891649811876 MSE test 12.150983704218321\n",
      "MAE train 1.6433486894117202 MAE test 2.4415661454665476\n",
      "Epoch 3688 / 10000 loss: 14.598481178283691\n",
      "MSE train 5.650757990902797 MSE test 12.150981618771471\n",
      "MAE train 1.643324508694544 MAE test 2.4415713670109667\n",
      "Epoch 3689 / 10000 loss: 14.598008394241333\n",
      "MSE train 5.650619835028064 MSE test 12.150621888857614\n",
      "MAE train 1.6433076749355977 MAE test 2.4415270066739905\n",
      "Epoch 3690 / 10000 loss: 14.597448348999023\n",
      "MSE train 5.650455057382305 MSE test 12.15064501516689\n",
      "MAE train 1.643275606250628 MAE test 2.441535475113937\n",
      "Epoch 3691 / 10000 loss: 14.597042798995972\n",
      "MSE train 5.650322834215404 MSE test 12.150445814559523\n",
      "MAE train 1.6432562615711803 MAE test 2.441511280031626\n",
      "Epoch 3692 / 10000 loss: 14.596344470977783\n",
      "MSE train 5.650170069131645 MSE test 12.15030174971282\n",
      "MAE train 1.6432310343875196 MAE test 2.441498599521987\n",
      "Epoch 3693 / 10000 loss: 14.595845460891724\n",
      "MSE train 5.650048824418225 MSE test 12.15015866597447\n",
      "MAE train 1.6432130499507176 MAE test 2.441481531663933\n",
      "Epoch 3694 / 10000 loss: 14.595301389694214\n",
      "MSE train 5.649899537696578 MSE test 12.149929238940674\n",
      "MAE train 1.6431906517452426 MAE test 2.441458112129057\n",
      "Epoch 3695 / 10000 loss: 14.594815015792847\n",
      "MSE train 5.649747232442878 MSE test 12.149828117321126\n",
      "MAE train 1.6431643586539302 MAE test 2.4414464061426977\n",
      "Epoch 3696 / 10000 loss: 14.594348430633545\n",
      "MSE train 5.649600558091654 MSE test 12.149742857911168\n",
      "MAE train 1.643139015845014 MAE test 2.441441099958401\n",
      "Epoch 3697 / 10000 loss: 14.593711853027344\n",
      "MSE train 5.649459995156488 MSE test 12.149497363472976\n",
      "MAE train 1.643118895957314 MAE test 2.441411129214514\n",
      "Epoch 3698 / 10000 loss: 14.593152284622192\n",
      "MSE train 5.649321180036111 MSE test 12.14945072443665\n",
      "MAE train 1.6430946108167421 MAE test 2.441410722757454\n",
      "Epoch 3699 / 10000 loss: 14.592652559280396\n",
      "MSE train 5.649182017188407 MSE test 12.149143941567775\n",
      "MAE train 1.6430764515161922 MAE test 2.44137303890977\n",
      "Epoch 3700 / 10000 loss: 14.592103719711304\n",
      "MSE train 5.649038913148942 MSE test 12.149157985489474\n",
      "MAE train 1.6430496227289417 MAE test 2.441380335620409\n",
      "Epoch 3701 / 10000 loss: 14.591652631759644\n",
      "MSE train 5.648899082225638 MSE test 12.148829786380198\n",
      "MAE train 1.643031799806342 MAE test 2.441339945750854\n",
      "Epoch 3702 / 10000 loss: 14.591047763824463\n",
      "MSE train 5.648746984546531 MSE test 12.148848446977814\n",
      "MAE train 1.6430027149428845 MAE test 2.441347836632915\n",
      "Epoch 3703 / 10000 loss: 14.590611219406128\n",
      "MSE train 5.648604671750037 MSE test 12.148564026831329\n",
      "MAE train 1.6429832151497747 MAE test 2.4413129451694062\n",
      "Epoch 3704 / 10000 loss: 14.589965581893921\n",
      "MSE train 5.6484713401817315 MSE test 12.14855696529839\n",
      "MAE train 1.6429592660993735 MAE test 2.4413175581192728\n",
      "Epoch 3705 / 10000 loss: 14.589487552642822\n",
      "MSE train 5.648332479101611 MSE test 12.148196346009628\n",
      "MAE train 1.6429423106301562 MAE test 2.4412730948796937\n",
      "Epoch 3706 / 10000 loss: 14.588933229446411\n",
      "MSE train 5.648166848049758 MSE test 12.148219171743376\n",
      "MAE train 1.6429100824048672 MAE test 2.441281544436819\n",
      "Epoch 3707 / 10000 loss: 14.588525533676147\n",
      "MSE train 5.648034379546382 MSE test 12.148021420633405\n",
      "MAE train 1.6428906855939502 MAE test 2.4412575547382622\n",
      "Epoch 3708 / 10000 loss: 14.587825775146484\n",
      "MSE train 5.64788080664124 MSE test 12.147873419107007\n",
      "MAE train 1.6428654111851257 MAE test 2.4412443914548114\n",
      "Epoch 3709 / 10000 loss: 14.58732533454895\n",
      "MSE train 5.647758982306424 MSE test 12.147733805638545\n",
      "MAE train 1.6428472431461567 MAE test 2.441227787521197\n",
      "Epoch 3710 / 10000 loss: 14.586782932281494\n",
      "MSE train 5.647608727238824 MSE test 12.147500664891108\n",
      "MAE train 1.6428247304672383 MAE test 2.441203917575326\n",
      "Epoch 3711 / 10000 loss: 14.58629298210144\n",
      "MSE train 5.6474545211629845 MSE test 12.147399231881947\n",
      "MAE train 1.6427980526485872 MAE test 2.441192209721632\n",
      "Epoch 3712 / 10000 loss: 14.58582592010498\n",
      "MSE train 5.647308823598363 MSE test 12.147321276099214\n",
      "MAE train 1.6427728141462128 MAE test 2.4411878390673785\n",
      "Epoch 3713 / 10000 loss: 14.585184335708618\n",
      "MSE train 5.647166373732234 MSE test 12.147058778383355\n",
      "MAE train 1.6427527626098968 MAE test 2.441155743978025\n",
      "Epoch 3714 / 10000 loss: 14.584623575210571\n",
      "MSE train 5.647031372743411 MSE test 12.147032994868987\n",
      "MAE train 1.642728931886444 MAE test 2.441158009406389\n",
      "Epoch 3715 / 10000 loss: 14.584131240844727\n",
      "MSE train 5.646892079074182 MSE test 12.146687403971338\n",
      "MAE train 1.642711639457329 MAE test 2.4411154783278586\n",
      "Epoch 3716 / 10000 loss: 14.583584785461426\n",
      "MSE train 5.6467293938862255 MSE test 12.146709974148841\n",
      "MAE train 1.6426801030740605 MAE test 2.4411238976339136\n",
      "Epoch 3717 / 10000 loss: 14.583164691925049\n",
      "MSE train 5.646588430705877 MSE test 12.146478527291466\n",
      "MAE train 1.6426596004904856 MAE test 2.4410957040373815\n",
      "Epoch 3718 / 10000 loss: 14.582478284835815\n",
      "MSE train 5.646440178778209 MSE test 12.146398933632662\n",
      "MAE train 1.6426338849679363 MAE test 2.44109117712532\n",
      "Epoch 3719 / 10000 loss: 14.58197021484375\n",
      "MSE train 5.6462978222129525 MSE test 12.146154591627246\n",
      "MAE train 1.642613441652801 MAE test 2.441061400396402\n",
      "Epoch 3720 / 10000 loss: 14.581406831741333\n",
      "MSE train 5.646156964663475 MSE test 12.14610949988093\n",
      "MAE train 1.6425887431470174 MAE test 2.441061249827231\n",
      "Epoch 3721 / 10000 loss: 14.580903053283691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.646015572550217 MSE test 12.145799074575471\n",
      "MAE train 1.6425702646791331 MAE test 2.4410231419501423\n",
      "Epoch 3722 / 10000 loss: 14.580349922180176\n",
      "MSE train 5.645867823408782 MSE test 12.145813938605325\n",
      "MAE train 1.642542447817229 MAE test 2.4410306091564378\n",
      "Epoch 3723 / 10000 loss: 14.579895496368408\n",
      "MSE train 5.645724439744772 MSE test 12.145492156060586\n",
      "MAE train 1.6425237803939026 MAE test 2.4409910727326554\n",
      "Epoch 3724 / 10000 loss: 14.579275369644165\n",
      "MSE train 5.645572677086773 MSE test 12.1455072703401\n",
      "MAE train 1.6424950007389527 MAE test 2.440998573335919\n",
      "Epoch 3725 / 10000 loss: 14.57882285118103\n",
      "MSE train 5.645426984408688 MSE test 12.145202132372166\n",
      "MAE train 1.6424754031249362 MAE test 2.440961138941064\n",
      "Epoch 3726 / 10000 loss: 14.578185081481934\n",
      "MSE train 5.645283245924733 MSE test 12.14520787287793\n",
      "MAE train 1.6424488187653767 MAE test 2.4409674566843615\n",
      "Epoch 3727 / 10000 loss: 14.577713012695312\n",
      "MSE train 5.645138086552696 MSE test 12.144863282871496\n",
      "MAE train 1.642430283900707 MAE test 2.440925059466702\n",
      "Epoch 3728 / 10000 loss: 14.577113389968872\n",
      "MSE train 5.644972939593974 MSE test 12.144882076896002\n",
      "MAE train 1.6423983660345236 MAE test 2.440933069453446\n",
      "Epoch 3729 / 10000 loss: 14.576674222946167\n",
      "MSE train 5.6448241964576065 MSE test 12.144633726177627\n",
      "MAE train 1.6423766250602756 MAE test 2.4409028013803615\n",
      "Epoch 3730 / 10000 loss: 14.575984954833984\n",
      "MSE train 5.6446746505821315 MSE test 12.144575970238085\n",
      "MAE train 1.6423503452188342 MAE test 2.440901089137159\n",
      "Epoch 3731 / 10000 loss: 14.575460433959961\n",
      "MSE train 5.64452355587389 MSE test 12.144278269751807\n",
      "MAE train 1.6423294647454842 MAE test 2.440864666507467\n",
      "Epoch 3732 / 10000 loss: 14.574883460998535\n",
      "MSE train 5.644372737015728 MSE test 12.144280550223034\n",
      "MAE train 1.6423014908291937 MAE test 2.440870617350987\n",
      "Epoch 3733 / 10000 loss: 14.574387788772583\n",
      "MSE train 5.644216968234136 MSE test 12.143925092159552\n",
      "MAE train 1.6422808558191946 MAE test 2.440826930250275\n",
      "Epoch 3734 / 10000 loss: 14.573769330978394\n",
      "MSE train 5.644032376536271 MSE test 12.14394124080309\n",
      "MAE train 1.6422446538430762 MAE test 2.44083470863867\n",
      "Epoch 3735 / 10000 loss: 14.573299884796143\n",
      "MSE train 5.643864366439201 MSE test 12.143711648756465\n",
      "MAE train 1.6422180679160605 MAE test 2.440806924482727\n",
      "Epoch 3736 / 10000 loss: 14.572539329528809\n",
      "MSE train 5.643671484683557 MSE test 12.143603751829875\n",
      "MAE train 1.6421828503920057 MAE test 2.4407990818274587\n",
      "Epoch 3737 / 10000 loss: 14.571931600570679\n",
      "MSE train 5.643469118763041 MSE test 12.14338016204062\n",
      "MAE train 1.6421478918916192 MAE test 2.440772226016332\n",
      "Epoch 3738 / 10000 loss: 14.571217060089111\n",
      "MSE train 5.643209847848822 MSE test 12.143257325184903\n",
      "MAE train 1.6420968195566867 MAE test 2.440762743295173\n",
      "Epoch 3739 / 10000 loss: 14.570467710494995\n",
      "MSE train 5.642887128100894 MSE test 12.143035957444088\n",
      "MAE train 1.6420315590981474 MAE test 2.4407365225447575\n",
      "Epoch 3740 / 10000 loss: 14.569481134414673\n",
      "MSE train 5.642438672523861 MSE test 12.142859353989868\n",
      "MAE train 1.6419327185123422 MAE test 2.4407207474766572\n",
      "Epoch 3741 / 10000 loss: 14.568205118179321\n",
      "MSE train 5.642054749162716 MSE test 12.142667106175903\n",
      "MAE train 1.6418482194183268 MAE test 2.4406984929126794\n",
      "Epoch 3742 / 10000 loss: 14.566389799118042\n",
      "MSE train 5.641809583653867 MSE test 12.142419398956461\n",
      "MAE train 1.6418018626071382 MAE test 2.440673165997067\n",
      "Epoch 3743 / 10000 loss: 14.564764261245728\n",
      "MSE train 5.641623110524719 MSE test 12.142312575926583\n",
      "MAE train 1.6417675814517136 MAE test 2.4406607319947313\n",
      "Epoch 3744 / 10000 loss: 14.563886880874634\n",
      "MSE train 5.641455056476269 MSE test 12.142217866981726\n",
      "MAE train 1.6417379056812975 MAE test 2.4406540879306484\n",
      "Epoch 3745 / 10000 loss: 14.563106060028076\n",
      "MSE train 5.6413046465295285 MSE test 12.14200102307514\n",
      "MAE train 1.6417153443135413 MAE test 2.440627516480831\n",
      "Epoch 3746 / 10000 loss: 14.56245732307434\n",
      "MSE train 5.641148859950818 MSE test 12.14192382445097\n",
      "MAE train 1.6416883287255577 MAE test 2.4406230490274825\n",
      "Epoch 3747 / 10000 loss: 14.561891317367554\n",
      "MSE train 5.641004248191703 MSE test 12.141699798113939\n",
      "MAE train 1.6416672746613061 MAE test 2.440595616514429\n",
      "Epoch 3748 / 10000 loss: 14.561284065246582\n",
      "MSE train 5.640856708405375 MSE test 12.141640172474425\n",
      "MAE train 1.641641521698572 MAE test 2.4405934833154284\n",
      "Epoch 3749 / 10000 loss: 14.560749530792236\n",
      "MSE train 5.640713206386414 MSE test 12.141375498225472\n",
      "MAE train 1.6416214453425975 MAE test 2.440561036619767\n",
      "Epoch 3750 / 10000 loss: 14.560170650482178\n",
      "MSE train 5.6405778073341075 MSE test 12.141365997307291\n",
      "MAE train 1.6415971561582523 MAE test 2.4405653080108087\n",
      "Epoch 3751 / 10000 loss: 14.559670209884644\n",
      "MSE train 5.64043836672737 MSE test 12.141010648866443\n",
      "MAE train 1.6415799809866178 MAE test 2.440521473486693\n",
      "Epoch 3752 / 10000 loss: 14.559110164642334\n",
      "MSE train 5.640271419206892 MSE test 12.141037421094406\n",
      "MAE train 1.6415473450172446 MAE test 2.440530397806271\n",
      "Epoch 3753 / 10000 loss: 14.558693170547485\n",
      "MSE train 5.6401384663392005 MSE test 12.140844282715216\n",
      "MAE train 1.6415277171349592 MAE test 2.440506964501308\n",
      "Epoch 3754 / 10000 loss: 14.557982921600342\n",
      "MSE train 5.639984615210595 MSE test 12.14069828763192\n",
      "MAE train 1.6415022713029057 MAE test 2.4404940304319505\n",
      "Epoch 3755 / 10000 loss: 14.557473421096802\n",
      "MSE train 5.639862765251392 MSE test 12.140563550440588\n",
      "MAE train 1.6414839326616906 MAE test 2.4404780387802933\n",
      "Epoch 3756 / 10000 loss: 14.556924104690552\n",
      "MSE train 5.639712730762803 MSE test 12.140332503322943\n",
      "MAE train 1.6414613053857685 MAE test 2.440454407452392\n",
      "Epoch 3757 / 10000 loss: 14.55642580986023\n",
      "MSE train 5.639558761993955 MSE test 12.14023435320821\n",
      "MAE train 1.6414345250753384 MAE test 2.440443094800929\n",
      "Epoch 3758 / 10000 loss: 14.555955171585083\n",
      "MSE train 5.639414272923114 MSE test 12.140161281839404\n",
      "MAE train 1.6414093563411325 MAE test 2.440439354406702\n",
      "Epoch 3759 / 10000 loss: 14.555306911468506\n",
      "MSE train 5.639272559269549 MSE test 12.139897962079928\n",
      "MAE train 1.6413893923586813 MAE test 2.4404071552831708\n",
      "Epoch 3760 / 10000 loss: 14.554742097854614\n",
      "MSE train 5.639139190156171 MSE test 12.139879482277491\n",
      "MAE train 1.6413656673745458 MAE test 2.440410366836676\n",
      "Epoch 3761 / 10000 loss: 14.554246664047241\n",
      "MSE train 5.63900112781227 MSE test 12.13953119230672\n",
      "MAE train 1.641348568400858 MAE test 2.440367487148856\n",
      "Epoch 3762 / 10000 loss: 14.553697347640991\n",
      "MSE train 5.638837982269111 MSE test 12.13955668076427\n",
      "MAE train 1.6413167560886772 MAE test 2.440376305445279\n",
      "Epoch 3763 / 10000 loss: 14.553278923034668\n",
      "MSE train 5.638701182874537 MSE test 12.139342887454744\n",
      "MAE train 1.641296622660763 MAE test 2.440350342857308\n",
      "Epoch 3764 / 10000 loss: 14.552582263946533\n",
      "MSE train 5.6385503011097065 MSE test 12.139237885384267\n",
      "MAE train 1.641270780726039 MAE test 2.4403426429194846\n",
      "Epoch 3765 / 10000 loss: 14.552072525024414\n",
      "MSE train 5.638417591572851 MSE test 12.139048255610998\n",
      "MAE train 1.6412511048619502 MAE test 2.4403197573334654\n",
      "Epoch 3766 / 10000 loss: 14.551506996154785\n",
      "MSE train 5.6382656165949 MSE test 12.138911941002483\n",
      "MAE train 1.6412258477876673 MAE test 2.4403081342159747\n",
      "Epoch 3767 / 10000 loss: 14.55100131034851\n",
      "MSE train 5.638143921552464 MSE test 12.138771294640806\n",
      "MAE train 1.6412076648905216 MAE test 2.4402914553033783\n",
      "Epoch 3768 / 10000 loss: 14.550451517105103\n",
      "MSE train 5.637995052494622 MSE test 12.138545467087322\n",
      "MAE train 1.6411852229282569 MAE test 2.440268549611126\n",
      "Epoch 3769 / 10000 loss: 14.549959897994995\n",
      "MSE train 5.6378428519095065 MSE test 12.138447142615721\n",
      "MAE train 1.6411588285231438 MAE test 2.440257300168025\n",
      "Epoch 3770 / 10000 loss: 14.549488067626953\n",
      "MSE train 5.637695961332437 MSE test 12.138362231402272\n",
      "MAE train 1.6411333569007998 MAE test 2.440252107953119\n",
      "Epoch 3771 / 10000 loss: 14.548846006393433\n",
      "MSE train 5.637555714932115 MSE test 12.138122571486873\n",
      "MAE train 1.6411131019938936 MAE test 2.4402229492819343\n",
      "Epoch 3772 / 10000 loss: 14.548279523849487\n",
      "MSE train 5.637415891549103 MSE test 12.13807266916105\n",
      "MAE train 1.6410885679681293 MAE test 2.440222217278478\n",
      "Epoch 3773 / 10000 loss: 14.547775506973267\n",
      "MSE train 5.6372764888094995 MSE test 12.137778088003351\n",
      "MAE train 1.641069956187353 MAE test 2.440186125773377\n",
      "Epoch 3774 / 10000 loss: 14.547220945358276\n",
      "MSE train 5.637138156111202 MSE test 12.13778862164706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6410443051221133 MAE test 2.440193058585732\n",
      "Epoch 3775 / 10000 loss: 14.54675555229187\n",
      "MSE train 5.636999627580145 MSE test 12.137445017741603\n",
      "MAE train 1.6410269867563303 MAE test 2.440150769056578\n",
      "Epoch 3776 / 10000 loss: 14.546167135238647\n",
      "MSE train 5.636839593521022 MSE test 12.137468461815494\n",
      "MAE train 1.6409958643424576 MAE test 2.440159359497983\n",
      "Epoch 3777 / 10000 loss: 14.545744180679321\n",
      "MSE train 5.636700154592653 MSE test 12.137236333127946\n",
      "MAE train 1.6409755924407856 MAE test 2.4401310968022565\n",
      "Epoch 3778 / 10000 loss: 14.54505968093872\n",
      "MSE train 5.636555404234711 MSE test 12.137163639393576\n",
      "MAE train 1.6409503758592012 MAE test 2.440127467922028\n",
      "Epoch 3779 / 10000 loss: 14.544552326202393\n",
      "MSE train 5.636415223202225 MSE test 12.136911176297588\n",
      "MAE train 1.6409304965991718 MAE test 2.4400966754996625\n",
      "Epoch 3780 / 10000 loss: 14.543989896774292\n",
      "MSE train 5.636280729824256 MSE test 12.136882421768671\n",
      "MAE train 1.640906718029559 MAE test 2.440098587359582\n",
      "Epoch 3781 / 10000 loss: 14.543493747711182\n",
      "MSE train 5.636143417710939 MSE test 12.136548033094801\n",
      "MAE train 1.6408895122339828 MAE test 2.440057452870928\n",
      "Epoch 3782 / 10000 loss: 14.542946815490723\n",
      "MSE train 5.635986210068884 MSE test 12.136571333156649\n",
      "MAE train 1.6408590527817406 MAE test 2.440065991678849\n",
      "Epoch 3783 / 10000 loss: 14.54252028465271\n",
      "MSE train 5.635845378201103 MSE test 12.136320347132456\n",
      "MAE train 1.6408388960898663 MAE test 2.4400353238960526\n",
      "Epoch 3784 / 10000 loss: 14.541849136352539\n",
      "MSE train 5.63570876860902 MSE test 12.136278415386666\n",
      "MAE train 1.6408149109915857 MAE test 2.4400355526309543\n",
      "Epoch 3785 / 10000 loss: 14.541348218917847\n",
      "MSE train 5.6355704914771865 MSE test 12.135962503298835\n",
      "MAE train 1.6407970668817968 MAE test 2.4399966960782433\n",
      "Epoch 3786 / 10000 loss: 14.540799856185913\n",
      "MSE train 5.635423403537728 MSE test 12.135980503910037\n",
      "MAE train 1.6407690819340492 MAE test 2.440004533941949\n",
      "Epoch 3787 / 10000 loss: 14.54035472869873\n",
      "MSE train 5.635283154738692 MSE test 12.135676627676142\n",
      "MAE train 1.6407504524159533 MAE test 2.439967168720064\n",
      "Epoch 3788 / 10000 loss: 14.539726972579956\n",
      "MSE train 5.635144298089723 MSE test 12.135685891362987\n",
      "MAE train 1.640724636957072 MAE test 2.439973878500888\n",
      "Epoch 3789 / 10000 loss: 14.539266586303711\n",
      "MSE train 5.6350055558864165 MSE test 12.135348042819416\n",
      "MAE train 1.6407071223837855 MAE test 2.4399322147917846\n",
      "Epoch 3790 / 10000 loss: 14.53867483139038\n",
      "MSE train 5.634849824228955 MSE test 12.135368787644051\n",
      "MAE train 1.640676995636541 MAE test 2.439940374386842\n",
      "Epoch 3791 / 10000 loss: 14.538247108459473\n",
      "MSE train 5.634709024785068 MSE test 12.135113386314996\n",
      "MAE train 1.6406569243405267 MAE test 2.4399090786764317\n",
      "Epoch 3792 / 10000 loss: 14.537581205368042\n",
      "MSE train 5.634573790030131 MSE test 12.135073956737806\n",
      "MAE train 1.6406331580325095 MAE test 2.439909559648419\n",
      "Epoch 3793 / 10000 loss: 14.537084579467773\n",
      "MSE train 5.634436024319475 MSE test 12.134750800682266\n",
      "MAE train 1.6406155780007017 MAE test 2.4398697347530653\n",
      "Epoch 3794 / 10000 loss: 14.536539077758789\n",
      "MSE train 5.634286009487588 MSE test 12.134769787956532\n",
      "MAE train 1.6405868538427153 MAE test 2.439877641056171\n",
      "Epoch 3795 / 10000 loss: 14.536103010177612\n",
      "MSE train 5.63414537595369 MSE test 12.134482318867368\n",
      "MAE train 1.6405677085285442 MAE test 2.4398422829161808\n",
      "Epoch 3796 / 10000 loss: 14.535463094711304\n",
      "MSE train 5.634012829524062 MSE test 12.134479005474828\n",
      "MAE train 1.6405437004026904 MAE test 2.439847330853801\n",
      "Epoch 3797 / 10000 loss: 14.53498888015747\n",
      "MSE train 5.6338754332838805 MSE test 12.134120712229802\n",
      "MAE train 1.6405268995770468 MAE test 2.439803036600605\n",
      "Epoch 3798 / 10000 loss: 14.534430503845215\n",
      "MSE train 5.633712176493985 MSE test 12.134143028181052\n",
      "MAE train 1.6404950816570267 MAE test 2.439811356203334\n",
      "Epoch 3799 / 10000 loss: 14.534025192260742\n",
      "MSE train 5.6335805325821 MSE test 12.133941598461119\n",
      "MAE train 1.6404757914106687 MAE test 2.4397867988137283\n",
      "Epoch 3800 / 10000 loss: 14.53333067893982\n",
      "MSE train 5.633429099790819 MSE test 12.133802329648669\n",
      "MAE train 1.6404506220779336 MAE test 2.4397746077155804\n",
      "Epoch 3801 / 10000 loss: 14.532832145690918\n",
      "MSE train 5.633308366958567 MSE test 12.133653677429386\n",
      "MAE train 1.6404327817581343 MAE test 2.4397567564782636\n",
      "Epoch 3802 / 10000 loss: 14.53228759765625\n",
      "MSE train 5.6331604312760835 MSE test 12.133431339407005\n",
      "MAE train 1.6404104241187523 MAE test 2.4397340927779494\n",
      "Epoch 3803 / 10000 loss: 14.531802892684937\n",
      "MSE train 5.633011968999127 MSE test 12.133329979764088\n",
      "MAE train 1.6403848720261751 MAE test 2.4397222611949\n",
      "Epoch 3804 / 10000 loss: 14.531333446502686\n",
      "MSE train 5.632863319126608 MSE test 12.133225819547643\n",
      "MAE train 1.6403594342978625 MAE test 2.4397144649124582\n",
      "Epoch 3805 / 10000 loss: 14.530709743499756\n",
      "MSE train 5.632729007528463 MSE test 12.133017131654714\n",
      "MAE train 1.640339730758462 MAE test 2.4396890004210325\n",
      "Epoch 3806 / 10000 loss: 14.530150890350342\n",
      "MSE train 5.632579749162259 MSE test 12.132907558370627\n",
      "MAE train 1.6403143209338265 MAE test 2.439680536660946\n",
      "Epoch 3807 / 10000 loss: 14.529651641845703\n",
      "MSE train 5.6324502983040405 MSE test 12.132723233869315\n",
      "MAE train 1.6402952582677983 MAE test 2.43965813277558\n",
      "Epoch 3808 / 10000 loss: 14.529097318649292\n",
      "MSE train 5.632300426958799 MSE test 12.13257075264786\n",
      "MAE train 1.6402708270277717 MAE test 2.439644251610714\n",
      "Epoch 3809 / 10000 loss: 14.528603792190552\n",
      "MSE train 5.632180342399901 MSE test 12.132441622584748\n",
      "MAE train 1.6402526887916586 MAE test 2.439628859762896\n",
      "Epoch 3810 / 10000 loss: 14.52807354927063\n",
      "MSE train 5.6320329215177996 MSE test 12.132203822868089\n",
      "MAE train 1.640230718579561 MAE test 2.4396042121069197\n",
      "Epoch 3811 / 10000 loss: 14.527583122253418\n",
      "MSE train 5.631880240829182 MSE test 12.13210291173676\n",
      "MAE train 1.6402042418498306 MAE test 2.4395924217924025\n",
      "Epoch 3812 / 10000 loss: 14.527127027511597\n",
      "MSE train 5.631740342011898 MSE test 12.132034997381844\n",
      "MAE train 1.6401799481543478 MAE test 2.4395891441643283\n",
      "Epoch 3813 / 10000 loss: 14.526486873626709\n",
      "MSE train 5.631600690037833 MSE test 12.131750842123035\n",
      "MAE train 1.6401609206293102 MAE test 2.439554096601785\n",
      "Epoch 3814 / 10000 loss: 14.525937557220459\n",
      "MSE train 5.631469055874597 MSE test 12.131745716675729\n",
      "MAE train 1.6401371749364182 MAE test 2.4395588269178377\n",
      "Epoch 3815 / 10000 loss: 14.525467157363892\n",
      "MSE train 5.631332442536123 MSE test 12.131385822095659\n",
      "MAE train 1.640120552090686 MAE test 2.439514243235963\n",
      "Epoch 3816 / 10000 loss: 14.52491545677185\n",
      "MSE train 5.631169339751658 MSE test 12.13140772124704\n",
      "MAE train 1.6400887621130555 MAE test 2.439522424075553\n",
      "Epoch 3817 / 10000 loss: 14.524513483047485\n",
      "MSE train 5.631039064041073 MSE test 12.131209450009818\n",
      "MAE train 1.640069720864586 MAE test 2.4394981933964877\n",
      "Epoch 3818 / 10000 loss: 14.523821115493774\n",
      "MSE train 5.6308879920689385 MSE test 12.131062481486419\n",
      "MAE train 1.6400448077592724 MAE test 2.439484953686342\n",
      "Epoch 3819 / 10000 loss: 14.523326635360718\n",
      "MSE train 5.630768569589578 MSE test 12.13092150565258\n",
      "MAE train 1.640027086603105 MAE test 2.439468011318983\n",
      "Epoch 3820 / 10000 loss: 14.52278995513916\n",
      "MSE train 5.630621069622858 MSE test 12.130689716631592\n",
      "MAE train 1.6400049628872437 MAE test 2.439444083404617\n",
      "Epoch 3821 / 10000 loss: 14.522306680679321\n",
      "MSE train 5.630470262676218 MSE test 12.130588577165769\n",
      "MAE train 1.6399789001976797 MAE test 2.4394322385100398\n",
      "Epoch 3822 / 10000 loss: 14.52184772491455\n",
      "MSE train 5.630326440085941 MSE test 12.130505642697386\n",
      "MAE train 1.6399539981531293 MAE test 2.4394270472935786\n",
      "Epoch 3823 / 10000 loss: 14.521214962005615\n",
      "MSE train 5.630187308202515 MSE test 12.130253310072504\n",
      "MAE train 1.6399342497363687 MAE test 2.4393960064109654\n",
      "Epoch 3824 / 10000 loss: 14.520660400390625\n",
      "MSE train 5.630053000579597 MSE test 12.130215117801654\n",
      "MAE train 1.6399106580365532 MAE test 2.439396504919859\n",
      "Epoch 3825 / 10000 loss: 14.520171642303467\n",
      "MSE train 5.62991651773615 MSE test 12.129890288079984\n",
      "MAE train 1.639893357172652 MAE test 2.439356322600553\n",
      "Epoch 3826 / 10000 loss: 14.519632577896118\n",
      "MSE train 5.629766455253211 MSE test 12.129909307670614\n",
      "MAE train 1.6398646144682956 MAE test 2.439364122151268\n",
      "Epoch 3827 / 10000 loss: 14.519203186035156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.629626579638304 MSE test 12.129625526858486\n",
      "MAE train 1.6398454933307107 MAE test 2.4393290712756928\n",
      "Epoch 3828 / 10000 loss: 14.518564462661743\n",
      "MSE train 5.629495534621383 MSE test 12.129618229822348\n",
      "MAE train 1.6398219352684906 MAE test 2.4393335086562193\n",
      "Epoch 3829 / 10000 loss: 14.518092393875122\n",
      "MSE train 5.629358985157582 MSE test 12.12925860829542\n",
      "MAE train 1.6398053095190663 MAE test 2.439288922849855\n",
      "Epoch 3830 / 10000 loss: 14.517544984817505\n",
      "MSE train 5.629196081346781 MSE test 12.129280453186157\n",
      "MAE train 1.6397735690911477 MAE test 2.439297085720833\n",
      "Epoch 3831 / 10000 loss: 14.517144203186035\n",
      "MSE train 5.629065882816018 MSE test 12.12908199395724\n",
      "MAE train 1.6397545419407933 MAE test 2.4392728098814236\n",
      "Epoch 3832 / 10000 loss: 14.516453266143799\n",
      "MSE train 5.628914997849774 MSE test 12.128936029687273\n",
      "MAE train 1.6397296276632232 MAE test 2.439259674225985\n",
      "Epoch 3833 / 10000 loss: 14.515959739685059\n",
      "MSE train 5.628795712301841 MSE test 12.128794259985233\n",
      "MAE train 1.6397119556535515 MAE test 2.4392426279924524\n",
      "Epoch 3834 / 10000 loss: 14.515422582626343\n",
      "MSE train 5.628648362002165 MSE test 12.128563574601007\n",
      "MAE train 1.6396898399831068 MAE test 2.439218816379099\n",
      "Epoch 3835 / 10000 loss: 14.514941930770874\n",
      "MSE train 5.628497975620185 MSE test 12.128462553303413\n",
      "MAE train 1.639663860552977 MAE test 2.439206956537607\n",
      "Epoch 3836 / 10000 loss: 14.514482498168945\n",
      "MSE train 5.628353802567346 MSE test 12.12837760480788\n",
      "MAE train 1.6396389143533214 MAE test 2.439201513132516\n",
      "Epoch 3837 / 10000 loss: 14.5138521194458\n",
      "MSE train 5.628215073016694 MSE test 12.12813001738879\n",
      "MAE train 1.6396191184213238 MAE test 2.439171054193154\n",
      "Epoch 3838 / 10000 loss: 14.513299703598022\n",
      "MSE train 5.628079369582171 MSE test 12.128085811344278\n",
      "MAE train 1.639595341836031 MAE test 2.4391707806234733\n",
      "Epoch 3839 / 10000 loss: 14.512807846069336\n",
      "MSE train 5.627942478709975 MSE test 12.12777304543928\n",
      "MAE train 1.6395776804985662 MAE test 2.4391320916722243\n",
      "Epoch 3840 / 10000 loss: 14.512268304824829\n",
      "MSE train 5.627798502445293 MSE test 12.127788634852726\n",
      "MAE train 1.6395504473362674 MAE test 2.439139442697229\n",
      "Epoch 3841 / 10000 loss: 14.511828660964966\n",
      "MSE train 5.627660015591804 MSE test 12.127476000780064\n",
      "MAE train 1.6395323737782233 MAE test 2.439100752657656\n",
      "Epoch 3842 / 10000 loss: 14.511216163635254\n",
      "MSE train 5.62751841825118 MSE test 12.127488284958337\n",
      "MAE train 1.639505774710759 MAE test 2.4391076843322668\n",
      "Epoch 3843 / 10000 loss: 14.510772228240967\n",
      "MSE train 5.62738009957202 MSE test 12.127166760118879\n",
      "MAE train 1.639487940503036 MAE test 2.4390678551306006\n",
      "Epoch 3844 / 10000 loss: 14.510170459747314\n",
      "MSE train 5.627234232357071 MSE test 12.127182006330715\n",
      "MAE train 1.6394602507892735 MAE test 2.439075163909076\n",
      "Epoch 3845 / 10000 loss: 14.509732961654663\n",
      "MSE train 5.627094818623266 MSE test 12.126880076993833\n",
      "MAE train 1.639441682177135 MAE test 2.439037807513649\n",
      "Epoch 3846 / 10000 loss: 14.509111881256104\n",
      "MSE train 5.626958850020586 MSE test 12.126885490802534\n",
      "MAE train 1.6394166093352975 MAE test 2.4390438612238277\n",
      "Epoch 3847 / 10000 loss: 14.508656024932861\n",
      "MSE train 5.626821596028008 MSE test 12.1265414469444\n",
      "MAE train 1.6393994938535963 MAE test 2.43900119245122\n",
      "Epoch 3848 / 10000 loss: 14.508080005645752\n",
      "MSE train 5.626664523544565 MSE test 12.126561948579132\n",
      "MAE train 1.6393690486843708 MAE test 2.439009193054199\n",
      "Epoch 3849 / 10000 loss: 14.507664918899536\n",
      "MSE train 5.626526111284195 MSE test 12.126321996085228\n",
      "MAE train 1.6393491127624216 MAE test 2.438979666274581\n",
      "Epoch 3850 / 10000 loss: 14.506997346878052\n",
      "MSE train 5.626385706210504 MSE test 12.126257869473742\n",
      "MAE train 1.6393246645809525 MAE test 2.4389768702405275\n",
      "Epoch 3851 / 10000 loss: 14.506501913070679\n",
      "MSE train 5.626247211122261 MSE test 12.1259823071664\n",
      "MAE train 1.6393056809832522 MAE test 2.4389428573216696\n",
      "Epoch 3852 / 10000 loss: 14.50595498085022\n",
      "MSE train 5.6261165564831055 MSE test 12.125974558167234\n",
      "MAE train 1.6392822474493642 MAE test 2.438947259180407\n",
      "Epoch 3853 / 10000 loss: 14.505483150482178\n",
      "MSE train 5.625980820978554 MSE test 12.125614595191891\n",
      "MAE train 1.6392658117699426 MAE test 2.438902586815\n",
      "Epoch 3854 / 10000 loss: 14.504940032958984\n",
      "MSE train 5.625817585923313 MSE test 12.125637335144294\n",
      "MAE train 1.6392339661704098 MAE test 2.4389108920481255\n",
      "Epoch 3855 / 10000 loss: 14.50454306602478\n",
      "MSE train 5.625688768224717 MSE test 12.125444051468415\n",
      "MAE train 1.6392151677261095 MAE test 2.438887251729944\n",
      "Epoch 3856 / 10000 loss: 14.503851652145386\n",
      "MSE train 5.625538081576293 MSE test 12.125288939008076\n",
      "MAE train 1.6391905179408195 MAE test 2.438872951793527\n",
      "Epoch 3857 / 10000 loss: 14.50335955619812\n",
      "MSE train 5.625418900980081 MSE test 12.125156364666674\n",
      "MAE train 1.6391726515669456 MAE test 2.4388570447419724\n",
      "Epoch 3858 / 10000 loss: 14.502830982208252\n",
      "MSE train 5.6252714300884845 MSE test 12.124920581677438\n",
      "MAE train 1.6391505932741077 MAE test 2.4388325794688446\n",
      "Epoch 3859 / 10000 loss: 14.502344608306885\n",
      "MSE train 5.625119973709349 MSE test 12.124819771207585\n",
      "MAE train 1.6391243644085103 MAE test 2.438820748214311\n",
      "Epoch 3860 / 10000 loss: 14.50188946723938\n",
      "MSE train 5.624978895922684 MSE test 12.124746303659407\n",
      "MAE train 1.6390998968069983 MAE test 2.438816755022965\n",
      "Epoch 3861 / 10000 loss: 14.501255512237549\n",
      "MSE train 5.624839576586901 MSE test 12.124475065214105\n",
      "MAE train 1.6390805874924992 MAE test 2.4387832833311998\n",
      "Epoch 3862 / 10000 loss: 14.500707387924194\n",
      "MSE train 5.624709165981652 MSE test 12.124459248469627\n",
      "MAE train 1.6390573990284603 MAE test 2.4387866204290125\n",
      "Epoch 3863 / 10000 loss: 14.500230550765991\n",
      "MSE train 5.624573288021743 MSE test 12.124103654071817\n",
      "MAE train 1.6390408532557703 MAE test 2.4387424943009957\n",
      "Epoch 3864 / 10000 loss: 14.499692916870117\n",
      "MSE train 5.624411250685198 MSE test 12.12412626688996\n",
      "MAE train 1.639009271066921 MAE test 2.4387507853493715\n",
      "Epoch 3865 / 10000 loss: 14.499292373657227\n",
      "MSE train 5.624279646438514 MSE test 12.123922921257961\n",
      "MAE train 1.6389900182925892 MAE test 2.438725875665181\n",
      "Epoch 3866 / 10000 loss: 14.498605012893677\n",
      "MSE train 5.624129237403335 MSE test 12.12378986221926\n",
      "MAE train 1.6389648725069987 MAE test 2.438714357739871\n",
      "Epoch 3867 / 10000 loss: 14.49811053276062\n",
      "MSE train 5.624007895880983 MSE test 12.123634576013217\n",
      "MAE train 1.6389470339281098 MAE test 2.438695563864146\n",
      "Epoch 3868 / 10000 loss: 14.497568130493164\n",
      "MSE train 5.623860598008654 MSE test 12.123423799650283\n",
      "MAE train 1.6389245280250453 MAE test 2.4386742477807632\n",
      "Epoch 3869 / 10000 loss: 14.49708890914917\n",
      "MSE train 5.623717447629821 MSE test 12.12332201647036\n",
      "MAE train 1.6389001828852001 MAE test 2.438662280212805\n",
      "Epoch 3870 / 10000 loss: 14.496614456176758\n",
      "MSE train 5.623566569870792 MSE test 12.123188623229757\n",
      "MAE train 1.6388748893259648 MAE test 2.4386507210921216\n",
      "Epoch 3871 / 10000 loss: 14.496013879776001\n",
      "MSE train 5.623444472853919 MSE test 12.12302844628977\n",
      "MAE train 1.6388569761023346 MAE test 2.4386312947267816\n",
      "Epoch 3872 / 10000 loss: 14.495469570159912\n",
      "MSE train 5.623296717555839 MSE test 12.122824225648294\n",
      "MAE train 1.6388342185246383 MAE test 2.438610814570013\n",
      "Epoch 3873 / 10000 loss: 14.494990110397339\n",
      "MSE train 5.623156975331976 MSE test 12.122720800217865\n",
      "MAE train 1.6388107244166168 MAE test 2.4385986264267916\n",
      "Epoch 3874 / 10000 loss: 14.494507551193237\n",
      "MSE train 5.62300578425726 MSE test 12.122568545409619\n",
      "MAE train 1.6387858552020145 MAE test 2.4385846865875793\n",
      "Epoch 3875 / 10000 loss: 14.493921995162964\n",
      "MSE train 5.6228868595665285 MSE test 12.122430929355293\n",
      "MAE train 1.6387681790363453 MAE test 2.4385681230840057\n",
      "Epoch 3876 / 10000 loss: 14.493389129638672\n",
      "MSE train 5.622739469794033 MSE test 12.12219769310365\n",
      "MAE train 1.6387460821737805 MAE test 2.4385439638869504\n",
      "Epoch 3877 / 10000 loss: 14.492907285690308\n",
      "MSE train 5.622588622902971 MSE test 12.122097021180954\n",
      "MAE train 1.6387199854411016 MAE test 2.438532166758292\n",
      "Epoch 3878 / 10000 loss: 14.49245023727417\n",
      "MSE train 5.622446091610591 MSE test 12.12201832495462\n",
      "MAE train 1.6386952793708631 MAE test 2.438527510698153\n",
      "Epoch 3879 / 10000 loss: 14.491818904876709\n",
      "MSE train 5.622307001047782 MSE test 12.121759083904827\n",
      "MAE train 1.6386757079465912 MAE test 2.438495537234002\n",
      "Epoch 3880 / 10000 loss: 14.4912691116333\n",
      "MSE train 5.622175062929318 MSE test 12.121730829236462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6386524559875937 MAE test 2.4384973131474195\n",
      "Epoch 3881 / 10000 loss: 14.490785837173462\n",
      "MSE train 5.62203922108338 MSE test 12.121390893735548\n",
      "MAE train 1.6386356056927975 MAE test 2.4384551511910755\n",
      "Epoch 3882 / 10000 loss: 14.49025011062622\n",
      "MSE train 5.621882201884701 MSE test 12.121412958759684\n",
      "MAE train 1.6386051410245757 MAE test 2.4384633593551333\n",
      "Epoch 3883 / 10000 loss: 14.489837646484375\n",
      "MSE train 5.621743834881807 MSE test 12.121172677202651\n",
      "MAE train 1.6385852242836472 MAE test 2.43843376109214\n",
      "Epoch 3884 / 10000 loss: 14.489170789718628\n",
      "MSE train 5.621604263013704 MSE test 12.121111879021793\n",
      "MAE train 1.6385609011960318 MAE test 2.4384314063965733\n",
      "Epoch 3885 / 10000 loss: 14.488677263259888\n",
      "MSE train 5.621466047572973 MSE test 12.120831440247294\n",
      "MAE train 1.63854210642827 MAE test 2.438396763738513\n",
      "Epoch 3886 / 10000 loss: 14.488131284713745\n",
      "MSE train 5.621334683490061 MSE test 12.120828745592242\n",
      "MAE train 1.6385183801795105 MAE test 2.438401798439477\n",
      "Epoch 3887 / 10000 loss: 14.48766541481018\n",
      "MSE train 5.6211987603194995 MSE test 12.120469863426866\n",
      "MAE train 1.6385018831884557 MAE test 2.4383572309109844\n",
      "Epoch 3888 / 10000 loss: 14.487116575241089\n",
      "MSE train 5.621035850852643 MSE test 12.12049266391689\n",
      "MAE train 1.638470097906272 MAE test 2.438365546434632\n",
      "Epoch 3889 / 10000 loss: 14.486719608306885\n",
      "MSE train 5.620906492292537 MSE test 12.12029782624376\n",
      "MAE train 1.6384512037381742 MAE test 2.4383417033318953\n",
      "Epoch 3890 / 10000 loss: 14.486029863357544\n",
      "MSE train 5.620755849082017 MSE test 12.120147378743326\n",
      "MAE train 1.6384264339812356 MAE test 2.438327992349661\n",
      "Epoch 3891 / 10000 loss: 14.485538721084595\n",
      "MSE train 5.6206368223069925 MSE test 12.12001134699616\n",
      "MAE train 1.6384087068364988 MAE test 2.438311643709364\n",
      "Epoch 3892 / 10000 loss: 14.48500657081604\n",
      "MSE train 5.620489567869005 MSE test 12.119777583119792\n",
      "MAE train 1.6383866563520824 MAE test 2.43828739744688\n",
      "Epoch 3893 / 10000 loss: 14.484525203704834\n",
      "MSE train 5.620338481130843 MSE test 12.119677363277077\n",
      "MAE train 1.638360495104012 MAE test 2.438275657257668\n",
      "Epoch 3894 / 10000 loss: 14.484069108963013\n",
      "MSE train 5.620196414226522 MSE test 12.119600719988892\n",
      "MAE train 1.6383358677003257 MAE test 2.43827124518492\n",
      "Epoch 3895 / 10000 loss: 14.48343825340271\n",
      "MSE train 5.620057181371573 MSE test 12.119337388397538\n",
      "MAE train 1.6383163562477545 MAE test 2.4382387497233036\n",
      "Epoch 3896 / 10000 loss: 14.482888460159302\n",
      "MSE train 5.619926078983857 MSE test 12.119314113324213\n",
      "MAE train 1.638293196522859 MAE test 2.438241158073623\n",
      "Epoch 3897 / 10000 loss: 14.482406854629517\n",
      "MSE train 5.619790230638854 MSE test 12.118967620164856\n",
      "MAE train 1.6382764768933193 MAE test 2.4381981657488097\n",
      "Epoch 3898 / 10000 loss: 14.481873035430908\n",
      "MSE train 5.619630632279184 MSE test 12.118990121955727\n",
      "MAE train 1.6382454363607661 MAE test 2.4382064231142797\n",
      "Epoch 3899 / 10000 loss: 14.481465816497803\n",
      "MSE train 5.61949461366124 MSE test 12.118767494124349\n",
      "MAE train 1.638225643482833 MAE test 2.438179060058063\n",
      "Epoch 3900 / 10000 loss: 14.480788707733154\n",
      "MSE train 5.619348217186543 MSE test 12.118675332904798\n",
      "MAE train 1.6382004159549104 MAE test 2.438172723643844\n",
      "Epoch 3901 / 10000 loss: 14.480292081832886\n",
      "MSE train 5.619212562460344 MSE test 12.118457628670017\n",
      "MAE train 1.6381806458856543 MAE test 2.4381460147619483\n",
      "Epoch 3902 / 10000 loss: 14.479740619659424\n",
      "MSE train 5.619067072276236 MSE test 12.118372553289394\n",
      "MAE train 1.6381554811491015 MAE test 2.4381405813170502\n",
      "Epoch 3903 / 10000 loss: 14.479244947433472\n",
      "MSE train 5.618930537365951 MSE test 12.118148409235154\n",
      "MAE train 1.6381356734270356 MAE test 2.4381130609853727\n",
      "Epoch 3904 / 10000 loss: 14.478692531585693\n",
      "MSE train 5.618787782594488 MSE test 12.118078311584155\n",
      "MAE train 1.6381108193746834 MAE test 2.4381095305289464\n",
      "Epoch 3905 / 10000 loss: 14.478197813034058\n",
      "MSE train 5.618649650144781 MSE test 12.117826010529262\n",
      "MAE train 1.6380913492024185 MAE test 2.438078456148725\n",
      "Epoch 3906 / 10000 loss: 14.477648496627808\n",
      "MSE train 5.6185170362412284 MSE test 12.117798049132084\n",
      "MAE train 1.6380679701684036 MAE test 2.438080261909636\n",
      "Epoch 3907 / 10000 loss: 14.477165460586548\n",
      "MSE train 5.6183815402430755 MSE test 12.117461283096116\n",
      "MAE train 1.6380511500667343 MAE test 2.4380384981735754\n",
      "Epoch 3908 / 10000 loss: 14.47663140296936\n",
      "MSE train 5.618224944218397 MSE test 12.117484004929254\n",
      "MAE train 1.638020790183029 MAE test 2.438046788927295\n",
      "Epoch 3909 / 10000 loss: 14.476217031478882\n",
      "MSE train 5.6180860711351865 MSE test 12.117239850915482\n",
      "MAE train 1.6380008517489475 MAE test 2.438016704533228\n",
      "Epoch 3910 / 10000 loss: 14.475552558898926\n",
      "MSE train 5.617948254634103 MSE test 12.117186538448465\n",
      "MAE train 1.6379767998893464 MAE test 2.4380152727336983\n",
      "Epoch 3911 / 10000 loss: 14.47506046295166\n",
      "MSE train 5.6178103866516 MSE test 12.116891630753443\n",
      "MAE train 1.6379584538911505 MAE test 2.4379787963923354\n",
      "Epoch 3912 / 10000 loss: 14.474518299102783\n",
      "MSE train 5.617674485631624 MSE test 12.116899286872474\n",
      "MAE train 1.6379334108815724 MAE test 2.4379851366180674\n",
      "Epoch 3913 / 10000 loss: 14.474064826965332\n",
      "MSE train 5.617537611426447 MSE test 12.116553925686443\n",
      "MAE train 1.6379164235193517 MAE test 2.4379422656747587\n",
      "Epoch 3914 / 10000 loss: 14.473491430282593\n",
      "MSE train 5.617379114596284 MSE test 12.116575916280198\n",
      "MAE train 1.637885647435248 MAE test 2.437950457592512\n",
      "Epoch 3915 / 10000 loss: 14.473081111907959\n",
      "MSE train 5.617241694909503 MSE test 12.116345491895139\n",
      "MAE train 1.6378657312509606 MAE test 2.4379221138944294\n",
      "Epoch 3916 / 10000 loss: 14.472408294677734\n",
      "MSE train 5.617097781498437 MSE test 12.116267143584372\n",
      "MAE train 1.6378407610089958 MAE test 2.4379175079365\n",
      "Epoch 3917 / 10000 loss: 14.471912622451782\n",
      "MSE train 5.616959383958623 MSE test 12.116022377484931\n",
      "MAE train 1.6378210130662032 MAE test 2.4378873892594863\n",
      "Epoch 3918 / 10000 loss: 14.471362113952637\n",
      "MSE train 5.616823828951033 MSE test 12.115981228799846\n",
      "MAE train 1.6377972539042376 MAE test 2.43788749502055\n",
      "Epoch 3919 / 10000 loss: 14.470872640609741\n",
      "MSE train 5.616687129722336 MSE test 12.115667165707382\n",
      "MAE train 1.6377796661913377 MAE test 2.437848598200129\n",
      "Epoch 3920 / 10000 loss: 14.470334768295288\n",
      "MSE train 5.6165415178124425 MSE test 12.115684459098878\n",
      "MAE train 1.637752047523739 MAE test 2.4378561658196323\n",
      "Epoch 3921 / 10000 loss: 14.469900131225586\n",
      "MSE train 5.616402422957393 MSE test 12.115379889908187\n",
      "MAE train 1.6377336446174282 MAE test 2.4378184463873787\n",
      "Epoch 3922 / 10000 loss: 14.469282865524292\n",
      "MSE train 5.616263993429552 MSE test 12.115389128476936\n",
      "MAE train 1.637707938102099 MAE test 2.437824992824892\n",
      "Epoch 3923 / 10000 loss: 14.468832015991211\n",
      "MSE train 5.616126030377732 MSE test 12.115054666606495\n",
      "MAE train 1.6376904836285002 MAE test 2.43778349488867\n",
      "Epoch 3924 / 10000 loss: 14.468246936798096\n",
      "MSE train 5.615972604419334 MSE test 12.11507410278028\n",
      "MAE train 1.6376609502184523 MAE test 2.4377913293278874\n",
      "Epoch 3925 / 10000 loss: 14.467824459075928\n",
      "MSE train 5.615832262693741 MSE test 12.11481161217163\n",
      "MAE train 1.6376411519460221 MAE test 2.4377589325970628\n",
      "Epoch 3926 / 10000 loss: 14.46717381477356\n",
      "MSE train 5.6156999754326895 MSE test 12.114782075244621\n",
      "MAE train 1.6376178941251411 MAE test 2.4377605034379126\n",
      "Epoch 3927 / 10000 loss: 14.46668815612793\n",
      "MSE train 5.615563199381118 MSE test 12.114442820509238\n",
      "MAE train 1.637600833753115 MAE test 2.4377184115656405\n",
      "Epoch 3928 / 10000 loss: 14.466153383255005\n",
      "MSE train 5.615406210415991 MSE test 12.114464479999654\n",
      "MAE train 1.637570435293987 MAE test 2.437726559752919\n",
      "Epoch 3929 / 10000 loss: 14.465739011764526\n",
      "MSE train 5.6152669216917 MSE test 12.114221687787872\n",
      "MAE train 1.6375504020401963 MAE test 2.437696647512986\n",
      "Epoch 3930 / 10000 loss: 14.465073347091675\n",
      "MSE train 5.6151278561918225 MSE test 12.114164935801426\n",
      "MAE train 1.637526174426163 MAE test 2.4376947674241864\n",
      "Epoch 3931 / 10000 loss: 14.464579343795776\n",
      "MSE train 5.614989187495451 MSE test 12.113876519739026\n",
      "MAE train 1.6375075267119277 MAE test 2.437659112895962\n",
      "Epoch 3932 / 10000 loss: 14.464035511016846\n",
      "MSE train 5.614855105510489 MSE test 12.11387971645555\n",
      "MAE train 1.637483076293715 MAE test 2.4376648673884715\n",
      "Epoch 3933 / 10000 loss: 14.463575839996338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.614718076921608 MSE test 12.113526791194936\n",
      "MAE train 1.637466252538706 MAE test 2.437621051739032\n",
      "Epoch 3934 / 10000 loss: 14.463013887405396\n",
      "MSE train 5.614556207256833 MSE test 12.113548949850362\n",
      "MAE train 1.6374347781823853 MAE test 2.437629249170117\n",
      "Epoch 3935 / 10000 loss: 14.462610244750977\n",
      "MSE train 5.614422151544866 MSE test 12.113339439226579\n",
      "MAE train 1.6374151691871124 MAE test 2.437603544552915\n",
      "Epoch 3936 / 10000 loss: 14.461926460266113\n",
      "MSE train 5.614271705161822 MSE test 12.113220063301522\n",
      "MAE train 1.6373897202129282 MAE test 2.437593743574832\n",
      "Epoch 3937 / 10000 loss: 14.461429595947266\n",
      "MSE train 5.614144853220247 MSE test 12.113046988672828\n",
      "MAE train 1.6373710967709456 MAE test 2.437572680629455\n",
      "Epoch 3938 / 10000 loss: 14.460880517959595\n",
      "MSE train 5.61399527043691 MSE test 12.112871351803484\n",
      "MAE train 1.6373473162674226 MAE test 2.4375557649528585\n",
      "Epoch 3939 / 10000 loss: 14.460395097732544\n",
      "MSE train 5.613868115006434 MSE test 12.112758559435495\n",
      "MAE train 1.6373271899612452 MAE test 2.4375423932498745\n",
      "Epoch 3940 / 10000 loss: 14.459887504577637\n",
      "MSE train 5.613718881352397 MSE test 12.112542014964484\n",
      "MAE train 1.6373044160979298 MAE test 2.4375202848159017\n",
      "Epoch 3941 / 10000 loss: 14.459361791610718\n",
      "MSE train 5.613573328089435 MSE test 12.112439993215084\n",
      "MAE train 1.637279607654772 MAE test 2.437508306057204\n",
      "Epoch 3942 / 10000 loss: 14.458887815475464\n",
      "MSE train 5.613421751038329 MSE test 12.112315281477077\n",
      "MAE train 1.6372540294624505 MAE test 2.4374978045416\n",
      "Epoch 3943 / 10000 loss: 14.458280801773071\n",
      "MSE train 5.613294935645155 MSE test 12.1121419906889\n",
      "MAE train 1.6372354454166245 MAE test 2.4374767072169656\n",
      "Epoch 3944 / 10000 loss: 14.457731008529663\n",
      "MSE train 5.613144818616309 MSE test 12.11196279989215\n",
      "MAE train 1.637211652182493 MAE test 2.437459343674953\n",
      "Epoch 3945 / 10000 loss: 14.457244396209717\n",
      "MSE train 5.613016168783322 MSE test 12.111850816276359\n",
      "MAE train 1.637191184905139 MAE test 2.4374460760657564\n",
      "Epoch 3946 / 10000 loss: 14.456738948822021\n",
      "MSE train 5.6128660965914365 MSE test 12.111638970539014\n",
      "MAE train 1.6371681623596415 MAE test 2.437424559172742\n",
      "Epoch 3947 / 10000 loss: 14.456206560134888\n",
      "MSE train 5.612722417493441 MSE test 12.111535759045829\n",
      "MAE train 1.6371438790714454 MAE test 2.437412427579222\n",
      "Epoch 3948 / 10000 loss: 14.455726385116577\n",
      "MSE train 5.612569551409908 MSE test 12.11139687653613\n",
      "MAE train 1.6371184096372051 MAE test 2.4374001394306393\n",
      "Epoch 3949 / 10000 loss: 14.45512866973877\n",
      "MSE train 5.612446808668974 MSE test 12.111242763249374\n",
      "MAE train 1.6371004073843807 MAE test 2.437381488976064\n",
      "Epoch 3950 / 10000 loss: 14.454585075378418\n",
      "MSE train 5.612297229537193 MSE test 12.111028210068488\n",
      "MAE train 1.637077616063394 MAE test 2.437359647621158\n",
      "Epoch 3951 / 10000 loss: 14.454102993011475\n",
      "MSE train 5.612150858104083 MSE test 12.110926375142963\n",
      "MAE train 1.6370527122552703 MAE test 2.437347700782886\n",
      "Epoch 3952 / 10000 loss: 14.453628301620483\n",
      "MSE train 5.611998109626179 MSE test 12.110799563614437\n",
      "MAE train 1.6370270062200856 MAE test 2.437336940239683\n",
      "Epoch 3953 / 10000 loss: 14.453020095825195\n",
      "MSE train 5.611870963315789 MSE test 12.110629186254728\n",
      "MAE train 1.637008394394756 MAE test 2.4373162316018813\n",
      "Epoch 3954 / 10000 loss: 14.452468633651733\n",
      "MSE train 5.611719786855207 MSE test 12.110443658401836\n",
      "MAE train 1.6369846364155551 MAE test 2.4372980657373278\n",
      "Epoch 3955 / 10000 loss: 14.451981544494629\n",
      "MSE train 5.611586887495131 MSE test 12.110333893109718\n",
      "MAE train 1.6369632051025071 MAE test 2.4372850927089265\n",
      "Epoch 3956 / 10000 loss: 14.451478481292725\n",
      "MSE train 5.611434625274385 MSE test 12.11013375893602\n",
      "MAE train 1.6369395605266246 MAE test 2.437265045444777\n",
      "Epoch 3957 / 10000 loss: 14.450928688049316\n",
      "MSE train 5.611295666004008 MSE test 12.11002672874174\n",
      "MAE train 1.636916639515751 MAE test 2.4372524499927177\n",
      "Epoch 3958 / 10000 loss: 14.450434684753418\n",
      "MSE train 5.611141172404852 MSE test 12.109853430914942\n",
      "MAE train 1.6368918630426528 MAE test 2.4372358069725495\n",
      "Epoch 3959 / 10000 loss: 14.449860334396362\n",
      "MSE train 5.611014880801836 MSE test 12.109731824727755\n",
      "MAE train 1.6368724012697486 MAE test 2.43722132735139\n",
      "Epoch 3960 / 10000 loss: 14.449337244033813\n",
      "MSE train 5.610862284629542 MSE test 12.109502906454784\n",
      "MAE train 1.6368493940724391 MAE test 2.437197673257557\n",
      "Epoch 3961 / 10000 loss: 14.448822975158691\n",
      "MSE train 5.610709091142099 MSE test 12.10940058767534\n",
      "MAE train 1.636823158023064 MAE test 2.4371856921751163\n",
      "Epoch 3962 / 10000 loss: 14.44835114479065\n",
      "MSE train 5.610557359852561 MSE test 12.109302728557283\n",
      "MAE train 1.6367972314576686 MAE test 2.4371785874208434\n",
      "Epoch 3963 / 10000 loss: 14.44771957397461\n",
      "MSE train 5.610415248569917 MSE test 12.109078137396486\n",
      "MAE train 1.6367766150202878 MAE test 2.437151060622292\n",
      "Epoch 3964 / 10000 loss: 14.44715666770935\n",
      "MSE train 5.610264374866731 MSE test 12.108995696768297\n",
      "MAE train 1.6367506868348836 MAE test 2.437145949511355\n",
      "Epoch 3965 / 10000 loss: 14.446648120880127\n",
      "MSE train 5.610119572976283 MSE test 12.108758113281395\n",
      "MAE train 1.6367298901644043 MAE test 2.4371168058236594\n",
      "Epoch 3966 / 10000 loss: 14.446083545684814\n",
      "MSE train 5.609972989941636 MSE test 12.10870311306907\n",
      "MAE train 1.636704560318385 MAE test 2.4371151867040517\n",
      "Epoch 3967 / 10000 loss: 14.44557499885559\n",
      "MSE train 5.609826187981341 MSE test 12.10841102400133\n",
      "MAE train 1.6366848656243818 MAE test 2.437079138443138\n",
      "Epoch 3968 / 10000 loss: 14.445013284683228\n",
      "MSE train 5.609680811274301 MSE test 12.1084142373771\n",
      "MAE train 1.6366586381689623 MAE test 2.437084952228442\n",
      "Epoch 3969 / 10000 loss: 14.44453477859497\n",
      "MSE train 5.6095317865594385 MSE test 12.108061389043906\n",
      "MAE train 1.6366400386308078 MAE test 2.437041243035126\n",
      "Epoch 3970 / 10000 loss: 14.443940877914429\n",
      "MSE train 5.609356462357842 MSE test 12.108080042065284\n",
      "MAE train 1.6366066454736643 MAE test 2.4370490644496954\n",
      "Epoch 3971 / 10000 loss: 14.44350290298462\n",
      "MSE train 5.609203295176882 MSE test 12.107859463491076\n",
      "MAE train 1.6365842337227867 MAE test 2.43702206122112\n",
      "Epoch 3972 / 10000 loss: 14.442781686782837\n",
      "MSE train 5.609032384800162 MSE test 12.107749640982316\n",
      "MAE train 1.6365554997813787 MAE test 2.437013583142676\n",
      "Epoch 3973 / 10000 loss: 14.442233562469482\n",
      "MSE train 5.608871748751469 MSE test 12.10754822837749\n",
      "MAE train 1.6365317324954356 MAE test 2.436989072525404\n",
      "Epoch 3974 / 10000 loss: 14.441613674163818\n",
      "MSE train 5.608683937333469 MSE test 12.107412565948772\n",
      "MAE train 1.6365008287626348 MAE test 2.4369773891828435\n",
      "Epoch 3975 / 10000 loss: 14.441030502319336\n",
      "MSE train 5.608509592183718 MSE test 12.107249668848455\n",
      "MAE train 1.636474627862703 MAE test 2.436957835886586\n",
      "Epoch 3976 / 10000 loss: 14.44036316871643\n",
      "MSE train 5.608287330760966 MSE test 12.107029292068765\n",
      "MAE train 1.63644009861094 MAE test 2.4369355416079808\n",
      "Epoch 3977 / 10000 loss: 14.439701080322266\n",
      "MSE train 5.608032743333959 MSE test 12.10691317078789\n",
      "MAE train 1.6363973381985386 MAE test 2.4369221047971803\n",
      "Epoch 3978 / 10000 loss: 14.438950777053833\n",
      "MSE train 5.607717330590394 MSE test 12.106757021573376\n",
      "MAE train 1.6363447345987328 MAE test 2.4369080704617434\n",
      "Epoch 3979 / 10000 loss: 14.437921047210693\n",
      "MSE train 5.607387152496072 MSE test 12.106577337808003\n",
      "MAE train 1.6362921986005685 MAE test 2.4368867088593062\n",
      "Epoch 3980 / 10000 loss: 14.436718702316284\n",
      "MSE train 5.607061152317561 MSE test 12.106340545981839\n",
      "MAE train 1.6362398788606465 MAE test 2.4368625467983835\n",
      "Epoch 3981 / 10000 loss: 14.43537712097168\n",
      "MSE train 5.606826660904726 MSE test 12.106220574709871\n",
      "MAE train 1.6362000721162522 MAE test 2.436848594409859\n",
      "Epoch 3982 / 10000 loss: 14.434169054031372\n",
      "MSE train 5.606637367507883 MSE test 12.106076468953209\n",
      "MAE train 1.636168369619912 MAE test 2.43683572801825\n",
      "Epoch 3983 / 10000 loss: 14.43320345878601\n",
      "MSE train 5.606497353078771 MSE test 12.105911229306862\n",
      "MAE train 1.636147488297542 MAE test 2.436815676932593\n",
      "Epoch 3984 / 10000 loss: 14.432509899139404\n",
      "MSE train 5.606340387855319 MSE test 12.10570377312518\n",
      "MAE train 1.6361231126230473 MAE test 2.436794703180177\n",
      "Epoch 3985 / 10000 loss: 14.431957483291626\n",
      "MSE train 5.606195884250777 MSE test 12.105599244915204\n",
      "MAE train 1.6360986344006083 MAE test 2.4367823601557395\n",
      "Epoch 3986 / 10000 loss: 14.43143630027771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.606042076577271 MSE test 12.1054454784226\n",
      "MAE train 1.6360731125249786 MAE test 2.436768147567235\n",
      "Epoch 3987 / 10000 loss: 14.430825471878052\n",
      "MSE train 5.605921644568281 MSE test 12.105309248975178\n",
      "MAE train 1.6360549145176035 MAE test 2.4367517676864834\n",
      "Epoch 3988 / 10000 loss: 14.430277347564697\n",
      "MSE train 5.605773528375095 MSE test 12.105075983635578\n",
      "MAE train 1.6360324636042451 MAE test 2.4367275242862667\n",
      "Epoch 3989 / 10000 loss: 14.429782390594482\n",
      "MSE train 5.605622659167307 MSE test 12.104976340021507\n",
      "MAE train 1.6360061269888562 MAE test 2.4367158525853587\n",
      "Epoch 3990 / 10000 loss: 14.429315090179443\n",
      "MSE train 5.605480179076921 MSE test 12.10489754960395\n",
      "MAE train 1.6359812303613632 MAE test 2.4367111111113915\n",
      "Epoch 3991 / 10000 loss: 14.428677082061768\n",
      "MSE train 5.605341353796053 MSE test 12.104640676757661\n",
      "MAE train 1.6359614786805992 MAE test 2.436679466210698\n",
      "Epoch 3992 / 10000 loss: 14.428121566772461\n",
      "MSE train 5.605209636591087 MSE test 12.104611384656714\n",
      "MAE train 1.6359380778913444 MAE test 2.4366810288892706\n",
      "Epoch 3993 / 10000 loss: 14.427631616592407\n",
      "MSE train 5.605074109366091 MSE test 12.104275478987054\n",
      "MAE train 1.635921042885126 MAE test 2.436639391600948\n",
      "Epoch 3994 / 10000 loss: 14.42709231376648\n",
      "MSE train 5.604918791915577 MSE test 12.104297387856258\n",
      "MAE train 1.6358907242359315 MAE test 2.4366475101761513\n",
      "Epoch 3995 / 10000 loss: 14.426671743392944\n",
      "MSE train 5.604780328016451 MSE test 12.104051951104477\n",
      "MAE train 1.63587073468146 MAE test 2.4366172831608988\n",
      "Epoch 3996 / 10000 loss: 14.426004886627197\n",
      "MSE train 5.604644133805951 MSE test 12.104001653752487\n",
      "MAE train 1.6358467420948184 MAE test 2.436616186698415\n",
      "Epoch 3997 / 10000 loss: 14.425509214401245\n",
      "MSE train 5.604507119351717 MSE test 12.103701653388027\n",
      "MAE train 1.6358285274880502 MAE test 2.4365790863666854\n",
      "Epoch 3998 / 10000 loss: 14.42496395111084\n",
      "MSE train 5.604369535436548 MSE test 12.103712280553816\n",
      "MAE train 1.635802750233938 MAE test 2.436585759091609\n",
      "Epoch 3999 / 10000 loss: 14.424511194229126\n",
      "MSE train 5.604232759448516 MSE test 12.103377793989015\n",
      "MAE train 1.635785386902964 MAE test 2.4365442924963876\n",
      "Epoch 4000 / 10000 loss: 14.423922061920166\n",
      "MSE train 5.604079587824369 MSE test 12.103397738118344\n",
      "MAE train 1.635755625820052 MAE test 2.4365521612712686\n",
      "Epoch 4001 / 10000 loss: 14.423497438430786\n",
      "MSE train 5.603940275892254 MSE test 12.103140112459736\n",
      "MAE train 1.6357357543018327 MAE test 2.4365204136818903\n",
      "Epoch 4002 / 10000 loss: 14.422839164733887\n",
      "MSE train 5.603807822605375 MSE test 12.103105064106458\n",
      "MAE train 1.6357123269707543 MAE test 2.4365212475015996\n",
      "Epoch 4003 / 10000 loss: 14.422347784042358\n",
      "MSE train 5.603671682924197 MSE test 12.10277480741335\n",
      "MAE train 1.6356950407383541 MAE test 2.4364803516782\n",
      "Epoch 4004 / 10000 loss: 14.421807527542114\n",
      "MSE train 5.60351940584863 MSE test 12.102794901795264\n",
      "MAE train 1.6356655202434058 MAE test 2.436488240966232\n",
      "Epoch 4005 / 10000 loss: 14.421380043029785\n",
      "MSE train 5.6033798416823135 MSE test 12.102529765930214\n",
      "MAE train 1.6356457846516934 MAE test 2.4364555569733657\n",
      "Epoch 4006 / 10000 loss: 14.420726537704468\n",
      "MSE train 5.603248929942034 MSE test 12.102504072538517\n",
      "MAE train 1.6356225336458585 MAE test 2.4364576048548683\n",
      "Epoch 4007 / 10000 loss: 14.420238256454468\n",
      "MSE train 5.603112888864488 MSE test 12.10215935410723\n",
      "MAE train 1.635605579061003 MAE test 2.4364148873599203\n",
      "Epoch 4008 / 10000 loss: 14.419697999954224\n",
      "MSE train 5.602954463883112 MSE test 12.102180610599568\n",
      "MAE train 1.6355746059405631 MAE test 2.436422959935624\n",
      "Epoch 4009 / 10000 loss: 14.419282913208008\n",
      "MSE train 5.602817590689621 MSE test 12.101952354581606\n",
      "MAE train 1.6355546154029894 MAE test 2.436394943027309\n",
      "Epoch 4010 / 10000 loss: 14.418603420257568\n",
      "MSE train 5.602673219282034 MSE test 12.10186921497763\n",
      "MAE train 1.6355294490800274 MAE test 2.436389715855905\n",
      "Epoch 4011 / 10000 loss: 14.418100833892822\n",
      "MSE train 5.602535439383059 MSE test 12.101631684958697\n",
      "MAE train 1.635509505187331 MAE test 2.436360580222298\n",
      "Epoch 4012 / 10000 loss: 14.417542219161987\n",
      "MSE train 5.602397184353435 MSE test 12.101578185314068\n",
      "MAE train 1.6354851967750992 MAE test 2.4363591311793833\n",
      "Epoch 4013 / 10000 loss: 14.417044401168823\n",
      "MSE train 5.602259486257399 MSE test 12.101286164182673\n",
      "MAE train 1.635466678312507 MAE test 2.4363231077110066\n",
      "Epoch 4014 / 10000 loss: 14.416495084762573\n",
      "MSE train 5.602124248669357 MSE test 12.101291330634345\n",
      "MAE train 1.6354416766905555 MAE test 2.436329136403526\n",
      "Epoch 4015 / 10000 loss: 14.4160315990448\n",
      "MSE train 5.601987401000527 MSE test 12.100942486210627\n",
      "MAE train 1.635424641957192 MAE test 2.4362859434663293\n",
      "Epoch 4016 / 10000 loss: 14.41545557975769\n",
      "MSE train 5.601827507477306 MSE test 12.100962710910643\n",
      "MAE train 1.6353934001871815 MAE test 2.4362939039625076\n",
      "Epoch 4017 / 10000 loss: 14.415039777755737\n",
      "MSE train 5.6016911216305285 MSE test 12.100739696539334\n",
      "MAE train 1.635373392429346 MAE test 2.4362665836241706\n",
      "Epoch 4018 / 10000 loss: 14.414354801177979\n",
      "MSE train 5.601543887909567 MSE test 12.100643359596706\n",
      "MAE train 1.6353479249085203 MAE test 2.4362597473393373\n",
      "Epoch 4019 / 10000 loss: 14.413848400115967\n",
      "MSE train 5.601408061142029 MSE test 12.100427777542135\n",
      "MAE train 1.635327932200324 MAE test 2.436233418458799\n",
      "Epoch 4020 / 10000 loss: 14.41328740119934\n",
      "MSE train 5.601260824749453 MSE test 12.100333414547661\n",
      "MAE train 1.635302438015766 MAE test 2.4362268540938263\n",
      "Epoch 4021 / 10000 loss: 14.412781953811646\n",
      "MSE train 5.601125071483634 MSE test 12.100120491135744\n",
      "MAE train 1.6352824258488847 MAE test 2.4362008739140464\n",
      "Epoch 4022 / 10000 loss: 14.412220478057861\n",
      "MSE train 5.600977339717344 MSE test 12.100024252531341\n",
      "MAE train 1.635256876368022 MAE test 2.4361940913082476\n",
      "Epoch 4023 / 10000 loss: 14.411714315414429\n",
      "MSE train 5.600842135359982 MSE test 12.099815611123377\n",
      "MAE train 1.6352368815666887 MAE test 2.436168661474661\n",
      "Epoch 4024 / 10000 loss: 14.411151885986328\n",
      "MSE train 5.600693216195613 MSE test 12.099710753800263\n",
      "MAE train 1.6352112690300897 MAE test 2.4361608067919485\n",
      "Epoch 4025 / 10000 loss: 14.410644054412842\n",
      "MSE train 5.600560760107266 MSE test 12.099516816363135\n",
      "MAE train 1.6351915832487192 MAE test 2.4361372569957225\n",
      "Epoch 4026 / 10000 loss: 14.4100821018219\n",
      "MSE train 5.600409991389333 MSE test 12.099381310285878\n",
      "MAE train 1.6351663143089432 MAE test 2.436125554270924\n",
      "Epoch 4027 / 10000 loss: 14.409576892852783\n",
      "MSE train 5.600287749126811 MSE test 12.099230544535764\n",
      "MAE train 1.6351481078515366 MAE test 2.4361074646447367\n",
      "Epoch 4028 / 10000 loss: 14.409025192260742\n",
      "MSE train 5.600139463066826 MSE test 12.099008393880537\n",
      "MAE train 1.6351254954512913 MAE test 2.436084853395565\n",
      "Epoch 4029 / 10000 loss: 14.408533811569214\n",
      "MSE train 5.599990777809376 MSE test 12.098904956487587\n",
      "MAE train 1.6350997887458727 MAE test 2.436072821546645\n",
      "Epoch 4030 / 10000 loss: 14.408053874969482\n",
      "MSE train 5.599840052137219 MSE test 12.098790557315441\n",
      "MAE train 1.635073941619308 MAE test 2.4360637808798664\n",
      "Epoch 4031 / 10000 loss: 14.407423734664917\n",
      "MSE train 5.59970676633232 MSE test 12.098591279843513\n",
      "MAE train 1.6350541679412807 MAE test 2.43603959858705\n",
      "Epoch 4032 / 10000 loss: 14.406856775283813\n",
      "MSE train 5.599554860846643 MSE test 12.09845334340144\n",
      "MAE train 1.635028676970725 MAE test 2.436027642122314\n",
      "Epoch 4033 / 10000 loss: 14.40634822845459\n",
      "MSE train 5.599431594414811 MSE test 12.09829909486918\n",
      "MAE train 1.6350103132839822 MAE test 2.4360091672107904\n",
      "Epoch 4034 / 10000 loss: 14.40579104423523\n",
      "MSE train 5.599282114668348 MSE test 12.098077086804755\n",
      "MAE train 1.6349874291956001 MAE test 2.435986618292404\n",
      "Epoch 4035 / 10000 loss: 14.405295848846436\n",
      "MSE train 5.599133462900283 MSE test 12.097971621636546\n",
      "MAE train 1.6349617693935254 MAE test 2.4359743987479376\n",
      "Epoch 4036 / 10000 loss: 14.404808282852173\n",
      "MSE train 5.598980924502325 MSE test 12.09784882575183\n",
      "MAE train 1.6349357055525775 MAE test 2.435964359714828\n",
      "Epoch 4037 / 10000 loss: 14.40417766571045\n",
      "MSE train 5.598849084256148 MSE test 12.097658390551002\n",
      "MAE train 1.6349161126978522 MAE test 2.4359413580672036\n",
      "Epoch 4038 / 10000 loss: 14.403605937957764\n",
      "MSE train 5.598695943641254 MSE test 12.097496119823262\n",
      "MAE train 1.6348909617457204 MAE test 2.4359263828587996\n",
      "Epoch 4039 / 10000 loss: 14.40309453010559\n",
      "MSE train 5.598572320777967 MSE test 12.097361803849658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6348720454617776 MAE test 2.435910530996196\n",
      "Epoch 4040 / 10000 loss: 14.402547121047974\n",
      "MSE train 5.598420922636488 MSE test 12.097118180648339\n",
      "MAE train 1.6348491864487085 MAE test 2.4358853250603203\n",
      "Epoch 4041 / 10000 loss: 14.402031898498535\n",
      "MSE train 5.59826477495334 MSE test 12.097010423393838\n",
      "MAE train 1.6348219332803975 MAE test 2.4358729122429423\n",
      "Epoch 4042 / 10000 loss: 14.401551961898804\n",
      "MSE train 5.598119056151362 MSE test 12.096929222594376\n",
      "MAE train 1.6347965175226034 MAE test 2.4358681882764404\n",
      "Epoch 4043 / 10000 loss: 14.400888919830322\n",
      "MSE train 5.59797410380519 MSE test 12.096647753464993\n",
      "MAE train 1.634776122896079 MAE test 2.435833793242075\n",
      "Epoch 4044 / 10000 loss: 14.400310039520264\n",
      "MSE train 5.597837694768174 MSE test 12.096623622374649\n",
      "MAE train 1.634751708513331 MAE test 2.4358363638605702\n",
      "Epoch 4045 / 10000 loss: 14.399800539016724\n",
      "MSE train 5.597694891025319 MSE test 12.096257970762412\n",
      "MAE train 1.634733800484598 MAE test 2.4357913962294475\n",
      "Epoch 4046 / 10000 loss: 14.399226188659668\n",
      "MSE train 5.597525606924944 MSE test 12.096268850332999\n",
      "MAE train 1.63470077453052 MAE test 2.435798481660635\n",
      "Epoch 4047 / 10000 loss: 14.398787021636963\n",
      "MSE train 5.597385982630208 MSE test 12.09605552079587\n",
      "MAE train 1.6346799645771402 MAE test 2.43577273573774\n",
      "Epoch 4048 / 10000 loss: 14.398056268692017\n",
      "MSE train 5.597226621607615 MSE test 12.095907222697615\n",
      "MAE train 1.6346531710427956 MAE test 2.4357596994911983\n",
      "Epoch 4049 / 10000 loss: 14.397515296936035\n",
      "MSE train 5.597095705380825 MSE test 12.095741635491274\n",
      "MAE train 1.6346335255145656 MAE test 2.435740043580848\n",
      "Epoch 4050 / 10000 loss: 14.396924257278442\n",
      "MSE train 5.596937451161377 MSE test 12.095512731154201\n",
      "MAE train 1.6346090791556318 MAE test 2.435716887799718\n",
      "Epoch 4051 / 10000 loss: 14.396389722824097\n",
      "MSE train 5.596780881971254 MSE test 12.095396703074242\n",
      "MAE train 1.6345821548686161 MAE test 2.435703596407883\n",
      "Epoch 4052 / 10000 loss: 14.395856142044067\n",
      "MSE train 5.596617522958301 MSE test 12.095255717377484\n",
      "MAE train 1.6345543977486545 MAE test 2.435691555900611\n",
      "Epoch 4053 / 10000 loss: 14.395184993743896\n",
      "MSE train 5.596477885256881 MSE test 12.095066485185406\n",
      "MAE train 1.6345334259373525 MAE test 2.435668997074489\n",
      "Epoch 4054 / 10000 loss: 14.394564867019653\n",
      "MSE train 5.5963137647697945 MSE test 12.094868773825896\n",
      "MAE train 1.6345070991296522 MAE test 2.4356498777993902\n",
      "Epoch 4055 / 10000 loss: 14.394003868103027\n",
      "MSE train 5.5961697143349145 MSE test 12.094739015832529\n",
      "MAE train 1.6344837524655442 MAE test 2.4356349322272117\n",
      "Epoch 4056 / 10000 loss: 14.393417358398438\n",
      "MSE train 5.596003824196152 MSE test 12.094510228369819\n",
      "MAE train 1.6344578302561132 MAE test 2.435611932563888\n",
      "Epoch 4057 / 10000 loss: 14.39279842376709\n",
      "MSE train 5.5958449929083285 MSE test 12.09438746903109\n",
      "MAE train 1.634430874325593 MAE test 2.435597925460932\n",
      "Epoch 4058 / 10000 loss: 14.392226219177246\n",
      "MSE train 5.595675371741703 MSE test 12.094223019699811\n",
      "MAE train 1.6344025709926486 MAE test 2.43558306247036\n",
      "Epoch 4059 / 10000 loss: 14.39154052734375\n",
      "MSE train 5.5955371909745555 MSE test 12.09405711695102\n",
      "MAE train 1.6343817341788032 MAE test 2.435563565904764\n",
      "Epoch 4060 / 10000 loss: 14.390905141830444\n",
      "MSE train 5.5953714882448145 MSE test 12.093813782046142\n",
      "MAE train 1.6343563334137794 MAE test 2.435538763999013\n",
      "Epoch 4061 / 10000 loss: 14.390328884124756\n",
      "MSE train 5.595206052333942 MSE test 12.093694733495093\n",
      "MAE train 1.6343278962008985 MAE test 2.43552524484026\n",
      "Epoch 4062 / 10000 loss: 14.389768362045288\n",
      "MSE train 5.595041984480328 MSE test 12.093575240568386\n",
      "MAE train 1.6342998994722757 MAE test 2.435516013332667\n",
      "Epoch 4063 / 10000 loss: 14.389055728912354\n",
      "MSE train 5.594891997750321 MSE test 12.093346448553705\n",
      "MAE train 1.6342776431110364 MAE test 2.4354885229721797\n",
      "Epoch 4064 / 10000 loss: 14.388415098190308\n",
      "MSE train 5.594730540711559 MSE test 12.093230937749924\n",
      "MAE train 1.6342499738778946 MAE test 2.435479819374356\n",
      "Epoch 4065 / 10000 loss: 14.387838125228882\n",
      "MSE train 5.594585596754558 MSE test 12.09301817816733\n",
      "MAE train 1.6342282563748376 MAE test 2.4354543020385235\n",
      "Epoch 4066 / 10000 loss: 14.387212753295898\n",
      "MSE train 5.594425687230552 MSE test 12.092887057017794\n",
      "MAE train 1.6342011150529456 MAE test 2.435443589048302\n",
      "Epoch 4067 / 10000 loss: 14.386651754379272\n",
      "MSE train 5.5942915533739646 MSE test 12.092710226722541\n",
      "MAE train 1.6341809971158245 MAE test 2.4354225367368167\n",
      "Epoch 4068 / 10000 loss: 14.38604736328125\n",
      "MSE train 5.594135710663154 MSE test 12.092515305019768\n",
      "MAE train 1.6341563586424726 MAE test 2.4354037070257943\n",
      "Epoch 4069 / 10000 loss: 14.385513305664062\n",
      "MSE train 5.593997709862753 MSE test 12.092399826031153\n",
      "MAE train 1.6341337184625326 MAE test 2.4353903733952995\n",
      "Epoch 4070 / 10000 loss: 14.38497281074524\n",
      "MSE train 5.593842793274442 MSE test 12.092198853340575\n",
      "MAE train 1.6341093116586036 MAE test 2.435370682697675\n",
      "Epoch 4071 / 10000 loss: 14.384386777877808\n",
      "MSE train 5.593705087821373 MSE test 12.092085367710256\n",
      "MAE train 1.634086536179362 MAE test 2.435357550622612\n",
      "Epoch 4072 / 10000 loss: 14.38386082649231\n",
      "MSE train 5.593551035226921 MSE test 12.09189692088195\n",
      "MAE train 1.63406188946905 MAE test 2.4353393956662863\n",
      "Epoch 4073 / 10000 loss: 14.383274793624878\n",
      "MSE train 5.593420741899029 MSE test 12.091779486350076\n",
      "MAE train 1.6340409021304225 MAE test 2.435325683252622\n",
      "Epoch 4074 / 10000 loss: 14.382747173309326\n",
      "MSE train 5.593269174374366 MSE test 12.091568101199316\n",
      "MAE train 1.6340173115034737 MAE test 2.435304593392308\n",
      "Epoch 4075 / 10000 loss: 14.382195472717285\n",
      "MSE train 5.593127276785903 MSE test 12.091461561849036\n",
      "MAE train 1.6339932047256964 MAE test 2.4352922164953372\n",
      "Epoch 4076 / 10000 loss: 14.381698846817017\n",
      "MSE train 5.5929744712720115 MSE test 12.091312125700094\n",
      "MAE train 1.6339677467154317 MAE test 2.435278921686951\n",
      "Epoch 4077 / 10000 loss: 14.38109803199768\n",
      "MSE train 5.59285425769183 MSE test 12.09116839304204\n",
      "MAE train 1.6339497671451682 MAE test 2.4352617276265063\n",
      "Epoch 4078 / 10000 loss: 14.380552053451538\n",
      "MSE train 5.592705987166532 MSE test 12.090940326542102\n",
      "MAE train 1.6339272689889648 MAE test 2.4352385186743772\n",
      "Epoch 4079 / 10000 loss: 14.380062818527222\n",
      "MSE train 5.5925563387514545 MSE test 12.090839606124028\n",
      "MAE train 1.6339012634158472 MAE test 2.4352268140625175\n",
      "Epoch 4080 / 10000 loss: 14.379594326019287\n",
      "MSE train 5.592410830300325 MSE test 12.090749812304265\n",
      "MAE train 1.6338759961687557 MAE test 2.435220966261477\n",
      "Epoch 4081 / 10000 loss: 14.378963708877563\n",
      "MSE train 5.592273407750108 MSE test 12.090516864509071\n",
      "MAE train 1.633855971814141 MAE test 2.4351924564936662\n",
      "Epoch 4082 / 10000 loss: 14.37840747833252\n",
      "MSE train 5.592133209212943 MSE test 12.090455625624479\n",
      "MAE train 1.6338313733004743 MAE test 2.435190242280024\n",
      "Epoch 4083 / 10000 loss: 14.377910137176514\n",
      "MSE train 5.5919954131422225 MSE test 12.090185165080301\n",
      "MAE train 1.6338122077224129 MAE test 2.4351569874798784\n",
      "Epoch 4084 / 10000 loss: 14.37736177444458\n",
      "MSE train 5.591865464538612 MSE test 12.090178340852658\n",
      "MAE train 1.6337888135140604 MAE test 2.4351616329517465\n",
      "Epoch 4085 / 10000 loss: 14.376888036727905\n",
      "MSE train 5.59173048810555 MSE test 12.089822518888038\n",
      "MAE train 1.633772264708072 MAE test 2.435117602813741\n",
      "Epoch 4086 / 10000 loss: 14.376347780227661\n",
      "MSE train 5.591568689273766 MSE test 12.089848422678708\n",
      "MAE train 1.6337405049891092 MAE test 2.435126435854387\n",
      "Epoch 4087 / 10000 loss: 14.375949621200562\n",
      "MSE train 5.591440059331022 MSE test 12.08965464446296\n",
      "MAE train 1.633721529365562 MAE test 2.435102755618038\n",
      "Epoch 4088 / 10000 loss: 14.3752601146698\n",
      "MSE train 5.591290608873693 MSE test 12.089510083835275\n",
      "MAE train 1.6336967474537307 MAE test 2.435090009520767\n",
      "Epoch 4089 / 10000 loss: 14.374769687652588\n",
      "MSE train 5.591172687237674 MSE test 12.089374034079931\n",
      "MAE train 1.6336790673686428 MAE test 2.435073632314107\n",
      "Epoch 4090 / 10000 loss: 14.374239444732666\n",
      "MSE train 5.591026685456517 MSE test 12.089146576272046\n",
      "MAE train 1.6336570325671844 MAE test 2.435050430046836\n",
      "Epoch 4091 / 10000 loss: 14.373759746551514\n",
      "MSE train 5.59087772685155 MSE test 12.089048457255597\n",
      "MAE train 1.6336310502386642 MAE test 2.4350388898494204\n",
      "Epoch 4092 / 10000 loss: 14.373305320739746\n",
      "MSE train 5.59073585770675 MSE test 12.088970396336729\n",
      "MAE train 1.6336063278138202 MAE test 2.435034470651228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4093 / 10000 loss: 14.372678518295288\n",
      "MSE train 5.590598581299938 MSE test 12.088721570641011\n",
      "MAE train 1.6335866786945725 MAE test 2.4350038197709982\n",
      "Epoch 4094 / 10000 loss: 14.372132062911987\n",
      "MSE train 5.590466250139526 MSE test 12.088688162716862\n",
      "MAE train 1.6335632952480414 MAE test 2.4350050732486115\n",
      "Epoch 4095 / 10000 loss: 14.37164831161499\n",
      "MSE train 5.590331502834709 MSE test 12.088367536086302\n",
      "MAE train 1.6335460450917638 MAE test 2.4349653706230447\n",
      "Epoch 4096 / 10000 loss: 14.371115446090698\n",
      "MSE train 5.5901838891731614 MSE test 12.088391012404307\n",
      "MAE train 1.6335175970556157 MAE test 2.4349738541389714\n",
      "Epoch 4097 / 10000 loss: 14.370691537857056\n",
      "MSE train 5.590046030094234 MSE test 12.088110592735632\n",
      "MAE train 1.633498577763708 MAE test 2.434939177959709\n",
      "Epoch 4098 / 10000 loss: 14.37006163597107\n",
      "MSE train 5.589916968320954 MSE test 12.088108412504807\n",
      "MAE train 1.633475221274382 MAE test 2.434944388208817\n",
      "Epoch 4099 / 10000 loss: 14.369597434997559\n",
      "MSE train 5.589782368129201 MSE test 12.087754074406343\n",
      "MAE train 1.6334586748983486 MAE test 2.434900397235041\n",
      "Epoch 4100 / 10000 loss: 14.36905574798584\n",
      "MSE train 5.589622435731721 MSE test 12.087780823422852\n",
      "MAE train 1.6334272748528158 MAE test 2.4349093241119246\n",
      "Epoch 4101 / 10000 loss: 14.36866044998169\n",
      "MSE train 5.589493480276732 MSE test 12.087582474080458\n",
      "MAE train 1.6334082565758805 MAE test 2.4348849416610356\n",
      "Epoch 4102 / 10000 loss: 14.367980241775513\n",
      "MSE train 5.589345087129365 MSE test 12.08744962254617\n",
      "MAE train 1.6333833990647237 MAE test 2.4348736534004782\n",
      "Epoch 4103 / 10000 loss: 14.36749267578125\n",
      "MSE train 5.589226857475899 MSE test 12.087302561109444\n",
      "MAE train 1.6333658574098635 MAE test 2.434855780156283\n",
      "Epoch 4104 / 10000 loss: 14.366960048675537\n",
      "MSE train 5.589081799273047 MSE test 12.087089079246445\n",
      "MAE train 1.6333437305977667 MAE test 2.4348343470851526\n",
      "Epoch 4105 / 10000 loss: 14.366488218307495\n",
      "MSE train 5.588937815642701 MSE test 12.086990603526191\n",
      "MAE train 1.6333188108410281 MAE test 2.4348226485602513\n",
      "Epoch 4106 / 10000 loss: 14.366027355194092\n",
      "MSE train 5.58879094312712 MSE test 12.086882363986426\n",
      "MAE train 1.6332936568920589 MAE test 2.4348144311106608\n",
      "Epoch 4107 / 10000 loss: 14.365421056747437\n",
      "MSE train 5.588663205444366 MSE test 12.086693857109806\n",
      "MAE train 1.6332747396521232 MAE test 2.4347913060490933\n",
      "Epoch 4108 / 10000 loss: 14.364877223968506\n",
      "MSE train 5.588515782971926 MSE test 12.08655648859082\n",
      "MAE train 1.633250238451847 MAE test 2.434779468928743\n",
      "Epoch 4109 / 10000 loss: 14.36439299583435\n",
      "MSE train 5.588398754701875 MSE test 12.086419132648198\n",
      "MAE train 1.6332327315037674 MAE test 2.4347627931714815\n",
      "Epoch 4110 / 10000 loss: 14.363867282867432\n",
      "MSE train 5.588254295369655 MSE test 12.086194995884098\n",
      "MAE train 1.6332109526603422 MAE test 2.434740044084842\n",
      "Epoch 4111 / 10000 loss: 14.363394260406494\n",
      "MSE train 5.588106624073541 MSE test 12.086096963482644\n",
      "MAE train 1.6331851798088302 MAE test 2.4347283829370365\n",
      "Epoch 4112 / 10000 loss: 14.362945079803467\n",
      "MSE train 5.587965122542888 MSE test 12.086017438243257\n",
      "MAE train 1.6331605233463373 MAE test 2.4347237962279635\n",
      "Epoch 4113 / 10000 loss: 14.362323760986328\n",
      "MSE train 5.587829118514093 MSE test 12.085774153161134\n",
      "MAE train 1.633140952069723 MAE test 2.4346937301689136\n",
      "Epoch 4114 / 10000 loss: 14.361781120300293\n",
      "MSE train 5.58769582062465 MSE test 12.085733879884302\n",
      "MAE train 1.6331174401071005 MAE test 2.4346941326181812\n",
      "Epoch 4115 / 10000 loss: 14.36129879951477\n",
      "MSE train 5.587561427870234 MSE test 12.085427808947575\n",
      "MAE train 1.6330998513942565 MAE test 2.434656164390602\n",
      "Epoch 4116 / 10000 loss: 14.36076807975769\n",
      "MSE train 5.587422069225659 MSE test 12.085447317684526\n",
      "MAE train 1.6330734217414822 MAE test 2.4346641553203274\n",
      "Epoch 4117 / 10000 loss: 14.360334634780884\n",
      "MSE train 5.587286630037855 MSE test 12.085129889385195\n",
      "MAE train 1.6330558211544863 MAE test 2.4346247210946097\n",
      "Epoch 4118 / 10000 loss: 14.359740734100342\n",
      "MSE train 5.587143913995949 MSE test 12.08515063643986\n",
      "MAE train 1.6330285331568208 MAE test 2.434632892551703\n",
      "Epoch 4119 / 10000 loss: 14.359313249588013\n",
      "MSE train 5.587007256882861 MSE test 12.084850736630875\n",
      "MAE train 1.6330101979760088 MAE test 2.434595648005639\n",
      "Epoch 4120 / 10000 loss: 14.358704328536987\n",
      "MSE train 5.58687370754606 MSE test 12.084862138177906\n",
      "MAE train 1.6329853625734814 MAE test 2.4346026130260783\n",
      "Epoch 4121 / 10000 loss: 14.358258247375488\n",
      "MSE train 5.586738889947624 MSE test 12.084523308599312\n",
      "MAE train 1.632968360309311 MAE test 2.43456048250821\n",
      "Epoch 4122 / 10000 loss: 14.357690811157227\n",
      "MSE train 5.586586045449405 MSE test 12.084548813624874\n",
      "MAE train 1.6329385221682766 MAE test 2.434569266745258\n",
      "Epoch 4123 / 10000 loss: 14.357282638549805\n",
      "MSE train 5.586449737648952 MSE test 12.084304133403664\n",
      "MAE train 1.632918842241489 MAE test 2.434538965288523\n",
      "Epoch 4124 / 10000 loss: 14.356631517410278\n",
      "MSE train 5.5863151704886995 MSE test 12.084256636157894\n",
      "MAE train 1.6328951780489152 MAE test 2.4345384615015\n",
      "Epoch 4125 / 10000 loss: 14.356146812438965\n",
      "MSE train 5.5861801050737085 MSE test 12.08396124634095\n",
      "MAE train 1.6328771089677734 MAE test 2.4345017977937937\n",
      "Epoch 4126 / 10000 loss: 14.355614185333252\n",
      "MSE train 5.586046587378929 MSE test 12.083974607366413\n",
      "MAE train 1.6328522602666597 MAE test 2.434509033007786\n",
      "Epoch 4127 / 10000 loss: 14.355170488357544\n",
      "MSE train 5.5859123991089135 MSE test 12.08363417151855\n",
      "MAE train 1.6328354241662737 MAE test 2.434466668532262\n",
      "Epoch 4128 / 10000 loss: 14.354604959487915\n",
      "MSE train 5.585758545115259 MSE test 12.083660396579731\n",
      "MAE train 1.632805343691833 MAE test 2.434475567155856\n",
      "Epoch 4129 / 10000 loss: 14.354199171066284\n",
      "MSE train 5.58562296623978 MSE test 12.083422095876003\n",
      "MAE train 1.6327856747032417 MAE test 2.434446046757138\n",
      "Epoch 4130 / 10000 loss: 14.353543758392334\n",
      "MSE train 5.585485968485396 MSE test 12.083364906335706\n",
      "MAE train 1.6327616423612843 MAE test 2.434444347548386\n",
      "Epoch 4131 / 10000 loss: 14.353057861328125\n",
      "MSE train 5.585350382071151 MSE test 12.083089367220028\n",
      "MAE train 1.6327429371150162 MAE test 2.43441017183156\n",
      "Epoch 4132 / 10000 loss: 14.352522611618042\n",
      "MSE train 5.585222371919581 MSE test 12.083088824759018\n",
      "MAE train 1.6327197761115673 MAE test 2.4344156368137195\n",
      "Epoch 4133 / 10000 loss: 14.352061986923218\n",
      "MSE train 5.585089280065634 MSE test 12.082732196234383\n",
      "MAE train 1.6327035141600892 MAE test 2.4343712419116668\n",
      "Epoch 4134 / 10000 loss: 14.351527452468872\n",
      "MSE train 5.584929607473922 MSE test 12.082760312107311\n",
      "MAE train 1.632672118613286 MAE test 2.434380403097671\n",
      "Epoch 4135 / 10000 loss: 14.351139307022095\n",
      "MSE train 5.584802757385371 MSE test 12.08256533867954\n",
      "MAE train 1.6326534155611339 MAE test 2.434356326099948\n",
      "Epoch 4136 / 10000 loss: 14.350460290908813\n",
      "MSE train 5.584655118785693 MSE test 12.082423687647744\n",
      "MAE train 1.6326289191232637 MAE test 2.4343439809346026\n",
      "Epoch 4137 / 10000 loss: 14.349978685379028\n",
      "MSE train 5.584538806220755 MSE test 12.082285384758238\n",
      "MAE train 1.6326115047956846 MAE test 2.4343270933965857\n",
      "Epoch 4138 / 10000 loss: 14.349455833435059\n",
      "MSE train 5.584394433880995 MSE test 12.082061022202694\n",
      "MAE train 1.6325897309156532 MAE test 2.4343043581446673\n",
      "Epoch 4139 / 10000 loss: 14.348983764648438\n",
      "MSE train 5.584247346305432 MSE test 12.081961301183888\n",
      "MAE train 1.6325640408579425 MAE test 2.4342923999365236\n",
      "Epoch 4140 / 10000 loss: 14.348536252975464\n",
      "MSE train 5.5841064012635515 MSE test 12.081882783403463\n",
      "MAE train 1.6325394745486357 MAE test 2.434287992625173\n",
      "Epoch 4141 / 10000 loss: 14.347917795181274\n",
      "MSE train 5.583970806182501 MSE test 12.08163696350928\n",
      "MAE train 1.6325199770224879 MAE test 2.4342575207602186\n",
      "Epoch 4142 / 10000 loss: 14.347376823425293\n",
      "MSE train 5.583838236770944 MSE test 12.08159880782131\n",
      "MAE train 1.6324965880134752 MAE test 2.434258268095029\n",
      "Epoch 4143 / 10000 loss: 14.34689712524414\n",
      "MSE train 5.583704263870766 MSE test 12.081288818402676\n",
      "MAE train 1.6324791156482221 MAE test 2.4342196935809506\n",
      "Epoch 4144 / 10000 loss: 14.34636902809143\n",
      "MSE train 5.583564184569603 MSE test 12.081309945205529\n",
      "MAE train 1.63245245566321 MAE test 2.4342279717555875\n",
      "Epoch 4145 / 10000 loss: 14.345938920974731\n",
      "MSE train 5.583428790455989 MSE test 12.080997190617492\n",
      "MAE train 1.6324346839234851 MAE test 2.434189032676165\n",
      "Epoch 4146 / 10000 loss: 14.34534215927124\n",
      "MSE train 5.583289550865306 MSE test 12.081016104763332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6324082597290597 MAE test 2.4341970217510775\n",
      "Epoch 4147 / 10000 loss: 14.344910383224487\n",
      "MSE train 5.583153876098454 MSE test 12.080701352896575\n",
      "MAE train 1.6323904710341803 MAE test 2.4341578243211246\n",
      "Epoch 4148 / 10000 loss: 14.344316244125366\n",
      "MSE train 5.583014027012699 MSE test 12.080720376869715\n",
      "MAE train 1.6323638905235345 MAE test 2.4341658265282238\n",
      "Epoch 4149 / 10000 loss: 14.34388542175293\n",
      "MSE train 5.582878215049153 MSE test 12.080408347179116\n",
      "MAE train 1.6323459828793732 MAE test 2.4341269640926715\n",
      "Epoch 4150 / 10000 loss: 14.343287706375122\n",
      "MSE train 5.582740001509405 MSE test 12.080425996027438\n",
      "MAE train 1.6323198340772849 MAE test 2.434134801904269\n",
      "Epoch 4151 / 10000 loss: 14.342854499816895\n",
      "MSE train 5.582604502085237 MSE test 12.08010673017104\n",
      "MAE train 1.6323021843300267 MAE test 2.4340950266884995\n",
      "Epoch 4152 / 10000 loss: 14.342265367507935\n",
      "MSE train 5.582462636798237 MSE test 12.080127297383763\n",
      "MAE train 1.632275077912348 MAE test 2.434103236314319\n",
      "Epoch 4153 / 10000 loss: 14.341837644577026\n",
      "MSE train 5.5823263098246185 MSE test 12.079825013453899\n",
      "MAE train 1.6322567990383148 MAE test 2.4340655960924513\n",
      "Epoch 4154 / 10000 loss: 14.341232061386108\n",
      "MSE train 5.58219289533456 MSE test 12.079837631292007\n",
      "MAE train 1.6322319546748025 MAE test 2.434072788092681\n",
      "Epoch 4155 / 10000 loss: 14.34078860282898\n",
      "MSE train 5.582058332796541 MSE test 12.079499081590507\n",
      "MAE train 1.632214945613045 MAE test 2.4340305710223773\n",
      "Epoch 4156 / 10000 loss: 14.340221643447876\n",
      "MSE train 5.58190663259795 MSE test 12.079524929148741\n",
      "MAE train 1.6321853529159391 MAE test 2.4340394924035857\n",
      "Epoch 4157 / 10000 loss: 14.339813232421875\n",
      "MSE train 5.581770392916091 MSE test 12.079274640589816\n",
      "MAE train 1.632165747795744 MAE test 2.434008361602047\n",
      "Epoch 4158 / 10000 loss: 14.339166164398193\n",
      "MSE train 5.5816378571174345 MSE test 12.07923462352487\n",
      "MAE train 1.6321423951995269 MAE test 2.434008896736808\n",
      "Epoch 4159 / 10000 loss: 14.338684558868408\n",
      "MSE train 5.581503675948111 MSE test 12.078925270216727\n",
      "MAE train 1.6321248176547556 MAE test 2.4339703495967764\n",
      "Epoch 4160 / 10000 loss: 14.338157892227173\n",
      "MSE train 5.581364782477908 MSE test 12.078945543970105\n",
      "MAE train 1.6320984662784395 MAE test 2.433978567623338\n",
      "Epoch 4161 / 10000 loss: 14.33772611618042\n",
      "MSE train 5.5812296842103475 MSE test 12.078627870427331\n",
      "MAE train 1.6320808532918223 MAE test 2.433938953020811\n",
      "Epoch 4162 / 10000 loss: 14.337134838104248\n",
      "MSE train 5.581088289442953 MSE test 12.078648881677525\n",
      "MAE train 1.6320538613953401 MAE test 2.4339472428235704\n",
      "Epoch 4163 / 10000 loss: 14.336707830429077\n",
      "MSE train 5.580952216007609 MSE test 12.07834416170044\n",
      "MAE train 1.6320356842681123 MAE test 2.4339092707671552\n",
      "Epoch 4164 / 10000 loss: 14.336103916168213\n",
      "MSE train 5.580817796952273 MSE test 12.078358452515166\n",
      "MAE train 1.6320105588580822 MAE test 2.4339166923872133\n",
      "Epoch 4165 / 10000 loss: 14.33566427230835\n",
      "MSE train 5.580683110262265 MSE test 12.078023760521196\n",
      "MAE train 1.6319934124294475 MAE test 2.433874943526027\n",
      "Epoch 4166 / 10000 loss: 14.33509111404419\n",
      "MSE train 5.580533536395277 MSE test 12.078049257399949\n",
      "MAE train 1.6319643443779102 MAE test 2.4338838150980924\n",
      "Epoch 4167 / 10000 loss: 14.334679126739502\n",
      "MSE train 5.5803967609224285 MSE test 12.077786962282785\n",
      "MAE train 1.6319448992531296 MAE test 2.433851175350719\n",
      "Epoch 4168 / 10000 loss: 14.334041357040405\n",
      "MSE train 5.580268054306701 MSE test 12.077763262503794\n",
      "MAE train 1.6319220980746867 MAE test 2.433853792883317\n",
      "Epoch 4169 / 10000 loss: 14.333566188812256\n",
      "MSE train 5.5801347353023365 MSE test 12.07742585474474\n",
      "MAE train 1.6319053356572744 MAE test 2.4338117018560643\n",
      "Epoch 4170 / 10000 loss: 14.333042860031128\n",
      "MSE train 5.579982590849837 MSE test 12.077453486276827\n",
      "MAE train 1.6318756069927942 MAE test 2.433820866093355\n",
      "Epoch 4171 / 10000 loss: 14.332637071609497\n",
      "MSE train 5.579846685370407 MSE test 12.077205522411024\n",
      "MAE train 1.63185601194231 MAE test 2.433790008986071\n",
      "Epoch 4172 / 10000 loss: 14.331988096237183\n",
      "MSE train 5.579713519289727 MSE test 12.077163112543047\n",
      "MAE train 1.631832568532117 MAE test 2.4337902707684753\n",
      "Epoch 4173 / 10000 loss: 14.331506967544556\n",
      "MSE train 5.5795792405411735 MSE test 12.076859309597353\n",
      "MAE train 1.6318147970412995 MAE test 2.433752421268031\n",
      "Epoch 4174 / 10000 loss: 14.330979108810425\n",
      "MSE train 5.579443174826515 MSE test 12.076877543798528\n",
      "MAE train 1.6317891990702287 MAE test 2.433760363037226\n",
      "Epoch 4175 / 10000 loss: 14.330542802810669\n",
      "MSE train 5.579308779111905 MSE test 12.076547879067377\n",
      "MAE train 1.6317719992496793 MAE test 2.4337192335899394\n",
      "Epoch 4176 / 10000 loss: 14.32996416091919\n",
      "MSE train 5.5791613622499465 MSE test 12.076573045240568\n",
      "MAE train 1.631743476676451 MAE test 2.433728075367982\n",
      "Epoch 4177 / 10000 loss: 14.329549074172974\n",
      "MSE train 5.579024587005426 MSE test 12.076298867893383\n",
      "MAE train 1.6317243149389005 MAE test 2.4336939371793624\n",
      "Epoch 4178 / 10000 loss: 14.328919649124146\n",
      "MSE train 5.578897528641359 MSE test 12.076289253841502\n",
      "MAE train 1.6317015832930892 MAE test 2.4336983313203833\n",
      "Epoch 4179 / 10000 loss: 14.328453540802002\n",
      "MSE train 5.578764336203467 MSE test 12.075935788998725\n",
      "MAE train 1.631685167590955 MAE test 2.433654218934666\n",
      "Epoch 4180 / 10000 loss: 14.327927112579346\n",
      "MSE train 5.578606662491879 MSE test 12.075964662252122\n",
      "MAE train 1.6316541824585868 MAE test 2.433663549362138\n",
      "Epoch 4181 / 10000 loss: 14.327534914016724\n",
      "MSE train 5.578477025605033 MSE test 12.075756185230553\n",
      "MAE train 1.6316350313780539 MAE test 2.433637662042543\n",
      "Epoch 4182 / 10000 loss: 14.326863527297974\n",
      "MSE train 5.578330712688328 MSE test 12.075641436260964\n",
      "MAE train 1.6316101603884834 MAE test 2.433628804535579\n",
      "Epoch 4183 / 10000 loss: 14.326379299163818\n",
      "MSE train 5.57820888709852 MSE test 12.075471227606542\n",
      "MAE train 1.6315921044037054 MAE test 2.4336077793091544\n",
      "Epoch 4184 / 10000 loss: 14.325845718383789\n",
      "MSE train 5.578063881248644 MSE test 12.07529638544901\n",
      "MAE train 1.631569078303639 MAE test 2.4335913652776844\n",
      "Epoch 4185 / 10000 loss: 14.325372695922852\n",
      "MSE train 5.5779380624872825 MSE test 12.075185944518338\n",
      "MAE train 1.6315485978780537 MAE test 2.4335779100336103\n",
      "Epoch 4186 / 10000 loss: 14.324885129928589\n",
      "MSE train 5.577792477614166 MSE test 12.074990357260088\n",
      "MAE train 1.6315259155831123 MAE test 2.43355886613391\n",
      "Epoch 4187 / 10000 loss: 14.324356079101562\n",
      "MSE train 5.577658248083561 MSE test 12.074884418254237\n",
      "MAE train 1.6315032753903604 MAE test 2.433545988506637\n",
      "Epoch 4188 / 10000 loss: 14.323883295059204\n",
      "MSE train 5.577510499752273 MSE test 12.074730264121886\n",
      "MAE train 1.6314790276814977 MAE test 2.433532170835791\n",
      "Epoch 4189 / 10000 loss: 14.323316812515259\n",
      "MSE train 5.5773939947754165 MSE test 12.074600186224009\n",
      "MAE train 1.631461289600089 MAE test 2.4335161938066077\n",
      "Epoch 4190 / 10000 loss: 14.322803735733032\n",
      "MSE train 5.577249505949725 MSE test 12.074374249831095\n",
      "MAE train 1.6314394946763437 MAE test 2.4334933574518662\n",
      "Epoch 4191 / 10000 loss: 14.3223237991333\n",
      "MSE train 5.577102435997447 MSE test 12.074272757263907\n",
      "MAE train 1.6314137623635057 MAE test 2.4334810609901227\n",
      "Epoch 4192 / 10000 loss: 14.321879148483276\n",
      "MSE train 5.5769631120747425 MSE test 12.074199858170482\n",
      "MAE train 1.6313894543888223 MAE test 2.433477466758186\n",
      "Epoch 4193 / 10000 loss: 14.32125973701477\n",
      "MSE train 5.576827371472978 MSE test 12.073943328483148\n",
      "MAE train 1.6313700977911567 MAE test 2.4334455239104966\n",
      "Epoch 4194 / 10000 loss: 14.320722341537476\n",
      "MSE train 5.576698181997259 MSE test 12.073918515830327\n",
      "MAE train 1.631347212717366 MAE test 2.433448042822696\n",
      "Epoch 4195 / 10000 loss: 14.320249080657959\n",
      "MSE train 5.576565296087381 MSE test 12.073585633071504\n",
      "MAE train 1.6313304320508226 MAE test 2.4334064867124345\n",
      "Epoch 4196 / 10000 loss: 14.31972622871399\n",
      "MSE train 5.576414999600414 MSE test 12.073613533104242\n",
      "MAE train 1.6313011414472207 MAE test 2.4334157215762353\n",
      "Epoch 4197 / 10000 loss: 14.31931757926941\n",
      "MSE train 5.576278701928232 MSE test 12.073354760765664\n",
      "MAE train 1.6312816884872607 MAE test 2.4333834605997944\n",
      "Epoch 4198 / 10000 loss: 14.318676948547363\n",
      "MSE train 5.576149402740325 MSE test 12.073328173809193\n",
      "MAE train 1.631258807264545 MAE test 2.4333857596462574\n",
      "Epoch 4199 / 10000 loss: 14.318201780319214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.576016297138175 MSE test 12.072996677463554\n",
      "MAE train 1.631241928539797 MAE test 2.433344369859566\n",
      "Epoch 4200 / 10000 loss: 14.317678928375244\n",
      "MSE train 5.5758669636017535 MSE test 12.07302428309923\n",
      "MAE train 1.631212885533278 MAE test 2.433353574740961\n",
      "Epoch 4201 / 10000 loss: 14.317268371582031\n",
      "MSE train 5.575730524840211 MSE test 12.072760172064564\n",
      "MAE train 1.631193520284919 MAE test 2.433320642433189\n",
      "Epoch 4202 / 10000 loss: 14.316630363464355\n",
      "MSE train 5.575602471833914 MSE test 12.072740003638192\n",
      "MAE train 1.6311707995431755 MAE test 2.433323754186387\n",
      "Epoch 4203 / 10000 loss: 14.31615924835205\n",
      "MSE train 5.575469529307193 MSE test 12.07239881903239\n",
      "MAE train 1.6311541598232848 MAE test 2.4332811389442397\n",
      "Epoch 4204 / 10000 loss: 14.31563687324524\n",
      "MSE train 5.575316143532228 MSE test 12.072427644695214\n",
      "MAE train 1.6311241204123508 MAE test 2.43329051431356\n",
      "Epoch 4205 / 10000 loss: 14.315235137939453\n",
      "MSE train 5.575181354318502 MSE test 12.072188765442702\n",
      "MAE train 1.6311045214666937 MAE test 2.4332607363418814\n",
      "Epoch 4206 / 10000 loss: 14.314580917358398\n",
      "MSE train 5.575044585103965 MSE test 12.072132169789088\n",
      "MAE train 1.6310805263958401 MAE test 2.4332592733651994\n",
      "Epoch 4207 / 10000 loss: 14.31409740447998\n",
      "MSE train 5.574909552951921 MSE test 12.071858401574556\n",
      "MAE train 1.6310617642440375 MAE test 2.4332251475434408\n",
      "Epoch 4208 / 10000 loss: 14.313565015792847\n",
      "MSE train 5.574782487264638 MSE test 12.071856787378739\n",
      "MAE train 1.6310388787064747 MAE test 2.4332306126236842\n",
      "Epoch 4209 / 10000 loss: 14.313104391098022\n",
      "MSE train 5.574650025882056 MSE test 12.071499372670129\n",
      "MAE train 1.6310226684099158 MAE test 2.4331859574544907\n",
      "Epoch 4210 / 10000 loss: 14.312576532363892\n",
      "MSE train 5.574491236256034 MSE test 12.071529593175173\n",
      "MAE train 1.6309914127638254 MAE test 2.433195523747915\n",
      "Epoch 4211 / 10000 loss: 14.31218934059143\n",
      "MSE train 5.574364519232656 MSE test 12.071331312673063\n",
      "MAE train 1.6309726939468208 MAE test 2.433170863080863\n",
      "Epoch 4212 / 10000 loss: 14.311513900756836\n",
      "MSE train 5.574217564719203 MSE test 12.071195405823113\n",
      "MAE train 1.630948192391317 MAE test 2.433159398153914\n",
      "Epoch 4213 / 10000 loss: 14.311033725738525\n",
      "MSE train 5.574101544896368 MSE test 12.071051716590024\n",
      "MAE train 1.6309308751081093 MAE test 2.4331416582243417\n",
      "Epoch 4214 / 10000 loss: 14.310510873794556\n",
      "MSE train 5.573957830574681 MSE test 12.070833432601885\n",
      "MAE train 1.6309091256794097 MAE test 2.4331198360909108\n",
      "Epoch 4215 / 10000 loss: 14.310043334960938\n",
      "MSE train 5.5738124429241545 MSE test 12.070731984382448\n",
      "MAE train 1.6308837312536042 MAE test 2.4331074946970097\n",
      "Epoch 4216 / 10000 loss: 14.309594869613647\n",
      "MSE train 5.573670136656879 MSE test 12.070646557441188\n",
      "MAE train 1.6308590274125296 MAE test 2.4331023762919393\n",
      "Epoch 4217 / 10000 loss: 14.30898380279541\n",
      "MSE train 5.573536761925762 MSE test 12.070417787487004\n",
      "MAE train 1.630839525409445 MAE test 2.4330738935338507\n",
      "Epoch 4218 / 10000 loss: 14.308443784713745\n",
      "MSE train 5.5733977615646575 MSE test 12.070353454989737\n",
      "MAE train 1.6308151575344347 MAE test 2.433071462070818\n",
      "Epoch 4219 / 10000 loss: 14.307960748672485\n",
      "MSE train 5.57326307474118 MSE test 12.07010019394081\n",
      "MAE train 1.6307959656393543 MAE test 2.4330399102152835\n",
      "Epoch 4220 / 10000 loss: 14.307425260543823\n",
      "MSE train 5.573133982098742 MSE test 12.070078209701187\n",
      "MAE train 1.6307730721778233 MAE test 2.433042832399685\n",
      "Epoch 4221 / 10000 loss: 14.306952476501465\n",
      "MSE train 5.573001671601685 MSE test 12.069744009296079\n",
      "MAE train 1.630756415640254 MAE test 2.433001079490206\n",
      "Epoch 4222 / 10000 loss: 14.30643105506897\n",
      "MSE train 5.5728506485751845 MSE test 12.06977347042692\n",
      "MAE train 1.6307269229419408 MAE test 2.433010562659934\n",
      "Epoch 4223 / 10000 loss: 14.306023836135864\n",
      "MSE train 5.572714833961024 MSE test 12.069519356882601\n",
      "MAE train 1.6307074210908195 MAE test 2.4329788565624955\n",
      "Epoch 4224 / 10000 loss: 14.305380582809448\n",
      "MSE train 5.572584234195396 MSE test 12.06948715669629\n",
      "MAE train 1.630684363803862 MAE test 2.432980494839165\n",
      "Epoch 4225 / 10000 loss: 14.304903745651245\n",
      "MSE train 5.572450893959366 MSE test 12.069166584224726\n",
      "MAE train 1.6306671429608306 MAE test 2.4329404383565403\n",
      "Epoch 4226 / 10000 loss: 14.304381370544434\n",
      "MSE train 5.572307314482314 MSE test 12.069192233783406\n",
      "MAE train 1.6306395425788731 MAE test 2.432949428014965\n",
      "Epoch 4227 / 10000 loss: 14.30396056175232\n",
      "MSE train 5.57217141551405 MSE test 12.06889846835697\n",
      "MAE train 1.630621008761259 MAE test 2.432912727382852\n",
      "Epoch 4228 / 10000 loss: 14.303348064422607\n",
      "MSE train 5.57204185945739 MSE test 12.068907580088641\n",
      "MAE train 1.6305972347680144 MAE test 2.432919596077691\n",
      "Epoch 4229 / 10000 loss: 14.302898406982422\n",
      "MSE train 5.571908396790267 MSE test 12.0685560105327\n",
      "MAE train 1.6305806254427153 MAE test 2.4328756478782068\n",
      "Epoch 4230 / 10000 loss: 14.302350282669067\n",
      "MSE train 5.571752337613149 MSE test 12.068585583302315\n",
      "MAE train 1.630549984268605 MAE test 2.4328851519688968\n",
      "Epoch 4231 / 10000 loss: 14.301955461502075\n",
      "MSE train 5.571621051410846 MSE test 12.068367236767763\n",
      "MAE train 1.6305306166860218 MAE test 2.432857926604064\n",
      "Epoch 4232 / 10000 loss: 14.301291227340698\n",
      "MSE train 5.571476822704591 MSE test 12.06827158369838\n",
      "MAE train 1.6305057894859725 MAE test 2.4328515660327166\n",
      "Epoch 4233 / 10000 loss: 14.300806999206543\n",
      "MSE train 5.571348502193931 MSE test 12.06807318172179\n",
      "MAE train 1.6304866989339097 MAE test 2.4328268937990036\n",
      "Epoch 4234 / 10000 loss: 14.300268650054932\n",
      "MSE train 5.571202898967279 MSE test 12.067956729008598\n",
      "MAE train 1.6304620783135337 MAE test 2.432817938743586\n",
      "Epoch 4235 / 10000 loss: 14.299787521362305\n",
      "MSE train 5.571083629208659 MSE test 12.067796641321918\n",
      "MAE train 1.6304443392100694 MAE test 2.4327980982026642\n",
      "Epoch 4236 / 10000 loss: 14.299257755279541\n",
      "MSE train 5.5709399731167055 MSE test 12.067605522977916\n",
      "MAE train 1.630422030537314 MAE test 2.432779735158459\n",
      "Epoch 4237 / 10000 loss: 14.298790216445923\n",
      "MSE train 5.570805275221057 MSE test 12.067501011765513\n",
      "MAE train 1.6303991991371571 MAE test 2.432766960575342\n",
      "Epoch 4238 / 10000 loss: 14.298320531845093\n",
      "MSE train 5.5706581259941075 MSE test 12.067350119404647\n",
      "MAE train 1.6303750067415128 MAE test 2.432753637712893\n",
      "Epoch 4239 / 10000 loss: 14.297752380371094\n",
      "MSE train 5.570542083882913 MSE test 12.067218894944109\n",
      "MAE train 1.6303573607034967 MAE test 2.43273742625348\n",
      "Epoch 4240 / 10000 loss: 14.297239542007446\n",
      "MSE train 5.570398048222137 MSE test 12.066994008791323\n",
      "MAE train 1.6303356381296885 MAE test 2.432714823823568\n",
      "Epoch 4241 / 10000 loss: 14.296762228012085\n",
      "MSE train 5.570251200056503 MSE test 12.066891989988875\n",
      "MAE train 1.6303098949499315 MAE test 2.432702377242753\n",
      "Epoch 4242 / 10000 loss: 14.296319246292114\n",
      "MSE train 5.570112497972937 MSE test 12.066821519614686\n",
      "MAE train 1.6302856792170675 MAE test 2.4326991756044203\n",
      "Epoch 4243 / 10000 loss: 14.295701742172241\n",
      "MSE train 5.569976950387088 MSE test 12.066562134245123\n",
      "MAE train 1.6302663653555602 MAE test 2.43266679693347\n",
      "Epoch 4244 / 10000 loss: 14.295165538787842\n",
      "MSE train 5.569848600826387 MSE test 12.066541157827201\n",
      "MAE train 1.6302436146352082 MAE test 2.43266986403653\n",
      "Epoch 4245 / 10000 loss: 14.294692993164062\n",
      "MSE train 5.569716057927112 MSE test 12.066203577793054\n",
      "MAE train 1.630226919888655 MAE test 2.4326276630202948\n",
      "Epoch 4246 / 10000 loss: 14.294172286987305\n",
      "MSE train 5.569564314113949 MSE test 12.066233155898226\n",
      "MAE train 1.630197247124648 MAE test 2.4326371831900593\n",
      "Epoch 4247 / 10000 loss: 14.293768882751465\n",
      "MSE train 5.569428937337121 MSE test 12.065985043877255\n",
      "MAE train 1.6301776748445052 MAE test 2.4326061958314034\n",
      "Epoch 4248 / 10000 loss: 14.293121337890625\n",
      "MSE train 5.569296114929275 MSE test 12.065943787858572\n",
      "MAE train 1.6301542882215583 MAE test 2.4326067309582973\n",
      "Epoch 4249 / 10000 loss: 14.29264235496521\n",
      "MSE train 5.569162244929268 MSE test 12.065640848926261\n",
      "MAE train 1.630136465464004 MAE test 2.4325688596325716\n",
      "Epoch 4250 / 10000 loss: 14.292115211486816\n",
      "MSE train 5.569027354736805 MSE test 12.06565985447439\n",
      "MAE train 1.6301111589110875 MAE test 2.4325770253034005\n",
      "Epoch 4251 / 10000 loss: 14.291679859161377\n",
      "MSE train 5.568893596905076 MSE test 12.06532685466323\n",
      "MAE train 1.630094050528393 MAE test 2.4325353686224007\n",
      "Epoch 4252 / 10000 loss: 14.291106224060059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.5687453861938465 MSE test 12.065354253151979\n",
      "MAE train 1.6300652725071547 MAE test 2.43254462075906\n",
      "Epoch 4253 / 10000 loss: 14.290694952011108\n",
      "MSE train 5.568609059984018 MSE test 12.065086596601589\n",
      "MAE train 1.6300459384393693 MAE test 2.4325111677417506\n",
      "Epoch 4254 / 10000 loss: 14.290061712265015\n",
      "MSE train 5.568481771714744 MSE test 12.065070304435443\n",
      "MAE train 1.6300233232609436 MAE test 2.4325148338912244\n",
      "Epoch 4255 / 10000 loss: 14.28959321975708\n",
      "MSE train 5.56834907500784 MSE test 12.064724773743595\n",
      "MAE train 1.630006734575994 MAE test 2.4324716223579554\n",
      "Epoch 4256 / 10000 loss: 14.289071321487427\n",
      "MSE train 5.568194610158808 MSE test 12.064754924968623\n",
      "MAE train 1.6299764337491431 MAE test 2.432481234348524\n",
      "Epoch 4257 / 10000 loss: 14.288673162460327\n",
      "MSE train 5.56806138499004 MSE test 12.064525206954377\n",
      "MAE train 1.6299569010522883 MAE test 2.4324525598868227\n",
      "Epoch 4258 / 10000 loss: 14.288014888763428\n",
      "MSE train 5.567921037650902 MSE test 12.06445251461354\n",
      "MAE train 1.6299323886124586 MAE test 2.432449125254191\n",
      "Epoch 4259 / 10000 loss: 14.28753137588501\n",
      "MSE train 5.567786975593557 MSE test 12.064212786338548\n",
      "MAE train 1.6299129348633077 MAE test 2.4324192147016155\n",
      "Epoch 4260 / 10000 loss: 14.286994695663452\n",
      "MSE train 5.5676532033982715 MSE test 12.064170850638696\n",
      "MAE train 1.6298893637934326 MAE test 2.4324196743678757\n",
      "Epoch 4261 / 10000 loss: 14.286515951156616\n",
      "MSE train 5.56751955720972 MSE test 12.063875209525605\n",
      "MAE train 1.6298714090216078 MAE test 2.4323827217153036\n",
      "Epoch 4262 / 10000 loss: 14.285988330841064\n",
      "MSE train 5.567387241270167 MSE test 12.063892097607763\n",
      "MAE train 1.6298468005301903 MAE test 2.432390617965111\n",
      "Epoch 4263 / 10000 loss: 14.285547494888306\n",
      "MSE train 5.567254147427972 MSE test 12.063548610589205\n",
      "MAE train 1.6298300566550004 MAE test 2.432347638589086\n",
      "Epoch 4264 / 10000 loss: 14.284986972808838\n",
      "MSE train 5.567101039599554 MSE test 12.063578446432832\n",
      "MAE train 1.6298000650931712 MAE test 2.4323572325288594\n",
      "Epoch 4265 / 10000 loss: 14.284586668014526\n",
      "MSE train 5.566966750931386 MSE test 12.06334065991914\n",
      "MAE train 1.6297804728622713 MAE test 2.4323275335633214\n",
      "Epoch 4266 / 10000 loss: 14.283933401107788\n",
      "MSE train 5.566829589153363 MSE test 12.063282134553239\n",
      "MAE train 1.629756407167124 MAE test 2.4323258957668754\n",
      "Epoch 4267 / 10000 loss: 14.283450841903687\n",
      "MSE train 5.566694782604904 MSE test 12.063014104004507\n",
      "MAE train 1.6297374709686279 MAE test 2.432292409458569\n",
      "Epoch 4268 / 10000 loss: 14.282917976379395\n",
      "MSE train 5.566568025179526 MSE test 12.063007547339318\n",
      "MAE train 1.6297147895531645 MAE test 2.432297346426888\n",
      "Epoch 4269 / 10000 loss: 14.282453775405884\n",
      "MSE train 5.566435991969129 MSE test 12.06265381388135\n",
      "MAE train 1.629698510242655 MAE test 2.4322530743980324\n",
      "Epoch 4270 / 10000 loss: 14.281931638717651\n",
      "MSE train 5.566278531478435 MSE test 12.06268526541748\n",
      "MAE train 1.6296675309747717 MAE test 2.432262887052031\n",
      "Epoch 4271 / 10000 loss: 14.281542301177979\n",
      "MSE train 5.566149843657115 MSE test 12.06247785251432\n",
      "MAE train 1.629648449416877 MAE test 2.43223699938131\n",
      "Epoch 4272 / 10000 loss: 14.280872106552124\n",
      "MSE train 5.566003880088108 MSE test 12.062361509793075\n",
      "MAE train 1.6296237036138685 MAE test 2.43222808422715\n",
      "Epoch 4273 / 10000 loss: 14.280389785766602\n",
      "MSE train 5.565883828267495 MSE test 12.062195604167387\n",
      "MAE train 1.6296058541006715 MAE test 2.4322074575235018\n",
      "Epoch 4274 / 10000 loss: 14.279859066009521\n",
      "MSE train 5.565739755894034 MSE test 12.062013005995183\n",
      "MAE train 1.629583219265344 MAE test 2.432190199139408\n",
      "Epoch 4275 / 10000 loss: 14.279389381408691\n",
      "MSE train 5.565609621694222 MSE test 12.061905376269728\n",
      "MAE train 1.6295615212500127 MAE test 2.432176992022504\n",
      "Epoch 4276 / 10000 loss: 14.27891230583191\n",
      "MSE train 5.565463452129982 MSE test 12.061733301904994\n",
      "MAE train 1.6295380912338668 MAE test 2.432161052161806\n",
      "Epoch 4277 / 10000 loss: 14.278364658355713\n",
      "MSE train 5.565340859701541 MSE test 12.061617408617538\n",
      "MAE train 1.6295184133732814 MAE test 2.432146764119458\n",
      "Epoch 4278 / 10000 loss: 14.277871370315552\n",
      "MSE train 5.565195782773904 MSE test 12.061414587094156\n",
      "MAE train 1.6294959609207649 MAE test 2.4321269403814605\n",
      "Epoch 4279 / 10000 loss: 14.27735710144043\n",
      "MSE train 5.565057921992962 MSE test 12.06130956124365\n",
      "MAE train 1.629472295821938 MAE test 2.4321140625314066\n",
      "Epoch 4280 / 10000 loss: 14.276892900466919\n",
      "MSE train 5.564910769453358 MSE test 12.06117985317327\n",
      "MAE train 1.6294475516117635 MAE test 2.4321034630779703\n",
      "Epoch 4281 / 10000 loss: 14.276311159133911\n",
      "MSE train 5.5647936081535105 MSE test 12.061024615115043\n",
      "MAE train 1.6294301447476838 MAE test 2.4320841693695403\n",
      "Epoch 4282 / 10000 loss: 14.275784015655518\n",
      "MSE train 5.564649823188771 MSE test 12.06082099520502\n",
      "MAE train 1.629408030211833 MAE test 2.432064284408102\n",
      "Epoch 4283 / 10000 loss: 14.275317192077637\n",
      "MSE train 5.564510101668999 MSE test 12.060717535389331\n",
      "MAE train 1.6293838827997442 MAE test 2.432051595615632\n",
      "Epoch 4284 / 10000 loss: 14.27485704421997\n",
      "MSE train 5.564363484076216 MSE test 12.060597572456176\n",
      "MAE train 1.6293590327505043 MAE test 2.4320422098540178\n",
      "Epoch 4285 / 10000 loss: 14.274268865585327\n",
      "MSE train 5.5642435202096365 MSE test 12.060430178087564\n",
      "MAE train 1.6293412169880135 MAE test 2.432021391308574\n",
      "Epoch 4286 / 10000 loss: 14.273736953735352\n",
      "MSE train 5.5640991306274215 MSE test 12.060247766057234\n",
      "MAE train 1.629318492905926 MAE test 2.432004165081932\n",
      "Epoch 4287 / 10000 loss: 14.273268222808838\n",
      "MSE train 5.563969559190126 MSE test 12.060139251700422\n",
      "MAE train 1.629296926125467 MAE test 2.431990835932522\n",
      "Epoch 4288 / 10000 loss: 14.272789239883423\n",
      "MSE train 5.563823385561787 MSE test 12.059965818058995\n",
      "MAE train 1.629273527675528 MAE test 2.4319747395240854\n",
      "Epoch 4289 / 10000 loss: 14.272244215011597\n",
      "MSE train 5.563700042931717 MSE test 12.059850542949432\n",
      "MAE train 1.6292536451614272 MAE test 2.4319605271124254\n",
      "Epoch 4290 / 10000 loss: 14.27175259590149\n",
      "MSE train 5.56355488166648 MSE test 12.059650923823584\n",
      "MAE train 1.6292310943911334 MAE test 2.431941131589343\n",
      "Epoch 4291 / 10000 loss: 14.271233797073364\n",
      "MSE train 5.563418523522239 MSE test 12.059545066409665\n",
      "MAE train 1.629207811460792 MAE test 2.431928127591939\n",
      "Epoch 4292 / 10000 loss: 14.270767450332642\n",
      "MSE train 5.563271216288832 MSE test 12.059407164459502\n",
      "MAE train 1.6291832282308338 MAE test 2.4319165037791173\n",
      "Epoch 4293 / 10000 loss: 14.270192384719849\n",
      "MSE train 5.563155518657003 MSE test 12.059261733672175\n",
      "MAE train 1.6291659444353903 MAE test 2.4318984519133924\n",
      "Epoch 4294 / 10000 loss: 14.269669532775879\n",
      "MSE train 5.563011816564585 MSE test 12.05904543643167\n",
      "MAE train 1.6291441013594143 MAE test 2.4318769795774604\n",
      "Epoch 4295 / 10000 loss: 14.26920223236084\n",
      "MSE train 5.562867299101843 MSE test 12.058942961647219\n",
      "MAE train 1.6291188321117356 MAE test 2.4318644313082602\n",
      "Epoch 4296 / 10000 loss: 14.268752813339233\n",
      "MSE train 5.562724716455642 MSE test 12.05885545729804\n",
      "MAE train 1.6290941145742592 MAE test 2.431859145232653\n",
      "Epoch 4297 / 10000 loss: 14.268145084381104\n",
      "MSE train 5.562592459985044 MSE test 12.058632558438255\n",
      "MAE train 1.629074635303039 MAE test 2.4318313094767197\n",
      "Epoch 4298 / 10000 loss: 14.267606735229492\n",
      "MSE train 5.5624516020533825 MSE test 12.05855843776789\n",
      "MAE train 1.629050041976594 MAE test 2.431827772642845\n",
      "Epoch 4299 / 10000 loss: 14.267123460769653\n",
      "MSE train 5.562318381483459 MSE test 12.058327160329032\n",
      "MAE train 1.6290305650814434 MAE test 2.4317988883525365\n",
      "Epoch 4300 / 10000 loss: 14.266586303710938\n",
      "MSE train 5.562181716622469 MSE test 12.058274427776592\n",
      "MAE train 1.6290065201459345 MAE test 2.431798048442757\n",
      "Epoch 4301 / 10000 loss: 14.266105890274048\n",
      "MSE train 5.562047418265868 MSE test 12.058003223742647\n",
      "MAE train 1.6289877744304977 MAE test 2.4317641632516254\n",
      "Epoch 4302 / 10000 loss: 14.265574216842651\n",
      "MSE train 5.561920724396422 MSE test 12.0580027697725\n",
      "MAE train 1.6289649684931444 MAE test 2.4317698997870565\n",
      "Epoch 4303 / 10000 loss: 14.265114068984985\n",
      "MSE train 5.561788778841339 MSE test 12.057645486590326\n",
      "MAE train 1.6289487501523785 MAE test 2.431725182352115\n",
      "Epoch 4304 / 10000 loss: 14.264587640762329\n",
      "MSE train 5.561630450659135 MSE test 12.057677355271103\n",
      "MAE train 1.6289175504257096 MAE test 2.431735080346804\n",
      "Epoch 4305 / 10000 loss: 14.264201879501343\n",
      "MSE train 5.561503994153431 MSE test 12.057478507423106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6288987949598437 MAE test 2.431710261089139\n",
      "Epoch 4306 / 10000 loss: 14.263527631759644\n",
      "MSE train 5.561357426252153 MSE test 12.057344715919992\n",
      "MAE train 1.628874330177464 MAE test 2.431699191507378\n",
      "Epoch 4307 / 10000 loss: 14.263047933578491\n",
      "MSE train 5.561241613511724 MSE test 12.057200022435792\n",
      "MAE train 1.6288569971922833 MAE test 2.4316812296896964\n",
      "Epoch 4308 / 10000 loss: 14.262526988983154\n",
      "MSE train 5.561098210960565 MSE test 12.056984159005784\n",
      "MAE train 1.6288352239427915 MAE test 2.4316598352971983\n",
      "Epoch 4309 / 10000 loss: 14.262059211730957\n",
      "MSE train 5.560953427794271 MSE test 12.056882089668957\n",
      "MAE train 1.6288098790607273 MAE test 2.4316473434687307\n",
      "Epoch 4310 / 10000 loss: 14.261610984802246\n",
      "MSE train 5.56081104825798 MSE test 12.056795816516637\n",
      "MAE train 1.628785171914489 MAE test 2.431642228215606\n",
      "Epoch 4311 / 10000 loss: 14.26100206375122\n",
      "MSE train 5.5606784788371195 MSE test 12.056571181264552\n",
      "MAE train 1.6287656587245334 MAE test 2.431614192747912\n",
      "Epoch 4312 / 10000 loss: 14.26046347618103\n",
      "MSE train 5.560538193228378 MSE test 12.056500582917005\n",
      "MAE train 1.6287411182268947 MAE test 2.431611111734567\n",
      "Epoch 4313 / 10000 loss: 14.259979724884033\n",
      "MSE train 5.560404386779177 MSE test 12.056262728817547\n",
      "MAE train 1.6287216495817407 MAE test 2.431581415678877\n",
      "Epoch 4314 / 10000 loss: 14.259442806243896\n",
      "MSE train 5.56027032284593 MSE test 12.056220536119472\n",
      "MAE train 1.628698008895745 MAE test 2.4315819058800545\n",
      "Epoch 4315 / 10000 loss: 14.258963346481323\n",
      "MSE train 5.560136636091991 MSE test 12.055927620427134\n",
      "MAE train 1.6286799312105074 MAE test 2.431545285240169\n",
      "Epoch 4316 / 10000 loss: 14.258435726165771\n",
      "MSE train 5.560005366452162 MSE test 12.055943583715829\n",
      "MAE train 1.628655589362926 MAE test 2.431553136369369\n",
      "Epoch 4317 / 10000 loss: 14.257992267608643\n",
      "MSE train 5.559872393955393 MSE test 12.05559665885561\n",
      "MAE train 1.628638905185789 MAE test 2.431509709161126\n",
      "Epoch 4318 / 10000 loss: 14.257436513900757\n",
      "MSE train 5.559717797018402 MSE test 12.0556274742643\n",
      "MAE train 1.6286085439754254 MAE test 2.431519491690957\n",
      "Epoch 4319 / 10000 loss: 14.257039070129395\n",
      "MSE train 5.5595848779569925 MSE test 12.055399390680568\n",
      "MAE train 1.6285889859397948 MAE test 2.431490999515969\n",
      "Epoch 4320 / 10000 loss: 14.256379842758179\n",
      "MSE train 5.559443847237257 MSE test 12.055323934011081\n",
      "MAE train 1.6285643739136821 MAE test 2.431487306014417\n",
      "Epoch 4321 / 10000 loss: 14.255895376205444\n",
      "MSE train 5.559310308178199 MSE test 12.055090913879008\n",
      "MAE train 1.6285448428957356 MAE test 2.4314582198928947\n",
      "Epoch 4322 / 10000 loss: 14.255357503890991\n",
      "MSE train 5.559173929638533 MSE test 12.055039078040203\n",
      "MAE train 1.628520835942979 MAE test 2.431457515445167\n",
      "Epoch 4323 / 10000 loss: 14.254876375198364\n",
      "MSE train 5.559039416341411 MSE test 12.05476512337512\n",
      "MAE train 1.628502092729005 MAE test 2.4314232962402413\n",
      "Epoch 4324 / 10000 loss: 14.254342794418335\n",
      "MSE train 5.558912505815371 MSE test 12.054766846453703\n",
      "MAE train 1.6284791849466795 MAE test 2.4314293542669465\n",
      "Epoch 4325 / 10000 loss: 14.253884315490723\n",
      "MSE train 5.558780235502624 MSE test 12.054408973813825\n",
      "MAE train 1.6284628827302996 MAE test 2.431384572143521\n",
      "Epoch 4326 / 10000 loss: 14.253355979919434\n",
      "MSE train 5.558621718802504 MSE test 12.054440903518808\n",
      "MAE train 1.62843164451609 MAE test 2.4313945337627767\n",
      "Epoch 4327 / 10000 loss: 14.252968072891235\n",
      "MSE train 5.558495268657133 MSE test 12.054242768511074\n",
      "MAE train 1.6284128695743674 MAE test 2.431369814656901\n",
      "Epoch 4328 / 10000 loss: 14.252294301986694\n",
      "MSE train 5.558348519417756 MSE test 12.054107145538165\n",
      "MAE train 1.6283884105257074 MAE test 2.431358554341327\n",
      "Epoch 4329 / 10000 loss: 14.251813650131226\n",
      "MSE train 5.558232596720954 MSE test 12.053964567062792\n",
      "MAE train 1.6283710010764494 MAE test 2.431340880999539\n",
      "Epoch 4330 / 10000 loss: 14.251291990280151\n",
      "MSE train 5.5580889767273 MSE test 12.05374663060263\n",
      "MAE train 1.6283492188829254 MAE test 2.4313192758851243\n",
      "Epoch 4331 / 10000 loss: 14.250823259353638\n",
      "MSE train 5.557943319480726 MSE test 12.053644547348116\n",
      "MAE train 1.628323673711303 MAE test 2.431306798706779\n",
      "Epoch 4332 / 10000 loss: 14.250374794006348\n",
      "MSE train 5.557801679599668 MSE test 12.053563277756389\n",
      "MAE train 1.628299015537358 MAE test 2.431302384011713\n",
      "Epoch 4333 / 10000 loss: 14.24976134300232\n",
      "MSE train 5.557667617369777 MSE test 12.05332851847624\n",
      "MAE train 1.6282793923666394 MAE test 2.43127308104769\n",
      "Epoch 4334 / 10000 loss: 14.24922227859497\n",
      "MSE train 5.557530754127111 MSE test 12.053274652314167\n",
      "MAE train 1.6282553138319917 MAE test 2.4312721510608424\n",
      "Epoch 4335 / 10000 loss: 14.248738288879395\n",
      "MSE train 5.557395815908478 MSE test 12.053002370178172\n",
      "MAE train 1.6282364350111644 MAE test 2.43123814870764\n",
      "Epoch 4336 / 10000 loss: 14.248204946517944\n",
      "MSE train 5.557268755278547 MSE test 12.053001780414052\n",
      "MAE train 1.6282135555541057 MAE test 2.431243953882645\n",
      "Epoch 4337 / 10000 loss: 14.247743368148804\n",
      "MSE train 5.557136208243676 MSE test 12.052644833710772\n",
      "MAE train 1.62819717806686 MAE test 2.4311992910550932\n",
      "Epoch 4338 / 10000 loss: 14.247214555740356\n",
      "MSE train 5.556977640291252 MSE test 12.05267654806532\n",
      "MAE train 1.6281659341194155 MAE test 2.431209259192817\n",
      "Epoch 4339 / 10000 loss: 14.246824979782104\n",
      "MSE train 5.556850277512703 MSE test 12.052476397751057\n",
      "MAE train 1.628146992707361 MAE test 2.4311843129314776\n",
      "Epoch 4340 / 10000 loss: 14.246150255203247\n",
      "MSE train 5.556703265065094 MSE test 12.05234521920014\n",
      "MAE train 1.6281223734976729 MAE test 2.4311736488823716\n",
      "Epoch 4341 / 10000 loss: 14.245666980743408\n",
      "MSE train 5.556586466426368 MSE test 12.052197790502237\n",
      "MAE train 1.6281048779313738 MAE test 2.431155389349689\n",
      "Epoch 4342 / 10000 loss: 14.245141506195068\n",
      "MSE train 5.556442492082299 MSE test 12.051985481859488\n",
      "MAE train 1.628082915328892 MAE test 2.4311345184374487\n",
      "Epoch 4343 / 10000 loss: 14.24467158317566\n",
      "MSE train 5.5562981713643245 MSE test 12.051883042882348\n",
      "MAE train 1.6280576642585285 MAE test 2.4311220205578152\n",
      "Epoch 4344 / 10000 loss: 14.244217157363892\n",
      "MSE train 5.556153687183766 MSE test 12.051788817783217\n",
      "MAE train 1.6280327104105323 MAE test 2.4311159962678373\n",
      "Epoch 4345 / 10000 loss: 14.243608951568604\n",
      "MSE train 5.55602294157883 MSE test 12.051579799124454\n",
      "MAE train 1.6280132209549223 MAE test 2.431089971965032\n",
      "Epoch 4346 / 10000 loss: 14.243066787719727\n",
      "MSE train 5.555877771155897 MSE test 12.051480629079672\n",
      "MAE train 1.6279882832506127 MAE test 2.43108337653992\n",
      "Epoch 4347 / 10000 loss: 14.242580652236938\n",
      "MSE train 5.555751458620044 MSE test 12.051294784453788\n",
      "MAE train 1.6279693581877355 MAE test 2.4310602904748033\n",
      "Epoch 4348 / 10000 loss: 14.242040872573853\n",
      "MSE train 5.555605237099478 MSE test 12.051155747573235\n",
      "MAE train 1.627945167323472 MAE test 2.431048678390976\n",
      "Epoch 4349 / 10000 loss: 14.241559028625488\n",
      "MSE train 5.555488473817187 MSE test 12.05102252907737\n",
      "MAE train 1.6279273860079209 MAE test 2.4310322387911936\n",
      "Epoch 4350 / 10000 loss: 14.2410409450531\n",
      "MSE train 5.555344460362211 MSE test 12.05079912132797\n",
      "MAE train 1.6279056449235962 MAE test 2.4310100066843567\n",
      "Epoch 4351 / 10000 loss: 14.240564107894897\n",
      "MSE train 5.555196185080946 MSE test 12.05069740191527\n",
      "MAE train 1.6278795077442803 MAE test 2.4309976477126725\n",
      "Epoch 4352 / 10000 loss: 14.24011778831482\n",
      "MSE train 5.555057590682474 MSE test 12.05063196724979\n",
      "MAE train 1.6278552349668418 MAE test 2.4309952794647334\n",
      "Epoch 4353 / 10000 loss: 14.23949384689331\n",
      "MSE train 5.554920957105505 MSE test 12.050365320833027\n",
      "MAE train 1.6278357934745957 MAE test 2.4309620242098062\n",
      "Epoch 4354 / 10000 loss: 14.238953590393066\n",
      "MSE train 5.554792883460033 MSE test 12.050353713489791\n",
      "MAE train 1.6278129305187354 MAE test 2.43096648141452\n",
      "Epoch 4355 / 10000 loss: 14.238480806350708\n",
      "MSE train 5.554659309549104 MSE test 12.050005171501418\n",
      "MAE train 1.627796167408948 MAE test 2.430922908848594\n",
      "Epoch 4356 / 10000 loss: 14.237954139709473\n",
      "MSE train 5.5545026133504365 MSE test 12.05003675737899\n",
      "MAE train 1.627765357598594 MAE test 2.4309329166131564\n",
      "Epoch 4357 / 10000 loss: 14.237553119659424\n",
      "MSE train 5.554369730662794 MSE test 12.049815698405174\n",
      "MAE train 1.6277456417985272 MAE test 2.4309053956566453\n",
      "Epoch 4358 / 10000 loss: 14.236884593963623\n",
      "MSE train 5.554225436577203 MSE test 12.049727719866587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6277206419205286 MAE test 2.4309002271670512\n",
      "Epoch 4359 / 10000 loss: 14.236393928527832\n",
      "MSE train 5.554093960576158 MSE test 12.049518719867878\n",
      "MAE train 1.6277010072509692 MAE test 2.430874247707224\n",
      "Epoch 4360 / 10000 loss: 14.235850811004639\n",
      "MSE train 5.5539488820972505 MSE test 12.049424822991732\n",
      "MAE train 1.6276759926423565 MAE test 2.4308683655086933\n",
      "Epoch 4361 / 10000 loss: 14.235361337661743\n",
      "MSE train 5.5538207196978275 MSE test 12.0492332632127\n",
      "MAE train 1.6276567443605492 MAE test 2.430844600880812\n",
      "Epoch 4362 / 10000 loss: 14.234819650650024\n",
      "MSE train 5.55367417304443 MSE test 12.049108059568889\n",
      "MAE train 1.6276321563893197 MAE test 2.430834777218385\n",
      "Epoch 4363 / 10000 loss: 14.234334707260132\n",
      "MSE train 5.553556524125696 MSE test 12.048962134425981\n",
      "MAE train 1.6276144671621067 MAE test 2.430816746167926\n",
      "Epoch 4364 / 10000 loss: 14.233805894851685\n",
      "MSE train 5.553412605408358 MSE test 12.048751000900431\n",
      "MAE train 1.6275925301906569 MAE test 2.4307960908166177\n",
      "Epoch 4365 / 10000 loss: 14.233333349227905\n",
      "MSE train 5.553267612389056 MSE test 12.048649591579911\n",
      "MAE train 1.627567131670517 MAE test 2.430783762609569\n",
      "Epoch 4366 / 10000 loss: 14.23287844657898\n",
      "MSE train 5.553123041137893 MSE test 12.048557285689514\n",
      "MAE train 1.6275421428284922 MAE test 2.4307780352288435\n",
      "Epoch 4367 / 10000 loss: 14.232266664505005\n",
      "MSE train 5.552991780552012 MSE test 12.04834702092321\n",
      "MAE train 1.62752259064012 MAE test 2.4307518749007078\n",
      "Epoch 4368 / 10000 loss: 14.231723546981812\n",
      "MSE train 5.5528469586660325 MSE test 12.048252275388949\n",
      "MAE train 1.6274976501879483 MAE test 2.430745872395538\n",
      "Epoch 4369 / 10000 loss: 14.23123574256897\n",
      "MSE train 5.552719255459569 MSE test 12.048061118620353\n",
      "MAE train 1.6274784934670918 MAE test 2.4307221185021937\n",
      "Epoch 4370 / 10000 loss: 14.230695724487305\n",
      "MSE train 5.552573067764028 MSE test 12.047935158397236\n",
      "MAE train 1.6274540039595158 MAE test 2.4307121739015005\n",
      "Epoch 4371 / 10000 loss: 14.230213165283203\n",
      "MSE train 5.55245588290817 MSE test 12.047790262103133\n",
      "MAE train 1.6274363916968981 MAE test 2.430694248146863\n",
      "Epoch 4372 / 10000 loss: 14.229686498641968\n",
      "MSE train 5.552312391381349 MSE test 12.047578462116926\n",
      "MAE train 1.627414551860891 MAE test 2.430673466334106\n",
      "Epoch 4373 / 10000 loss: 14.229216575622559\n",
      "MSE train 5.5521674469608655 MSE test 12.047477441775118\n",
      "MAE train 1.6273891351157248 MAE test 2.430661151616643\n",
      "Epoch 4374 / 10000 loss: 14.228763103485107\n",
      "MSE train 5.552023577560881 MSE test 12.04738783904891\n",
      "MAE train 1.6273642204528322 MAE test 2.430655725960855\n",
      "Epoch 4375 / 10000 loss: 14.228152751922607\n",
      "MSE train 5.551891794680202 MSE test 12.047173328075898\n",
      "MAE train 1.6273446424687183 MAE test 2.4306289770337517\n",
      "Epoch 4376 / 10000 loss: 14.227611541748047\n",
      "MSE train 5.551748157269231 MSE test 12.047087372544352\n",
      "MAE train 1.627319752481342 MAE test 2.4306240373852614\n",
      "Epoch 4377 / 10000 loss: 14.22712516784668\n",
      "MSE train 5.551617512817887 MSE test 12.046881667803568\n",
      "MAE train 1.6273002433818529 MAE test 2.430598401876179\n",
      "Epoch 4378 / 10000 loss: 14.226584672927856\n",
      "MSE train 5.551472673577044 MSE test 12.046785896900683\n",
      "MAE train 1.6272753344011803 MAE test 2.430592216947077\n",
      "Epoch 4379 / 10000 loss: 14.226098775863647\n",
      "MSE train 5.551346035753608 MSE test 12.046600286586832\n",
      "MAE train 1.627256345304743 MAE test 2.4305691158289044\n",
      "Epoch 4380 / 10000 loss: 14.225560426712036\n",
      "MSE train 5.551199849949422 MSE test 12.046465236808336\n",
      "MAE train 1.6272320989028974 MAE test 2.4305579741152075\n",
      "Epoch 4381 / 10000 loss: 14.225078582763672\n",
      "MSE train 5.5510831672750225 MSE test 12.046330745246335\n",
      "MAE train 1.6272143957887508 MAE test 2.430541311890602\n",
      "Epoch 4382 / 10000 loss: 14.224559307098389\n",
      "MSE train 5.55093919372353 MSE test 12.046109283466107\n",
      "MAE train 1.6271926602364815 MAE test 2.4305192687781516\n",
      "Epoch 4383 / 10000 loss: 14.224084615707397\n",
      "MSE train 5.550790991471839 MSE test 12.046008639049699\n",
      "MAE train 1.627166556740279 MAE test 2.43050695023236\n",
      "Epoch 4384 / 10000 loss: 14.22363829612732\n",
      "MSE train 5.550651655210784 MSE test 12.045941918669133\n",
      "MAE train 1.6271421739943381 MAE test 2.4305043448733694\n",
      "Epoch 4385 / 10000 loss: 14.22301435470581\n",
      "MSE train 5.550514728410882 MSE test 12.045680805174133\n",
      "MAE train 1.6271225993542235 MAE test 2.430471691500259\n",
      "Epoch 4386 / 10000 loss: 14.222474813461304\n",
      "MSE train 5.550385591699955 MSE test 12.045664940444924\n",
      "MAE train 1.6270996357020577 MAE test 2.4304755273265966\n",
      "Epoch 4387 / 10000 loss: 14.221997499465942\n",
      "MSE train 5.550251349991623 MSE test 12.04532378693666\n",
      "MAE train 1.6270826417058153 MAE test 2.4304327744071443\n",
      "Epoch 4388 / 10000 loss: 14.221470594406128\n",
      "MSE train 5.5500961527345964 MSE test 12.04535547231288\n",
      "MAE train 1.627052222012567 MAE test 2.430442700672502\n",
      "Epoch 4389 / 10000 loss: 14.221063137054443\n",
      "MSE train 5.549959746534002 MSE test 12.045119030173726\n",
      "MAE train 1.62703217810243 MAE test 2.430413110985597\n",
      "Epoch 4390 / 10000 loss: 14.2204008102417\n",
      "MSE train 5.549820026875871 MSE test 12.045061377854202\n",
      "MAE train 1.6270076276941032 MAE test 2.430411664003237\n",
      "Epoch 4391 / 10000 loss: 14.219908237457275\n",
      "MSE train 5.54968233721686 MSE test 12.044795799943232\n",
      "MAE train 1.6269880920237298 MAE test 2.430378435705588\n",
      "Epoch 4392 / 10000 loss: 14.219363927841187\n",
      "MSE train 5.549552418145868 MSE test 12.044788762429315\n",
      "MAE train 1.6269648589963208 MAE test 2.4303833862571156\n",
      "Epoch 4393 / 10000 loss: 14.218885898590088\n",
      "MSE train 5.549416560089405 MSE test 12.04443779776134\n",
      "MAE train 1.626947801819444 MAE test 2.4303393874581065\n",
      "Epoch 4394 / 10000 loss: 14.218350410461426\n",
      "MSE train 5.5492557607038435 MSE test 12.044470062592234\n",
      "MAE train 1.6269162202032943 MAE test 2.430349378472837\n",
      "Epoch 4395 / 10000 loss: 14.217942953109741\n",
      "MSE train 5.549121216265104 MSE test 12.044258438421052\n",
      "MAE train 1.6268961143094738 MAE test 2.4303229111669613\n",
      "Epoch 4396 / 10000 loss: 14.217256784439087\n",
      "MSE train 5.548970676878689 MSE test 12.044153143154468\n",
      "MAE train 1.6268703284422035 MAE test 2.4303154553071424\n",
      "Epoch 4397 / 10000 loss: 14.216753005981445\n",
      "MSE train 5.5488406268771895 MSE test 12.043973224019824\n",
      "MAE train 1.6268507457129713 MAE test 2.43029302744743\n",
      "Epoch 4398 / 10000 loss: 14.216194868087769\n",
      "MSE train 5.548688137304182 MSE test 12.043820422009654\n",
      "MAE train 1.6268258054158584 MAE test 2.4302795839668168\n",
      "Epoch 4399 / 10000 loss: 14.215691328048706\n",
      "MSE train 5.548561638797201 MSE test 12.043698023230446\n",
      "MAE train 1.6268058961923442 MAE test 2.4302644401572824\n",
      "Epoch 4400 / 10000 loss: 14.215155839920044\n",
      "MSE train 5.548408091835601 MSE test 12.043478197573076\n",
      "MAE train 1.626782360613515 MAE test 2.43024253880414\n",
      "Epoch 4401 / 10000 loss: 14.214627981185913\n",
      "MSE train 5.5482505265579185 MSE test 12.04337572455704\n",
      "MAE train 1.6267546689307348 MAE test 2.430229978248701\n",
      "Epoch 4402 / 10000 loss: 14.21413779258728\n",
      "MSE train 5.548096463893983 MSE test 12.043298606608474\n",
      "MAE train 1.626727767889692 MAE test 2.4302260420238344\n",
      "Epoch 4403 / 10000 loss: 14.213470697402954\n",
      "MSE train 5.547945474661758 MSE test 12.04305469714025\n",
      "MAE train 1.6267053267271168 MAE test 2.4301955455822406\n",
      "Epoch 4404 / 10000 loss: 14.212870359420776\n",
      "MSE train 5.547793011414806 MSE test 12.04301336058654\n",
      "MAE train 1.626678462027578 MAE test 2.4301961605657607\n",
      "Epoch 4405 / 10000 loss: 14.212316989898682\n",
      "MSE train 5.547636251916818 MSE test 12.042713686800917\n",
      "MAE train 1.6266564927384697 MAE test 2.430158638056945\n",
      "Epoch 4406 / 10000 loss: 14.211700916290283\n",
      "MSE train 5.5474761995678685 MSE test 12.042731345596144\n",
      "MAE train 1.6266268904971615 MAE test 2.4301667300329806\n",
      "Epoch 4407 / 10000 loss: 14.211156606674194\n",
      "MSE train 5.547311982335272 MSE test 12.042391982072985\n",
      "MAE train 1.6266044715867523 MAE test 2.4301241940892258\n",
      "Epoch 4408 / 10000 loss: 14.210466384887695\n",
      "MSE train 5.547127351544715 MSE test 12.042420076493041\n",
      "MAE train 1.6265690094213388 MAE test 2.430133640609513\n",
      "Epoch 4409 / 10000 loss: 14.209917545318604\n",
      "MSE train 5.546955974515183 MSE test 12.042166602321167\n",
      "MAE train 1.6265431157342018 MAE test 2.430101910186417\n",
      "Epoch 4410 / 10000 loss: 14.209115982055664\n",
      "MSE train 5.546789784235369 MSE test 12.042129724105635\n",
      "MAE train 1.6265140282752935 MAE test 2.430103048086942\n",
      "Epoch 4411 / 10000 loss: 14.20847201347351\n",
      "MSE train 5.546625108567178 MSE test 12.041816591348141\n",
      "MAE train 1.6264911554915669 MAE test 2.4300637771494076\n",
      "Epoch 4412 / 10000 loss: 14.207785606384277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.546461126126991 MSE test 12.04183923790073\n",
      "MAE train 1.626460414512558 MAE test 2.4300724464005885\n",
      "Epoch 4413 / 10000 loss: 14.207213163375854\n",
      "MSE train 5.5463076565898985 MSE test 12.041524500294303\n",
      "MAE train 1.6264392030899615 MAE test 2.43003291718391\n",
      "Epoch 4414 / 10000 loss: 14.206505060195923\n",
      "MSE train 5.546156787355051 MSE test 12.041546335751656\n",
      "MAE train 1.626410587142855 MAE test 2.4300414186011396\n",
      "Epoch 4415 / 10000 loss: 14.205989122390747\n",
      "MSE train 5.5460134250442055 MSE test 12.041230668017235\n",
      "MAE train 1.6263911852844977 MAE test 2.4300017388655135\n",
      "Epoch 4416 / 10000 loss: 14.205342292785645\n",
      "MSE train 5.545869543502235 MSE test 12.041253341152975\n",
      "MAE train 1.6263638386180872 MAE test 2.430010327303004\n",
      "Epoch 4417 / 10000 loss: 14.204875230789185\n",
      "MSE train 5.5457310570460345 MSE test 12.040941109471136\n",
      "MAE train 1.626345178620473 MAE test 2.429971052184259\n",
      "Epoch 4418 / 10000 loss: 14.204259872436523\n",
      "MSE train 5.54559201244876 MSE test 12.040963143034665\n",
      "MAE train 1.626318799656338 MAE test 2.429979530270872\n",
      "Epoch 4419 / 10000 loss: 14.203813552856445\n",
      "MSE train 5.54545597577117 MSE test 12.040644775873231\n",
      "MAE train 1.6263007501850917 MAE test 2.4299394750101344\n",
      "Epoch 4420 / 10000 loss: 14.203220129013062\n",
      "MSE train 5.545314905177243 MSE test 12.040670019635497\n",
      "MAE train 1.6262736903301531 MAE test 2.429948372753502\n",
      "Epoch 4421 / 10000 loss: 14.202789068222046\n",
      "MSE train 5.545179003989524 MSE test 12.040367706757646\n",
      "MAE train 1.6262552058679844 MAE test 2.429910343607442\n",
      "Epoch 4422 / 10000 loss: 14.202186346054077\n",
      "MSE train 5.545046281397327 MSE test 12.04038575420328\n",
      "MAE train 1.6262303373938238 MAE test 2.4299182934368937\n",
      "Epoch 4423 / 10000 loss: 14.20174527168274\n",
      "MSE train 5.54491235513451 MSE test 12.040050495088561\n",
      "MAE train 1.626213082009279 MAE test 2.4298761044076853\n",
      "Epoch 4424 / 10000 loss: 14.201179027557373\n",
      "MSE train 5.544763207175479 MSE test 12.04008124836387\n",
      "MAE train 1.6261838721490347 MAE test 2.429885723659308\n",
      "Epoch 4425 / 10000 loss: 14.200769901275635\n",
      "MSE train 5.544627670226622 MSE test 12.039826292782369\n",
      "MAE train 1.6261642563155565 MAE test 2.4298536610147927\n",
      "Epoch 4426 / 10000 loss: 14.200133085250854\n",
      "MSE train 5.5444986447263265 MSE test 12.039800159520164\n",
      "MAE train 1.6261413427026021 MAE test 2.4298560120752803\n",
      "Epoch 4427 / 10000 loss: 14.199658870697021\n",
      "MSE train 5.544366057846409 MSE test 12.039478117042858\n",
      "MAE train 1.6261241217944418 MAE test 2.4298155275062125\n",
      "Epoch 4428 / 10000 loss: 14.199138879776001\n",
      "MSE train 5.544221633511403 MSE test 12.039508427590306\n",
      "MAE train 1.6260961036708748 MAE test 2.4298250681288884\n",
      "Epoch 4429 / 10000 loss: 14.198723316192627\n",
      "MSE train 5.5440862226292715 MSE test 12.039227633213692\n",
      "MAE train 1.6260771581307754 MAE test 2.429789777192765\n",
      "Epoch 4430 / 10000 loss: 14.198105812072754\n",
      "MSE train 5.543960015986446 MSE test 12.039232159849064\n",
      "MAE train 1.626054236977786 MAE test 2.429796003943206\n",
      "Epoch 4431 / 10000 loss: 14.19765019416809\n",
      "MSE train 5.543827726067617 MSE test 12.03887904697307\n",
      "MAE train 1.6260377250806906 MAE test 2.4297516259242373\n",
      "Epoch 4432 / 10000 loss: 14.197121143341064\n",
      "MSE train 5.543671336865048 MSE test 12.038913035796446\n",
      "MAE train 1.6260068013699274 MAE test 2.4297616608141936\n",
      "Epoch 4433 / 10000 loss: 14.196732521057129\n",
      "MSE train 5.543543866181437 MSE test 12.038710110004025\n",
      "MAE train 1.6259877917234633 MAE test 2.4297361669163\n",
      "Epoch 4434 / 10000 loss: 14.19606637954712\n",
      "MSE train 5.5433986312845684 MSE test 12.038593424455135\n",
      "MAE train 1.625963115883157 MAE test 2.429727104356907\n",
      "Epoch 4435 / 10000 loss: 14.195586919784546\n",
      "MSE train 5.543280591511992 MSE test 12.038435327036368\n",
      "MAE train 1.6259454675041136 MAE test 2.4297073036283288\n",
      "Epoch 4436 / 10000 loss: 14.19506025314331\n",
      "MSE train 5.5431376895114655 MSE test 12.038247726578556\n",
      "MAE train 1.625923113263459 MAE test 2.4296893120164507\n",
      "Epoch 4437 / 10000 loss: 14.194595336914062\n",
      "MSE train 5.543004126776909 MSE test 12.0381451870572\n",
      "MAE train 1.6259003406802621 MAE test 2.429676590989966\n",
      "Epoch 4438 / 10000 loss: 14.194128274917603\n",
      "MSE train 5.542858061864144 MSE test 12.037999170200608\n",
      "MAE train 1.6258761675590914 MAE test 2.4296638254231633\n",
      "Epoch 4439 / 10000 loss: 14.193564176559448\n",
      "MSE train 5.542743031280568 MSE test 12.037869851741902\n",
      "MAE train 1.6258585822494165 MAE test 2.429647655879328\n",
      "Epoch 4440 / 10000 loss: 14.193055629730225\n",
      "MSE train 5.542600001179234 MSE test 12.037650677360787\n",
      "MAE train 1.625836848521089 MAE test 2.429625682596177\n",
      "Epoch 4441 / 10000 loss: 14.192580938339233\n",
      "MSE train 5.542454514223659 MSE test 12.037551306650409\n",
      "MAE train 1.6258111979840222 MAE test 2.4296133988554116\n",
      "Epoch 4442 / 10000 loss: 14.192140102386475\n",
      "MSE train 5.542316404171521 MSE test 12.037482260214706\n",
      "MAE train 1.6257869825101177 MAE test 2.429610318358947\n",
      "Epoch 4443 / 10000 loss: 14.191527843475342\n",
      "MSE train 5.542182096769498 MSE test 12.037231943900574\n",
      "MAE train 1.6257675849530668 MAE test 2.42957888707546\n",
      "Epoch 4444 / 10000 loss: 14.19099473953247\n",
      "MSE train 5.542053268514821 MSE test 12.037207962038842\n",
      "MAE train 1.6257447066915605 MAE test 2.4295815286555493\n",
      "Epoch 4445 / 10000 loss: 14.19052243232727\n",
      "MSE train 5.5419213208063995 MSE test 12.03688644735632\n",
      "MAE train 1.6257276415430253 MAE test 2.4295411177813926\n",
      "Epoch 4446 / 10000 loss: 14.190004110336304\n",
      "MSE train 5.541776696739993 MSE test 12.036917762449127\n",
      "MAE train 1.6256995705419384 MAE test 2.4295507959499103\n",
      "Epoch 4447 / 10000 loss: 14.18959093093872\n",
      "MSE train 5.54164149169347 MSE test 12.036639700841258\n",
      "MAE train 1.6256806220300402 MAE test 2.4295158585736165\n",
      "Epoch 4448 / 10000 loss: 14.18897294998169\n",
      "MSE train 5.541515758246487 MSE test 12.036642820472421\n",
      "MAE train 1.625657868268011 MAE test 2.42952191437392\n",
      "Epoch 4449 / 10000 loss: 14.18851637840271\n",
      "MSE train 5.5413836167669634 MSE test 12.036290283027874\n",
      "MAE train 1.6256413942420849 MAE test 2.4294776113367003\n",
      "Epoch 4450 / 10000 loss: 14.187990427017212\n",
      "MSE train 5.541227417982797 MSE test 12.036324527595704\n",
      "MAE train 1.6256105287828042 MAE test 2.4294876791059443\n",
      "Epoch 4451 / 10000 loss: 14.187603235244751\n",
      "MSE train 5.541100062767136 MSE test 12.036122160166519\n",
      "MAE train 1.625591550172959 MAE test 2.42946227097225\n",
      "Epoch 4452 / 10000 loss: 14.186937093734741\n",
      "MSE train 5.540954936943591 MSE test 12.036005571953993\n",
      "MAE train 1.625566914232296 MAE test 2.429453224571249\n",
      "Epoch 4453 / 10000 loss: 14.186458110809326\n",
      "MSE train 5.54083696098935 MSE test 12.03584793386574\n",
      "MAE train 1.6255492914585548 MAE test 2.4294334867076834\n",
      "Epoch 4454 / 10000 loss: 14.185932159423828\n",
      "MSE train 5.540694157680931 MSE test 12.035660294481273\n",
      "MAE train 1.6255269910498105 MAE test 2.4294154767745466\n",
      "Epoch 4455 / 10000 loss: 14.18546724319458\n",
      "MSE train 5.540560437787555 MSE test 12.03555811989589\n",
      "MAE train 1.6255041867305664 MAE test 2.4294028060897577\n",
      "Epoch 4456 / 10000 loss: 14.185000658035278\n",
      "MSE train 5.54041438224073 MSE test 12.035413373676489\n",
      "MAE train 1.6254800094558925 MAE test 2.429390189400652\n",
      "Epoch 4457 / 10000 loss: 14.184436321258545\n",
      "MSE train 5.540299422753391 MSE test 12.035283403697559\n",
      "MAE train 1.625462479088376 MAE test 2.429373944271911\n",
      "Epoch 4458 / 10000 loss: 14.183927059173584\n",
      "MSE train 5.54015643615371 MSE test 12.0350644867718\n",
      "MAE train 1.625440774979006 MAE test 2.429352010779201\n",
      "Epoch 4459 / 10000 loss: 14.183453559875488\n",
      "MSE train 5.540010988084669 MSE test 12.03496522531288\n",
      "MAE train 1.6254151430653268 MAE test 2.429339725977363\n",
      "Epoch 4460 / 10000 loss: 14.183012962341309\n",
      "MSE train 5.539872806392689 MSE test 12.034896410291351\n",
      "MAE train 1.6253909370938204 MAE test 2.4293366741602718\n",
      "Epoch 4461 / 10000 loss: 14.182400226593018\n",
      "MSE train 5.539738420978291 MSE test 12.034646526566908\n",
      "MAE train 1.6253715347353124 MAE test 2.429305295687183\n",
      "Epoch 4462 / 10000 loss: 14.181867599487305\n",
      "MSE train 5.539609552399572 MSE test 12.03462247105515\n",
      "MAE train 1.6253486706180105 MAE test 2.4293079108919393\n",
      "Epoch 4463 / 10000 loss: 14.181395292282104\n",
      "MSE train 5.5394774997457725 MSE test 12.03430174867051\n",
      "MAE train 1.6253315835704383 MAE test 2.4292676146767995\n",
      "Epoch 4464 / 10000 loss: 14.180876970291138\n",
      "MSE train 5.53933304486265 MSE test 12.034333032495926\n",
      "MAE train 1.6253035828614566 MAE test 2.4292772656905544\n",
      "Epoch 4465 / 10000 loss: 14.180463075637817\n",
      "MSE train 5.539197814112643 MSE test 12.034053871345803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6252846702615327 MAE test 2.429242191176181\n",
      "Epoch 4466 / 10000 loss: 14.179846286773682\n",
      "MSE train 5.539071870192109 MSE test 12.034058598498083\n",
      "MAE train 1.625261858573704 MAE test 2.4292484578771445\n",
      "Epoch 4467 / 10000 loss: 14.179390907287598\n",
      "MSE train 5.5389395783099555 MSE test 12.033706085577794\n",
      "MAE train 1.625245364582877 MAE test 2.42920413606903\n",
      "Epoch 4468 / 10000 loss: 14.178863048553467\n",
      "MSE train 5.538783307736777 MSE test 12.03374054044913\n",
      "MAE train 1.6252145014298014 MAE test 2.4292142431112183\n",
      "Epoch 4469 / 10000 loss: 14.178475141525269\n",
      "MSE train 5.538655788550996 MSE test 12.03353819293134\n",
      "MAE train 1.6251955078783111 MAE test 2.4291888225407443\n",
      "Epoch 4470 / 10000 loss: 14.177808046340942\n",
      "MSE train 5.538510575513358 MSE test 12.033422160658457\n",
      "MAE train 1.6251708572224153 MAE test 2.429179835934778\n",
      "Epoch 4471 / 10000 loss: 14.177330255508423\n",
      "MSE train 5.538392326319526 MSE test 12.03326425395915\n",
      "MAE train 1.6251532082062945 MAE test 2.429160055750508\n",
      "Epoch 4472 / 10000 loss: 14.176803350448608\n",
      "MSE train 5.538249338668943 MSE test 12.033077703084038\n",
      "MAE train 1.6251308457607527 MAE test 2.429142189707465\n",
      "Epoch 4473 / 10000 loss: 14.176337480545044\n",
      "MSE train 5.538115970914552 MSE test 12.032975496597311\n",
      "MAE train 1.6251081579730509 MAE test 2.4291295003893487\n",
      "Epoch 4474 / 10000 loss: 14.175870656967163\n",
      "MSE train 5.537969823358614 MSE test 12.032828616214907\n",
      "MAE train 1.6250840233115031 MAE test 2.429116609805188\n",
      "Epoch 4475 / 10000 loss: 14.175306558609009\n",
      "MSE train 5.537854434391613 MSE test 12.032700790346773\n",
      "MAE train 1.6250663696171932 MAE test 2.4291006273723\n",
      "Epoch 4476 / 10000 loss: 14.174798488616943\n",
      "MSE train 5.537711188258894 MSE test 12.032482227136065\n",
      "MAE train 1.6250445956993076 MAE test 2.429078710955364\n",
      "Epoch 4477 / 10000 loss: 14.174322366714478\n",
      "MSE train 5.537565684959338 MSE test 12.032383139240402\n",
      "MAE train 1.6250189737871321 MAE test 2.42906644847082\n",
      "Epoch 4478 / 10000 loss: 14.173880577087402\n",
      "MSE train 5.537427071258573 MSE test 12.032313636281534\n",
      "MAE train 1.6249947013130561 MAE test 2.429063282880801\n",
      "Epoch 4479 / 10000 loss: 14.173267841339111\n",
      "MSE train 5.537292614855507 MSE test 12.032065611628965\n",
      "MAE train 1.6249752584502275 MAE test 2.429032134856375\n",
      "Epoch 4480 / 10000 loss: 14.172734498977661\n",
      "MSE train 5.53716310025658 MSE test 12.032039331548614\n",
      "MAE train 1.6249522871328175 MAE test 2.4290344488922506\n",
      "Epoch 4481 / 10000 loss: 14.172260046005249\n",
      "MSE train 5.537030666232028 MSE test 12.031722757669888\n",
      "MAE train 1.6249350427294118 MAE test 2.4289946673487894\n",
      "Epoch 4482 / 10000 loss: 14.171740770339966\n",
      "MSE train 5.536887979943971 MSE test 12.031753126738232\n",
      "MAE train 1.6249075051606514 MAE test 2.429004189483211\n",
      "Epoch 4483 / 10000 loss: 14.171323299407959\n",
      "MSE train 5.536752762516807 MSE test 12.031464421377692\n",
      "MAE train 1.6248888640908874 MAE test 2.4289679051158646\n",
      "Epoch 4484 / 10000 loss: 14.170713186264038\n",
      "MSE train 5.536624537832076 MSE test 12.031477062011437\n",
      "MAE train 1.624865304076254 MAE test 2.4289751525407275\n",
      "Epoch 4485 / 10000 loss: 14.170265436172485\n",
      "MSE train 5.536491644057161 MSE test 12.031129287656773\n",
      "MAE train 1.6248485888927617 MAE test 2.4289314061098985\n",
      "Epoch 4486 / 10000 loss: 14.169722557067871\n",
      "MSE train 5.536336738398331 MSE test 12.031163216195953\n",
      "MAE train 1.624818033202564 MAE test 2.428941410515167\n",
      "Epoch 4487 / 10000 loss: 14.169329643249512\n",
      "MSE train 5.536206141153458 MSE test 12.03094850830123\n",
      "MAE train 1.62479864380944 MAE test 2.4289144213719593\n",
      "Epoch 4488 / 10000 loss: 14.168668270111084\n",
      "MSE train 5.536062843171457 MSE test 12.030857728019772\n",
      "MAE train 1.6247738633886688 MAE test 2.428908596997659\n",
      "Epoch 4489 / 10000 loss: 14.168186902999878\n",
      "MSE train 5.535935102275482 MSE test 12.030662264023636\n",
      "MAE train 1.6247547413864476 MAE test 2.4288840613131297\n",
      "Epoch 4490 / 10000 loss: 14.167651653289795\n",
      "MSE train 5.535790400946699 MSE test 12.0305511668547\n",
      "MAE train 1.6247301280230568 MAE test 2.428875699786584\n",
      "Epoch 4491 / 10000 loss: 14.167171716690063\n",
      "MSE train 5.535671396743011 MSE test 12.030393467018682\n",
      "MAE train 1.6247123355248807 MAE test 2.42885592663009\n",
      "Epoch 4492 / 10000 loss: 14.166644811630249\n",
      "MSE train 5.5355283745681785 MSE test 12.030209831016473\n",
      "MAE train 1.6246899142184883 MAE test 2.4288384170404487\n",
      "Epoch 4493 / 10000 loss: 14.166177749633789\n",
      "MSE train 5.535395588701722 MSE test 12.030107373129185\n",
      "MAE train 1.6246674098925227 MAE test 2.4288256672229767\n",
      "Epoch 4494 / 10000 loss: 14.165708065032959\n",
      "MSE train 5.535249317844471 MSE test 12.029955070287109\n",
      "MAE train 1.6246433963854545 MAE test 2.4288120827929793\n",
      "Epoch 4495 / 10000 loss: 14.165147542953491\n",
      "MSE train 5.535132408385884 MSE test 12.02983210264299\n",
      "MAE train 1.6246252970818245 MAE test 2.4287967115713283\n",
      "Epoch 4496 / 10000 loss: 14.164642810821533\n",
      "MSE train 5.534988656849179 MSE test 12.029615508004653\n",
      "MAE train 1.6246033805602682 MAE test 2.428775011915706\n",
      "Epoch 4497 / 10000 loss: 14.164157390594482\n",
      "MSE train 5.53484356663763 MSE test 12.029515907979786\n",
      "MAE train 1.6245778700062268 MAE test 2.428762666218052\n",
      "Epoch 4498 / 10000 loss: 14.1637122631073\n",
      "MSE train 5.534703236542974 MSE test 12.029440391287082\n",
      "MAE train 1.6245533442115858 MAE test 2.4287587211428048\n",
      "Epoch 4499 / 10000 loss: 14.163101196289062\n",
      "MSE train 5.534569198145593 MSE test 12.029203934853534\n",
      "MAE train 1.624533764363952 MAE test 2.4287290176082967\n",
      "Epoch 4500 / 10000 loss: 14.162564992904663\n",
      "MSE train 5.534435034256596 MSE test 12.029160721135748\n",
      "MAE train 1.6245100640770203 MAE test 2.42872916782527\n",
      "Epoch 4501 / 10000 loss: 14.162084817886353\n",
      "MSE train 5.534300944334904 MSE test 12.028876622734604\n",
      "MAE train 1.624491647902091 MAE test 2.428693472609513\n",
      "Epoch 4502 / 10000 loss: 14.161557674407959\n",
      "MSE train 5.5341720971176125 MSE test 12.028891144222442\n",
      "MAE train 1.6244679417510006 MAE test 2.4287009411112828\n",
      "Epoch 4503 / 10000 loss: 14.161109924316406\n",
      "MSE train 5.534039357590192 MSE test 12.02854205357122\n",
      "MAE train 1.624451326160204 MAE test 2.428657030003671\n",
      "Epoch 4504 / 10000 loss: 14.160566329956055\n",
      "MSE train 5.533883277755095 MSE test 12.028575930390172\n",
      "MAE train 1.6244205262631464 MAE test 2.4286670122839444\n",
      "Epoch 4505 / 10000 loss: 14.160173654556274\n",
      "MSE train 5.533753299083762 MSE test 12.028365859638072\n",
      "MAE train 1.6244011998294716 MAE test 2.428640594530848\n",
      "Epoch 4506 / 10000 loss: 14.15950870513916\n",
      "MSE train 5.533608457565409 MSE test 12.028264641614212\n",
      "MAE train 1.6243763189563956 MAE test 2.428633436274824\n",
      "Epoch 4507 / 10000 loss: 14.159025192260742\n",
      "MSE train 5.533483993086892 MSE test 12.028084718877661\n",
      "MAE train 1.6243577192205716 MAE test 2.4286108571036444\n",
      "Epoch 4508 / 10000 loss: 14.158490657806396\n",
      "MSE train 5.533338724497433 MSE test 12.027939997452945\n",
      "MAE train 1.6243338056362522 MAE test 2.4285982236584096\n",
      "Epoch 4509 / 10000 loss: 14.15801477432251\n",
      "MSE train 5.533221843467312 MSE test 12.02781577993418\n",
      "MAE train 1.6243158203533283 MAE test 2.4285826910343897\n",
      "Epoch 4510 / 10000 loss: 14.157507181167603\n",
      "MSE train 5.533078307769105 MSE test 12.02759563149744\n",
      "MAE train 1.6242940385878915 MAE test 2.428560547139334\n",
      "Epoch 4511 / 10000 loss: 14.157025337219238\n",
      "MSE train 5.5329314320941085 MSE test 12.027496165789351\n",
      "MAE train 1.6242681860871961 MAE test 2.4285482105389673\n",
      "Epoch 4512 / 10000 loss: 14.15658164024353\n",
      "MSE train 5.532792782208295 MSE test 12.02742894065223\n",
      "MAE train 1.6242438952616955 MAE test 2.428545317758428\n",
      "Epoch 4513 / 10000 loss: 14.155964136123657\n",
      "MSE train 5.53265704543369 MSE test 12.027172737424278\n",
      "MAE train 1.624224419344015 MAE test 2.428513119169251\n",
      "Epoch 4514 / 10000 loss: 14.155429124832153\n",
      "MSE train 5.532528387424347 MSE test 12.027153729727262\n",
      "MAE train 1.6242015674863584 MAE test 2.4285163341046068\n",
      "Epoch 4515 / 10000 loss: 14.154954671859741\n",
      "MSE train 5.5323952255531905 MSE test 12.026820820531018\n",
      "MAE train 1.624184578005738 MAE test 2.4284744708142725\n",
      "Epoch 4516 / 10000 loss: 14.154432773590088\n",
      "MSE train 5.532244433909185 MSE test 12.02685235659803\n",
      "MAE train 1.6241550792701454 MAE test 2.42848413373709\n",
      "Epoch 4517 / 10000 loss: 14.154024600982666\n",
      "MSE train 5.532108024477545 MSE test 12.026599421081965\n",
      "MAE train 1.6241353507613272 MAE test 2.4284523228036305\n",
      "Epoch 4518 / 10000 loss: 14.153381109237671\n",
      "MSE train 5.531976947404618 MSE test 12.026569396936349\n",
      "MAE train 1.6241121614696374 MAE test 2.428454145396035\n",
      "Epoch 4519 / 10000 loss: 14.152901411056519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.531842602890662 MSE test 12.026251450143542\n",
      "MAE train 1.6240945829402207 MAE test 2.4284141833242185\n",
      "Epoch 4520 / 10000 loss: 14.15237545967102\n",
      "MSE train 5.531699021653026 MSE test 12.026278169829519\n",
      "MAE train 1.624067006476131 MAE test 2.4284232193497233\n",
      "Epoch 4521 / 10000 loss: 14.151950359344482\n",
      "MSE train 5.531561963765244 MSE test 12.025982800973578\n",
      "MAE train 1.6240482037307644 MAE test 2.4283860758621962\n",
      "Epoch 4522 / 10000 loss: 14.151338577270508\n",
      "MSE train 5.531430387647962 MSE test 12.025994460007157\n",
      "MAE train 1.624023967976453 MAE test 2.4283932036461917\n",
      "Epoch 4523 / 10000 loss: 14.150885581970215\n",
      "MSE train 5.531294842757908 MSE test 12.025647280260275\n",
      "MAE train 1.624006773542903 MAE test 2.4283495372344155\n",
      "Epoch 4524 / 10000 loss: 14.150327920913696\n",
      "MSE train 5.53113866589984 MSE test 12.025676691076699\n",
      "MAE train 1.6239761617558897 MAE test 2.428358976133366\n",
      "Epoch 4525 / 10000 loss: 14.149921894073486\n",
      "MSE train 5.531002763925054 MSE test 12.025446886886101\n",
      "MAE train 1.6239561319364044 MAE test 2.428330102281306\n",
      "Epoch 4526 / 10000 loss: 14.149256467819214\n",
      "MSE train 5.530858903388651 MSE test 12.025371358719491\n",
      "MAE train 1.6239310512700804 MAE test 2.428326226799369\n",
      "Epoch 4527 / 10000 loss: 14.148760318756104\n",
      "MSE train 5.530720946026428 MSE test 12.025133816654156\n",
      "MAE train 1.6239108962335973 MAE test 2.428296437520998\n",
      "Epoch 4528 / 10000 loss: 14.148210525512695\n",
      "MSE train 5.530580354690269 MSE test 12.025083243119221\n",
      "MAE train 1.6238862588100376 MAE test 2.4282957330297292\n",
      "Epoch 4529 / 10000 loss: 14.147712230682373\n",
      "MSE train 5.530438945451631 MSE test 12.024797656748804\n",
      "MAE train 1.6238666857897521 MAE test 2.42825992886767\n",
      "Epoch 4530 / 10000 loss: 14.147159814834595\n",
      "MSE train 5.530301141158932 MSE test 12.024800755423666\n",
      "MAE train 1.6238418976591869 MAE test 2.4282660736374306\n",
      "Epoch 4531 / 10000 loss: 14.146676063537598\n",
      "MSE train 5.5301541524983815 MSE test 12.024438920073226\n",
      "MAE train 1.623823338763772 MAE test 2.4282207063016674\n",
      "Epoch 4532 / 10000 loss: 14.146095275878906\n",
      "MSE train 5.529975061333294 MSE test 12.02446137531933\n",
      "MAE train 1.62378913476856 MAE test 2.4282294701570115\n",
      "Epoch 4533 / 10000 loss: 14.145641088485718\n",
      "MSE train 5.529812624441477 MSE test 12.024245344492954\n",
      "MAE train 1.6237650800556753 MAE test 2.4282026047991168\n",
      "Epoch 4534 / 10000 loss: 14.144873142242432\n",
      "MSE train 5.529616814187998 MSE test 12.024108082694067\n",
      "MAE train 1.6237332841495575 MAE test 2.428191274312571\n",
      "Epoch 4535 / 10000 loss: 14.144232988357544\n",
      "MSE train 5.529454663236621 MSE test 12.023935347162055\n",
      "MAE train 1.623709159866961 MAE test 2.428169902045248\n",
      "Epoch 4536 / 10000 loss: 14.143472671508789\n",
      "MSE train 5.52929584988614 MSE test 12.023736809463085\n",
      "MAE train 1.6236845043732941 MAE test 2.428150159735223\n",
      "Epoch 4537 / 10000 loss: 14.142793655395508\n",
      "MSE train 5.529151312557496 MSE test 12.023637450404912\n",
      "MAE train 1.6236592071794673 MAE test 2.42813723494432\n",
      "Epoch 4538 / 10000 loss: 14.142257690429688\n",
      "MSE train 5.5289973003287916 MSE test 12.023498818957075\n",
      "MAE train 1.62363316259994 MAE test 2.428125096245187\n",
      "Epoch 4539 / 10000 loss: 14.141650915145874\n",
      "MSE train 5.528872860345 MSE test 12.023348701260899\n",
      "MAE train 1.6236142625185492 MAE test 2.4281062131183506\n",
      "Epoch 4540 / 10000 loss: 14.14110279083252\n",
      "MSE train 5.528718246071609 MSE test 12.023123344572213\n",
      "MAE train 1.623590389122153 MAE test 2.4280834155147417\n",
      "Epoch 4541 / 10000 loss: 14.140602111816406\n",
      "MSE train 5.528559526838437 MSE test 12.023008026273883\n",
      "MAE train 1.6235626640185978 MAE test 2.428069145473018\n",
      "Epoch 4542 / 10000 loss: 14.140110969543457\n",
      "MSE train 5.528398165835967 MSE test 12.022903775628134\n",
      "MAE train 1.6235346992025017 MAE test 2.4280617014731907\n",
      "Epoch 4543 / 10000 loss: 14.139449119567871\n",
      "MSE train 5.52823990777385 MSE test 12.022659689205762\n",
      "MAE train 1.6235108026035723 MAE test 2.4280311850089213\n",
      "Epoch 4544 / 10000 loss: 14.138838768005371\n",
      "MSE train 5.528062503833966 MSE test 12.022557063834372\n",
      "MAE train 1.6234799725196314 MAE test 2.42802408313029\n",
      "Epoch 4545 / 10000 loss: 14.138254404067993\n",
      "MSE train 5.527875376599969 MSE test 12.022289589946617\n",
      "MAE train 1.6234512841222755 MAE test 2.427990782007693\n",
      "Epoch 4546 / 10000 loss: 14.137572288513184\n",
      "MSE train 5.527656317162321 MSE test 12.022185374260866\n",
      "MAE train 1.6234130988679178 MAE test 2.4279837099095776\n",
      "Epoch 4547 / 10000 loss: 14.136871099472046\n",
      "MSE train 5.5273946555691955 MSE test 12.021849105097816\n",
      "MAE train 1.6233718286878134 MAE test 2.427941995397685\n",
      "Epoch 4548 / 10000 loss: 14.135996103286743\n",
      "MSE train 5.527088355364477 MSE test 12.021756744580491\n",
      "MAE train 1.6233173580951559 MAE test 2.427936746494229\n",
      "Epoch 4549 / 10000 loss: 14.134990215301514\n",
      "MSE train 5.52677238822656 MSE test 12.021307441898681\n",
      "MAE train 1.6232674544224281 MAE test 2.4278810446410146\n",
      "Epoch 4550 / 10000 loss: 14.13368558883667\n",
      "MSE train 5.526508976934481 MSE test 12.021277440377622\n",
      "MAE train 1.6232171469971484 MAE test 2.4278835795019917\n",
      "Epoch 4551 / 10000 loss: 14.132488250732422\n",
      "MSE train 5.526341069468694 MSE test 12.021060289005263\n",
      "MAE train 1.6231911478471601 MAE test 2.4278564642468443\n",
      "Epoch 4552 / 10000 loss: 14.131349563598633\n",
      "MSE train 5.526181124849179 MSE test 12.02095531887178\n",
      "MAE train 1.6231637412534603 MAE test 2.4278487938224673\n",
      "Epoch 4553 / 10000 loss: 14.13068151473999\n",
      "MSE train 5.526057814645575 MSE test 12.020822121777169\n",
      "MAE train 1.6231450341150804 MAE test 2.427831973026557\n",
      "Epoch 4554 / 10000 loss: 14.130072116851807\n",
      "MSE train 5.525913810077414 MSE test 12.020660403057695\n",
      "MAE train 1.6231222071766593 MAE test 2.427816960843778\n",
      "Epoch 4555 / 10000 loss: 14.129560947418213\n",
      "MSE train 5.525780656564828 MSE test 12.020585246854305\n",
      "MAE train 1.623099298932916 MAE test 2.42780744594562\n",
      "Epoch 4556 / 10000 loss: 14.12906527519226\n",
      "MSE train 5.525636504607034 MSE test 12.020466090876813\n",
      "MAE train 1.6230751151550198 MAE test 2.427797750858281\n",
      "Epoch 4557 / 10000 loss: 14.12848162651062\n",
      "MSE train 5.525524021351839 MSE test 12.02035675705091\n",
      "MAE train 1.6230578862393015 MAE test 2.4277838814060675\n",
      "Epoch 4558 / 10000 loss: 14.127958297729492\n",
      "MSE train 5.525383748187004 MSE test 12.020156615309936\n",
      "MAE train 1.6230363181261387 MAE test 2.4277639960437236\n",
      "Epoch 4559 / 10000 loss: 14.127477884292603\n",
      "MSE train 5.525241155017281 MSE test 12.020074067023945\n",
      "MAE train 1.6230109934410641 MAE test 2.427753632131686\n",
      "Epoch 4560 / 10000 loss: 14.127031326293945\n",
      "MSE train 5.525105382079624 MSE test 12.020017335936029\n",
      "MAE train 1.6229869680681335 MAE test 2.427751857020581\n",
      "Epoch 4561 / 10000 loss: 14.126416206359863\n",
      "MSE train 5.5249738180480845 MSE test 12.019782176803819\n",
      "MAE train 1.6229677903253434 MAE test 2.427722129890697\n",
      "Epoch 4562 / 10000 loss: 14.125882863998413\n",
      "MSE train 5.524846666817725 MSE test 12.019764260846086\n",
      "MAE train 1.6229450409708044 MAE test 2.427725340228674\n",
      "Epoch 4563 / 10000 loss: 14.125410079956055\n",
      "MSE train 5.524716756888924 MSE test 12.019459282645016\n",
      "MAE train 1.6229279479328365 MAE test 2.4276868094773576\n",
      "Epoch 4564 / 10000 loss: 14.124890327453613\n",
      "MSE train 5.524578121308836 MSE test 12.0194958025738\n",
      "MAE train 1.6229010813670661 MAE test 2.427696964138618\n",
      "Epoch 4565 / 10000 loss: 14.12447214126587\n",
      "MSE train 5.52444563088312 MSE test 12.019207103494061\n",
      "MAE train 1.6228829146781516 MAE test 2.4276604992614157\n",
      "Epoch 4566 / 10000 loss: 14.12387204170227\n",
      "MSE train 5.524317547740658 MSE test 12.019229559057777\n",
      "MAE train 1.6228589527135928 MAE test 2.4276688668656106\n",
      "Epoch 4567 / 10000 loss: 14.123432874679565\n",
      "MSE train 5.524186575278762 MSE test 12.018895002995874\n",
      "MAE train 1.6228422185704388 MAE test 2.427626605236612\n",
      "Epoch 4568 / 10000 loss: 14.122881650924683\n",
      "MSE train 5.524037217193924 MSE test 12.018931910452201\n",
      "MAE train 1.622812673162949 MAE test 2.4276368670836628\n",
      "Epoch 4569 / 10000 loss: 14.122484922409058\n",
      "MSE train 5.523905354329553 MSE test 12.018699433213769\n",
      "MAE train 1.6227932912353977 MAE test 2.4276075078040282\n",
      "Epoch 4570 / 10000 loss: 14.121840000152588\n",
      "MSE train 5.523772022960354 MSE test 12.01865118056866\n",
      "MAE train 1.6227696443639923 MAE test 2.4276069166723633\n",
      "Epoch 4571 / 10000 loss: 14.121363878250122\n",
      "MSE train 5.523639765512988 MSE test 12.01838412080046\n",
      "MAE train 1.6227510393866327 MAE test 2.427573212834349\n",
      "Epoch 4572 / 10000 loss: 14.12083911895752\n",
      "MSE train 5.523515770261672 MSE test 12.018389226403546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6227285356877765 MAE test 2.427579424128744\n",
      "Epoch 4573 / 10000 loss: 14.120385646820068\n",
      "MSE train 5.5233858038132055 MSE test 12.018039856869008\n",
      "MAE train 1.6227123618626076 MAE test 2.427535325853403\n",
      "Epoch 4574 / 10000 loss: 14.119865417480469\n",
      "MSE train 5.523230950158646 MSE test 12.018076575759897\n",
      "MAE train 1.622681588922538 MAE test 2.427545591548574\n",
      "Epoch 4575 / 10000 loss: 14.119483232498169\n",
      "MSE train 5.523105687924793 MSE test 12.017878947277111\n",
      "MAE train 1.6226629118555427 MAE test 2.427520656183211\n",
      "Epoch 4576 / 10000 loss: 14.118820667266846\n",
      "MSE train 5.522962004607203 MSE test 12.017759576786212\n",
      "MAE train 1.6226384709896569 MAE test 2.4275110896090952\n",
      "Epoch 4577 / 10000 loss: 14.118345260620117\n",
      "MSE train 5.522846610724953 MSE test 12.017609223081362\n",
      "MAE train 1.6226212449981137 MAE test 2.4274921799604954\n",
      "Epoch 4578 / 10000 loss: 14.117826461791992\n",
      "MSE train 5.5227054647587766 MSE test 12.01741427581959\n",
      "MAE train 1.6225992475709778 MAE test 2.4274730744375472\n",
      "Epoch 4579 / 10000 loss: 14.117365837097168\n",
      "MSE train 5.522569355341496 MSE test 12.017315393151895\n",
      "MAE train 1.6225756908804574 MAE test 2.427460740408859\n",
      "Epoch 4580 / 10000 loss: 14.116911172866821\n",
      "MSE train 5.522424998949795 MSE test 12.017192735873907\n",
      "MAE train 1.6225511342916972 MAE test 2.427450738193241\n",
      "Epoch 4581 / 10000 loss: 14.116333246231079\n",
      "MSE train 5.522309468777963 MSE test 12.01704004145248\n",
      "MAE train 1.6225339173456519 MAE test 2.427431530541261\n",
      "Epoch 4582 / 10000 loss: 14.115813970565796\n",
      "MSE train 5.522167961719009 MSE test 12.016845734752732\n",
      "MAE train 1.6225118192996113 MAE test 2.427412506873561\n",
      "Epoch 4583 / 10000 loss: 14.115353107452393\n",
      "MSE train 5.522032574771236 MSE test 12.016745660451003\n",
      "MAE train 1.6224884623531397 MAE test 2.427400019104574\n",
      "Epoch 4584 / 10000 loss: 14.114896535873413\n",
      "MSE train 5.5218879089791795 MSE test 12.01661837361377\n",
      "MAE train 1.6224639475870073 MAE test 2.427389438857431\n",
      "Epoch 4585 / 10000 loss: 14.114322900772095\n",
      "MSE train 5.521773322901149 MSE test 12.016470377497948\n",
      "MAE train 1.622446859606513 MAE test 2.427370843246615\n",
      "Epoch 4586 / 10000 loss: 14.113805532455444\n",
      "MSE train 5.521631905701029 MSE test 12.016267717683967\n",
      "MAE train 1.6224249431034314 MAE test 2.427350755025857\n",
      "Epoch 4587 / 10000 loss: 14.113344430923462\n",
      "MSE train 5.521493128027798 MSE test 12.016168629220333\n",
      "MAE train 1.622400747403829 MAE test 2.427338406934423\n",
      "Epoch 4588 / 10000 loss: 14.112895727157593\n",
      "MSE train 5.521349639396128 MSE test 12.016061193209463\n",
      "MAE train 1.6223760499729114 MAE test 2.427330341158914\n",
      "Epoch 4589 / 10000 loss: 14.11230754852295\n",
      "MSE train 5.521228306130319 MSE test 12.015884447740683\n",
      "MAE train 1.6223579474225345 MAE test 2.427308070339213\n",
      "Epoch 4590 / 10000 loss: 14.111780881881714\n",
      "MSE train 5.521085217348732 MSE test 12.015732237805679\n",
      "MAE train 1.622334452332776 MAE test 2.4272943905228237\n",
      "Epoch 4591 / 10000 loss: 14.111313104629517\n",
      "MSE train 5.520968870642668 MSE test 12.015614059799969\n",
      "MAE train 1.6223162631751005 MAE test 2.427279581811339\n",
      "Epoch 4592 / 10000 loss: 14.11081838607788\n",
      "MSE train 5.520827232269876 MSE test 12.015399698207002\n",
      "MAE train 1.622294522226079 MAE test 2.4272580077421457\n",
      "Epoch 4593 / 10000 loss: 14.110331773757935\n",
      "MSE train 5.520684470972924 MSE test 12.015300794150049\n",
      "MAE train 1.6222694091038112 MAE test 2.427245687152131\n",
      "Epoch 4594 / 10000 loss: 14.109891653060913\n",
      "MSE train 5.520544925482385 MSE test 12.015220248254236\n",
      "MAE train 1.6222449733463638 MAE test 2.427241029257973\n",
      "Epoch 4595 / 10000 loss: 14.109288692474365\n",
      "MSE train 5.52041379414843 MSE test 12.014994179258967\n",
      "MAE train 1.622225663734416 MAE test 2.4272125252191055\n",
      "Epoch 4596 / 10000 loss: 14.108757734298706\n",
      "MSE train 5.520277660346542 MSE test 12.014935068240925\n",
      "MAE train 1.6222015761407171 MAE test 2.4272106148746273\n",
      "Epoch 4597 / 10000 loss: 14.108281373977661\n",
      "MSE train 5.520145100562779 MSE test 12.014683915351814\n",
      "MAE train 1.6221825400697059 MAE test 2.4271789621226114\n",
      "Epoch 4598 / 10000 loss: 14.107755184173584\n",
      "MSE train 5.520018807726191 MSE test 12.014667595638445\n",
      "MAE train 1.6221599709940153 MAE test 2.4271824763702856\n",
      "Epoch 4599 / 10000 loss: 14.10728931427002\n",
      "MSE train 5.5198884812933775 MSE test 12.0143361632567\n",
      "MAE train 1.6221433802329523 MAE test 2.427140664183189\n",
      "Epoch 4600 / 10000 loss: 14.106775999069214\n",
      "MSE train 5.519739885137687 MSE test 12.014369473624145\n",
      "MAE train 1.6221141096774807 MAE test 2.427150513615963\n",
      "Epoch 4601 / 10000 loss: 14.106376647949219\n",
      "MSE train 5.519606324826828 MSE test 12.014121430242513\n",
      "MAE train 1.6220947202377172 MAE test 2.4271192177242895\n",
      "Epoch 4602 / 10000 loss: 14.105740070343018\n",
      "MSE train 5.519477210103461 MSE test 12.014089337279355\n",
      "MAE train 1.6220717735964951 MAE test 2.4271207265518875\n",
      "Epoch 4603 / 10000 loss: 14.105268716812134\n",
      "MSE train 5.5193455272587215 MSE test 12.013780778240886\n",
      "MAE train 1.6220543245339425 MAE test 2.4270817909191544\n",
      "Epoch 4604 / 10000 loss: 14.104750871658325\n",
      "MSE train 5.51920866524388 MSE test 12.013807083697575\n",
      "MAE train 1.6220281119913813 MAE test 2.427090732008218\n",
      "Epoch 4605 / 10000 loss: 14.104328155517578\n",
      "MSE train 5.519075490789489 MSE test 12.013497987960276\n",
      "MAE train 1.6220103000805715 MAE test 2.4270517095375976\n",
      "Epoch 4606 / 10000 loss: 14.103743076324463\n",
      "MSE train 5.518940197628772 MSE test 12.013521893341682\n",
      "MAE train 1.6219845257757173 MAE test 2.427060357346894\n",
      "Epoch 4607 / 10000 loss: 14.103316307067871\n",
      "MSE train 5.518807020920431 MSE test 12.013206678055138\n",
      "MAE train 1.6219668520625705 MAE test 2.427020538940414\n",
      "Epoch 4608 / 10000 loss: 14.102735996246338\n",
      "MSE train 5.518669001294824 MSE test 12.013232473820246\n",
      "MAE train 1.621940361656067 MAE test 2.427029424506714\n",
      "Epoch 4609 / 10000 loss: 14.102313995361328\n",
      "MSE train 5.51853511601553 MSE test 12.012929587290483\n",
      "MAE train 1.621922215531693 MAE test 2.4269911723581594\n",
      "Epoch 4610 / 10000 loss: 14.101723194122314\n",
      "MSE train 5.518403232316444 MSE test 12.012949234822502\n",
      "MAE train 1.6218973864217159 MAE test 2.4269992760745693\n",
      "Epoch 4611 / 10000 loss: 14.101288795471191\n",
      "MSE train 5.518270525967613 MSE test 12.012619924440212\n",
      "MAE train 1.6218801650733006 MAE test 2.4269576598519897\n",
      "Epoch 4612 / 10000 loss: 14.100724220275879\n",
      "MSE train 5.518125113903854 MSE test 12.012649882570782\n",
      "MAE train 1.6218517411996876 MAE test 2.4269670800806296\n",
      "Epoch 4613 / 10000 loss: 14.100314855575562\n",
      "MSE train 5.517990282577034 MSE test 12.012384043346701\n",
      "MAE train 1.621832479427649 MAE test 2.4269335100572675\n",
      "Epoch 4614 / 10000 loss: 14.099692344665527\n",
      "MSE train 5.517865171607676 MSE test 12.012372795179488\n",
      "MAE train 1.621810071304373 MAE test 2.426937675310832\n",
      "Epoch 4615 / 10000 loss: 14.099226951599121\n",
      "MSE train 5.517733748439108 MSE test 12.012030371841899\n",
      "MAE train 1.6217934517680834 MAE test 2.426894404813374\n",
      "Epoch 4616 / 10000 loss: 14.098710298538208\n",
      "MSE train 5.517581304966859 MSE test 12.012063547384622\n",
      "MAE train 1.6217632881186204 MAE test 2.42690425340196\n",
      "Epoch 4617 / 10000 loss: 14.098315715789795\n",
      "MSE train 5.517449821538922 MSE test 12.011838600198391\n",
      "MAE train 1.621743864416805 MAE test 2.4268758449919474\n",
      "Epoch 4618 / 10000 loss: 14.097663640975952\n",
      "MSE train 5.517310861491898 MSE test 12.011766825424461\n",
      "MAE train 1.6217194037239004 MAE test 2.4268723092211912\n",
      "Epoch 4619 / 10000 loss: 14.0971839427948\n",
      "MSE train 5.517178587165965 MSE test 12.011535394193928\n",
      "MAE train 1.6217000162565376 MAE test 2.4268431273895312\n",
      "Epoch 4620 / 10000 loss: 14.096651077270508\n",
      "MSE train 5.517044667120844 MSE test 12.011489380902594\n",
      "MAE train 1.6216762559208833 MAE test 2.426842858626224\n",
      "Epoch 4621 / 10000 loss: 14.096174478530884\n",
      "MSE train 5.516911651575322 MSE test 12.01121276596479\n",
      "MAE train 1.621657772337525 MAE test 2.4268079580408886\n",
      "Epoch 4622 / 10000 loss: 14.09564733505249\n",
      "MSE train 5.5167854015692805 MSE test 12.011221952236703\n",
      "MAE train 1.621634679721951 MAE test 2.4268147332764514\n",
      "Epoch 4623 / 10000 loss: 14.095196723937988\n",
      "MSE train 5.5166540628932355 MSE test 12.010869531573963\n",
      "MAE train 1.6216183165958418 MAE test 2.4267701994412123\n",
      "Epoch 4624 / 10000 loss: 14.094666004180908\n",
      "MSE train 5.51649795341022 MSE test 12.01090334830592\n",
      "MAE train 1.6215873437740427 MAE test 2.4267801442344696\n",
      "Epoch 4625 / 10000 loss: 14.094278812408447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.516371474530824 MSE test 12.010703214168943\n",
      "MAE train 1.6215685216896771 MAE test 2.42675488266419\n",
      "Epoch 4626 / 10000 loss: 14.09361219406128\n",
      "MSE train 5.516226443950069 MSE test 12.010581248611427\n",
      "MAE train 1.6215438452279474 MAE test 2.4267449917527113\n",
      "Epoch 4627 / 10000 loss: 14.093133449554443\n",
      "MSE train 5.516109802763782 MSE test 12.010428677441967\n",
      "MAE train 1.6215264742612348 MAE test 2.426725799587207\n",
      "Epoch 4628 / 10000 loss: 14.092610359191895\n",
      "MSE train 5.515967358552348 MSE test 12.010231073485615\n",
      "MAE train 1.6215042361214536 MAE test 2.426706354628262\n",
      "Epoch 4629 / 10000 loss: 14.092144250869751\n",
      "MSE train 5.515829859698234 MSE test 12.010129978364423\n",
      "MAE train 1.6214804998864079 MAE test 2.4266937409240694\n",
      "Epoch 4630 / 10000 loss: 14.09168529510498\n",
      "MSE train 5.5156841122026545 MSE test 12.010005271317821\n",
      "MAE train 1.621455695981604 MAE test 2.426683498306435\n",
      "Epoch 4631 / 10000 loss: 14.091103315353394\n",
      "MSE train 5.515567086791494 MSE test 12.0098500471199\n",
      "MAE train 1.6214383103202352 MAE test 2.426663976764143\n",
      "Epoch 4632 / 10000 loss: 14.090578556060791\n",
      "MSE train 5.515424096495307 MSE test 12.009653763825105\n",
      "MAE train 1.6214159309422471 MAE test 2.426644686029579\n",
      "Epoch 4633 / 10000 loss: 14.090111494064331\n",
      "MSE train 5.515287666338041 MSE test 12.00955122859718\n",
      "MAE train 1.6213925124919089 MAE test 2.4266319094798727\n",
      "Epoch 4634 / 10000 loss: 14.089649677276611\n",
      "MSE train 5.515141523246071 MSE test 12.009419177014504\n",
      "MAE train 1.6213677979624588 MAE test 2.4266207420635224\n",
      "Epoch 4635 / 10000 loss: 14.08907151222229\n",
      "MSE train 5.515025768381085 MSE test 12.009271229806972\n",
      "MAE train 1.6213505787831943 MAE test 2.4266021611844515\n",
      "Epoch 4636 / 10000 loss: 14.088549852371216\n",
      "MSE train 5.5148827611302105 MSE test 12.009062433283715\n",
      "MAE train 1.6213284597521833 MAE test 2.4265812912453697\n",
      "Epoch 4637 / 10000 loss: 14.088083982467651\n",
      "MSE train 5.51474117701116 MSE test 12.008960632923914\n",
      "MAE train 1.6213037900879999 MAE test 2.4265686151278247\n",
      "Epoch 4638 / 10000 loss: 14.087630987167358\n",
      "MSE train 5.514596978739218 MSE test 12.008857992441065\n",
      "MAE train 1.6212788604436683 MAE test 2.4265611862644354\n",
      "Epoch 4639 / 10000 loss: 14.08703327178955\n",
      "MSE train 5.51447074706516 MSE test 12.008665028297527\n",
      "MAE train 1.621260032709001 MAE test 2.426536872184688\n",
      "Epoch 4640 / 10000 loss: 14.086498022079468\n",
      "MSE train 5.514325672195002 MSE test 12.008536037672707\n",
      "MAE train 1.6212355400991212 MAE test 2.4265261497460586\n",
      "Epoch 4641 / 10000 loss: 14.086020231246948\n",
      "MSE train 5.514209690635985 MSE test 12.008390894477015\n",
      "MAE train 1.6212182421059427 MAE test 2.4265079430084056\n",
      "Epoch 4642 / 10000 loss: 14.085499048233032\n",
      "MSE train 5.514067069836008 MSE test 12.008178379237858\n",
      "MAE train 1.6211963096492814 MAE test 2.426486629642654\n",
      "Epoch 4643 / 10000 loss: 14.085032939910889\n",
      "MSE train 5.513923797413284 MSE test 12.008076346200099\n",
      "MAE train 1.621171272180226 MAE test 2.426473941608265\n",
      "Epoch 4644 / 10000 loss: 14.08458423614502\n",
      "MSE train 5.51378087181411 MSE test 12.007982591111857\n",
      "MAE train 1.6211464343116821 MAE test 2.4264676570184336\n",
      "Epoch 4645 / 10000 loss: 14.083979368209839\n",
      "MSE train 5.5136509326696075 MSE test 12.007771612116612\n",
      "MAE train 1.6211271480762321 MAE test 2.4264410785559036\n",
      "Epoch 4646 / 10000 loss: 14.08344316482544\n",
      "MSE train 5.51350769462196 MSE test 12.007675346658678\n",
      "MAE train 1.6211023262699613 MAE test 2.4264345151302162\n",
      "Epoch 4647 / 10000 loss: 14.082961082458496\n",
      "MSE train 5.513381123032284 MSE test 12.007483013829365\n",
      "MAE train 1.6210834447848206 MAE test 2.426410315802965\n",
      "Epoch 4648 / 10000 loss: 14.08242678642273\n",
      "MSE train 5.51323645577709 MSE test 12.007356214010796\n",
      "MAE train 1.621058991871082 MAE test 2.426399903571532\n",
      "Epoch 4649 / 10000 loss: 14.081948518753052\n",
      "MSE train 5.513120309038282 MSE test 12.007208544012965\n",
      "MAE train 1.6210416965743342 MAE test 2.4263813828879814\n",
      "Epoch 4650 / 10000 loss: 14.081428527832031\n",
      "MSE train 5.512978177481657 MSE test 12.006997906407108\n",
      "MAE train 1.6210198012645785 MAE test 2.426360324369841\n",
      "Epoch 4651 / 10000 loss: 14.080963134765625\n",
      "MSE train 5.512836105430978 MSE test 12.006895260289319\n",
      "MAE train 1.6209950087463578 MAE test 2.4263475685129716\n",
      "Epoch 4652 / 10000 loss: 14.080513715744019\n",
      "MSE train 5.512692702093071 MSE test 12.006794796375436\n",
      "MAE train 1.6209701501445226 MAE test 2.426340447768949\n",
      "Epoch 4653 / 10000 loss: 14.07991361618042\n",
      "MSE train 5.512565626255439 MSE test 12.006594423147362\n",
      "MAE train 1.6209512192482007 MAE test 2.426315207629381\n",
      "Epoch 4654 / 10000 loss: 14.079380989074707\n",
      "MSE train 5.512421482331002 MSE test 12.006476341408304\n",
      "MAE train 1.6209266152648836 MAE test 2.4263059039075623\n",
      "Epoch 4655 / 10000 loss: 14.078904151916504\n",
      "MSE train 5.51230356212054 MSE test 12.006315260235581\n",
      "MAE train 1.620909102737892 MAE test 2.4262856610330426\n",
      "Epoch 4656 / 10000 loss: 14.078380584716797\n",
      "MSE train 5.512161511097945 MSE test 12.00612472295929\n",
      "MAE train 1.6208867282820734 MAE test 2.4262671533239826\n",
      "Epoch 4657 / 10000 loss: 14.077917575836182\n",
      "MSE train 5.512029256886476 MSE test 12.006018607205009\n",
      "MAE train 1.6208643349168976 MAE test 2.4262539510252736\n",
      "Epoch 4658 / 10000 loss: 14.077451944351196\n",
      "MSE train 5.511884220291223 MSE test 12.005865147539481\n",
      "MAE train 1.6208402575971244 MAE test 2.4262401138735674\n",
      "Epoch 4659 / 10000 loss: 14.076894760131836\n",
      "MSE train 5.511769622652328 MSE test 12.005734766642332\n",
      "MAE train 1.6208227886859028 MAE test 2.4262238055262126\n",
      "Epoch 4660 / 10000 loss: 14.076392889022827\n",
      "MSE train 5.51162763155498 MSE test 12.005512070641556\n",
      "MAE train 1.6208010234426193 MAE test 2.426201205959239\n",
      "Epoch 4661 / 10000 loss: 14.07591986656189\n",
      "MSE train 5.511483959945589 MSE test 12.005409026336373\n",
      "MAE train 1.6207757610124838 MAE test 2.426188394936317\n",
      "Epoch 4662 / 10000 loss: 14.075482845306396\n",
      "MSE train 5.511346400090203 MSE test 12.00533192510986\n",
      "MAE train 1.620751572707681 MAE test 2.426184236559287\n",
      "Epoch 4663 / 10000 loss: 14.074877262115479\n",
      "MSE train 5.511213893127318 MSE test 12.005085652664832\n",
      "MAE train 1.6207323430558334 MAE test 2.426153194147905\n",
      "Epoch 4664 / 10000 loss: 14.074351787567139\n",
      "MSE train 5.5110842927420896 MSE test 12.00504691780565\n",
      "MAE train 1.620709305024825 MAE test 2.426153952612023\n",
      "Epoch 4665 / 10000 loss: 14.073882818222046\n",
      "MSE train 5.510953066179304 MSE test 12.004741707068407\n",
      "MAE train 1.6206917990459766 MAE test 2.426115440707568\n",
      "Epoch 4666 / 10000 loss: 14.073368072509766\n",
      "MSE train 5.5108198662743515 MSE test 12.004761687061427\n",
      "MAE train 1.6206665019348543 MAE test 2.426123691096944\n",
      "Epoch 4667 / 10000 loss: 14.07294511795044\n",
      "MSE train 5.510688223618698 MSE test 12.004436000539489\n",
      "MAE train 1.620649362019035 MAE test 2.42608256214387\n",
      "Epoch 4668 / 10000 loss: 14.072378396987915\n",
      "MSE train 5.510546800899459 MSE test 12.00446091544341\n",
      "MAE train 1.6206218846912843 MAE test 2.4260914570088223\n",
      "Epoch 4669 / 10000 loss: 14.071970224380493\n",
      "MSE train 5.510413231181874 MSE test 12.004175765570965\n",
      "MAE train 1.6206032645952735 MAE test 2.4260554515559742\n",
      "Epoch 4670 / 10000 loss: 14.071364641189575\n",
      "MSE train 5.510289073669898 MSE test 12.004177198728831\n",
      "MAE train 1.6205806253282853 MAE test 2.4260613416489\n",
      "Epoch 4671 / 10000 loss: 14.070920467376709\n",
      "MSE train 5.510158569065311 MSE test 12.003822960258642\n",
      "MAE train 1.620564338705253 MAE test 2.426016599469287\n",
      "Epoch 4672 / 10000 loss: 14.070398807525635\n",
      "MSE train 5.510005140255764 MSE test 12.003852822688948\n",
      "MAE train 1.6205338532823599 MAE test 2.4260261528459344\n",
      "Epoch 4673 / 10000 loss: 14.070018768310547\n",
      "MSE train 5.509878829391487 MSE test 12.003643387102883\n",
      "MAE train 1.6205151221596814 MAE test 2.425999753079974\n",
      "Epoch 4674 / 10000 loss: 14.069364786148071\n",
      "MSE train 5.5097364563564275 MSE test 12.003531211598872\n",
      "MAE train 1.6204906366294907 MAE test 2.425991198583989\n",
      "Epoch 4675 / 10000 loss: 14.068894147872925\n",
      "MSE train 5.509617640991381 MSE test 12.003359355447326\n",
      "MAE train 1.6204729898870844 MAE test 2.425969619799696\n",
      "Epoch 4676 / 10000 loss: 14.0683753490448\n",
      "MSE train 5.509476224148976 MSE test 12.003190007147833\n",
      "MAE train 1.6204500977564202 MAE test 2.4259538396726317\n",
      "Epoch 4677 / 10000 loss: 14.06791615486145\n",
      "MSE train 5.509355499696666 MSE test 12.003076970942804\n",
      "MAE train 1.620430623869137 MAE test 2.4259397574909145\n",
      "Epoch 4678 / 10000 loss: 14.067439079284668\n",
      "MSE train 5.5092139287184985 MSE test 12.002878220008611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6204083859545058 MAE test 2.425920217910998\n",
      "Epoch 4679 / 10000 loss: 14.066933631896973\n",
      "MSE train 5.509080615964909 MSE test 12.00277303505944\n",
      "MAE train 1.6203855642515734 MAE test 2.425907166077659\n",
      "Epoch 4680 / 10000 loss: 14.066480159759521\n",
      "MSE train 5.5089366986850035 MSE test 12.00263605479372\n",
      "MAE train 1.6203612443856494 MAE test 2.42589546296712\n",
      "Epoch 4681 / 10000 loss: 14.065917015075684\n",
      "MSE train 5.508823814287447 MSE test 12.00249036189495\n",
      "MAE train 1.6203444531806581 MAE test 2.425877217767801\n",
      "Epoch 4682 / 10000 loss: 14.065408706665039\n",
      "MSE train 5.508683299739307 MSE test 12.002276733252248\n",
      "MAE train 1.620322775485032 MAE test 2.4258558002018074\n",
      "Epoch 4683 / 10000 loss: 14.064953327178955\n",
      "MSE train 5.508542917932798 MSE test 12.002174706099044\n",
      "MAE train 1.6202981918847332 MAE test 2.425843167982635\n",
      "Epoch 4684 / 10000 loss: 14.064516067504883\n",
      "MSE train 5.508402775087881 MSE test 12.002080900830984\n",
      "MAE train 1.6202737473407665 MAE test 2.425836944821258\n",
      "Epoch 4685 / 10000 loss: 14.063924551010132\n",
      "MSE train 5.508275556655847 MSE test 12.001870758129233\n",
      "MAE train 1.6202548653978748 MAE test 2.425810501039001\n",
      "Epoch 4686 / 10000 loss: 14.063401222229004\n",
      "MSE train 5.508135005806563 MSE test 12.001775355348892\n",
      "MAE train 1.620230433996062 MAE test 2.4258041194056146\n",
      "Epoch 4687 / 10000 loss: 14.062930822372437\n",
      "MSE train 5.508011162716456 MSE test 12.00158368057607\n",
      "MAE train 1.620211952731459 MAE test 2.425780033183905\n",
      "Epoch 4688 / 10000 loss: 14.062408924102783\n",
      "MSE train 5.507869137001943 MSE test 12.001458674241185\n",
      "MAE train 1.620187865157914 MAE test 2.425769913402465\n",
      "Epoch 4689 / 10000 loss: 14.061943292617798\n",
      "MSE train 5.507755476701004 MSE test 12.001311531097956\n",
      "MAE train 1.620170942163992 MAE test 2.4257514962089157\n",
      "Epoch 4690 / 10000 loss: 14.061434268951416\n",
      "MSE train 5.507615842790644 MSE test 12.001103253062844\n",
      "MAE train 1.620149366138236 MAE test 2.425730794166114\n",
      "Epoch 4691 / 10000 loss: 14.060981273651123\n",
      "MSE train 5.507476648744504 MSE test 12.001002025490612\n",
      "MAE train 1.620125038881802 MAE test 2.4257182747018873\n",
      "Epoch 4692 / 10000 loss: 14.060541152954102\n",
      "MSE train 5.507335300654349 MSE test 12.00089989025016\n",
      "MAE train 1.6201005255940921 MAE test 2.425711011153994\n",
      "Epoch 4693 / 10000 loss: 14.05995488166809\n",
      "MSE train 5.507211532903703 MSE test 12.000706145973549\n",
      "MAE train 1.6200820897600823 MAE test 2.425686657038701\n",
      "Epoch 4694 / 10000 loss: 14.05943250656128\n",
      "MSE train 5.507069301442123 MSE test 12.000579598192843\n",
      "MAE train 1.6200579726605568 MAE test 2.4256763453773176\n",
      "Epoch 4695 / 10000 loss: 14.058966398239136\n",
      "MSE train 5.506955765940481 MSE test 12.000432199626374\n",
      "MAE train 1.6200410764430173 MAE test 2.4256579125994\n",
      "Epoch 4696 / 10000 loss: 14.058457851409912\n",
      "MSE train 5.506816016700261 MSE test 12.000223856248423\n",
      "MAE train 1.6200194735055795 MAE test 2.4256372134988826\n",
      "Epoch 4697 / 10000 loss: 14.058005094528198\n",
      "MSE train 5.5066769028239655 MSE test 12.000122223548175\n",
      "MAE train 1.6199951641199337 MAE test 2.425624648200479\n",
      "Epoch 4698 / 10000 loss: 14.057565450668335\n",
      "MSE train 5.506535642683812 MSE test 12.000020204452959\n",
      "MAE train 1.6199706639660134 MAE test 2.425617410536722\n",
      "Epoch 4699 / 10000 loss: 14.056979179382324\n",
      "MSE train 5.50641195857763 MSE test 11.999826541472084\n",
      "MAE train 1.6199522384619254 MAE test 2.425593071192294\n",
      "Epoch 4700 / 10000 loss: 14.056457996368408\n",
      "MSE train 5.5062697104767695 MSE test 11.99969994525228\n",
      "MAE train 1.6199281196074733 MAE test 2.425582772086376\n",
      "Epoch 4701 / 10000 loss: 14.055990934371948\n",
      "MSE train 5.506156215272408 MSE test 11.999552524691712\n",
      "MAE train 1.6199112264821562 MAE test 2.425564316327017\n",
      "Epoch 4702 / 10000 loss: 14.055483341217041\n",
      "MSE train 5.506016552326655 MSE test 11.99934429432106\n",
      "MAE train 1.6198896324482726 MAE test 2.4255436409263846\n",
      "Epoch 4703 / 10000 loss: 14.05502963066101\n",
      "MSE train 5.505877515015737 MSE test 11.999242801016223\n",
      "MAE train 1.6198653388097501 MAE test 2.425531106191323\n",
      "Epoch 4704 / 10000 loss: 14.054591417312622\n",
      "MSE train 5.50573623738029 MSE test 11.999140456272269\n",
      "MAE train 1.6198408415507042 MAE test 2.425523830772718\n",
      "Epoch 4705 / 10000 loss: 14.054004430770874\n",
      "MSE train 5.505612671145612 MSE test 11.998947232989737\n",
      "MAE train 1.6198224376400385 MAE test 2.425499556924035\n",
      "Epoch 4706 / 10000 loss: 14.053483724594116\n",
      "MSE train 5.505470565223062 MSE test 11.998819679277236\n",
      "MAE train 1.6197983554578215 MAE test 2.425489134933512\n",
      "Epoch 4707 / 10000 loss: 14.05301809310913\n",
      "MSE train 5.505357239266843 MSE test 11.998673438636335\n",
      "MAE train 1.6197814842762843 MAE test 2.425470841929749\n",
      "Epoch 4708 / 10000 loss: 14.052510976791382\n",
      "MSE train 5.505217618607207 MSE test 11.99846350485199\n",
      "MAE train 1.6197599272682361 MAE test 2.4254499433629144\n",
      "Epoch 4709 / 10000 loss: 14.052056789398193\n",
      "MSE train 5.505078063871808 MSE test 11.99836217661107\n",
      "MAE train 1.6197355080539129 MAE test 2.4254374279901953\n",
      "Epoch 4710 / 10000 loss: 14.0516197681427\n",
      "MSE train 5.50493737963524 MSE test 11.998263675438539\n",
      "MAE train 1.619711040062842 MAE test 2.425430651341635\n",
      "Epoch 4711 / 10000 loss: 14.051032781600952\n",
      "MSE train 5.504812314253331 MSE test 11.998063657080602\n",
      "MAE train 1.6196924201125795 MAE test 2.4254055054992514\n",
      "Epoch 4712 / 10000 loss: 14.050509929656982\n",
      "MSE train 5.504670605423162 MSE test 11.997949670805452\n",
      "MAE train 1.6196681233901526 MAE test 2.425396820557741\n",
      "Epoch 4713 / 10000 loss: 14.050043821334839\n",
      "MSE train 5.504553933013552 MSE test 11.997786691141139\n",
      "MAE train 1.619650788099007 MAE test 2.425376403560722\n",
      "Epoch 4714 / 10000 loss: 14.0495285987854\n",
      "MSE train 5.504413640321852 MSE test 11.997604311523013\n",
      "MAE train 1.6196284712135263 MAE test 2.4253590174169966\n",
      "Epoch 4715 / 10000 loss: 14.049073696136475\n",
      "MSE train 5.504286562310349 MSE test 11.997497772285207\n",
      "MAE train 1.6196072296033537 MAE test 2.425345825156036\n",
      "Epoch 4716 / 10000 loss: 14.048611640930176\n",
      "MSE train 5.5041439302521376 MSE test 11.99732921645557\n",
      "MAE train 1.6195839740222104 MAE test 2.425330161017876\n",
      "Epoch 4717 / 10000 loss: 14.048076868057251\n",
      "MSE train 5.504025831450851 MSE test 11.997212294158759\n",
      "MAE train 1.619565191058316 MAE test 2.4253156366762356\n",
      "Epoch 4718 / 10000 loss: 14.047596216201782\n",
      "MSE train 5.503884523515867 MSE test 11.997007008056961\n",
      "MAE train 1.6195431180770674 MAE test 2.4252953111602684\n",
      "Epoch 4719 / 10000 loss: 14.047102451324463\n",
      "MSE train 5.503748675859188 MSE test 11.996903168080394\n",
      "MAE train 1.6195196022677818 MAE test 2.4252824782089726\n",
      "Epoch 4720 / 10000 loss: 14.046656370162964\n",
      "MSE train 5.503605733825116 MSE test 11.996783430597443\n",
      "MAE train 1.619495091770276 MAE test 2.425273010933986\n",
      "Epoch 4721 / 10000 loss: 14.046082973480225\n",
      "MSE train 5.503488885488013 MSE test 11.996616077572643\n",
      "MAE train 1.6194777763008124 MAE test 2.425252025427698\n",
      "Epoch 4722 / 10000 loss: 14.045567512512207\n",
      "MSE train 5.503347967253505 MSE test 11.996436558858486\n",
      "MAE train 1.6194552090640373 MAE test 2.425234993795427\n",
      "Epoch 4723 / 10000 loss: 14.045110702514648\n",
      "MSE train 5.5032232243166685 MSE test 11.99632774217711\n",
      "MAE train 1.6194345938244723 MAE test 2.4252215113286293\n",
      "Epoch 4724 / 10000 loss: 14.044645547866821\n",
      "MSE train 5.503080967601343 MSE test 11.996149182444515\n",
      "MAE train 1.6194116568371588 MAE test 2.4252045861505866\n",
      "Epoch 4725 / 10000 loss: 14.04412055015564\n",
      "MSE train 5.502958481720401 MSE test 11.99603719663964\n",
      "MAE train 1.6193916571785787 MAE test 2.425190697442448\n",
      "Epoch 4726 / 10000 loss: 14.043650150299072\n",
      "MSE train 5.502816373197112 MSE test 11.99585002657601\n",
      "MAE train 1.6193689697218796 MAE test 2.4251726612152535\n",
      "Epoch 4727 / 10000 loss: 14.043134927749634\n",
      "MSE train 5.502689788607152 MSE test 11.995741172331652\n",
      "MAE train 1.6193478747037942 MAE test 2.425159179881047\n",
      "Epoch 4728 / 10000 loss: 14.04267144203186\n",
      "MSE train 5.502546731980569 MSE test 11.995572753251935\n",
      "MAE train 1.619324490376169 MAE test 2.4251435427565324\n",
      "Epoch 4729 / 10000 loss: 14.042137145996094\n",
      "MSE train 5.502429282336517 MSE test 11.995454395925618\n",
      "MAE train 1.619305895964478 MAE test 2.4251288327294427\n",
      "Epoch 4730 / 10000 loss: 14.041656255722046\n",
      "MSE train 5.50228810124937 MSE test 11.995247251141393\n",
      "MAE train 1.6192838665246059 MAE test 2.425108259126941\n",
      "Epoch 4731 / 10000 loss: 14.041165113449097\n",
      "MSE train 5.502151635833965 MSE test 11.995143546085465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6192601883129412 MAE test 2.4250954399717233\n",
      "Epoch 4732 / 10000 loss: 14.04072093963623\n",
      "MSE train 5.502009072967288 MSE test 11.995027952119095\n",
      "MAE train 1.6192356705805198 MAE test 2.4250865162870263\n",
      "Epoch 4733 / 10000 loss: 14.040144920349121\n",
      "MSE train 5.501890702313304 MSE test 11.994854193288367\n",
      "MAE train 1.6192181125822254 MAE test 2.4250647072772353\n",
      "Epoch 4734 / 10000 loss: 14.039628505706787\n",
      "MSE train 5.5017493981253205 MSE test 11.994686792122858\n",
      "MAE train 1.6191951427399833 MAE test 2.425049216181523\n",
      "Epoch 4735 / 10000 loss: 14.039169549942017\n",
      "MSE train 5.501630319814668 MSE test 11.994572449430791\n",
      "MAE train 1.619176069180419 MAE test 2.425035022661122\n",
      "Epoch 4736 / 10000 loss: 14.038694381713867\n",
      "MSE train 5.501489326777574 MSE test 11.99437004046794\n",
      "MAE train 1.6191539979108374 MAE test 2.4250150693944765\n",
      "Epoch 4737 / 10000 loss: 14.038195371627808\n",
      "MSE train 5.501354643510219 MSE test 11.994266073314574\n",
      "MAE train 1.6191307709602483 MAE test 2.4250022160519937\n",
      "Epoch 4738 / 10000 loss: 14.037747621536255\n",
      "MSE train 5.501211513411015 MSE test 11.99413972686062\n",
      "MAE train 1.6191063348326313 MAE test 2.4249919321037123\n",
      "Epoch 4739 / 10000 loss: 14.037180423736572\n",
      "MSE train 5.5010968967195915 MSE test 11.993981567667051\n",
      "MAE train 1.619089364735498 MAE test 2.424972103585908\n",
      "Epoch 4740 / 10000 loss: 14.036668539047241\n",
      "MSE train 5.50095656809261 MSE test 11.993786427582545\n",
      "MAE train 1.6190673081121105 MAE test 2.42495309491674\n",
      "Epoch 4741 / 10000 loss: 14.036214590072632\n",
      "MSE train 5.500824268432019 MSE test 11.993682017415187\n",
      "MAE train 1.6190446920492076 MAE test 2.4249401786670153\n",
      "Epoch 4742 / 10000 loss: 14.03576374053955\n",
      "MSE train 5.5006809247276225 MSE test 11.993541861651368\n",
      "MAE train 1.6190205456377298 MAE test 2.4249281402960032\n",
      "Epoch 4743 / 10000 loss: 14.035205841064453\n",
      "MSE train 5.500568822537808 MSE test 11.993400814617425\n",
      "MAE train 1.6190038059101175 MAE test 2.4249105047184107\n",
      "Epoch 4744 / 10000 loss: 14.034703493118286\n",
      "MSE train 5.5004287425789435 MSE test 11.993183643808152\n",
      "MAE train 1.6189822547013255 MAE test 2.424888714114537\n",
      "Epoch 4745 / 10000 loss: 14.034249067306519\n",
      "MSE train 5.500287644042661 MSE test 11.993081841192451\n",
      "MAE train 1.6189574601575758 MAE test 2.4248761150130793\n",
      "Epoch 4746 / 10000 loss: 14.03381633758545\n",
      "MSE train 5.500149645787022 MSE test 11.992997314679222\n",
      "MAE train 1.6189332538283927 MAE test 2.4248711450247806\n",
      "Epoch 4747 / 10000 loss: 14.033222436904907\n",
      "MSE train 5.500020140692758 MSE test 11.992770029262722\n",
      "MAE train 1.618914239975883 MAE test 2.4248425326215304\n",
      "Epoch 4748 / 10000 loss: 14.03270173072815\n",
      "MSE train 5.4998853330936 MSE test 11.99270571225951\n",
      "MAE train 1.6188903524043174 MAE test 2.4248401456677184\n",
      "Epoch 4749 / 10000 loss: 14.032234191894531\n",
      "MSE train 5.499754447719591 MSE test 11.992455693859359\n",
      "MAE train 1.6188715426127465 MAE test 2.4248086755232636\n",
      "Epoch 4750 / 10000 loss: 14.031716346740723\n",
      "MSE train 5.499628837638698 MSE test 11.99243140104435\n",
      "MAE train 1.6188490854300401 MAE test 2.4248113818340844\n",
      "Epoch 4751 / 10000 loss: 14.03125786781311\n",
      "MSE train 5.499499874601217 MSE test 11.992105695010757\n",
      "MAE train 1.6188325636284535 MAE test 2.424770273320169\n",
      "Epoch 4752 / 10000 loss: 14.030752897262573\n",
      "MSE train 5.499356734549217 MSE test 11.992134096802747\n",
      "MAE train 1.6188045049496158 MAE test 2.424779751178598\n",
      "Epoch 4753 / 10000 loss: 14.03035569190979\n",
      "MSE train 5.499224175791989 MSE test 11.991862736080472\n",
      "MAE train 1.6187857645700223 MAE test 2.4247455303535648\n",
      "Epoch 4754 / 10000 loss: 14.02974534034729\n",
      "MSE train 5.499101538999443 MSE test 11.991853488768479\n",
      "MAE train 1.618763653961795 MAE test 2.4247501639912024\n",
      "Epoch 4755 / 10000 loss: 14.029294490814209\n",
      "MSE train 5.498972178789783 MSE test 11.991504761565253\n",
      "MAE train 1.6187474983726353 MAE test 2.4247061192875288\n",
      "Epoch 4756 / 10000 loss: 14.028787851333618\n",
      "MSE train 5.498820579145914 MSE test 11.991534807281676\n",
      "MAE train 1.6187173485048851 MAE test 2.4247158112814886\n",
      "Epoch 4757 / 10000 loss: 14.02840805053711\n",
      "MSE train 5.498693220995415 MSE test 11.991318511693567\n",
      "MAE train 1.6186985154003415 MAE test 2.4246885708577746\n",
      "Epoch 4758 / 10000 loss: 14.02776288986206\n",
      "MSE train 5.498553280278637 MSE test 11.991222948502344\n",
      "MAE train 1.6186741510556464 MAE test 2.4246822189540636\n",
      "Epoch 4759 / 10000 loss: 14.027294635772705\n",
      "MSE train 5.49842900905996 MSE test 11.99102659967829\n",
      "MAE train 1.6186556246283479 MAE test 2.4246575262425067\n",
      "Epoch 4760 / 10000 loss: 14.026774406433105\n",
      "MSE train 5.498287584450599 MSE test 11.990909036681892\n",
      "MAE train 1.6186314377659412 MAE test 2.4246484126550087\n",
      "Epoch 4761 / 10000 loss: 14.026309728622437\n",
      "MSE train 5.498172492097479 MSE test 11.990752174654382\n",
      "MAE train 1.6186143422892658 MAE test 2.4246287442526397\n",
      "Epoch 4762 / 10000 loss: 14.025799036026001\n",
      "MSE train 5.49803290506957 MSE test 11.990559632290099\n",
      "MAE train 1.618592406143547 MAE test 2.424610081157019\n",
      "Epoch 4763 / 10000 loss: 14.025346517562866\n",
      "MSE train 5.497901098195084 MSE test 11.990455938257004\n",
      "MAE train 1.6185698985863353 MAE test 2.4245972385914647\n",
      "Epoch 4764 / 10000 loss: 14.024895429611206\n",
      "MSE train 5.497758122196683 MSE test 11.990312859798285\n",
      "MAE train 1.6185458927937197 MAE test 2.424584866580567\n",
      "Epoch 4765 / 10000 loss: 14.024340629577637\n",
      "MSE train 5.497646075232023 MSE test 11.990175539180171\n",
      "MAE train 1.618529083417472 MAE test 2.4245676742604925\n",
      "Epoch 4766 / 10000 loss: 14.02384090423584\n",
      "MSE train 5.497506141547429 MSE test 11.989955936892686\n",
      "MAE train 1.6185075922456036 MAE test 2.424545593139561\n",
      "Epoch 4767 / 10000 loss: 14.02338433265686\n",
      "MSE train 5.497364527153408 MSE test 11.98985439061534\n",
      "MAE train 1.618482669703333 MAE test 2.424533018921052\n",
      "Epoch 4768 / 10000 loss: 14.02295446395874\n",
      "MSE train 5.497227792623769 MSE test 11.989774999461524\n",
      "MAE train 1.6184586217880634 MAE test 2.424528703178934\n",
      "Epoch 4769 / 10000 loss: 14.022358417510986\n",
      "MSE train 5.4970972783964465 MSE test 11.989537115676674\n",
      "MAE train 1.6184396071983769 MAE test 2.4244987293632967\n",
      "Epoch 4770 / 10000 loss: 14.021838426589966\n",
      "MSE train 5.49696659075032 MSE test 11.989489255202036\n",
      "MAE train 1.6184163780773269 MAE test 2.424498448547141\n",
      "Epoch 4771 / 10000 loss: 14.021373987197876\n",
      "MSE train 5.496835863055735 MSE test 11.989205455534062\n",
      "MAE train 1.6183984042997708 MAE test 2.42446266316527\n",
      "Epoch 4772 / 10000 loss: 14.020862579345703\n",
      "MSE train 5.496711254750375 MSE test 11.98921429443652\n",
      "MAE train 1.618375400066367 MAE test 2.4244696206443828\n",
      "Epoch 4773 / 10000 loss: 14.020428657531738\n",
      "MSE train 5.496581987612523 MSE test 11.988863226532331\n",
      "MAE train 1.6183593022942433 MAE test 2.424425273627605\n",
      "Epoch 4774 / 10000 loss: 14.019904136657715\n",
      "MSE train 5.496429860493606 MSE test 11.988893460555214\n",
      "MAE train 1.618329011304176 MAE test 2.4244350010281885\n",
      "Epoch 4775 / 10000 loss: 14.019526720046997\n",
      "MSE train 5.496303826228143 MSE test 11.98868275510147\n",
      "MAE train 1.6183103418753586 MAE test 2.4244084451385706\n",
      "Epoch 4776 / 10000 loss: 14.01887822151184\n",
      "MSE train 5.496162699507464 MSE test 11.988575967924715\n",
      "MAE train 1.6182859640641158 MAE test 2.424400695851248\n",
      "Epoch 4777 / 10000 loss: 14.018411874771118\n",
      "MSE train 5.4960428142507665 MSE test 11.98839742945327\n",
      "MAE train 1.6182681349867598 MAE test 2.424378258033084\n",
      "Epoch 4778 / 10000 loss: 14.017894983291626\n",
      "MSE train 5.495901650162409 MSE test 11.988243409070732\n",
      "MAE train 1.6182448546291808 MAE test 2.4243645175555084\n",
      "Epoch 4779 / 10000 loss: 14.017436504364014\n",
      "MSE train 5.495787164286668 MSE test 11.988121928767798\n",
      "MAE train 1.61822707608475 MAE test 2.4243493532377767\n",
      "Epoch 4780 / 10000 loss: 14.016950607299805\n",
      "MSE train 5.495647341993564 MSE test 11.987903675869488\n",
      "MAE train 1.6182055793722459 MAE test 2.4243274549248555\n",
      "Epoch 4781 / 10000 loss: 14.016476154327393\n",
      "MSE train 5.495506179466005 MSE test 11.987802207815173\n",
      "MAE train 1.6181807491634306 MAE test 2.424314886043625\n",
      "Epoch 4782 / 10000 loss: 14.016045808792114\n",
      "MSE train 5.495368882532665 MSE test 11.987719753326417\n",
      "MAE train 1.6181566315071525 MAE test 2.4243101822550646\n",
      "Epoch 4783 / 10000 loss: 14.015451908111572\n",
      "MSE train 5.495238999397507 MSE test 11.98748799407349\n",
      "MAE train 1.618137613102439 MAE test 2.424280980529714\n",
      "Epoch 4784 / 10000 loss: 14.01493239402771\n",
      "MSE train 5.495106090827317 MSE test 11.987430776048019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6181140283164295 MAE test 2.4242795221979576\n",
      "Epoch 4785 / 10000 loss: 14.014466285705566\n",
      "MSE train 5.494975115251615 MSE test 11.987166221830996\n",
      "MAE train 1.6180955213072747 MAE test 2.424246174693962\n",
      "Epoch 4786 / 10000 loss: 14.013951539993286\n",
      "MSE train 5.494852379789217 MSE test 11.987158437951235\n",
      "MAE train 1.6180733719542142 MAE test 2.4242510045556087\n",
      "Epoch 4787 / 10000 loss: 14.013502597808838\n",
      "MSE train 5.494723803487909 MSE test 11.986809809797755\n",
      "MAE train 1.6180573738662853 MAE test 2.4242069758341196\n",
      "Epoch 4788 / 10000 loss: 14.012998104095459\n",
      "MSE train 5.494571930677405 MSE test 11.986840471130614\n",
      "MAE train 1.6180271381073001 MAE test 2.4242167599184343\n",
      "Epoch 4789 / 10000 loss: 14.01262092590332\n",
      "MSE train 5.494445354113734 MSE test 11.986627306814032\n",
      "MAE train 1.618008396102655 MAE test 2.424189885376538\n",
      "Epoch 4790 / 10000 loss: 14.011974096298218\n",
      "MSE train 5.494304965984434 MSE test 11.986526221908179\n",
      "MAE train 1.6179840372546626 MAE test 2.42418284868211\n",
      "Epoch 4791 / 10000 loss: 14.01150631904602\n",
      "MSE train 5.494182888413077 MSE test 11.986339028298088\n",
      "MAE train 1.6179658519208695 MAE test 2.4241593015620433\n",
      "Epoch 4792 / 10000 loss: 14.010989427566528\n",
      "MSE train 5.494041454266603 MSE test 11.986202996719724\n",
      "MAE train 1.6179420715595962 MAE test 2.4241478658891014\n",
      "Epoch 4793 / 10000 loss: 14.010526418685913\n",
      "MSE train 5.493929403989888 MSE test 11.986066770845712\n",
      "MAE train 1.6179252415885066 MAE test 2.424130820587088\n",
      "Epoch 4794 / 10000 loss: 14.010027647018433\n",
      "MSE train 5.493790266326603 MSE test 11.985847135225983\n",
      "MAE train 1.6179039256774335 MAE test 2.42410873987568\n",
      "Epoch 4795 / 10000 loss: 14.009574174880981\n",
      "MSE train 5.493648222615965 MSE test 11.98574635370537\n",
      "MAE train 1.617878885295035 MAE test 2.424096247970296\n",
      "Epoch 4796 / 10000 loss: 14.009146451950073\n",
      "MSE train 5.49351247120191 MSE test 11.9856701235028\n",
      "MAE train 1.6178549688253983 MAE test 2.4240923501537655\n",
      "Epoch 4797 / 10000 loss: 14.008549213409424\n",
      "MSE train 5.49338155574008 MSE test 11.985426243362769\n",
      "MAE train 1.6178359789647188 MAE test 2.4240615954572555\n",
      "Epoch 4798 / 10000 loss: 14.008031845092773\n",
      "MSE train 5.493253301894799 MSE test 11.985387424798933\n",
      "MAE train 1.6178131428685942 MAE test 2.4240624826970656\n",
      "Epoch 4799 / 10000 loss: 14.007569074630737\n",
      "MSE train 5.493123289724557 MSE test 11.98508554464641\n",
      "MAE train 1.6177957419114473 MAE test 2.4240243741928396\n",
      "Epoch 4800 / 10000 loss: 14.007062196731567\n",
      "MSE train 5.492992442206675 MSE test 11.985104914503625\n",
      "MAE train 1.6177709049793316 MAE test 2.4240327017255203\n",
      "Epoch 4801 / 10000 loss: 14.00664210319519\n",
      "MSE train 5.492862055478525 MSE test 11.98477743187478\n",
      "MAE train 1.6177540308406468 MAE test 2.423991312654978\n",
      "Epoch 4802 / 10000 loss: 14.00608491897583\n",
      "MSE train 5.492720389038257 MSE test 11.98480346845433\n",
      "MAE train 1.6177263255719239 MAE test 2.424000503912032\n",
      "Epoch 4803 / 10000 loss: 14.005685806274414\n",
      "MSE train 5.492587762074719 MSE test 11.984528317898153\n",
      "MAE train 1.6177076256477387 MAE test 2.4239657724863424\n",
      "Epoch 4804 / 10000 loss: 14.005080461502075\n",
      "MSE train 5.492465477039042 MSE test 11.984521576472565\n",
      "MAE train 1.617685519403488 MAE test 2.4239707402534068\n",
      "Epoch 4805 / 10000 loss: 14.004632711410522\n",
      "MSE train 5.492336091434983 MSE test 11.984171022802755\n",
      "MAE train 1.6176693425649482 MAE test 2.4239264447917193\n",
      "Epoch 4806 / 10000 loss: 14.004125833511353\n",
      "MSE train 5.492184331375232 MSE test 11.984200675691838\n",
      "MAE train 1.6176391436508906 MAE test 2.4239360971543618\n",
      "Epoch 4807 / 10000 loss: 14.003747940063477\n",
      "MSE train 5.492058032308955 MSE test 11.983988078646195\n",
      "MAE train 1.617620434755034 MAE test 2.423909285929357\n",
      "Epoch 4808 / 10000 loss: 14.00310206413269\n",
      "MSE train 5.491917410869409 MSE test 11.98388466955469\n",
      "MAE train 1.6175960748363496 MAE test 2.4239019655671923\n",
      "Epoch 4809 / 10000 loss: 14.002634763717651\n",
      "MSE train 5.491796210382893 MSE test 11.98370060155748\n",
      "MAE train 1.6175780229373913 MAE test 2.4238787998050695\n",
      "Epoch 4810 / 10000 loss: 14.00211787223816\n",
      "MSE train 5.491654962123762 MSE test 11.983557787202178\n",
      "MAE train 1.617554426966782 MAE test 2.423866500480197\n",
      "Epoch 4811 / 10000 loss: 14.001657485961914\n",
      "MSE train 5.491542685371621 MSE test 11.98342761587146\n",
      "MAE train 1.617537400802808 MAE test 2.423850196006319\n",
      "Epoch 4812 / 10000 loss: 14.001163721084595\n",
      "MSE train 5.4914033702799525 MSE test 11.983205252013063\n",
      "MAE train 1.617516067244527 MAE test 2.4238277952627145\n",
      "Epoch 4813 / 10000 loss: 14.000704050064087\n",
      "MSE train 5.491260836103519 MSE test 11.983104344068265\n",
      "MAE train 1.6174909228340952 MAE test 2.423815269299283\n",
      "Epoch 4814 / 10000 loss: 14.000279664993286\n",
      "MSE train 5.491126296415353 MSE test 11.983032909480732\n",
      "MAE train 1.6174671925182778 MAE test 2.4238119956700284\n",
      "Epoch 4815 / 10000 loss: 13.999679803848267\n",
      "MSE train 5.490994859882102 MSE test 11.982778853773754\n",
      "MAE train 1.6174482831827375 MAE test 2.423779940030403\n",
      "Epoch 4816 / 10000 loss: 13.999162912368774\n",
      "MSE train 5.490869858569441 MSE test 11.98275305212242\n",
      "MAE train 1.6174259485506397 MAE test 2.4237824914146033\n",
      "Epoch 4817 / 10000 loss: 13.99870491027832\n",
      "MSE train 5.4907406920743 MSE test 11.982426881530792\n",
      "MAE train 1.61740933195007 MAE test 2.4237412667670895\n",
      "Epoch 4818 / 10000 loss: 13.998201608657837\n",
      "MSE train 5.490598140650328 MSE test 11.982454236691593\n",
      "MAE train 1.6173813918059998 MAE test 2.4237506429610076\n",
      "Epoch 4819 / 10000 loss: 13.997804641723633\n",
      "MSE train 5.490465755740454 MSE test 11.982182846488485\n",
      "MAE train 1.6173626411361721 MAE test 2.4237163741379195\n",
      "Epoch 4820 / 10000 loss: 13.997196197509766\n",
      "MSE train 5.4903433843359775 MSE test 11.982173037147172\n",
      "MAE train 1.617340592131188 MAE test 2.4237209522982197\n",
      "Epoch 4821 / 10000 loss: 13.996746063232422\n",
      "MSE train 5.490214151037711 MSE test 11.981824749266869\n",
      "MAE train 1.6173243876581203 MAE test 2.4236769301124323\n",
      "Epoch 4822 / 10000 loss: 13.996241092681885\n",
      "MSE train 5.4900630610809715 MSE test 11.981854369800045\n",
      "MAE train 1.6172943397318575 MAE test 2.423686599618065\n",
      "Epoch 4823 / 10000 loss: 13.995862007141113\n",
      "MSE train 5.489935687729448 MSE test 11.981637044497788\n",
      "MAE train 1.6172754961828 MAE test 2.42365917192099\n",
      "Epoch 4824 / 10000 loss: 13.99521780014038\n",
      "MSE train 5.489796235171302 MSE test 11.981543306291991\n",
      "MAE train 1.6172511643824348 MAE test 2.423653083313496\n",
      "Epoch 4825 / 10000 loss: 13.9947509765625\n",
      "MSE train 5.489671429921801 MSE test 11.981343529569482\n",
      "MAE train 1.6172325538127617 MAE test 2.4236279245016568\n",
      "Epoch 4826 / 10000 loss: 13.994231700897217\n",
      "MSE train 5.489530624438158 MSE test 11.981232783331194\n",
      "MAE train 1.6172083246002884 MAE test 2.4236196925699245\n",
      "Epoch 4827 / 10000 loss: 13.99376654624939\n",
      "MSE train 5.489413319313041 MSE test 11.98106612898974\n",
      "MAE train 1.617190876571248 MAE test 2.423598737582335\n",
      "Epoch 4828 / 10000 loss: 13.9932541847229\n",
      "MSE train 5.489273359448729 MSE test 11.980891755794602\n",
      "MAE train 1.6171683416928193 MAE test 2.4235824147821337\n",
      "Epoch 4829 / 10000 loss: 13.992799520492554\n",
      "MSE train 5.489150738961599 MSE test 11.980782199977376\n",
      "MAE train 1.6171482402332165 MAE test 2.423568768193725\n",
      "Epoch 4830 / 10000 loss: 13.992333173751831\n",
      "MSE train 5.489009576900116 MSE test 11.980595072796246\n",
      "MAE train 1.617125705984164 MAE test 2.4235508078234513\n",
      "Epoch 4831 / 10000 loss: 13.99181842803955\n",
      "MSE train 5.488883048027025 MSE test 11.980486913527736\n",
      "MAE train 1.6171045778308097 MAE test 2.4235373458573903\n",
      "Epoch 4832 / 10000 loss: 13.991358757019043\n",
      "MSE train 5.488740520951107 MSE test 11.98031972278465\n",
      "MAE train 1.6170812201100815 MAE test 2.4235219132575634\n",
      "Epoch 4833 / 10000 loss: 13.990824699401855\n",
      "MSE train 5.488623934340764 MSE test 11.980200696770849\n",
      "MAE train 1.6170628166862127 MAE test 2.4235070301053883\n",
      "Epoch 4834 / 10000 loss: 13.990344762802124\n",
      "MSE train 5.488483174208295 MSE test 11.979991744379458\n",
      "MAE train 1.61704085464048 MAE test 2.4234863058421077\n",
      "Epoch 4835 / 10000 loss: 13.98985767364502\n",
      "MSE train 5.488346445459039 MSE test 11.979888278646246\n",
      "MAE train 1.6170170687272174 MAE test 2.423473431784877\n",
      "Epoch 4836 / 10000 loss: 13.989416360855103\n",
      "MSE train 5.488204741959486 MSE test 11.979776498461456\n",
      "MAE train 1.6169926056036674 MAE test 2.423465038820572\n",
      "Epoch 4837 / 10000 loss: 13.988839626312256\n",
      "MSE train 5.488084903765916 MSE test 11.979596158966933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.616974807653068 MAE test 2.4234423271421353\n",
      "Epoch 4838 / 10000 loss: 13.98832368850708\n",
      "MSE train 5.487943589142656 MSE test 11.979441679325944\n",
      "MAE train 1.6169514513163732 MAE test 2.4234285448744393\n",
      "Epoch 4839 / 10000 loss: 13.987864255905151\n",
      "MSE train 5.487829355632182 MSE test 11.979319093329558\n",
      "MAE train 1.6169337545877722 MAE test 2.4234132046783476\n",
      "Epoch 4840 / 10000 loss: 13.987378597259521\n",
      "MSE train 5.487689560236867 MSE test 11.97910036982682\n",
      "MAE train 1.616912213273602 MAE test 2.4233912437827807\n",
      "Epoch 4841 / 10000 loss: 13.986905813217163\n",
      "MSE train 5.48754850915908 MSE test 11.978998707834233\n",
      "MAE train 1.6168874013548513 MAE test 2.4233786113460973\n",
      "Epoch 4842 / 10000 loss: 13.986475944519043\n",
      "MSE train 5.487411292279322 MSE test 11.978915413776944\n",
      "MAE train 1.6168632960679936 MAE test 2.4233738267891156\n",
      "Epoch 4843 / 10000 loss: 13.985881090164185\n",
      "MSE train 5.487281479944839 MSE test 11.978684436610763\n",
      "MAE train 1.6168442470483115 MAE test 2.423344672524194\n",
      "Epoch 4844 / 10000 loss: 13.985362529754639\n",
      "MSE train 5.487148328252034 MSE test 11.9786256062627\n",
      "MAE train 1.6168206333871413 MAE test 2.4233430285167468\n",
      "Epoch 4845 / 10000 loss: 13.984895944595337\n",
      "MSE train 5.487017387220839 MSE test 11.978363555265295\n",
      "MAE train 1.6168020319871548 MAE test 2.4233099482313354\n",
      "Epoch 4846 / 10000 loss: 13.984380722045898\n",
      "MSE train 5.48689440854744 MSE test 11.97835278521993\n",
      "MAE train 1.616779906862076 MAE test 2.4233144288928217\n",
      "Epoch 4847 / 10000 loss: 13.983930349349976\n",
      "MSE train 5.486765757060751 MSE test 11.978006996166982\n",
      "MAE train 1.6167637856300343 MAE test 2.4232706949728438\n",
      "Epoch 4848 / 10000 loss: 13.983426570892334\n",
      "MSE train 5.486614788482369 MSE test 11.978036949799515\n",
      "MAE train 1.6167337744101808 MAE test 2.4232804034702005\n",
      "Epoch 4849 / 10000 loss: 13.983046770095825\n",
      "MSE train 5.486486776441301 MSE test 11.977817120473942\n",
      "MAE train 1.6167148446738737 MAE test 2.423252649336896\n",
      "Epoch 4850 / 10000 loss: 13.982403755187988\n",
      "MSE train 5.486348062602397 MSE test 11.977729038365808\n",
      "MAE train 1.6166905504064286 MAE test 2.423247281112311\n",
      "Epoch 4851 / 10000 loss: 13.981934070587158\n",
      "MSE train 5.486221183661901 MSE test 11.977519416747791\n",
      "MAE train 1.616671692286762 MAE test 2.423220845158576\n",
      "Epoch 4852 / 10000 loss: 13.981415510177612\n",
      "MSE train 5.4860819452551635 MSE test 11.977427960297597\n",
      "MAE train 1.6166473866772115 MAE test 2.4232150802072416\n",
      "Epoch 4853 / 10000 loss: 13.980947971343994\n",
      "MSE train 5.485957155205589 MSE test 11.977230900311621\n",
      "MAE train 1.616628741166024 MAE test 2.423190218070784\n",
      "Epoch 4854 / 10000 loss: 13.98042917251587\n",
      "MSE train 5.485816178295391 MSE test 11.977118129217338\n",
      "MAE train 1.6166045347605502 MAE test 2.4231817447798427\n",
      "Epoch 4855 / 10000 loss: 13.979962587356567\n",
      "MSE train 5.485699556788763 MSE test 11.976955487679014\n",
      "MAE train 1.6165871804991772 MAE test 2.423161273583492\n",
      "Epoch 4856 / 10000 loss: 13.979450225830078\n",
      "MSE train 5.485559727417306 MSE test 11.976773747200022\n",
      "MAE train 1.6165648716095504 MAE test 2.423144027396991\n",
      "Epoch 4857 / 10000 loss: 13.97899580001831\n",
      "MSE train 5.485433293320673 MSE test 11.97666703305869\n",
      "MAE train 1.616543775460878 MAE test 2.423130733762605\n",
      "Epoch 4858 / 10000 loss: 13.978534698486328\n",
      "MSE train 5.485291118551601 MSE test 11.976495820386884\n",
      "MAE train 1.6165206050541443 MAE test 2.4231147800304824\n",
      "Epoch 4859 / 10000 loss: 13.978002786636353\n",
      "MSE train 5.48517228931706 MSE test 11.976380037351035\n",
      "MAE train 1.6165015977604817 MAE test 2.4231003019225503\n",
      "Epoch 4860 / 10000 loss: 13.97752594947815\n",
      "MSE train 5.4850310098620465 MSE test 11.97617757053224\n",
      "MAE train 1.616479398499662 MAE test 2.4230803837259938\n",
      "Epoch 4861 / 10000 loss: 13.977027654647827\n",
      "MSE train 5.484897032457008 MSE test 11.976072910681232\n",
      "MAE train 1.6164563507603062 MAE test 2.423067338240741\n",
      "Epoch 4862 / 10000 loss: 13.976578712463379\n",
      "MSE train 5.484753792645352 MSE test 11.975942270219315\n",
      "MAE train 1.6164319430969514 MAE test 2.4230565526437062\n",
      "Epoch 4863 / 10000 loss: 13.976013660430908\n",
      "MSE train 5.484639871943278 MSE test 11.975788068748699\n",
      "MAE train 1.616415058036635 MAE test 2.4230371325693874\n",
      "Epoch 4864 / 10000 loss: 13.975503206253052\n",
      "MSE train 5.484499599391266 MSE test 11.975585886320967\n",
      "MAE train 1.6163931063456796 MAE test 2.4230172711328275\n",
      "Epoch 4865 / 10000 loss: 13.975050449371338\n",
      "MSE train 5.48436429119197 MSE test 11.975482402832979\n",
      "MAE train 1.6163697226186273 MAE test 2.423004379082364\n",
      "Epoch 4866 / 10000 loss: 13.974603652954102\n",
      "MSE train 5.48422126830465 MSE test 11.975357501120692\n",
      "MAE train 1.6163452510537843 MAE test 2.422994308198957\n",
      "Epoch 4867 / 10000 loss: 13.974032878875732\n",
      "MSE train 5.484105807664403 MSE test 11.97519674163766\n",
      "MAE train 1.616328134702941 MAE test 2.4229740622385383\n",
      "Epoch 4868 / 10000 loss: 13.973519325256348\n",
      "MSE train 5.483965173113875 MSE test 11.975005349900785\n",
      "MAE train 1.6163058764211655 MAE test 2.422955562313095\n",
      "Epoch 4869 / 10000 loss: 13.973063707351685\n",
      "MSE train 5.48383468113706 MSE test 11.97489967116531\n",
      "MAE train 1.6162837686259464 MAE test 2.4229423642660977\n",
      "Epoch 4870 / 10000 loss: 13.972607851028442\n",
      "MSE train 5.4836912577445505 MSE test 11.974747259698384\n",
      "MAE train 1.6162598627727187 MAE test 2.422928820707771\n",
      "Epoch 4871 / 10000 loss: 13.972057342529297\n",
      "MSE train 5.483577961461884 MSE test 11.974616800509793\n",
      "MAE train 1.6162426214688637 MAE test 2.4229124163211146\n",
      "Epoch 4872 / 10000 loss: 13.971561670303345\n",
      "MSE train 5.48343716092564 MSE test 11.974395307669191\n",
      "MAE train 1.6162209338540088 MAE test 2.4228900960435475\n",
      "Epoch 4873 / 10000 loss: 13.971094131469727\n",
      "MSE train 5.4832948240194685 MSE test 11.974293137874215\n",
      "MAE train 1.6161958802891436 MAE test 2.422877342031121\n",
      "Epoch 4874 / 10000 loss: 13.970661401748657\n",
      "MSE train 5.483157764277135 MSE test 11.974213785564233\n",
      "MAE train 1.6161717740747106 MAE test 2.4228730469014272\n",
      "Epoch 4875 / 10000 loss: 13.970062255859375\n",
      "MSE train 5.483026181558913 MSE test 11.973973047984543\n",
      "MAE train 1.6161525900555223 MAE test 2.4228426089889687\n",
      "Epoch 4876 / 10000 loss: 13.969538927078247\n",
      "MSE train 5.482895608074642 MSE test 11.973927749075282\n",
      "MAE train 1.616129394872339 MAE test 2.422842663611876\n",
      "Epoch 4877 / 10000 loss: 13.969071865081787\n",
      "MSE train 5.482764087060566 MSE test 11.973636331258978\n",
      "MAE train 1.616111419746122 MAE test 2.42280578758548\n",
      "Epoch 4878 / 10000 loss: 13.96855640411377\n",
      "MSE train 5.482636406323396 MSE test 11.973648638380006\n",
      "MAE train 1.616087655477696 MAE test 2.4228132264146223\n",
      "Epoch 4879 / 10000 loss: 13.968123197555542\n",
      "MSE train 5.482505573822596 MSE test 11.973304216120331\n",
      "MAE train 1.616071058411726 MAE test 2.4227695869060595\n",
      "Epoch 4880 / 10000 loss: 13.967582702636719\n",
      "MSE train 5.482354967328307 MSE test 11.973332269520842\n",
      "MAE train 1.616041229423006 MAE test 2.4227790370055753\n",
      "Epoch 4881 / 10000 loss: 13.967191934585571\n",
      "MSE train 5.482223956545147 MSE test 11.97310182726103\n",
      "MAE train 1.6160219406449243 MAE test 2.422749863003703\n",
      "Epoch 4882 / 10000 loss: 13.966548919677734\n",
      "MSE train 5.48208708774141 MSE test 11.973030098564324\n",
      "MAE train 1.6159977863344643 MAE test 2.4227465407342113\n",
      "Epoch 4883 / 10000 loss: 13.96607518196106\n",
      "MSE train 5.481954984480889 MSE test 11.9727870368171\n",
      "MAE train 1.6159785917127942 MAE test 2.422715794654006\n",
      "Epoch 4884 / 10000 loss: 13.965550422668457\n",
      "MSE train 5.4818253693193535 MSE test 11.972749168080123\n",
      "MAE train 1.6159555468711677 MAE test 2.4227167889214227\n",
      "Epoch 4885 / 10000 loss: 13.965081691741943\n",
      "MSE train 5.481693824734582 MSE test 11.97244432270992\n",
      "MAE train 1.6159379427372027 MAE test 2.4226781713771794\n",
      "Epoch 4886 / 10000 loss: 13.964566230773926\n",
      "MSE train 5.481559706788442 MSE test 11.972463795638744\n",
      "MAE train 1.6159124647321332 MAE test 2.422686510568383\n",
      "Epoch 4887 / 10000 loss: 13.964140892028809\n",
      "MSE train 5.481426975129072 MSE test 11.972141031552393\n",
      "MAE train 1.615895021399805 MAE test 2.422645568092226\n",
      "Epoch 4888 / 10000 loss: 13.963568687438965\n",
      "MSE train 5.481286061989267 MSE test 11.97216349380978\n",
      "MAE train 1.6158677721149 MAE test 2.422654274138074\n",
      "Epoch 4889 / 10000 loss: 13.963154554367065\n",
      "MSE train 5.481151275768324 MSE test 11.97187275886638\n",
      "MAE train 1.6158490548966609 MAE test 2.4226173969620515\n",
      "Epoch 4890 / 10000 loss: 13.962551832199097\n",
      "MSE train 5.48102457791831 MSE test 11.971877013442132\n",
      "MAE train 1.615825794203515 MAE test 2.422623732326232\n",
      "Epoch 4891 / 10000 loss: 13.96210503578186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.480892012150785 MSE test 11.971526530864667\n",
      "MAE train 1.6158089937692888 MAE test 2.422579259456872\n",
      "Epoch 4892 / 10000 loss: 13.961568593978882\n",
      "MSE train 5.480738390264868 MSE test 11.971553406906915\n",
      "MAE train 1.6157785779475435 MAE test 2.4225884911967888\n",
      "Epoch 4893 / 10000 loss: 13.961175918579102\n",
      "MSE train 5.480607716351057 MSE test 11.971333147591357\n",
      "MAE train 1.615759216658793 MAE test 2.422560517818938\n",
      "Epoch 4894 / 10000 loss: 13.960520267486572\n",
      "MSE train 5.480465165147056 MSE test 11.971238340849853\n",
      "MAE train 1.6157343794117573 MAE test 2.4225542108531575\n",
      "Epoch 4895 / 10000 loss: 13.96003794670105\n",
      "MSE train 5.480336099575716 MSE test 11.971033502979438\n",
      "MAE train 1.6157151272613368 MAE test 2.4225281827348515\n",
      "Epoch 4896 / 10000 loss: 13.95950436592102\n",
      "MSE train 5.480191728552413 MSE test 11.97092565855406\n",
      "MAE train 1.615690237351762 MAE test 2.422520192483889\n",
      "Epoch 4897 / 10000 loss: 13.959021806716919\n",
      "MSE train 5.480067886473084 MSE test 11.97074781610042\n",
      "MAE train 1.6156717742311595 MAE test 2.4224975865080163\n",
      "Epoch 4898 / 10000 loss: 13.958489656448364\n",
      "MSE train 5.479922398583134 MSE test 11.97058659312655\n",
      "MAE train 1.6156479107420865 MAE test 2.422482749875051\n",
      "Epoch 4899 / 10000 loss: 13.958012104034424\n",
      "MSE train 5.4798011224665375 MSE test 11.970464533909277\n",
      "MAE train 1.6156288910857375 MAE test 2.4224672363960496\n",
      "Epoch 4900 / 10000 loss: 13.957508563995361\n",
      "MSE train 5.479654841297276 MSE test 11.970245650529856\n",
      "MAE train 1.6156062440151069 MAE test 2.422445018448236\n",
      "Epoch 4901 / 10000 loss: 13.957003831863403\n",
      "MSE train 5.479507733944572 MSE test 11.97013893925267\n",
      "MAE train 1.6155805664736274 MAE test 2.4224313905112123\n",
      "Epoch 4902 / 10000 loss: 13.956541776657104\n",
      "MSE train 5.479359527336556 MSE test 11.970039064336532\n",
      "MAE train 1.6155548052644564 MAE test 2.4224241858251196\n",
      "Epoch 4903 / 10000 loss: 13.955920934677124\n",
      "MSE train 5.479221659962457 MSE test 11.969821511209242\n",
      "MAE train 1.615534199668068 MAE test 2.4223962810817117\n",
      "Epoch 4904 / 10000 loss: 13.955361604690552\n",
      "MSE train 5.479068327247791 MSE test 11.969718851124636\n",
      "MAE train 1.6155076691270958 MAE test 2.4223886389653666\n",
      "Epoch 4905 / 10000 loss: 13.954846382141113\n",
      "MSE train 5.478926348532781 MSE test 11.969514246807007\n",
      "MAE train 1.615486282496864 MAE test 2.4223622111124565\n",
      "Epoch 4906 / 10000 loss: 13.954267024993896\n",
      "MSE train 5.478761826742555 MSE test 11.969383402245523\n",
      "MAE train 1.615458394671842 MAE test 2.422350766578447\n",
      "Epoch 4907 / 10000 loss: 13.953723192214966\n",
      "MSE train 5.478616060547418 MSE test 11.969212936359035\n",
      "MAE train 1.615436263276721 MAE test 2.4223284415056963\n",
      "Epoch 4908 / 10000 loss: 13.953109741210938\n",
      "MSE train 5.478436892809973 MSE test 11.969000540474052\n",
      "MAE train 1.615407763320498 MAE test 2.422306288759263\n",
      "Epoch 4909 / 10000 loss: 13.952518463134766\n",
      "MSE train 5.478256987590727 MSE test 11.968876367961192\n",
      "MAE train 1.6153771152832779 MAE test 2.4222896312256346\n",
      "Epoch 4910 / 10000 loss: 13.951889991760254\n",
      "MSE train 5.478066080038783 MSE test 11.96871466662477\n",
      "MAE train 1.6153446360021981 MAE test 2.422273723021264\n",
      "Epoch 4911 / 10000 loss: 13.95111632347107\n",
      "MSE train 5.477917063945841 MSE test 11.96855480730146\n",
      "MAE train 1.615321068653069 MAE test 2.4222524829662233\n",
      "Epoch 4912 / 10000 loss: 13.950396299362183\n",
      "MSE train 5.477755802223565 MSE test 11.968325771661384\n",
      "MAE train 1.6152955546189531 MAE test 2.422228387377384\n",
      "Epoch 4913 / 10000 loss: 13.949774742126465\n",
      "MSE train 5.477604609712729 MSE test 11.968219481233279\n",
      "MAE train 1.6152687908779597 MAE test 2.422214554305745\n",
      "Epoch 4914 / 10000 loss: 13.949250221252441\n",
      "MSE train 5.47746085458024 MSE test 11.968132398872918\n",
      "MAE train 1.6152435306078987 MAE test 2.422208952860251\n",
      "Epoch 4915 / 10000 loss: 13.948615550994873\n",
      "MSE train 5.47732870865689 MSE test 11.967913778871859\n",
      "MAE train 1.615223972903446 MAE test 2.4221811288055592\n",
      "Epoch 4916 / 10000 loss: 13.94807481765747\n",
      "MSE train 5.477190318452856 MSE test 11.967846435313515\n",
      "MAE train 1.6151996180995472 MAE test 2.422178311795074\n",
      "Epoch 4917 / 10000 loss: 13.947596788406372\n",
      "MSE train 5.47705880008414 MSE test 11.96761945477096\n",
      "MAE train 1.6151804636479676 MAE test 2.4221495948943317\n",
      "Epoch 4918 / 10000 loss: 13.94707202911377\n",
      "MSE train 5.476926968152023 MSE test 11.967579006888538\n",
      "MAE train 1.6151571125314248 MAE test 2.422150314487325\n",
      "Epoch 4919 / 10000 loss: 13.946604013442993\n",
      "MSE train 5.476795708913267 MSE test 11.967304638386443\n",
      "MAE train 1.6151390765757434 MAE test 2.422115660329252\n",
      "Epoch 4920 / 10000 loss: 13.946089506149292\n",
      "MSE train 5.4766709912380485 MSE test 11.967319471213461\n",
      "MAE train 1.615116180344204 MAE test 2.4221235185394576\n",
      "Epoch 4921 / 10000 loss: 13.945652961730957\n",
      "MSE train 5.476541656510892 MSE test 11.966975183297563\n",
      "MAE train 1.6151001105436646 MAE test 2.4220800166542342\n",
      "Epoch 4922 / 10000 loss: 13.945130348205566\n",
      "MSE train 5.476389444756424 MSE test 11.967011234760452\n",
      "MAE train 1.6150698501958733 MAE test 2.422090601294914\n",
      "Epoch 4923 / 10000 loss: 13.944753885269165\n",
      "MSE train 5.476263964962677 MSE test 11.96680899184985\n",
      "MAE train 1.6150513088623475 MAE test 2.4220651247351648\n",
      "Epoch 4924 / 10000 loss: 13.944105386734009\n",
      "MSE train 5.476123076987595 MSE test 11.966703625161827\n",
      "MAE train 1.6150270681707637 MAE test 2.4220576961664446\n",
      "Epoch 4925 / 10000 loss: 13.94364047050476\n",
      "MSE train 5.476004902892951 MSE test 11.966535966163594\n",
      "MAE train 1.6150095531559505 MAE test 2.4220366494056713\n",
      "Epoch 4926 / 10000 loss: 13.943126440048218\n",
      "MSE train 5.475864672054528 MSE test 11.966376190237034\n",
      "MAE train 1.614986698212688 MAE test 2.4220222969234477\n",
      "Epoch 4927 / 10000 loss: 13.942670822143555\n",
      "MSE train 5.475747360003902 MSE test 11.966265845599532\n",
      "MAE train 1.6149680544277918 MAE test 2.4220085982896817\n",
      "Epoch 4928 / 10000 loss: 13.94219708442688\n",
      "MSE train 5.47560766044875 MSE test 11.966063596324103\n",
      "MAE train 1.6149462441372233 MAE test 2.421988842867871\n",
      "Epoch 4929 / 10000 loss: 13.941706895828247\n",
      "MSE train 5.475472249390142 MSE test 11.965964724933286\n",
      "MAE train 1.6149227552393104 MAE test 2.4219765905913366\n",
      "Epoch 4930 / 10000 loss: 13.941267013549805\n",
      "MSE train 5.475330896704759 MSE test 11.965851542885279\n",
      "MAE train 1.614898425273553 MAE test 2.421968129006683\n",
      "Epoch 4931 / 10000 loss: 13.940696001052856\n",
      "MSE train 5.4752137907754985 MSE test 11.965682762763835\n",
      "MAE train 1.6148810853965427 MAE test 2.421946930540712\n",
      "Epoch 4932 / 10000 loss: 13.940184593200684\n",
      "MSE train 5.4750737311239766 MSE test 11.965516502655479\n",
      "MAE train 1.6148582997708676 MAE test 2.4219317484667204\n",
      "Epoch 4933 / 10000 loss: 13.939730882644653\n",
      "MSE train 5.474955129690527 MSE test 11.965405965694677\n",
      "MAE train 1.6148392538761551 MAE test 2.4219179844700234\n",
      "Epoch 4934 / 10000 loss: 13.939260959625244\n",
      "MSE train 5.474815232832573 MSE test 11.965208621016972\n",
      "MAE train 1.61481720588579 MAE test 2.4218988262611227\n",
      "Epoch 4935 / 10000 loss: 13.938763856887817\n",
      "MSE train 5.474683169583384 MSE test 11.96510676353162\n",
      "MAE train 1.6147945699408504 MAE test 2.421886182389649\n",
      "Epoch 4936 / 10000 loss: 13.938318967819214\n",
      "MSE train 5.474541043085753 MSE test 11.964974430633138\n",
      "MAE train 1.6147703931222808 MAE test 2.421875274092895\n",
      "Epoch 4937 / 10000 loss: 13.937761306762695\n",
      "MSE train 5.474429185593663 MSE test 11.964828248504103\n",
      "MAE train 1.6147538159785761 MAE test 2.4218569405312587\n",
      "Epoch 4938 / 10000 loss: 13.937258243560791\n",
      "MSE train 5.474290316727228 MSE test 11.964621275739464\n",
      "MAE train 1.6147321751696182 MAE test 2.4218365772096893\n",
      "Epoch 4939 / 10000 loss: 13.936810970306396\n",
      "MSE train 5.474153491570741 MSE test 11.964521274797123\n",
      "MAE train 1.614708300251731 MAE test 2.42182414844147\n",
      "Epoch 4940 / 10000 loss: 13.936376571655273\n",
      "MSE train 5.474013336607503 MSE test 11.964416218903084\n",
      "MAE train 1.6146839804758637 MAE test 2.4218166930287137\n",
      "Epoch 4941 / 10000 loss: 13.935799360275269\n",
      "MSE train 5.473892510474967 MSE test 11.964230731920185\n",
      "MAE train 1.614666009368482 MAE test 2.4217933342502596\n",
      "Epoch 4942 / 10000 loss: 13.935285329818726\n",
      "MSE train 5.47375189568509 MSE test 11.964092851715444\n",
      "MAE train 1.614642345053485 MAE test 2.421781743738549\n",
      "Epoch 4943 / 10000 loss: 13.934827327728271\n",
      "MSE train 5.473640679760258 MSE test 11.963959885608553\n",
      "MAE train 1.614625626847975 MAE test 2.4217650870552023\n",
      "Epoch 4944 / 10000 loss: 13.934333324432373\n",
      "MSE train 5.4735022899774455 MSE test 11.963741069068785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6146043086384672 MAE test 2.4217432218697845\n",
      "Epoch 4945 / 10000 loss: 13.933881521224976\n",
      "MSE train 5.473361312961417 MSE test 11.963641537097084\n",
      "MAE train 1.614579440045111 MAE test 2.421730849353973\n",
      "Epoch 4946 / 10000 loss: 13.933457612991333\n",
      "MSE train 5.47322655729745 MSE test 11.963566116663513\n",
      "MAE train 1.6145556644302819 MAE test 2.4217271529117848\n",
      "Epoch 4947 / 10000 loss: 13.932864427566528\n",
      "MSE train 5.473096614703978 MSE test 11.963324264350401\n",
      "MAE train 1.6145367590730375 MAE test 2.421696623864561\n",
      "Epoch 4948 / 10000 loss: 13.932350397109985\n",
      "MSE train 5.472969295031573 MSE test 11.963285738626785\n",
      "MAE train 1.6145140785584795 MAE test 2.4216976522946347\n",
      "Epoch 4949 / 10000 loss: 13.931890964508057\n",
      "MSE train 5.472840061643294 MSE test 11.96298687137297\n",
      "MAE train 1.6144966743681537 MAE test 2.4216598765291595\n",
      "Epoch 4950 / 10000 loss: 13.931387424468994\n",
      "MSE train 5.472710724067989 MSE test 11.963006209424481\n",
      "MAE train 1.6144721630851346 MAE test 2.4216683209787497\n",
      "Epoch 4951 / 10000 loss: 13.930970668792725\n",
      "MSE train 5.4725812381273995 MSE test 11.962679063032315\n",
      "MAE train 1.614455355666668 MAE test 2.4216269374799926\n",
      "Epoch 4952 / 10000 loss: 13.930421113967896\n",
      "MSE train 5.472439889808571 MSE test 11.962705929487639\n",
      "MAE train 1.614427648089452 MAE test 2.4216363339061804\n",
      "Epoch 4953 / 10000 loss: 13.930025339126587\n",
      "MSE train 5.472308190024997 MSE test 11.962436842139741\n",
      "MAE train 1.6144088860527328 MAE test 2.421602317297009\n",
      "Epoch 4954 / 10000 loss: 13.929421186447144\n",
      "MSE train 5.472186683785855 MSE test 11.962426048916699\n",
      "MAE train 1.6143870150844835 MAE test 2.4216068874020533\n",
      "Epoch 4955 / 10000 loss: 13.928973913192749\n",
      "MSE train 5.472058167302218 MSE test 11.962081313570518\n",
      "MAE train 1.6143707846910507 MAE test 2.4215632820491173\n",
      "Epoch 4956 / 10000 loss: 13.928472757339478\n",
      "MSE train 5.471908843387657 MSE test 11.962111324309106\n",
      "MAE train 1.6143410641056706 MAE test 2.4215730807049125\n",
      "Epoch 4957 / 10000 loss: 13.928094625473022\n",
      "MSE train 5.471781420475046 MSE test 11.961890786612424\n",
      "MAE train 1.614322204566782 MAE test 2.4215452176540673\n",
      "Epoch 4958 / 10000 loss: 13.927458047866821\n",
      "MSE train 5.471644394997655 MSE test 11.961806939979247\n",
      "MAE train 1.6142981044597668 MAE test 2.421540484268193\n",
      "Epoch 4959 / 10000 loss: 13.926993131637573\n",
      "MSE train 5.471517595663297 MSE test 11.961592540155882\n",
      "MAE train 1.6142792947527094 MAE test 2.4215134403669576\n",
      "Epoch 4960 / 10000 loss: 13.926478385925293\n",
      "MSE train 5.471381062613789 MSE test 11.961513466390254\n",
      "MAE train 1.6142552282945188 MAE test 2.421509310352777\n",
      "Epoch 4961 / 10000 loss: 13.926015615463257\n",
      "MSE train 5.471253792653658 MSE test 11.961297262616041\n",
      "MAE train 1.6142363739855494 MAE test 2.4214820393121093\n",
      "Epoch 4962 / 10000 loss: 13.92549991607666\n",
      "MSE train 5.471118392962792 MSE test 11.96122499750244\n",
      "MAE train 1.6142124152677912 MAE test 2.4214787812276413\n",
      "Epoch 4963 / 10000 loss: 13.925036907196045\n",
      "MSE train 5.470989898951668 MSE test 11.960997359898181\n",
      "MAE train 1.6141935489698405 MAE test 2.421450056676309\n",
      "Epoch 4964 / 10000 loss: 13.924522399902344\n",
      "MSE train 5.470858681796864 MSE test 11.960945204167588\n",
      "MAE train 1.6141701867488054 MAE test 2.421449370518007\n",
      "Epoch 4965 / 10000 loss: 13.924060344696045\n",
      "MSE train 5.470728901807387 MSE test 11.960677701717147\n",
      "MAE train 1.6141519155412554 MAE test 2.4214155801858235\n",
      "Epoch 4966 / 10000 loss: 13.9235520362854\n",
      "MSE train 5.470607299718848 MSE test 11.960676182300924\n",
      "MAE train 1.6141298402364823 MAE test 2.4214213481610525\n",
      "Epoch 4967 / 10000 loss: 13.923110246658325\n",
      "MSE train 5.470479515542824 MSE test 11.960325849863453\n",
      "MAE train 1.6141138824889834 MAE test 2.421377043495209\n",
      "Epoch 4968 / 10000 loss: 13.922606229782104\n",
      "MSE train 5.470327824779026 MSE test 11.960356779544007\n",
      "MAE train 1.6140836077901113 MAE test 2.421386977470992\n",
      "Epoch 4969 / 10000 loss: 13.922234773635864\n",
      "MSE train 5.470204023358445 MSE test 11.960153272590933\n",
      "MAE train 1.6140652292785698 MAE test 2.4213612802468663\n",
      "Epoch 4970 / 10000 loss: 13.92158842086792\n",
      "MSE train 5.470063337133877 MSE test 11.960036282742918\n",
      "MAE train 1.6140410147077833 MAE test 2.4213523524271223\n",
      "Epoch 4971 / 10000 loss: 13.921126365661621\n",
      "MSE train 5.469948134966815 MSE test 11.959874195312501\n",
      "MAE train 1.6140239195695196 MAE test 2.4213319329071243\n",
      "Epoch 4972 / 10000 loss: 13.920618057250977\n",
      "MSE train 5.469809058924794 MSE test 11.959691813921898\n",
      "MAE train 1.6140016317679682 MAE test 2.421314703486943\n",
      "Epoch 4973 / 10000 loss: 13.920167207717896\n",
      "MSE train 5.469683501817136 MSE test 11.959586200667335\n",
      "MAE train 1.613980684879417 MAE test 2.421301521218949\n",
      "Epoch 4974 / 10000 loss: 13.91971206665039\n",
      "MSE train 5.469542330569138 MSE test 11.959417477128252\n",
      "MAE train 1.6139575153479098 MAE test 2.42128599729101\n",
      "Epoch 4975 / 10000 loss: 13.919182538986206\n",
      "MSE train 5.469425397873399 MSE test 11.959301956875795\n",
      "MAE train 1.613938927274749 MAE test 2.4212715484989538\n",
      "Epoch 4976 / 10000 loss: 13.91870903968811\n",
      "MSE train 5.469285416638513 MSE test 11.959098182268884\n",
      "MAE train 1.6139168808696165 MAE test 2.421251578134204\n",
      "Epoch 4977 / 10000 loss: 13.918218612670898\n",
      "MSE train 5.469151541989654 MSE test 11.958995511123952\n",
      "MAE train 1.6138937475726283 MAE test 2.421238774594374\n",
      "Epoch 4978 / 10000 loss: 13.917776107788086\n",
      "MSE train 5.469009900646109 MSE test 11.958872483515727\n",
      "MAE train 1.6138693854500599 MAE test 2.4212290389147957\n",
      "Epoch 4979 / 10000 loss: 13.917211771011353\n",
      "MSE train 5.4688952397193695 MSE test 11.958711335524656\n",
      "MAE train 1.6138524101971514 MAE test 2.421208749573657\n",
      "Epoch 4980 / 10000 loss: 13.916703224182129\n",
      "MSE train 5.468755910147248 MSE test 11.958524798712068\n",
      "MAE train 1.6138301407102607 MAE test 2.4211909889408156\n",
      "Epoch 4981 / 10000 loss: 13.91625428199768\n",
      "MSE train 5.4686287929063 MSE test 11.958419647346265\n",
      "MAE train 1.6138087980705944 MAE test 2.421177865675908\n",
      "Epoch 4982 / 10000 loss: 13.915799379348755\n",
      "MSE train 5.468487134496895 MSE test 11.958258972602112\n",
      "MAE train 1.6137853183242008 MAE test 2.42116336632398\n",
      "Epoch 4983 / 10000 loss: 13.915263652801514\n",
      "MSE train 5.468373095324603 MSE test 11.958137847511445\n",
      "MAE train 1.6137675908337807 MAE test 2.421148192198663\n",
      "Epoch 4984 / 10000 loss: 13.914781093597412\n",
      "MSE train 5.468233436483092 MSE test 11.957923749278503\n",
      "MAE train 1.613745822303749 MAE test 2.4211269327072578\n",
      "Epoch 4985 / 10000 loss: 13.914307355880737\n",
      "MSE train 5.468095037072873 MSE test 11.957822668801931\n",
      "MAE train 1.6137215691359004 MAE test 2.421114327167646\n",
      "Epoch 4986 / 10000 loss: 13.913874864578247\n",
      "MSE train 5.467956403269602 MSE test 11.957727766442787\n",
      "MAE train 1.6136972739767315 MAE test 2.4211081616663477\n",
      "Epoch 4987 / 10000 loss: 13.913291454315186\n",
      "MSE train 5.46783089079808 MSE test 11.957521351199611\n",
      "MAE train 1.613678600495463 MAE test 2.4210820984982835\n",
      "Epoch 4988 / 10000 loss: 13.912775039672852\n",
      "MSE train 5.467691671940367 MSE test 11.957422573687172\n",
      "MAE train 1.6136543457874482 MAE test 2.4210754890988584\n",
      "Epoch 4989 / 10000 loss: 13.91231083869934\n",
      "MSE train 5.4675703481040685 MSE test 11.957237968558363\n",
      "MAE train 1.6136362398804225 MAE test 2.421052208022273\n",
      "Epoch 4990 / 10000 loss: 13.911796808242798\n",
      "MSE train 5.467429920765037 MSE test 11.95710271224302\n",
      "MAE train 1.6136125166896869 MAE test 2.4210409802680037\n",
      "Epoch 4991 / 10000 loss: 13.91133737564087\n",
      "MSE train 5.467318423253435 MSE test 11.956968205497313\n",
      "MAE train 1.6135957828803082 MAE test 2.4210240877838443\n",
      "Epoch 4992 / 10000 loss: 13.910842180252075\n",
      "MSE train 5.467180065246885 MSE test 11.956749796767753\n",
      "MAE train 1.6135744146195938 MAE test 2.421002316035294\n",
      "Epoch 4993 / 10000 loss: 13.91038966178894\n",
      "MSE train 5.467038970421858 MSE test 11.956650320470114\n",
      "MAE train 1.6135495262756314 MAE test 2.4209899058208433\n",
      "Epoch 4994 / 10000 loss: 13.909964799880981\n",
      "MSE train 5.466903664947627 MSE test 11.956572958413425\n",
      "MAE train 1.6135256338087338 MAE test 2.4209859865188266\n",
      "Epoch 4995 / 10000 loss: 13.909370183944702\n",
      "MSE train 5.46677357281322 MSE test 11.95633405584129\n",
      "MAE train 1.6135066422284894 MAE test 2.4209558029555116\n",
      "Epoch 4996 / 10000 loss: 13.908854007720947\n",
      "MSE train 5.4666449236984125 MSE test 11.956290823509255\n",
      "MAE train 1.6134837246487745 MAE test 2.42095625214472\n",
      "Epoch 4997 / 10000 loss: 13.908392906188965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.466515059244089 MSE test 11.956000213447421\n",
      "MAE train 1.6134659637819557 MAE test 2.4209195124113077\n",
      "Epoch 4998 / 10000 loss: 13.907886981964111\n",
      "MSE train 5.466388728849701 MSE test 11.956014612240606\n",
      "MAE train 1.6134423358414984 MAE test 2.4209273255758377\n",
      "Epoch 4999 / 10000 loss: 13.907460451126099\n",
      "MSE train 5.46625948303381 MSE test 11.955674642864219\n",
      "MAE train 1.6134258463940259 MAE test 2.420884323140959\n",
      "Epoch 5000 / 10000 loss: 13.906925678253174\n",
      "MSE train 5.466111794778462 MSE test 11.955703795088276\n",
      "MAE train 1.6133965261479823 MAE test 2.4208940277233646\n",
      "Epoch 5001 / 10000 loss: 13.906540393829346\n",
      "MSE train 5.465981875473108 MSE test 11.95546980938996\n",
      "MAE train 1.6133774277909736 MAE test 2.4208644305024407\n",
      "Epoch 5002 / 10000 loss: 13.90591025352478\n",
      "MSE train 5.465849350989755 MSE test 11.95540992934214\n",
      "MAE train 1.6133538957178868 MAE test 2.4208627649209618\n",
      "Epoch 5003 / 10000 loss: 13.905444145202637\n",
      "MSE train 5.465718583823217 MSE test 11.955149313869441\n",
      "MAE train 1.6133352239491012 MAE test 2.4208298246366318\n",
      "Epoch 5004 / 10000 loss: 13.90493130683899\n",
      "MSE train 5.465596220516865 MSE test 11.9551377630975\n",
      "MAE train 1.6133131961254297 MAE test 2.4208343305630757\n",
      "Epoch 5005 / 10000 loss: 13.904481649398804\n",
      "MSE train 5.465467748793999 MSE test 11.954795436556314\n",
      "MAE train 1.6132969570639306 MAE test 2.420791047725262\n",
      "Epoch 5006 / 10000 loss: 13.903979778289795\n",
      "MSE train 5.4653180774969545 MSE test 11.954825584765198\n",
      "MAE train 1.6132671663453704 MAE test 2.4208008665454734\n",
      "Epoch 5007 / 10000 loss: 13.903598546981812\n",
      "MSE train 5.465189683612475 MSE test 11.9546032221309\n",
      "MAE train 1.6132481575704856 MAE test 2.420772766228426\n",
      "Epoch 5008 / 10000 loss: 13.902961254119873\n",
      "MSE train 5.465052846906411 MSE test 11.954523724179223\n",
      "MAE train 1.6132240169406684 MAE test 2.4207686086121014\n",
      "Epoch 5009 / 10000 loss: 13.902492761611938\n",
      "MSE train 5.464924218102493 MSE test 11.954301280199395\n",
      "MAE train 1.6132050166633123 MAE test 2.420740530891537\n",
      "Epoch 5010 / 10000 loss: 13.90197491645813\n",
      "MSE train 5.464789771863356 MSE test 11.954236621598499\n",
      "MAE train 1.613181126605684 MAE test 2.4207382534402986\n",
      "Epoch 5011 / 10000 loss: 13.901509761810303\n",
      "MSE train 5.4646594091391245 MSE test 11.953992570156391\n",
      "MAE train 1.6131622249383175 MAE test 2.4207074460944615\n",
      "Epoch 5012 / 10000 loss: 13.900993347167969\n",
      "MSE train 5.464533416459647 MSE test 11.95396364287502\n",
      "MAE train 1.6131396979458241 MAE test 2.4207097313272725\n",
      "Epoch 5013 / 10000 loss: 13.900534629821777\n",
      "MSE train 5.464404352141587 MSE test 11.953648943929553\n",
      "MAE train 1.6131227536776644 MAE test 2.420669960807965\n",
      "Epoch 5014 / 10000 loss: 13.900030374526978\n",
      "MSE train 5.464266069452901 MSE test 11.953674801867747\n",
      "MAE train 1.6130959148771975 MAE test 2.420679238507481\n",
      "Epoch 5015 / 10000 loss: 13.899624586105347\n",
      "MSE train 5.464134091927114 MSE test 11.953384080550734\n",
      "MAE train 1.6130776529389932 MAE test 2.4206424801359634\n",
      "Epoch 5016 / 10000 loss: 13.89903473854065\n",
      "MSE train 5.46400881672691 MSE test 11.953393574062712\n",
      "MAE train 1.6130544201719599 MAE test 2.4206496711295573\n",
      "Epoch 5017 / 10000 loss: 13.898600816726685\n",
      "MSE train 5.463878706275568 MSE test 11.953049799967896\n",
      "MAE train 1.6130378295961567 MAE test 2.420606194724107\n",
      "Epoch 5018 / 10000 loss: 13.898070096969604\n",
      "MSE train 5.463729243876393 MSE test 11.95307882700575\n",
      "MAE train 1.6130081234656657 MAE test 2.4206158823645927\n",
      "Epoch 5019 / 10000 loss: 13.897684812545776\n",
      "MSE train 5.46359988882586 MSE test 11.952852998094182\n",
      "MAE train 1.612988982627613 MAE test 2.420587334573998\n",
      "Epoch 5020 / 10000 loss: 13.897046327590942\n",
      "MSE train 5.463463436410536 MSE test 11.952778102450514\n",
      "MAE train 1.6129648497284048 MAE test 2.4205837700869295\n",
      "Epoch 5021 / 10000 loss: 13.89657711982727\n",
      "MSE train 5.463333270848221 MSE test 11.952546259389255\n",
      "MAE train 1.6129457467536248 MAE test 2.420554496639142\n",
      "Epoch 5022 / 10000 loss: 13.896058320999146\n",
      "MSE train 5.463201820562427 MSE test 11.952496587526298\n",
      "MAE train 1.6129223384141533 MAE test 2.4205541537301083\n",
      "Epoch 5023 / 10000 loss: 13.895591259002686\n",
      "MSE train 5.463070764910801 MSE test 11.952221335953114\n",
      "MAE train 1.6129040072705014 MAE test 2.4205193901662834\n",
      "Epoch 5024 / 10000 loss: 13.89507794380188\n",
      "MSE train 5.462947159373961 MSE test 11.952225416856715\n",
      "MAE train 1.6128813802303097 MAE test 2.420525889788885\n",
      "Epoch 5025 / 10000 loss: 13.894636154174805\n",
      "MSE train 5.462817575345664 MSE test 11.951874664047486\n",
      "MAE train 1.6128650896193348 MAE test 2.420481567601629\n",
      "Epoch 5026 / 10000 loss: 13.894118547439575\n",
      "MSE train 5.4626645988584634 MSE test 11.9519048934175\n",
      "MAE train 1.612834575244896 MAE test 2.4204914036917056\n",
      "Epoch 5027 / 10000 loss: 13.893739461898804\n",
      "MSE train 5.462539220401038 MSE test 11.951701411088766\n",
      "MAE train 1.6128159345941064 MAE test 2.420465714638024\n",
      "Epoch 5028 / 10000 loss: 13.89308762550354\n",
      "MSE train 5.462396935020721 MSE test 11.951583834518594\n",
      "MAE train 1.612791405943184 MAE test 2.4204567336939564\n",
      "Epoch 5029 / 10000 loss: 13.89261770248413\n",
      "MSE train 5.4622799780797875 MSE test 11.951421799846207\n",
      "MAE train 1.61277402900504 MAE test 2.4204363423209556\n",
      "Epoch 5030 / 10000 loss: 13.892102003097534\n",
      "MSE train 5.462139145305145 MSE test 11.951239198454168\n",
      "MAE train 1.6127513907898268 MAE test 2.42041914570835\n",
      "Epoch 5031 / 10000 loss: 13.891643047332764\n",
      "MSE train 5.462011849124736 MSE test 11.951133308075438\n",
      "MAE train 1.6127301699675083 MAE test 2.4204059183300344\n",
      "Epoch 5032 / 10000 loss: 13.891179323196411\n",
      "MSE train 5.461868711429676 MSE test 11.950964336229454\n",
      "MAE train 1.6127066209886876 MAE test 2.420390400939911\n",
      "Epoch 5033 / 10000 loss: 13.890641927719116\n",
      "MSE train 5.461749684097691 MSE test 11.950848626842891\n",
      "MAE train 1.6126877030116813 MAE test 2.420375951010062\n",
      "Epoch 5034 / 10000 loss: 13.890159130096436\n",
      "MSE train 5.461607580380661 MSE test 11.95064467677227\n",
      "MAE train 1.6126652445408476 MAE test 2.420356019627765\n",
      "Epoch 5035 / 10000 loss: 13.889659881591797\n",
      "MSE train 5.461471530812568 MSE test 11.950541757874978\n",
      "MAE train 1.612641770058994 MAE test 2.420343178373565\n",
      "Epoch 5036 / 10000 loss: 13.889207601547241\n",
      "MSE train 5.461327506990215 MSE test 11.950417961036216\n",
      "MAE train 1.6126169725416606 MAE test 2.420333401741656\n",
      "Epoch 5037 / 10000 loss: 13.888633012771606\n",
      "MSE train 5.461210512527181 MSE test 11.950257047330187\n",
      "MAE train 1.6125996106707996 MAE test 2.4203131653287784\n",
      "Epoch 5038 / 10000 loss: 13.888114213943481\n",
      "MSE train 5.461068615104455 MSE test 11.950069389271128\n",
      "MAE train 1.6125768917286247 MAE test 2.420295330410449\n",
      "Epoch 5039 / 10000 loss: 13.887652397155762\n",
      "MSE train 5.460938450308729 MSE test 11.949964179611106\n",
      "MAE train 1.6125550142119311 MAE test 2.420282210292906\n",
      "Epoch 5040 / 10000 loss: 13.887187719345093\n",
      "MSE train 5.46079387651747 MSE test 11.949804590042854\n",
      "MAE train 1.612530951476593 MAE test 2.4202679066915755\n",
      "Epoch 5041 / 10000 loss: 13.886637449264526\n",
      "MSE train 5.4606773753796976 MSE test 11.949681824180761\n",
      "MAE train 1.6125129015499073 MAE test 2.420252541614379\n",
      "Epoch 5042 / 10000 loss: 13.886141777038574\n",
      "MSE train 5.460534660679423 MSE test 11.949465759738363\n",
      "MAE train 1.6124906031090436 MAE test 2.4202310960195135\n",
      "Epoch 5043 / 10000 loss: 13.885655403137207\n",
      "MSE train 5.460392389401288 MSE test 11.949364488117158\n",
      "MAE train 1.6124656629005907 MAE test 2.4202184831237985\n",
      "Epoch 5044 / 10000 loss: 13.885210514068604\n",
      "MSE train 5.460251029243547 MSE test 11.949272681079462\n",
      "MAE train 1.612440829852859 MAE test 2.4202127748010187\n",
      "Epoch 5045 / 10000 loss: 13.884610414505005\n",
      "MSE train 5.4601205743716985 MSE test 11.949058613474996\n",
      "MAE train 1.6124213878164513 MAE test 2.4201857928932298\n",
      "Epoch 5046 / 10000 loss: 13.884078025817871\n",
      "MSE train 5.459979206142186 MSE test 11.94897231181292\n",
      "MAE train 1.6123965107489728 MAE test 2.420180829075787\n",
      "Epoch 5047 / 10000 loss: 13.883596897125244\n",
      "MSE train 5.4598490933118695 MSE test 11.948764702753357\n",
      "MAE train 1.6123770626511018 MAE test 2.420154686709614\n",
      "Epoch 5048 / 10000 loss: 13.883063554763794\n",
      "MSE train 5.459706577727992 MSE test 11.948673398140066\n",
      "MAE train 1.6123520698262837 MAE test 2.420149091098223\n",
      "Epoch 5049 / 10000 loss: 13.882580757141113\n",
      "MSE train 5.4595781105122505 MSE test 11.948477649905206\n",
      "MAE train 1.6123327704042225 MAE test 2.4201244613941943\n",
      "Epoch 5050 / 10000 loss: 13.882046699523926\n",
      "MSE train 5.459433371567304 MSE test 11.948364737302045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6123077616897565 MAE test 2.420116149293482\n",
      "Epoch 5051 / 10000 loss: 13.88156247138977\n",
      "MSE train 5.459312376013515 MSE test 11.948202531781721\n",
      "MAE train 1.612289666253798 MAE test 2.4200957912464585\n",
      "Epoch 5052 / 10000 loss: 13.881032466888428\n",
      "MSE train 5.459168046375889 MSE test 11.948021551474099\n",
      "MAE train 1.6122663496088332 MAE test 2.4200788603095025\n",
      "Epoch 5053 / 10000 loss: 13.880558490753174\n",
      "MSE train 5.459037328062919 MSE test 11.947914661828612\n",
      "MAE train 1.6122445918920316 MAE test 2.42006555007553\n",
      "Epoch 5054 / 10000 loss: 13.880075931549072\n",
      "MSE train 5.458890077377742 MSE test 11.947740660616747\n",
      "MAE train 1.6122204023623192 MAE test 2.420049482288108\n",
      "Epoch 5055 / 10000 loss: 13.879523277282715\n",
      "MSE train 5.45876456677435 MSE test 11.947626146560305\n",
      "MAE train 1.6122001501278453 MAE test 2.4200352069168822\n",
      "Epoch 5056 / 10000 loss: 13.879024267196655\n",
      "MSE train 5.458617158128097 MSE test 11.94742763263735\n",
      "MAE train 1.6121765602887377 MAE test 2.4200160563449935\n",
      "Epoch 5057 / 10000 loss: 13.878496408462524\n",
      "MSE train 5.458479052173468 MSE test 11.94732153114499\n",
      "MAE train 1.6121530112167717 MAE test 2.4200028578963875\n",
      "Epoch 5058 / 10000 loss: 13.878016471862793\n",
      "MSE train 5.458328610569818 MSE test 11.947177082972038\n",
      "MAE train 1.612127431409914 MAE test 2.4199905489701248\n",
      "Epoch 5059 / 10000 loss: 13.877430200576782\n",
      "MSE train 5.458208531467268 MSE test 11.947036674887931\n",
      "MAE train 1.6121092687227763 MAE test 2.4199729982492677\n",
      "Epoch 5060 / 10000 loss: 13.876896619796753\n",
      "MSE train 5.458059833349931 MSE test 11.946817185459025\n",
      "MAE train 1.612085903129565 MAE test 2.4199512267784233\n",
      "Epoch 5061 / 10000 loss: 13.876405715942383\n",
      "MSE train 5.457909622790444 MSE test 11.946713900157405\n",
      "MAE train 1.6120594665759878 MAE test 2.4199384210951735\n",
      "Epoch 5062 / 10000 loss: 13.875935554504395\n",
      "MSE train 5.4577611608084275 MSE test 11.946624058294846\n",
      "MAE train 1.6120332299600801 MAE test 2.419933062256334\n",
      "Epoch 5063 / 10000 loss: 13.87529969215393\n",
      "MSE train 5.4576201892752785 MSE test 11.94639760053516\n",
      "MAE train 1.6120119592197344 MAE test 2.419904595842809\n",
      "Epoch 5064 / 10000 loss: 13.874733209609985\n",
      "MSE train 5.457471278450169 MSE test 11.946323244570552\n",
      "MAE train 1.6119854128381148 MAE test 2.4199012606030506\n",
      "Epoch 5065 / 10000 loss: 13.874212741851807\n",
      "MSE train 5.45732563792458 MSE test 11.946080580857592\n",
      "MAE train 1.6119635265541985 MAE test 2.4198708022919297\n",
      "Epoch 5066 / 10000 loss: 13.873637437820435\n",
      "MSE train 5.457179324486081 MSE test 11.946034982163175\n",
      "MAE train 1.6119372350574084 MAE test 2.4198711600502913\n",
      "Epoch 5067 / 10000 loss: 13.873106479644775\n",
      "MSE train 5.457028447370203 MSE test 11.945731979637163\n",
      "MAE train 1.6119156235040728 MAE test 2.4198330966541115\n",
      "Epoch 5068 / 10000 loss: 13.87252163887024\n",
      "MSE train 5.456874229907557 MSE test 11.945740535873165\n",
      "MAE train 1.6118864339188448 MAE test 2.4198404072856663\n",
      "Epoch 5069 / 10000 loss: 13.872007846832275\n",
      "MSE train 5.4567133960587375 MSE test 11.945398960611804\n",
      "MAE train 1.611863615537139 MAE test 2.419797500292552\n",
      "Epoch 5070 / 10000 loss: 13.87135100364685\n",
      "MSE train 5.456530552307653 MSE test 11.945412472709373\n",
      "MAE train 1.611827643571554 MAE test 2.4198055224808868\n",
      "Epoch 5071 / 10000 loss: 13.870821714401245\n",
      "MSE train 5.456348062843254 MSE test 11.945137752736178\n",
      "MAE train 1.6117985463219549 MAE test 2.419771158002878\n",
      "Epoch 5072 / 10000 loss: 13.87003755569458\n",
      "MSE train 5.456157590838539 MSE test 11.945091633473094\n",
      "MAE train 1.611762938950356 MAE test 2.4197717170365918\n",
      "Epoch 5073 / 10000 loss: 13.869359970092773\n",
      "MSE train 5.455940141361443 MSE test 11.944737778516538\n",
      "MAE train 1.6117281686747555 MAE test 2.4197275287499544\n",
      "Epoch 5074 / 10000 loss: 13.868565320968628\n",
      "MSE train 5.455685845944744 MSE test 11.944733036438365\n",
      "MAE train 1.6116771714213298 MAE test 2.419733534999327\n",
      "Epoch 5075 / 10000 loss: 13.867779731750488\n",
      "MSE train 5.45543062212219 MSE test 11.944436519860606\n",
      "MAE train 1.6116324794718864 MAE test 2.419696729893588\n",
      "Epoch 5076 / 10000 loss: 13.86667013168335\n",
      "MSE train 5.455201495173816 MSE test 11.944391676410048\n",
      "MAE train 1.611588401451239 MAE test 2.419697638295224\n",
      "Epoch 5077 / 10000 loss: 13.865658521652222\n",
      "MSE train 5.45500200618262 MSE test 11.944043272398453\n",
      "MAE train 1.6115576954014807 MAE test 2.419654059457801\n",
      "Epoch 5078 / 10000 loss: 13.864667654037476\n",
      "MSE train 5.45481478261306 MSE test 11.944076431362012\n",
      "MAE train 1.6115206194588378 MAE test 2.419664444640284\n",
      "Epoch 5079 / 10000 loss: 13.8639497756958\n",
      "MSE train 5.454660397139007 MSE test 11.94385315620122\n",
      "MAE train 1.6114968616354266 MAE test 2.4196363016846343\n",
      "Epoch 5080 / 10000 loss: 13.863123655319214\n",
      "MSE train 5.45451395649604 MSE test 11.943819064627945\n",
      "MAE train 1.6114706967858425 MAE test 2.419637887524779\n",
      "Epoch 5081 / 10000 loss: 13.862532138824463\n",
      "MSE train 5.4543714352442585 MSE test 11.943563746526888\n",
      "MAE train 1.6114502425311712 MAE test 2.4196056146771827\n",
      "Epoch 5082 / 10000 loss: 13.861931562423706\n",
      "MSE train 5.454239402395775 MSE test 11.943583872783202\n",
      "MAE train 1.6114261800590852 MAE test 2.419614059689584\n",
      "Epoch 5083 / 10000 loss: 13.861419677734375\n",
      "MSE train 5.454102092674684 MSE test 11.943250860097118\n",
      "MAE train 1.6114084483601576 MAE test 2.4195719298992904\n",
      "Epoch 5084 / 10000 loss: 13.860846519470215\n",
      "MSE train 5.453942851563505 MSE test 11.943295008476065\n",
      "MAE train 1.6113767785977207 MAE test 2.41958343947596\n",
      "Epoch 5085 / 10000 loss: 13.860416650772095\n",
      "MSE train 5.45381080861724 MSE test 11.943102091243526\n",
      "MAE train 1.6113569581298017 MAE test 2.4195590137433785\n",
      "Epoch 5086 / 10000 loss: 13.859721899032593\n",
      "MSE train 5.453663121863028 MSE test 11.942999827718765\n",
      "MAE train 1.6113313353224952 MAE test 2.419551938719383\n",
      "Epoch 5087 / 10000 loss: 13.859210729598999\n",
      "MSE train 5.45353942525719 MSE test 11.94284172536013\n",
      "MAE train 1.6113128262532301 MAE test 2.4195319800009956\n",
      "Epoch 5088 / 10000 loss: 13.858657360076904\n",
      "MSE train 5.453393137768296 MSE test 11.94267881150344\n",
      "MAE train 1.611288835013147 MAE test 2.419517266066272\n",
      "Epoch 5089 / 10000 loss: 13.85816216468811\n",
      "MSE train 5.453266604870561 MSE test 11.942575858362057\n",
      "MAE train 1.6112682835389915 MAE test 2.4195043281430566\n",
      "Epoch 5090 / 10000 loss: 13.857657194137573\n",
      "MSE train 5.453120185973681 MSE test 11.94238915318799\n",
      "MAE train 1.6112447554646085 MAE test 2.4194865900350906\n",
      "Epoch 5091 / 10000 loss: 13.857115745544434\n",
      "MSE train 5.452985239332137 MSE test 11.942290123551626\n",
      "MAE train 1.611221941831219 MAE test 2.419474162342915\n",
      "Epoch 5092 / 10000 loss: 13.856629371643066\n",
      "MSE train 5.452837404500562 MSE test 11.942144604814647\n",
      "MAE train 1.6111969767997052 MAE test 2.4194616384547643\n",
      "Epoch 5093 / 10000 loss: 13.856050968170166\n",
      "MSE train 5.452720218107569 MSE test 11.942019023229912\n",
      "MAE train 1.6111791493154626 MAE test 2.4194458498047906\n",
      "Epoch 5094 / 10000 loss: 13.855529308319092\n",
      "MSE train 5.4525755588128035 MSE test 11.941803593092088\n",
      "MAE train 1.6111565078522212 MAE test 2.419424511007212\n",
      "Epoch 5095 / 10000 loss: 13.855039596557617\n",
      "MSE train 5.452430175812599 MSE test 11.941706881815001\n",
      "MAE train 1.6111309484439387 MAE test 2.419412392529529\n",
      "Epoch 5096 / 10000 loss: 13.854584217071533\n",
      "MSE train 5.452289547299432 MSE test 11.941628852775436\n",
      "MAE train 1.611106105888472 MAE test 2.4194084116597265\n",
      "Epoch 5097 / 10000 loss: 13.853966474533081\n",
      "MSE train 5.452155437912788 MSE test 11.94139900493664\n",
      "MAE train 1.6110863206751345 MAE test 2.4193793854790115\n",
      "Epoch 5098 / 10000 loss: 13.853425741195679\n",
      "MSE train 5.4520203266457195 MSE test 11.941348551774912\n",
      "MAE train 1.6110622720221386 MAE test 2.4193789460035346\n",
      "Epoch 5099 / 10000 loss: 13.852939367294312\n",
      "MSE train 5.451885933711532 MSE test 11.94107971973413\n",
      "MAE train 1.6110432642460242 MAE test 2.4193450054528522\n",
      "Epoch 5100 / 10000 loss: 13.852408409118652\n",
      "MSE train 5.451760146029347 MSE test 11.941081651579598\n",
      "MAE train 1.611020395949725 MAE test 2.41935122821494\n",
      "Epoch 5101 / 10000 loss: 13.851946353912354\n",
      "MSE train 5.451628062993723 MSE test 11.940733965169807\n",
      "MAE train 1.6110036828221133 MAE test 2.419307320551016\n",
      "Epoch 5102 / 10000 loss: 13.851419687271118\n",
      "MSE train 5.451473173186254 MSE test 11.940765665847495\n",
      "MAE train 1.6109728410654756 MAE test 2.4193173169548237\n",
      "Epoch 5103 / 10000 loss: 13.851028442382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.451345608451559 MSE test 11.940563214759447\n",
      "MAE train 1.61095389439186 MAE test 2.4192917495816846\n",
      "Epoch 5104 / 10000 loss: 13.850365161895752\n",
      "MSE train 5.451201905592165 MSE test 11.940449238614795\n",
      "MAE train 1.6109290550614965 MAE test 2.4192832494020804\n",
      "Epoch 5105 / 10000 loss: 13.849884986877441\n",
      "MSE train 5.451082912278793 MSE test 11.940286132622171\n",
      "MAE train 1.6109114221868526 MAE test 2.41926270749698\n",
      "Epoch 5106 / 10000 loss: 13.849361419677734\n",
      "MSE train 5.450940799835757 MSE test 11.940110375493925\n",
      "MAE train 1.610888353122439 MAE test 2.41924642292671\n",
      "Epoch 5107 / 10000 loss: 13.848895072937012\n",
      "MSE train 5.450815468219693 MSE test 11.940004254268542\n",
      "MAE train 1.6108678249483952 MAE test 2.419233114793232\n",
      "Epoch 5108 / 10000 loss: 13.8484206199646\n",
      "MSE train 5.450672414924826 MSE test 11.93982375356465\n",
      "MAE train 1.610844587148197 MAE test 2.4192162194689306\n",
      "Epoch 5109 / 10000 loss: 13.847891330718994\n",
      "MSE train 5.450547256435273 MSE test 11.939716039284825\n",
      "MAE train 1.6108240979410535 MAE test 2.41920270239761\n",
      "Epoch 5110 / 10000 loss: 13.84741735458374\n",
      "MSE train 5.450404079547752 MSE test 11.93953770802751\n",
      "MAE train 1.6108007505679278 MAE test 2.4191860556412905\n",
      "Epoch 5111 / 10000 loss: 13.84688925743103\n",
      "MSE train 5.450280933180954 MSE test 11.939428078172892\n",
      "MAE train 1.6107807650127022 MAE test 2.419172297581657\n",
      "Epoch 5112 / 10000 loss: 13.84641432762146\n",
      "MSE train 5.45013825304839 MSE test 11.93924288196359\n",
      "MAE train 1.6107576902411957 MAE test 2.419154786491752\n",
      "Epoch 5113 / 10000 loss: 13.845894813537598\n",
      "MSE train 5.450012070227575 MSE test 11.939135824446074\n",
      "MAE train 1.6107368597839997 MAE test 2.419141344989096\n",
      "Epoch 5114 / 10000 loss: 13.845427751541138\n",
      "MSE train 5.4498691110071595 MSE test 11.938965503871502\n",
      "MAE train 1.6107133139522576 MAE test 2.4191257089932474\n",
      "Epoch 5115 / 10000 loss: 13.844894647598267\n",
      "MSE train 5.449750469690772 MSE test 11.938851053482589\n",
      "MAE train 1.610694516796191 MAE test 2.419111321211312\n",
      "Epoch 5116 / 10000 loss: 13.844413995742798\n",
      "MSE train 5.449609114171152 MSE test 11.938649551016656\n",
      "MAE train 1.610672082445683 MAE test 2.419091740594477\n",
      "Epoch 5117 / 10000 loss: 13.843916177749634\n",
      "MSE train 5.449475409249642 MSE test 11.938547170624462\n",
      "MAE train 1.6106492064408409 MAE test 2.4190788819187725\n",
      "Epoch 5118 / 10000 loss: 13.843467235565186\n",
      "MSE train 5.449332681572014 MSE test 11.938417699021613\n",
      "MAE train 1.6106247078211542 MAE test 2.4190683935064623\n",
      "Epoch 5119 / 10000 loss: 13.842902183532715\n",
      "MSE train 5.449218989317015 MSE test 11.938265629149365\n",
      "MAE train 1.6106079709943046 MAE test 2.4190492113790025\n",
      "Epoch 5120 / 10000 loss: 13.842393159866333\n",
      "MSE train 5.449079323848204 MSE test 11.938065985366125\n",
      "MAE train 1.6105858842755176 MAE test 2.419029882879897\n",
      "Epoch 5121 / 10000 loss: 13.841941833496094\n",
      "MSE train 5.448945630775214 MSE test 11.937964519512068\n",
      "MAE train 1.6105629645883 MAE test 2.4190171269823266\n",
      "Epoch 5122 / 10000 loss: 13.84149694442749\n",
      "MSE train 5.448803546160585 MSE test 11.937836713808203\n",
      "MAE train 1.6105385593094546 MAE test 2.4190068446304873\n",
      "Epoch 5123 / 10000 loss: 13.840932607650757\n",
      "MSE train 5.448690026787719 MSE test 11.937683209183474\n",
      "MAE train 1.6105218587633021 MAE test 2.418987489241934\n",
      "Epoch 5124 / 10000 loss: 13.840425729751587\n",
      "MSE train 5.448550825860137 MSE test 11.93748558183566\n",
      "MAE train 1.6104998082370168 MAE test 2.418968401727774\n",
      "Epoch 5125 / 10000 loss: 13.839974880218506\n",
      "MSE train 5.448418479489109 MSE test 11.93738371719262\n",
      "MAE train 1.6104772117335127 MAE test 2.4189555858688103\n",
      "Epoch 5126 / 10000 loss: 13.839531660079956\n",
      "MSE train 5.448276696178354 MSE test 11.937250118935339\n",
      "MAE train 1.6104529526621851 MAE test 2.418944551043297\n",
      "Epoch 5127 / 10000 loss: 13.838972330093384\n",
      "MSE train 5.448164753597111 MSE test 11.937103394497168\n",
      "MAE train 1.6104364645846256 MAE test 2.418926044348696\n",
      "Epoch 5128 / 10000 loss: 13.838471412658691\n",
      "MSE train 5.448026013570806 MSE test 11.936895930164463\n",
      "MAE train 1.610414682790667 MAE test 2.418905700188415\n",
      "Epoch 5129 / 10000 loss: 13.83802318572998\n",
      "MSE train 5.447889867030165 MSE test 11.936795357929118\n",
      "MAE train 1.6103910283312077 MAE test 2.41889303057531\n",
      "Epoch 5130 / 10000 loss: 13.837589263916016\n",
      "MSE train 5.4477499072748365 MSE test 11.936686450718769\n",
      "MAE train 1.610366671667052 MAE test 2.418885111592831\n",
      "Epoch 5131 / 10000 loss: 13.837014198303223\n",
      "MSE train 5.447630260385334 MSE test 11.936504362681882\n",
      "MAE train 1.6103489664369548 MAE test 2.418862075949246\n",
      "Epoch 5132 / 10000 loss: 13.836503267288208\n",
      "MSE train 5.447490278021121 MSE test 11.93635830847689\n",
      "MAE train 1.6103254403986187 MAE test 2.4188495050625334\n",
      "Epoch 5133 / 10000 loss: 13.836047172546387\n",
      "MSE train 5.447378852081429 MSE test 11.936231066211032\n",
      "MAE train 1.6103085986061458 MAE test 2.4188334473262127\n",
      "Epoch 5134 / 10000 loss: 13.835562705993652\n",
      "MSE train 5.447240785428875 MSE test 11.936010429398033\n",
      "MAE train 1.6102871831429726 MAE test 2.41881143794077\n",
      "Epoch 5135 / 10000 loss: 13.835105657577515\n",
      "MSE train 5.447100438405145 MSE test 11.935910772434214\n",
      "MAE train 1.6102624874156406 MAE test 2.418798866935871\n",
      "Epoch 5136 / 10000 loss: 13.834684133529663\n",
      "MSE train 5.446966480111597 MSE test 11.935833916653905\n",
      "MAE train 1.6102387915818919 MAE test 2.4187949824005086\n",
      "Epoch 5137 / 10000 loss: 13.834093809127808\n",
      "MSE train 5.446837059267666 MSE test 11.935591869735374\n",
      "MAE train 1.6102199659487104 MAE test 2.4187643533969534\n",
      "Epoch 5138 / 10000 loss: 13.83358359336853\n",
      "MSE train 5.446710666128508 MSE test 11.935552060518404\n",
      "MAE train 1.6101974165078703 MAE test 2.4187651858197805\n",
      "Epoch 5139 / 10000 loss: 13.833127975463867\n",
      "MSE train 5.446582052257699 MSE test 11.935253162731616\n",
      "MAE train 1.6101800768020047 MAE test 2.418727402257664\n",
      "Epoch 5140 / 10000 loss: 13.83262825012207\n",
      "MSE train 5.446453395488099 MSE test 11.935270877236745\n",
      "MAE train 1.6101556607658942 MAE test 2.4187355389358425\n",
      "Epoch 5141 / 10000 loss: 13.832215309143066\n",
      "MSE train 5.446324482077252 MSE test 11.934945701696977\n",
      "MAE train 1.6101388548871989 MAE test 2.4186944041835217\n",
      "Epoch 5142 / 10000 loss: 13.831667423248291\n",
      "MSE train 5.446184965856398 MSE test 11.934970322944773\n",
      "MAE train 1.6101115218856048 MAE test 2.418703415916744\n",
      "Epoch 5143 / 10000 loss: 13.831275224685669\n",
      "MSE train 5.446053932685066 MSE test 11.934698041339853\n",
      "MAE train 1.610092915135907 MAE test 2.418668934823289\n",
      "Epoch 5144 / 10000 loss: 13.830679416656494\n",
      "MSE train 5.445933561501571 MSE test 11.934689210955757\n",
      "MAE train 1.6100711532862073 MAE test 2.4186737052087315\n",
      "Epoch 5145 / 10000 loss: 13.830238580703735\n",
      "MSE train 5.445805651537257 MSE test 11.934342811316634\n",
      "MAE train 1.6100550040572101 MAE test 2.418629894183827\n",
      "Epoch 5146 / 10000 loss: 13.829740047454834\n",
      "MSE train 5.445656909080244 MSE test 11.934371074582971\n",
      "MAE train 1.610025306615257 MAE test 2.418639362647032\n",
      "Epoch 5147 / 10000 loss: 13.829367637634277\n",
      "MSE train 5.445531300575595 MSE test 11.934155524747863\n",
      "MAE train 1.6100067147707868 MAE test 2.418612029753905\n",
      "Epoch 5148 / 10000 loss: 13.828733444213867\n",
      "MSE train 5.445393945112886 MSE test 11.934060645202992\n",
      "MAE train 1.609982598034715 MAE test 2.4186058842703564\n",
      "Epoch 5149 / 10000 loss: 13.82827377319336\n",
      "MSE train 5.445271011710807 MSE test 11.933863021293874\n",
      "MAE train 1.6099643013966447 MAE test 2.418580851725103\n",
      "Epoch 5150 / 10000 loss: 13.827764511108398\n",
      "MSE train 5.445132250534958 MSE test 11.933750799174673\n",
      "MAE train 1.6099402488883765 MAE test 2.4185725254240373\n",
      "Epoch 5151 / 10000 loss: 13.827307224273682\n",
      "MSE train 5.4450169743597545 MSE test 11.933586485992658\n",
      "MAE train 1.6099231931360298 MAE test 2.418551727962164\n",
      "Epoch 5152 / 10000 loss: 13.826804161071777\n",
      "MSE train 5.4448790296145875 MSE test 11.933410577185594\n",
      "MAE train 1.6099007636338147 MAE test 2.4185353647072056\n",
      "Epoch 5153 / 10000 loss: 13.82635760307312\n",
      "MSE train 5.444757935123065 MSE test 11.933302585078682\n",
      "MAE train 1.6098809776962277 MAE test 2.4185217082359665\n",
      "Epoch 5154 / 10000 loss: 13.825902223587036\n",
      "MSE train 5.444618644813501 MSE test 11.933117436344839\n",
      "MAE train 1.609858411237182 MAE test 2.4185041591887417\n",
      "Epoch 5155 / 10000 loss: 13.825392723083496\n",
      "MSE train 5.444495426002101 MSE test 11.933009498480086\n",
      "MAE train 1.6098380700707446 MAE test 2.4184905156911927\n",
      "Epoch 5156 / 10000 loss: 13.824939966201782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.444355260254979 MSE test 11.932835825672825\n",
      "MAE train 1.6098149939950124 MAE test 2.4184743896495005\n",
      "Epoch 5157 / 10000 loss: 13.824420690536499\n",
      "MSE train 5.4442381469088446 MSE test 11.932721302156985\n",
      "MAE train 1.6097963230744006 MAE test 2.4184599085859775\n",
      "Epoch 5158 / 10000 loss: 13.823955535888672\n",
      "MSE train 5.444099035899784 MSE test 11.932521618332608\n",
      "MAE train 1.6097741214319023 MAE test 2.4184405020829582\n",
      "Epoch 5159 / 10000 loss: 13.823465347290039\n",
      "MSE train 5.443969128730653 MSE test 11.932417477679314\n",
      "MAE train 1.6097520046075944 MAE test 2.4184273320268392\n",
      "Epoch 5160 / 10000 loss: 13.823023557662964\n",
      "MSE train 5.443828228465653 MSE test 11.932277633721696\n",
      "MAE train 1.6097279401374753 MAE test 2.418415457870144\n",
      "Epoch 5161 / 10000 loss: 13.822475910186768\n",
      "MSE train 5.44371792572429 MSE test 11.93213502371128\n",
      "MAE train 1.6097116209039846 MAE test 2.418397425409466\n",
      "Epoch 5162 / 10000 loss: 13.821982622146606\n",
      "MSE train 5.4435801509405675 MSE test 11.931921029278419\n",
      "MAE train 1.609690033848997 MAE test 2.418376226321114\n",
      "Epoch 5163 / 10000 loss: 13.821537971496582\n",
      "MSE train 5.443443001755665 MSE test 11.931820163451736\n",
      "MAE train 1.6096660411772208 MAE test 2.418363450804854\n",
      "Epoch 5164 / 10000 loss: 13.821112871170044\n",
      "MSE train 5.4433056666216535 MSE test 11.931722976960124\n",
      "MAE train 1.6096418971076776 MAE test 2.418356975674042\n",
      "Epoch 5165 / 10000 loss: 13.820536136627197\n",
      "MSE train 5.44318167673435 MSE test 11.931518267060842\n",
      "MAE train 1.6096234738721276 MAE test 2.4183310327517225\n",
      "Epoch 5166 / 10000 loss: 13.820026874542236\n",
      "MSE train 5.4430436689780155 MSE test 11.931414827379385\n",
      "MAE train 1.6095993685107932 MAE test 2.4183238074078535\n",
      "Epoch 5167 / 10000 loss: 13.819569110870361\n",
      "MSE train 5.442924776213254 MSE test 11.931235101834313\n",
      "MAE train 1.6095817114093083 MAE test 2.41830104926496\n",
      "Epoch 5168 / 10000 loss: 13.819062948226929\n",
      "MSE train 5.442785930590565 MSE test 11.931088181918513\n",
      "MAE train 1.6095583675592817 MAE test 2.418288338014713\n",
      "Epoch 5169 / 10000 loss: 13.81861138343811\n",
      "MSE train 5.442674942385976 MSE test 11.930962112572775\n",
      "MAE train 1.60954152234755 MAE test 2.4182723907763917\n",
      "Epoch 5170 / 10000 loss: 13.818130493164062\n",
      "MSE train 5.442537623920123 MSE test 11.93074055254544\n",
      "MAE train 1.6095201954732488 MAE test 2.418250259145927\n",
      "Epoch 5171 / 10000 loss: 13.817675590515137\n",
      "MSE train 5.442397691522661 MSE test 11.930640518081333\n",
      "MAE train 1.609495534903356 MAE test 2.4182375895541877\n",
      "Epoch 5172 / 10000 loss: 13.81725788116455\n",
      "MSE train 5.442264480254196 MSE test 11.930563641336674\n",
      "MAE train 1.609471924470114 MAE test 2.4182336962698723\n",
      "Epoch 5173 / 10000 loss: 13.816669464111328\n",
      "MSE train 5.442135321109148 MSE test 11.93031956438217\n",
      "MAE train 1.609453130713128 MAE test 2.4182027734907057\n",
      "Epoch 5174 / 10000 loss: 13.816162586212158\n",
      "MSE train 5.442009960724492 MSE test 11.930281080252652\n",
      "MAE train 1.6094307182175422 MAE test 2.41820377668824\n",
      "Epoch 5175 / 10000 loss: 13.815709590911865\n",
      "MSE train 5.441881807655769 MSE test 11.929977724794158\n",
      "MAE train 1.6094135233355842 MAE test 2.418165406645495\n",
      "Epoch 5176 / 10000 loss: 13.815212726593018\n",
      "MSE train 5.44175164548605 MSE test 11.92999639558776\n",
      "MAE train 1.6093886371392652 MAE test 2.418173638061769\n",
      "Epoch 5177 / 10000 loss: 13.814804792404175\n",
      "MSE train 5.441622584704352 MSE test 11.92967876093282\n",
      "MAE train 1.6093715486911895 MAE test 2.4181334644023584\n",
      "Epoch 5178 / 10000 loss: 13.814251899719238\n",
      "MSE train 5.441487416001376 MSE test 11.929700058631788\n",
      "MAE train 1.6093453333534542 MAE test 2.418142023570942\n",
      "Epoch 5179 / 10000 loss: 13.813852071762085\n",
      "MSE train 5.441356966031148 MSE test 11.929406793192255\n",
      "MAE train 1.6093273057381179 MAE test 2.4181048926063515\n",
      "Epoch 5180 / 10000 loss: 13.81327509880066\n",
      "MSE train 5.441233323610489 MSE test 11.929414777114141\n",
      "MAE train 1.6093042785661424 MAE test 2.4181117733763693\n",
      "Epoch 5181 / 10000 loss: 13.812852144241333\n",
      "MSE train 5.441104758775315 MSE test 11.929073612456234\n",
      "MAE train 1.6092878111026983 MAE test 2.4180686111746916\n",
      "Epoch 5182 / 10000 loss: 13.812328815460205\n",
      "MSE train 5.440958729003891 MSE test 11.929099887291311\n",
      "MAE train 1.6092587463637356 MAE test 2.4180778075022826\n",
      "Epoch 5183 / 10000 loss: 13.81195068359375\n",
      "MSE train 5.440830256086244 MSE test 11.928866604504782\n",
      "MAE train 1.6092398620149237 MAE test 2.4180482276448476\n",
      "Epoch 5184 / 10000 loss: 13.811328649520874\n",
      "MSE train 5.440698929819215 MSE test 11.928802643427625\n",
      "MAE train 1.6092164785075276 MAE test 2.418045981090721\n",
      "Epoch 5185 / 10000 loss: 13.810870170593262\n",
      "MSE train 5.44056953843947 MSE test 11.928545841879007\n",
      "MAE train 1.609197900408229 MAE test 2.4180134821878876\n",
      "Epoch 5186 / 10000 loss: 13.810365200042725\n",
      "MSE train 5.440448123725573 MSE test 11.928527490501933\n",
      "MAE train 1.6091760596229527 MAE test 2.4180170307187265\n",
      "Epoch 5187 / 10000 loss: 13.809919118881226\n",
      "MSE train 5.440320941316212 MSE test 11.928191814011182\n",
      "MAE train 1.6091598273310916 MAE test 2.417974581162207\n",
      "Epoch 5188 / 10000 loss: 13.809426307678223\n",
      "MSE train 5.440175433557842 MSE test 11.928219029033995\n",
      "MAE train 1.609130892248758 MAE test 2.4179838994285565\n",
      "Epoch 5189 / 10000 loss: 13.809046983718872\n",
      "MSE train 5.4400462699177 MSE test 11.92798049790364\n",
      "MAE train 1.6091119657466628 MAE test 2.4179536710495393\n",
      "Epoch 5190 / 10000 loss: 13.808426856994629\n",
      "MSE train 5.439917282399928 MSE test 11.927926862320374\n",
      "MAE train 1.6090889770853685 MAE test 2.4179527285482494\n",
      "Epoch 5191 / 10000 loss: 13.807969570159912\n",
      "MSE train 5.43978790853464 MSE test 11.927649899854083\n",
      "MAE train 1.6090708761072552 MAE test 2.4179176930901516\n",
      "Epoch 5192 / 10000 loss: 13.807467937469482\n",
      "MSE train 5.439666676125111 MSE test 11.927651278533853\n",
      "MAE train 1.6090486395336723 MAE test 2.4179237465675723\n",
      "Epoch 5193 / 10000 loss: 13.80703592300415\n",
      "MSE train 5.439539007207445 MSE test 11.92730181805258\n",
      "MAE train 1.6090325655446198 MAE test 2.41787955974272\n",
      "Epoch 5194 / 10000 loss: 13.806531429290771\n",
      "MSE train 5.439389096840499 MSE test 11.927329449800622\n",
      "MAE train 1.6090025714332286 MAE test 2.417888922752159\n",
      "Epoch 5195 / 10000 loss: 13.806161642074585\n",
      "MSE train 5.439265230704063 MSE test 11.927122321260073\n",
      "MAE train 1.60898419996329 MAE test 2.4178626533928775\n",
      "Epoch 5196 / 10000 loss: 13.805524110794067\n",
      "MSE train 5.439126045582745 MSE test 11.927009900974491\n",
      "MAE train 1.6089599850124177 MAE test 2.417854291471178\n",
      "Epoch 5197 / 10000 loss: 13.805065631866455\n",
      "MSE train 5.439009117510826 MSE test 11.926838017195433\n",
      "MAE train 1.6089426725158054 MAE test 2.417832530018413\n",
      "Epoch 5198 / 10000 loss: 13.804561138153076\n",
      "MSE train 5.438870301681364 MSE test 11.926672223840722\n",
      "MAE train 1.6089197439126595 MAE test 2.417817436630444\n",
      "Epoch 5199 / 10000 loss: 13.80411148071289\n",
      "MSE train 5.438753974655792 MSE test 11.926557788228386\n",
      "MAE train 1.608901307706997 MAE test 2.4178029611517244\n",
      "Epoch 5200 / 10000 loss: 13.803643703460693\n",
      "MSE train 5.4386153300666065 MSE test 11.926351339668104\n",
      "MAE train 1.6088793502371428 MAE test 2.417782724968186\n",
      "Epoch 5201 / 10000 loss: 13.80315899848938\n",
      "MSE train 5.438481352369681 MSE test 11.926248760536978\n",
      "MAE train 1.6088561888030408 MAE test 2.417769739199426\n",
      "Epoch 5202 / 10000 loss: 13.802725315093994\n",
      "MSE train 5.438340985238299 MSE test 11.926128284913089\n",
      "MAE train 1.6088318308201583 MAE test 2.4177603098097973\n",
      "Epoch 5203 / 10000 loss: 13.802161455154419\n",
      "MSE train 5.438225425922429 MSE test 11.925960639791242\n",
      "MAE train 1.6088147571427878 MAE test 2.4177391013415397\n",
      "Epoch 5204 / 10000 loss: 13.801656484603882\n",
      "MSE train 5.438086485408274 MSE test 11.92578380444858\n",
      "MAE train 1.6087920611424507 MAE test 2.417722604597277\n",
      "Epoch 5205 / 10000 loss: 13.801208019256592\n",
      "MSE train 5.437965665772615 MSE test 11.925673848694776\n",
      "MAE train 1.6087723961820353 MAE test 2.4177087008653286\n",
      "Epoch 5206 / 10000 loss: 13.800748825073242\n",
      "MSE train 5.437825878207168 MSE test 11.925485181502602\n",
      "MAE train 1.6087497787134308 MAE test 2.4176906948604424\n",
      "Epoch 5207 / 10000 loss: 13.80024266242981\n",
      "MSE train 5.4377009091632695 MSE test 11.925377555024419\n",
      "MAE train 1.6087290058685375 MAE test 2.4176770891420767\n",
      "Epoch 5208 / 10000 loss: 13.799790620803833\n",
      "MSE train 5.437559843499296 MSE test 11.92520895404031\n",
      "MAE train 1.6087055930067344 MAE test 2.417661588198473\n",
      "Epoch 5209 / 10000 loss: 13.799264669418335\n",
      "MSE train 5.437444495194143 MSE test 11.925090484469596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6086874838352627 MAE test 2.417646609771682\n",
      "Epoch 5210 / 10000 loss: 13.798792362213135\n",
      "MSE train 5.437305100588076 MSE test 11.924881314560707\n",
      "MAE train 1.6086654157029614 MAE test 2.417626036847926\n",
      "Epoch 5211 / 10000 loss: 13.798311948776245\n",
      "MSE train 5.437170113847212 MSE test 11.924778458831447\n",
      "MAE train 1.6086420129640833 MAE test 2.417613006732289\n",
      "Epoch 5212 / 10000 loss: 13.797877550125122\n",
      "MSE train 5.4370296872348 MSE test 11.924662321953603\n",
      "MAE train 1.608617574600283 MAE test 2.41760412862615\n",
      "Epoch 5213 / 10000 loss: 13.797309398651123\n",
      "MSE train 5.43691185131604 MSE test 11.924487048892114\n",
      "MAE train 1.6086001235781728 MAE test 2.4175819348517815\n",
      "Epoch 5214 / 10000 loss: 13.796801567077637\n",
      "MSE train 5.436772015306169 MSE test 11.924324207325196\n",
      "MAE train 1.6085769100471843 MAE test 2.417567218014321\n",
      "Epoch 5215 / 10000 loss: 13.796350002288818\n",
      "MSE train 5.4366565697354075 MSE test 11.924206828925023\n",
      "MAE train 1.6085587939890285 MAE test 2.417552364972075\n",
      "Epoch 5216 / 10000 loss: 13.795876502990723\n",
      "MSE train 5.436517447943999 MSE test 11.923995231863831\n",
      "MAE train 1.6085368567595564 MAE test 2.417531492323678\n",
      "Epoch 5217 / 10000 loss: 13.795397520065308\n",
      "MSE train 5.436380592374853 MSE test 11.923893182609216\n",
      "MAE train 1.6085130034255453 MAE test 2.4175185696742756\n",
      "Epoch 5218 / 10000 loss: 13.794966220855713\n",
      "MSE train 5.436240887402302 MSE test 11.923786123377262\n",
      "MAE train 1.608488557336664 MAE test 2.417510830183266\n",
      "Epoch 5219 / 10000 loss: 13.794390439987183\n",
      "MSE train 5.4361191739070795 MSE test 11.923596964945794\n",
      "MAE train 1.6084704472333142 MAE test 2.4174868848362063\n",
      "Epoch 5220 / 10000 loss: 13.793879985809326\n",
      "MSE train 5.435978548878311 MSE test 11.923461636104681\n",
      "MAE train 1.6084464307916027 MAE test 2.417475633128838\n",
      "Epoch 5221 / 10000 loss: 13.793421983718872\n",
      "MSE train 5.4358667090688195 MSE test 11.923321879505421\n",
      "MAE train 1.6084297590932732 MAE test 2.4174579653341595\n",
      "Epoch 5222 / 10000 loss: 13.792926549911499\n",
      "MSE train 5.435728096207227 MSE test 11.923105866876229\n",
      "MAE train 1.6084080772068128 MAE test 2.4174365401001596\n",
      "Epoch 5223 / 10000 loss: 13.79247760772705\n",
      "MSE train 5.435588403181063 MSE test 11.923005331618146\n",
      "MAE train 1.6083835516457874 MAE test 2.4174238236068626\n",
      "Epoch 5224 / 10000 loss: 13.792051315307617\n",
      "MSE train 5.435450676197049 MSE test 11.922913872943765\n",
      "MAE train 1.608359240977553 MAE test 2.417418072654931\n",
      "Epoch 5225 / 10000 loss: 13.791464567184448\n",
      "MSE train 5.435322942073826 MSE test 11.922697327296992\n",
      "MAE train 1.608340259730338 MAE test 2.4173906527997713\n",
      "Epoch 5226 / 10000 loss: 13.790950298309326\n",
      "MSE train 5.435185883143222 MSE test 11.922614697444516\n",
      "MAE train 1.608315978565204 MAE test 2.4173860567743577\n",
      "Epoch 5227 / 10000 loss: 13.790485858917236\n",
      "MSE train 5.435057713465127 MSE test 11.92239771726518\n",
      "MAE train 1.608296939605688 MAE test 2.4173585857439197\n",
      "Epoch 5228 / 10000 loss: 13.789971828460693\n",
      "MSE train 5.43492162052529 MSE test 11.922322664938308\n",
      "MAE train 1.6082727459564214 MAE test 2.4173549580620755\n",
      "Epoch 5229 / 10000 loss: 13.789507150650024\n",
      "MSE train 5.434791966658484 MSE test 11.92209473720731\n",
      "MAE train 1.6082536297901957 MAE test 2.4173261238862054\n",
      "Epoch 5230 / 10000 loss: 13.788993120193481\n",
      "MSE train 5.434659824407471 MSE test 11.922039527555471\n",
      "MAE train 1.608230016804027 MAE test 2.4173250258408023\n",
      "Epoch 5231 / 10000 loss: 13.788530111312866\n",
      "MSE train 5.434528561791693 MSE test 11.921772327816413\n",
      "MAE train 1.6082113845113317 MAE test 2.4172912323951783\n",
      "Epoch 5232 / 10000 loss: 13.78801941871643\n",
      "MSE train 5.434405679688117 MSE test 11.921767195499038\n",
      "MAE train 1.608189030939169 MAE test 2.4172964746805854\n",
      "Epoch 5233 / 10000 loss: 13.78757381439209\n",
      "MSE train 5.434276038631936 MSE test 11.921418399428275\n",
      "MAE train 1.6081726113718164 MAE test 2.4172524002480174\n",
      "Epoch 5234 / 10000 loss: 13.787068128585815\n",
      "MSE train 5.43412340335592 MSE test 11.921445993677645\n",
      "MAE train 1.608142104814869 MAE test 2.4172617627654573\n",
      "Epoch 5235 / 10000 loss: 13.786691427230835\n",
      "MSE train 5.433996774342216 MSE test 11.921238989315912\n",
      "MAE train 1.6081232268880856 MAE test 2.417235525591842\n",
      "Epoch 5236 / 10000 loss: 13.786044597625732\n",
      "MSE train 5.433854723613591 MSE test 11.92112622112785\n",
      "MAE train 1.6080984712137414 MAE test 2.4172271290028897\n",
      "Epoch 5237 / 10000 loss: 13.785575866699219\n",
      "MSE train 5.433734650854963 MSE test 11.920954345488749\n",
      "MAE train 1.608080579006349 MAE test 2.4172053822216193\n",
      "Epoch 5238 / 10000 loss: 13.78506088256836\n",
      "MSE train 5.433592568779693 MSE test 11.920788398425032\n",
      "MAE train 1.6080570288573843 MAE test 2.417190291288594\n",
      "Epoch 5239 / 10000 loss: 13.784600973129272\n",
      "MSE train 5.433472701187913 MSE test 11.920673729017043\n",
      "MAE train 1.608037954513669 MAE test 2.417175803758242\n",
      "Epoch 5240 / 10000 loss: 13.7841215133667\n",
      "MSE train 5.433330379108243 MSE test 11.920466699703244\n",
      "MAE train 1.608015299298234 MAE test 2.4171555254546817\n",
      "Epoch 5241 / 10000 loss: 13.783624410629272\n",
      "MSE train 5.433192324012544 MSE test 11.920364128280896\n",
      "MAE train 1.6079913791725728 MAE test 2.417142556085355\n",
      "Epoch 5242 / 10000 loss: 13.783177375793457\n",
      "MSE train 5.433047732305566 MSE test 11.9202438340923\n",
      "MAE train 1.607966215217607 MAE test 2.4171331730205257\n",
      "Epoch 5243 / 10000 loss: 13.782599449157715\n",
      "MSE train 5.43292729704333 MSE test 11.92007508376199\n",
      "MAE train 1.6079482398041054 MAE test 2.4171118249515393\n",
      "Epoch 5244 / 10000 loss: 13.782079219818115\n",
      "MSE train 5.432783402798322 MSE test 11.91989957856567\n",
      "MAE train 1.6079245614172812 MAE test 2.4170955305535116\n",
      "Epoch 5245 / 10000 loss: 13.781614303588867\n",
      "MSE train 5.432658000892596 MSE test 11.919788720092093\n",
      "MAE train 1.607904099871168 MAE test 2.4170815226395868\n",
      "Epoch 5246 / 10000 loss: 13.781135559082031\n",
      "MSE train 5.432512597624616 MSE test 11.919596835926983\n",
      "MAE train 1.6078804852564477 MAE test 2.4170631590083547\n",
      "Epoch 5247 / 10000 loss: 13.780613899230957\n",
      "MSE train 5.432379707475233 MSE test 11.919490049609223\n",
      "MAE train 1.607858100022431 MAE test 2.417049649970751\n",
      "Epoch 5248 / 10000 loss: 13.78014326095581\n",
      "MSE train 5.432231758263735 MSE test 11.919328892238557\n",
      "MAE train 1.607833156176121 MAE test 2.4170351385432514\n",
      "Epoch 5249 / 10000 loss: 13.77958869934082\n",
      "MSE train 5.432111425895454 MSE test 11.919204818090124\n",
      "MAE train 1.6078143633602802 MAE test 2.4170194708209203\n",
      "Epoch 5250 / 10000 loss: 13.779084920883179\n",
      "MSE train 5.431964272923991 MSE test 11.918987310475208\n",
      "MAE train 1.6077909602513034 MAE test 2.4169978837160793\n",
      "Epoch 5251 / 10000 loss: 13.778590202331543\n",
      "MSE train 5.431817089823802 MSE test 11.918885682184463\n",
      "MAE train 1.6077650182796093 MAE test 2.4169850364291974\n",
      "Epoch 5252 / 10000 loss: 13.778133869171143\n",
      "MSE train 5.431669788618741 MSE test 11.918791099607178\n",
      "MAE train 1.6077388864272604 MAE test 2.4169789186199973\n",
      "Epoch 5253 / 10000 loss: 13.777519464492798\n",
      "MSE train 5.4315326779189235 MSE test 11.918578748917882\n",
      "MAE train 1.6077180078827136 MAE test 2.4169520474001236\n",
      "Epoch 5254 / 10000 loss: 13.776971817016602\n",
      "MSE train 5.431383215275187 MSE test 11.918487694822543\n",
      "MAE train 1.607691404010545 MAE test 2.4169464321289404\n",
      "Epoch 5255 / 10000 loss: 13.776469707489014\n",
      "MSE train 5.4312447249137135 MSE test 11.91828546403134\n",
      "MAE train 1.60767008400924 MAE test 2.4169208556072075\n",
      "Epoch 5256 / 10000 loss: 13.77591323852539\n",
      "MSE train 5.431090637557072 MSE test 11.918182798435462\n",
      "MAE train 1.6076427550845553 MAE test 2.4169137694660834\n",
      "Epoch 5257 / 10000 loss: 13.775400161743164\n",
      "MSE train 5.430953093900669 MSE test 11.918002886148738\n",
      "MAE train 1.6076213574832166 MAE test 2.4168910399090846\n",
      "Epoch 5258 / 10000 loss: 13.774834394454956\n",
      "MSE train 5.4307934697598546 MSE test 11.917856688108792\n",
      "MAE train 1.6075937793948365 MAE test 2.4168784942438784\n",
      "Epoch 5259 / 10000 loss: 13.774312019348145\n",
      "MSE train 5.430658698417311 MSE test 11.917729673202052\n",
      "MAE train 1.6075721446361428 MAE test 2.4168624736435764\n",
      "Epoch 5260 / 10000 loss: 13.773751020431519\n",
      "MSE train 5.430494270242149 MSE test 11.917507487188736\n",
      "MAE train 1.6075452541763235 MAE test 2.4168403460473624\n",
      "Epoch 5261 / 10000 loss: 13.773204803466797\n",
      "MSE train 5.430322806262516 MSE test 11.91740734985173\n",
      "MAE train 1.6075141135941275 MAE test 2.4168277077277596\n",
      "Epoch 5262 / 10000 loss: 13.772681951522827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.430153483313148 MSE test 11.917329771964067\n",
      "MAE train 1.6074830242692446 MAE test 2.416823794566292\n",
      "Epoch 5263 / 10000 loss: 13.771970987319946\n",
      "MSE train 5.429982512574004 MSE test 11.91708545957756\n",
      "MAE train 1.6074554939099912 MAE test 2.4167929095318694\n",
      "Epoch 5264 / 10000 loss: 13.77131986618042\n",
      "MSE train 5.429809433202008 MSE test 11.917046216860845\n",
      "MAE train 1.6074231201260487 MAE test 2.4167938931615387\n",
      "Epoch 5265 / 10000 loss: 13.77070140838623\n",
      "MSE train 5.429626928718326 MSE test 11.916742189521784\n",
      "MAE train 1.607394568400221 MAE test 2.4167555045736218\n",
      "Epoch 5266 / 10000 loss: 13.770013809204102\n",
      "MSE train 5.429436298858864 MSE test 11.916759934334175\n",
      "MAE train 1.607357160287275 MAE test 2.4167636951415363\n",
      "Epoch 5267 / 10000 loss: 13.769388437271118\n",
      "MSE train 5.429242059919453 MSE test 11.916443383635098\n",
      "MAE train 1.6073266288727248 MAE test 2.4167236999838675\n",
      "Epoch 5268 / 10000 loss: 13.768590211868286\n",
      "MSE train 5.429040387609169 MSE test 11.916462442713275\n",
      "MAE train 1.6072868568332948 MAE test 2.416732061767806\n",
      "Epoch 5269 / 10000 loss: 13.767928123474121\n",
      "MSE train 5.428843777328771 MSE test 11.916165017745502\n",
      "MAE train 1.6072553764972943 MAE test 2.4166944497011924\n",
      "Epoch 5270 / 10000 loss: 13.767083883285522\n",
      "MSE train 5.428657142456678 MSE test 11.91617295397111\n",
      "MAE train 1.6072196901070641 MAE test 2.4167014088399466\n",
      "Epoch 5271 / 10000 loss: 13.766400337219238\n",
      "MSE train 5.4284733614597975 MSE test 11.915834645346926\n",
      "MAE train 1.607192321681689 MAE test 2.4166586758672812\n",
      "Epoch 5272 / 10000 loss: 13.765629529953003\n",
      "MSE train 5.428282257317935 MSE test 11.915857301421763\n",
      "MAE train 1.6071546656060998 MAE test 2.4166674697186887\n",
      "Epoch 5273 / 10000 loss: 13.765034198760986\n",
      "MSE train 5.428113336048504 MSE test 11.91561068982915\n",
      "MAE train 1.6071282261310975 MAE test 2.416636238869658\n",
      "Epoch 5274 / 10000 loss: 13.764241218566895\n",
      "MSE train 5.427954393758061 MSE test 11.915562049298458\n",
      "MAE train 1.6070996425754047 MAE test 2.416636036000034\n",
      "Epoch 5275 / 10000 loss: 13.76364254951477\n",
      "MSE train 5.427798918533997 MSE test 11.915266590922503\n",
      "MAE train 1.607077133110044 MAE test 2.416598687521857\n",
      "Epoch 5276 / 10000 loss: 13.763028621673584\n",
      "MSE train 5.427651623739668 MSE test 11.915275911701915\n",
      "MAE train 1.6070497479110377 MAE test 2.416605818823362\n",
      "Epoch 5277 / 10000 loss: 13.762518644332886\n",
      "MSE train 5.427505015500181 MSE test 11.914937384977234\n",
      "MAE train 1.607030027715646 MAE test 2.416563045600689\n",
      "Epoch 5278 / 10000 loss: 13.761913776397705\n",
      "MSE train 5.4273452876235915 MSE test 11.91496009753312\n",
      "MAE train 1.6069987792557412 MAE test 2.4165718485053316\n",
      "Epoch 5279 / 10000 loss: 13.761472225189209\n",
      "MSE train 5.42720248396629 MSE test 11.914713929284904\n",
      "MAE train 1.6069775950540117 MAE test 2.4165406628191617\n",
      "Epoch 5280 / 10000 loss: 13.760807037353516\n",
      "MSE train 5.427064266402561 MSE test 11.914664372964008\n",
      "MAE train 1.6069530831274006 MAE test 2.416540318984954\n",
      "Epoch 5281 / 10000 loss: 13.760310173034668\n",
      "MSE train 5.4269254868354935 MSE test 11.91437084201581\n",
      "MAE train 1.6069337530038845 MAE test 2.4165032098640635\n",
      "Epoch 5282 / 10000 loss: 13.75977635383606\n",
      "MSE train 5.426792027908367 MSE test 11.914379007775052\n",
      "MAE train 1.6069090133104647 MAE test 2.4165101728440006\n",
      "Epoch 5283 / 10000 loss: 13.759327173233032\n",
      "MSE train 5.426656095080729 MSE test 11.914038468385371\n",
      "MAE train 1.6068913007330505 MAE test 2.4164671180775787\n",
      "Epoch 5284 / 10000 loss: 13.758773803710938\n",
      "MSE train 5.426503950780952 MSE test 11.914061694635075\n",
      "MAE train 1.6068613618868504 MAE test 2.4164759600617876\n",
      "Epoch 5285 / 10000 loss: 13.758370637893677\n",
      "MSE train 5.426368759442477 MSE test 11.91382188307301\n",
      "MAE train 1.6068414785738032 MAE test 2.416445547410655\n",
      "Epoch 5286 / 10000 loss: 13.757732391357422\n",
      "MSE train 5.426233784693011 MSE test 11.913762569964224\n",
      "MAE train 1.6068175642781273 MAE test 2.4164439510593505\n",
      "Epoch 5287 / 10000 loss: 13.757256984710693\n",
      "MSE train 5.426099366603672 MSE test 11.913488392233843\n",
      "MAE train 1.6067985426817168 MAE test 2.4164092367478562\n",
      "Epoch 5288 / 10000 loss: 13.756738901138306\n",
      "MSE train 5.425974229622648 MSE test 11.913482431251378\n",
      "MAE train 1.6067758851518024 MAE test 2.4164144028354366\n",
      "Epoch 5289 / 10000 loss: 13.756290197372437\n",
      "MSE train 5.4258426045903905 MSE test 11.913131351217388\n",
      "MAE train 1.6067591622057067 MAE test 2.4163699973363983\n",
      "Epoch 5290 / 10000 loss: 13.755777597427368\n",
      "MSE train 5.425689081949242 MSE test 11.913156144263278\n",
      "MAE train 1.6067286342073404 MAE test 2.4163790143613832\n",
      "Epoch 5291 / 10000 loss: 13.755398035049438\n",
      "MSE train 5.425561613731853 MSE test 11.912946419832775\n",
      "MAE train 1.6067097097546124 MAE test 2.416352410067634\n",
      "Epoch 5292 / 10000 loss: 13.75475025177002\n",
      "MSE train 5.425419458164135 MSE test 11.912832086888232\n",
      "MAE train 1.606685007559307 MAE test 2.416343789869728\n",
      "Epoch 5293 / 10000 loss: 13.754281997680664\n",
      "MSE train 5.4252992683081285 MSE test 11.912656573637298\n",
      "MAE train 1.606667186696432 MAE test 2.4163215491725185\n",
      "Epoch 5294 / 10000 loss: 13.753769636154175\n",
      "MSE train 5.425157778003645 MSE test 11.912491138676021\n",
      "MAE train 1.6066437374421 MAE test 2.4163064995174417\n",
      "Epoch 5295 / 10000 loss: 13.753312349319458\n",
      "MSE train 5.425040077176994 MSE test 11.91237254225008\n",
      "MAE train 1.6066252782307158 MAE test 2.4162914887181532\n",
      "Epoch 5296 / 10000 loss: 13.75283670425415\n",
      "MSE train 5.42489958311921 MSE test 11.912159387084643\n",
      "MAE train 1.6066030977186037 MAE test 2.416270415902307\n",
      "Epoch 5297 / 10000 loss: 13.752351760864258\n",
      "MSE train 5.424761732574581 MSE test 11.912055197677685\n",
      "MAE train 1.6065791791704076 MAE test 2.416257205780296\n",
      "Epoch 5298 / 10000 loss: 13.751915693283081\n",
      "MSE train 5.42462063947494 MSE test 11.911943100418492\n",
      "MAE train 1.6065545735043745 MAE test 2.416248814176609\n",
      "Epoch 5299 / 10000 loss: 13.751339673995972\n",
      "MSE train 5.424498870103686 MSE test 11.91175565940336\n",
      "MAE train 1.6065364920707461 MAE test 2.4162250708873882\n",
      "Epoch 5300 / 10000 loss: 13.750827312469482\n",
      "MSE train 5.424357635894989 MSE test 11.9116101946229\n",
      "MAE train 1.6065125587196296 MAE test 2.4162125076589174\n",
      "Epoch 5301 / 10000 loss: 13.750369548797607\n",
      "MSE train 5.424245267143466 MSE test 11.911475168102145\n",
      "MAE train 1.606495704119095 MAE test 2.416195411246579\n",
      "Epoch 5302 / 10000 loss: 13.749879121780396\n",
      "MSE train 5.424106266527818 MSE test 11.911251860857035\n",
      "MAE train 1.6064740131854633 MAE test 2.4161730730984616\n",
      "Epoch 5303 / 10000 loss: 13.749425172805786\n",
      "MSE train 5.423964984489628 MSE test 11.911149082613168\n",
      "MAE train 1.6064491756618573 MAE test 2.4161600170186235\n",
      "Epoch 5304 / 10000 loss: 13.74900221824646\n",
      "MSE train 5.423829462210144 MSE test 11.91106524189913\n",
      "MAE train 1.6064251679249748 MAE test 2.416155252751354\n",
      "Epoch 5305 / 10000 loss: 13.748411893844604\n",
      "MSE train 5.4236993228198624 MSE test 11.910825691355372\n",
      "MAE train 1.6064060884563969 MAE test 2.4161248737395034\n",
      "Epoch 5306 / 10000 loss: 13.747901201248169\n",
      "MSE train 5.423570096199839 MSE test 11.910773827805935\n",
      "MAE train 1.6063830213950485 MAE test 2.4161241883183857\n",
      "Epoch 5307 / 10000 loss: 13.747442245483398\n",
      "MSE train 5.423439915520358 MSE test 11.910487597720751\n",
      "MAE train 1.606364947474897 MAE test 2.41608793636055\n",
      "Epoch 5308 / 10000 loss: 13.746938705444336\n",
      "MSE train 5.423315956372547 MSE test 11.910491695538713\n",
      "MAE train 1.6063419671748096 MAE test 2.4160943531234698\n",
      "Epoch 5309 / 10000 loss: 13.746509552001953\n",
      "MSE train 5.423187004273274 MSE test 11.910144028521382\n",
      "MAE train 1.6063255169486736 MAE test 2.416050365963113\n",
      "Epoch 5310 / 10000 loss: 13.745991468429565\n",
      "MSE train 5.423037718442931 MSE test 11.910167636816192\n",
      "MAE train 1.6062957206287611 MAE test 2.416059238934719\n",
      "Epoch 5311 / 10000 loss: 13.745615243911743\n",
      "MSE train 5.422910539427134 MSE test 11.90994682178627\n",
      "MAE train 1.6062768376860521 MAE test 2.4160312135094832\n",
      "Epoch 5312 / 10000 loss: 13.744982242584229\n",
      "MSE train 5.422773230472719 MSE test 11.909853136206705\n",
      "MAE train 1.6062525729469674 MAE test 2.416025227513276\n",
      "Epoch 5313 / 10000 loss: 13.744519710540771\n",
      "MSE train 5.422647514212932 MSE test 11.909643364868003\n",
      "MAE train 1.6062338233869278 MAE test 2.4159986452362023\n",
      "Epoch 5314 / 10000 loss: 13.744009733200073\n",
      "MSE train 5.4225096112732665 MSE test 11.909545063274717\n",
      "MAE train 1.6062095557863523 MAE test 2.4159920860812347\n",
      "Epoch 5315 / 10000 loss: 13.74354863166809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.422386651890083 MSE test 11.90934999489427\n",
      "MAE train 1.6061911774828532 MAE test 2.4159673823502157\n",
      "Epoch 5316 / 10000 loss: 13.743038654327393\n",
      "MSE train 5.422247145506615 MSE test 11.909226488881696\n",
      "MAE train 1.606167042823219 MAE test 2.4159576489464665\n",
      "Epoch 5317 / 10000 loss: 13.742581129074097\n",
      "MSE train 5.422133336509705 MSE test 11.909069796032538\n",
      "MAE train 1.6061501597036363 MAE test 2.4159378299610466\n",
      "Epoch 5318 / 10000 loss: 13.742080450057983\n",
      "MSE train 5.421995459742076 MSE test 11.908871623948498\n",
      "MAE train 1.606128094591354 MAE test 2.4159186940075057\n",
      "Epoch 5319 / 10000 loss: 13.741634130477905\n",
      "MSE train 5.421864617163098 MSE test 11.908765971177482\n",
      "MAE train 1.60610578375745 MAE test 2.4159053369929193\n",
      "Epoch 5320 / 10000 loss: 13.74119257926941\n",
      "MSE train 5.4217234226935505 MSE test 11.908620449230387\n",
      "MAE train 1.6060816443858488 MAE test 2.4158927918247226\n",
      "Epoch 5321 / 10000 loss: 13.740642547607422\n",
      "MSE train 5.421612404257885 MSE test 11.908478105678018\n",
      "MAE train 1.606065111106824 MAE test 2.415874807491323\n",
      "Epoch 5322 / 10000 loss: 13.740149736404419\n",
      "MSE train 5.421474073027575 MSE test 11.908258225435816\n",
      "MAE train 1.606043344136088 MAE test 2.4158529396220545\n",
      "Epoch 5323 / 10000 loss: 13.739701509475708\n",
      "MSE train 5.421335376780622 MSE test 11.90815421690697\n",
      "MAE train 1.6060190068715947 MAE test 2.415839785874141\n",
      "Epoch 5324 / 10000 loss: 13.739275217056274\n",
      "MSE train 5.421198562141694 MSE test 11.908058769968536\n",
      "MAE train 1.605994802158591 MAE test 2.415833600213568\n",
      "Epoch 5325 / 10000 loss: 13.738692283630371\n",
      "MSE train 5.421071811079366 MSE test 11.907840216134437\n",
      "MAE train 1.605975952880718 MAE test 2.4158059391356916\n",
      "Epoch 5326 / 10000 loss: 13.738180875778198\n",
      "MSE train 5.420935700040736 MSE test 11.907752453610463\n",
      "MAE train 1.6059517906149263 MAE test 2.4158007634280914\n",
      "Epoch 5327 / 10000 loss: 13.7377188205719\n",
      "MSE train 5.420809089540462 MSE test 11.907535680810325\n",
      "MAE train 1.6059329454740325 MAE test 2.4157733501977847\n",
      "Epoch 5328 / 10000 loss: 13.737207651138306\n",
      "MSE train 5.420673499808407 MSE test 11.907451661197381\n",
      "MAE train 1.605908830883731 MAE test 2.415768665702829\n",
      "Epoch 5329 / 10000 loss: 13.736746311187744\n",
      "MSE train 5.420546281092716 MSE test 11.907231190070988\n",
      "MAE train 1.6058899366679762 MAE test 2.4157408096822235\n",
      "Epoch 5330 / 10000 loss: 13.736233472824097\n",
      "MSE train 5.420411983303387 MSE test 11.907155096271767\n",
      "MAE train 1.6058659604637395 MAE test 2.41573712873995\n",
      "Epoch 5331 / 10000 loss: 13.735773086547852\n",
      "MSE train 5.420283336077102 MSE test 11.906920099700272\n",
      "MAE train 1.6058470424747855 MAE test 2.4157074505414773\n",
      "Epoch 5332 / 10000 loss: 13.735261678695679\n",
      "MSE train 5.420154420235038 MSE test 11.90686817666506\n",
      "MAE train 1.6058239283539057 MAE test 2.415706858349058\n",
      "Epoch 5333 / 10000 loss: 13.734801769256592\n",
      "MSE train 5.420025030413883 MSE test 11.906584078413918\n",
      "MAE train 1.6058058831808897 MAE test 2.4156709705959574\n",
      "Epoch 5334 / 10000 loss: 13.73429799079895\n",
      "MSE train 5.419901920356795 MSE test 11.90658657108062\n",
      "MAE train 1.6057830479780675 MAE test 2.4156773024050517\n",
      "Epoch 5335 / 10000 loss: 13.733866930007935\n",
      "MSE train 5.419773548326971 MSE test 11.906236771133852\n",
      "MAE train 1.6057666786252918 MAE test 2.4156331341277446\n",
      "Epoch 5336 / 10000 loss: 13.733349561691284\n",
      "MSE train 5.419623914725947 MSE test 11.906259858277402\n",
      "MAE train 1.6057367145942336 MAE test 2.4156420700023356\n",
      "Epoch 5337 / 10000 loss: 13.732973098754883\n",
      "MSE train 5.4194979332715905 MSE test 11.906042960823429\n",
      "MAE train 1.6057179386217058 MAE test 2.415614653867617\n",
      "Epoch 5338 / 10000 loss: 13.732333898544312\n",
      "MSE train 5.419359468128993 MSE test 11.905939349949103\n",
      "MAE train 1.6056935493280111 MAE test 2.4156075182548853\n",
      "Epoch 5339 / 10000 loss: 13.731870651245117\n",
      "MSE train 5.419236958815153 MSE test 11.905744288240367\n",
      "MAE train 1.6056752167156945 MAE test 2.415582925356992\n",
      "Epoch 5340 / 10000 loss: 13.731357336044312\n",
      "MSE train 5.4190971045013265 MSE test 11.90561484437794\n",
      "MAE train 1.6056510174756375 MAE test 2.415572535036326\n",
      "Epoch 5341 / 10000 loss: 13.730895519256592\n",
      "MSE train 5.418984182598528 MSE test 11.905462219071994\n",
      "MAE train 1.6056342304912123 MAE test 2.415553340898255\n",
      "Epoch 5342 / 10000 loss: 13.730393886566162\n",
      "MSE train 5.418846209615967 MSE test 11.905255094692034\n",
      "MAE train 1.6056122408565134 MAE test 2.415533174935552\n",
      "Epoch 5343 / 10000 loss: 13.729943990707397\n",
      "MSE train 5.418711690450757 MSE test 11.905149978060395\n",
      "MAE train 1.6055889440664914 MAE test 2.415520000929407\n",
      "Epoch 5344 / 10000 loss: 13.729505777359009\n",
      "MSE train 5.418570929032252 MSE test 11.905023754212126\n",
      "MAE train 1.6055643997294033 MAE test 2.4155099969701044\n",
      "Epoch 5345 / 10000 loss: 13.728936433792114\n",
      "MSE train 5.418455459611731 MSE test 11.904855718390161\n",
      "MAE train 1.6055472523473553 MAE test 2.4154888628053066\n",
      "Epoch 5346 / 10000 loss: 13.72842788696289\n",
      "MSE train 5.418316450516557 MSE test 11.904669707902574\n",
      "MAE train 1.6055244867471559 MAE test 2.4154713453615275\n",
      "Epoch 5347 / 10000 loss: 13.727975845336914\n",
      "MSE train 5.418192810155472 MSE test 11.90455828479493\n",
      "MAE train 1.6055040664081184 MAE test 2.415457389428979\n",
      "Epoch 5348 / 10000 loss: 13.727516412734985\n",
      "MSE train 5.418052387887605 MSE test 11.904376644797773\n",
      "MAE train 1.6054808300052639 MAE test 2.415440406969067\n",
      "Epoch 5349 / 10000 loss: 13.726994037628174\n",
      "MSE train 5.417932779444202 MSE test 11.904260357995524\n",
      "MAE train 1.6054614936394886 MAE test 2.4154258342994486\n",
      "Epoch 5350 / 10000 loss: 13.726526737213135\n",
      "MSE train 5.417792880084121 MSE test 11.904063308520485\n",
      "MAE train 1.605438756431815 MAE test 2.415406905968545\n",
      "Epoch 5351 / 10000 loss: 13.726022720336914\n",
      "MSE train 5.417666039570463 MSE test 11.903953101068987\n",
      "MAE train 1.6054174762184683 MAE test 2.41539309629286\n",
      "Epoch 5352 / 10000 loss: 13.725569009780884\n",
      "MSE train 5.4175250609925865 MSE test 11.903789718823914\n",
      "MAE train 1.605393663764827 MAE test 2.415378393278584\n",
      "Epoch 5353 / 10000 loss: 13.725032567977905\n",
      "MSE train 5.417412878279445 MSE test 11.903661022532647\n",
      "MAE train 1.6053764667066828 MAE test 2.4153622509559454\n",
      "Epoch 5354 / 10000 loss: 13.724549293518066\n",
      "MSE train 5.41727452024203 MSE test 11.903439117227173\n",
      "MAE train 1.6053545935588842 MAE test 2.4153401818489306\n",
      "Epoch 5355 / 10000 loss: 13.724082708358765\n",
      "MSE train 5.417136658263118 MSE test 11.903334190162164\n",
      "MAE train 1.6053303861885029 MAE test 2.4153270260873745\n",
      "Epoch 5356 / 10000 loss: 13.723655223846436\n",
      "MSE train 5.417000546461813 MSE test 11.903238002239828\n",
      "MAE train 1.6053062618159855 MAE test 2.4153208068826624\n",
      "Epoch 5357 / 10000 loss: 13.723071813583374\n",
      "MSE train 5.416874795005494 MSE test 11.903019174434036\n",
      "MAE train 1.605287556351409 MAE test 2.415293171990105\n",
      "Epoch 5358 / 10000 loss: 13.72256088256836\n",
      "MSE train 5.4167398755851375 MSE test 11.90293137501805\n",
      "MAE train 1.605263547793621 MAE test 2.415288045690073\n",
      "Epoch 5359 / 10000 loss: 13.722099781036377\n",
      "MSE train 5.4166144818614175 MSE test 11.902714400311433\n",
      "MAE train 1.605244883869402 MAE test 2.4152606570028823\n",
      "Epoch 5360 / 10000 loss: 13.721591472625732\n",
      "MSE train 5.416480370799903 MSE test 11.902631052568227\n",
      "MAE train 1.6052209663055905 MAE test 2.41525607603929\n",
      "Epoch 5361 / 10000 loss: 13.72113299369812\n",
      "MSE train 5.416354611389412 MSE test 11.902409760897566\n",
      "MAE train 1.6052023202912231 MAE test 2.4152281320320634\n",
      "Epoch 5362 / 10000 loss: 13.72062611579895\n",
      "MSE train 5.416222494130928 MSE test 11.902336297685633\n",
      "MAE train 1.6051786618868333 MAE test 2.4152247995826133\n",
      "Epoch 5363 / 10000 loss: 13.720168828964233\n",
      "MSE train 5.416095353521209 MSE test 11.902097472747604\n",
      "MAE train 1.6051600423141383 MAE test 2.4151946415749896\n",
      "Epoch 5364 / 10000 loss: 13.719663858413696\n",
      "MSE train 5.415970119635351 MSE test 11.90205283381123\n",
      "MAE train 1.6051375221386692 MAE test 2.415194966174767\n",
      "Epoch 5365 / 10000 loss: 13.719212055206299\n",
      "MSE train 5.415843315778337 MSE test 11.901756418998056\n",
      "MAE train 1.6051202166745528 MAE test 2.415157491705771\n",
      "Epoch 5366 / 10000 loss: 13.718717575073242\n",
      "MSE train 5.415718094929576 MSE test 11.901767925726233\n",
      "MAE train 1.6050964851108798 MAE test 2.4151649380358844\n",
      "Epoch 5367 / 10000 loss: 13.718306064605713\n",
      "MSE train 5.415591311047703 MSE test 11.90143474068113\n",
      "MAE train 1.6050800072213234 MAE test 2.4151227925122227\n",
      "Epoch 5368 / 10000 loss: 13.7177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.415450703053569 MSE test 11.901456555352064\n",
      "MAE train 1.605052135746261 MAE test 2.4151315238149054\n",
      "Epoch 5369 / 10000 loss: 13.717391014099121\n",
      "MSE train 5.415322004113519 MSE test 11.9011995401004\n",
      "MAE train 1.6050334498770065 MAE test 2.415098958508535\n",
      "Epoch 5370 / 10000 loss: 13.716789484024048\n",
      "MSE train 5.415200954952618 MSE test 11.901166413317958\n",
      "MAE train 1.605011687848471 MAE test 2.4151006986159476\n",
      "Epoch 5371 / 10000 loss: 13.716343879699707\n",
      "MSE train 5.415074722911644 MSE test 11.900843964823558\n",
      "MAE train 1.6049951201961559 MAE test 2.4150598944563955\n",
      "Epoch 5372 / 10000 loss: 13.715855121612549\n",
      "MSE train 5.414938584402961 MSE test 11.90086435745827\n",
      "MAE train 1.6049684125108696 MAE test 2.415068423059059\n",
      "Epoch 5373 / 10000 loss: 13.715466499328613\n",
      "MSE train 5.4148097895462906 MSE test 11.900584016256126\n",
      "MAE train 1.6049502269495026 MAE test 2.415032894341723\n",
      "Epoch 5374 / 10000 loss: 13.71488332748413\n",
      "MSE train 5.4146913192857165 MSE test 11.900577885300859\n",
      "MAE train 1.6049285440326098 MAE test 2.4150380627943\n",
      "Epoch 5375 / 10000 loss: 13.714454650878906\n",
      "MSE train 5.414565274462827 MSE test 11.900228540607488\n",
      "MAE train 1.604912553514343 MAE test 2.4149938299707987\n",
      "Epoch 5376 / 10000 loss: 13.713958978652954\n",
      "MSE train 5.414418601240362 MSE test 11.900252675887801\n",
      "MAE train 1.6048831235364467 MAE test 2.4150028089519844\n",
      "Epoch 5377 / 10000 loss: 13.713593244552612\n",
      "MSE train 5.414295674277161 MSE test 11.900038284586321\n",
      "MAE train 1.6048648999407913 MAE test 2.4149756086632346\n",
      "Epoch 5378 / 10000 loss: 13.712966680526733\n",
      "MSE train 5.41416002098377 MSE test 11.89993444260913\n",
      "MAE train 1.6048410218076985 MAE test 2.414968337698498\n",
      "Epoch 5379 / 10000 loss: 13.712514400482178\n",
      "MSE train 5.414041168028685 MSE test 11.89974398031763\n",
      "MAE train 1.604823354771635 MAE test 2.4149442082097647\n",
      "Epoch 5380 / 10000 loss: 13.712014436721802\n",
      "MSE train 5.4139042999506195 MSE test 11.899610770742655\n",
      "MAE train 1.6047997944765182 MAE test 2.4149332125908116\n",
      "Epoch 5381 / 10000 loss: 13.711566686630249\n",
      "MSE train 5.413795308106983 MSE test 11.899466424443402\n",
      "MAE train 1.6047836786417822 MAE test 2.4149149529135987\n",
      "Epoch 5382 / 10000 loss: 13.71108102798462\n",
      "MSE train 5.413660531631839 MSE test 11.899252739093463\n",
      "MAE train 1.6047624214325056 MAE test 2.4148938195306093\n",
      "Epoch 5383 / 10000 loss: 13.710644721984863\n",
      "MSE train 5.413525814473978 MSE test 11.899150581099365\n",
      "MAE train 1.6047388636473885 MAE test 2.4148808786106675\n",
      "Epoch 5384 / 10000 loss: 13.710225820541382\n",
      "MSE train 5.413390257937955 MSE test 11.899047340526714\n",
      "MAE train 1.6047149645914114 MAE test 2.414873638519021\n",
      "Epoch 5385 / 10000 loss: 13.709657192230225\n",
      "MSE train 5.413269573817682 MSE test 11.898847649921146\n",
      "MAE train 1.6046970253267707 MAE test 2.414848313234782\n",
      "Epoch 5386 / 10000 loss: 13.709155797958374\n",
      "MSE train 5.413133030275155 MSE test 11.898729349417968\n",
      "MAE train 1.6046732278326645 MAE test 2.4148392042854208\n",
      "Epoch 5387 / 10000 loss: 13.708705425262451\n",
      "MSE train 5.413020403829537 MSE test 11.898565449728219\n",
      "MAE train 1.604656601136689 MAE test 2.414818459813353\n",
      "Epoch 5388 / 10000 loss: 13.70821213722229\n",
      "MSE train 5.41288485360771 MSE test 11.898381913938222\n",
      "MAE train 1.6046345001839093 MAE test 2.414801114803924\n",
      "Epoch 5389 / 10000 loss: 13.707772731781006\n",
      "MSE train 5.412763716533094 MSE test 11.898273192231047\n",
      "MAE train 1.6046145415804187 MAE test 2.4147873522503684\n",
      "Epoch 5390 / 10000 loss: 13.707328081130981\n",
      "MSE train 5.412626269170943 MSE test 11.898094802834596\n",
      "MAE train 1.6045918228528273 MAE test 2.4147706223689265\n",
      "Epoch 5391 / 10000 loss: 13.706817150115967\n",
      "MSE train 5.412509850742116 MSE test 11.89798001819248\n",
      "MAE train 1.60457314954894 MAE test 2.414756096447174\n",
      "Epoch 5392 / 10000 loss: 13.706361770629883\n",
      "MSE train 5.412372802627531 MSE test 11.897782786304647\n",
      "MAE train 1.6045509676106682 MAE test 2.4147369908012553\n",
      "Epoch 5393 / 10000 loss: 13.705872535705566\n",
      "MSE train 5.412247468417827 MSE test 11.89767475912156\n",
      "MAE train 1.604529907272887 MAE test 2.4147233174112874\n",
      "Epoch 5394 / 10000 loss: 13.70543360710144\n",
      "MSE train 5.412108825109769 MSE test 11.897518179209579\n",
      "MAE train 1.604506393328051 MAE test 2.4147093367609798\n",
      "Epoch 5395 / 10000 loss: 13.704903841018677\n",
      "MSE train 5.411999867489416 MSE test 11.89738675875744\n",
      "MAE train 1.604489974221334 MAE test 2.4146926943567917\n",
      "Epoch 5396 / 10000 loss: 13.704427480697632\n",
      "MSE train 5.411863871265596 MSE test 11.897164511857067\n",
      "MAE train 1.604468562934763 MAE test 2.414670459693167\n",
      "Epoch 5397 / 10000 loss: 13.703978538513184\n",
      "MSE train 5.411727146835526 MSE test 11.89706103130397\n",
      "MAE train 1.6044445579233586 MAE test 2.414657352619292\n",
      "Epoch 5398 / 10000 loss: 13.703563451766968\n",
      "MSE train 5.4115939353752065 MSE test 11.896971333768143\n",
      "MAE train 1.6044208976148389 MAE test 2.414651839595922\n",
      "Epoch 5399 / 10000 loss: 13.702986240386963\n",
      "MSE train 5.411468335257975 MSE test 11.896743354386896\n",
      "MAE train 1.6044023954549564 MAE test 2.4146229355119413\n",
      "Epoch 5400 / 10000 loss: 13.702484369277954\n",
      "MSE train 5.411338170236681 MSE test 11.896673476824128\n",
      "MAE train 1.6043791194339259 MAE test 2.4146199672880013\n",
      "Epoch 5401 / 10000 loss: 13.702032089233398\n",
      "MSE train 5.411211059006193 MSE test 11.896423588599582\n",
      "MAE train 1.6043607199477516 MAE test 2.414588290845833\n",
      "Epoch 5402 / 10000 loss: 13.701533317565918\n",
      "MSE train 5.411089653606298 MSE test 11.8963923257029\n",
      "MAE train 1.6043388834431958 MAE test 2.4145902483893535\n",
      "Epoch 5403 / 10000 loss: 13.70108962059021\n",
      "MSE train 5.410963959908847 MSE test 11.89606998478056\n",
      "MAE train 1.6043224561342095 MAE test 2.4145494373234206\n",
      "Epoch 5404 / 10000 loss: 13.700601577758789\n",
      "MSE train 5.410827077708483 MSE test 11.896090404448332\n",
      "MAE train 1.6042956029057573 MAE test 2.4145579524504086\n",
      "Epoch 5405 / 10000 loss: 13.70021367073059\n",
      "MSE train 5.410698062360282 MSE test 11.89581111778176\n",
      "MAE train 1.6042773541286832 MAE test 2.4145225120248637\n",
      "Epoch 5406 / 10000 loss: 13.699629306793213\n",
      "MSE train 5.410579235640672 MSE test 11.89580244759032\n",
      "MAE train 1.6042556758493511 MAE test 2.4145273590978142\n",
      "Epoch 5407 / 10000 loss: 13.699197769165039\n",
      "MSE train 5.410452715854 MSE test 11.895452159558568\n",
      "MAE train 1.6042396125075726 MAE test 2.414483002650644\n",
      "Epoch 5408 / 10000 loss: 13.69870138168335\n",
      "MSE train 5.41030541371285 MSE test 11.895474667554131\n",
      "MAE train 1.6042101041610137 MAE test 2.4144917953534963\n",
      "Epoch 5409 / 10000 loss: 13.698333978652954\n",
      "MSE train 5.410181601461184 MSE test 11.89525830438905\n",
      "MAE train 1.604191753091909 MAE test 2.4144643418510685\n",
      "Epoch 5410 / 10000 loss: 13.697705030441284\n",
      "MSE train 5.4100451465107655 MSE test 11.895153127168063\n",
      "MAE train 1.6041677522564353 MAE test 2.414456913009168\n",
      "Epoch 5411 / 10000 loss: 13.697250127792358\n",
      "MSE train 5.4099248783274385 MSE test 11.894959574745585\n",
      "MAE train 1.6041498710475417 MAE test 2.414432409487551\n",
      "Epoch 5412 / 10000 loss: 13.696746587753296\n",
      "MSE train 5.409786786953942 MSE test 11.894826078843748\n",
      "MAE train 1.6041260793666274 MAE test 2.4144214209872428\n",
      "Epoch 5413 / 10000 loss: 13.696293830871582\n",
      "MSE train 5.409676086183806 MSE test 11.894676622281638\n",
      "MAE train 1.604109722733454 MAE test 2.4144025254877177\n",
      "Epoch 5414 / 10000 loss: 13.695802927017212\n",
      "MSE train 5.409539640707956 MSE test 11.894463056605082\n",
      "MAE train 1.6040881341028677 MAE test 2.414381447815738\n",
      "Epoch 5415 / 10000 loss: 13.69536018371582\n",
      "MSE train 5.4094041479756685 MSE test 11.89435744788867\n",
      "MAE train 1.6040645753704799 MAE test 2.414368129930292\n",
      "Epoch 5416 / 10000 loss: 13.69493317604065\n",
      "MSE train 5.409265466587447 MSE test 11.894242986728228\n",
      "MAE train 1.6040402703675951 MAE test 2.414359536390824\n",
      "Epoch 5417 / 10000 loss: 13.694361209869385\n",
      "MSE train 5.409145361804219 MSE test 11.89405226029017\n",
      "MAE train 1.604022442534947 MAE test 2.414335409251867\n",
      "Epoch 5418 / 10000 loss: 13.693853855133057\n",
      "MSE train 5.409005370769699 MSE test 11.893903997131426\n",
      "MAE train 1.603998603469288 MAE test 2.4143226065235313\n",
      "Epoch 5419 / 10000 loss: 13.693397998809814\n",
      "MSE train 5.408893480967987 MSE test 11.89376415531227\n",
      "MAE train 1.6039818623640878 MAE test 2.414304969643735\n",
      "Epoch 5420 / 10000 loss: 13.692907333374023\n",
      "MSE train 5.408754320090771 MSE test 11.893536822514799\n",
      "MAE train 1.603960011853535 MAE test 2.414282199739057\n",
      "Epoch 5421 / 10000 loss: 13.692452192306519\n",
      "MSE train 5.4086121320723795 MSE test 11.893428423202439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.6039350530559293 MAE test 2.414268591822684\n",
      "Epoch 5422 / 10000 loss: 13.692023515701294\n",
      "MSE train 5.4084738562594925 MSE test 11.893336082115729\n",
      "MAE train 1.6039105332511265 MAE test 2.414262895303493\n",
      "Epoch 5423 / 10000 loss: 13.691425800323486\n",
      "MSE train 5.408339898295029 MSE test 11.893093043662535\n",
      "MAE train 1.6038907028158071 MAE test 2.414232235556299\n",
      "Epoch 5424 / 10000 loss: 13.690900325775146\n",
      "MSE train 5.408202831081088 MSE test 11.893026251720983\n",
      "MAE train 1.6038662354314603 MAE test 2.4142298964251068\n",
      "Epoch 5425 / 10000 loss: 13.69041919708252\n",
      "MSE train 5.408062311238937 MSE test 11.892741020709135\n",
      "MAE train 1.6038459912456247 MAE test 2.4141940156185235\n",
      "Epoch 5426 / 10000 loss: 13.689883708953857\n",
      "MSE train 5.407924768663397 MSE test 11.892722040704381\n",
      "MAE train 1.6038209414463442 MAE test 2.4141978816433367\n",
      "Epoch 5427 / 10000 loss: 13.689400672912598\n",
      "MSE train 5.407770757284701 MSE test 11.892354301057276\n",
      "MAE train 1.6037999671983916 MAE test 2.4141517650497804\n",
      "Epoch 5428 / 10000 loss: 13.68882703781128\n",
      "MSE train 5.407576687959054 MSE test 11.89235537935867\n",
      "MAE train 1.6037617756248437 MAE test 2.41415846839999\n",
      "Epoch 5429 / 10000 loss: 13.688342332839966\n",
      "MSE train 5.407369784781174 MSE test 11.892113724883\n",
      "MAE train 1.6037276757210042 MAE test 2.4141287601581065\n",
      "Epoch 5430 / 10000 loss: 13.687509298324585\n",
      "MSE train 5.40706636212433 MSE test 11.891954861695819\n",
      "MAE train 1.6036715710471157 MAE test 2.4141159484807146\n",
      "Epoch 5431 / 10000 loss: 13.686679601669312\n",
      "MSE train 5.4066806879439575 MSE test 11.891714526387565\n",
      "MAE train 1.6036022647751076 MAE test 2.414087473422774\n",
      "Epoch 5432 / 10000 loss: 13.685423851013184\n",
      "MSE train 5.4063953804371705 MSE test 11.891493964470715\n",
      "MAE train 1.6035509137404067 MAE test 2.4140672389916817\n",
      "Epoch 5433 / 10000 loss: 13.683727741241455\n",
      "MSE train 5.4062666348947825 MSE test 11.891354127176553\n",
      "MAE train 1.6035311290732226 MAE test 2.4140497494995725\n",
      "Epoch 5434 / 10000 loss: 13.682566165924072\n",
      "MSE train 5.406125620484592 MSE test 11.891133604580427\n",
      "MAE train 1.6035086922246458 MAE test 2.4140275464438528\n",
      "Epoch 5435 / 10000 loss: 13.682017087936401\n",
      "MSE train 5.405987505088838 MSE test 11.891031822126621\n",
      "MAE train 1.6034843794862466 MAE test 2.414014370867884\n",
      "Epoch 5436 / 10000 loss: 13.681565046310425\n",
      "MSE train 5.405849616349208 MSE test 11.890933850313445\n",
      "MAE train 1.6034598552025199 MAE test 2.414007536665221\n",
      "Epoch 5437 / 10000 loss: 13.680971622467041\n",
      "MSE train 5.405726066735517 MSE test 11.890735078029415\n",
      "MAE train 1.6034412625812153 MAE test 2.413982053372741\n",
      "Epoch 5438 / 10000 loss: 13.680449485778809\n",
      "MSE train 5.405587893779809 MSE test 11.8906279754571\n",
      "MAE train 1.6034169082737206 MAE test 2.413974154036852\n",
      "Epoch 5439 / 10000 loss: 13.679980516433716\n",
      "MSE train 5.405471053761201 MSE test 11.890459320358946\n",
      "MAE train 1.6033994613900862 MAE test 2.4139525790611023\n",
      "Epoch 5440 / 10000 loss: 13.679467916488647\n",
      "MSE train 5.405333036681169 MSE test 11.890297990161447\n",
      "MAE train 1.603376346070719 MAE test 2.413937892368906\n",
      "Epoch 5441 / 10000 loss: 13.67901062965393\n",
      "MSE train 5.405217818932731 MSE test 11.890184331411362\n",
      "MAE train 1.6033581595424322 MAE test 2.413923349334789\n",
      "Epoch 5442 / 10000 loss: 13.678535461425781\n",
      "MSE train 5.405079961217639 MSE test 11.889976743525217\n",
      "MAE train 1.6033361362396619 MAE test 2.413902882630261\n",
      "Epoch 5443 / 10000 loss: 13.678048372268677\n",
      "MSE train 5.404945239765946 MSE test 11.889875483753109\n",
      "MAE train 1.6033127588229548 MAE test 2.413889969989437\n",
      "Epoch 5444 / 10000 loss: 13.677610158920288\n",
      "MSE train 5.404805833871346 MSE test 11.889761492461757\n",
      "MAE train 1.6032883342658732 MAE test 2.4138813136936776\n",
      "Epoch 5445 / 10000 loss: 13.67703652381897\n",
      "MSE train 5.404687602885271 MSE test 11.889583768077923\n",
      "MAE train 1.6032708223665046 MAE test 2.413858733692743\n",
      "Epoch 5446 / 10000 loss: 13.67652416229248\n",
      "MSE train 5.404548099053704 MSE test 11.88942617051137\n",
      "MAE train 1.6032473766104098 MAE test 2.4138446358699555\n",
      "Epoch 5447 / 10000 loss: 13.67606496810913\n",
      "MSE train 5.404434464290159 MSE test 11.889304108068059\n",
      "MAE train 1.603229901371914 MAE test 2.4138291394764124\n",
      "Epoch 5448 / 10000 loss: 13.675581455230713\n",
      "MSE train 5.404295704998922 MSE test 11.88908592860615\n",
      "MAE train 1.6032080019982187 MAE test 2.4138074231153674\n",
      "Epoch 5449 / 10000 loss: 13.67510461807251\n",
      "MSE train 5.404156442426435 MSE test 11.888983556457395\n",
      "MAE train 1.603183682674734 MAE test 2.413794438472419\n",
      "Epoch 5450 / 10000 loss: 13.67467188835144\n",
      "MSE train 5.404018594683386 MSE test 11.888888585634858\n",
      "MAE train 1.60315936667863 MAE test 2.4137882629314213\n",
      "Epoch 5451 / 10000 loss: 13.674078941345215\n",
      "MSE train 5.40389083834699 MSE test 11.888672498844805\n",
      "MAE train 1.6031404337895725 MAE test 2.4137608433556172\n",
      "Epoch 5452 / 10000 loss: 13.673557758331299\n",
      "MSE train 5.403752996522101 MSE test 11.888583678893909\n",
      "MAE train 1.6031160858073503 MAE test 2.4137554968368473\n",
      "Epoch 5453 / 10000 loss: 13.673084020614624\n",
      "MSE train 5.403625011008459 MSE test 11.888371613196783\n",
      "MAE train 1.6030970991294533 MAE test 2.413728615498152\n",
      "Epoch 5454 / 10000 loss: 13.672560214996338\n",
      "MSE train 5.403486296961047 MSE test 11.888281483879615\n",
      "MAE train 1.6030726338162293 MAE test 2.413723128456519\n",
      "Epoch 5455 / 10000 loss: 13.672083616256714\n",
      "MSE train 5.403358337263295 MSE test 11.888073890756688\n",
      "MAE train 1.603053608045928 MAE test 2.4136968272679264\n",
      "Epoch 5456 / 10000 loss: 13.671557426452637\n",
      "MSE train 5.403218042092538 MSE test 11.88797621381227\n",
      "MAE train 1.6030290330500616 MAE test 2.4136903874502957\n",
      "Epoch 5457 / 10000 loss: 13.671078443527222\n",
      "MSE train 5.40309202582911 MSE test 11.887781857594112\n",
      "MAE train 1.6030103140143352 MAE test 2.413665778861411\n",
      "Epoch 5458 / 10000 loss: 13.670549392700195\n",
      "MSE train 5.402949283287953 MSE test 11.887657969601918\n",
      "MAE train 1.6029857398428549 MAE test 2.413656032189101\n",
      "Epoch 5459 / 10000 loss: 13.67006802558899\n",
      "MSE train 5.4028317506660235 MSE test 11.887501653420037\n",
      "MAE train 1.6029684682131646 MAE test 2.413636260850923\n",
      "Epoch 5460 / 10000 loss: 13.66954517364502\n",
      "MSE train 5.402690007931903 MSE test 11.887303008824665\n",
      "MAE train 1.602945872812838 MAE test 2.4136170801838204\n",
      "Epoch 5461 / 10000 loss: 13.669074296951294\n",
      "MSE train 5.402554923361827 MSE test 11.88719730010194\n",
      "MAE train 1.6029231320013977 MAE test 2.4136037147076523\n",
      "Epoch 5462 / 10000 loss: 13.668607473373413\n",
      "MSE train 5.402409449735453 MSE test 11.887052114970901\n",
      "MAE train 1.6028984500825232 MAE test 2.413591242741957\n",
      "Epoch 5463 / 10000 loss: 13.668030738830566\n",
      "MSE train 5.40229390191628 MSE test 11.886908791615523\n",
      "MAE train 1.6028815232425213 MAE test 2.4135731008764987\n",
      "Epoch 5464 / 10000 loss: 13.667510032653809\n",
      "MSE train 5.402151213665267 MSE test 11.886689550847008\n",
      "MAE train 1.602859188719639 MAE test 2.413551293486528\n",
      "Epoch 5465 / 10000 loss: 13.667033672332764\n",
      "MSE train 5.402008536432307 MSE test 11.886585347001445\n",
      "MAE train 1.6028345535884716 MAE test 2.4135381171424766\n",
      "Epoch 5466 / 10000 loss: 13.666580200195312\n",
      "MSE train 5.401867119901205 MSE test 11.88648691727814\n",
      "MAE train 1.6028098647143745 MAE test 2.4135315172745155\n",
      "Epoch 5467 / 10000 loss: 13.665970087051392\n",
      "MSE train 5.401737248591751 MSE test 11.886273381833092\n",
      "MAE train 1.602790729632339 MAE test 2.413504429897174\n",
      "Epoch 5468 / 10000 loss: 13.665432453155518\n",
      "MSE train 5.40159641774746 MSE test 11.88617676806045\n",
      "MAE train 1.602766168333981 MAE test 2.413498097464263\n",
      "Epoch 5469 / 10000 loss: 13.664945363998413\n",
      "MSE train 5.401469160178909 MSE test 11.885975541928959\n",
      "MAE train 1.6027473553203855 MAE test 2.413472574293992\n",
      "Epoch 5470 / 10000 loss: 13.664412498474121\n",
      "MSE train 5.401327488321114 MSE test 11.88586239614455\n",
      "MAE train 1.6027228110473415 MAE test 2.413464151590184\n",
      "Epoch 5471 / 10000 loss: 13.663929224014282\n",
      "MSE train 5.401207662515108 MSE test 11.88569050274993\n",
      "MAE train 1.6027052074217578 MAE test 2.4134423522920927\n",
      "Epoch 5472 / 10000 loss: 13.663403034210205\n",
      "MSE train 5.40106676799595 MSE test 11.885519942738888\n",
      "MAE train 1.6026820141186162 MAE test 2.4134266600259253\n",
      "Epoch 5473 / 10000 loss: 13.662932395935059\n",
      "MSE train 5.400947090293333 MSE test 11.885403950681823\n",
      "MAE train 1.6026631880166993 MAE test 2.4134119462694357\n",
      "Epoch 5474 / 10000 loss: 13.662448406219482\n",
      "MSE train 5.400806504469669 MSE test 11.88519764113788\n",
      "MAE train 1.6026407920617232 MAE test 2.413391722945349\n",
      "Epoch 5475 / 10000 loss: 13.661940574645996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.400672210691934 MSE test 11.885091112732493\n",
      "MAE train 1.6026179733329224 MAE test 2.413378193954877\n",
      "Epoch 5476 / 10000 loss: 13.661487102508545\n",
      "MSE train 5.400529609537134 MSE test 11.884956773712554\n",
      "MAE train 1.6025933922666213 MAE test 2.4133670190232936\n",
      "Epoch 5477 / 10000 loss: 13.660913944244385\n",
      "MSE train 5.4004147976038315 MSE test 11.88479829454176\n",
      "MAE train 1.602576582371022 MAE test 2.4133469017527625\n",
      "Epoch 5478 / 10000 loss: 13.660398483276367\n",
      "MSE train 5.4002743626961305 MSE test 11.884595605127434\n",
      "MAE train 1.6025540792695625 MAE test 2.4133271342398515\n",
      "Epoch 5479 / 10000 loss: 13.659935474395752\n",
      "MSE train 5.400140667888288 MSE test 11.884487494660512\n",
      "MAE train 1.6025314327198577 MAE test 2.4133134154084486\n",
      "Epoch 5480 / 10000 loss: 13.659478187561035\n",
      "MSE train 5.399996282137015 MSE test 11.884342723844766\n",
      "MAE train 1.6025066597331388 MAE test 2.4133009422899874\n",
      "Epoch 5481 / 10000 loss: 13.658906698226929\n",
      "MSE train 5.399880710438275 MSE test 11.884192956226013\n",
      "MAE train 1.6024896104520918 MAE test 2.41328193682854\n",
      "Epoch 5482 / 10000 loss: 13.658390283584595\n",
      "MSE train 5.399736917396028 MSE test 11.883973543465478\n",
      "MAE train 1.602466797865316 MAE test 2.4132600837850413\n",
      "Epoch 5483 / 10000 loss: 13.657916069030762\n",
      "MSE train 5.399592608566305 MSE test 11.88386421212707\n",
      "MAE train 1.6024418255045612 MAE test 2.413246251874083\n",
      "Epoch 5484 / 10000 loss: 13.657453298568726\n",
      "MSE train 5.399444338228372 MSE test 11.883750689870705\n",
      "MAE train 1.6024158955669845 MAE test 2.4132377827673923\n",
      "Epoch 5485 / 10000 loss: 13.65683650970459\n",
      "MSE train 5.399308670422043 MSE test 11.8835454840417\n",
      "MAE train 1.6023955528048381 MAE test 2.413211805521608\n",
      "Epoch 5486 / 10000 loss: 13.656274557113647\n",
      "MSE train 5.399151763311601 MSE test 11.883409061254609\n",
      "MAE train 1.6023685002397996 MAE test 2.413200523001616\n",
      "Epoch 5487 / 10000 loss: 13.65574836730957\n",
      "MSE train 5.399015054941793 MSE test 11.883240919794751\n",
      "MAE train 1.6023479777514456 MAE test 2.4131793395682726\n",
      "Epoch 5488 / 10000 loss: 13.655160665512085\n",
      "MSE train 5.398846098626683 MSE test 11.883026423526056\n",
      "MAE train 1.6023207998580082 MAE test 2.413158276997007\n",
      "Epoch 5489 / 10000 loss: 13.654597520828247\n",
      "MSE train 5.398673649450967 MSE test 11.882903028748299\n",
      "MAE train 1.6022918782829156 MAE test 2.4131428615654076\n",
      "Epoch 5490 / 10000 loss: 13.654003381729126\n",
      "MSE train 5.398480089654546 MSE test 11.882739126600914\n",
      "MAE train 1.60225915039161 MAE test 2.4131282746740568\n",
      "Epoch 5491 / 10000 loss: 13.653249979019165\n",
      "MSE train 5.398306601654969 MSE test 11.882570116258739\n",
      "MAE train 1.6022327500523539 MAE test 2.4131072065569668\n",
      "Epoch 5492 / 10000 loss: 13.65250015258789\n",
      "MSE train 5.398104330215634 MSE test 11.882329233549413\n",
      "MAE train 1.6022002876378596 MAE test 2.4130830394995315\n",
      "Epoch 5493 / 10000 loss: 13.651750802993774\n",
      "MSE train 5.397912774552062 MSE test 11.882202899937138\n",
      "MAE train 1.6021673370757876 MAE test 2.4130674127254323\n",
      "Epoch 5494 / 10000 loss: 13.651012897491455\n",
      "MSE train 5.397737906625402 MSE test 11.882081182945225\n",
      "MAE train 1.6021373851198133 MAE test 2.4130582096139026\n",
      "Epoch 5495 / 10000 loss: 13.650172710418701\n",
      "MSE train 5.397593737431191 MSE test 11.881868366826609\n",
      "MAE train 1.6021159311639928 MAE test 2.4130314471218894\n",
      "Epoch 5496 / 10000 loss: 13.64948296546936\n",
      "MSE train 5.397444744552308 MSE test 11.881745182517143\n",
      "MAE train 1.6020904191234742 MAE test 2.4130219299515017\n",
      "Epoch 5497 / 10000 loss: 13.648921012878418\n",
      "MSE train 5.397324833624624 MSE test 11.881576078788813\n",
      "MAE train 1.6020729513993233 MAE test 2.4130006076964685\n",
      "Epoch 5498 / 10000 loss: 13.648365497589111\n",
      "MSE train 5.397185927614479 MSE test 11.881398137283426\n",
      "MAE train 1.6020502957571623 MAE test 2.4129841028941823\n",
      "Epoch 5499 / 10000 loss: 13.6478910446167\n",
      "MSE train 5.397066000457811 MSE test 11.881289041768474\n",
      "MAE train 1.6020310222521217 MAE test 2.412970313062804\n",
      "Epoch 5500 / 10000 loss: 13.647423267364502\n",
      "MSE train 5.396928872963407 MSE test 11.881101920278617\n",
      "MAE train 1.6020087045563904 MAE test 2.4129525768949773\n",
      "Epoch 5501 / 10000 loss: 13.646915674209595\n",
      "MSE train 5.3968071959482025 MSE test 11.880995937350656\n",
      "MAE train 1.6019887080053048 MAE test 2.4129391804828275\n",
      "Epoch 5502 / 10000 loss: 13.646466970443726\n",
      "MSE train 5.396670042950859 MSE test 11.880827789506757\n",
      "MAE train 1.6019658167785635 MAE test 2.4129237916278505\n",
      "Epoch 5503 / 10000 loss: 13.64594841003418\n",
      "MSE train 5.396558043662973 MSE test 11.8807120100568\n",
      "MAE train 1.6019483655493498 MAE test 2.412909129943817\n",
      "Epoch 5504 / 10000 loss: 13.64548635482788\n",
      "MSE train 5.396422919544479 MSE test 11.880506736711462\n",
      "MAE train 1.6019267174627103 MAE test 2.4128890635893927\n",
      "Epoch 5505 / 10000 loss: 13.645013093948364\n",
      "MSE train 5.396293411502033 MSE test 11.880405220560537\n",
      "MAE train 1.601904458256019 MAE test 2.412876199152185\n",
      "Epoch 5506 / 10000 loss: 13.644588232040405\n",
      "MSE train 5.396157273310781 MSE test 11.880283592300898\n",
      "MAE train 1.6018806511678123 MAE test 2.412866663983823\n",
      "Epoch 5507 / 10000 loss: 13.64403748512268\n",
      "MSE train 5.396046305133553 MSE test 11.880119516506984\n",
      "MAE train 1.6018643791003406 MAE test 2.412845838365324\n",
      "Epoch 5508 / 10000 loss: 13.643545389175415\n",
      "MSE train 5.395912023439664 MSE test 11.879940063264531\n",
      "MAE train 1.6018422795359317 MAE test 2.4128290297288353\n",
      "Epoch 5509 / 10000 loss: 13.643109321594238\n",
      "MSE train 5.395794107830414 MSE test 11.87983190269964\n",
      "MAE train 1.6018230583372783 MAE test 2.4128153060210993\n",
      "Epoch 5510 / 10000 loss: 13.642666101455688\n",
      "MSE train 5.39565870331967 MSE test 11.879650264676386\n",
      "MAE train 1.6018006798929665 MAE test 2.4127982025725063\n",
      "Epoch 5511 / 10000 loss: 13.642165422439575\n",
      "MSE train 5.39554176325094 MSE test 11.879539759622972\n",
      "MAE train 1.601781708028691 MAE test 2.412784166845104\n",
      "Epoch 5512 / 10000 loss: 13.641719818115234\n",
      "MSE train 5.395406247797777 MSE test 11.879354882004995\n",
      "MAE train 1.6017593470759484 MAE test 2.412766639163847\n",
      "Epoch 5513 / 10000 loss: 13.641223430633545\n",
      "MSE train 5.395288424433577 MSE test 11.87924430113209\n",
      "MAE train 1.6017401238127515 MAE test 2.4127526070615266\n",
      "Epoch 5514 / 10000 loss: 13.640779495239258\n",
      "MSE train 5.395152697509539 MSE test 11.879063161504833\n",
      "MAE train 1.6017176064779177 MAE test 2.4127355379311637\n",
      "Epoch 5515 / 10000 loss: 13.640278816223145\n",
      "MSE train 5.395037097508992 MSE test 11.878950029795392\n",
      "MAE train 1.6016989826966055 MAE test 2.412721187776016\n",
      "Epoch 5516 / 10000 loss: 13.639830827713013\n",
      "MSE train 5.394901803451499 MSE test 11.878758935117075\n",
      "MAE train 1.6016767970264143 MAE test 2.4127028577057312\n",
      "Epoch 5517 / 10000 loss: 13.63934063911438\n",
      "MSE train 5.394781443282147 MSE test 11.878649279892088\n",
      "MAE train 1.6016568874336736 MAE test 2.412688942830405\n",
      "Epoch 5518 / 10000 loss: 13.638901233673096\n",
      "MSE train 5.394645325195679 MSE test 11.878478668640897\n",
      "MAE train 1.6016340142944987 MAE test 2.4126731861085093\n",
      "Epoch 5519 / 10000 loss: 13.63839054107666\n",
      "MSE train 5.394534683270327 MSE test 11.878357998227505\n",
      "MAE train 1.6016167725960568 MAE test 2.4126578712042575\n",
      "Epoch 5520 / 10000 loss: 13.637932538986206\n",
      "MSE train 5.394400182477487 MSE test 11.878146419560867\n",
      "MAE train 1.6015952103255109 MAE test 2.4126369555142455\n",
      "Epoch 5521 / 10000 loss: 13.637466192245483\n",
      "MSE train 5.394270278025712 MSE test 11.87804115176291\n",
      "MAE train 1.6015727388854917 MAE test 2.412623577626247\n",
      "Epoch 5522 / 10000 loss: 13.637046098709106\n",
      "MSE train 5.394134923949976 MSE test 11.877920614368353\n",
      "MAE train 1.6015489646998742 MAE test 2.41261414216701\n",
      "Epoch 5523 / 10000 loss: 13.636494398117065\n",
      "MSE train 5.394022267571564 MSE test 11.87774471437973\n",
      "MAE train 1.6015323638910166 MAE test 2.4125918046203667\n",
      "Epoch 5524 / 10000 loss: 13.636002540588379\n",
      "MSE train 5.39388768091454 MSE test 11.877575521802658\n",
      "MAE train 1.6015098298548436 MAE test 2.4125762525312187\n",
      "Epoch 5525 / 10000 loss: 13.635564804077148\n",
      "MSE train 5.393776031728398 MSE test 11.877456668169417\n",
      "MAE train 1.601492295077291 MAE test 2.4125611517630188\n",
      "Epoch 5526 / 10000 loss: 13.635110855102539\n",
      "MSE train 5.393641891399096 MSE test 11.87724600253381\n",
      "MAE train 1.6014707852392631 MAE test 2.412540353731209\n",
      "Epoch 5527 / 10000 loss: 13.634641170501709\n",
      "MSE train 5.393512326063834 MSE test 11.877139787837267\n",
      "MAE train 1.6014483983613714 MAE test 2.4125268662544537\n",
      "Epoch 5528 / 10000 loss: 13.634221076965332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.393376649870306 MSE test 11.877015381974488\n",
      "MAE train 1.6014246059744548 MAE test 2.4125169348136377\n",
      "Epoch 5529 / 10000 loss: 13.633670330047607\n",
      "MSE train 5.393264983541113 MSE test 11.876843006393862\n",
      "MAE train 1.6014081654299221 MAE test 2.4124950484943057\n",
      "Epoch 5530 / 10000 loss: 13.633179903030396\n",
      "MSE train 5.393130612283206 MSE test 11.876664358963255\n",
      "MAE train 1.6013858662825249 MAE test 2.4124783000290537\n",
      "Epoch 5531 / 10000 loss: 13.632744789123535\n",
      "MSE train 5.393015504453656 MSE test 11.876548891406584\n",
      "MAE train 1.6013673663480268 MAE test 2.4124636361204224\n",
      "Epoch 5532 / 10000 loss: 13.632297039031982\n",
      "MSE train 5.392880566155163 MSE test 11.876350411960715\n",
      "MAE train 1.601345383682111 MAE test 2.4124443543726595\n",
      "Epoch 5533 / 10000 loss: 13.631810903549194\n",
      "MSE train 5.392757433828698 MSE test 11.876239759159821\n",
      "MAE train 1.6013247248713705 MAE test 2.4124303063966708\n",
      "Epoch 5534 / 10000 loss: 13.631377220153809\n",
      "MSE train 5.392620744313349 MSE test 11.876078655621825\n",
      "MAE train 1.6013014428098087 MAE test 2.4124157341142816\n",
      "Epoch 5535 / 10000 loss: 13.63085412979126\n",
      "MSE train 5.392513218760294 MSE test 11.875945897805364\n",
      "MAE train 1.601285191180723 MAE test 2.412398874710159\n",
      "Epoch 5536 / 10000 loss: 13.630385398864746\n",
      "MSE train 5.392378930349842 MSE test 11.875721541105413\n",
      "MAE train 1.6012638894600442 MAE test 2.4123763561688807\n",
      "Epoch 5537 / 10000 loss: 13.62993836402893\n",
      "MSE train 5.392244380997939 MSE test 11.875615123836507\n",
      "MAE train 1.6012402465672504 MAE test 2.4123628328763944\n",
      "Epoch 5538 / 10000 loss: 13.62952709197998\n",
      "MSE train 5.392112440978884 MSE test 11.875519213739569\n",
      "MAE train 1.601216737015366 MAE test 2.412356512078006\n",
      "Epoch 5539 / 10000 loss: 13.628957033157349\n",
      "MSE train 5.39198913447381 MSE test 11.875293481470587\n",
      "MAE train 1.601198458877469 MAE test 2.412327842488973\n",
      "Epoch 5540 / 10000 loss: 13.628459692001343\n",
      "MSE train 5.391858924960946 MSE test 11.875211458752968\n",
      "MAE train 1.6011751254049724 MAE test 2.412323303753195\n",
      "Epoch 5541 / 10000 loss: 13.628010749816895\n",
      "MSE train 5.39173426746369 MSE test 11.874975547459254\n",
      "MAE train 1.6011567550879058 MAE test 2.4122933533218767\n",
      "Epoch 5542 / 10000 loss: 13.627514839172363\n",
      "MSE train 5.391608509022523 MSE test 11.874916275238458\n",
      "MAE train 1.6011341344479921 MAE test 2.4122917107216266\n",
      "Epoch 5543 / 10000 loss: 13.627066612243652\n",
      "MSE train 5.391482488642778 MSE test 11.874637497430395\n",
      "MAE train 1.6011163025561321 MAE test 2.412256339325404\n",
      "Epoch 5544 / 10000 loss: 13.626575231552124\n",
      "MSE train 5.39136445533368 MSE test 11.874629759649208\n",
      "MAE train 1.6010945888644788 MAE test 2.412261246971668\n",
      "Epoch 5545 / 10000 loss: 13.626150369644165\n",
      "MSE train 5.391239374015073 MSE test 11.874276172535085\n",
      "MAE train 1.601078626186041 MAE test 2.412216430830685\n",
      "Epoch 5546 / 10000 loss: 13.625654458999634\n",
      "MSE train 5.391092099020439 MSE test 11.874295232801037\n",
      "MAE train 1.601048984268651 MAE test 2.4122247293817467\n",
      "Epoch 5547 / 10000 loss: 13.625289678573608\n",
      "MSE train 5.3909693837290815 MSE test 11.87408080986174\n",
      "MAE train 1.6010306391101066 MAE test 2.412197462769348\n",
      "Epoch 5548 / 10000 loss: 13.624658107757568\n",
      "MSE train 5.390831480465679 MSE test 11.87396271251302\n",
      "MAE train 1.6010062992544156 MAE test 2.4121883326931273\n",
      "Epoch 5549 / 10000 loss: 13.62419867515564\n",
      "MSE train 5.3907128425109505 MSE test 11.873779933109748\n",
      "MAE train 1.600988517215381 MAE test 2.4121650988650862\n",
      "Epoch 5550 / 10000 loss: 13.623691320419312\n",
      "MSE train 5.390571505897104 MSE test 11.873614293812114\n",
      "MAE train 1.6009644985877074 MAE test 2.4121499496320364\n",
      "Epoch 5551 / 10000 loss: 13.623231172561646\n",
      "MSE train 5.39045209388777 MSE test 11.873486558584053\n",
      "MAE train 1.6009456905461992 MAE test 2.4121336687127215\n",
      "Epoch 5552 / 10000 loss: 13.622738122940063\n",
      "MSE train 5.390302324048982 MSE test 11.873261893328625\n",
      "MAE train 1.600921335323061 MAE test 2.412111033277338\n",
      "Epoch 5553 / 10000 loss: 13.622234344482422\n",
      "MSE train 5.390140827773219 MSE test 11.873151814081243\n",
      "MAE train 1.6008925011542519 MAE test 2.4120969229954645\n",
      "Epoch 5554 / 10000 loss: 13.621746063232422\n",
      "MSE train 5.389954969111093 MSE test 11.873045116916668\n",
      "MAE train 1.6008586338012514 MAE test 2.41208901269354\n",
      "Epoch 5555 / 10000 loss: 13.621047735214233\n",
      "MSE train 5.389732855422913 MSE test 11.872824785409902\n",
      "MAE train 1.6008209899562962 MAE test 2.4120606307261747\n",
      "Epoch 5556 / 10000 loss: 13.620298862457275\n",
      "MSE train 5.389488687471794 MSE test 11.872712452597906\n",
      "MAE train 1.6007758722597287 MAE test 2.4120514633325034\n",
      "Epoch 5557 / 10000 loss: 13.619366645812988\n",
      "MSE train 5.389352927837356 MSE test 11.872501304351104\n",
      "MAE train 1.600755558800815 MAE test 2.41202350306336\n",
      "Epoch 5558 / 10000 loss: 13.61831784248352\n",
      "MSE train 5.389216675429519 MSE test 11.872365592005838\n",
      "MAE train 1.6007314391182024 MAE test 2.4120113098440754\n",
      "Epoch 5559 / 10000 loss: 13.617772102355957\n",
      "MSE train 5.389106264720715 MSE test 11.872198816107513\n",
      "MAE train 1.6007150029409485 MAE test 2.4119898057193265\n",
      "Epoch 5560 / 10000 loss: 13.617273330688477\n",
      "MSE train 5.3889727674282 MSE test 11.871996819039175\n",
      "MAE train 1.6006932674628844 MAE test 2.411969925628922\n",
      "Epoch 5561 / 10000 loss: 13.616833925247192\n",
      "MSE train 5.388848369451889 MSE test 11.871883433548945\n",
      "MAE train 1.600672218041071 MAE test 2.411955464767074\n",
      "Epoch 5562 / 10000 loss: 13.616398811340332\n",
      "MSE train 5.388711970744204 MSE test 11.871720179554389\n",
      "MAE train 1.6006488771423988 MAE test 2.411940563355247\n",
      "Epoch 5563 / 10000 loss: 13.615869283676147\n",
      "MSE train 5.388604714981615 MSE test 11.871580760652755\n",
      "MAE train 1.6006327188977303 MAE test 2.4119228535821158\n",
      "Epoch 5564 / 10000 loss: 13.615398406982422\n",
      "MSE train 5.388470714671956 MSE test 11.871350163654075\n",
      "MAE train 1.6006114607273332 MAE test 2.4118995408562003\n",
      "Epoch 5565 / 10000 loss: 13.61495327949524\n",
      "MSE train 5.38833580675681 MSE test 11.87123871990899\n",
      "MAE train 1.600587701698798 MAE test 2.4118854133497716\n",
      "Epoch 5566 / 10000 loss: 13.614545345306396\n",
      "MSE train 5.388204487480397 MSE test 11.871139837147915\n",
      "MAE train 1.6005642698260352 MAE test 2.411878745039301\n",
      "Epoch 5567 / 10000 loss: 13.613974332809448\n",
      "MSE train 5.388080710518112 MSE test 11.870904032045653\n",
      "MAE train 1.6005459455985855 MAE test 2.4118488422648268\n",
      "Epoch 5568 / 10000 loss: 13.61348032951355\n",
      "MSE train 5.387952504391898 MSE test 11.87082471727169\n",
      "MAE train 1.6005229173979547 MAE test 2.4118447153886433\n",
      "Epoch 5569 / 10000 loss: 13.61303448677063\n",
      "MSE train 5.387827210468332 MSE test 11.870567128167448\n",
      "MAE train 1.6005046574106006 MAE test 2.411812067803321\n",
      "Epoch 5570 / 10000 loss: 13.612543821334839\n",
      "MSE train 5.387707814109856 MSE test 11.870525505752246\n",
      "MAE train 1.6004831158202308 MAE test 2.411812734954606\n",
      "Epoch 5571 / 10000 loss: 13.612107038497925\n",
      "MSE train 5.387583957985923 MSE test 11.870196703334495\n",
      "MAE train 1.600466758859315 MAE test 2.4117711197005107\n",
      "Epoch 5572 / 10000 loss: 13.611628532409668\n",
      "MSE train 5.387450164215366 MSE test 11.870206866410612\n",
      "MAE train 1.600440477795875 MAE test 2.411778369408022\n",
      "Epoch 5573 / 10000 loss: 13.611247539520264\n",
      "MSE train 5.387323265642931 MSE test 11.869915622609666\n",
      "MAE train 1.6004224749223372 MAE test 2.411741460108799\n",
      "Epoch 5574 / 10000 loss: 13.610674619674683\n",
      "MSE train 5.38720638259184 MSE test 11.869900251965474\n",
      "MAE train 1.6004009810452284 MAE test 2.4117454675785046\n",
      "Epoch 5575 / 10000 loss: 13.610255241394043\n",
      "MSE train 5.387081911027817 MSE test 11.869542208530317\n",
      "MAE train 1.6003850272367715 MAE test 2.411700172203364\n",
      "Epoch 5576 / 10000 loss: 13.609764575958252\n",
      "MSE train 5.386937527375826 MSE test 11.869554458562469\n",
      "MAE train 1.600355982235202 MAE test 2.4117077066860877\n",
      "Epoch 5577 / 10000 loss: 13.609405755996704\n",
      "MSE train 5.3868158037160665 MSE test 11.869327460666346\n",
      "MAE train 1.6003378701015143 MAE test 2.4116789209308505\n",
      "Epoch 5578 / 10000 loss: 13.608789205551147\n",
      "MSE train 5.386682559152185 MSE test 11.869216087540007\n",
      "MAE train 1.6003142337304899 MAE test 2.41167075335344\n",
      "Epoch 5579 / 10000 loss: 13.608343601226807\n",
      "MSE train 5.386563660246698 MSE test 11.86900745512326\n",
      "MAE train 1.600296474856025 MAE test 2.411644348520852\n",
      "Epoch 5580 / 10000 loss: 13.607850551605225\n",
      "MSE train 5.3864289886856 MSE test 11.868876375584723\n",
      "MAE train 1.6002728692864034 MAE test 2.4116337032205655\n",
      "Epoch 5581 / 10000 loss: 13.607408285140991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.386318298031932 MSE test 11.868702771051025\n",
      "MAE train 1.6002564998355058 MAE test 2.411611768670934\n",
      "Epoch 5582 / 10000 loss: 13.606921672821045\n",
      "MSE train 5.386184672449436 MSE test 11.868504387404844\n",
      "MAE train 1.600234603232491 MAE test 2.4115926210218603\n",
      "Epoch 5583 / 10000 loss: 13.606490850448608\n",
      "MSE train 5.386063902418527 MSE test 11.868384149853382\n",
      "MAE train 1.6002145466550728 MAE test 2.4115774939432097\n",
      "Epoch 5584 / 10000 loss: 13.606056451797485\n",
      "MSE train 5.385927952141193 MSE test 11.868198843144121\n",
      "MAE train 1.6001917268140273 MAE test 2.411559969086552\n",
      "Epoch 5585 / 10000 loss: 13.605546474456787\n",
      "MSE train 5.385815887936621 MSE test 11.868067574552995\n",
      "MAE train 1.6001740723160136 MAE test 2.4115434342240816\n",
      "Epoch 5586 / 10000 loss: 13.605093955993652\n",
      "MSE train 5.385681057737783 MSE test 11.867846928318846\n",
      "MAE train 1.6001523001751627 MAE test 2.411521494321403\n",
      "Epoch 5587 / 10000 loss: 13.604624271392822\n",
      "MSE train 5.385552441788018 MSE test 11.867728040905208\n",
      "MAE train 1.6001301702352697 MAE test 2.411506528751653\n",
      "Epoch 5588 / 10000 loss: 13.60420274734497\n",
      "MSE train 5.385416098036416 MSE test 11.867583804900857\n",
      "MAE train 1.6001063108560207 MAE test 2.4114942103862327\n",
      "Epoch 5589 / 10000 loss: 13.603659868240356\n",
      "MSE train 5.385306436685176 MSE test 11.86740897904468\n",
      "MAE train 1.6000901549433668 MAE test 2.4114721591256103\n",
      "Epoch 5590 / 10000 loss: 13.603174448013306\n",
      "MSE train 5.385172305173498 MSE test 11.867200654290336\n",
      "MAE train 1.6000682784448736 MAE test 2.4114517841597642\n",
      "Epoch 5591 / 10000 loss: 13.602743148803711\n",
      "MSE train 5.385048882050739 MSE test 11.867078581657072\n",
      "MAE train 1.6000475320078198 MAE test 2.411436433024011\n",
      "Epoch 5592 / 10000 loss: 13.602312326431274\n",
      "MSE train 5.384912297327584 MSE test 11.86690399609564\n",
      "MAE train 1.6000242407088872 MAE test 2.4114203020224667\n",
      "Epoch 5593 / 10000 loss: 13.601792097091675\n",
      "MSE train 5.384804385183934 MSE test 11.866759697689513\n",
      "MAE train 1.6000078582980326 MAE test 2.4114021336424356\n",
      "Epoch 5594 / 10000 loss: 13.60132646560669\n",
      "MSE train 5.384670077772759 MSE test 11.866522595219724\n",
      "MAE train 1.59998648808529 MAE test 2.411378166874535\n",
      "Epoch 5595 / 10000 loss: 13.600881338119507\n",
      "MSE train 5.384535656162421 MSE test 11.866402812565086\n",
      "MAE train 1.5999628462475113 MAE test 2.4113631224517795\n",
      "Epoch 5596 / 10000 loss: 13.600472211837769\n",
      "MSE train 5.384403560175026 MSE test 11.866291675277573\n",
      "MAE train 1.5999392861213924 MAE test 2.4113550582888155\n",
      "Epoch 5597 / 10000 loss: 13.599905490875244\n",
      "MSE train 5.384280662459106 MSE test 11.866054680057418\n",
      "MAE train 1.5999210048170973 MAE test 2.411325113115132\n",
      "Epoch 5598 / 10000 loss: 13.599411725997925\n",
      "MSE train 5.38414993569641 MSE test 11.86595399179083\n",
      "MAE train 1.599897581541812 MAE test 2.411318408015766\n",
      "Epoch 5599 / 10000 loss: 13.598965883255005\n",
      "MSE train 5.384026316735029 MSE test 11.865711458875717\n",
      "MAE train 1.5998792547296494 MAE test 2.411287781298865\n",
      "Epoch 5600 / 10000 loss: 13.59847354888916\n",
      "MSE train 5.383898149418227 MSE test 11.865624430676247\n",
      "MAE train 1.599856201189183 MAE test 2.411282835471506\n",
      "Epoch 5601 / 10000 loss: 13.598028898239136\n",
      "MSE train 5.3837727733545115 MSE test 11.86535577694659\n",
      "MAE train 1.5998379287929603 MAE test 2.41124891425868\n",
      "Epoch 5602 / 10000 loss: 13.597538471221924\n",
      "MSE train 5.383653569103622 MSE test 11.865305903138339\n",
      "MAE train 1.599816400264571 MAE test 2.4112487020945665\n",
      "Epoch 5603 / 10000 loss: 13.597102642059326\n",
      "MSE train 5.383529589040317 MSE test 11.864962846261811\n",
      "MAE train 1.599800070401757 MAE test 2.411205430710183\n",
      "Epoch 5604 / 10000 loss: 13.596623659133911\n",
      "MSE train 5.383393892248588 MSE test 11.864962517735066\n",
      "MAE train 1.5997732941173999 MAE test 2.4112115186087206\n",
      "Epoch 5605 / 10000 loss: 13.596246242523193\n",
      "MSE train 5.3832666314470545 MSE test 11.864667813375725\n",
      "MAE train 1.5997550010764012 MAE test 2.411174327418287\n",
      "Epoch 5606 / 10000 loss: 13.595666646957397\n",
      "MSE train 5.383150005634479 MSE test 11.8646321357137\n",
      "MAE train 1.5997337652676908 MAE test 2.411175955986869\n",
      "Epoch 5607 / 10000 loss: 13.595239639282227\n",
      "MSE train 5.3830253865640225 MSE test 11.864263647015767\n",
      "MAE train 1.5997177394201458 MAE test 2.4111294995999013\n",
      "Epoch 5608 / 10000 loss: 13.594757556915283\n",
      "MSE train 5.3828810804848635 MSE test 11.864262597609379\n",
      "MAE train 1.5996887164050688 MAE test 2.4111355316720515\n",
      "Epoch 5609 / 10000 loss: 13.594396114349365\n",
      "MSE train 5.38275817179317 MSE test 11.864018064152367\n",
      "MAE train 1.5996704070068142 MAE test 2.4111047295533554\n",
      "Epoch 5610 / 10000 loss: 13.593780517578125\n",
      "MSE train 5.382625595542475 MSE test 11.863900390745366\n",
      "MAE train 1.5996467659351472 MAE test 2.411095946656725\n",
      "Epoch 5611 / 10000 loss: 13.59333324432373\n",
      "MSE train 5.382503599393278 MSE test 11.863663773479491\n",
      "MAE train 1.5996285303204694 MAE test 2.411066208983452\n",
      "Epoch 5612 / 10000 loss: 13.592838764190674\n",
      "MSE train 5.38237060321363 MSE test 11.863543026762194\n",
      "MAE train 1.5996048545714445 MAE test 2.4110570965464744\n",
      "Epoch 5613 / 10000 loss: 13.592393159866333\n",
      "MSE train 5.382250037184128 MSE test 11.863314022149739\n",
      "MAE train 1.5995867968800572 MAE test 2.411028346908996\n",
      "Epoch 5614 / 10000 loss: 13.591899633407593\n",
      "MSE train 5.382115482269014 MSE test 11.863177359199897\n",
      "MAE train 1.599563041261362 MAE test 2.411017222768208\n",
      "Epoch 5615 / 10000 loss: 13.591454029083252\n",
      "MSE train 5.382000281394402 MSE test 11.862971427239849\n",
      "MAE train 1.5995458933405529 MAE test 2.4109914610805983\n",
      "Epoch 5616 / 10000 loss: 13.590962171554565\n",
      "MSE train 5.381865009345525 MSE test 11.86278391590107\n",
      "MAE train 1.5995229533057804 MAE test 2.4109739147146287\n",
      "Epoch 5617 / 10000 loss: 13.59052300453186\n",
      "MSE train 5.381755102871254 MSE test 11.86263002305085\n",
      "MAE train 1.5995060262958463 MAE test 2.4109547636036077\n",
      "Epoch 5618 / 10000 loss: 13.590060949325562\n",
      "MSE train 5.38162057032911 MSE test 11.86237780393698\n",
      "MAE train 1.599484638419639 MAE test 2.4109291089941762\n",
      "Epoch 5619 / 10000 loss: 13.589607238769531\n",
      "MSE train 5.381485150342944 MSE test 11.86224172634525\n",
      "MAE train 1.599460796022901 MAE test 2.410912265932446\n",
      "Epoch 5620 / 10000 loss: 13.589196920394897\n",
      "MSE train 5.381352204680274 MSE test 11.862113369049288\n",
      "MAE train 1.5994370771892195 MAE test 2.4109022783912417\n",
      "Epoch 5621 / 10000 loss: 13.588626384735107\n",
      "MSE train 5.381228310156549 MSE test 11.861858063784014\n",
      "MAE train 1.5994186192717348 MAE test 2.4108703051566756\n",
      "Epoch 5622 / 10000 loss: 13.588130235671997\n",
      "MSE train 5.381096560963451 MSE test 11.861738183410745\n",
      "MAE train 1.5993950063930404 MAE test 2.4108614247648483\n",
      "Epoch 5623 / 10000 loss: 13.587682008743286\n",
      "MSE train 5.38097179195176 MSE test 11.86147553857742\n",
      "MAE train 1.5993764760773446 MAE test 2.4108285452252023\n",
      "Epoch 5624 / 10000 loss: 13.587185144424438\n",
      "MSE train 5.3808425307946885 MSE test 11.861367883377559\n",
      "MAE train 1.5993532229404361 MAE test 2.410821267438611\n",
      "Epoch 5625 / 10000 loss: 13.586736917495728\n",
      "MSE train 5.380715834933129 MSE test 11.861076781802664\n",
      "MAE train 1.5993347255903472 MAE test 2.4107848271929337\n",
      "Epoch 5626 / 10000 loss: 13.586241960525513\n",
      "MSE train 5.380595418283143 MSE test 11.86100470573089\n",
      "MAE train 1.5993129797973407 MAE test 2.4107821270042633\n",
      "Epoch 5627 / 10000 loss: 13.585803031921387\n",
      "MSE train 5.3804699389871535 MSE test 11.86063624722856\n",
      "MAE train 1.5992964228191047 MAE test 2.4107359723784705\n",
      "Epoch 5628 / 10000 loss: 13.585319995880127\n",
      "MSE train 5.380331968441934 MSE test 11.860610780807438\n",
      "MAE train 1.599269183091036 MAE test 2.4107392186311354\n",
      "Epoch 5629 / 10000 loss: 13.584936618804932\n",
      "MSE train 5.380202872623904 MSE test 11.860293330748076\n",
      "MAE train 1.599250485738015 MAE test 2.4106995123919877\n",
      "Epoch 5630 / 10000 loss: 13.584348678588867\n",
      "MSE train 5.380084211644742 MSE test 11.860225853819548\n",
      "MAE train 1.599228970096506 MAE test 2.410697495757769\n",
      "Epoch 5631 / 10000 loss: 13.58391261100769\n",
      "MSE train 5.379957519525008 MSE test 11.859831086860321\n",
      "MAE train 1.5992125330072489 MAE test 2.4106481238933712\n",
      "Epoch 5632 / 10000 loss: 13.583425045013428\n",
      "MSE train 5.379811944022554 MSE test 11.859798933962084\n",
      "MAE train 1.5991833541511582 MAE test 2.410650680996734\n",
      "Epoch 5633 / 10000 loss: 13.583053350448608\n",
      "MSE train 5.379685237210711 MSE test 11.859514879593446\n",
      "MAE train 1.5991644653555221 MAE test 2.4106153311388363\n",
      "Epoch 5634 / 10000 loss: 13.582433938980103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.379552315818816 MSE test 11.859375502649481\n",
      "MAE train 1.5991406448891807 MAE test 2.4106043212557093\n",
      "Epoch 5635 / 10000 loss: 13.581977128982544\n",
      "MSE train 5.379424291794012 MSE test 11.859079044979199\n",
      "MAE train 1.5991216703345388 MAE test 2.410567477277029\n",
      "Epoch 5636 / 10000 loss: 13.581474304199219\n",
      "MSE train 5.37929593710772 MSE test 11.858959807646755\n",
      "MAE train 1.599098603982598 MAE test 2.4105591290618795\n",
      "Epoch 5637 / 10000 loss: 13.581019401550293\n",
      "MSE train 5.379166417011184 MSE test 11.858612580419882\n",
      "MAE train 1.599080231270046 MAE test 2.4105159351573944\n",
      "Epoch 5638 / 10000 loss: 13.580519914627075\n",
      "MSE train 5.379044054338157 MSE test 11.858540148441993\n",
      "MAE train 1.5990576546741389 MAE test 2.4105136129610223\n",
      "Epoch 5639 / 10000 loss: 13.580088138580322\n",
      "MSE train 5.378914838415885 MSE test 11.8581171963228\n",
      "MAE train 1.5990409202172402 MAE test 2.4104609205980605\n",
      "Epoch 5640 / 10000 loss: 13.579577922821045\n",
      "MSE train 5.378764236239486 MSE test 11.858060671368094\n",
      "MAE train 1.599010751410146 MAE test 2.4104607070110613\n",
      "Epoch 5641 / 10000 loss: 13.57919979095459\n",
      "MSE train 5.378636376786495 MSE test 11.857763298301068\n",
      "MAE train 1.5989915784863642 MAE test 2.410424019039317\n",
      "Epoch 5642 / 10000 loss: 13.57856011390686\n",
      "MSE train 5.378495250308855 MSE test 11.857569706342751\n",
      "MAE train 1.5989666227894428 MAE test 2.410406490121358\n",
      "Epoch 5643 / 10000 loss: 13.57809066772461\n",
      "MSE train 5.378369560705639 MSE test 11.857286197144585\n",
      "MAE train 1.598947730893014 MAE test 2.410371679818917\n",
      "Epoch 5644 / 10000 loss: 13.577571392059326\n",
      "MSE train 5.3782248148829455 MSE test 11.857052085769173\n",
      "MAE train 1.5989226451467524 MAE test 2.4103491305739206\n",
      "Epoch 5645 / 10000 loss: 13.57709789276123\n",
      "MSE train 5.378106019311077 MSE test 11.856802450656156\n",
      "MAE train 1.5989048631333622 MAE test 2.4103188014320693\n",
      "Epoch 5646 / 10000 loss: 13.57658314704895\n",
      "MSE train 5.377959507698838 MSE test 11.856475597950151\n",
      "MAE train 1.598881401843039 MAE test 2.410284684699532\n",
      "Epoch 5647 / 10000 loss: 13.576109647750854\n",
      "MSE train 5.377810389222489 MSE test 11.856252149630745\n",
      "MAE train 1.59885546407947 MAE test 2.410257808086032\n",
      "Epoch 5648 / 10000 loss: 13.575647592544556\n",
      "MSE train 5.377656232613061 MSE test 11.856015918222443\n",
      "MAE train 1.598828384081151 MAE test 2.4102352439181423\n",
      "Epoch 5649 / 10000 loss: 13.575023651123047\n",
      "MSE train 5.3775113589317725 MSE test 11.855677136221395\n",
      "MAE train 1.598806402372869 MAE test 2.4101937538899914\n",
      "Epoch 5650 / 10000 loss: 13.574452877044678\n",
      "MSE train 5.37734007295125 MSE test 11.855397056000484\n",
      "MAE train 1.5987768208863553 MAE test 2.4101657122924283\n",
      "Epoch 5651 / 10000 loss: 13.573906183242798\n",
      "MSE train 5.377175932144667 MSE test 11.855064836526397\n",
      "MAE train 1.5987517779580689 MAE test 2.4101251273745303\n",
      "Epoch 5652 / 10000 loss: 13.573278188705444\n",
      "MSE train 5.376953560501761 MSE test 11.854671387820925\n",
      "MAE train 1.5987155006881262 MAE test 2.410082607588006\n",
      "Epoch 5653 / 10000 loss: 13.57262659072876\n",
      "MSE train 5.3766792944783415 MSE test 11.854334642042012\n",
      "MAE train 1.5986701527164666 MAE test 2.4100410322210646\n",
      "Epoch 5654 / 10000 loss: 13.571827411651611\n",
      "MSE train 5.376361039142539 MSE test 11.853927490792008\n",
      "MAE train 1.5986177943040747 MAE test 2.4099962190063664\n",
      "Epoch 5655 / 10000 loss: 13.570661544799805\n",
      "MSE train 5.376181499940224 MSE test 11.853602900264239\n",
      "MAE train 1.5985902973399617 MAE test 2.4099565710350004\n",
      "Epoch 5656 / 10000 loss: 13.569419384002686\n",
      "MSE train 5.376032961242049 MSE test 11.85326334011164\n",
      "MAE train 1.5985664816423282 MAE test 2.4099217969248463\n",
      "Epoch 5657 / 10000 loss: 13.568690538406372\n",
      "MSE train 5.3758886526639476 MSE test 11.853054487736795\n",
      "MAE train 1.5985410935323419 MAE test 2.4098975548570714\n",
      "Epoch 5658 / 10000 loss: 13.568207263946533\n",
      "MSE train 5.375748502907102 MSE test 11.852859252146692\n",
      "MAE train 1.5985160572181967 MAE test 2.4098808305502426\n",
      "Epoch 5659 / 10000 loss: 13.567574501037598\n",
      "MSE train 5.375616850237608 MSE test 11.852534772716236\n",
      "MAE train 1.598496361720051 MAE test 2.4098415617985385\n",
      "Epoch 5660 / 10000 loss: 13.56701922416687\n",
      "MSE train 5.3754803730818566 MSE test 11.852363712142388\n",
      "MAE train 1.5984719029235193 MAE test 2.4098276063291966\n",
      "Epoch 5661 / 10000 loss: 13.566514253616333\n",
      "MSE train 5.3753488915189225 MSE test 11.852033687322718\n",
      "MAE train 1.598452475970235 MAE test 2.4097873821852382\n",
      "Epoch 5662 / 10000 loss: 13.56596827507019\n",
      "MSE train 5.375221159831206 MSE test 11.851906171605608\n",
      "MAE train 1.5984295225415475 MAE test 2.409778711020922\n",
      "Epoch 5663 / 10000 loss: 13.565478324890137\n",
      "MSE train 5.375091939332697 MSE test 11.851532695487602\n",
      "MAE train 1.598411740501195 MAE test 2.4097326498996257\n",
      "Epoch 5664 / 10000 loss: 13.564952850341797\n",
      "MSE train 5.374964572717708 MSE test 11.851476045688898\n",
      "MAE train 1.598387586740521 MAE test 2.40973268546292\n",
      "Epoch 5665 / 10000 loss: 13.564516067504883\n",
      "MSE train 5.37483684759883 MSE test 11.851090228836613\n",
      "MAE train 1.5983707311938895 MAE test 2.409684834533343\n",
      "Epoch 5666 / 10000 loss: 13.563958883285522\n",
      "MSE train 5.374699637668702 MSE test 11.851057159341686\n",
      "MAE train 1.598343818451738 MAE test 2.4096875822849344\n",
      "Epoch 5667 / 10000 loss: 13.563556432723999\n",
      "MSE train 5.374571320158966 MSE test 11.850742231807015\n",
      "MAE train 1.5983253922630263 MAE test 2.4096483930306625\n",
      "Epoch 5668 / 10000 loss: 13.562957286834717\n",
      "MSE train 5.374454452101016 MSE test 11.8506870073907\n",
      "MAE train 1.5983042576730937 MAE test 2.409648042657338\n",
      "Epoch 5669 / 10000 loss: 13.562514066696167\n",
      "MSE train 5.374330029042124 MSE test 11.850313042117861\n",
      "MAE train 1.5982882922308432 MAE test 2.4096011656003835\n",
      "Epoch 5670 / 10000 loss: 13.562023878097534\n",
      "MSE train 5.374187454876709 MSE test 11.85030865971505\n",
      "MAE train 1.5982596985292765 MAE test 2.409607028785386\n",
      "Epoch 5671 / 10000 loss: 13.561651945114136\n",
      "MSE train 5.3740641965249685 MSE test 11.850060227081995\n",
      "MAE train 1.5982414872452095 MAE test 2.4095757902622155\n",
      "Epoch 5672 / 10000 loss: 13.561037063598633\n",
      "MSE train 5.373935097779117 MSE test 11.84996253521952\n",
      "MAE train 1.5982183682272295 MAE test 2.409569592897762\n",
      "Epoch 5673 / 10000 loss: 13.560588836669922\n",
      "MSE train 5.373811399889308 MSE test 11.8497145923857\n",
      "MAE train 1.5982002015618264 MAE test 2.4095382742277183\n",
      "Epoch 5674 / 10000 loss: 13.560095071792603\n",
      "MSE train 5.373687735987347 MSE test 11.849649206433682\n",
      "MAE train 1.5981779727088525 MAE test 2.40953607975881\n",
      "Epoch 5675 / 10000 loss: 13.55965280532837\n",
      "MSE train 5.373563435584743 MSE test 11.849362388638566\n",
      "MAE train 1.5981605284982903 MAE test 2.409499715529312\n",
      "Epoch 5676 / 10000 loss: 13.55916714668274\n",
      "MSE train 5.373446734909702 MSE test 11.849354946173866\n",
      "MAE train 1.598138952722849 MAE test 2.40950477880555\n",
      "Epoch 5677 / 10000 loss: 13.558751821517944\n",
      "MSE train 5.37332368854227 MSE test 11.849003644399597\n",
      "MAE train 1.5981232764900697 MAE test 2.409460192679429\n",
      "Epoch 5678 / 10000 loss: 13.558260917663574\n",
      "MSE train 5.3731800394750175 MSE test 11.849023184950472\n",
      "MAE train 1.5980942973731862 MAE test 2.409468595928102\n",
      "Epoch 5679 / 10000 loss: 13.557904720306396\n",
      "MSE train 5.373059674819621 MSE test 11.848808367112637\n",
      "MAE train 1.598076401765438 MAE test 2.4094411720065123\n",
      "Epoch 5680 / 10000 loss: 13.557290077209473\n",
      "MSE train 5.372927000783886 MSE test 11.848703140024899\n",
      "MAE train 1.5980528660223225 MAE test 2.4094336534417478\n",
      "Epoch 5681 / 10000 loss: 13.556847095489502\n",
      "MSE train 5.372810537847268 MSE test 11.848513219150972\n",
      "MAE train 1.5980355131502224 MAE test 2.4094093612045437\n",
      "Epoch 5682 / 10000 loss: 13.556358575820923\n",
      "MSE train 5.372676503967296 MSE test 11.848381650557199\n",
      "MAE train 1.5980121915753291 MAE test 2.409398458115517\n",
      "Epoch 5683 / 10000 loss: 13.555920124053955\n",
      "MSE train 5.372569709838801 MSE test 11.848237662330138\n",
      "MAE train 1.5979964245493792 MAE test 2.4093799877632414\n",
      "Epoch 5684 / 10000 loss: 13.555444955825806\n",
      "MSE train 5.372437626189223 MSE test 11.84802907491895\n",
      "MAE train 1.5979752864630905 MAE test 2.4093593240916844\n",
      "Epoch 5685 / 10000 loss: 13.555018663406372\n",
      "MSE train 5.372306763848019 MSE test 11.847929730284617\n",
      "MAE train 1.5979524424487206 MAE test 2.4093464806301164\n",
      "Epoch 5686 / 10000 loss: 13.554608583450317\n",
      "MSE train 5.372173031892504 MSE test 11.847820194206285\n",
      "MAE train 1.5979287743511021 MAE test 2.409338274501877\n",
      "Epoch 5687 / 10000 loss: 13.55405569076538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.372058160178908 MSE test 11.84763920843382\n",
      "MAE train 1.5979117015177855 MAE test 2.4093150208212575\n",
      "Epoch 5688 / 10000 loss: 13.553568124771118\n",
      "MSE train 5.371923887003412 MSE test 11.847496106491414\n",
      "MAE train 1.5978885962601639 MAE test 2.4093025579490943\n",
      "Epoch 5689 / 10000 loss: 13.553133010864258\n",
      "MSE train 5.371817710430356 MSE test 11.847367661213568\n",
      "MAE train 1.5978726989874639 MAE test 2.4092859831602267\n",
      "Epoch 5690 / 10000 loss: 13.552667617797852\n",
      "MSE train 5.371685311546866 MSE test 11.847149915872121\n",
      "MAE train 1.5978516814368406 MAE test 2.4092640663771263\n",
      "Epoch 5691 / 10000 loss: 13.552233695983887\n",
      "MSE train 5.371550916083225 MSE test 11.847052618368956\n",
      "MAE train 1.5978279468644525 MAE test 2.4092514277665242\n",
      "Epoch 5692 / 10000 loss: 13.551832914352417\n",
      "MSE train 5.3714212221406195 MSE test 11.84696933558039\n",
      "MAE train 1.5978047188468727 MAE test 2.409246516485131\n",
      "Epoch 5693 / 10000 loss: 13.551266431808472\n",
      "MSE train 5.3712978270429526 MSE test 11.846743806713576\n",
      "MAE train 1.5977864555514278 MAE test 2.409217527050931\n",
      "Epoch 5694 / 10000 loss: 13.550778150558472\n",
      "MSE train 5.371172336988388 MSE test 11.846685004878154\n",
      "MAE train 1.5977638368434797 MAE test 2.409215748981978\n",
      "Epoch 5695 / 10000 loss: 13.55033802986145\n",
      "MSE train 5.3710476793598785 MSE test 11.846428618327815\n",
      "MAE train 1.597745864039893 MAE test 2.4091828430077196\n",
      "Epoch 5696 / 10000 loss: 13.549853801727295\n",
      "MSE train 5.370931872483083 MSE test 11.846416812995383\n",
      "MAE train 1.5977247928590415 MAE test 2.4091870332108245\n",
      "Epoch 5697 / 10000 loss: 13.549429416656494\n",
      "MSE train 5.370809136196918 MSE test 11.846081243236018\n",
      "MAE train 1.597709026891569 MAE test 2.4091440910017305\n",
      "Epoch 5698 / 10000 loss: 13.548955917358398\n",
      "MSE train 5.37066704460923 MSE test 11.846109048637338\n",
      "MAE train 1.5976803927374992 MAE test 2.409153321896117\n",
      "Epoch 5699 / 10000 loss: 13.548597574234009\n",
      "MSE train 5.370544292363786 MSE test 11.845888952870293\n",
      "MAE train 1.5976621421189587 MAE test 2.4091249821105762\n",
      "Epoch 5700 / 10000 loss: 13.547991752624512\n",
      "MSE train 5.370415303374614 MSE test 11.845812716599594\n",
      "MAE train 1.5976389635699193 MAE test 2.409120949402742\n",
      "Epoch 5701 / 10000 loss: 13.547550201416016\n",
      "MSE train 5.37029194145125 MSE test 11.84558715901251\n",
      "MAE train 1.5976207248758936 MAE test 2.4090919143661993\n",
      "Epoch 5702 / 10000 loss: 13.547062635421753\n",
      "MSE train 5.3701674468009495 MSE test 11.845533868070063\n",
      "MAE train 1.5975982607127515 MAE test 2.409090807561897\n",
      "Epoch 5703 / 10000 loss: 13.546624422073364\n",
      "MSE train 5.370042995599865 MSE test 11.845269072723257\n",
      "MAE train 1.5975805167249895 MAE test 2.4090568022402117\n",
      "Epoch 5704 / 10000 loss: 13.546141862869263\n",
      "MSE train 5.369927283578718 MSE test 11.845266432640873\n",
      "MAE train 1.5975592793042825 MAE test 2.409062142370948\n",
      "Epoch 5705 / 10000 loss: 13.545724153518677\n",
      "MSE train 5.369804420760972 MSE test 11.844924789360439\n",
      "MAE train 1.5975435977796186 MAE test 2.4090184156142134\n",
      "Epoch 5706 / 10000 loss: 13.545244216918945\n",
      "MSE train 5.369660420269001 MSE test 11.844952725569707\n",
      "MAE train 1.5975144877609602 MAE test 2.409027613571676\n",
      "Epoch 5707 / 10000 loss: 13.544891595840454\n",
      "MSE train 5.369540417290004 MSE test 11.844746546776896\n",
      "MAE train 1.597496598017259 MAE test 2.4090010082416\n",
      "Epoch 5708 / 10000 loss: 13.544277906417847\n",
      "MSE train 5.369407301915222 MSE test 11.844643076393352\n",
      "MAE train 1.5974729892392394 MAE test 2.408993477948869\n",
      "Epoch 5709 / 10000 loss: 13.543838024139404\n",
      "MSE train 5.36929216342021 MSE test 11.844463975822146\n",
      "MAE train 1.5974558337625733 MAE test 2.40897035059309\n",
      "Epoch 5710 / 10000 loss: 13.543351411819458\n",
      "MSE train 5.369158111233669 MSE test 11.844323854949067\n",
      "MAE train 1.5974327159000403 MAE test 2.4089581594954153\n",
      "Epoch 5711 / 10000 loss: 13.54291582107544\n",
      "MSE train 5.3690519282624285 MSE test 11.844195415019769\n",
      "MAE train 1.5974168364798036 MAE test 2.4089414949166583\n",
      "Epoch 5712 / 10000 loss: 13.54245138168335\n",
      "MSE train 5.368919631649041 MSE test 11.843978312939331\n",
      "MAE train 1.5973958169130675 MAE test 2.4089195678912945\n",
      "Epoch 5713 / 10000 loss: 13.542019844055176\n",
      "MSE train 5.36878516800906 MSE test 11.843881459369419\n",
      "MAE train 1.597372053815375 MAE test 2.408906882885731\n",
      "Epoch 5714 / 10000 loss: 13.541619539260864\n",
      "MSE train 5.368655457059167 MSE test 11.843798137666784\n",
      "MAE train 1.5973488093621766 MAE test 2.40890188242789\n",
      "Epoch 5715 / 10000 loss: 13.54105281829834\n",
      "MSE train 5.3685320221005055 MSE test 11.843572680119326\n",
      "MAE train 1.597330528304796 MAE test 2.4088728320049686\n",
      "Epoch 5716 / 10000 loss: 13.540566205978394\n",
      "MSE train 5.368406477397928 MSE test 11.843513322399508\n",
      "MAE train 1.5973078807444827 MAE test 2.4088709052994037\n",
      "Epoch 5717 / 10000 loss: 13.540126323699951\n",
      "MSE train 5.368281808864974 MSE test 11.843257196844021\n",
      "MAE train 1.5972898866747935 MAE test 2.408837949340286\n",
      "Epoch 5718 / 10000 loss: 13.539642810821533\n",
      "MSE train 5.368165979716994 MSE test 11.843244360202318\n",
      "MAE train 1.5972688073157115 MAE test 2.4088419472434643\n",
      "Epoch 5719 / 10000 loss: 13.539219379425049\n",
      "MSE train 5.368043197383426 MSE test 11.842909039867811\n",
      "MAE train 1.597253013980187 MAE test 2.4087989694080902\n",
      "Epoch 5720 / 10000 loss: 13.538745880126953\n",
      "MSE train 5.367901264584178 MSE test 11.842936076011007\n",
      "MAE train 1.5972244092826595 MAE test 2.408808026997174\n",
      "Epoch 5721 / 10000 loss: 13.538387298583984\n",
      "MSE train 5.367778325447892 MSE test 11.842713644192576\n",
      "MAE train 1.5972061429748337 MAE test 2.4087793173247825\n",
      "Epoch 5722 / 10000 loss: 13.53778338432312\n",
      "MSE train 5.367649877273018 MSE test 11.842639732311438\n",
      "MAE train 1.597183032675847 MAE test 2.4087755160428133\n",
      "Epoch 5723 / 10000 loss: 13.537342071533203\n",
      "MSE train 5.3675260124168895 MSE test 11.84240787499371\n",
      "MAE train 1.5971647724858804 MAE test 2.408745622627343\n",
      "Epoch 5724 / 10000 loss: 13.536855697631836\n",
      "MSE train 5.367403560262633 MSE test 11.842362065807023\n",
      "MAE train 1.597142666698101 MAE test 2.408745420794259\n",
      "Epoch 5725 / 10000 loss: 13.536419153213501\n",
      "MSE train 5.367279376826274 MSE test 11.842079953758915\n",
      "MAE train 1.597125347604438 MAE test 2.408709132018019\n",
      "Epoch 5726 / 10000 loss: 13.535941362380981\n",
      "MSE train 5.367160679195604 MSE test 11.842089056083424\n",
      "MAE train 1.5971030543827267 MAE test 2.4087159165522674\n",
      "Epoch 5727 / 10000 loss: 13.535536527633667\n",
      "MSE train 5.367037092526013 MSE test 11.841752771494475\n",
      "MAE train 1.597087057400515 MAE test 2.4086727632247777\n",
      "Epoch 5728 / 10000 loss: 13.535035371780396\n",
      "MSE train 5.366895771022883 MSE test 11.841778582007803\n",
      "MAE train 1.5970586145995194 MAE test 2.408681673249765\n",
      "Epoch 5729 / 10000 loss: 13.534676313400269\n",
      "MSE train 5.366772328766191 MSE test 11.841553015322583\n",
      "MAE train 1.5970402875811087 MAE test 2.4086525327688184\n",
      "Epoch 5730 / 10000 loss: 13.534072875976562\n",
      "MSE train 5.366644776312914 MSE test 11.841482705955901\n",
      "MAE train 1.5970173156795815 MAE test 2.4086491748710737\n",
      "Epoch 5731 / 10000 loss: 13.5336332321167\n",
      "MSE train 5.366520369879652 MSE test 11.841242140575057\n",
      "MAE train 1.5969990766408606 MAE test 2.4086181520957446\n",
      "Epoch 5732 / 10000 loss: 13.53314757347107\n",
      "MSE train 5.366400851942623 MSE test 11.841207538963301\n",
      "MAE train 1.5969774621768489 MAE test 2.408619347984481\n",
      "Epoch 5733 / 10000 loss: 13.532714605331421\n",
      "MSE train 5.366277434870786 MSE test 11.840902483892332\n",
      "MAE train 1.5969608447326438 MAE test 2.4085801397144158\n",
      "Epoch 5734 / 10000 loss: 13.532240867614746\n",
      "MSE train 5.36614928610806 MSE test 11.84092220447568\n",
      "MAE train 1.5969359172337478 MAE test 2.4085882531853398\n",
      "Epoch 5735 / 10000 loss: 13.531855344772339\n",
      "MSE train 5.366023895059663 MSE test 11.84062346581107\n",
      "MAE train 1.5969186267169782 MAE test 2.4085498092262525\n",
      "Epoch 5736 / 10000 loss: 13.531310081481934\n",
      "MSE train 5.365901025652271 MSE test 11.840636443118491\n",
      "MAE train 1.5968951680676788 MAE test 2.408557065902455\n",
      "Epoch 5737 / 10000 loss: 13.530914068222046\n",
      "MSE train 5.365776156661541 MSE test 11.84031659227264\n",
      "MAE train 1.5968784816355956 MAE test 2.408515955682482\n",
      "Epoch 5738 / 10000 loss: 13.530391693115234\n",
      "MSE train 5.365643420567229 MSE test 11.840337393056961\n",
      "MAE train 1.5968523353546318 MAE test 2.408524202025111\n",
      "Epoch 5739 / 10000 loss: 13.530014514923096\n",
      "MSE train 5.365516964839918 MSE test 11.840062871398457\n",
      "MAE train 1.5968342134251587 MAE test 2.40848880233615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5740 / 10000 loss: 13.529447793960571\n",
      "MSE train 5.365401398774611 MSE test 11.840056377434495\n",
      "MAE train 1.596813021305649 MAE test 2.4084935682709117\n",
      "Epoch 5741 / 10000 loss: 13.529029130935669\n",
      "MSE train 5.365277698467498 MSE test 11.839714112014354\n",
      "MAE train 1.5967970884529987 MAE test 2.408449609423658\n",
      "Epoch 5742 / 10000 loss: 13.528549432754517\n",
      "MSE train 5.365134742737619 MSE test 11.839739191220959\n",
      "MAE train 1.596768223132492 MAE test 2.408458370510273\n",
      "Epoch 5743 / 10000 loss: 13.528193473815918\n",
      "MSE train 5.365013294368209 MSE test 11.839524506517753\n",
      "MAE train 1.5967501281237007 MAE test 2.4084305828160644\n",
      "Epoch 5744 / 10000 loss: 13.527584314346313\n",
      "MSE train 5.36488174586123 MSE test 11.839431336295197\n",
      "MAE train 1.596726628395387 MAE test 2.4084242578002124\n",
      "Epoch 5745 / 10000 loss: 13.527143716812134\n",
      "MSE train 5.364762051413458 MSE test 11.839229848989238\n",
      "MAE train 1.596708728281588 MAE test 2.408398170379659\n",
      "Epoch 5746 / 10000 loss: 13.526656866073608\n",
      "MSE train 5.364629486159422 MSE test 11.839128190441924\n",
      "MAE train 1.5966851790899943 MAE test 2.4083907719794526\n",
      "Epoch 5747 / 10000 loss: 13.526217222213745\n",
      "MSE train 5.364513962458566 MSE test 11.838947323730965\n",
      "MAE train 1.5966679518032774 MAE test 2.408367299937728\n",
      "Epoch 5748 / 10000 loss: 13.525732278823853\n",
      "MSE train 5.3643800211481905 MSE test 11.838807829873328\n",
      "MAE train 1.5966447870275202 MAE test 2.408355104163456\n",
      "Epoch 5749 / 10000 loss: 13.52529788017273\n",
      "MSE train 5.364273807251695 MSE test 11.838675729364567\n",
      "MAE train 1.5966289566618022 MAE test 2.408337854552405\n",
      "Epoch 5750 / 10000 loss: 13.524832248687744\n",
      "MSE train 5.364141534231894 MSE test 11.83845757224252\n",
      "MAE train 1.5966079080209268 MAE test 2.40831566103234\n",
      "Epoch 5751 / 10000 loss: 13.524402141571045\n",
      "MSE train 5.364007245995857 MSE test 11.838358664914333\n",
      "MAE train 1.5965842012000226 MAE test 2.4083026122788294\n",
      "Epoch 5752 / 10000 loss: 13.524002313613892\n",
      "MSE train 5.363877162811061 MSE test 11.838271431230734\n",
      "MAE train 1.596560889148069 MAE test 2.4082970057910185\n",
      "Epoch 5753 / 10000 loss: 13.5234375\n",
      "MSE train 5.36375407614989 MSE test 11.838047086188372\n",
      "MAE train 1.5965426280914423 MAE test 2.4082679550688924\n",
      "Epoch 5754 / 10000 loss: 13.522950649261475\n",
      "MSE train 5.36362726678531 MSE test 11.837980104205286\n",
      "MAE train 1.596519759869543 MAE test 2.4082649466140156\n",
      "Epoch 5755 / 10000 loss: 13.52251148223877\n",
      "MSE train 5.36350272119997 MSE test 11.837732325853935\n",
      "MAE train 1.5965015929878688 MAE test 2.4082329256378965\n",
      "Epoch 5756 / 10000 loss: 13.522027015686035\n",
      "MSE train 5.36338493887826 MSE test 11.837704826996317\n",
      "MAE train 1.5964802611430753 MAE test 2.4082349585307075\n",
      "Epoch 5757 / 10000 loss: 13.521597623825073\n",
      "MSE train 5.363261905949865 MSE test 11.837383825068315\n",
      "MAE train 1.5964640609951426 MAE test 2.4081936290647223\n",
      "Epoch 5758 / 10000 loss: 13.521125078201294\n",
      "MSE train 5.363126835878668 MSE test 11.837405866002982\n",
      "MAE train 1.5964372777385107 MAE test 2.4082019621219417\n",
      "Epoch 5759 / 10000 loss: 13.520753622055054\n",
      "MSE train 5.363000584196022 MSE test 11.837140110073367\n",
      "MAE train 1.5964190104951343 MAE test 2.4081676171773228\n",
      "Epoch 5760 / 10000 loss: 13.520177841186523\n",
      "MSE train 5.362885013852445 MSE test 11.837123289538942\n",
      "MAE train 1.5963979945529712 MAE test 2.408170988300756\n",
      "Epoch 5761 / 10000 loss: 13.519753456115723\n",
      "MSE train 5.362761448069533 MSE test 11.836784736224296\n",
      "MAE train 1.5963820010626424 MAE test 2.4081274163259834\n",
      "Epoch 5762 / 10000 loss: 13.519279956817627\n",
      "MSE train 5.362620001276906 MSE test 11.836807978561954\n",
      "MAE train 1.5963535265993591 MAE test 2.4081358860839734\n",
      "Epoch 5763 / 10000 loss: 13.518921136856079\n",
      "MSE train 5.362496619166388 MSE test 11.836580760701313\n",
      "MAE train 1.5963352076081567 MAE test 2.4081063941869085\n",
      "Epoch 5764 / 10000 loss: 13.51831841468811\n",
      "MSE train 5.362368697605267 MSE test 11.836506578054992\n",
      "MAE train 1.596312173878524 MAE test 2.4081024185520796\n",
      "Epoch 5765 / 10000 loss: 13.51787805557251\n",
      "MSE train 5.362244336639529 MSE test 11.836265737341657\n",
      "MAE train 1.596293903863177 MAE test 2.4080712157892337\n",
      "Epoch 5766 / 10000 loss: 13.517392635345459\n",
      "MSE train 5.362123947984379 MSE test 11.836225353182872\n",
      "MAE train 1.5962721434950498 MAE test 2.408071557516317\n",
      "Epoch 5767 / 10000 loss: 13.516958475112915\n",
      "MSE train 5.362000153054512 MSE test 11.835923568587265\n",
      "MAE train 1.5962552941421355 MAE test 2.4080326126911307\n",
      "Epoch 5768 / 10000 loss: 13.516483783721924\n",
      "MSE train 5.3618746315816 MSE test 11.835938010479556\n",
      "MAE train 1.5962311139615277 MAE test 2.4080399263897045\n",
      "Epoch 5769 / 10000 loss: 13.516093969345093\n",
      "MSE train 5.361749706158285 MSE test 11.83562439354879\n",
      "MAE train 1.5962142156734715 MAE test 2.407999457396645\n",
      "Epoch 5770 / 10000 loss: 13.51556134223938\n",
      "MSE train 5.361620786392877 MSE test 11.835639943550087\n",
      "MAE train 1.5961891115508409 MAE test 2.4080068919183613\n",
      "Epoch 5771 / 10000 loss: 13.515177011489868\n",
      "MSE train 5.361494678532041 MSE test 11.83534337049451\n",
      "MAE train 1.5961715264313558 MAE test 2.4079685541620934\n",
      "Epoch 5772 / 10000 loss: 13.514627456665039\n",
      "MSE train 5.361374185124588 MSE test 11.835349212524067\n",
      "MAE train 1.5961487640516632 MAE test 2.407974739118739\n",
      "Epoch 5773 / 10000 loss: 13.514226198196411\n",
      "MSE train 5.361249468087056 MSE test 11.835017127334126\n",
      "MAE train 1.596132316955792 MAE test 2.4079318974486412\n",
      "Epoch 5774 / 10000 loss: 13.513715505599976\n",
      "MSE train 5.36111215426806 MSE test 11.83503680475858\n",
      "MAE train 1.5961049521852235 MAE test 2.407939844202705\n",
      "Epoch 5775 / 10000 loss: 13.513346672058105\n",
      "MSE train 5.360986044896515 MSE test 11.834783064467354\n",
      "MAE train 1.596086451139914 MAE test 2.407906897746459\n",
      "Epoch 5776 / 10000 loss: 13.512762069702148\n",
      "MSE train 5.360867384287663 MSE test 11.834745668087603\n",
      "MAE train 1.5960650210635043 MAE test 2.407907550725074\n",
      "Epoch 5777 / 10000 loss: 13.5123291015625\n",
      "MSE train 5.360743303270632 MSE test 11.834430122775021\n",
      "MAE train 1.5960483798766067 MAE test 2.407866774408588\n",
      "Epoch 5778 / 10000 loss: 13.511855125427246\n",
      "MSE train 5.360612627844503 MSE test 11.834446513705545\n",
      "MAE train 1.5960228116248572 MAE test 2.4078742626871046\n",
      "Epoch 5779 / 10000 loss: 13.511474609375\n",
      "MSE train 5.360486334121601 MSE test 11.83415606255829\n",
      "MAE train 1.5960050389058444 MAE test 2.407836647204566\n",
      "Epoch 5780 / 10000 loss: 13.51091742515564\n",
      "MSE train 5.360368096898574 MSE test 11.834156441479985\n",
      "MAE train 1.5959829345256453 MAE test 2.407842064291306\n",
      "Epoch 5781 / 10000 loss: 13.510510444641113\n",
      "MSE train 5.360243646611283 MSE test 11.833815394566086\n",
      "MAE train 1.5959667230906538 MAE test 2.4077980143680313\n",
      "Epoch 5782 / 10000 loss: 13.510013103485107\n",
      "MSE train 5.360102687814892 MSE test 11.83383528125616\n",
      "MAE train 1.5959384016852405 MAE test 2.4078059141877515\n",
      "Epoch 5783 / 10000 loss: 13.50965142250061\n",
      "MSE train 5.359978545156316 MSE test 11.83360178032659\n",
      "MAE train 1.5959199845823742 MAE test 2.4077754761652126\n",
      "Epoch 5784 / 10000 loss: 13.50905156135559\n",
      "MSE train 5.359851670734081 MSE test 11.833530475180863\n",
      "MAE train 1.5958971299164182 MAE test 2.4077717113087447\n",
      "Epoch 5785 / 10000 loss: 13.50861144065857\n",
      "MSE train 5.35972661800913 MSE test 11.83327600278151\n",
      "MAE train 1.595878900987797 MAE test 2.4077386000814798\n",
      "Epoch 5786 / 10000 loss: 13.508126974105835\n",
      "MSE train 5.359609117484028 MSE test 11.833246414911947\n",
      "MAE train 1.5958576188309253 MAE test 2.407740132758866\n",
      "Epoch 5787 / 10000 loss: 13.507698059082031\n",
      "MSE train 5.359485687835288 MSE test 11.8329182271025\n",
      "MAE train 1.595841409050264 MAE test 2.407697676643204\n",
      "Epoch 5788 / 10000 loss: 13.507225513458252\n",
      "MSE train 5.359348896758438 MSE test 11.832936505122804\n",
      "MAE train 1.595814205217481 MAE test 2.4077053054965827\n",
      "Epoch 5789 / 10000 loss: 13.506856203079224\n",
      "MSE train 5.359222528753485 MSE test 11.832674839347298\n",
      "MAE train 1.5957957595611423 MAE test 2.407671235484906\n",
      "Epoch 5790 / 10000 loss: 13.506274223327637\n",
      "MSE train 5.359105429745516 MSE test 11.832643895265775\n",
      "MAE train 1.595774573391694 MAE test 2.4076725647593915\n",
      "Epoch 5791 / 10000 loss: 13.505844354629517\n",
      "MSE train 5.358981426238326 MSE test 11.83231277501327\n",
      "MAE train 1.5957582581675962 MAE test 2.4076296785197915\n",
      "Epoch 5792 / 10000 loss: 13.505371570587158\n",
      "MSE train 5.358844302274764 MSE test 11.832330035787678\n",
      "MAE train 1.5957309723243296 MAE test 2.4076371301013855\n",
      "Epoch 5793 / 10000 loss: 13.505002737045288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.358717835839445 MSE test 11.832069730191037\n",
      "MAE train 1.5957124670199803 MAE test 2.407603184894478\n",
      "Epoch 5794 / 10000 loss: 13.504419326782227\n",
      "MSE train 5.358600036118753 MSE test 11.832034616950853\n",
      "MAE train 1.5956911793664776 MAE test 2.407603927497406\n",
      "Epoch 5795 / 10000 loss: 13.503987550735474\n",
      "MSE train 5.358475926004712 MSE test 11.831707256814308\n",
      "MAE train 1.5956747345970452 MAE test 2.4075614589487366\n",
      "Epoch 5796 / 10000 loss: 13.50351357460022\n",
      "MSE train 5.358340795320452 MSE test 11.831722376789784\n",
      "MAE train 1.5956480034126252 MAE test 2.407568572132076\n",
      "Epoch 5797 / 10000 loss: 13.503139972686768\n",
      "MSE train 5.358213966105916 MSE test 11.831449266613888\n",
      "MAE train 1.5956296450429135 MAE test 2.4075329327168435\n",
      "Epoch 5798 / 10000 loss: 13.502565145492554\n",
      "MSE train 5.358097938784724 MSE test 11.831427000587134\n",
      "MAE train 1.5956085513508256 MAE test 2.4075352512993766\n",
      "Epoch 5799 / 10000 loss: 13.502140760421753\n",
      "MSE train 5.357973798631965 MSE test 11.83108162503467\n",
      "MAE train 1.5955924483959694 MAE test 2.4074904273862914\n",
      "Epoch 5800 / 10000 loss: 13.501665592193604\n",
      "MSE train 5.357831645303986 MSE test 11.831098133048743\n",
      "MAE train 1.5955638553892573 MAE test 2.407497653915235\n",
      "Epoch 5801 / 10000 loss: 13.50130581855774\n",
      "MSE train 5.3577078663141195 MSE test 11.83086550303395\n",
      "MAE train 1.5955454465190109 MAE test 2.407467087947834\n",
      "Epoch 5802 / 10000 loss: 13.500701904296875\n",
      "MSE train 5.35757892999757 MSE test 11.830781753538242\n",
      "MAE train 1.5955222440253167 MAE test 2.4074614712096896\n",
      "Epoch 5803 / 10000 loss: 13.50025987625122\n",
      "MSE train 5.357454215670926 MSE test 11.830538747060807\n",
      "MAE train 1.5955038532070116 MAE test 2.4074295616685997\n",
      "Epoch 5804 / 10000 loss: 13.499773502349854\n",
      "MSE train 5.357331511041156 MSE test 11.830483761690903\n",
      "MAE train 1.5954817038959739 MAE test 2.407427583703887\n",
      "Epoch 5805 / 10000 loss: 13.49933671951294\n",
      "MSE train 5.3572065989699835 MSE test 11.830187773305301\n",
      "MAE train 1.5954643138121996 MAE test 2.407388905526766\n",
      "Epoch 5806 / 10000 loss: 13.498857259750366\n",
      "MSE train 5.357085916851218 MSE test 11.83018725420646\n",
      "MAE train 1.5954415730995604 MAE test 2.4073938424475725\n",
      "Epoch 5807 / 10000 loss: 13.498454809188843\n",
      "MSE train 5.356961205735454 MSE test 11.829843889963081\n",
      "MAE train 1.5954252568396425 MAE test 2.4073490884619955\n",
      "Epoch 5808 / 10000 loss: 13.497946977615356\n",
      "MSE train 5.356820899294248 MSE test 11.82985672229024\n",
      "MAE train 1.5953971629912402 MAE test 2.407355668789029\n",
      "Epoch 5809 / 10000 loss: 13.497581720352173\n",
      "MSE train 5.356695067041356 MSE test 11.82960781163059\n",
      "MAE train 1.5953785456797136 MAE test 2.4073228347610764\n",
      "Epoch 5810 / 10000 loss: 13.49698543548584\n",
      "MSE train 5.356571043892421 MSE test 11.829543264505396\n",
      "MAE train 1.5953561985889506 MAE test 2.4073194766560833\n",
      "Epoch 5811 / 10000 loss: 13.496545791625977\n",
      "MSE train 5.356445144891276 MSE test 11.829253192204394\n",
      "MAE train 1.5953383918992408 MAE test 2.4072813797218062\n",
      "Epoch 5812 / 10000 loss: 13.496063709259033\n",
      "MSE train 5.356327126572699 MSE test 11.829242466989129\n",
      "MAE train 1.5953164883299513 MAE test 2.407284835697142\n",
      "Epoch 5813 / 10000 loss: 13.495651960372925\n",
      "MSE train 5.356202440112442 MSE test 11.828887952475448\n",
      "MAE train 1.5953003603737523 MAE test 2.4072385109362378\n",
      "Epoch 5814 / 10000 loss: 13.49515962600708\n",
      "MSE train 5.356058422657233 MSE test 11.828898645658407\n",
      "MAE train 1.5952713299570924 MAE test 2.407244625950859\n",
      "Epoch 5815 / 10000 loss: 13.49480152130127\n",
      "MSE train 5.355935536719245 MSE test 11.828669054637933\n",
      "MAE train 1.5952529820523933 MAE test 2.407214069019637\n",
      "Epoch 5816 / 10000 loss: 13.49419116973877\n",
      "MSE train 5.355802922812377 MSE test 11.828562234976188\n",
      "MAE train 1.595229266921468 MAE test 2.4072051150191642\n",
      "Epoch 5817 / 10000 loss: 13.493747234344482\n",
      "MSE train 5.3556812925282555 MSE test 11.828342381403582\n",
      "MAE train 1.5952110417686836 MAE test 2.407175736547307\n",
      "Epoch 5818 / 10000 loss: 13.49325704574585\n",
      "MSE train 5.3555478924492785 MSE test 11.828229506432558\n",
      "MAE train 1.5951872595525731 MAE test 2.4071659252963684\n",
      "Epoch 5819 / 10000 loss: 13.492813348770142\n",
      "MSE train 5.355428779504561 MSE test 11.828022966255329\n",
      "MAE train 1.5951694018188745 MAE test 2.407138158973994\n",
      "Epoch 5820 / 10000 loss: 13.492323637008667\n",
      "MSE train 5.355293403909361 MSE test 11.827882855506017\n",
      "MAE train 1.5951456204351473 MAE test 2.407124780159992\n",
      "Epoch 5821 / 10000 loss: 13.491882801055908\n",
      "MSE train 5.355183055569222 MSE test 11.827713107917155\n",
      "MAE train 1.5951292745691255 MAE test 2.4071015886701788\n",
      "Epoch 5822 / 10000 loss: 13.49140191078186\n",
      "MSE train 5.355048991755833 MSE test 11.827498113076174\n",
      "MAE train 1.5951073846472554 MAE test 2.4070786148998047\n",
      "Epoch 5823 / 10000 loss: 13.490971565246582\n",
      "MSE train 5.354921565008299 MSE test 11.827376140169788\n",
      "MAE train 1.5950856594856493 MAE test 2.4070614164427933\n",
      "Epoch 5824 / 10000 loss: 13.490547895431519\n",
      "MSE train 5.354783924788 MSE test 11.827211736664228\n",
      "MAE train 1.5950616867028131 MAE test 2.4070446937719625\n",
      "Epoch 5825 / 10000 loss: 13.49001407623291\n",
      "MSE train 5.354675487048377 MSE test 11.827050731696374\n",
      "MAE train 1.5950455658430744 MAE test 2.407022379280933\n",
      "Epoch 5826 / 10000 loss: 13.489537954330444\n",
      "MSE train 5.354540241219108 MSE test 11.82681174566852\n",
      "MAE train 1.595023779002749 MAE test 2.406996094572249\n",
      "Epoch 5827 / 10000 loss: 13.48910403251648\n",
      "MSE train 5.3544050874644515 MSE test 11.826686632077408\n",
      "MAE train 1.595000036925916 MAE test 2.4069781937061667\n",
      "Epoch 5828 / 10000 loss: 13.488692045211792\n",
      "MSE train 5.354270076134581 MSE test 11.826560115158088\n",
      "MAE train 1.5949758738668234 MAE test 2.406965956062329\n",
      "Epoch 5829 / 10000 loss: 13.488126993179321\n",
      "MSE train 5.354147455407803 MSE test 11.826329259796351\n",
      "MAE train 1.5949574022798114 MAE test 2.4069343731678727\n",
      "Epoch 5830 / 10000 loss: 13.48763132095337\n",
      "MSE train 5.354011276614427 MSE test 11.82619300564659\n",
      "MAE train 1.5949331405432925 MAE test 2.406920700166942\n",
      "Epoch 5831 / 10000 loss: 13.487181663513184\n",
      "MSE train 5.353892958868369 MSE test 11.825982740244253\n",
      "MAE train 1.5949153326430072 MAE test 2.406891486418925\n",
      "Epoch 5832 / 10000 loss: 13.486687183380127\n",
      "MSE train 5.353755122757383 MSE test 11.82580035155915\n",
      "MAE train 1.5948914725560608 MAE test 2.406871664304349\n",
      "Epoch 5833 / 10000 loss: 13.486242294311523\n",
      "MSE train 5.353643941638512 MSE test 11.825636989248192\n",
      "MAE train 1.5948744653827995 MAE test 2.4068481324934545\n",
      "Epoch 5834 / 10000 loss: 13.485768556594849\n",
      "MSE train 5.353506664253264 MSE test 11.825376586590579\n",
      "MAE train 1.594852294595184 MAE test 2.4068180747821106\n",
      "Epoch 5835 / 10000 loss: 13.485317468643188\n",
      "MSE train 5.353366671584777 MSE test 11.82523388745943\n",
      "MAE train 1.5948273673427937 MAE test 2.406796739743624\n",
      "Epoch 5836 / 10000 loss: 13.484901428222656\n",
      "MSE train 5.353230949153903 MSE test 11.825100787786967\n",
      "MAE train 1.5948027409605174 MAE test 2.4067823629675\n",
      "Epoch 5837 / 10000 loss: 13.48431658744812\n",
      "MSE train 5.353100256028096 MSE test 11.824820941247168\n",
      "MAE train 1.5947828169506584 MAE test 2.406743045689427\n",
      "Epoch 5838 / 10000 loss: 13.483806848526001\n",
      "MSE train 5.352966774308421 MSE test 11.824703260202266\n",
      "MAE train 1.5947583068427336 MAE test 2.4067300409798045\n",
      "Epoch 5839 / 10000 loss: 13.483342170715332\n",
      "MSE train 5.352832228622493 MSE test 11.824380121543307\n",
      "MAE train 1.5947380066410184 MAE test 2.4066844805828405\n",
      "Epoch 5840 / 10000 loss: 13.482829332351685\n",
      "MSE train 5.352704920716539 MSE test 11.82429667585227\n",
      "MAE train 1.594714109492544 MAE test 2.4066750211659307\n",
      "Epoch 5841 / 10000 loss: 13.48236894607544\n",
      "MSE train 5.352567587893529 MSE test 11.82387949101974\n",
      "MAE train 1.5946946953700027 MAE test 2.4066167082534418\n",
      "Epoch 5842 / 10000 loss: 13.48184871673584\n",
      "MSE train 5.352407152701558 MSE test 11.823814359884706\n",
      "MAE train 1.594661391610545 MAE test 2.406608621747551\n",
      "Epoch 5843 / 10000 loss: 13.481434106826782\n",
      "MSE train 5.352260990291803 MSE test 11.823491672995614\n",
      "MAE train 1.5946369845558301 MAE test 2.406561086460111\n",
      "Epoch 5844 / 10000 loss: 13.480751752853394\n",
      "MSE train 5.352098871927099 MSE test 11.823288223480937\n",
      "MAE train 1.5946050557798457 MAE test 2.406533835983642\n",
      "Epoch 5845 / 10000 loss: 13.48020887374878\n",
      "MSE train 5.351930182821135 MSE test 11.822927442525469\n",
      "MAE train 1.5945742892465224 MAE test 2.406479192280279\n",
      "Epoch 5846 / 10000 loss: 13.479580163955688\n",
      "MSE train 5.351733964160676 MSE test 11.822689122760698\n",
      "MAE train 1.5945321034224316 MAE test 2.4064444779500485\n",
      "Epoch 5847 / 10000 loss: 13.478934526443481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.3515040722501785 MSE test 11.822247640349783\n",
      "MAE train 1.5944836877376782 MAE test 2.40637619327596\n",
      "Epoch 5848 / 10000 loss: 13.478135347366333\n",
      "MSE train 5.351229235362956 MSE test 11.821976210307406\n",
      "MAE train 1.5944173152275178 MAE test 2.4063351734504317\n",
      "Epoch 5849 / 10000 loss: 13.477211952209473\n",
      "MSE train 5.350925230885271 MSE test 11.821426297249321\n",
      "MAE train 1.594347643355022 MAE test 2.4062541816855245\n",
      "Epoch 5850 / 10000 loss: 13.476007461547852\n",
      "MSE train 5.350669003649181 MSE test 11.821246228074363\n",
      "MAE train 1.594284660701672 MAE test 2.406229348246807\n",
      "Epoch 5851 / 10000 loss: 13.474760055541992\n",
      "MSE train 5.350484684001007 MSE test 11.820831023266308\n",
      "MAE train 1.5942497118712928 MAE test 2.4061725805291685\n",
      "Epoch 5852 / 10000 loss: 13.47359561920166\n",
      "MSE train 5.350333397607694 MSE test 11.820786051282528\n",
      "MAE train 1.5942181521692746 MAE test 2.4061709233282547\n",
      "Epoch 5853 / 10000 loss: 13.472915649414062\n",
      "MSE train 5.350192494345389 MSE test 11.820441408498185\n",
      "MAE train 1.5941970452131677 MAE test 2.4061261260101405\n",
      "Epoch 5854 / 10000 loss: 13.472257137298584\n",
      "MSE train 5.350051868208594 MSE test 11.820443113795333\n",
      "MAE train 1.594168913125645 MAE test 2.4061318582307596\n",
      "Epoch 5855 / 10000 loss: 13.471801996231079\n",
      "MSE train 5.349917410562262 MSE test 11.820147265537038\n",
      "MAE train 1.5941490606168411 MAE test 2.406094000752382\n",
      "Epoch 5856 / 10000 loss: 13.47119927406311\n",
      "MSE train 5.349792796304971 MSE test 11.820146103908217\n",
      "MAE train 1.594125434310911 MAE test 2.4060997650973097\n",
      "Epoch 5857 / 10000 loss: 13.470757007598877\n",
      "MSE train 5.349662612671768 MSE test 11.81980806859485\n",
      "MAE train 1.5941078536708948 MAE test 2.4060568278383765\n",
      "Epoch 5858 / 10000 loss: 13.470231771469116\n",
      "MSE train 5.349517072891555 MSE test 11.819830827218789\n",
      "MAE train 1.594078530897349 MAE test 2.406065774509499\n",
      "Epoch 5859 / 10000 loss: 13.469845533370972\n",
      "MSE train 5.3493881407131445 MSE test 11.81960134430896\n",
      "MAE train 1.5940590986507834 MAE test 2.4060366551691588\n",
      "Epoch 5860 / 10000 loss: 13.46922755241394\n",
      "MSE train 5.349257522152147 MSE test 11.819537102223617\n",
      "MAE train 1.5940354555274667 MAE test 2.4060345638716956\n",
      "Epoch 5861 / 10000 loss: 13.468767881393433\n",
      "MSE train 5.349128064048757 MSE test 11.819285014770605\n",
      "MAE train 1.5940164186204206 MAE test 2.406002634116595\n",
      "Epoch 5862 / 10000 loss: 13.468268394470215\n",
      "MSE train 5.34900721976347 MSE test 11.819266003729382\n",
      "MAE train 1.593994459049221 MAE test 2.4060063286534965\n",
      "Epoch 5863 / 10000 loss: 13.467824220657349\n",
      "MSE train 5.348879684507887 MSE test 11.818938411418223\n",
      "MAE train 1.5939775932100775 MAE test 2.40596489333052\n",
      "Epoch 5864 / 10000 loss: 13.46733570098877\n",
      "MSE train 5.348736103669343 MSE test 11.818963720540756\n",
      "MAE train 1.5939489356284897 MAE test 2.4059742487109435\n",
      "Epoch 5865 / 10000 loss: 13.46695613861084\n",
      "MSE train 5.348606407343362 MSE test 11.818725610923867\n",
      "MAE train 1.5939296695066978 MAE test 2.4059441428251644\n",
      "Epoch 5866 / 10000 loss: 13.466347455978394\n",
      "MSE train 5.348480044157828 MSE test 11.818679027113747\n",
      "MAE train 1.593906931705067 MAE test 2.405944333008798\n",
      "Epoch 5867 / 10000 loss: 13.465893983840942\n",
      "MSE train 5.348350719817521 MSE test 11.818393818096517\n",
      "MAE train 1.5938887637267412 MAE test 2.4059082570406547\n",
      "Epoch 5868 / 10000 loss: 13.465400457382202\n",
      "MSE train 5.3482263838302915 MSE test 11.818403047616153\n",
      "MAE train 1.5938654739594658 MAE test 2.405915599543914\n",
      "Epoch 5869 / 10000 loss: 13.46498155593872\n",
      "MSE train 5.348097415116906 MSE test 11.818071857627265\n",
      "MAE train 1.5938484360774976 MAE test 2.40587372515955\n",
      "Epoch 5870 / 10000 loss: 13.464460372924805\n",
      "MSE train 5.347953110406487 MSE test 11.818095990927048\n",
      "MAE train 1.5938197054758965 MAE test 2.405882951468823\n",
      "Epoch 5871 / 10000 loss: 13.46407961845398\n",
      "MSE train 5.347823050538323 MSE test 11.817859567528732\n",
      "MAE train 1.5938004145512426 MAE test 2.405853075321811\n",
      "Epoch 5872 / 10000 loss: 13.463467836380005\n",
      "MSE train 5.3476949040266115 MSE test 11.817806950999667\n",
      "MAE train 1.5937774028002953 MAE test 2.4058525161711444\n",
      "Epoch 5873 / 10000 loss: 13.463011980056763\n",
      "MSE train 5.347564679579123 MSE test 11.817530344916225\n",
      "MAE train 1.59375889784827 MAE test 2.4058175620508\n",
      "Epoch 5874 / 10000 loss: 13.462515830993652\n",
      "MSE train 5.3474423643599085 MSE test 11.817532228068814\n",
      "MAE train 1.5937363272362453 MAE test 2.4058239479746524\n",
      "Epoch 5875 / 10000 loss: 13.462088346481323\n",
      "MSE train 5.347313151435003 MSE test 11.817192160556111\n",
      "MAE train 1.5937194766186515 MAE test 2.4057810105330915\n",
      "Epoch 5876 / 10000 loss: 13.461578845977783\n",
      "MSE train 5.347165006901307 MSE test 11.81721621349524\n",
      "MAE train 1.5936898091406713 MAE test 2.4057902152138473\n",
      "Epoch 5877 / 10000 loss: 13.461204051971436\n",
      "MSE train 5.347037472788642 MSE test 11.817000597604572\n",
      "MAE train 1.593670753391192 MAE test 2.40576301264527\n",
      "Epoch 5878 / 10000 loss: 13.460577964782715\n",
      "MSE train 5.346900840556717 MSE test 11.81690950326749\n",
      "MAE train 1.5936463896074307 MAE test 2.4057575500885786\n",
      "Epoch 5879 / 10000 loss: 13.460117816925049\n",
      "MSE train 5.34677424233264 MSE test 11.816702999338094\n",
      "MAE train 1.5936274243664341 MAE test 2.405731535722264\n",
      "Epoch 5880 / 10000 loss: 13.459611654281616\n",
      "MSE train 5.346637241005426 MSE test 11.816610360210127\n",
      "MAE train 1.5936030248675541 MAE test 2.405725897752319\n",
      "Epoch 5881 / 10000 loss: 13.459153175354004\n",
      "MSE train 5.346512026210504 MSE test 11.816412371425912\n",
      "MAE train 1.593584230098524 MAE test 2.4057009715038933\n",
      "Epoch 5882 / 10000 loss: 13.458647012710571\n",
      "MSE train 5.346373536396395 MSE test 11.816305937511643\n",
      "MAE train 1.5935597412707936 MAE test 2.4056935750823523\n",
      "Epoch 5883 / 10000 loss: 13.4581880569458\n",
      "MSE train 5.3462534828724415 MSE test 11.816131166249066\n",
      "MAE train 1.5935418352382194 MAE test 2.405671611620011\n",
      "Epoch 5884 / 10000 loss: 13.457685947418213\n",
      "MSE train 5.346114164358624 MSE test 11.815978121711183\n",
      "MAE train 1.593518024287796 MAE test 2.4056582959874615\n",
      "Epoch 5885 / 10000 loss: 13.45723295211792\n",
      "MSE train 5.346000777514463 MSE test 11.815855554484308\n",
      "MAE train 1.5935007712680593 MAE test 2.4056429746144765\n",
      "Epoch 5886 / 10000 loss: 13.45675778388977\n",
      "MSE train 5.345862638135155 MSE test 11.815635345995474\n",
      "MAE train 1.5934786808366896 MAE test 2.4056211990645138\n",
      "Epoch 5887 / 10000 loss: 13.456296920776367\n",
      "MSE train 5.345722982064409 MSE test 11.815535460154207\n",
      "MAE train 1.5934541993043299 MAE test 2.40560875713474\n",
      "Epoch 5888 / 10000 loss: 13.455877542495728\n",
      "MSE train 5.3455872985589155 MSE test 11.815444204784157\n",
      "MAE train 1.5934299877729647 MAE test 2.4056032642385707\n",
      "Epoch 5889 / 10000 loss: 13.45529580116272\n",
      "MSE train 5.345459029266411 MSE test 11.815222184027098\n",
      "MAE train 1.5934108733659258 MAE test 2.405575279965713\n",
      "Epoch 5890 / 10000 loss: 13.454791784286499\n",
      "MSE train 5.345326143540178 MSE test 11.815148012690472\n",
      "MAE train 1.5933870291093948 MAE test 2.4055719831405598\n",
      "Epoch 5891 / 10000 loss: 13.454334497451782\n",
      "MSE train 5.345196712088189 MSE test 11.814908743414613\n",
      "MAE train 1.5933679508442642 MAE test 2.4055418251388336\n",
      "Epoch 5892 / 10000 loss: 13.45383358001709\n",
      "MSE train 5.345071384549776 MSE test 11.814866536355343\n",
      "MAE train 1.5933454081480718 MAE test 2.405542600113992\n",
      "Epoch 5893 / 10000 loss: 13.45338225364685\n",
      "MSE train 5.344942622982824 MSE test 11.81456620669038\n",
      "MAE train 1.593327721980818 MAE test 2.405504749263773\n",
      "Epoch 5894 / 10000 loss: 13.45289158821106\n",
      "MSE train 5.344812910725463 MSE test 11.814578384344099\n",
      "MAE train 1.5933029228515194 MAE test 2.405512445577462\n",
      "Epoch 5895 / 10000 loss: 13.452485799789429\n",
      "MSE train 5.3446831749990515 MSE test 11.814264192285737\n",
      "MAE train 1.5932852467443552 MAE test 2.405472836574621\n",
      "Epoch 5896 / 10000 loss: 13.451939821243286\n",
      "MSE train 5.344549309867262 MSE test 11.814278114924377\n",
      "MAE train 1.5932593256241814 MAE test 2.405480764180899\n",
      "Epoch 5897 / 10000 loss: 13.451541662216187\n",
      "MSE train 5.344418504244175 MSE test 11.813984495989484\n",
      "MAE train 1.5932408744221955 MAE test 2.4054437502475468\n",
      "Epoch 5898 / 10000 loss: 13.450976371765137\n",
      "MSE train 5.34429480619495 MSE test 11.81398615615751\n",
      "MAE train 1.5932177667272542 MAE test 2.4054501239275985\n",
      "Epoch 5899 / 10000 loss: 13.450558423995972\n",
      "MSE train 5.344165674254681 MSE test 11.813651273426485\n",
      "MAE train 1.5932006357251856 MAE test 2.4054079477700507\n",
      "Epoch 5900 / 10000 loss: 13.450039625167847\n",
      "MSE train 5.344022792338954 MSE test 11.813668595857791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5931722393740275 MAE test 2.405416292750195\n",
      "Epoch 5901 / 10000 loss: 13.449659824371338\n",
      "MSE train 5.343892840768311 MSE test 11.813423739752494\n",
      "MAE train 1.5931530054530627 MAE test 2.4053855183358097\n",
      "Epoch 5902 / 10000 loss: 13.449055433273315\n",
      "MSE train 5.34376700033279 MSE test 11.81337132505466\n",
      "MAE train 1.5931304075186332 MAE test 2.405385014581171\n",
      "Epoch 5903 / 10000 loss: 13.448605298995972\n",
      "MSE train 5.3436377520134375 MSE test 11.813078252752309\n",
      "MAE train 1.5931123174207076 MAE test 2.4053481746549146\n",
      "Epoch 5904 / 10000 loss: 13.448114395141602\n",
      "MSE train 5.343512799458956 MSE test 11.81308144247926\n",
      "MAE train 1.5930888526620326 MAE test 2.405354787120561\n",
      "Epoch 5905 / 10000 loss: 13.447700262069702\n",
      "MSE train 5.343383743862359 MSE test 11.812747932200729\n",
      "MAE train 1.5930717121804454 MAE test 2.4053128732285187\n",
      "Epoch 5906 / 10000 loss: 13.447176933288574\n",
      "MSE train 5.343241133525867 MSE test 11.812763592872255\n",
      "MAE train 1.5930434441261794 MAE test 2.405321095981187\n",
      "Epoch 5907 / 10000 loss: 13.446794748306274\n",
      "MSE train 5.343110254623349 MSE test 11.812512449886565\n",
      "MAE train 1.5930240912215452 MAE test 2.405289609783676\n",
      "Epoch 5908 / 10000 loss: 13.446192026138306\n",
      "MSE train 5.342985422393573 MSE test 11.812464661941371\n",
      "MAE train 1.5930016785736107 MAE test 2.405289773088731\n",
      "Epoch 5909 / 10000 loss: 13.445742130279541\n",
      "MSE train 5.342855526996013 MSE test 11.812157112991715\n",
      "MAE train 1.592983797443304 MAE test 2.405251223261093\n",
      "Epoch 5910 / 10000 loss: 13.445250988006592\n",
      "MSE train 5.342724071606415 MSE test 11.812164163490547\n",
      "MAE train 1.5929586484476188 MAE test 2.4052583765813815\n",
      "Epoch 5911 / 10000 loss: 13.444843769073486\n",
      "MSE train 5.342592481724269 MSE test 11.811849728152783\n",
      "MAE train 1.5929405116306705 MAE test 2.405219009857838\n",
      "Epoch 5912 / 10000 loss: 13.444291114807129\n",
      "MSE train 5.342459058254989 MSE test 11.811855581640279\n",
      "MAE train 1.5929149343826632 MAE test 2.4052260636785725\n",
      "Epoch 5913 / 10000 loss: 13.443882465362549\n",
      "MSE train 5.342326086833904 MSE test 11.811546449972642\n",
      "MAE train 1.5928963759855208 MAE test 2.405187408157304\n",
      "Epoch 5914 / 10000 loss: 13.44331979751587\n",
      "MSE train 5.342195142120252 MSE test 11.811547146747662\n",
      "MAE train 1.5928715941073834 MAE test 2.405193856799869\n",
      "Epoch 5915 / 10000 loss: 13.442902565002441\n",
      "MSE train 5.342061529476113 MSE test 11.811222075978819\n",
      "MAE train 1.5928533153052487 MAE test 2.405153270854471\n",
      "Epoch 5916 / 10000 loss: 13.442352771759033\n",
      "MSE train 5.3419220406934675 MSE test 11.811227148030214\n",
      "MAE train 1.5928263521872845 MAE test 2.4051603316956003\n",
      "Epoch 5917 / 10000 loss: 13.441943883895874\n",
      "MSE train 5.341785598342857 MSE test 11.810932332119204\n",
      "MAE train 1.5928067753647916 MAE test 2.405123633579582\n",
      "Epoch 5918 / 10000 loss: 13.441356420516968\n",
      "MSE train 5.341657830044973 MSE test 11.810917991301592\n",
      "MAE train 1.592783334036612 MAE test 2.4051283041563774\n",
      "Epoch 5919 / 10000 loss: 13.440912961959839\n",
      "MSE train 5.341521357355868 MSE test 11.810566482937581\n",
      "MAE train 1.5927651390085593 MAE test 2.405084576793002\n",
      "Epoch 5920 / 10000 loss: 13.440384149551392\n",
      "MSE train 5.34136676564836 MSE test 11.81057246973218\n",
      "MAE train 1.5927345503786514 MAE test 2.4050919185953874\n",
      "Epoch 5921 / 10000 loss: 13.439982652664185\n",
      "MSE train 5.341228437035388 MSE test 11.810333066478693\n",
      "MAE train 1.5927137101907511 MAE test 2.4050624222585775\n",
      "Epoch 5922 / 10000 loss: 13.439334630966187\n",
      "MSE train 5.341083236081769 MSE test 11.810236489922563\n",
      "MAE train 1.5926878370147626 MAE test 2.4050568483765145\n",
      "Epoch 5923 / 10000 loss: 13.438841819763184\n",
      "MSE train 5.340939983767716 MSE test 11.809985428592688\n",
      "MAE train 1.592666331659098 MAE test 2.405026021387252\n",
      "Epoch 5924 / 10000 loss: 13.438296794891357\n",
      "MSE train 5.340795658655067 MSE test 11.809913210705902\n",
      "MAE train 1.5926405998366275 MAE test 2.405023650669339\n",
      "Epoch 5925 / 10000 loss: 13.4377920627594\n",
      "MSE train 5.340646207202387 MSE test 11.80961025834037\n",
      "MAE train 1.5926189176303551 MAE test 2.404986382118605\n",
      "Epoch 5926 / 10000 loss: 13.437235116958618\n",
      "MSE train 5.340499602362066 MSE test 11.80958807476946\n",
      "MAE train 1.592592067797905 MAE test 2.4049904980617685\n",
      "Epoch 5927 / 10000 loss: 13.436738014221191\n",
      "MSE train 5.34034316571078 MSE test 11.809224290389222\n",
      "MAE train 1.5925704330410044 MAE test 2.4049456992680107\n",
      "Epoch 5928 / 10000 loss: 13.436136722564697\n",
      "MSE train 5.340164825007889 MSE test 11.809216442780343\n",
      "MAE train 1.5925356833304165 MAE test 2.404951715606081\n",
      "Epoch 5929 / 10000 loss: 13.435655117034912\n",
      "MSE train 5.34000032284341 MSE test 11.808963312899339\n",
      "MAE train 1.5925101873629923 MAE test 2.404920896011731\n",
      "Epoch 5930 / 10000 loss: 13.43491244316101\n",
      "MSE train 5.33982690949306 MSE test 11.808851602708138\n",
      "MAE train 1.5924793371773525 MAE test 2.4049138331432722\n",
      "Epoch 5931 / 10000 loss: 13.434314489364624\n",
      "MSE train 5.339655679943336 MSE test 11.808589044993186\n",
      "MAE train 1.5924528836321727 MAE test 2.4048819262629784\n",
      "Epoch 5932 / 10000 loss: 13.43365478515625\n",
      "MSE train 5.3394855458310095 MSE test 11.808504272254897\n",
      "MAE train 1.5924225588436198 MAE test 2.4048782384309955\n",
      "Epoch 5933 / 10000 loss: 13.433033466339111\n",
      "MSE train 5.33931651782652 MSE test 11.808198284940557\n",
      "MAE train 1.5923973096186028 MAE test 2.4048406953117025\n",
      "Epoch 5934 / 10000 loss: 13.432369709014893\n",
      "MSE train 5.339160663016202 MSE test 11.808172107420916\n",
      "MAE train 1.5923689958262668 MAE test 2.4048441142484918\n",
      "Epoch 5935 / 10000 loss: 13.431785106658936\n",
      "MSE train 5.339005270950778 MSE test 11.80781051426206\n",
      "MAE train 1.5923477018667809 MAE test 2.4047992340579185\n",
      "Epoch 5936 / 10000 loss: 13.431139945983887\n",
      "MSE train 5.338838606879559 MSE test 11.807814048339157\n",
      "MAE train 1.5923150083932434 MAE test 2.4048060379932603\n",
      "Epoch 5937 / 10000 loss: 13.430655479431152\n",
      "MSE train 5.33869897437338 MSE test 11.807585114751664\n",
      "MAE train 1.5922939365515896 MAE test 2.404777462674389\n",
      "Epoch 5938 / 10000 loss: 13.429949045181274\n",
      "MSE train 5.3385561040296725 MSE test 11.80748269634398\n",
      "MAE train 1.592268580990152 MAE test 2.4047704516251796\n",
      "Epoch 5939 / 10000 loss: 13.429433584213257\n",
      "MSE train 5.338426815223226 MSE test 11.807269299580069\n",
      "MAE train 1.5922491402606749 MAE test 2.4047436019351482\n",
      "Epoch 5940 / 10000 loss: 13.428890943527222\n",
      "MSE train 5.338290974297441 MSE test 11.80717294022322\n",
      "MAE train 1.592224899569154 MAE test 2.4047371192230482\n",
      "Epoch 5941 / 10000 loss: 13.428410291671753\n",
      "MSE train 5.338167730541149 MSE test 11.806970281074788\n",
      "MAE train 1.5922063815201624 MAE test 2.4047114537550716\n",
      "Epoch 5942 / 10000 loss: 13.42789363861084\n",
      "MSE train 5.338034603769567 MSE test 11.806869842973525\n",
      "MAE train 1.5921826556500964 MAE test 2.404704328420986\n",
      "Epoch 5943 / 10000 loss: 13.427430868148804\n",
      "MSE train 5.337916884294492 MSE test 11.80668537772862\n",
      "MAE train 1.5921649605406827 MAE test 2.404680863787753\n",
      "Epoch 5944 / 10000 loss: 13.426929950714111\n",
      "MSE train 5.337783766874105 MSE test 11.8065582940119\n",
      "MAE train 1.5921415593557018 MAE test 2.4046702896557757\n",
      "Epoch 5945 / 10000 loss: 13.426480531692505\n",
      "MSE train 5.337676752248446 MSE test 11.806416469647829\n",
      "MAE train 1.59212565086207 MAE test 2.404652172101774\n",
      "Epoch 5946 / 10000 loss: 13.425997018814087\n",
      "MSE train 5.337546139538443 MSE test 11.806214809452197\n",
      "MAE train 1.5921044018410293 MAE test 2.4046321817797742\n",
      "Epoch 5947 / 10000 loss: 13.425563335418701\n",
      "MSE train 5.337418980115018 MSE test 11.806120252474539\n",
      "MAE train 1.5920823334138587 MAE test 2.4046200272143956\n",
      "Epoch 5948 / 10000 loss: 13.425146341323853\n",
      "MSE train 5.337285967716886 MSE test 11.805996507061183\n",
      "MAE train 1.5920587714920074 MAE test 2.404609803812675\n",
      "Epoch 5949 / 10000 loss: 13.424601793289185\n",
      "MSE train 5.337178049612419 MSE test 11.805843648262288\n",
      "MAE train 1.5920427917552324 MAE test 2.40459026095\n",
      "Epoch 5950 / 10000 loss: 13.424119710922241\n",
      "MSE train 5.337047080912785 MSE test 11.805659959444602\n",
      "MAE train 1.5920210276962998 MAE test 2.4045724923191596\n",
      "Epoch 5951 / 10000 loss: 13.423690795898438\n",
      "MSE train 5.336928869067708 MSE test 11.805561750054215\n",
      "MAE train 1.5920013415337715 MAE test 2.4045598709799414\n",
      "Epoch 5952 / 10000 loss: 13.423261880874634\n",
      "MSE train 5.336796047685411 MSE test 11.805395382007815\n",
      "MAE train 1.5919787082640182 MAE test 2.4045442472469936\n",
      "Epoch 5953 / 10000 loss: 13.422758340835571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.33668727980771 MSE test 11.805286510843693\n",
      "MAE train 1.5919616395917064 MAE test 2.4045303034994663\n",
      "Epoch 5954 / 10000 loss: 13.42231035232544\n",
      "MSE train 5.336555816593839 MSE test 11.805083066957385\n",
      "MAE train 1.5919401894644958 MAE test 2.40451002978883\n",
      "Epoch 5955 / 10000 loss: 13.421850442886353\n",
      "MSE train 5.33642952702605 MSE test 11.804989278309312\n",
      "MAE train 1.59191830019817 MAE test 2.4044979966570543\n",
      "Epoch 5956 / 10000 loss: 13.421439409255981\n",
      "MSE train 5.33629699393524 MSE test 11.804868129389213\n",
      "MAE train 1.591894807887889 MAE test 2.4044880795048114\n",
      "Epoch 5957 / 10000 loss: 13.42090106010437\n",
      "MSE train 5.336188909026919 MSE test 11.80471416201109\n",
      "MAE train 1.5918788057149589 MAE test 2.404468418327686\n",
      "Epoch 5958 / 10000 loss: 13.420423746109009\n",
      "MSE train 5.336057994020773 MSE test 11.804536266124739\n",
      "MAE train 1.591856935382609 MAE test 2.404451376355959\n",
      "Epoch 5959 / 10000 loss: 13.419998168945312\n",
      "MSE train 5.335942381966552 MSE test 11.804437702572299\n",
      "MAE train 1.5918379191843017 MAE test 2.4044387447192923\n",
      "Epoch 5960 / 10000 loss: 13.419568538665771\n",
      "MSE train 5.335810205202084 MSE test 11.804262230373778\n",
      "MAE train 1.5918156538804356 MAE test 2.40442199823267\n",
      "Epoch 5961 / 10000 loss: 13.419078588485718\n",
      "MSE train 5.335697336483593 MSE test 11.804160477845413\n",
      "MAE train 1.5917973763599143 MAE test 2.4044089751562363\n",
      "Epoch 5962 / 10000 loss: 13.418643236160278\n",
      "MSE train 5.335565385858016 MSE test 11.803975008205102\n",
      "MAE train 1.591775383710449 MAE test 2.4043909712686933\n",
      "Epoch 5963 / 10000 loss: 13.418164730072021\n",
      "MSE train 5.335447843834481 MSE test 11.803877359186698\n",
      "MAE train 1.5917558382102879 MAE test 2.404378478785871\n",
      "Epoch 5964 / 10000 loss: 13.41773796081543\n",
      "MSE train 5.33531507491768 MSE test 11.80371282593015\n",
      "MAE train 1.5917331637164753 MAE test 2.4043631056942876\n",
      "Epoch 5965 / 10000 loss: 13.417238712310791\n",
      "MSE train 5.335207079804754 MSE test 11.803604591893075\n",
      "MAE train 1.5917162722654212 MAE test 2.4043492815721614\n",
      "Epoch 5966 / 10000 loss: 13.41679334640503\n",
      "MSE train 5.335075994770767 MSE test 11.803400952842152\n",
      "MAE train 1.591694888771128 MAE test 2.4043290157581647\n",
      "Epoch 5967 / 10000 loss: 13.41633915901184\n",
      "MSE train 5.334949428057842 MSE test 11.803308790004467\n",
      "MAE train 1.5916728758046388 MAE test 2.404317213900959\n",
      "Epoch 5968 / 10000 loss: 13.415931463241577\n",
      "MSE train 5.334817453991818 MSE test 11.803191952481047\n",
      "MAE train 1.591649420809349 MAE test 2.4043078621310863\n",
      "Epoch 5969 / 10000 loss: 13.415394306182861\n",
      "MSE train 5.334708424968248 MSE test 11.803034424540328\n",
      "MAE train 1.5916332358141903 MAE test 2.404287790669524\n",
      "Epoch 5970 / 10000 loss: 13.414917469024658\n",
      "MSE train 5.334577621945436 MSE test 11.802865980711342\n",
      "MAE train 1.591611158111194 MAE test 2.4042719670739987\n",
      "Epoch 5971 / 10000 loss: 13.414492845535278\n",
      "MSE train 5.334466150872373 MSE test 11.802764955742479\n",
      "MAE train 1.5915932442210947 MAE test 2.4042590683205036\n",
      "Epoch 5972 / 10000 loss: 13.414057731628418\n",
      "MSE train 5.3343350626190125 MSE test 11.802573367864268\n",
      "MAE train 1.5915715921584028 MAE test 2.4042403179655696\n",
      "Epoch 5973 / 10000 loss: 13.413587808609009\n",
      "MSE train 5.334213957238105 MSE test 11.80247937692038\n",
      "MAE train 1.59155105364044 MAE test 2.404228308535702\n",
      "Epoch 5974 / 10000 loss: 13.413169384002686\n",
      "MSE train 5.334081158982214 MSE test 11.802333263406393\n",
      "MAE train 1.5915279362554267 MAE test 2.404215259468941\n",
      "Epoch 5975 / 10000 loss: 13.412655115127563\n",
      "MSE train 5.333977263058729 MSE test 11.802211888653567\n",
      "MAE train 1.5915123636395039 MAE test 2.404199809886988\n",
      "Epoch 5976 / 10000 loss: 13.41219711303711\n",
      "MSE train 5.333847066991075 MSE test 11.801999069277857\n",
      "MAE train 1.5914913613410497 MAE test 2.404178401232475\n",
      "Epoch 5977 / 10000 loss: 13.411768674850464\n",
      "MSE train 5.3337163563815535 MSE test 11.801909451973692\n",
      "MAE train 1.5914682407202252 MAE test 2.4041669709882973\n",
      "Epoch 5978 / 10000 loss: 13.41137146949768\n",
      "MSE train 5.333588142325458 MSE test 11.80182002844349\n",
      "MAE train 1.5914451347994771 MAE test 2.404161064294122\n",
      "Epoch 5979 / 10000 loss: 13.410817861557007\n",
      "MSE train 5.333469209084417 MSE test 11.801618567394158\n",
      "MAE train 1.5914272834240986 MAE test 2.4041354977724922\n",
      "Epoch 5980 / 10000 loss: 13.41033673286438\n",
      "MSE train 5.333341671137694 MSE test 11.80153600206009\n",
      "MAE train 1.5914042605008774 MAE test 2.404130492832077\n",
      "Epoch 5981 / 10000 loss: 13.409902811050415\n",
      "MSE train 5.333223100325061 MSE test 11.801337957112839\n",
      "MAE train 1.5913864449727089 MAE test 2.404105360121799\n",
      "Epoch 5982 / 10000 loss: 13.409422874450684\n",
      "MSE train 5.333095613979799 MSE test 11.80125650798884\n",
      "MAE train 1.5913634227344184 MAE test 2.4041005029747717\n",
      "Epoch 5983 / 10000 loss: 13.40898871421814\n",
      "MSE train 5.332977210480779 MSE test 11.801060114779357\n",
      "MAE train 1.5913456224611804 MAE test 2.4040755869704964\n",
      "Epoch 5984 / 10000 loss: 13.408509254455566\n",
      "MSE train 5.332849544496563 MSE test 11.800977387335225\n",
      "MAE train 1.5913225910349555 MAE test 2.404070569121942\n",
      "Epoch 5985 / 10000 loss: 13.40807557106018\n",
      "MSE train 5.33273168106769 MSE test 11.800784321285533\n",
      "MAE train 1.5913048478424856 MAE test 2.4040460978777047\n",
      "Epoch 5986 / 10000 loss: 13.40759539604187\n",
      "MSE train 5.332603325899749 MSE test 11.80069621211884\n",
      "MAE train 1.591281764470149 MAE test 2.4040403932710506\n",
      "Epoch 5987 / 10000 loss: 13.407162189483643\n",
      "MSE train 5.332487225426494 MSE test 11.800512942484755\n",
      "MAE train 1.5912642763158453 MAE test 2.4040171535019454\n",
      "Epoch 5988 / 10000 loss: 13.406682968139648\n",
      "MSE train 5.3323571930845075 MSE test 11.80040648550377\n",
      "MAE train 1.5912411299576805 MAE test 2.4040091349669717\n",
      "Epoch 5989 / 10000 loss: 13.406250953674316\n",
      "MSE train 5.332247843031433 MSE test 11.80025201913875\n",
      "MAE train 1.591224825829679 MAE test 2.403989536407087\n",
      "Epoch 5990 / 10000 loss: 13.405776977539062\n",
      "MSE train 5.3321178779019185 MSE test 11.80008832540164\n",
      "MAE train 1.5912028259327702 MAE test 2.4039743462386443\n",
      "Epoch 5991 / 10000 loss: 13.405353784561157\n",
      "MSE train 5.332007519211577 MSE test 11.79998846481468\n",
      "MAE train 1.5911851688152154 MAE test 2.403961618553693\n",
      "Epoch 5992 / 10000 loss: 13.40491771697998\n",
      "MSE train 5.331877067440797 MSE test 11.799793291048639\n",
      "MAE train 1.5911637215244343 MAE test 2.403942462959809\n",
      "Epoch 5993 / 10000 loss: 13.404453039169312\n",
      "MSE train 5.331753937473761 MSE test 11.799702098649563\n",
      "MAE train 1.5911425913763468 MAE test 2.4039308442614207\n",
      "Epoch 5994 / 10000 loss: 13.404040813446045\n",
      "MSE train 5.331621535141987 MSE test 11.799568122683675\n",
      "MAE train 1.5911192944570394 MAE test 2.4039193482560486\n",
      "Epoch 5995 / 10000 loss: 13.403517484664917\n",
      "MSE train 5.331517576417928 MSE test 11.799435825579708\n",
      "MAE train 1.5911038938860644 MAE test 2.403902528750633\n",
      "Epoch 5996 / 10000 loss: 13.403052568435669\n",
      "MSE train 5.331387803138647 MSE test 11.799231803901932\n",
      "MAE train 1.5910827884996295 MAE test 2.4038822740506594\n",
      "Epoch 5997 / 10000 loss: 13.402631998062134\n",
      "MSE train 5.3312603578897715 MSE test 11.79914281369525\n",
      "MAE train 1.5910604776434314 MAE test 2.4038709300623085\n",
      "Epoch 5998 / 10000 loss: 13.402229070663452\n",
      "MSE train 5.3311294670970515 MSE test 11.799033634991169\n",
      "MAE train 1.5910370965809655 MAE test 2.403862573020384\n",
      "Epoch 5999 / 10000 loss: 13.40168809890747\n",
      "MSE train 5.331018263778283 MSE test 11.798868053436578\n",
      "MAE train 1.5910205099797219 MAE test 2.403841540107247\n",
      "Epoch 6000 / 10000 loss: 13.401211023330688\n",
      "MSE train 5.330887342835521 MSE test 11.798719628259082\n",
      "MAE train 1.59099790331538 MAE test 2.403828268467469\n",
      "Epoch 6001 / 10000 loss: 13.400784730911255\n",
      "MSE train 5.330782485088682 MSE test 11.798608142137406\n",
      "MAE train 1.5909818856077784 MAE test 2.4038140642709864\n",
      "Epoch 6002 / 10000 loss: 13.400334596633911\n",
      "MSE train 5.330652933367595 MSE test 11.798395558962953\n",
      "MAE train 1.590960985315457 MAE test 2.4037927444843863\n",
      "Epoch 6003 / 10000 loss: 13.39989948272705\n",
      "MSE train 5.330522243325655 MSE test 11.798307638137937\n",
      "MAE train 1.5909378301832602 MAE test 2.4037815500064124\n",
      "Epoch 6004 / 10000 loss: 13.399503707885742\n",
      "MSE train 5.330394564177724 MSE test 11.79821999372761\n",
      "MAE train 1.5909147824684886 MAE test 2.403775879310746\n",
      "Epoch 6005 / 10000 loss: 13.398950099945068\n",
      "MSE train 5.330275494133947 MSE test 11.798017239796565\n",
      "MAE train 1.590896911790439 MAE test 2.4037501952020817\n",
      "Epoch 6006 / 10000 loss: 13.398470163345337\n",
      "MSE train 5.330149023608729 MSE test 11.797939396609666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.590874008164885 MAE test 2.4037457692521094\n",
      "Epoch 6007 / 10000 loss: 13.398036479949951\n",
      "MSE train 5.330029453355786 MSE test 11.797734140486574\n",
      "MAE train 1.5908561017289033 MAE test 2.4037197783916895\n",
      "Epoch 6008 / 10000 loss: 13.397557735443115\n",
      "MSE train 5.329904857914706 MSE test 11.79766755680804\n",
      "MAE train 1.5908334607306842 MAE test 2.403716789544475\n",
      "Epoch 6009 / 10000 loss: 13.397125720977783\n",
      "MSE train 5.329783730404495 MSE test 11.797444707067884\n",
      "MAE train 1.5908155067787366 MAE test 2.403688583289661\n",
      "Epoch 6010 / 10000 loss: 13.396647930145264\n",
      "MSE train 5.329665825781389 MSE test 11.797407171132233\n",
      "MAE train 1.5907940403323109 MAE test 2.4036892557018215\n",
      "Epoch 6011 / 10000 loss: 13.396219491958618\n",
      "MSE train 5.329544765462583 MSE test 11.797127434072419\n",
      "MAE train 1.5907772327056207 MAE test 2.4036539267459913\n",
      "Epoch 6012 / 10000 loss: 13.395751237869263\n",
      "MSE train 5.3294258666920555 MSE test 11.797144247837938\n",
      "MAE train 1.5907544167732384 MAE test 2.403661420057789\n",
      "Epoch 6013 / 10000 loss: 13.395361185073853\n",
      "MSE train 5.329304345551384 MSE test 11.79683297282187\n",
      "MAE train 1.5907381682458233 MAE test 2.4036221370006974\n",
      "Epoch 6014 / 10000 loss: 13.39485216140747\n",
      "MSE train 5.329172614101277 MSE test 11.79685852876785\n",
      "MAE train 1.5907118548240986 MAE test 2.403630734871064\n",
      "Epoch 6015 / 10000 loss: 13.394486427307129\n",
      "MSE train 5.329049132315459 MSE test 11.796608965993007\n",
      "MAE train 1.590693746676474 MAE test 2.4035991706108883\n",
      "Epoch 6016 / 10000 loss: 13.393917083740234\n",
      "MSE train 5.328936537798068 MSE test 11.796592895414156\n",
      "MAE train 1.5906731698664145 MAE test 2.4036025227783226\n",
      "Epoch 6017 / 10000 loss: 13.393496990203857\n",
      "MSE train 5.328815629320917 MSE test 11.79627366675378\n",
      "MAE train 1.5906572476706038 MAE test 2.403562249791121\n",
      "Epoch 6018 / 10000 loss: 13.393032789230347\n",
      "MSE train 5.328679891689266 MSE test 11.796301092328743\n",
      "MAE train 1.590629829262052 MAE test 2.403571088148219\n",
      "Epoch 6019 / 10000 loss: 13.392675399780273\n",
      "MSE train 5.328557756174981 MSE test 11.796074805897902\n",
      "MAE train 1.5906116373769899 MAE test 2.4035424571574056\n",
      "Epoch 6020 / 10000 loss: 13.39208984375\n",
      "MSE train 5.328438579819575 MSE test 11.796027833859094\n",
      "MAE train 1.5905899794223568 MAE test 2.403541899826265\n",
      "Epoch 6021 / 10000 loss: 13.3916597366333\n",
      "MSE train 5.328316636530119 MSE test 11.795759587560786\n",
      "MAE train 1.5905726875358903 MAE test 2.403508034607893\n",
      "Epoch 6022 / 10000 loss: 13.391189336776733\n",
      "MSE train 5.328202328937556 MSE test 11.795767562711868\n",
      "MAE train 1.5905511959918535 MAE test 2.4035143867304978\n",
      "Epoch 6023 / 10000 loss: 13.390788078308105\n",
      "MSE train 5.3280814328768535 MSE test 11.795441831953509\n",
      "MAE train 1.5905353871790804 MAE test 2.403473319604064\n",
      "Epoch 6024 / 10000 loss: 13.39030122756958\n",
      "MSE train 5.327943261748068 MSE test 11.79546994631272\n",
      "MAE train 1.590507328171152 MAE test 2.403482242035168\n",
      "Epoch 6025 / 10000 loss: 13.389949321746826\n",
      "MSE train 5.327823259826128 MSE test 11.795259728473566\n",
      "MAE train 1.5904893257707449 MAE test 2.40345562310602\n",
      "Epoch 6026 / 10000 loss: 13.389354228973389\n",
      "MSE train 5.327697926706863 MSE test 11.795185890191226\n",
      "MAE train 1.5904665852428197 MAE test 2.403451698461697\n",
      "Epoch 6027 / 10000 loss: 13.388920783996582\n",
      "MSE train 5.327577262091994 MSE test 11.794969899612525\n",
      "MAE train 1.5904486029159908 MAE test 2.4034243761237333\n",
      "Epoch 6028 / 10000 loss: 13.388442516326904\n",
      "MSE train 5.327456649368411 MSE test 11.794919915371308\n",
      "MAE train 1.5904266487709298 MAE test 2.4034234608978746\n",
      "Epoch 6029 / 10000 loss: 13.388011932373047\n",
      "MSE train 5.327334991827987 MSE test 11.794663648442231\n",
      "MAE train 1.5904091728346654 MAE test 2.40339109625366\n",
      "Epoch 6030 / 10000 loss: 13.387539625167847\n",
      "MSE train 5.327222510987344 MSE test 11.794664408300369\n",
      "MAE train 1.5903883040088025 MAE test 2.4033965446627876\n",
      "Epoch 6031 / 10000 loss: 13.387131214141846\n",
      "MSE train 5.327102263495381 MSE test 11.794335093676665\n",
      "MAE train 1.5903727297770531 MAE test 2.403355033643339\n",
      "Epoch 6032 / 10000 loss: 13.386658191680908\n",
      "MSE train 5.326962403094149 MSE test 11.794364083330555\n",
      "MAE train 1.5903442281829494 MAE test 2.4033640689547324\n",
      "Epoch 6033 / 10000 loss: 13.386311292648315\n",
      "MSE train 5.326844698928434 MSE test 11.79416613407444\n",
      "MAE train 1.5903265431262112 MAE test 2.403338987203711\n",
      "Epoch 6034 / 10000 loss: 13.385708808898926\n",
      "MSE train 5.32671591304927 MSE test 11.794070330803873\n",
      "MAE train 1.5903033731996974 MAE test 2.403332299306122\n",
      "Epoch 6035 / 10000 loss: 13.385275602340698\n",
      "MSE train 5.326601532418108 MSE test 11.793893201638713\n",
      "MAE train 1.590286183660665 MAE test 2.40330986676296\n",
      "Epoch 6036 / 10000 loss: 13.3847975730896\n",
      "MSE train 5.326471203407051 MSE test 11.793773736214552\n",
      "MAE train 1.5902630981505543 MAE test 2.4033002182957617\n",
      "Epoch 6037 / 10000 loss: 13.38436770439148\n",
      "MSE train 5.326365867639383 MSE test 11.79363646236223\n",
      "MAE train 1.590247458258842 MAE test 2.403282800755613\n",
      "Epoch 6038 / 10000 loss: 13.383899927139282\n",
      "MSE train 5.326237022572446 MSE test 11.793444671129802\n",
      "MAE train 1.5902262653820176 MAE test 2.4032640861470984\n",
      "Epoch 6039 / 10000 loss: 13.3834810256958\n",
      "MSE train 5.3261142209042855 MSE test 11.793356047815502\n",
      "MAE train 1.5902051699728117 MAE test 2.403252806469169\n",
      "Epoch 6040 / 10000 loss: 13.383071422576904\n",
      "MSE train 5.325982363855032 MSE test 11.793221149097002\n",
      "MAE train 1.5901819509685462 MAE test 2.4032411908585343\n",
      "Epoch 6041 / 10000 loss: 13.382549285888672\n",
      "MSE train 5.325878974941194 MSE test 11.793092498106116\n",
      "MAE train 1.5901665972951504 MAE test 2.4032248550178554\n",
      "Epoch 6042 / 10000 loss: 13.382085800170898\n",
      "MSE train 5.325749662999958 MSE test 11.792886856932686\n",
      "MAE train 1.5901455608358714 MAE test 2.4032044067925082\n",
      "Epoch 6043 / 10000 loss: 13.381665468215942\n",
      "MSE train 5.325621699055533 MSE test 11.792799485634992\n",
      "MAE train 1.590123060887318 MAE test 2.4031932813362413\n",
      "Epoch 6044 / 10000 loss: 13.381266355514526\n",
      "MSE train 5.325491806641008 MSE test 11.79269574747605\n",
      "MAE train 1.5900997394978746 MAE test 2.403185568628157\n",
      "Epoch 6045 / 10000 loss: 13.3807213306427\n",
      "MSE train 5.325378871516997 MSE test 11.792522995509389\n",
      "MAE train 1.590082818215254 MAE test 2.403163698621882\n",
      "Epoch 6046 / 10000 loss: 13.380244493484497\n",
      "MSE train 5.325248252611693 MSE test 11.79239168945977\n",
      "MAE train 1.5900598565361506 MAE test 2.403152548416225\n",
      "Epoch 6047 / 10000 loss: 13.379815816879272\n",
      "MSE train 5.325144815796439 MSE test 11.792266470129272\n",
      "MAE train 1.5900444457880427 MAE test 2.4031366491239377\n",
      "Epoch 6048 / 10000 loss: 13.379354238510132\n",
      "MSE train 5.325016038577076 MSE test 11.792059080909027\n",
      "MAE train 1.5900235686460993 MAE test 2.403115980943273\n",
      "Epoch 6049 / 10000 loss: 13.378934860229492\n",
      "MSE train 5.324887058318719 MSE test 11.791972737239691\n",
      "MAE train 1.5900007848293518 MAE test 2.40310498662374\n",
      "Epoch 6050 / 10000 loss: 13.378536939620972\n",
      "MSE train 5.324758208102436 MSE test 11.791875922200083\n",
      "MAE train 1.5899775718205256 MAE test 2.4030981272757\n",
      "Epoch 6051 / 10000 loss: 13.377988815307617\n",
      "MSE train 5.324642768708674 MSE test 11.79169213282227\n",
      "MAE train 1.5899601940948973 MAE test 2.403074880354291\n",
      "Epoch 6052 / 10000 loss: 13.377509593963623\n",
      "MSE train 5.324512924460095 MSE test 11.791582616916893\n",
      "MAE train 1.5899370236696344 MAE test 2.403066449132048\n",
      "Epoch 6053 / 10000 loss: 13.377078294754028\n",
      "MSE train 5.3244046307684645 MSE test 11.791431441865376\n",
      "MAE train 1.5899208803464357 MAE test 2.403047297818882\n",
      "Epoch 6054 / 10000 loss: 13.37660551071167\n",
      "MSE train 5.324275167141568 MSE test 11.79126395831773\n",
      "MAE train 1.589898962334916 MAE test 2.403031625175172\n",
      "Epoch 6055 / 10000 loss: 13.376184225082397\n",
      "MSE train 5.324164037059618 MSE test 11.791167524922972\n",
      "MAE train 1.5898809953014457 MAE test 2.4030193554104353\n",
      "Epoch 6056 / 10000 loss: 13.375752449035645\n",
      "MSE train 5.324033798675954 MSE test 11.790978175011952\n",
      "MAE train 1.5898593526222018 MAE test 2.4030009170224758\n",
      "Epoch 6057 / 10000 loss: 13.375282049179077\n",
      "MSE train 5.3239141635639475 MSE test 11.790887236802941\n",
      "MAE train 1.5898390790755457 MAE test 2.4029893533210482\n",
      "Epoch 6058 / 10000 loss: 13.37486457824707\n",
      "MSE train 5.323782196972751 MSE test 11.790738261939998\n",
      "MAE train 1.5898160850452598 MAE test 2.402975957638908\n",
      "Epoch 6059 / 10000 loss: 13.374355792999268\n",
      "MSE train 5.323678710569662 MSE test 11.790623122957301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5898004342621777 MAE test 2.402961339697794\n",
      "Epoch 6060 / 10000 loss: 13.373901844024658\n",
      "MSE train 5.323549190339761 MSE test 11.790410791599726\n",
      "MAE train 1.5897794238443383 MAE test 2.402940036838404\n",
      "Epoch 6061 / 10000 loss: 13.373472213745117\n",
      "MSE train 5.323419430668569 MSE test 11.790324175827912\n",
      "MAE train 1.5897564291203066 MAE test 2.402929025782402\n",
      "Epoch 6062 / 10000 loss: 13.373076677322388\n",
      "MSE train 5.3232918674988055 MSE test 11.790234373583457\n",
      "MAE train 1.589733360171518 MAE test 2.402923029658314\n",
      "Epoch 6063 / 10000 loss: 13.37252402305603\n",
      "MSE train 5.323173862250735 MSE test 11.79003710108894\n",
      "MAE train 1.589715586899074 MAE test 2.402898089580886\n",
      "Epoch 6064 / 10000 loss: 13.372045516967773\n",
      "MSE train 5.323046810692399 MSE test 11.789952756772411\n",
      "MAE train 1.5896925878881294 MAE test 2.402892799314248\n",
      "Epoch 6065 / 10000 loss: 13.371612787246704\n",
      "MSE train 5.322929565312212 MSE test 11.789761456769432\n",
      "MAE train 1.5896748999751564 MAE test 2.402868627084658\n",
      "Epoch 6066 / 10000 loss: 13.371134996414185\n",
      "MSE train 5.322801927921457 MSE test 11.789673317800645\n",
      "MAE train 1.589651857951592 MAE test 2.4028628617439316\n",
      "Epoch 6067 / 10000 loss: 13.370701789855957\n",
      "MSE train 5.32268640957704 MSE test 11.789491803514247\n",
      "MAE train 1.5896344175625463 MAE test 2.4028399130932256\n",
      "Epoch 6068 / 10000 loss: 13.370224714279175\n",
      "MSE train 5.322557122396784 MSE test 11.789386520917967\n",
      "MAE train 1.589611303901224 MAE test 2.4028320120871673\n",
      "Epoch 6069 / 10000 loss: 13.369793891906738\n",
      "MSE train 5.322448049067645 MSE test 11.7892330484247\n",
      "MAE train 1.589594993885288 MAE test 2.4028125905316804\n",
      "Epoch 6070 / 10000 loss: 13.369320631027222\n",
      "MSE train 5.3223186354117855 MSE test 11.789072632509429\n",
      "MAE train 1.5895729195199761 MAE test 2.4027977915413707\n",
      "Epoch 6071 / 10000 loss: 13.368897676467896\n",
      "MSE train 5.322210189324188 MSE test 11.788973436955004\n",
      "MAE train 1.5895556889017977 MAE test 2.4027851866032717\n",
      "Epoch 6072 / 10000 loss: 13.368460655212402\n",
      "MSE train 5.322080618208749 MSE test 11.788774007916867\n",
      "MAE train 1.5895343960250852 MAE test 2.402765473785927\n",
      "Epoch 6073 / 10000 loss: 13.368003129959106\n",
      "MSE train 5.321955970857925 MSE test 11.788686084209338\n",
      "MAE train 1.5895127482200007 MAE test 2.402754307417417\n",
      "Epoch 6074 / 10000 loss: 13.367595672607422\n",
      "MSE train 5.32182473637321 MSE test 11.788564485640153\n",
      "MAE train 1.589489369374855 MAE test 2.4027443099034107\n",
      "Epoch 6075 / 10000 loss: 13.367065906524658\n",
      "MSE train 5.321718618293909 MSE test 11.788419319996235\n",
      "MAE train 1.5894736098355882 MAE test 2.402725925248937\n",
      "Epoch 6076 / 10000 loss: 13.366594791412354\n",
      "MSE train 5.321589195349995 MSE test 11.78823752724057\n",
      "MAE train 1.5894519738386286 MAE test 2.4027084294725776\n",
      "Epoch 6077 / 10000 loss: 13.366175651550293\n",
      "MSE train 5.321472294780745 MSE test 11.788146020619228\n",
      "MAE train 1.5894324066080934 MAE test 2.402696813435063\n",
      "Epoch 6078 / 10000 loss: 13.365754842758179\n",
      "MSE train 5.321340979678667 MSE test 11.787983569695252\n",
      "MAE train 1.589409854145641 MAE test 2.402681715664573\n",
      "Epoch 6079 / 10000 loss: 13.365257263183594\n",
      "MSE train 5.321234187632635 MSE test 11.787879628017782\n",
      "MAE train 1.589393100867898 MAE test 2.4026685144470195\n",
      "Epoch 6080 / 10000 loss: 13.364816188812256\n",
      "MSE train 5.321104272621157 MSE test 11.787676439792573\n",
      "MAE train 1.5893717738265423 MAE test 2.402648304147898\n",
      "Epoch 6081 / 10000 loss: 13.364364862442017\n",
      "MSE train 5.320978617599075 MSE test 11.787588506789671\n",
      "MAE train 1.5893498444148122 MAE test 2.4026371351123625\n",
      "Epoch 6082 / 10000 loss: 13.363960266113281\n",
      "MSE train 5.320847836855028 MSE test 11.787473319936835\n",
      "MAE train 1.5893264561821512 MAE test 2.402627939099669\n",
      "Epoch 6083 / 10000 loss: 13.363425493240356\n",
      "MSE train 5.320739477147608 MSE test 11.787318506949743\n",
      "MAE train 1.589310309496225 MAE test 2.4026083571273955\n",
      "Epoch 6084 / 10000 loss: 13.362952709197998\n",
      "MSE train 5.320609578508133 MSE test 11.787153735207763\n",
      "MAE train 1.5892881705262305 MAE test 2.4025929776470236\n",
      "Epoch 6085 / 10000 loss: 13.36253023147583\n",
      "MSE train 5.320500500645578 MSE test 11.787054814328794\n",
      "MAE train 1.589270745361607 MAE test 2.40258041830941\n",
      "Epoch 6086 / 10000 loss: 13.36209487915039\n",
      "MSE train 5.320370669167201 MSE test 11.786858679134658\n",
      "MAE train 1.5892492853661246 MAE test 2.4025611030486345\n",
      "Epoch 6087 / 10000 loss: 13.361634254455566\n",
      "MSE train 5.320248090875437 MSE test 11.786769700454272\n",
      "MAE train 1.5892281941059994 MAE test 2.4025498051210845\n",
      "Epoch 6088 / 10000 loss: 13.361223936080933\n",
      "MSE train 5.320116411937672 MSE test 11.786637284182072\n",
      "MAE train 1.5892048942636061 MAE test 2.4025384435358457\n",
      "Epoch 6089 / 10000 loss: 13.360701560974121\n",
      "MSE train 5.320012816431247 MSE test 11.786505284872145\n",
      "MAE train 1.5891895089259926 MAE test 2.4025217362121163\n",
      "Epoch 6090 / 10000 loss: 13.36023736000061\n",
      "MSE train 5.319883810332109 MSE test 11.786303919056833\n",
      "MAE train 1.5891683685549627 MAE test 2.4025017635171584\n",
      "Epoch 6091 / 10000 loss: 13.359819173812866\n",
      "MSE train 5.319758147443438 MSE test 11.786216776450182\n",
      "MAE train 1.589146439634158 MAE test 2.402490711850996\n",
      "Epoch 6092 / 10000 loss: 13.359416484832764\n",
      "MSE train 5.319627442800814 MSE test 11.78610099286108\n",
      "MAE train 1.5891230659525264 MAE test 2.402481430259502\n",
      "Epoch 6093 / 10000 loss: 13.358880519866943\n",
      "MSE train 5.319519376617955 MSE test 11.785947447777188\n",
      "MAE train 1.5891069788289292 MAE test 2.4024620155424588\n",
      "Epoch 6094 / 10000 loss: 13.358407974243164\n",
      "MSE train 5.319389648971359 MSE test 11.785780428593927\n",
      "MAE train 1.5890849215027651 MAE test 2.4024463675861196\n",
      "Epoch 6095 / 10000 loss: 13.35798716545105\n",
      "MSE train 5.31927963229192 MSE test 11.785682566669829\n",
      "MAE train 1.589067246069521 MAE test 2.4024339445429232\n",
      "Epoch 6096 / 10000 loss: 13.357554197311401\n",
      "MSE train 5.3191496668531615 MSE test 11.78548989933843\n",
      "MAE train 1.5890456799241144 MAE test 2.4024150558234085\n",
      "Epoch 6097 / 10000 loss: 13.357088804244995\n",
      "MSE train 5.319028907102549 MSE test 11.785399922886088\n",
      "MAE train 1.5890250813384583 MAE test 2.402403644051759\n",
      "Epoch 6098 / 10000 loss: 13.35667610168457\n",
      "MSE train 5.3188971700937335 MSE test 11.785257457399325\n",
      "MAE train 1.5890019572790852 MAE test 2.4023910254343557\n",
      "Epoch 6099 / 10000 loss: 13.356162309646606\n",
      "MSE train 5.318794354751545 MSE test 11.785135934772079\n",
      "MAE train 1.5889865888212027 MAE test 2.402375646305617\n",
      "Epoch 6100 / 10000 loss: 13.355705261230469\n",
      "MSE train 5.318665244080874 MSE test 11.784924846717807\n",
      "MAE train 1.5889656013441205 MAE test 2.4023544604190747\n",
      "Epoch 6101 / 10000 loss: 13.3552827835083\n",
      "MSE train 5.318536146430184 MSE test 11.784838662643226\n",
      "MAE train 1.5889427707247497 MAE test 2.4023435379159905\n",
      "Epoch 6102 / 10000 loss: 13.354888200759888\n",
      "MSE train 5.3184082080642625 MSE test 11.784744899612283\n",
      "MAE train 1.5889196523344906 MAE test 2.402337009510252\n",
      "Epoch 6103 / 10000 loss: 13.354339122772217\n",
      "MSE train 5.318291582031892 MSE test 11.784554337369508\n",
      "MAE train 1.588902074186075 MAE test 2.402312946348298\n",
      "Epoch 6104 / 10000 loss: 13.353861570358276\n",
      "MSE train 5.318163195583437 MSE test 11.78445742983747\n",
      "MAE train 1.5888789779417214 MAE test 2.40230606171099\n",
      "Epoch 6105 / 10000 loss: 13.353431701660156\n",
      "MSE train 5.318050158506533 MSE test 11.78428642940468\n",
      "MAE train 1.5888619839399374 MAE test 2.402284464887166\n",
      "Epoch 6106 / 10000 loss: 13.352956771850586\n",
      "MSE train 5.317920273814128 MSE test 11.784158655250376\n",
      "MAE train 1.5888390913194974 MAE test 2.4022737230153925\n",
      "Epoch 6107 / 10000 loss: 13.352530002593994\n",
      "MSE train 5.317816761596787 MSE test 11.784031821975185\n",
      "MAE train 1.5888236732012382 MAE test 2.4022576854688373\n",
      "Epoch 6108 / 10000 loss: 13.35206913948059\n",
      "MSE train 5.317688488457816 MSE test 11.78382674127976\n",
      "MAE train 1.5888027973071626 MAE test 2.4022372540815073\n",
      "Epoch 6109 / 10000 loss: 13.351652383804321\n",
      "MSE train 5.317560781242189 MSE test 11.783740807692894\n",
      "MAE train 1.588780333756715 MAE test 2.402226367986906\n",
      "Epoch 6110 / 10000 loss: 13.35125470161438\n",
      "MSE train 5.317431356049882 MSE test 11.783636515623165\n",
      "MAE train 1.5887570755727602 MAE test 2.4022185301951318\n",
      "Epoch 6111 / 10000 loss: 13.350712537765503\n",
      "MSE train 5.317318827327491 MSE test 11.783464998607862\n",
      "MAE train 1.5887402082523168 MAE test 2.402196881489905\n",
      "Epoch 6112 / 10000 loss: 13.350237607955933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.31718856844376 MSE test 11.78333234353811\n",
      "MAE train 1.5887173053337953 MAE test 2.402185515356184\n",
      "Epoch 6113 / 10000 loss: 13.349811792373657\n",
      "MSE train 5.31708540635902 MSE test 11.783208336456326\n",
      "MAE train 1.5887019271116154 MAE test 2.402169828957188\n",
      "Epoch 6114 / 10000 loss: 13.349352598190308\n",
      "MSE train 5.3169570120585385 MSE test 11.782999707040817\n",
      "MAE train 1.58868108092762 MAE test 2.4021489591857668\n",
      "Epoch 6115 / 10000 loss: 13.348934888839722\n",
      "MSE train 5.316828208746854 MSE test 11.782913860466458\n",
      "MAE train 1.58865834233236 MAE test 2.40213808232656\n",
      "Epoch 6116 / 10000 loss: 13.348540306091309\n",
      "MSE train 5.316699712381891 MSE test 11.782816403009086\n",
      "MAE train 1.5886351800748453 MAE test 2.4021310947659043\n",
      "Epoch 6117 / 10000 loss: 13.347994565963745\n",
      "MSE train 5.316584378494107 MSE test 11.78263214430959\n",
      "MAE train 1.5886178212672746 MAE test 2.40210785400554\n",
      "Epoch 6118 / 10000 loss: 13.347517967224121\n",
      "MSE train 5.316454935186028 MSE test 11.782523638599466\n",
      "MAE train 1.5885946956830996 MAE test 2.4020995157645557\n",
      "Epoch 6119 / 10000 loss: 13.347090005874634\n",
      "MSE train 5.316346198273226 MSE test 11.782370089762157\n",
      "MAE train 1.5885784716234495 MAE test 2.4020801282626376\n",
      "Epoch 6120 / 10000 loss: 13.346619606018066\n",
      "MSE train 5.31621678992656 MSE test 11.782207181490806\n",
      "MAE train 1.5885564240432533 MAE test 2.4020649824548204\n",
      "Epoch 6121 / 10000 loss: 13.346198797225952\n",
      "MSE train 5.316108091701539 MSE test 11.782108028633658\n",
      "MAE train 1.5885391437392005 MAE test 2.4020524298387325\n",
      "Epoch 6122 / 10000 loss: 13.345765113830566\n",
      "MSE train 5.31597859852092 MSE test 11.781909151969284\n",
      "MAE train 1.588517819523188 MAE test 2.402032771967862\n",
      "Epoch 6123 / 10000 loss: 13.345308542251587\n",
      "MSE train 5.315854819536311 MSE test 11.78182078698686\n",
      "MAE train 1.5884964431495472 MAE test 2.402021585407175\n",
      "Epoch 6124 / 10000 loss: 13.344902753829956\n",
      "MSE train 5.31572345661907 MSE test 11.781693612697898\n",
      "MAE train 1.5884731289036427 MAE test 2.402010874201585\n",
      "Epoch 6125 / 10000 loss: 13.344377756118774\n",
      "MSE train 5.315618583166238 MSE test 11.78155394860806\n",
      "MAE train 1.588457599382195 MAE test 2.401993242801139\n",
      "Epoch 6126 / 10000 loss: 13.343911409378052\n",
      "MSE train 5.315489399902831 MSE test 11.781362150121486\n",
      "MAE train 1.5884362289755234 MAE test 2.4019744648678345\n",
      "Epoch 6127 / 10000 loss: 13.343495607376099\n",
      "MSE train 5.315368316378934 MSE test 11.781272838726226\n",
      "MAE train 1.5884155849833739 MAE test 2.4019631684332587\n",
      "Epoch 6128 / 10000 loss: 13.343085527420044\n",
      "MSE train 5.315236689052248 MSE test 11.781130400880382\n",
      "MAE train 1.588392498478239 MAE test 2.401950542134755\n",
      "Epoch 6129 / 10000 loss: 13.342572212219238\n",
      "MSE train 5.315133831730205 MSE test 11.781008623859123\n",
      "MAE train 1.5883771504450468 MAE test 2.4019351597601504\n",
      "Epoch 6130 / 10000 loss: 13.342115879058838\n",
      "MSE train 5.315004766875624 MSE test 11.780797075471332\n",
      "MAE train 1.5883561849716448 MAE test 2.4019138964988183\n",
      "Epoch 6131 / 10000 loss: 13.341695547103882\n",
      "MSE train 5.314875669717507 MSE test 11.78071079370985\n",
      "MAE train 1.58833338752755 MAE test 2.4019029946979233\n",
      "Epoch 6132 / 10000 loss: 13.341302394866943\n",
      "MSE train 5.314747626088882 MSE test 11.780615924923739\n",
      "MAE train 1.5883102789849837 MAE test 2.40189633037078\n",
      "Epoch 6133 / 10000 loss: 13.340755224227905\n",
      "MSE train 5.31463102010027 MSE test 11.78042581757753\n",
      "MAE train 1.588292729193085 MAE test 2.40187234625008\n",
      "Epoch 6134 / 10000 loss: 13.340279579162598\n",
      "MSE train 5.314502625665486 MSE test 11.780327765592874\n",
      "MAE train 1.5882696612409846 MAE test 2.401865318140823\n",
      "Epoch 6135 / 10000 loss: 13.339849948883057\n",
      "MSE train 5.314389736207933 MSE test 11.780157708331009\n",
      "MAE train 1.5882527172395577 MAE test 2.4018438536883195\n",
      "Epoch 6136 / 10000 loss: 13.339377164840698\n",
      "MSE train 5.3142598354856085 MSE test 11.780027137227412\n",
      "MAE train 1.5882298776300703 MAE test 2.401832744556642\n",
      "Epoch 6137 / 10000 loss: 13.338951587677002\n",
      "MSE train 5.314156476169091 MSE test 11.779902512632614\n",
      "MAE train 1.5882144907144604 MAE test 2.401817011871296\n",
      "Epoch 6138 / 10000 loss: 13.338493585586548\n",
      "MSE train 5.314028187706653 MSE test 11.779694558909249\n",
      "MAE train 1.588193657154829 MAE test 2.4017962123824805\n",
      "Epoch 6139 / 10000 loss: 13.338076829910278\n",
      "MSE train 5.31389960157593 MSE test 11.779608812337493\n",
      "MAE train 1.5881709893772897 MAE test 2.4017853797240187\n",
      "Epoch 6140 / 10000 loss: 13.337683200836182\n",
      "MSE train 5.313770901861751 MSE test 11.779509940671181\n",
      "MAE train 1.5881478137895833 MAE test 2.4017782105701486\n",
      "Epoch 6141 / 10000 loss: 13.337138414382935\n",
      "MSE train 5.313656016345294 MSE test 11.779328185628763\n",
      "MAE train 1.5881305429777577 MAE test 2.4017552809749643\n",
      "Epoch 6142 / 10000 loss: 13.336663722991943\n",
      "MSE train 5.313526336960821 MSE test 11.779214578877461\n",
      "MAE train 1.5881074433901672 MAE test 2.4017462784806445\n",
      "Epoch 6143 / 10000 loss: 13.336236476898193\n",
      "MSE train 5.313419149583093 MSE test 11.779067725467437\n",
      "MAE train 1.5880914997472528 MAE test 2.4017277654820455\n",
      "Epoch 6144 / 10000 loss: 13.335768222808838\n",
      "MSE train 5.313290178811827 MSE test 11.778892102889705\n",
      "MAE train 1.5880698205140733 MAE test 2.4017110131503925\n",
      "Epoch 6145 / 10000 loss: 13.335350513458252\n",
      "MSE train 5.313176060671182 MSE test 11.778799030732431\n",
      "MAE train 1.5880510576615565 MAE test 2.401699244486468\n",
      "Epoch 6146 / 10000 loss: 13.334927558898926\n",
      "MSE train 5.313045458867313 MSE test 11.778622131577862\n",
      "MAE train 1.5880289707447477 MAE test 2.40168231728996\n",
      "Epoch 6147 / 10000 loss: 13.33444619178772\n",
      "MSE train 5.312932918249239 MSE test 11.778526105150407\n",
      "MAE train 1.5880106435864865 MAE test 2.4016701770082944\n",
      "Epoch 6148 / 10000 loss: 13.334020376205444\n",
      "MSE train 5.312802155870667 MSE test 11.77834430663948\n",
      "MAE train 1.5879886146562954 MAE test 2.4016526217830787\n",
      "Epoch 6149 / 10000 loss: 13.333544254302979\n",
      "MSE train 5.312687682405065 MSE test 11.778249550295024\n",
      "MAE train 1.5879697629424432 MAE test 2.4016406505954624\n",
      "Epoch 6150 / 10000 loss: 13.333121299743652\n",
      "MSE train 5.312556526372942 MSE test 11.778076240688744\n",
      "MAE train 1.587947441450307 MAE test 2.4016241541633705\n",
      "Epoch 6151 / 10000 loss: 13.332637786865234\n",
      "MSE train 5.312446267440878 MSE test 11.77797731526019\n",
      "MAE train 1.5879297497078513 MAE test 2.401611652673889\n",
      "Epoch 6152 / 10000 loss: 13.33220624923706\n",
      "MSE train 5.312315783721485 MSE test 11.777786318826541\n",
      "MAE train 1.587907985696129 MAE test 2.4015929439002517\n",
      "Epoch 6153 / 10000 loss: 13.331740856170654\n",
      "MSE train 5.312196889031084 MSE test 11.777694880326337\n",
      "MAE train 1.5878879397415706 MAE test 2.4015813951629625\n",
      "Epoch 6154 / 10000 loss: 13.33132553100586\n",
      "MSE train 5.312065169919611 MSE test 11.777542542409469\n",
      "MAE train 1.58786501646632 MAE test 2.4015674930543143\n",
      "Epoch 6155 / 10000 loss: 13.330822467803955\n",
      "MSE train 5.311961538155705 MSE test 11.777429013950275\n",
      "MAE train 1.5878493194505048 MAE test 2.4015531674341424\n",
      "Epoch 6156 / 10000 loss: 13.330372095108032\n",
      "MSE train 5.311832091555606 MSE test 11.777216165815055\n",
      "MAE train 1.5878282650096283 MAE test 2.401531714755939\n",
      "Epoch 6157 / 10000 loss: 13.329943418502808\n",
      "MSE train 5.311702896047034 MSE test 11.777129651458452\n",
      "MAE train 1.587805448272124 MAE test 2.4015208154255383\n",
      "Epoch 6158 / 10000 loss: 13.32955026626587\n",
      "MSE train 5.3115751492946055 MSE test 11.777036126021239\n",
      "MAE train 1.5877823664040247 MAE test 2.4015142914585175\n",
      "Epoch 6159 / 10000 loss: 13.32900333404541\n",
      "MSE train 5.311458031115527 MSE test 11.776843470479442\n",
      "MAE train 1.587764740534669 MAE test 2.401490009698275\n",
      "Epoch 6160 / 10000 loss: 13.32852816581726\n",
      "MSE train 5.311330178964838 MSE test 11.77675001098862\n",
      "MAE train 1.5877417011673385 MAE test 2.4014835077058874\n",
      "Epoch 6161 / 10000 loss: 13.328098773956299\n",
      "MSE train 5.31121549933092 MSE test 11.776571931180392\n",
      "MAE train 1.5877244255397964 MAE test 2.4014610658870437\n",
      "Epoch 6162 / 10000 loss: 13.327625036239624\n",
      "MSE train 5.311086034361943 MSE test 11.776457822316665\n",
      "MAE train 1.5877013815989542 MAE test 2.4014519764528997\n",
      "Epoch 6163 / 10000 loss: 13.327197790145874\n",
      "MSE train 5.310979288460625 MSE test 11.776314099027024\n",
      "MAE train 1.5876854966560454 MAE test 2.4014338605605303\n",
      "Epoch 6164 / 10000 loss: 13.326730251312256\n",
      "MSE train 5.310850545659701 MSE test 11.776134550283253\n",
      "MAE train 1.5876639498408058 MAE test 2.4014165840763266\n",
      "Epoch 6165 / 10000 loss: 13.326313257217407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.310734484493699 MSE test 11.776043301990747\n",
      "MAE train 1.5876446562038977 MAE test 2.4014050769626807\n",
      "Epoch 6166 / 10000 loss: 13.325894594192505\n",
      "MSE train 5.310603618368773 MSE test 11.775875089072214\n",
      "MAE train 1.5876222948553549 MAE test 2.401389190488918\n",
      "Epoch 6167 / 10000 loss: 13.325403928756714\n",
      "MSE train 5.310494939884358 MSE test 11.77577464988515\n",
      "MAE train 1.5876050401284825 MAE test 2.401376515655346\n",
      "Epoch 6168 / 10000 loss: 13.32496976852417\n",
      "MSE train 5.310364888436264 MSE test 11.775577039770985\n",
      "MAE train 1.5875835109277696 MAE test 2.4013569694777352\n",
      "Epoch 6169 / 10000 loss: 13.324512243270874\n",
      "MSE train 5.310242495795128 MSE test 11.775487975492101\n",
      "MAE train 1.5875625209716322 MAE test 2.4013457429220413\n",
      "Epoch 6170 / 10000 loss: 13.32410454750061\n",
      "MSE train 5.3101108175502105 MSE test 11.775353393419797\n",
      "MAE train 1.587539254852387 MAE test 2.4013340373202685\n",
      "Epoch 6171 / 10000 loss: 13.323584079742432\n",
      "MSE train 5.310007350819786 MSE test 11.775222305232269\n",
      "MAE train 1.5875239127401461 MAE test 2.401317519208186\n",
      "Epoch 6172 / 10000 loss: 13.323123455047607\n",
      "MSE train 5.309878239872141 MSE test 11.775019407506777\n",
      "MAE train 1.587502749000101 MAE test 2.401297303050682\n",
      "Epoch 6173 / 10000 loss: 13.322706699371338\n",
      "MSE train 5.309752399298414 MSE test 11.774932424204499\n",
      "MAE train 1.587480809014648 MAE test 2.4012863452845616\n",
      "Epoch 6174 / 10000 loss: 13.322305917739868\n",
      "MSE train 5.309621875524297 MSE test 11.774816896554281\n",
      "MAE train 1.587457454607338 MAE test 2.401277040046491\n",
      "Epoch 6175 / 10000 loss: 13.32177186012268\n",
      "MSE train 5.309513184055254 MSE test 11.774661593591764\n",
      "MAE train 1.5874412774416127 MAE test 2.4012574712313053\n",
      "Epoch 6176 / 10000 loss: 13.321301221847534\n",
      "MSE train 5.309383336881517 MSE test 11.774497520111783\n",
      "MAE train 1.5874190953338676 MAE test 2.4012421017735828\n",
      "Epoch 6177 / 10000 loss: 13.32088041305542\n",
      "MSE train 5.309274860369166 MSE test 11.774397838152945\n",
      "MAE train 1.5874018904172613 MAE test 2.4012295318136547\n",
      "Epoch 6178 / 10000 loss: 13.320446252822876\n",
      "MSE train 5.3091451805726075 MSE test 11.774198432694762\n",
      "MAE train 1.5873804882624232 MAE test 2.4012097405982393\n",
      "Epoch 6179 / 10000 loss: 13.319990873336792\n",
      "MSE train 5.30902145637523 MSE test 11.774110288926877\n",
      "MAE train 1.587359133195618 MAE test 2.40119864020764\n",
      "Epoch 6180 / 10000 loss: 13.319584846496582\n",
      "MSE train 5.3088900426371906 MSE test 11.773982727684805\n",
      "MAE train 1.5873357742563272 MAE test 2.401187829604941\n",
      "Epoch 6181 / 10000 loss: 13.3190598487854\n",
      "MSE train 5.308785138874952 MSE test 11.773843639674341\n",
      "MAE train 1.587320230125129 MAE test 2.401170294194881\n",
      "Epoch 6182 / 10000 loss: 13.318593502044678\n",
      "MSE train 5.308655936073348 MSE test 11.773651727015364\n",
      "MAE train 1.5872987996182624 MAE test 2.401151437740451\n",
      "Epoch 6183 / 10000 loss: 13.318177700042725\n",
      "MSE train 5.3085349184669655 MSE test 11.773563001751787\n",
      "MAE train 1.5872781696094604 MAE test 2.401140261889032\n",
      "Epoch 6184 / 10000 loss: 13.317766666412354\n",
      "MSE train 5.308403265103537 MSE test 11.773419867398433\n",
      "MAE train 1.5872550530902239 MAE test 2.4011274895463726\n",
      "Epoch 6185 / 10000 loss: 13.31725287437439\n",
      "MSE train 5.308300327245404 MSE test 11.773299030453419\n",
      "MAE train 1.5872396675351468 MAE test 2.40111227360408\n",
      "Epoch 6186 / 10000 loss: 13.31679630279541\n",
      "MSE train 5.308171118744828 MSE test 11.7730874378458\n",
      "MAE train 1.5872186220634985 MAE test 2.4010909477023965\n",
      "Epoch 6187 / 10000 loss: 13.316375017166138\n",
      "MSE train 5.30804204218868 MSE test 11.773001606795376\n",
      "MAE train 1.5871958133934712 MAE test 2.4010801548164404\n",
      "Epoch 6188 / 10000 loss: 13.315980672836304\n",
      "MSE train 5.307913928418627 MSE test 11.772906535172583\n",
      "MAE train 1.5871726530993027 MAE test 2.4010734140299093\n",
      "Epoch 6189 / 10000 loss: 13.31543254852295\n",
      "MSE train 5.307797319568947 MSE test 11.772717379864048\n",
      "MAE train 1.5871550673787747 MAE test 2.401049598785213\n",
      "Epoch 6190 / 10000 loss: 13.314956903457642\n",
      "MSE train 5.307668719242439 MSE test 11.772618457467031\n",
      "MAE train 1.5871319344612402 MAE test 2.401042396259689\n",
      "Epoch 6191 / 10000 loss: 13.314525604248047\n",
      "MSE train 5.307555934909635 MSE test 11.77245006856315\n",
      "MAE train 1.5871149754719942 MAE test 2.4010212009546517\n",
      "Epoch 6192 / 10000 loss: 13.314052104949951\n",
      "MSE train 5.307425851746372 MSE test 11.772317812511634\n",
      "MAE train 1.5870920846307304 MAE test 2.4010097930401395\n",
      "Epoch 6193 / 10000 loss: 13.313624858856201\n",
      "MSE train 5.3073224524369875 MSE test 11.7721952903674\n",
      "MAE train 1.5870766306961483 MAE test 2.400994377511298\n",
      "Epoch 6194 / 10000 loss: 13.313166618347168\n",
      "MSE train 5.307194045035898 MSE test 11.771986171559375\n",
      "MAE train 1.5870557323659382 MAE test 2.400973361200271\n",
      "Epoch 6195 / 10000 loss: 13.312747478485107\n",
      "MSE train 5.307064851611099 MSE test 11.771901297997568\n",
      "MAE train 1.5870329028616168 MAE test 2.4009627188439047\n",
      "Epoch 6196 / 10000 loss: 13.312352895736694\n",
      "MSE train 5.30693643532337 MSE test 11.771804861227954\n",
      "MAE train 1.5870096974438292 MAE test 2.4009557946762197\n",
      "Epoch 6197 / 10000 loss: 13.31180477142334\n",
      "MSE train 5.306820265055148 MSE test 11.771619232105778\n",
      "MAE train 1.5869921701450103 MAE test 2.400932430604152\n",
      "Epoch 6198 / 10000 loss: 13.31132698059082\n",
      "MSE train 5.306691133340782 MSE test 11.77151447182088\n",
      "MAE train 1.5869689946086931 MAE test 2.40092448150319\n",
      "Epoch 6199 / 10000 loss: 13.310895919799805\n",
      "MSE train 5.306580436729025 MSE test 11.771355552299775\n",
      "MAE train 1.5869523996683939 MAE test 2.400904500256863\n",
      "Epoch 6200 / 10000 loss: 13.310423135757446\n",
      "MSE train 5.306450467294491 MSE test 11.771204752620395\n",
      "MAE train 1.5869299005593593 MAE test 2.4008907661113805\n",
      "Epoch 6201 / 10000 loss: 13.309998989105225\n",
      "MSE train 5.306345312363914 MSE test 11.771098541851968\n",
      "MAE train 1.5869136947152893 MAE test 2.400877427409358\n",
      "Epoch 6202 / 10000 loss: 13.309552907943726\n",
      "MSE train 5.306216236671236 MSE test 11.770886521145925\n",
      "MAE train 1.58689266926096 MAE test 2.4008560130560026\n",
      "Epoch 6203 / 10000 loss: 13.309115171432495\n",
      "MSE train 5.306086546464846 MSE test 11.770801409343717\n",
      "MAE train 1.5868697011761093 MAE test 2.4008453604590727\n",
      "Epoch 6204 / 10000 loss: 13.308720827102661\n",
      "MSE train 5.305958600258642 MSE test 11.77070851959897\n",
      "MAE train 1.586846525495791 MAE test 2.4008388924869397\n",
      "Epoch 6205 / 10000 loss: 13.3081693649292\n",
      "MSE train 5.305840973283148 MSE test 11.770515815121051\n",
      "MAE train 1.5868287581855631 MAE test 2.4008146436234523\n",
      "Epoch 6206 / 10000 loss: 13.30769157409668\n",
      "MSE train 5.305713059952021 MSE test 11.770424357112281\n",
      "MAE train 1.5868056236044152 MAE test 2.4008083821680963\n",
      "Epoch 6207 / 10000 loss: 13.30725884437561\n",
      "MSE train 5.3055974256304 MSE test 11.770244063907338\n",
      "MAE train 1.586788129526852 MAE test 2.4007857011956952\n",
      "Epoch 6208 / 10000 loss: 13.306782007217407\n",
      "MSE train 5.305467886148986 MSE test 11.770135507473325\n",
      "MAE train 1.5867649286013292 MAE test 2.400777287313453\n",
      "Epoch 6209 / 10000 loss: 13.306350469589233\n",
      "MSE train 5.305358917109828 MSE test 11.769984649345936\n",
      "MAE train 1.586748611353173 MAE test 2.4007583239007784\n",
      "Epoch 6210 / 10000 loss: 13.305878162384033\n",
      "MSE train 5.305229368986592 MSE test 11.769819712713725\n",
      "MAE train 1.5867265018343195 MAE test 2.400742814953806\n",
      "Epoch 6211 / 10000 loss: 13.305455446243286\n",
      "MSE train 5.305119541959714 MSE test 11.76972292092916\n",
      "MAE train 1.5867089093374676 MAE test 2.400730682301137\n",
      "Epoch 6212 / 10000 loss: 13.305020809173584\n",
      "MSE train 5.304989530160611 MSE test 11.769526636613596\n",
      "MAE train 1.586687328305221 MAE test 2.400711226585195\n",
      "Epoch 6213 / 10000 loss: 13.304557800292969\n",
      "MSE train 5.304866888486639 MSE test 11.769438544010873\n",
      "MAE train 1.5866662810071932 MAE test 2.400700204269555\n",
      "Epoch 6214 / 10000 loss: 13.304147243499756\n",
      "MSE train 5.304735023864114 MSE test 11.769302881842387\n",
      "MAE train 1.5866429368766841 MAE test 2.4006883407811244\n",
      "Epoch 6215 / 10000 loss: 13.30362582206726\n",
      "MSE train 5.304631326186009 MSE test 11.769173911083499\n",
      "MAE train 1.5866275032063877 MAE test 2.4006721431070126\n",
      "Epoch 6216 / 10000 loss: 13.303162097930908\n",
      "MSE train 5.304502031132713 MSE test 11.76896927004087\n",
      "MAE train 1.5866062601110444 MAE test 2.4006516168286556\n",
      "Epoch 6217 / 10000 loss: 13.302742719650269\n",
      "MSE train 5.304375297314339 MSE test 11.768883177658093\n",
      "MAE train 1.5865840706813643 MAE test 2.40064085008955\n",
      "Epoch 6218 / 10000 loss: 13.302340984344482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.3042448679796825 MSE test 11.768770990423581\n",
      "MAE train 1.5865606385515834 MAE test 2.400631943019526\n",
      "Epoch 6219 / 10000 loss: 13.301803350448608\n",
      "MSE train 5.304134654866608 MSE test 11.768610686597734\n",
      "MAE train 1.5865441483146634 MAE test 2.4006117792655624\n",
      "Epoch 6220 / 10000 loss: 13.301328659057617\n",
      "MSE train 5.304004424354004 MSE test 11.768456863705067\n",
      "MAE train 1.5865215990959765 MAE test 2.4005976477113813\n",
      "Epoch 6221 / 10000 loss: 13.300905466079712\n",
      "MSE train 5.303899124416803 MSE test 11.768351069417175\n",
      "MAE train 1.5865053249322727 MAE test 2.4005843776712297\n",
      "Epoch 6222 / 10000 loss: 13.300460577011108\n",
      "MSE train 5.30376990336249 MSE test 11.768140233251165\n",
      "MAE train 1.5864842081736414 MAE test 2.4005630567310106\n",
      "Epoch 6223 / 10000 loss: 13.300021648406982\n",
      "MSE train 5.303641053110777 MSE test 11.76805473685577\n",
      "MAE train 1.5864614644748822 MAE test 2.4005523888067994\n",
      "Epoch 6224 / 10000 loss: 13.299626111984253\n",
      "MSE train 5.303512690003993 MSE test 11.767956843682812\n",
      "MAE train 1.5864382574718807 MAE test 2.4005452589250056\n",
      "Epoch 6225 / 10000 loss: 13.299079895019531\n",
      "MSE train 5.303396963640562 MSE test 11.767772240653954\n",
      "MAE train 1.586420798474312 MAE test 2.400522026050522\n",
      "Epoch 6226 / 10000 loss: 13.298603773117065\n",
      "MSE train 5.303267813162076 MSE test 11.767664913462445\n",
      "MAE train 1.5863976429756041 MAE test 2.4005137370972185\n",
      "Epoch 6227 / 10000 loss: 13.29817509651184\n",
      "MSE train 5.303158211156351 MSE test 11.767509152750504\n",
      "MAE train 1.5863812431628204 MAE test 2.4004941451376545\n",
      "Epoch 6228 / 10000 loss: 13.297704935073853\n",
      "MSE train 5.303028748035411 MSE test 11.767351734012959\n",
      "MAE train 1.586358974137356 MAE test 2.4004795445826455\n",
      "Epoch 6229 / 10000 loss: 13.297284126281738\n",
      "MSE train 5.302922264279293 MSE test 11.767249676986507\n",
      "MAE train 1.586342327123701 MAE test 2.4004667495439156\n",
      "Epoch 6230 / 10000 loss: 13.296846628189087\n",
      "MSE train 5.302793264910481 MSE test 11.767042199835373\n",
      "MAE train 1.586321180731785 MAE test 2.4004458206216066\n",
      "Epoch 6231 / 10000 loss: 13.296401500701904\n",
      "MSE train 5.3026661410631615 MSE test 11.766956347762367\n",
      "MAE train 1.5862988874790225 MAE test 2.4004351062962104\n",
      "Epoch 6232 / 10000 loss: 13.29600477218628\n",
      "MSE train 5.302536636211538 MSE test 11.766848919874171\n",
      "MAE train 1.5862755891402724 MAE test 2.400426765590238\n",
      "Epoch 6233 / 10000 loss: 13.295466661453247\n",
      "MSE train 5.302424769407522 MSE test 11.766680415327798\n",
      "MAE train 1.586258842669419 MAE test 2.4004055573120153\n",
      "Epoch 6234 / 10000 loss: 13.294994115829468\n",
      "MSE train 5.302294705363663 MSE test 11.766541876568212\n",
      "MAE train 1.5862360239211808 MAE test 2.4003933127783204\n",
      "Epoch 6235 / 10000 loss: 13.294569969177246\n",
      "MSE train 5.302191804990006 MSE test 11.76642314124193\n",
      "MAE train 1.586220623315892 MAE test 2.4003783963017438\n",
      "Epoch 6236 / 10000 loss: 13.294117450714111\n",
      "MSE train 5.30206345001503 MSE test 11.766210534660829\n",
      "MAE train 1.5861997593177508 MAE test 2.400356804758016\n",
      "Epoch 6237 / 10000 loss: 13.293699026107788\n",
      "MSE train 5.3019339597874104 MSE test 11.766125469337622\n",
      "MAE train 1.5861768451165652 MAE test 2.4003461998690754\n",
      "Epoch 6238 / 10000 loss: 13.293309688568115\n",
      "MSE train 5.30180688488575 MSE test 11.7660338109344\n",
      "MAE train 1.586153833649521 MAE test 2.4003398342873923\n",
      "Epoch 6239 / 10000 loss: 13.29276156425476\n",
      "MSE train 5.301689372996971 MSE test 11.765838213925853\n",
      "MAE train 1.586136140200416 MAE test 2.400315198286519\n",
      "Epoch 6240 / 10000 loss: 13.292288541793823\n",
      "MSE train 5.301562684519564 MSE test 11.765750933614916\n",
      "MAE train 1.5861132095745314 MAE test 2.4003094069897166\n",
      "Epoch 6241 / 10000 loss: 13.291860580444336\n",
      "MSE train 5.301446045400034 MSE test 11.765562243589804\n",
      "MAE train 1.586095625230259 MAE test 2.4002856539356747\n",
      "Epoch 6242 / 10000 loss: 13.291387796401978\n",
      "MSE train 5.301318518834731 MSE test 11.765468949404276\n",
      "MAE train 1.586072633584687 MAE test 2.4002791087655706\n",
      "Epoch 6243 / 10000 loss: 13.290960788726807\n",
      "MSE train 5.301204422679506 MSE test 11.765293915973269\n",
      "MAE train 1.5860554513948397 MAE test 2.4002570873058193\n",
      "Epoch 6244 / 10000 loss: 13.290488958358765\n",
      "MSE train 5.301075158287555 MSE test 11.765175901733318\n",
      "MAE train 1.5860324738085296 MAE test 2.4002473970399154\n",
      "Epoch 6245 / 10000 loss: 13.290064334869385\n",
      "MSE train 5.300969567546407 MSE test 11.765037528647307\n",
      "MAE train 1.586016790468225 MAE test 2.4002300202964846\n",
      "Epoch 6246 / 10000 loss: 13.289600849151611\n",
      "MSE train 5.300841381573708 MSE test 11.764849660865064\n",
      "MAE train 1.5859954870463278 MAE test 2.400211521276268\n",
      "Epoch 6247 / 10000 loss: 13.289187908172607\n",
      "MSE train 5.300721831905152 MSE test 11.764761315175498\n",
      "MAE train 1.5859752650659549 MAE test 2.400200491534308\n",
      "Epoch 6248 / 10000 loss: 13.288777351379395\n",
      "MSE train 5.300590646531648 MSE test 11.764610592979988\n",
      "MAE train 1.5859523817869425 MAE test 2.4001866565063064\n",
      "Epoch 6249 / 10000 loss: 13.288272380828857\n",
      "MSE train 5.300487378494917 MSE test 11.764497358714083\n",
      "MAE train 1.5859367889598024 MAE test 2.4001724654860257\n",
      "Epoch 6250 / 10000 loss: 13.287825107574463\n",
      "MSE train 5.300358360666839 MSE test 11.764283598792646\n",
      "MAE train 1.5859157765139524 MAE test 2.4001506811339386\n",
      "Epoch 6251 / 10000 loss: 13.287400245666504\n",
      "MSE train 5.300229221224761 MSE test 11.76419808207294\n",
      "MAE train 1.5858929764877845 MAE test 2.400140027349268\n",
      "Epoch 6252 / 10000 loss: 13.287009477615356\n",
      "MSE train 5.300101963069864 MSE test 11.764104973461393\n",
      "MAE train 1.5858699481549112 MAE test 2.4001334578315987\n",
      "Epoch 6253 / 10000 loss: 13.286463499069214\n",
      "MSE train 5.299984731304751 MSE test 11.763911027506383\n",
      "MAE train 1.585852307526278 MAE test 2.4001090407431365\n",
      "Epoch 6254 / 10000 loss: 13.285990476608276\n",
      "MSE train 5.299857647784784 MSE test 11.763820616346267\n",
      "MAE train 1.5858293493995224 MAE test 2.4001028352467806\n",
      "Epoch 6255 / 10000 loss: 13.285562992095947\n",
      "MSE train 5.299741882887047 MSE test 11.76363693722272\n",
      "MAE train 1.585811909388709 MAE test 2.400079700162456\n",
      "Epoch 6256 / 10000 loss: 13.285091161727905\n",
      "MSE train 5.299613451603955 MSE test 11.763534090928625\n",
      "MAE train 1.585788868746362 MAE test 2.40007192957536\n",
      "Epoch 6257 / 10000 loss: 13.284664392471313\n",
      "MSE train 5.299502698851651 MSE test 11.763373747567712\n",
      "MAE train 1.5857723070968281 MAE test 2.400051759310282\n",
      "Epoch 6258 / 10000 loss: 13.284195899963379\n",
      "MSE train 5.29937330051135 MSE test 11.76322649487149\n",
      "MAE train 1.585749839613639 MAE test 2.40003836631189\n",
      "Epoch 6259 / 10000 loss: 13.283774375915527\n",
      "MSE train 5.299269376526495 MSE test 11.763117572003221\n",
      "MAE train 1.5857340386203684 MAE test 2.400024753925982\n",
      "Epoch 6260 / 10000 loss: 13.28333067893982\n",
      "MSE train 5.299140964306144 MSE test 11.762903196480647\n",
      "MAE train 1.585713191629361 MAE test 2.4000028538603253\n",
      "Epoch 6261 / 10000 loss: 13.282902479171753\n",
      "MSE train 5.299011063854626 MSE test 11.762818415485974\n",
      "MAE train 1.585690205267318 MAE test 2.399992315597405\n",
      "Epoch 6262 / 10000 loss: 13.282515048980713\n",
      "MSE train 5.298884609632918 MSE test 11.762729548623572\n",
      "MAE train 1.5856672968389207 MAE test 2.3999862878503815\n",
      "Epoch 6263 / 10000 loss: 13.281965970993042\n",
      "MSE train 5.298766060502125 MSE test 11.762528132193797\n",
      "MAE train 1.5856495018278642 MAE test 2.3999609081223094\n",
      "Epoch 6264 / 10000 loss: 13.281492948532104\n",
      "MSE train 5.298641079784686 MSE test 11.762451185489974\n",
      "MAE train 1.5856267834236204 MAE test 2.399956413067409\n",
      "Epoch 6265 / 10000 loss: 13.281064987182617\n",
      "MSE train 5.298521705725466 MSE test 11.762243500705518\n",
      "MAE train 1.5856089500704618 MAE test 2.3999302459989695\n",
      "Epoch 6266 / 10000 loss: 13.280593872070312\n",
      "MSE train 5.298400013875081 MSE test 11.762183421884197\n",
      "MAE train 1.5855867650879396 MAE test 2.399927886721891\n",
      "Epoch 6267 / 10000 loss: 13.28016710281372\n",
      "MSE train 5.298278929170873 MSE test 11.761946107433015\n",
      "MAE train 1.5855690596008147 MAE test 2.399897964720459\n",
      "Epoch 6268 / 10000 loss: 13.279699325561523\n",
      "MSE train 5.2981665645008515 MSE test 11.76192808902628\n",
      "MAE train 1.5855484651464709 MAE test 2.3999009664084725\n",
      "Epoch 6269 / 10000 loss: 13.279284715652466\n",
      "MSE train 5.298047046918706 MSE test 11.76161495247822\n",
      "MAE train 1.585532673631095 MAE test 2.399861449070317\n",
      "Epoch 6270 / 10000 loss: 13.27882719039917\n",
      "MSE train 5.297912668653005 MSE test 11.761640420685957\n",
      "MAE train 1.585505577451776 MAE test 2.399869989943085\n",
      "Epoch 6271 / 10000 loss: 13.2784743309021\n",
      "MSE train 5.297790929436141 MSE test 11.761413172678107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5854874502652885 MAE test 2.399841324171766\n",
      "Epoch 6272 / 10000 loss: 13.277897119522095\n",
      "MSE train 5.297674019178551 MSE test 11.761369957356452\n",
      "MAE train 1.5854661751306693 MAE test 2.399841108056804\n",
      "Epoch 6273 / 10000 loss: 13.277473449707031\n",
      "MSE train 5.297552974040566 MSE test 11.761093450401777\n",
      "MAE train 1.5854492255890833 MAE test 2.399806190735966\n",
      "Epoch 6274 / 10000 loss: 13.277011156082153\n",
      "MSE train 5.297435892574891 MSE test 11.76110558465067\n",
      "MAE train 1.585426830765623 MAE test 2.3998130486470686\n",
      "Epoch 6275 / 10000 loss: 13.27662467956543\n",
      "MSE train 5.297314908304255 MSE test 11.760795423672745\n",
      "MAE train 1.5854105919603247 MAE test 2.399773875832116\n",
      "Epoch 6276 / 10000 loss: 13.276125431060791\n",
      "MSE train 5.297183405785097 MSE test 11.760818360159702\n",
      "MAE train 1.5853842918366279 MAE test 2.399782102803424\n",
      "Epoch 6277 / 10000 loss: 13.275765419006348\n",
      "MSE train 5.297060635368591 MSE test 11.760575870289344\n",
      "MAE train 1.5853661863572304 MAE test 2.3997514853623048\n",
      "Epoch 6278 / 10000 loss: 13.275201320648193\n",
      "MSE train 5.296948061484748 MSE test 11.760551903404874\n",
      "MAE train 1.585345618982385 MAE test 2.3997537383640846\n",
      "Epoch 6279 / 10000 loss: 13.274784326553345\n",
      "MSE train 5.29682766535979 MSE test 11.760242807713244\n",
      "MAE train 1.5853295146092268 MAE test 2.3997146863885344\n",
      "Epoch 6280 / 10000 loss: 13.274325370788574\n",
      "MSE train 5.296695976398575 MSE test 11.760266386930276\n",
      "MAE train 1.5853031538860816 MAE test 2.3997230068644804\n",
      "Epoch 6281 / 10000 loss: 13.273965835571289\n",
      "MSE train 5.296573224051707 MSE test 11.76002448595773\n",
      "MAE train 1.585285048163988 MAE test 2.399692458422771\n",
      "Epoch 6282 / 10000 loss: 13.273401021957397\n",
      "MSE train 5.296460612232447 MSE test 11.760000258280385\n",
      "MAE train 1.585264473964767 MAE test 2.3996946784533484\n",
      "Epoch 6283 / 10000 loss: 13.272983312606812\n",
      "MSE train 5.296340191522485 MSE test 11.759691851756342\n",
      "MAE train 1.5852483521330656 MAE test 2.3996557117391046\n",
      "Epoch 6284 / 10000 loss: 13.272525548934937\n",
      "MSE train 5.296208721586979 MSE test 11.7597152163363\n",
      "MAE train 1.5852220526756808 MAE test 2.3996640165328085\n",
      "Epoch 6285 / 10000 loss: 13.272165775299072\n",
      "MSE train 5.296085966051998 MSE test 11.759471911445036\n",
      "MAE train 1.585203967973555 MAE test 2.3996332875410684\n",
      "Epoch 6286 / 10000 loss: 13.271601438522339\n",
      "MSE train 5.295973535822422 MSE test 11.759449262307774\n",
      "MAE train 1.5851834139254821 MAE test 2.3996357090235074\n",
      "Epoch 6287 / 10000 loss: 13.27118444442749\n",
      "MSE train 5.295853098632784 MSE test 11.759138581645018\n",
      "MAE train 1.5851673339158074 MAE test 2.3995964350940158\n",
      "Epoch 6288 / 10000 loss: 13.270725727081299\n",
      "MSE train 5.295720647778367 MSE test 11.759162323085725\n",
      "MAE train 1.5851407681251124 MAE test 2.399604810144456\n",
      "Epoch 6289 / 10000 loss: 13.270368099212646\n",
      "MSE train 5.295598091862342 MSE test 11.758924601784829\n",
      "MAE train 1.5851226247434937 MAE test 2.399574774113094\n",
      "Epoch 6290 / 10000 loss: 13.269799947738647\n",
      "MSE train 5.295484455204153 MSE test 11.75889494870671\n",
      "MAE train 1.585101882461335 MAE test 2.3995763301974384\n",
      "Epoch 6291 / 10000 loss: 13.269379377365112\n",
      "MSE train 5.295363851061625 MSE test 11.758594292982606\n",
      "MAE train 1.5850855624573201 MAE test 2.399538324956009\n",
      "Epoch 6292 / 10000 loss: 13.268920660018921\n",
      "MSE train 5.295235909568717 MSE test 11.75861581815627\n",
      "MAE train 1.5850602083443386 MAE test 2.3995464167860447\n",
      "Epoch 6293 / 10000 loss: 13.268553972244263\n",
      "MSE train 5.295112978202911 MSE test 11.758353694065708\n",
      "MAE train 1.5850424542753612 MAE test 2.3995132878568817\n",
      "Epoch 6294 / 10000 loss: 13.26800537109375\n",
      "MSE train 5.2950011010767435 MSE test 11.7583504604047\n",
      "MAE train 1.5850216763714304 MAE test 2.399518207353259\n",
      "Epoch 6295 / 10000 loss: 13.267601728439331\n",
      "MSE train 5.294880401764252 MSE test 11.758025770255015\n",
      "MAE train 1.5850058021917937 MAE test 2.399477130431547\n",
      "Epoch 6296 / 10000 loss: 13.267131567001343\n",
      "MSE train 5.294742777722229 MSE test 11.758050797888812\n",
      "MAE train 1.584977840647157 MAE test 2.39948568807632\n",
      "Epoch 6297 / 10000 loss: 13.266784429550171\n",
      "MSE train 5.294623733909981 MSE test 11.757845629595623\n",
      "MAE train 1.584959951053035 MAE test 2.3994598152166113\n",
      "Epoch 6298 / 10000 loss: 13.266195058822632\n",
      "MSE train 5.294498114782522 MSE test 11.757763897135474\n",
      "MAE train 1.584937143404393 MAE test 2.3994546991441226\n",
      "Epoch 6299 / 10000 loss: 13.26576566696167\n",
      "MSE train 5.294379007322412 MSE test 11.757559487786493\n",
      "MAE train 1.5849192901691638 MAE test 2.399428937915063\n",
      "Epoch 6300 / 10000 loss: 13.265293598175049\n",
      "MSE train 5.294255570128167 MSE test 11.757491186947183\n",
      "MAE train 1.5848968078987233 MAE test 2.3994255519490624\n",
      "Epoch 6301 / 10000 loss: 13.264865398406982\n",
      "MSE train 5.294134848724286 MSE test 11.757267841461486\n",
      "MAE train 1.5848789169355257 MAE test 2.399397377750424\n",
      "Epoch 6302 / 10000 loss: 13.264394998550415\n",
      "MSE train 5.294018736729136 MSE test 11.757231342676423\n",
      "MAE train 1.5848577257335432 MAE test 2.3993980632380243\n",
      "Epoch 6303 / 10000 loss: 13.263973474502563\n",
      "MSE train 5.293898332984377 MSE test 11.756947403081162\n",
      "MAE train 1.5848410982925178 MAE test 2.399362183800124\n",
      "Epoch 6304 / 10000 loss: 13.263511896133423\n",
      "MSE train 5.293777322475221 MSE test 11.756964191380414\n",
      "MAE train 1.584817608747474 MAE test 2.3993696810323315\n",
      "Epoch 6305 / 10000 loss: 13.26313304901123\n",
      "MSE train 5.2936556671652335 MSE test 11.756668838284611\n",
      "MAE train 1.584800891790178 MAE test 2.3993323333847894\n",
      "Epoch 6306 / 10000 loss: 13.262615442276001\n",
      "MSE train 5.2935314876146595 MSE test 11.75668699577291\n",
      "MAE train 1.5847765411947126 MAE test 2.399340010313545\n",
      "Epoch 6307 / 10000 loss: 13.262240648269653\n",
      "MSE train 5.29340874633004 MSE test 11.756407543518035\n",
      "MAE train 1.5847592065616856 MAE test 2.399304668022831\n",
      "Epoch 6308 / 10000 loss: 13.261708736419678\n",
      "MSE train 5.293292355771112 MSE test 11.756416540076401\n",
      "MAE train 1.5847370142628083 MAE test 2.399311175057844\n",
      "Epoch 6309 / 10000 loss: 13.261318683624268\n",
      "MSE train 5.293170797118376 MSE test 11.756105025666136\n",
      "MAE train 1.5847206534056772 MAE test 2.3992717469621945\n",
      "Epoch 6310 / 10000 loss: 13.26082158088684\n",
      "MSE train 5.293039265995682 MSE test 11.75612713957328\n",
      "MAE train 1.5846943373135443 MAE test 2.3992799502964295\n",
      "Epoch 6311 / 10000 loss: 13.260461330413818\n",
      "MSE train 5.2929163290679755 MSE test 11.75588519487885\n",
      "MAE train 1.5846761710567554 MAE test 2.3992493846024874\n",
      "Epoch 6312 / 10000 loss: 13.259896039962769\n",
      "MSE train 5.292803398260671 MSE test 11.755859266136653\n",
      "MAE train 1.5846555465977963 MAE test 2.3992514177492286\n",
      "Epoch 6313 / 10000 loss: 13.25947880744934\n",
      "MSE train 5.292682856973511 MSE test 11.75555190078258\n",
      "MAE train 1.5846393536332504 MAE test 2.399212501881378\n",
      "Epoch 6314 / 10000 loss: 13.25901985168457\n",
      "MSE train 5.2925519553453215 MSE test 11.755574482515389\n",
      "MAE train 1.5846132174239296 MAE test 2.3992207913805013\n",
      "Epoch 6315 / 10000 loss: 13.258660078048706\n",
      "MSE train 5.292429016351464 MSE test 11.755327680132954\n",
      "MAE train 1.584595148899297 MAE test 2.399189588122042\n",
      "Epoch 6316 / 10000 loss: 13.258098125457764\n",
      "MSE train 5.29231705994776 MSE test 11.755308322118546\n",
      "MAE train 1.584574646346876 MAE test 2.3991924976976104\n",
      "Epoch 6317 / 10000 loss: 13.257682800292969\n",
      "MSE train 5.292196629785335 MSE test 11.75499257056719\n",
      "MAE train 1.584558652350681 MAE test 2.3991524840456373\n",
      "Epoch 6318 / 10000 loss: 13.257224082946777\n",
      "MSE train 5.292062047645138 MSE test 11.755016527319519\n",
      "MAE train 1.5845315124419228 MAE test 2.399160979294923\n",
      "Epoch 6319 / 10000 loss: 13.25687026977539\n",
      "MSE train 5.291940232621017 MSE test 11.754790469569203\n",
      "MAE train 1.5845133246318983 MAE test 2.399132433693377\n",
      "Epoch 6320 / 10000 loss: 13.256293535232544\n",
      "MSE train 5.291822506830613 MSE test 11.754743255490563\n",
      "MAE train 1.5844919094962442 MAE test 2.399131749304602\n",
      "Epoch 6321 / 10000 loss: 13.255868911743164\n",
      "MSE train 5.2917010718163295 MSE test 11.754471594834184\n",
      "MAE train 1.5844747529124492 MAE test 2.399097359812161\n",
      "Epoch 6322 / 10000 loss: 13.255404949188232\n",
      "MSE train 5.291585818978898 MSE test 11.754479859420785\n",
      "MAE train 1.5844528882850508 MAE test 2.399103851959621\n",
      "Epoch 6323 / 10000 loss: 13.255013465881348\n",
      "MSE train 5.291464855627095 MSE test 11.754162438049175\n",
      "MAE train 1.584436806544934 MAE test 2.3990635611208475\n",
      "Epoch 6324 / 10000 loss: 13.254523992538452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.29133015720326 MSE test 11.754185983116177\n",
      "MAE train 1.5844096220543618 MAE test 2.399072064703013\n",
      "Epoch 6325 / 10000 loss: 13.254170894622803\n",
      "MSE train 5.291208382232856 MSE test 11.753960876383056\n",
      "MAE train 1.5843914226239468 MAE test 2.399043621300258\n",
      "Epoch 6326 / 10000 loss: 13.253593683242798\n",
      "MSE train 5.291090095408752 MSE test 11.75391147109298\n",
      "MAE train 1.5843699090742762 MAE test 2.399042698487586\n",
      "Epoch 6327 / 10000 loss: 13.25316834449768\n",
      "MSE train 5.290968480752263 MSE test 11.753643796106278\n",
      "MAE train 1.5843526202310054 MAE test 2.3990087653944885\n",
      "Epoch 6328 / 10000 loss: 13.25270414352417\n",
      "MSE train 5.290854392609132 MSE test 11.753648953790389\n",
      "MAE train 1.584331124773618 MAE test 2.3990148924246637\n",
      "Epoch 6329 / 10000 loss: 13.252309322357178\n",
      "MSE train 5.290733659450469 MSE test 11.753327216266953\n",
      "MAE train 1.5843151668043527 MAE test 2.398973999447939\n",
      "Epoch 6330 / 10000 loss: 13.251827716827393\n",
      "MSE train 5.2905970768652715 MSE test 11.753351373148266\n",
      "MAE train 1.5842874931284745 MAE test 2.3989826418997797\n",
      "Epoch 6331 / 10000 loss: 13.251477003097534\n",
      "MSE train 5.290476523199602 MSE test 11.753137381885631\n",
      "MAE train 1.5842694079256465 MAE test 2.3989556386075144\n",
      "Epoch 6332 / 10000 loss: 13.250893354415894\n",
      "MSE train 5.290353815750359 MSE test 11.75306973636119\n",
      "MAE train 1.5842470839781935 MAE test 2.3989523394006866\n",
      "Epoch 6333 / 10000 loss: 13.250465154647827\n",
      "MSE train 5.290232209537424 MSE test 11.752836589734786\n",
      "MAE train 1.5842291388862024 MAE test 2.3989228431147773\n",
      "Epoch 6334 / 10000 loss: 13.24999451637268\n",
      "MSE train 5.290118233318093 MSE test 11.75280879447624\n",
      "MAE train 1.5842083037356025 MAE test 2.398924739897864\n",
      "Epoch 6335 / 10000 loss: 13.249576807022095\n",
      "MSE train 5.289997906411165 MSE test 11.752506476828035\n",
      "MAE train 1.5841920845854343 MAE test 2.3988863185563645\n",
      "Epoch 6336 / 10000 loss: 13.249117374420166\n",
      "MSE train 5.289868626493251 MSE test 11.752528091079046\n",
      "MAE train 1.5841663925612788 MAE test 2.3988946524230554\n",
      "Epoch 6337 / 10000 loss: 13.248753547668457\n",
      "MSE train 5.2897453579247244 MSE test 11.752270021841715\n",
      "MAE train 1.5841484638407959 MAE test 2.3988619265707825\n",
      "Epoch 6338 / 10000 loss: 13.248200416564941\n",
      "MSE train 5.2896335828565455 MSE test 11.752261739241275\n",
      "MAE train 1.5841278128767486 MAE test 2.3988663474767797\n",
      "Epoch 6339 / 10000 loss: 13.247793436050415\n",
      "MSE train 5.289512586902627 MSE test 11.751936558785898\n",
      "MAE train 1.5841118841969086 MAE test 2.3988249494704488\n",
      "Epoch 6340 / 10000 loss: 13.247327327728271\n",
      "MSE train 5.2893746165217586 MSE test 11.751960742281272\n",
      "MAE train 1.5840838611829469 MAE test 2.3988336691178125\n",
      "Epoch 6341 / 10000 loss: 13.246979713439941\n",
      "MSE train 5.289255013764936 MSE test 11.751753957513221\n",
      "MAE train 1.5840658706148856 MAE test 2.398807585824777\n",
      "Epoch 6342 / 10000 loss: 13.246389150619507\n",
      "MSE train 5.289129183539382 MSE test 11.751672281342627\n",
      "MAE train 1.5840430218339334 MAE test 2.3988024730664494\n",
      "Epoch 6343 / 10000 loss: 13.245960712432861\n",
      "MSE train 5.289009221573502 MSE test 11.751464535768259\n",
      "MAE train 1.5840250446649995 MAE test 2.3987763018289336\n",
      "Epoch 6344 / 10000 loss: 13.245487928390503\n",
      "MSE train 5.288886134106567 MSE test 11.7513989363074\n",
      "MAE train 1.584002623992054 MAE test 2.3987732869016227\n",
      "Epoch 6345 / 10000 loss: 13.245059967041016\n",
      "MSE train 5.2887644194223355 MSE test 11.751166894870787\n",
      "MAE train 1.58398467115623 MAE test 2.398743960707581\n",
      "Epoch 6346 / 10000 loss: 13.244588851928711\n",
      "MSE train 5.288649850982123 MSE test 11.751138951240698\n",
      "MAE train 1.583963733641246 MAE test 2.3987458544750577\n",
      "Epoch 6347 / 10000 loss: 13.244168758392334\n",
      "MSE train 5.288529194786092 MSE test 11.750836448826224\n",
      "MAE train 1.5839474711654915 MAE test 2.398707374244325\n",
      "Epoch 6348 / 10000 loss: 13.243709087371826\n",
      "MSE train 5.288399356556307 MSE test 11.75085783928127\n",
      "MAE train 1.5839216911839964 MAE test 2.398715731384521\n",
      "Epoch 6349 / 10000 loss: 13.243343830108643\n",
      "MSE train 5.288275617712242 MSE test 11.750599088901431\n",
      "MAE train 1.583903691609972 MAE test 2.3986829243499415\n",
      "Epoch 6350 / 10000 loss: 13.242788314819336\n",
      "MSE train 5.288163175525807 MSE test 11.750590493557723\n",
      "MAE train 1.5838829427317236 MAE test 2.3986873069623815\n",
      "Epoch 6351 / 10000 loss: 13.242379188537598\n",
      "MSE train 5.288041527119542 MSE test 11.750264596989313\n",
      "MAE train 1.5838669017741376 MAE test 2.3986457868605733\n",
      "Epoch 6352 / 10000 loss: 13.241911888122559\n",
      "MSE train 5.2879029194336775 MSE test 11.750288107488267\n",
      "MAE train 1.5838387799699427 MAE test 2.39865446195579\n",
      "Epoch 6353 / 10000 loss: 13.241562128067017\n",
      "MSE train 5.28778255452368 MSE test 11.750080774527934\n",
      "MAE train 1.5838206621001496 MAE test 2.398628312915784\n",
      "Epoch 6354 / 10000 loss: 13.240970373153687\n",
      "MSE train 5.287655875734542 MSE test 11.74999821077289\n",
      "MAE train 1.5837976816766504 MAE test 2.398623096641507\n",
      "Epoch 6355 / 10000 loss: 13.240538120269775\n",
      "MSE train 5.287535070217836 MSE test 11.74979012634958\n",
      "MAE train 1.5837795567019841 MAE test 2.3985968946360243\n",
      "Epoch 6356 / 10000 loss: 13.24006199836731\n",
      "MSE train 5.287410933705515 MSE test 11.749723165691249\n",
      "MAE train 1.5837569729059957 MAE test 2.3985937227895904\n",
      "Epoch 6357 / 10000 loss: 13.239631414413452\n",
      "MSE train 5.287288243228132 MSE test 11.749491244541172\n",
      "MAE train 1.583738841483324 MAE test 2.3985644133897788\n",
      "Epoch 6358 / 10000 loss: 13.239157676696777\n",
      "MSE train 5.287172403610137 MSE test 11.749461363172532\n",
      "MAE train 1.5837177030850491 MAE test 2.398566080344963\n",
      "Epoch 6359 / 10000 loss: 13.238734245300293\n",
      "MSE train 5.287050544026188 MSE test 11.749159848357275\n",
      "MAE train 1.5837011973421937 MAE test 2.3985277011942654\n",
      "Epoch 6360 / 10000 loss: 13.238270282745361\n",
      "MSE train 5.286920363290554 MSE test 11.749179921887313\n",
      "MAE train 1.5836754545686906 MAE test 2.398535955022402\n",
      "Epoch 6361 / 10000 loss: 13.237898826599121\n",
      "MSE train 5.286795325648688 MSE test 11.748915561469794\n",
      "MAE train 1.5836573393417264 MAE test 2.398502398390341\n",
      "Epoch 6362 / 10000 loss: 13.237343311309814\n",
      "MSE train 5.286681058416275 MSE test 11.748910337177207\n",
      "MAE train 1.5836361731359212 MAE test 2.398507314856936\n",
      "Epoch 6363 / 10000 loss: 13.236932754516602\n",
      "MSE train 5.286557816446315 MSE test 11.748583059454909\n",
      "MAE train 1.5836198659609133 MAE test 2.398465555343292\n",
      "Epoch 6364 / 10000 loss: 13.236455917358398\n",
      "MSE train 5.2864175157418885 MSE test 11.748605516942861\n",
      "MAE train 1.5835914749590125 MAE test 2.398474179598375\n",
      "Epoch 6365 / 10000 loss: 13.236101627349854\n",
      "MSE train 5.286295537577092 MSE test 11.748397487736362\n",
      "MAE train 1.5835731018452084 MAE test 2.398447971992679\n",
      "Epoch 6366 / 10000 loss: 13.23550295829773\n",
      "MSE train 5.286166912159901 MSE test 11.748313006167766\n",
      "MAE train 1.5835498195931728 MAE test 2.3984425357460206\n",
      "Epoch 6367 / 10000 loss: 13.235064268112183\n",
      "MSE train 5.286044365035206 MSE test 11.748105096559588\n",
      "MAE train 1.5835314091977934 MAE test 2.3984163873261686\n",
      "Epoch 6368 / 10000 loss: 13.234580993652344\n",
      "MSE train 5.285917668408355 MSE test 11.748034920000459\n",
      "MAE train 1.5835084215014779 MAE test 2.3984128419532613\n",
      "Epoch 6369 / 10000 loss: 13.234142780303955\n",
      "MSE train 5.285792935480173 MSE test 11.747806390750693\n",
      "MAE train 1.5834899079672125 MAE test 2.3983840151764273\n",
      "Epoch 6370 / 10000 loss: 13.233659982681274\n",
      "MSE train 5.285673390193245 MSE test 11.747769522087232\n",
      "MAE train 1.5834681854663177 MAE test 2.398384840785845\n",
      "Epoch 6371 / 10000 loss: 13.23322582244873\n",
      "MSE train 5.285548706582901 MSE test 11.74747692954541\n",
      "MAE train 1.5834510017434755 MAE test 2.398347664041927\n",
      "Epoch 6372 / 10000 loss: 13.232752084732056\n",
      "MSE train 5.285420693902696 MSE test 11.747492648011255\n",
      "MAE train 1.5834261279363802 MAE test 2.3983554435526298\n",
      "Epoch 6373 / 10000 loss: 13.232362031936646\n",
      "MSE train 5.285293521070511 MSE test 11.747204144978147\n",
      "MAE train 1.583408249746151 MAE test 2.398318781598743\n",
      "Epoch 6374 / 10000 loss: 13.231817722320557\n",
      "MSE train 5.285169068767118 MSE test 11.747213900651255\n",
      "MAE train 1.5833844409307722 MAE test 2.3983257902713024\n",
      "Epoch 6375 / 10000 loss: 13.231415510177612\n",
      "MSE train 5.2850415059303755 MSE test 11.746908714818927\n",
      "MAE train 1.5833668751164387 MAE test 2.3982869579056807\n",
      "Epoch 6376 / 10000 loss: 13.230887413024902\n",
      "MSE train 5.284908971378702 MSE test 11.746924679897548\n",
      "MAE train 1.5833409294116128 MAE test 2.3982948199322474\n",
      "Epoch 6377 / 10000 loss: 13.230496883392334\n",
      "MSE train 5.284779542611285 MSE test 11.74665306722921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5833222291909832 MAE test 2.3982604092086723\n",
      "Epoch 6378 / 10000 loss: 13.229931831359863\n",
      "MSE train 5.28466019628025 MSE test 11.746649803796265\n",
      "MAE train 1.5833001276783123 MAE test 2.398265720536277\n",
      "Epoch 6379 / 10000 loss: 13.229507446289062\n",
      "MSE train 5.284532306180807 MSE test 11.746322311415012\n",
      "MAE train 1.5832830538603446 MAE test 2.3982239927210833\n",
      "Epoch 6380 / 10000 loss: 13.229007005691528\n",
      "MSE train 5.284388316570259 MSE test 11.746343089253836\n",
      "MAE train 1.5832541749022913 MAE test 2.3982325550828234\n",
      "Epoch 6381 / 10000 loss: 13.22863221168518\n",
      "MSE train 5.284260927664123 MSE test 11.746128383164242\n",
      "MAE train 1.5832350221427673 MAE test 2.3982055739796935\n",
      "Epoch 6382 / 10000 loss: 13.22801923751831\n",
      "MSE train 5.284129643793486 MSE test 11.746052363894798\n",
      "MAE train 1.583211343560403 MAE test 2.398201375849157\n",
      "Epoch 6383 / 10000 loss: 13.227562189102173\n",
      "MSE train 5.284001013508569 MSE test 11.745825579384501\n",
      "MAE train 1.5831921697173912 MAE test 2.398172857882709\n",
      "Epoch 6384 / 10000 loss: 13.227062463760376\n",
      "MSE train 5.283876448490982 MSE test 11.745781681755735\n",
      "MAE train 1.583169640050704 MAE test 2.3981728739195884\n",
      "Epoch 6385 / 10000 loss: 13.2266104221344\n",
      "MSE train 5.283747948792367 MSE test 11.745498965176028\n",
      "MAE train 1.5831515743767273 MAE test 2.3981370609909063\n",
      "Epoch 6386 / 10000 loss: 13.226119041442871\n",
      "MSE train 5.283621871790677 MSE test 11.745509746684201\n",
      "MAE train 1.5831275421909983 MAE test 2.3981442901134296\n",
      "Epoch 6387 / 10000 loss: 13.225704431533813\n",
      "MSE train 5.283493160140863 MSE test 11.74520032543575\n",
      "MAE train 1.5831098907132535 MAE test 2.3981049867891775\n",
      "Epoch 6388 / 10000 loss: 13.225170135498047\n",
      "MSE train 5.283356737083597 MSE test 11.745218925702067\n",
      "MAE train 1.5830829807514497 MAE test 2.398113253621166\n",
      "Epoch 6389 / 10000 loss: 13.224776983261108\n",
      "MSE train 5.28322686360182 MSE test 11.744960838882042\n",
      "MAE train 1.5830638413868934 MAE test 2.3980806033406123\n",
      "Epoch 6390 / 10000 loss: 13.224194765090942\n",
      "MSE train 5.2831089515601635 MSE test 11.744947259241286\n",
      "MAE train 1.5830421961785321 MAE test 2.3980846702061496\n",
      "Epoch 6391 / 10000 loss: 13.223758697509766\n",
      "MSE train 5.282982385460878 MSE test 11.744621272000023\n",
      "MAE train 1.58302519176368 MAE test 2.398043179742839\n",
      "Epoch 6392 / 10000 loss: 13.223270654678345\n",
      "MSE train 5.282839798857748 MSE test 11.744644285324599\n",
      "MAE train 1.5829963599804178 MAE test 2.398052079193211\n",
      "Epoch 6393 / 10000 loss: 13.222898483276367\n",
      "MSE train 5.282714802094785 MSE test 11.744431689565793\n",
      "MAE train 1.5829773435818553 MAE test 2.39802538810005\n",
      "Epoch 6394 / 10000 loss: 13.2222900390625\n",
      "MSE train 5.282586125807734 MSE test 11.744356632616265\n",
      "MAE train 1.5829538660031806 MAE test 2.3980213689797374\n",
      "Epoch 6395 / 10000 loss: 13.221841096878052\n",
      "MSE train 5.282460954906527 MSE test 11.744133528414187\n",
      "MAE train 1.5829349504560193 MAE test 2.3979933237480773\n",
      "Epoch 6396 / 10000 loss: 13.221351385116577\n",
      "MSE train 5.282339454703446 MSE test 11.744089465268758\n",
      "MAE train 1.582912650553042 MAE test 2.397993390551176\n",
      "Epoch 6397 / 10000 loss: 13.220909833908081\n",
      "MSE train 5.282214658807858 MSE test 11.743812917939964\n",
      "MAE train 1.58289477506743 MAE test 2.397958351055725\n",
      "Epoch 6398 / 10000 loss: 13.220431089401245\n",
      "MSE train 5.28209409089453 MSE test 11.743823683315703\n",
      "MAE train 1.5828715521000425 MAE test 2.397965608780958\n",
      "Epoch 6399 / 10000 loss: 13.220027446746826\n",
      "MSE train 5.2819694057515365 MSE test 11.743509340129037\n",
      "MAE train 1.5828543674046882 MAE test 2.397925607595641\n",
      "Epoch 6400 / 10000 loss: 13.219515323638916\n",
      "MSE train 5.281833208518935 MSE test 11.743531874348504\n",
      "MAE train 1.5828267858362841 MAE test 2.397934426087788\n",
      "Epoch 6401 / 10000 loss: 13.219141483306885\n",
      "MSE train 5.281706665909749 MSE test 11.743292324284534\n",
      "MAE train 1.582807489994976 MAE test 2.3979041713536033\n",
      "Epoch 6402 / 10000 loss: 13.218557834625244\n",
      "MSE train 5.281588595040679 MSE test 11.74326059905287\n",
      "MAE train 1.5827854783475144 MAE test 2.3979058209379946\n",
      "Epoch 6403 / 10000 loss: 13.218122005462646\n",
      "MSE train 5.28146333855777 MSE test 11.742958888299674\n",
      "MAE train 1.5827677002627958 MAE test 2.397867453646228\n",
      "Epoch 6404 / 10000 loss: 13.217644929885864\n",
      "MSE train 5.281331054748005 MSE test 11.742978779123574\n",
      "MAE train 1.5827409667991332 MAE test 2.3978759058921804\n",
      "Epoch 6405 / 10000 loss: 13.217257976531982\n",
      "MSE train 5.281202329975287 MSE test 11.742710514177462\n",
      "MAE train 1.5827214351405738 MAE test 2.397841874404224\n",
      "Epoch 6406 / 10000 loss: 13.216691017150879\n",
      "MSE train 5.281083048363466 MSE test 11.742708622879775\n",
      "MAE train 1.5826982931288147 MAE test 2.3978474509820518\n",
      "Epoch 6407 / 10000 loss: 13.21626615524292\n",
      "MSE train 5.280954217401831 MSE test 11.742381815390528\n",
      "MAE train 1.582679781794047 MAE test 2.3978057758449713\n",
      "Epoch 6408 / 10000 loss: 13.215763568878174\n",
      "MSE train 5.280807641629986 MSE test 11.742404447732074\n",
      "MAE train 1.5826489106408101 MAE test 2.397814586903729\n",
      "Epoch 6409 / 10000 loss: 13.215380668640137\n",
      "MSE train 5.280676280811586 MSE test 11.742191971931518\n",
      "MAE train 1.5826271915591108 MAE test 2.397787856192878\n",
      "Epoch 6410 / 10000 loss: 13.214752912521362\n",
      "MSE train 5.280537492534083 MSE test 11.742113007988934\n",
      "MAE train 1.5825999467295582 MAE test 2.3977832815443407\n",
      "Epoch 6411 / 10000 loss: 13.214273929595947\n",
      "MSE train 5.28039882044449 MSE test 11.74189168923319\n",
      "MAE train 1.5825760984422326 MAE test 2.3977554180809584\n",
      "Epoch 6412 / 10000 loss: 13.213740587234497\n",
      "MSE train 5.280256432000501 MSE test 11.741837807097983\n",
      "MAE train 1.5825468740710684 MAE test 2.397754126898942\n",
      "Epoch 6413 / 10000 loss: 13.213236331939697\n",
      "MSE train 5.280104434922981 MSE test 11.741569286710439\n",
      "MAE train 1.5825195831719525 MAE test 2.397720062492028\n",
      "Epoch 6414 / 10000 loss: 13.212668657302856\n",
      "MSE train 5.279950204315249 MSE test 11.741566142243842\n",
      "MAE train 1.5824849874807672 MAE test 2.397725501497827\n",
      "Epoch 6415 / 10000 loss: 13.212135076522827\n",
      "MSE train 5.279773914756913 MSE test 11.741232668550673\n",
      "MAE train 1.5824506932714175 MAE test 2.3976829874119776\n",
      "Epoch 6416 / 10000 loss: 13.211477279663086\n",
      "MSE train 5.2795600380640915 MSE test 11.741248368050554\n",
      "MAE train 1.5823972517169453 MAE test 2.3976909272405695\n",
      "Epoch 6417 / 10000 loss: 13.210880279541016\n",
      "MSE train 5.279339550458275 MSE test 11.741030681745197\n",
      "MAE train 1.5823448953142238 MAE test 2.397663553951491\n",
      "Epoch 6418 / 10000 loss: 13.209947347640991\n",
      "MSE train 5.279089610526677 MSE test 11.740936252078438\n",
      "MAE train 1.582278880662225 MAE test 2.397657095818654\n",
      "Epoch 6419 / 10000 loss: 13.209057807922363\n",
      "MSE train 5.2788397935508 MSE test 11.740715926297309\n",
      "MAE train 1.582214823561441 MAE test 2.39762953384738\n",
      "Epoch 6420 / 10000 loss: 13.208015441894531\n",
      "MSE train 5.278607153726476 MSE test 11.740636268733954\n",
      "MAE train 1.5821533611584027 MAE test 2.397624947584679\n",
      "Epoch 6421 / 10000 loss: 13.206986904144287\n",
      "MSE train 5.278409701050365 MSE test 11.740395060518129\n",
      "MAE train 1.582107521846949 MAE test 2.3975944626397716\n",
      "Epoch 6422 / 10000 loss: 13.20601201057434\n",
      "MSE train 5.278245846007643 MSE test 11.740353852675474\n",
      "MAE train 1.5820683482499533 MAE test 2.397594799354715\n",
      "Epoch 6423 / 10000 loss: 13.205242395401001\n",
      "MSE train 5.278093422838533 MSE test 11.740048117942484\n",
      "MAE train 1.5820401562556619 MAE test 2.3975557346596377\n",
      "Epoch 6424 / 10000 loss: 13.204561710357666\n",
      "MSE train 5.277945267685416 MSE test 11.740061145729134\n",
      "MAE train 1.5820073156906471 MAE test 2.397563072554029\n",
      "Epoch 6425 / 10000 loss: 13.20404839515686\n",
      "MSE train 5.277806641974765 MSE test 11.739781394171972\n",
      "MAE train 1.5819841180651464 MAE test 2.397527258405471\n",
      "Epoch 6426 / 10000 loss: 13.203411102294922\n",
      "MSE train 5.277680626352743 MSE test 11.739780777196076\n",
      "MAE train 1.5819583558044625 MAE test 2.397532723763737\n",
      "Epoch 6427 / 10000 loss: 13.202945947647095\n",
      "MSE train 5.277550186595386 MSE test 11.73945551291371\n",
      "MAE train 1.5819389490473177 MAE test 2.397490915857126\n",
      "Epoch 6428 / 10000 loss: 13.202409744262695\n",
      "MSE train 5.277407799545816 MSE test 11.73947614563924\n",
      "MAE train 1.5819090467441397 MAE test 2.3974991776931005\n",
      "Epoch 6429 / 10000 loss: 13.202016592025757\n",
      "MSE train 5.277280617641104 MSE test 11.73925208868145\n",
      "MAE train 1.5818887714554364 MAE test 2.3974706096253042\n",
      "Epoch 6430 / 10000 loss: 13.201404809951782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.277156061341333 MSE test 11.739194108907682\n",
      "MAE train 1.58186520798486 MAE test 2.3974684862970226\n",
      "Epoch 6431 / 10000 loss: 13.200952529907227\n",
      "MSE train 5.27703044164966 MSE test 11.738937903065018\n",
      "MAE train 1.581846113974184 MAE test 2.397435708939731\n",
      "Epoch 6432 / 10000 loss: 13.200464963912964\n",
      "MSE train 5.276915714459639 MSE test 11.738932582487793\n",
      "MAE train 1.5818242212603835 MAE test 2.3974405251321604\n",
      "Epoch 6433 / 10000 loss: 13.200042009353638\n",
      "MSE train 5.27679294397972 MSE test 11.738606314444233\n",
      "MAE train 1.5818074051176465 MAE test 2.3973985956144492\n",
      "Epoch 6434 / 10000 loss: 13.199561834335327\n",
      "MSE train 5.276652917614086 MSE test 11.738632466287243\n",
      "MAE train 1.5817784065181861 MAE test 2.3974075779384743\n",
      "Epoch 6435 / 10000 loss: 13.199203968048096\n",
      "MSE train 5.276532722499371 MSE test 11.73843051109576\n",
      "MAE train 1.5817597972126654 MAE test 2.3973819216732712\n",
      "Epoch 6436 / 10000 loss: 13.198601961135864\n",
      "MSE train 5.276405039135505 MSE test 11.738344321160886\n",
      "MAE train 1.581736202758661 MAE test 2.3973760943192577\n",
      "Epoch 6437 / 10000 loss: 13.198163986206055\n",
      "MSE train 5.276286233650092 MSE test 11.738149794638803\n",
      "MAE train 1.581717887192085 MAE test 2.3973514457757723\n",
      "Epoch 6438 / 10000 loss: 13.19768500328064\n",
      "MSE train 5.276159380815918 MSE test 11.738067082349383\n",
      "MAE train 1.5816944922037033 MAE test 2.3973460876471786\n",
      "Epoch 6439 / 10000 loss: 13.197250366210938\n",
      "MSE train 5.2760411729756544 MSE test 11.737874589426237\n",
      "MAE train 1.5816763287063726 MAE test 2.397321722242843\n",
      "Epoch 6440 / 10000 loss: 13.196773767471313\n",
      "MSE train 5.275914801866992 MSE test 11.7377929767228\n",
      "MAE train 1.58165306485948 MAE test 2.3973165293364547\n",
      "Epoch 6441 / 10000 loss: 13.196341514587402\n",
      "MSE train 5.27579701413396 MSE test 11.73760149555365\n",
      "MAE train 1.5816350145946596 MAE test 2.3972923073219303\n",
      "Epoch 6442 / 10000 loss: 13.195866346359253\n",
      "MSE train 5.2756709699420385 MSE test 11.73752012579107\n",
      "MAE train 1.5816118466942575 MAE test 2.397287155797217\n",
      "Epoch 6443 / 10000 loss: 13.195436000823975\n",
      "MSE train 5.275553596496303 MSE test 11.737329378137371\n",
      "MAE train 1.5815938912971856 MAE test 2.397263039527973\n",
      "Epoch 6444 / 10000 loss: 13.1949622631073\n",
      "MSE train 5.275427725197131 MSE test 11.737247660576287\n",
      "MAE train 1.581570786128629 MAE test 2.3972578497708725\n",
      "Epoch 6445 / 10000 loss: 13.194532871246338\n",
      "MSE train 5.275310731497455 MSE test 11.737058534953785\n",
      "MAE train 1.5815529135161472 MAE test 2.39723394136223\n",
      "Epoch 6446 / 10000 loss: 13.194059610366821\n",
      "MSE train 5.275184738669558 MSE test 11.736974614390009\n",
      "MAE train 1.581529830770667 MAE test 2.397228470470182\n",
      "Epoch 6447 / 10000 loss: 13.193631887435913\n",
      "MSE train 5.2750687246531776 MSE test 11.736790014083882\n",
      "MAE train 1.581512108915289 MAE test 2.397205165616551\n",
      "Epoch 6448 / 10000 loss: 13.193160057067871\n",
      "MSE train 5.2749419246722296 MSE test 11.736698083890436\n",
      "MAE train 1.5814889949688327 MAE test 2.3971986556871454\n",
      "Epoch 6449 / 10000 loss: 13.192732810974121\n",
      "MSE train 5.274828798957607 MSE test 11.736527738547865\n",
      "MAE train 1.5814717734789143 MAE test 2.397177219702561\n",
      "Epoch 6450 / 10000 loss: 13.192262887954712\n",
      "MSE train 5.274700330417277 MSE test 11.736408715574584\n",
      "MAE train 1.5814487323052902 MAE test 2.3971671567971176\n",
      "Epoch 6451 / 10000 loss: 13.19183874130249\n",
      "MSE train 5.274596243215995 MSE test 11.736277185989213\n",
      "MAE train 1.5814330861229784 MAE test 2.397150834593432\n",
      "Epoch 6452 / 10000 loss: 13.191379308700562\n",
      "MSE train 5.274469077466952 MSE test 11.736085599867963\n",
      "MAE train 1.5814118225257912 MAE test 2.3971312696686846\n",
      "Epoch 6453 / 10000 loss: 13.190967082977295\n",
      "MSE train 5.274348049188932 MSE test 11.736002118603155\n",
      "MAE train 1.5813909253155687 MAE test 2.3971212778234694\n",
      "Epoch 6454 / 10000 loss: 13.190564632415771\n",
      "MSE train 5.27421802032814 MSE test 11.735866336837628\n",
      "MAE train 1.581367760475793 MAE test 2.3971089937705474\n",
      "Epoch 6455 / 10000 loss: 13.190050601959229\n",
      "MSE train 5.274115977395716 MSE test 11.735743563669818\n",
      "MAE train 1.5813524482869927 MAE test 2.3970938238772503\n",
      "Epoch 6456 / 10000 loss: 13.18959665298462\n",
      "MSE train 5.2739884191939 MSE test 11.735538202448621\n",
      "MAE train 1.5813313506831408 MAE test 2.397072432625076\n",
      "Epoch 6457 / 10000 loss: 13.189183712005615\n",
      "MSE train 5.273862583325419 MSE test 11.735455886001077\n",
      "MAE train 1.5813091378565696 MAE test 2.3970626186729813\n",
      "Epoch 6458 / 10000 loss: 13.188791275024414\n",
      "MSE train 5.273734537529583 MSE test 11.735350579281178\n",
      "MAE train 1.5812859022643606 MAE test 2.3970543310191545\n",
      "Epoch 6459 / 10000 loss: 13.18825650215149\n",
      "MSE train 5.27362389490409 MSE test 11.73518555646338\n",
      "MAE train 1.5812692358660465 MAE test 2.3970336034418853\n",
      "Epoch 6460 / 10000 loss: 13.18778944015503\n",
      "MSE train 5.2734952960305135 MSE test 11.735049021873943\n",
      "MAE train 1.5812464617817217 MAE test 2.3970212315380173\n",
      "Epoch 6461 / 10000 loss: 13.187369585037231\n",
      "MSE train 5.2733935595762285 MSE test 11.734933980242882\n",
      "MAE train 1.5812311192866766 MAE test 2.3970070814029274\n",
      "Epoch 6462 / 10000 loss: 13.18692135810852\n",
      "MSE train 5.273266666853904 MSE test 11.73472383874028\n",
      "MAE train 1.5812102919231734 MAE test 2.396985081464449\n",
      "Epoch 6463 / 10000 loss: 13.186505794525146\n",
      "MSE train 5.273138812316679 MSE test 11.734642716302975\n",
      "MAE train 1.5811875415980947 MAE test 2.3969754421930296\n",
      "Epoch 6464 / 10000 loss: 13.186121225357056\n",
      "MSE train 5.273012947000983 MSE test 11.734551326540544\n",
      "MAE train 1.581164589393035 MAE test 2.3969689790446624\n",
      "Epoch 6465 / 10000 loss: 13.185578346252441\n",
      "MSE train 5.2728974557217345 MSE test 11.73436296182872\n",
      "MAE train 1.5811470671289432 MAE test 2.3969451882686355\n",
      "Epoch 6466 / 10000 loss: 13.185109615325928\n",
      "MSE train 5.272771524843486 MSE test 11.734271487622706\n",
      "MAE train 1.5811241524717297 MAE test 2.3969387590206095\n",
      "Epoch 6467 / 10000 loss: 13.184686422348022\n",
      "MSE train 5.272658514258031 MSE test 11.734097737463225\n",
      "MAE train 1.5811070182299263 MAE test 2.3969168942968606\n",
      "Epoch 6468 / 10000 loss: 13.1842200756073\n",
      "MSE train 5.272530871582935 MSE test 11.733985086338258\n",
      "MAE train 1.5810840827593289 MAE test 2.3969076747168874\n",
      "Epoch 6469 / 10000 loss: 13.183797597885132\n",
      "MSE train 5.272425769389419 MSE test 11.733845840688895\n",
      "MAE train 1.5810683326017305 MAE test 2.3968903548174043\n",
      "Epoch 6470 / 10000 loss: 13.183338165283203\n",
      "MSE train 5.272298884179169 MSE test 11.733668262698014\n",
      "MAE train 1.5810468516335103 MAE test 2.3968726435381855\n",
      "Epoch 6471 / 10000 loss: 13.18292784690857\n",
      "MSE train 5.272184828581066 MSE test 11.733581308071871\n",
      "MAE train 1.581027800494843 MAE test 2.396862208018078\n",
      "Epoch 6472 / 10000 loss: 13.182516098022461\n",
      "MSE train 5.272055846861051 MSE test 11.733414247371774\n",
      "MAE train 1.5810055427428296 MAE test 2.3968458453234116\n",
      "Epoch 6473 / 10000 loss: 13.182032346725464\n",
      "MSE train 5.271948744170286 MSE test 11.733318444879332\n",
      "MAE train 1.5809884213960763 MAE test 2.396834247705277\n",
      "Epoch 6474 / 10000 loss: 13.18160605430603\n",
      "MSE train 5.271820547974862 MSE test 11.733123796908156\n",
      "MAE train 1.580966941487902 MAE test 2.3968142869894056\n",
      "Epoch 6475 / 10000 loss: 13.181153535842896\n",
      "MSE train 5.271700758563473 MSE test 11.73303876781077\n",
      "MAE train 1.58094637203673 MAE test 2.396804109870672\n",
      "Epoch 6476 / 10000 loss: 13.18075156211853\n",
      "MSE train 5.271571117514377 MSE test 11.732902381624719\n",
      "MAE train 1.58092330977941 MAE test 2.396791757403414\n",
      "Epoch 6477 / 10000 loss: 13.180242776870728\n",
      "MSE train 5.271469664842786 MSE test 11.73277959306376\n",
      "MAE train 1.5809081475683995 MAE test 2.3967765903907234\n",
      "Epoch 6478 / 10000 loss: 13.17979121208191\n",
      "MSE train 5.271342620582285 MSE test 11.732574827852401\n",
      "MAE train 1.5808871596460765 MAE test 2.3967553047933623\n",
      "Epoch 6479 / 10000 loss: 13.179379940032959\n",
      "MSE train 5.2712175146105 MSE test 11.73249289540512\n",
      "MAE train 1.5808651310622026 MAE test 2.3967455562354543\n",
      "Epoch 6480 / 10000 loss: 13.17898941040039\n",
      "MSE train 5.271089858216656 MSE test 11.732386642344625\n",
      "MAE train 1.5808420053511494 MAE test 2.3967371515443627\n",
      "Epoch 6481 / 10000 loss: 13.17845892906189\n",
      "MSE train 5.270980184400018 MSE test 11.732223950095415\n",
      "MAE train 1.5808255421479493 MAE test 2.3967167434897974\n",
      "Epoch 6482 / 10000 loss: 13.177994728088379\n",
      "MSE train 5.270852063133979 MSE test 11.732084134152867\n",
      "MAE train 1.58080293257206 MAE test 2.396703964270269\n",
      "Epoch 6483 / 10000 loss: 13.177577018737793\n",
      "MSE train 5.27075064318814 MSE test 11.73197253328748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5807876108656667 MAE test 2.396690283027869\n",
      "Epoch 6484 / 10000 loss: 13.177133321762085\n",
      "MSE train 5.270624046942577 MSE test 11.73176149784753\n",
      "MAE train 1.5807668688709775 MAE test 2.3966681836907027\n",
      "Epoch 6485 / 10000 loss: 13.176716566085815\n",
      "MSE train 5.270496374262008 MSE test 11.731680532890913\n",
      "MAE train 1.5807441481402509 MAE test 2.3966585731859715\n",
      "Epoch 6486 / 10000 loss: 13.176334142684937\n",
      "MSE train 5.270371387199763 MSE test 11.731592067574834\n",
      "MAE train 1.5807213406615583 MAE test 2.396652505072465\n",
      "Epoch 6487 / 10000 loss: 13.175792455673218\n",
      "MSE train 5.270255448408899 MSE test 11.731399445434441\n",
      "MAE train 1.5807038003510687 MAE test 2.396628176645339\n",
      "Epoch 6488 / 10000 loss: 13.175326347351074\n",
      "MSE train 5.270131044423457 MSE test 11.731316222708262\n",
      "MAE train 1.5806810786266607 MAE test 2.3966228260447244\n",
      "Epoch 6489 / 10000 loss: 13.174903631210327\n",
      "MSE train 5.270015734527885 MSE test 11.731128803937779\n",
      "MAE train 1.5806636122110544 MAE test 2.396599194487629\n",
      "Epoch 6490 / 10000 loss: 13.174438238143921\n",
      "MSE train 5.269890880380046 MSE test 11.731043292645989\n",
      "MAE train 1.5806408515845207 MAE test 2.3965935490458774\n",
      "Epoch 6491 / 10000 loss: 13.174015760421753\n",
      "MSE train 5.269776828201435 MSE test 11.73086348873353\n",
      "MAE train 1.5806235629224725 MAE test 2.3965709208290624\n",
      "Epoch 6492 / 10000 loss: 13.173550128936768\n",
      "MSE train 5.269650633768412 MSE test 11.730765200648186\n",
      "MAE train 1.5806007111494285 MAE test 2.3965636050731107\n",
      "Epoch 6493 / 10000 loss: 13.173128843307495\n",
      "MSE train 5.269541153665652 MSE test 11.730606743281944\n",
      "MAE train 1.5805842479737777 MAE test 2.396543771014723\n",
      "Epoch 6494 / 10000 loss: 13.17266583442688\n",
      "MSE train 5.269413707176731 MSE test 11.730467245035648\n",
      "MAE train 1.5805618107827364 MAE test 2.396531049843913\n",
      "Epoch 6495 / 10000 loss: 13.172249555587769\n",
      "MSE train 5.269312206438813 MSE test 11.730358383995643\n",
      "MAE train 1.5805464337992168 MAE test 2.396517743546437\n",
      "Epoch 6496 / 10000 loss: 13.17180871963501\n",
      "MSE train 5.269185992416081 MSE test 11.73014690435206\n",
      "MAE train 1.5805257924392693 MAE test 2.3964956064155296\n",
      "Epoch 6497 / 10000 loss: 13.171391725540161\n",
      "MSE train 5.269058025121623 MSE test 11.730066469727056\n",
      "MAE train 1.580502994929445 MAE test 2.3964860754442543\n",
      "Epoch 6498 / 10000 loss: 13.171010255813599\n",
      "MSE train 5.268933697988131 MSE test 11.729980538980918\n",
      "MAE train 1.5804802911097582 MAE test 2.3964803457479493\n",
      "Epoch 6499 / 10000 loss: 13.1704683303833\n",
      "MSE train 5.268817158436823 MSE test 11.729783517252528\n",
      "MAE train 1.5804626934403847 MAE test 2.3964554504657527\n",
      "Epoch 6500 / 10000 loss: 13.170001745223999\n",
      "MSE train 5.268694234743321 MSE test 11.729708754513245\n",
      "MAE train 1.58044016584067 MAE test 2.396451211377237\n",
      "Epoch 6501 / 10000 loss: 13.169580221176147\n",
      "MSE train 5.26857697346011 MSE test 11.729506635655405\n",
      "MAE train 1.5804225282399096 MAE test 2.396425658942249\n",
      "Epoch 6502 / 10000 loss: 13.169115543365479\n",
      "MSE train 5.268456848144731 MSE test 11.729447060737641\n",
      "MAE train 1.5804004575169168 MAE test 2.3964234121574335\n",
      "Epoch 6503 / 10000 loss: 13.168695211410522\n",
      "MSE train 5.268337852888079 MSE test 11.729219168524832\n",
      "MAE train 1.58038285415624 MAE test 2.3963944907075945\n",
      "Epoch 6504 / 10000 loss: 13.168233156204224\n",
      "MSE train 5.2682264977135045 MSE test 11.729197867014218\n",
      "MAE train 1.5803623029117777 MAE test 2.396397286513827\n",
      "Epoch 6505 / 10000 loss: 13.167820930480957\n",
      "MSE train 5.2681087082508 MSE test 11.728898608796893\n",
      "MAE train 1.5803464166292016 MAE test 2.396359013464474\n",
      "Epoch 6506 / 10000 loss: 13.167370557785034\n",
      "MSE train 5.267981173187545 MSE test 11.72892567720114\n",
      "MAE train 1.5803208088734506 MAE test 2.3963681829635983\n",
      "Epoch 6507 / 10000 loss: 13.167014837265015\n",
      "MSE train 5.267860392248015 MSE test 11.728676862722168\n",
      "MAE train 1.5803030950016066 MAE test 2.396336505245498\n",
      "Epoch 6508 / 10000 loss: 13.166465520858765\n",
      "MSE train 5.26775130007331 MSE test 11.728669071460876\n",
      "MAE train 1.5802828407839278 MAE test 2.396341049455259\n",
      "Epoch 6509 / 10000 loss: 13.166061162948608\n",
      "MSE train 5.267632860642651 MSE test 11.728351341391546\n",
      "MAE train 1.58026715125413 MAE test 2.3963003514651033\n",
      "Epoch 6510 / 10000 loss: 13.165607452392578\n",
      "MSE train 5.26749864608397 MSE test 11.728380477497414\n",
      "MAE train 1.5802397080845874 MAE test 2.396309815114459\n",
      "Epoch 6511 / 10000 loss: 13.16526460647583\n",
      "MSE train 5.267380614417285 MSE test 11.728172383968129\n",
      "MAE train 1.580221926729852 MAE test 2.3962834603645944\n",
      "Epoch 6512 / 10000 loss: 13.164687633514404\n",
      "MSE train 5.2672599242494815 MSE test 11.7281069423039\n",
      "MAE train 1.5801997912721106 MAE test 2.3962804479791076\n",
      "Epoch 6513 / 10000 loss: 13.164265394210815\n",
      "MSE train 5.267140976861144 MSE test 11.727883107755755\n",
      "MAE train 1.5801821078218508 MAE test 2.3962520407595456\n",
      "Epoch 6514 / 10000 loss: 13.163803815841675\n",
      "MSE train 5.267028163640285 MSE test 11.727853799936886\n",
      "MAE train 1.5801613377042056 MAE test 2.396253779976124\n",
      "Epoch 6515 / 10000 loss: 13.163389921188354\n",
      "MSE train 5.266909941518434 MSE test 11.72756691299338\n",
      "MAE train 1.5801450813131361 MAE test 2.396217133905427\n",
      "Epoch 6516 / 10000 loss: 13.162937879562378\n",
      "MSE train 5.266788480695035 MSE test 11.727590125417255\n",
      "MAE train 1.5801210813542803 MAE test 2.3962257920571766\n",
      "Epoch 6517 / 10000 loss: 13.162571430206299\n",
      "MSE train 5.266668349786707 MSE test 11.7273122447029\n",
      "MAE train 1.5801041274120433 MAE test 2.3961902994645805\n",
      "Epoch 6518 / 10000 loss: 13.162049055099487\n",
      "MSE train 5.26655302422887 MSE test 11.727327656464913\n",
      "MAE train 1.5800818328835413 MAE test 2.3961979196335794\n",
      "Epoch 6519 / 10000 loss: 13.161668539047241\n",
      "MSE train 5.266433533256902 MSE test 11.727025301874235\n",
      "MAE train 1.580065560662819 MAE test 2.396159249434123\n",
      "Epoch 6520 / 10000 loss: 13.161173582077026\n",
      "MSE train 5.26630691530279 MSE test 11.727050450410257\n",
      "MAE train 1.5800401916406654 MAE test 2.396168161731355\n",
      "Epoch 6521 / 10000 loss: 13.160816431045532\n",
      "MSE train 5.266185939891457 MSE test 11.726799635201582\n",
      "MAE train 1.5800224575692916 MAE test 2.3961362065596923\n",
      "Epoch 6522 / 10000 loss: 13.160270690917969\n",
      "MSE train 5.26607698946748 MSE test 11.726792535301557\n",
      "MAE train 1.580002215760854 MAE test 2.3961408687803156\n",
      "Epoch 6523 / 10000 loss: 13.159867286682129\n",
      "MSE train 5.265958522241817 MSE test 11.726474511954446\n",
      "MAE train 1.5799865196596838 MAE test 2.3961001463036773\n",
      "Epoch 6524 / 10000 loss: 13.15941309928894\n",
      "MSE train 5.265824371983554 MSE test 11.726503433877044\n",
      "MAE train 1.579959087271971 MAE test 2.3961095753693877\n",
      "Epoch 6525 / 10000 loss: 13.159071445465088\n",
      "MSE train 5.265706484889418 MSE test 11.7262960653982\n",
      "MAE train 1.5799413262012354 MAE test 2.396083318011136\n",
      "Epoch 6526 / 10000 loss: 13.158494234085083\n",
      "MSE train 5.2655857425840376 MSE test 11.726229800641406\n",
      "MAE train 1.5799191798716727 MAE test 2.3960801905685827\n",
      "Epoch 6527 / 10000 loss: 13.15807318687439\n",
      "MSE train 5.265466912841574 MSE test 11.726007958680167\n",
      "MAE train 1.5799014934042548 MAE test 2.3960520720002223\n",
      "Epoch 6528 / 10000 loss: 13.15761137008667\n",
      "MSE train 5.265353727886197 MSE test 11.725976531729525\n",
      "MAE train 1.5798806582230143 MAE test 2.3960535285363878\n",
      "Epoch 6529 / 10000 loss: 13.157198429107666\n",
      "MSE train 5.265235481165649 MSE test 11.725693761315716\n",
      "MAE train 1.5798643072729932 MAE test 2.396017435367112\n",
      "Epoch 6530 / 10000 loss: 13.15674614906311\n",
      "MSE train 5.265115896848515 MSE test 11.72571562482624\n",
      "MAE train 1.5798408115736582 MAE test 2.3960259267452644\n",
      "Epoch 6531 / 10000 loss: 13.156376600265503\n",
      "MSE train 5.264996178642215 MSE test 11.725429689932943\n",
      "MAE train 1.5798241258821295 MAE test 2.395989391857794\n",
      "Epoch 6532 / 10000 loss: 13.155863285064697\n",
      "MSE train 5.264877240309924 MSE test 11.725449578553881\n",
      "MAE train 1.5798008184505 MAE test 2.395997622989882\n",
      "Epoch 6533 / 10000 loss: 13.15549111366272\n",
      "MSE train 5.264757166014738 MSE test 11.725162625220864\n",
      "MAE train 1.5797840655604327 MAE test 2.395960949127504\n",
      "Epoch 6534 / 10000 loss: 13.154979944229126\n",
      "MSE train 5.264638219697117 MSE test 11.725182183171816\n",
      "MAE train 1.5797607494483963 MAE test 2.3959691283941273\n",
      "Epoch 6535 / 10000 loss: 13.154608249664307\n",
      "MSE train 5.264518026926931 MSE test 11.724896045413955\n",
      "MAE train 1.5797439493222216 MAE test 2.3959325758715497\n",
      "Epoch 6536 / 10000 loss: 13.154096364974976\n",
      "MSE train 5.264399581770559 MSE test 11.724914987715165\n",
      "MAE train 1.5797207672473736 MAE test 2.395940663956128\n",
      "Epoch 6537 / 10000 loss: 13.15372371673584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.264279459958653 MSE test 11.724626828485468\n",
      "MAE train 1.5797040267486018 MAE test 2.395903846564906\n",
      "Epoch 6538 / 10000 loss: 13.1532142162323\n",
      "MSE train 5.264160060362925 MSE test 11.724646670494195\n",
      "MAE train 1.5796805872741648 MAE test 2.395912068553427\n",
      "Epoch 6539 / 10000 loss: 13.152843475341797\n",
      "MSE train 5.264039762537568 MSE test 11.724362692974172\n",
      "MAE train 1.5796637176544674 MAE test 2.395875793177473\n",
      "Epoch 6540 / 10000 loss: 13.152329921722412\n",
      "MSE train 5.263922342887714 MSE test 11.724380624179998\n",
      "MAE train 1.5796408177808463 MAE test 2.395883765675828\n",
      "Epoch 6541 / 10000 loss: 13.151955127716064\n",
      "MSE train 5.263802381050578 MSE test 11.724088403650326\n",
      "MAE train 1.5796242104093594 MAE test 2.3958464133512285\n",
      "Epoch 6542 / 10000 loss: 13.151450395584106\n",
      "MSE train 5.2636809044509745 MSE test 11.72411004694521\n",
      "MAE train 1.5796002129286137 MAE test 2.39585487225537\n",
      "Epoch 6543 / 10000 loss: 13.151083946228027\n",
      "MSE train 5.263560316591644 MSE test 11.72383543724139\n",
      "MAE train 1.5795830734266305 MAE test 2.3958198158733626\n",
      "Epoch 6544 / 10000 loss: 13.150561332702637\n",
      "MSE train 5.263446723463433 MSE test 11.72384794646726\n",
      "MAE train 1.579561261750383 MAE test 2.3958270788682827\n",
      "Epoch 6545 / 10000 loss: 13.150178670883179\n",
      "MSE train 5.263327403260521 MSE test 11.723540637328279\n",
      "MAE train 1.5795451364776376 MAE test 2.3957877736505044\n",
      "Epoch 6546 / 10000 loss: 13.14969253540039\n",
      "MSE train 5.263198489589746 MSE test 11.723567199577506\n",
      "MAE train 1.5795191236492767 MAE test 2.3957968907538687\n",
      "Epoch 6547 / 10000 loss: 13.149340629577637\n",
      "MSE train 5.263077945892627 MSE test 11.7233304031496\n",
      "MAE train 1.5795012361356189 MAE test 2.3957668009358244\n",
      "Epoch 6548 / 10000 loss: 13.148784875869751\n",
      "MSE train 5.2629674671655815 MSE test 11.723308226686656\n",
      "MAE train 1.5794808802652034 MAE test 2.395769480179203\n",
      "Epoch 6549 / 10000 loss: 13.148375272750854\n",
      "MSE train 5.262849105445782 MSE test 11.723007063978008\n",
      "MAE train 1.5794648879631175 MAE test 2.395730993848312\n",
      "Epoch 6550 / 10000 loss: 13.147925615310669\n",
      "MSE train 5.262721670941553 MSE test 11.723033806770408\n",
      "MAE train 1.579439287335288 MAE test 2.395740136508309\n",
      "Epoch 6551 / 10000 loss: 13.147571563720703\n",
      "MSE train 5.262600984280536 MSE test 11.722787776643576\n",
      "MAE train 1.5794215479299332 MAE test 2.3957088451704505\n",
      "Epoch 6552 / 10000 loss: 13.14702320098877\n",
      "MSE train 5.262491974053738 MSE test 11.722777380144839\n",
      "MAE train 1.5794013427019218 MAE test 2.395713073711031\n",
      "Epoch 6553 / 10000 loss: 13.146618843078613\n",
      "MSE train 5.262373733656506 MSE test 11.722462889968856\n",
      "MAE train 1.5793856369106627 MAE test 2.3956728378113215\n",
      "Epoch 6554 / 10000 loss: 13.146168231964111\n",
      "MSE train 5.262240725137966 MSE test 11.722491852018054\n",
      "MAE train 1.5793584976286186 MAE test 2.3956823018640434\n",
      "Epoch 6555 / 10000 loss: 13.145825147628784\n",
      "MSE train 5.26212208199713 MSE test 11.722278781777467\n",
      "MAE train 1.579340662755643 MAE test 2.395655328315893\n",
      "Epoch 6556 / 10000 loss: 13.145253419876099\n",
      "MSE train 5.2620038935817 MSE test 11.72222374717035\n",
      "MAE train 1.5793189973201098 MAE test 2.395653699885587\n",
      "Epoch 6557 / 10000 loss: 13.144834280014038\n",
      "MSE train 5.26188458584568 MSE test 11.721981857466952\n",
      "MAE train 1.5793015443183374 MAE test 2.395622972989222\n",
      "Epoch 6558 / 10000 loss: 13.1443772315979\n",
      "MSE train 5.261775498478294 MSE test 11.721974717497616\n",
      "MAE train 1.5792812795686497 MAE test 2.395627637709654\n",
      "Epoch 6559 / 10000 loss: 13.143975496292114\n",
      "MSE train 5.261657760161893 MSE test 11.721658927819021\n",
      "MAE train 1.5792657356747712 MAE test 2.3955872504280884\n",
      "Epoch 6560 / 10000 loss: 13.143523693084717\n",
      "MSE train 5.261523670635287 MSE test 11.72168888628921\n",
      "MAE train 1.5792382998458845 MAE test 2.3955968453813634\n",
      "Epoch 6561 / 10000 loss: 13.143183708190918\n",
      "MSE train 5.2614059821031285 MSE test 11.721482406586865\n",
      "MAE train 1.5792205713961074 MAE test 2.3955707367721946\n",
      "Epoch 6562 / 10000 loss: 13.142608165740967\n",
      "MSE train 5.261285400805889 MSE test 11.72141705542223\n",
      "MAE train 1.579198445954425 MAE test 2.3955677627115803\n",
      "Epoch 6563 / 10000 loss: 13.14218807220459\n",
      "MSE train 5.2611666894934945 MSE test 11.721195605347917\n",
      "MAE train 1.5791807859475866 MAE test 2.395539736871623\n",
      "Epoch 6564 / 10000 loss: 13.141727924346924\n",
      "MSE train 5.2610537667292965 MSE test 11.721165260672066\n",
      "MAE train 1.5791599973956592 MAE test 2.3955413540554478\n",
      "Epoch 6565 / 10000 loss: 13.141315698623657\n",
      "MSE train 5.260935637995275 MSE test 11.720882267268696\n",
      "MAE train 1.5791436863874386 MAE test 2.3955052804457098\n",
      "Epoch 6566 / 10000 loss: 13.140864849090576\n",
      "MSE train 5.260815684790554 MSE test 11.720904912288429\n",
      "MAE train 1.5791200705054693 MAE test 2.3955138864760332\n",
      "Epoch 6567 / 10000 loss: 13.14049744606018\n",
      "MSE train 5.260695951470394 MSE test 11.72062236822273\n",
      "MAE train 1.5791033237541456 MAE test 2.3954778396636756\n",
      "Epoch 6568 / 10000 loss: 13.139982223510742\n",
      "MSE train 5.260578276232565 MSE test 11.720641323811808\n",
      "MAE train 1.5790803368771131 MAE test 2.395485953636522\n",
      "Epoch 6569 / 10000 loss: 13.139609336853027\n",
      "MSE train 5.260458509579844 MSE test 11.720350706182753\n",
      "MAE train 1.579063745856481 MAE test 2.3954488575511923\n",
      "Epoch 6570 / 10000 loss: 13.13910436630249\n",
      "MSE train 5.260337383637918 MSE test 11.720372685699688\n",
      "MAE train 1.5790398202236815 MAE test 2.3954573780563857\n",
      "Epoch 6571 / 10000 loss: 13.138737678527832\n",
      "MSE train 5.2602169885766505 MSE test 11.720097491160756\n",
      "MAE train 1.5790227384576256 MAE test 2.395422284614435\n",
      "Epoch 6572 / 10000 loss: 13.138216972351074\n",
      "MSE train 5.26010296048585 MSE test 11.72011133898561\n",
      "MAE train 1.579000782657183 MAE test 2.395429737644734\n",
      "Epoch 6573 / 10000 loss: 13.13783597946167\n",
      "MSE train 5.259983650649315 MSE test 11.71980662212689\n",
      "MAE train 1.5789846053676104 MAE test 2.395390809737666\n",
      "Epoch 6574 / 10000 loss: 13.137348890304565\n",
      "MSE train 5.259855665431597 MSE test 11.719833033430906\n",
      "MAE train 1.5789588369672456 MAE test 2.395399930771099\n",
      "Epoch 6575 / 10000 loss: 13.136994123458862\n",
      "MSE train 5.259734998842517 MSE test 11.719592209965482\n",
      "MAE train 1.5789409922533821 MAE test 2.3953693407292445\n",
      "Epoch 6576 / 10000 loss: 13.136443853378296\n",
      "MSE train 5.259625485043382 MSE test 11.719576125409159\n",
      "MAE train 1.5789207517545538 MAE test 2.3953728372352536\n",
      "Epoch 6577 / 10000 loss: 13.136037111282349\n",
      "MSE train 5.259507292299415 MSE test 11.7192682622882\n",
      "MAE train 1.57890491828902 MAE test 2.3953335009940533\n",
      "Epoch 6578 / 10000 loss: 13.13558840751648\n",
      "MSE train 5.2593767878169455 MSE test 11.719296668248935\n",
      "MAE train 1.5788784393808628 MAE test 2.395342886457005\n",
      "Epoch 6579 / 10000 loss: 13.135239601135254\n",
      "MSE train 5.259256843074533 MSE test 11.719069185374902\n",
      "MAE train 1.578860523543802 MAE test 2.3953140430456217\n",
      "Epoch 6580 / 10000 loss: 13.134678602218628\n",
      "MSE train 5.259144190397126 MSE test 11.719036947474926\n",
      "MAE train 1.5788398056204103 MAE test 2.395315435394945\n",
      "Epoch 6581 / 10000 loss: 13.134265184402466\n",
      "MSE train 5.259025612523621 MSE test 11.718753351079057\n",
      "MAE train 1.5788233706021024 MAE test 2.39527926731174\n",
      "Epoch 6582 / 10000 loss: 13.13381552696228\n",
      "MSE train 5.258906089273403 MSE test 11.718775169959665\n",
      "MAE train 1.5787998526836633 MAE test 2.395287772653795\n",
      "Epoch 6583 / 10000 loss: 13.13344693183899\n",
      "MSE train 5.258786314310283 MSE test 11.7184918849395\n",
      "MAE train 1.5787830954421669 MAE test 2.3952516310870102\n",
      "Epoch 6584 / 10000 loss: 13.132934331893921\n",
      "MSE train 5.258668398865822 MSE test 11.718511024300522\n",
      "MAE train 1.5787600216172564 MAE test 2.3952597887221563\n",
      "Epoch 6585 / 10000 loss: 13.132561206817627\n",
      "MSE train 5.258548602969834 MSE test 11.718221845333073\n",
      "MAE train 1.5787433665501358 MAE test 2.395222871264384\n",
      "Epoch 6586 / 10000 loss: 13.132055521011353\n",
      "MSE train 5.258428316153667 MSE test 11.718242929006946\n",
      "MAE train 1.5787196503503227 MAE test 2.39523129477026\n",
      "Epoch 6587 / 10000 loss: 13.131686687469482\n",
      "MSE train 5.258308047608452 MSE test 11.717964384761796\n",
      "MAE train 1.5787026539397087 MAE test 2.3951957641052566\n",
      "Epoch 6588 / 10000 loss: 13.13116979598999\n",
      "MSE train 5.258192687440272 MSE test 11.717980059574296\n",
      "MAE train 1.5786802943323448 MAE test 2.395203444868794\n",
      "Epoch 6589 / 10000 loss: 13.130791902542114\n",
      "MSE train 5.258073232913547 MSE test 11.717680676295341\n",
      "MAE train 1.5786639407514789 MAE test 2.3951651955445294\n",
      "Epoch 6590 / 10000 loss: 13.130297899246216\n",
      "MSE train 5.25794801729217 MSE test 11.717705132802184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5786388932390283 MAE test 2.3951740529771293\n",
      "Epoch 6591 / 10000 loss: 13.129938840866089\n",
      "MSE train 5.2578272832941355 MSE test 11.717450250479867\n",
      "MAE train 1.578621259940426 MAE test 2.395141615260705\n",
      "Epoch 6592 / 10000 loss: 13.12939977645874\n",
      "MSE train 5.257718308819219 MSE test 11.717447950599938\n",
      "MAE train 1.5786008896554742 MAE test 2.3951469244270465\n",
      "Epoch 6593 / 10000 loss: 13.129003047943115\n",
      "MSE train 5.257599986970165 MSE test 11.717129362840039\n",
      "MAE train 1.5785852064197348 MAE test 2.3951061552105295\n",
      "Epoch 6594 / 10000 loss: 13.12854528427124\n",
      "MSE train 5.257465803819659 MSE test 11.717158275730814\n",
      "MAE train 1.5785577109737197 MAE test 2.3951156050969233\n",
      "Epoch 6595 / 10000 loss: 13.1282057762146\n",
      "MSE train 5.257348719334726 MSE test 11.716954544033257\n",
      "MAE train 1.5785400303609867 MAE test 2.395089849529346\n",
      "Epoch 6596 / 10000 loss: 13.12762975692749\n",
      "MSE train 5.2572271192940025 MSE test 11.716882580413033\n",
      "MAE train 1.5785177157904138 MAE test 2.395085996546679\n",
      "Epoch 6597 / 10000 loss: 13.12721061706543\n",
      "MSE train 5.257109305769398 MSE test 11.716671447570494\n",
      "MAE train 1.5785000419731041 MAE test 2.395059289200368\n",
      "Epoch 6598 / 10000 loss: 13.126749515533447\n",
      "MSE train 5.256992912122709 MSE test 11.716624862099549\n",
      "MAE train 1.5784786435460705 MAE test 2.395058767135673\n",
      "Epoch 6599 / 10000 loss: 13.126332998275757\n",
      "MSE train 5.256874218940058 MSE test 11.716370492992398\n",
      "MAE train 1.5784615217792966 MAE test 2.3950263811950223\n",
      "Epoch 6600 / 10000 loss: 13.125878095626831\n",
      "MSE train 5.256764454523137 MSE test 11.716375117230417\n",
      "MAE train 1.578440827820274 MAE test 2.3950325907129484\n",
      "Epoch 6601 / 10000 loss: 13.12548828125\n",
      "MSE train 5.2566467595954585 MSE test 11.716054960089203\n",
      "MAE train 1.5784253120513052 MAE test 2.3949915792703\n",
      "Epoch 6602 / 10000 loss: 13.125025749206543\n",
      "MSE train 5.256511847909927 MSE test 11.716083766311716\n",
      "MAE train 1.5783976095250598 MAE test 2.3950010002382465\n",
      "Epoch 6603 / 10000 loss: 13.124689102172852\n",
      "MSE train 5.2563956654811665 MSE test 11.715884138456119\n",
      "MAE train 1.5783800425221899 MAE test 2.394975734049779\n",
      "Epoch 6604 / 10000 loss: 13.124110221862793\n",
      "MSE train 5.256272655962908 MSE test 11.715803153469933\n",
      "MAE train 1.578357515759919 MAE test 2.3949706686009007\n",
      "Epoch 6605 / 10000 loss: 13.123690843582153\n",
      "MSE train 5.256156716238797 MSE test 11.715606478951695\n",
      "MAE train 1.578340005981688 MAE test 2.3949458068539875\n",
      "Epoch 6606 / 10000 loss: 13.123229742050171\n",
      "MSE train 5.2560350386924215 MSE test 11.715534452787095\n",
      "MAE train 1.5783176572751396 MAE test 2.3949419130497507\n",
      "Epoch 6607 / 10000 loss: 13.122811317443848\n",
      "MSE train 5.2559179187122025 MSE test 11.715327304684811\n",
      "MAE train 1.5783000743265454 MAE test 2.394915682502436\n",
      "Epoch 6608 / 10000 loss: 13.122351884841919\n",
      "MSE train 5.255800360415533 MSE test 11.71527500520033\n",
      "MAE train 1.578278456587363 MAE test 2.3949143648588813\n",
      "Epoch 6609 / 10000 loss: 13.121935844421387\n",
      "MSE train 5.25568181034603 MSE test 11.715030455942289\n",
      "MAE train 1.5782611787302077 MAE test 2.3948832144058434\n",
      "Epoch 6610 / 10000 loss: 13.121479749679565\n",
      "MSE train 5.255573099598639 MSE test 11.71502501894435\n",
      "MAE train 1.5782409061601828 MAE test 2.39488802808403\n",
      "Epoch 6611 / 10000 loss: 13.121080875396729\n",
      "MSE train 5.255455874966787 MSE test 11.714705408173046\n",
      "MAE train 1.5782254931960666 MAE test 2.394847045521175\n",
      "Epoch 6612 / 10000 loss: 13.120630502700806\n",
      "MSE train 5.255321277281445 MSE test 11.714733371710677\n",
      "MAE train 1.5781978672167898 MAE test 2.3948562881433864\n",
      "Epoch 6613 / 10000 loss: 13.120294332504272\n",
      "MSE train 5.255204965776478 MSE test 11.714531047118685\n",
      "MAE train 1.5781803094213567 MAE test 2.394830612864187\n",
      "Epoch 6614 / 10000 loss: 13.119715929031372\n",
      "MSE train 5.255082666569694 MSE test 11.714452403051846\n",
      "MAE train 1.5781578980094106 MAE test 2.3948258187574125\n",
      "Epoch 6615 / 10000 loss: 13.119297742843628\n",
      "MSE train 5.254966147772685 MSE test 11.714249326567375\n",
      "MAE train 1.5781403751514076 MAE test 2.394800070006633\n",
      "Epoch 6616 / 10000 loss: 13.118837594985962\n",
      "MSE train 5.254846480896377 MSE test 11.714185769000563\n",
      "MAE train 1.5781183704439974 MAE test 2.394797224838964\n",
      "Epoch 6617 / 10000 loss: 13.118420839309692\n",
      "MSE train 5.25472826761231 MSE test 11.713959587935495\n",
      "MAE train 1.5781008565272063 MAE test 2.3947684527490942\n",
      "Epoch 6618 / 10000 loss: 13.117963075637817\n",
      "MSE train 5.254616901312219 MSE test 11.713931952765861\n",
      "MAE train 1.5780803023896557 MAE test 2.3947703264696543\n",
      "Epoch 6619 / 10000 loss: 13.1175537109375\n",
      "MSE train 5.254499584535855 MSE test 11.71363836054477\n",
      "MAE train 1.5780643379101003 MAE test 2.3947327056666583\n",
      "Epoch 6620 / 10000 loss: 13.117106914520264\n",
      "MSE train 5.254376062188069 MSE test 11.7136612062037\n",
      "MAE train 1.5780397100660064 MAE test 2.394741232623453\n",
      "Epoch 6621 / 10000 loss: 13.116748571395874\n",
      "MSE train 5.2542561730976685 MSE test 11.713395177535464\n",
      "MAE train 1.5780224692275344 MAE test 2.3947071819488657\n",
      "Epoch 6622 / 10000 loss: 13.116218566894531\n",
      "MSE train 5.254145998202136 MSE test 11.713399115808981\n",
      "MAE train 1.5780016185709769 MAE test 2.39471320252202\n",
      "Epoch 6623 / 10000 loss: 13.115830183029175\n",
      "MSE train 5.254027814384179 MSE test 11.71308049450467\n",
      "MAE train 1.5779859165087962 MAE test 2.3946722870440666\n",
      "Epoch 6624 / 10000 loss: 13.115363359451294\n",
      "MSE train 5.253895009562128 MSE test 11.71310636488705\n",
      "MAE train 1.5779587801099557 MAE test 2.394681226598513\n",
      "Epoch 6625 / 10000 loss: 13.115023136138916\n",
      "MSE train 5.253777258847627 MSE test 11.712893678959876\n",
      "MAE train 1.577941079198103 MAE test 2.394654158379899\n",
      "Epoch 6626 / 10000 loss: 13.114452123641968\n",
      "MSE train 5.2536585260890725 MSE test 11.712830679140271\n",
      "MAE train 1.577919292394445 MAE test 2.394651353612367\n",
      "Epoch 6627 / 10000 loss: 13.114035367965698\n",
      "MSE train 5.253539838021713 MSE test 11.712596022608706\n",
      "MAE train 1.5779017960733044 MAE test 2.3946214442653875\n",
      "Epoch 6628 / 10000 loss: 13.113578796386719\n",
      "MSE train 5.25343018114826 MSE test 11.712575619684484\n",
      "MAE train 1.5778815330933043 MAE test 2.3946242488032583\n",
      "Epoch 6629 / 10000 loss: 13.113173246383667\n",
      "MSE train 5.253313018690171 MSE test 11.712269252735847\n",
      "MAE train 1.577865865033292 MAE test 2.3945849335621583\n",
      "Epoch 6630 / 10000 loss: 13.112727165222168\n",
      "MSE train 5.253184068909442 MSE test 11.712294579314056\n",
      "MAE train 1.577839784539123 MAE test 2.3945937888161635\n",
      "Epoch 6631 / 10000 loss: 13.112379550933838\n",
      "MSE train 5.253064325449266 MSE test 11.712057735733977\n",
      "MAE train 1.5778220233309914 MAE test 2.39456354861967\n",
      "Epoch 6632 / 10000 loss: 13.111825704574585\n",
      "MSE train 5.252954204215763 MSE test 11.712031741931035\n",
      "MAE train 1.577801731010029 MAE test 2.3945656187285094\n",
      "Epoch 6633 / 10000 loss: 13.111418008804321\n",
      "MSE train 5.2528364860826064 MSE test 11.711730839482941\n",
      "MAE train 1.577785809293495 MAE test 2.394527017767375\n",
      "Epoch 6634 / 10000 loss: 13.110971212387085\n",
      "MSE train 5.252710610965228 MSE test 11.71175435013632\n",
      "MAE train 1.5777605627087496 MAE test 2.39453561354947\n",
      "Epoch 6635 / 10000 loss: 13.110617876052856\n",
      "MSE train 5.252590484240148 MSE test 11.711501800029527\n",
      "MAE train 1.5777429973218915 MAE test 2.3945033387432444\n",
      "Epoch 6636 / 10000 loss: 13.110076427459717\n",
      "MSE train 5.252482251780043 MSE test 11.711493274261196\n",
      "MAE train 1.5777228669991716 MAE test 2.394507688975878\n",
      "Epoch 6637 / 10000 loss: 13.109677791595459\n",
      "MSE train 5.252364465371597 MSE test 11.711173843932965\n",
      "MAE train 1.577707292233784 MAE test 2.3944666536786725\n",
      "Epoch 6638 / 10000 loss: 13.109227895736694\n",
      "MSE train 5.252231136449206 MSE test 11.71120032628514\n",
      "MAE train 1.577680001379228 MAE test 2.394475673842354\n",
      "Epoch 6639 / 10000 loss: 13.108889102935791\n",
      "MSE train 5.252114096400853 MSE test 11.710992183581686\n",
      "MAE train 1.577662389330442 MAE test 2.3944491874212877\n",
      "Epoch 6640 / 10000 loss: 13.108316421508789\n",
      "MSE train 5.251993832354531 MSE test 11.710922337438198\n",
      "MAE train 1.5776403321063543 MAE test 2.3944454987822987\n",
      "Epoch 6641 / 10000 loss: 13.107898950576782\n",
      "MSE train 5.251875888161384 MSE test 11.710701447642386\n",
      "MAE train 1.577622759857149 MAE test 2.3944173772449586\n",
      "Epoch 6642 / 10000 loss: 13.107441425323486\n",
      "MSE train 5.251762740696635 MSE test 11.710664425951528\n",
      "MAE train 1.5776019556588408 MAE test 2.394418004882646\n",
      "Epoch 6643 / 10000 loss: 13.107030868530273\n",
      "MSE train 5.251644953021129 MSE test 11.710386602463348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5775855405572847 MAE test 2.394382437517127\n",
      "Epoch 6644 / 10000 loss: 13.106581211090088\n",
      "MSE train 5.251528934493851 MSE test 11.71040309676148\n",
      "MAE train 1.5775629492635108 MAE test 2.39439009875506\n",
      "Epoch 6645 / 10000 loss: 13.106210231781006\n",
      "MSE train 5.251410363004582 MSE test 11.710104797408178\n",
      "MAE train 1.5775467533984637 MAE test 2.394351841505052\n",
      "Epoch 6646 / 10000 loss: 13.105713844299316\n",
      "MSE train 5.251286714462655 MSE test 11.71012663724333\n",
      "MAE train 1.5775220920217667 MAE test 2.3943602234587966\n",
      "Epoch 6647 / 10000 loss: 13.105355978012085\n",
      "MSE train 5.251166602661781 MSE test 11.709864611115526\n",
      "MAE train 1.5775047080161633 MAE test 2.3943267069648457\n",
      "Epoch 6648 / 10000 loss: 13.104823350906372\n",
      "MSE train 5.251057560364265 MSE test 11.709864819964181\n",
      "MAE train 1.5774842109751175 MAE test 2.394332218988864\n",
      "Epoch 6649 / 10000 loss: 13.104432344436646\n",
      "MSE train 5.250939538720149 MSE test 11.70954495111874\n",
      "MAE train 1.5774685861292745 MAE test 2.394291118750465\n",
      "Epoch 6650 / 10000 loss: 13.10397219657898\n",
      "MSE train 5.250806286843868 MSE test 11.709571266601012\n",
      "MAE train 1.5774413082179872 MAE test 2.394300119849978\n",
      "Epoch 6651 / 10000 loss: 13.103634595870972\n",
      "MSE train 5.25068934190802 MSE test 11.70936378365116\n",
      "MAE train 1.5774237074510888 MAE test 2.3942737429683243\n",
      "Epoch 6652 / 10000 loss: 13.10306167602539\n",
      "MSE train 5.2505690441724955 MSE test 11.709293294408324\n",
      "MAE train 1.5774016488669595 MAE test 2.3942699660630224\n",
      "Epoch 6653 / 10000 loss: 13.102644443511963\n",
      "MSE train 5.25045123243308 MSE test 11.709074053170108\n",
      "MAE train 1.5773840704164162 MAE test 2.394242072162859\n",
      "Epoch 6654 / 10000 loss: 13.102186679840088\n",
      "MSE train 5.25033770071458 MSE test 11.709035207459666\n",
      "MAE train 1.5773632107889475 MAE test 2.394242460660435\n",
      "Epoch 6655 / 10000 loss: 13.101775169372559\n",
      "MSE train 5.250219885819396 MSE test 11.708761457409944\n",
      "MAE train 1.577346690948284 MAE test 2.394207420151181\n",
      "Epoch 6656 / 10000 loss: 13.10132646560669\n",
      "MSE train 5.250105401729675 MSE test 11.70877628229571\n",
      "MAE train 1.5773245267183311 MAE test 2.394214863339428\n",
      "Epoch 6657 / 10000 loss: 13.1009521484375\n",
      "MSE train 5.249987227816191 MSE test 11.708472246990292\n",
      "MAE train 1.5773085433679073 MAE test 2.3941758671435305\n",
      "Epoch 6658 / 10000 loss: 13.100463151931763\n",
      "MSE train 5.249860655230814 MSE test 11.70849616415332\n",
      "MAE train 1.5772830883959343 MAE test 2.3941845453758597\n",
      "Epoch 6659 / 10000 loss: 13.100110292434692\n",
      "MSE train 5.24974067599064 MSE test 11.708249676191958\n",
      "MAE train 1.5772654399359296 MAE test 2.394153069519744\n",
      "Epoch 6660 / 10000 loss: 13.09956693649292\n",
      "MSE train 5.249632346603594 MSE test 11.70823530539634\n",
      "MAE train 1.5772453772118444 MAE test 2.3941566603782762\n",
      "Epoch 6661 / 10000 loss: 13.099164724349976\n",
      "MSE train 5.24951478270603 MSE test 11.707921180062362\n",
      "MAE train 1.5772297511840632 MAE test 2.3941163327382795\n",
      "Epoch 6662 / 10000 loss: 13.09871792793274\n",
      "MSE train 5.249383237724244 MSE test 11.707947436176577\n",
      "MAE train 1.5772029304850501 MAE test 2.3941253171594616\n",
      "Epoch 6663 / 10000 loss: 13.098376274108887\n",
      "MSE train 5.249264976715176 MSE test 11.707729137704566\n",
      "MAE train 1.577185183271106 MAE test 2.3940975230405614\n",
      "Epoch 6664 / 10000 loss: 13.097810745239258\n",
      "MSE train 5.249149096350544 MSE test 11.707677667708781\n",
      "MAE train 1.5771639431152122 MAE test 2.394096250920209\n",
      "Epoch 6665 / 10000 loss: 13.09739637374878\n",
      "MSE train 5.249030499099506 MSE test 11.707422905341009\n",
      "MAE train 1.577146799177695 MAE test 2.3940636901345815\n",
      "Epoch 6666 / 10000 loss: 13.096944093704224\n",
      "MSE train 5.248921753662893 MSE test 11.707423628705072\n",
      "MAE train 1.5771263778248 MAE test 2.3940692937562287\n",
      "Epoch 6667 / 10000 loss: 13.096552848815918\n",
      "MSE train 5.248804453464491 MSE test 11.707102953611631\n",
      "MAE train 1.5771109470041649 MAE test 2.3940281198079267\n",
      "Epoch 6668 / 10000 loss: 13.096096277236938\n",
      "MSE train 5.248670331945665 MSE test 11.707130172752334\n",
      "MAE train 1.5770834248283965 MAE test 2.394037245821104\n",
      "Epoch 6669 / 10000 loss: 13.095760583877563\n",
      "MSE train 5.2485544761333776 MSE test 11.70692910023749\n",
      "MAE train 1.577065947723813 MAE test 2.3940116951033454\n",
      "Epoch 6670 / 10000 loss: 13.095184564590454\n",
      "MSE train 5.248432273941044 MSE test 11.70684872409277\n",
      "MAE train 1.577043586533576 MAE test 2.3940066434053846\n",
      "Epoch 6671 / 10000 loss: 13.094767808914185\n",
      "MSE train 5.248316466915579 MSE test 11.706648955005692\n",
      "MAE train 1.577026151941312 MAE test 2.393981298925888\n",
      "Epoch 6672 / 10000 loss: 13.094309329986572\n",
      "MSE train 5.248196244464046 MSE test 11.706580735886766\n",
      "MAE train 1.5770040700891526 MAE test 2.393977847164033\n",
      "Epoch 6673 / 10000 loss: 13.093892812728882\n",
      "MSE train 5.248078891944914 MSE test 11.706364972190862\n",
      "MAE train 1.5769865431168475 MAE test 2.39395043176606\n",
      "Epoch 6674 / 10000 loss: 13.093436241149902\n",
      "MSE train 5.247964922341279 MSE test 11.706324917250445\n",
      "MAE train 1.5769655932461968 MAE test 2.3939506648864155\n",
      "Epoch 6675 / 10000 loss: 13.093024730682373\n",
      "MSE train 5.247847287643582 MSE test 11.706055508316842\n",
      "MAE train 1.576949016203216 MAE test 2.3939161993450786\n",
      "Epoch 6676 / 10000 loss: 13.092575073242188\n",
      "MSE train 5.247734269273063 MSE test 11.70606864068644\n",
      "MAE train 1.5769272448258589 MAE test 2.3939234371438234\n",
      "Epoch 6677 / 10000 loss: 13.092198371887207\n",
      "MSE train 5.247616516760679 MSE test 11.705759987784798\n",
      "MAE train 1.5769114550078953 MAE test 2.393883832733631\n",
      "Epoch 6678 / 10000 loss: 13.091716289520264\n",
      "MSE train 5.247487560926054 MSE test 11.705785298931298\n",
      "MAE train 1.5768853202580944 MAE test 2.3938926947888337\n",
      "Epoch 6679 / 10000 loss: 13.091370105743408\n",
      "MSE train 5.247368203491097 MSE test 11.705552867351663\n",
      "MAE train 1.5768675603203175 MAE test 2.3938630668815644\n",
      "Epoch 6680 / 10000 loss: 13.090815544128418\n",
      "MSE train 5.247257470336638 MSE test 11.70552232902055\n",
      "MAE train 1.5768471729583018 MAE test 2.3938645399305214\n",
      "Epoch 6681 / 10000 loss: 13.090406894683838\n",
      "MSE train 5.247139779978179 MSE test 11.705230364659355\n",
      "MAE train 1.5768310568281516 MAE test 2.3938271338313246\n",
      "Epoch 6682 / 10000 loss: 13.08996057510376\n",
      "MSE train 5.247017965189973 MSE test 11.70525198152383\n",
      "MAE train 1.57680684198854 MAE test 2.3938354924115424\n",
      "Epoch 6683 / 10000 loss: 13.089601755142212\n",
      "MSE train 5.246898381879872 MSE test 11.704982146083534\n",
      "MAE train 1.5767897555652803 MAE test 2.39380094218145\n",
      "Epoch 6684 / 10000 loss: 13.089077234268188\n",
      "MSE train 5.246787419023478 MSE test 11.704989665776596\n",
      "MAE train 1.5767685848392667 MAE test 2.393807440608406\n",
      "Epoch 6685 / 10000 loss: 13.088694095611572\n",
      "MSE train 5.246669321114141 MSE test 11.704676421802649\n",
      "MAE train 1.5767527982336715 MAE test 2.393767228717824\n",
      "Epoch 6686 / 10000 loss: 13.088221311569214\n",
      "MSE train 5.246538832434634 MSE test 11.704701888417427\n",
      "MAE train 1.576726227425534 MAE test 2.3937761035560645\n",
      "Epoch 6687 / 10000 loss: 13.087878465652466\n",
      "MSE train 5.246420275609454 MSE test 11.704479156137577\n",
      "MAE train 1.5767084640659814 MAE test 2.3937477493826784\n",
      "Epoch 6688 / 10000 loss: 13.08731722831726\n",
      "MSE train 5.246306208524643 MSE test 11.704434468610401\n",
      "MAE train 1.5766875313368087 MAE test 2.3937473640512543\n",
      "Epoch 6689 / 10000 loss: 13.08690333366394\n",
      "MSE train 5.246187972079409 MSE test 11.704167242232282\n",
      "MAE train 1.576670739757484 MAE test 2.3937131774498974\n",
      "Epoch 6690 / 10000 loss: 13.086454153060913\n",
      "MSE train 5.24607647366293 MSE test 11.704177352861327\n",
      "MAE train 1.576649390348668 MAE test 2.3937200227993087\n",
      "Epoch 6691 / 10000 loss: 13.086073875427246\n",
      "MSE train 5.245958776168066 MSE test 11.70386459939707\n",
      "MAE train 1.5766336875993985 MAE test 2.3936798865506677\n",
      "Epoch 6692 / 10000 loss: 13.085599660873413\n",
      "MSE train 5.245828216264946 MSE test 11.703890448460927\n",
      "MAE train 1.5766070903593872 MAE test 2.3936888072398155\n",
      "Epoch 6693 / 10000 loss: 13.085256814956665\n",
      "MSE train 5.24570971013142 MSE test 11.703668054828228\n",
      "MAE train 1.5765893334283259 MAE test 2.393660478717668\n",
      "Epoch 6694 / 10000 loss: 13.084694623947144\n",
      "MSE train 5.245595690737946 MSE test 11.70362334496742\n",
      "MAE train 1.5765684040630907 MAE test 2.393660095407859\n",
      "Epoch 6695 / 10000 loss: 13.08428168296814\n",
      "MSE train 5.245477438241358 MSE test 11.703356478035207\n",
      "MAE train 1.5765516020620296 MAE test 2.3936259515294704\n",
      "Epoch 6696 / 10000 loss: 13.083832263946533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.245366064871681 MSE test 11.70336625145695\n",
      "MAE train 1.5765302859665198 MAE test 2.393632751527593\n",
      "Epoch 6697 / 10000 loss: 13.083451747894287\n",
      "MSE train 5.245248414515797 MSE test 11.703053482603412\n",
      "MAE train 1.5765145912756628 MAE test 2.3935925908732063\n",
      "Epoch 6698 / 10000 loss: 13.082977771759033\n",
      "MSE train 5.245117793826268 MSE test 11.70307935855494\n",
      "MAE train 1.5764879674522312 MAE test 2.393601529086455\n",
      "Epoch 6699 / 10000 loss: 13.082634687423706\n",
      "MSE train 5.2449993701071405 MSE test 11.702857951859553\n",
      "MAE train 1.5764702127726327 MAE test 2.393573342437361\n",
      "Epoch 6700 / 10000 loss: 13.082072973251343\n",
      "MSE train 5.244885123224322 MSE test 11.702811881463715\n",
      "MAE train 1.5764492445189189 MAE test 2.393572779886594\n",
      "Epoch 6701 / 10000 loss: 13.08165955543518\n",
      "MSE train 5.244766880212664 MSE test 11.702547296248795\n",
      "MAE train 1.5764323868847554 MAE test 2.3935389433079344\n",
      "Epoch 6702 / 10000 loss: 13.081210136413574\n",
      "MSE train 5.244656216556928 MSE test 11.702555613681968\n",
      "MAE train 1.5764112731015032 MAE test 2.3935455416780065\n",
      "Epoch 6703 / 10000 loss: 13.080827474594116\n",
      "MSE train 5.244538666908106 MSE test 11.70224082490822\n",
      "MAE train 1.5763956517627324 MAE test 2.3935051317896328\n",
      "Epoch 6704 / 10000 loss: 13.080357074737549\n",
      "MSE train 5.244407201755582 MSE test 11.702267055249887\n",
      "MAE train 1.5763687875233092 MAE test 2.393514116506692\n",
      "Epoch 6705 / 10000 loss: 13.080016613006592\n",
      "MSE train 5.24428939560248 MSE test 11.702051267170932\n",
      "MAE train 1.5763510926213868 MAE test 2.393486653048968\n",
      "Epoch 6706 / 10000 loss: 13.079451084136963\n",
      "MSE train 5.2441729884283355 MSE test 11.701996535641095\n",
      "MAE train 1.576329730941661 MAE test 2.3934849625523085\n",
      "Epoch 6707 / 10000 loss: 13.079036951065063\n",
      "MSE train 5.244054651243749 MSE test 11.701748819371149\n",
      "MAE train 1.5763124918085276 MAE test 2.3934533344004234\n",
      "Epoch 6708 / 10000 loss: 13.078583240509033\n",
      "MSE train 5.2439467063466525 MSE test 11.701743812699092\n",
      "MAE train 1.576292332483902 MAE test 2.3934581649563325\n",
      "Epoch 6709 / 10000 loss: 13.078189134597778\n",
      "MSE train 5.243829832439214 MSE test 11.701424944379637\n",
      "MAE train 1.576276951306177 MAE test 2.3934172149338457\n",
      "Epoch 6710 / 10000 loss: 13.077739715576172\n",
      "MSE train 5.24369626561289 MSE test 11.70145228136161\n",
      "MAE train 1.5762495202584896 MAE test 2.393426362606849\n",
      "Epoch 6711 / 10000 loss: 13.077403783798218\n",
      "MSE train 5.243580362705815 MSE test 11.701249900431472\n",
      "MAE train 1.5762320357501254 MAE test 2.3934006564542014\n",
      "Epoch 6712 / 10000 loss: 13.076829433441162\n",
      "MSE train 5.243459157872344 MSE test 11.701173009647016\n",
      "MAE train 1.5762098076409936 MAE test 2.3933960399699514\n",
      "Epoch 6713 / 10000 loss: 13.07641339302063\n",
      "MSE train 5.243342868010669 MSE test 11.700967620189763\n",
      "MAE train 1.576192335639488 MAE test 2.3933699662198804\n",
      "Epoch 6714 / 10000 loss: 13.075954914093018\n",
      "MSE train 5.243225133243947 MSE test 11.700909493614928\n",
      "MAE train 1.5761706881887838 MAE test 2.393367838883549\n",
      "Epoch 6715 / 10000 loss: 13.075541734695435\n",
      "MSE train 5.243107225095989 MSE test 11.70067428548835\n",
      "MAE train 1.57615335767129 MAE test 2.3933378570778534\n",
      "Epoch 6716 / 10000 loss: 13.075087070465088\n",
      "MSE train 5.2429986457208795 MSE test 11.700659122980213\n",
      "MAE train 1.5761332222976352 MAE test 2.3933413575060554\n",
      "Epoch 6717 / 10000 loss: 13.074685335159302\n",
      "MSE train 5.24288216526282 MSE test 11.700349494228135\n",
      "MAE train 1.5761177565387523 MAE test 2.3933016230910713\n",
      "Epoch 6718 / 10000 loss: 13.074240922927856\n",
      "MSE train 5.242751745385353 MSE test 11.700376161472107\n",
      "MAE train 1.5760911527575263 MAE test 2.3933106600271854\n",
      "Epoch 6719 / 10000 loss: 13.073899984359741\n",
      "MSE train 5.242633376030591 MSE test 11.70015361055829\n",
      "MAE train 1.576073421170974 MAE test 2.3932823301336783\n",
      "Epoch 6720 / 10000 loss: 13.073338031768799\n",
      "MSE train 5.242519957913771 MSE test 11.700110637107418\n",
      "MAE train 1.576052586241137 MAE test 2.3932821702893587\n",
      "Epoch 6721 / 10000 loss: 13.072925567626953\n",
      "MSE train 5.242402008568558 MSE test 11.699841096730315\n",
      "MAE train 1.5760358913945047 MAE test 2.393247680618564\n",
      "Epoch 6722 / 10000 loss: 13.072477102279663\n",
      "MSE train 5.24228983824744 MSE test 11.69985284509803\n",
      "MAE train 1.5760142996926723 MAE test 2.3932547390031655\n",
      "Epoch 6723 / 10000 loss: 13.072099208831787\n",
      "MSE train 5.242172234480345 MSE test 11.699543751608353\n",
      "MAE train 1.5759985196932738 MAE test 2.3932150600046356\n",
      "Epoch 6724 / 10000 loss: 13.07162070274353\n",
      "MSE train 5.242043392997953 MSE test 11.699568796928718\n",
      "MAE train 1.5759723573305748 MAE test 2.3932238843018117\n",
      "Epoch 6725 / 10000 loss: 13.071274518966675\n",
      "MSE train 5.241924336492063 MSE test 11.699338158708617\n",
      "MAE train 1.5759545990578048 MAE test 2.3931944636041527\n",
      "Epoch 6726 / 10000 loss: 13.070719003677368\n",
      "MSE train 5.241813462505145 MSE test 11.699305365536516\n",
      "MAE train 1.5759341832291005 MAE test 2.393195645118458\n",
      "Epoch 6727 / 10000 loss: 13.070310354232788\n",
      "MSE train 5.241695982262604 MSE test 11.699017328173671\n",
      "MAE train 1.5759179825473 MAE test 2.393158736430514\n",
      "Epoch 6728 / 10000 loss: 13.069865226745605\n",
      "MSE train 5.24157619090277 MSE test 11.699037583426891\n",
      "MAE train 1.575894267401355 MAE test 2.3931669159512396\n",
      "Epoch 6729 / 10000 loss: 13.069501876831055\n",
      "MSE train 5.24145719630418 MSE test 11.698760230916537\n",
      "MAE train 1.5758774537895903 MAE test 2.3931313790049185\n",
      "Epoch 6730 / 10000 loss: 13.068986654281616\n",
      "MSE train 5.2413436940472415 MSE test 11.698772800496558\n",
      "MAE train 1.5758554710802335 MAE test 2.3931385448237195\n",
      "Epoch 6731 / 10000 loss: 13.068610906600952\n",
      "MSE train 5.24122538911137 MSE test 11.698470166412237\n",
      "MAE train 1.5758393707910792 MAE test 2.393099713190459\n",
      "Epoch 6732 / 10000 loss: 13.068124294281006\n",
      "MSE train 5.241100225179457 MSE test 11.698492981311194\n",
      "MAE train 1.575814218630961 MAE test 2.393108225436569\n",
      "Epoch 6733 / 10000 loss: 13.067770957946777\n",
      "MSE train 5.240980521363395 MSE test 11.6982432440186\n",
      "MAE train 1.5757966386826292 MAE test 2.3930763055637447\n",
      "Epoch 6734 / 10000 loss: 13.06723141670227\n",
      "MSE train 5.240872943386517 MSE test 11.698232650989443\n",
      "MAE train 1.5757766182840887 MAE test 2.3930804112992305\n",
      "Epoch 6735 / 10000 loss: 13.066833257675171\n",
      "MSE train 5.240755728694387 MSE test 11.69791665115123\n",
      "MAE train 1.575761065169347 MAE test 2.393039819314993\n",
      "Epoch 6736 / 10000 loss: 13.066385507583618\n",
      "MSE train 5.240623829176245 MSE test 11.69794288652362\n",
      "MAE train 1.5757340536933673 MAE test 2.393048821334043\n",
      "Epoch 6737 / 10000 loss: 13.066045999526978\n",
      "MSE train 5.2405067637242215 MSE test 11.697731317520327\n",
      "MAE train 1.575716430880794 MAE test 2.3930218922006112\n",
      "Epoch 6738 / 10000 loss: 13.065478563308716\n",
      "MSE train 5.240389005483368 MSE test 11.697669720121633\n",
      "MAE train 1.5756947953168738 MAE test 2.3930192817388596\n",
      "Epoch 6739 / 10000 loss: 13.065062522888184\n",
      "MSE train 5.240270964349693 MSE test 11.697435064706406\n",
      "MAE train 1.5756773785629796 MAE test 2.3929893609881963\n",
      "Epoch 6740 / 10000 loss: 13.064608097076416\n",
      "MSE train 5.2401623371110455 MSE test 11.697416723860464\n",
      "MAE train 1.575657253165752 MAE test 2.392992453129471\n",
      "Epoch 6741 / 10000 loss: 13.064205408096313\n",
      "MSE train 5.240045765910604 MSE test 11.6971103713194\n",
      "MAE train 1.575641674032531 MAE test 2.3929531290602544\n",
      "Epoch 6742 / 10000 loss: 13.063761472702026\n",
      "MSE train 5.239917056421231 MSE test 11.697136226906103\n",
      "MAE train 1.5756155157383809 MAE test 2.3929620669534213\n",
      "Epoch 6743 / 10000 loss: 13.063415765762329\n",
      "MSE train 5.239798169730238 MSE test 11.696904820999787\n",
      "MAE train 1.5755978010623664 MAE test 2.392932553440661\n",
      "Epoch 6744 / 10000 loss: 13.062861680984497\n",
      "MSE train 5.239687750275644 MSE test 11.696873999982069\n",
      "MAE train 1.5755774426573375 MAE test 2.3929339947952624\n",
      "Epoch 6745 / 10000 loss: 13.062453269958496\n",
      "MSE train 5.239570484382423 MSE test 11.696582874130488\n",
      "MAE train 1.5755613500273338 MAE test 2.392896663665358\n",
      "Epoch 6746 / 10000 loss: 13.062008142471313\n",
      "MSE train 5.239449462374048 MSE test 11.696604150187127\n",
      "MAE train 1.575537261185977 MAE test 2.3929049833197586\n",
      "Epoch 6747 / 10000 loss: 13.06164813041687\n",
      "MSE train 5.239330249167269 MSE test 11.696333545279682\n",
      "MAE train 1.575520231010648 MAE test 2.392870331740574\n",
      "Epoch 6748 / 10000 loss: 13.061125755310059\n",
      "MSE train 5.239219390324831 MSE test 11.696341598544784\n",
      "MAE train 1.5754989989828094 MAE test 2.3928769000543535\n",
      "Epoch 6749 / 10000 loss: 13.060744285583496\n",
      "MSE train 5.239101573532602 MSE test 11.696030157664936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5754831870757888 MAE test 2.3928369000937\n",
      "Epoch 6750 / 10000 loss: 13.060270309448242\n",
      "MSE train 5.238972244418473 MSE test 11.696054869678033\n",
      "MAE train 1.575456853837842 MAE test 2.392845681507498\n",
      "Epoch 6751 / 10000 loss: 13.059925317764282\n",
      "MSE train 5.2388536914005766 MSE test 11.695828466786173\n",
      "MAE train 1.5754390990024227 MAE test 2.392816809910575\n",
      "Epoch 6752 / 10000 loss: 13.059367656707764\n",
      "MSE train 5.238741507699262 MSE test 11.695789286739199\n",
      "MAE train 1.5754184530073028 MAE test 2.392817147434035\n",
      "Epoch 6753 / 10000 loss: 13.058956623077393\n",
      "MSE train 5.238623924230447 MSE test 11.69551201914253\n",
      "MAE train 1.5754019867403934 MAE test 2.3927816314076793\n",
      "Epoch 6754 / 10000 loss: 13.058509111404419\n",
      "MSE train 5.238509100817824 MSE test 11.695527272846657\n",
      "MAE train 1.5753795813611875 MAE test 2.3927891390251603\n",
      "Epoch 6755 / 10000 loss: 13.058138132095337\n",
      "MSE train 5.238391023078347 MSE test 11.695229476950596\n",
      "MAE train 1.5753634189606829 MAE test 2.392750932414889\n",
      "Epoch 6756 / 10000 loss: 13.057643413543701\n",
      "MSE train 5.238267986465894 MSE test 11.69525104163437\n",
      "MAE train 1.5753388002420612 MAE test 2.3927593000070546\n",
      "Epoch 6757 / 10000 loss: 13.057287454605103\n",
      "MSE train 5.238148478060872 MSE test 11.69499104095875\n",
      "MAE train 1.5753214315977024 MAE test 2.3927260029309285\n",
      "Epoch 6758 / 10000 loss: 13.056756258010864\n",
      "MSE train 5.238040400730903 MSE test 11.694989915938436\n",
      "MAE train 1.575301080952881 MAE test 2.3927313691108507\n",
      "Epoch 6759 / 10000 loss: 13.056365489959717\n",
      "MSE train 5.237922999625887 MSE test 11.694671474259811\n",
      "MAE train 1.5752855097623915 MAE test 2.392690444325517\n",
      "Epoch 6760 / 10000 loss: 13.055907726287842\n",
      "MSE train 5.237790602310226 MSE test 11.694697443259656\n",
      "MAE train 1.575258323590744 MAE test 2.3926994030909183\n",
      "Epoch 6761 / 10000 loss: 13.055569648742676\n",
      "MSE train 5.237674335787093 MSE test 11.694490400624284\n",
      "MAE train 1.5752407828721882 MAE test 2.392673072377016\n",
      "Epoch 6762 / 10000 loss: 13.054999113082886\n",
      "MSE train 5.237554898778338 MSE test 11.6944203021112\n",
      "MAE train 1.5752188161159282 MAE test 2.3926693445482208\n",
      "Epoch 6763 / 10000 loss: 13.054582595825195\n",
      "MSE train 5.23743770729031 MSE test 11.694201125927151\n",
      "MAE train 1.5752012987320743 MAE test 2.392641434478204\n",
      "Epoch 6764 / 10000 loss: 13.054126739501953\n",
      "MSE train 5.237325128170147 MSE test 11.694162782638402\n",
      "MAE train 1.5751805408629003 MAE test 2.3926418929196704\n",
      "Epoch 6765 / 10000 loss: 13.053715705871582\n",
      "MSE train 5.237207981218922 MSE test 11.693888386364922\n",
      "MAE train 1.5751641218229453 MAE test 2.392606750849152\n",
      "Epoch 6766 / 10000 loss: 13.053268194198608\n",
      "MSE train 5.2370937241441 MSE test 11.693903420269228\n",
      "MAE train 1.575141861098092 MAE test 2.3926142464116946\n",
      "Epoch 6767 / 10000 loss: 13.052895545959473\n",
      "MSE train 5.236976005401754 MSE test 11.693603152428958\n",
      "MAE train 1.5751258265851444 MAE test 2.392575693818893\n",
      "Epoch 6768 / 10000 loss: 13.05240511894226\n",
      "MSE train 5.2368515535373 MSE test 11.693625501239831\n",
      "MAE train 1.5751008126181354 MAE test 2.392584163494729\n",
      "Epoch 6769 / 10000 loss: 13.052050828933716\n",
      "MSE train 5.236732177619013 MSE test 11.693372691486235\n",
      "MAE train 1.575083325574504 MAE test 2.3925518192808393\n",
      "Epoch 6770 / 10000 loss: 13.051512718200684\n",
      "MSE train 5.2366247612390024 MSE test 11.693365085535905\n",
      "MAE train 1.5750632456771096 MAE test 2.39255631678482\n",
      "Epoch 6771 / 10000 loss: 13.051116466522217\n",
      "MSE train 5.236507670464521 MSE test 11.693047136045655\n",
      "MAE train 1.5750477191787167 MAE test 2.39251544236983\n",
      "Epoch 6772 / 10000 loss: 13.050665616989136\n",
      "MSE train 5.236375402213945 MSE test 11.69307297320748\n",
      "MAE train 1.5750205579650043 MAE test 2.3925243956130973\n",
      "Epoch 6773 / 10000 loss: 13.050327777862549\n",
      "MSE train 5.236259047248439 MSE test 11.692865136657913\n",
      "MAE train 1.5750030056253972 MAE test 2.3924979462008706\n",
      "Epoch 6774 / 10000 loss: 13.049757242202759\n",
      "MSE train 5.236140000246858 MSE test 11.692796314428374\n",
      "MAE train 1.5749810971336042 MAE test 2.392494374167249\n",
      "Epoch 6775 / 10000 loss: 13.049340963363647\n",
      "MSE train 5.236022707773263 MSE test 11.692574546263282\n",
      "MAE train 1.5749635934653181 MAE test 2.392466131283643\n",
      "Epoch 6776 / 10000 loss: 13.048885345458984\n",
      "MSE train 5.2359110018841 MSE test 11.692539558252948\n",
      "MAE train 1.5749429690769312 MAE test 2.392467025427668\n",
      "Epoch 6777 / 10000 loss: 13.04847502708435\n",
      "MSE train 5.2357941224683495 MSE test 11.69225855206707\n",
      "MAE train 1.574926732435045 MAE test 2.3924309997594646\n",
      "Epoch 6778 / 10000 loss: 13.048027753829956\n",
      "MSE train 5.235677226383714 MSE test 11.692276373167823\n",
      "MAE train 1.574903737474517 MAE test 2.3924388644907935\n",
      "Epoch 6779 / 10000 loss: 13.047660112380981\n",
      "MSE train 5.235559046099439 MSE test 11.691986877243512\n",
      "MAE train 1.5748873335284002 MAE test 2.3924017091563736\n",
      "Epoch 6780 / 10000 loss: 13.047157049179077\n",
      "MSE train 5.235440191166148 MSE test 11.692005003436037\n",
      "MAE train 1.5748638063794294 MAE test 2.3924096200047553\n",
      "Epoch 6781 / 10000 loss: 13.046791791915894\n",
      "MSE train 5.235321300398312 MSE test 11.691725716433325\n",
      "MAE train 1.57484700698883 MAE test 2.3923737928223052\n",
      "Epoch 6782 / 10000 loss: 13.046278238296509\n",
      "MSE train 5.235207629380455 MSE test 11.691737841311243\n",
      "MAE train 1.5748249049526515 MAE test 2.3923809024599394\n",
      "Epoch 6783 / 10000 loss: 13.045903205871582\n",
      "MSE train 5.235089401671695 MSE test 11.691437267942309\n",
      "MAE train 1.5748087242874793 MAE test 2.392342286579859\n",
      "Epoch 6784 / 10000 loss: 13.045412063598633\n",
      "MSE train 5.2349656792084 MSE test 11.691458345021356\n",
      "MAE train 1.5747838983491838 MAE test 2.3923505929226123\n",
      "Epoch 6785 / 10000 loss: 13.04505729675293\n",
      "MSE train 5.23484621553494 MSE test 11.691202611504549\n",
      "MAE train 1.574766429661963 MAE test 2.392317851334162\n",
      "Epoch 6786 / 10000 loss: 13.04452109336853\n",
      "MSE train 5.234738756773755 MSE test 11.691196807115492\n",
      "MAE train 1.5747462837201354 MAE test 2.392322589825097\n",
      "Epoch 6787 / 10000 loss: 13.044126749038696\n",
      "MSE train 5.234621610794783 MSE test 11.690878001293182\n",
      "MAE train 1.5747307408226574 MAE test 2.3922815861339095\n",
      "Epoch 6788 / 10000 loss: 13.043673515319824\n",
      "MSE train 5.234489282240852 MSE test 11.690903444743233\n",
      "MAE train 1.574703551229767 MAE test 2.39229049436083\n",
      "Epoch 6789 / 10000 loss: 13.043335199356079\n",
      "MSE train 5.2343731294133775 MSE test 11.6906963252264\n",
      "MAE train 1.5746860095426258 MAE test 2.392264126822232\n",
      "Epoch 6790 / 10000 loss: 13.042764902114868\n",
      "MSE train 5.234253705452107 MSE test 11.690625376168105\n",
      "MAE train 1.5746640267585783 MAE test 2.3922602779241537\n",
      "Epoch 6791 / 10000 loss: 13.042346715927124\n",
      "MSE train 5.234136656894773 MSE test 11.690406455992049\n",
      "MAE train 1.5746465074990612 MAE test 2.392232398256035\n",
      "Epoch 6792 / 10000 loss: 13.041889905929565\n",
      "MSE train 5.234023955850832 MSE test 11.690366481968642\n",
      "MAE train 1.5746257181344792 MAE test 2.39223264710674\n",
      "Epoch 6793 / 10000 loss: 13.041478157043457\n",
      "MSE train 5.233906888031965 MSE test 11.690093610991633\n",
      "MAE train 1.5746092478488327 MAE test 2.3921976874265294\n",
      "Epoch 6794 / 10000 loss: 13.041029930114746\n",
      "MSE train 5.233793438038728 MSE test 11.690106851789972\n",
      "MAE train 1.574587203964985 MAE test 2.3922049492102277\n",
      "Epoch 6795 / 10000 loss: 13.040655851364136\n",
      "MSE train 5.23367591219699 MSE test 11.689803414721439\n",
      "MAE train 1.5745712573373383 MAE test 2.39216596321426\n",
      "Epoch 6796 / 10000 loss: 13.040167808532715\n",
      "MSE train 5.233550190786577 MSE test 11.689825833806108\n",
      "MAE train 1.5745458784399076 MAE test 2.392174466551763\n",
      "Epoch 6797 / 10000 loss: 13.039815425872803\n",
      "MSE train 5.233430931615705 MSE test 11.689579851295457\n",
      "MAE train 1.5745282690566795 MAE test 2.3921429989489265\n",
      "Epoch 6798 / 10000 loss: 13.03927206993103\n",
      "MSE train 5.233323360333537 MSE test 11.689563816398149\n",
      "MAE train 1.5745082659128806 MAE test 2.3921463995258536\n",
      "Epoch 6799 / 10000 loss: 13.038870573043823\n",
      "MSE train 5.233206417235452 MSE test 11.689250936337436\n",
      "MAE train 1.574492648854104 MAE test 2.392106158965076\n",
      "Epoch 6800 / 10000 loss: 13.038422584533691\n",
      "MSE train 5.233076244187613 MSE test 11.689275521920043\n",
      "MAE train 1.5744660234889523 MAE test 2.3921149681811182\n",
      "Epoch 6801 / 10000 loss: 13.038080215454102\n",
      "MSE train 5.2329583942520195 MSE test 11.689054490301206\n",
      "MAE train 1.574448294558003 MAE test 2.3920867934953867\n",
      "Epoch 6802 / 10000 loss: 13.037517070770264\n",
      "MSE train 5.232844299633437 MSE test 11.689005577174829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5744272949404152 MAE test 2.3920858554424207\n",
      "Epoch 6803 / 10000 loss: 13.037103652954102\n",
      "MSE train 5.232726486688417 MSE test 11.688743331755521\n",
      "MAE train 1.5744103713923412 MAE test 2.392052284183836\n",
      "Epoch 6804 / 10000 loss: 13.036652565002441\n",
      "MSE train 5.2326170740516345 MSE test 11.688747886000076\n",
      "MAE train 1.5743895306501692 MAE test 2.3920584124893955\n",
      "Epoch 6805 / 10000 loss: 13.036267280578613\n",
      "MSE train 5.232500081419101 MSE test 11.688430525227359\n",
      "MAE train 1.5743739714249598 MAE test 2.3920175869182403\n",
      "Epoch 6806 / 10000 loss: 13.035800695419312\n",
      "MSE train 5.2323683004321095 MSE test 11.688455344431143\n",
      "MAE train 1.5743469137243689 MAE test 2.392026432751823\n",
      "Epoch 6807 / 10000 loss: 13.035462617874146\n",
      "MSE train 5.232251610189595 MSE test 11.688243931118212\n",
      "MAE train 1.5743293115115924 MAE test 2.3919995227089275\n",
      "Epoch 6808 / 10000 loss: 13.034892797470093\n",
      "MSE train 5.2321336599110175 MSE test 11.688178738556847\n",
      "MAE train 1.5743075785034613 MAE test 2.3919964603450197\n",
      "Epoch 6809 / 10000 loss: 13.03447675704956\n",
      "MSE train 5.232015972807039 MSE test 11.687946818824981\n",
      "MAE train 1.5742901277000099 MAE test 2.39196687722285\n",
      "Epoch 6810 / 10000 loss: 13.034021615982056\n",
      "MSE train 5.2319068326078915 MSE test 11.687922156385564\n",
      "MAE train 1.5742698921127343 MAE test 2.3919691710033684\n",
      "Epoch 6811 / 10000 loss: 13.033614873886108\n",
      "MSE train 5.231790372966303 MSE test 11.68762118054127\n",
      "MAE train 1.5742541351999622 MAE test 2.391930520344374\n",
      "Epoch 6812 / 10000 loss: 13.033170700073242\n",
      "MSE train 5.231664765777169 MSE test 11.687643830879335\n",
      "MAE train 1.5742287776674744 MAE test 2.391939093796682\n",
      "Epoch 6813 / 10000 loss: 13.032818794250488\n",
      "MSE train 5.2315456060392656 MSE test 11.687395084418156\n",
      "MAE train 1.5742112248170073 MAE test 2.391907282162023\n",
      "Epoch 6814 / 10000 loss: 13.032276391983032\n",
      "MSE train 5.231438195483223 MSE test 11.687381254153953\n",
      "MAE train 1.574191190859635 MAE test 2.39191100275631\n",
      "Epoch 6815 / 10000 loss: 13.03187608718872\n",
      "MSE train 5.231321208029656 MSE test 11.68706495735501\n",
      "MAE train 1.5741756031572154 MAE test 2.3918703389190124\n",
      "Epoch 6816 / 10000 loss: 13.031428337097168\n",
      "MSE train 5.231189946898042 MSE test 11.687088968807963\n",
      "MAE train 1.5741486836354717 MAE test 2.391879115781682\n",
      "Epoch 6817 / 10000 loss: 13.03108835220337\n",
      "MSE train 5.23107275312743 MSE test 11.68687342738083\n",
      "MAE train 1.5741310124151007 MAE test 2.391851681235033\n",
      "Epoch 6818 / 10000 loss: 13.030522108078003\n",
      "MSE train 5.230956099376609 MSE test 11.686813303918207\n",
      "MAE train 1.5741095207909974 MAE test 2.3918493116965363\n",
      "Epoch 6819 / 10000 loss: 13.030105113983154\n",
      "MSE train 5.230838081008314 MSE test 11.686569674930437\n",
      "MAE train 1.574092175989854 MAE test 2.3918182040100824\n",
      "Epoch 6820 / 10000 loss: 13.029651880264282\n",
      "MSE train 5.230730378839732 MSE test 11.686556299653969\n",
      "MAE train 1.574072076757167 MAE test 2.391822027648411\n",
      "Epoch 6821 / 10000 loss: 13.029253244400024\n",
      "MSE train 5.230613823750588 MSE test 11.686239741322174\n",
      "MAE train 1.5740565886024362 MAE test 2.3917813252597337\n",
      "Epoch 6822 / 10000 loss: 13.02880573272705\n",
      "MSE train 5.2304819984483215 MSE test 11.686263679811223\n",
      "MAE train 1.5740295328712468 MAE test 2.3917901272019844\n",
      "Epoch 6823 / 10000 loss: 13.028466701507568\n",
      "MSE train 5.230364970386466 MSE test 11.686049459373773\n",
      "MAE train 1.574011864345831 MAE test 2.391762885846546\n",
      "Epoch 6824 / 10000 loss: 13.027899265289307\n",
      "MSE train 5.230247497147082 MSE test 11.685986043934191\n",
      "MAE train 1.573990213781711 MAE test 2.3917601130334143\n",
      "Epoch 6825 / 10000 loss: 13.027482032775879\n",
      "MSE train 5.230129378682034 MSE test 11.68574711955706\n",
      "MAE train 1.5739727660730403 MAE test 2.391729658030269\n",
      "Epoch 6826 / 10000 loss: 13.027027606964111\n",
      "MSE train 5.230020982323747 MSE test 11.685727417628623\n",
      "MAE train 1.573952593671237 MAE test 2.3917326728284065\n",
      "Epoch 6827 / 10000 loss: 13.026625156402588\n",
      "MSE train 5.229904246666082 MSE test 11.685415850928635\n",
      "MAE train 1.5739369563553285 MAE test 2.3916926753507832\n",
      "Epoch 6828 / 10000 loss: 13.026179075241089\n",
      "MSE train 5.229774412386169 MSE test 11.68543816782299\n",
      "MAE train 1.5739104503271861 MAE test 2.3917012841101135\n",
      "Epoch 6829 / 10000 loss: 13.025835275650024\n",
      "MSE train 5.229655689776047 MSE test 11.685209628001095\n",
      "MAE train 1.5738926124735553 MAE test 2.3916721989667997\n",
      "Epoch 6830 / 10000 loss: 13.025274753570557\n",
      "MSE train 5.229543032202631 MSE test 11.6851662539824\n",
      "MAE train 1.5738718215948584 MAE test 2.391672111552933\n",
      "Epoch 6831 / 10000 loss: 13.024862051010132\n",
      "MSE train 5.2294249230102405 MSE test 11.684886567128606\n",
      "MAE train 1.5738551749055008 MAE test 2.391636332011004\n",
      "Epoch 6832 / 10000 loss: 13.024413108825684\n",
      "MSE train 5.229310005645097 MSE test 11.684896806560694\n",
      "MAE train 1.5738327556873029 MAE test 2.391643350221859\n",
      "Epoch 6833 / 10000 loss: 13.024038314819336\n",
      "MSE train 5.229191342111867 MSE test 11.684593404671482\n",
      "MAE train 1.573816449853006 MAE test 2.3916044662980798\n",
      "Epoch 6834 / 10000 loss: 13.023544549942017\n",
      "MSE train 5.2290668095759445 MSE test 11.68461031210934\n",
      "MAE train 1.5737914452240993 MAE test 2.3916124066351743\n",
      "Epoch 6835 / 10000 loss: 13.023185729980469\n",
      "MSE train 5.228946306089357 MSE test 11.684349608105858\n",
      "MAE train 1.5737737546672974 MAE test 2.3915791403655318\n",
      "Epoch 6836 / 10000 loss: 13.022649765014648\n",
      "MSE train 5.228837544661726 MSE test 11.684339251807629\n",
      "MAE train 1.5737533067933664 MAE test 2.3915834733869485\n",
      "Epoch 6837 / 10000 loss: 13.022251844406128\n",
      "MSE train 5.22871890810179 MSE test 11.684015392577475\n",
      "MAE train 1.5737374096492147 MAE test 2.3915419351473575\n",
      "Epoch 6838 / 10000 loss: 13.021793365478516\n",
      "MSE train 5.228584983513472 MSE test 11.6840346212754\n",
      "MAE train 1.5737098787904402 MAE test 2.3915502671301563\n",
      "Epoch 6839 / 10000 loss: 13.02144980430603\n",
      "MSE train 5.228466784596724 MSE test 11.683821231132413\n",
      "MAE train 1.573691901356032 MAE test 2.3915232859091122\n",
      "Epoch 6840 / 10000 loss: 13.020873069763184\n",
      "MSE train 5.228345118971431 MSE test 11.683743160119574\n",
      "MAE train 1.5736694117215109 MAE test 2.3915187389989194\n",
      "Epoch 6841 / 10000 loss: 13.020448684692383\n",
      "MSE train 5.2282252207826385 MSE test 11.683516222330667\n",
      "MAE train 1.5736512753179142 MAE test 2.391490041878264\n",
      "Epoch 6842 / 10000 loss: 13.019983530044556\n",
      "MSE train 5.228109290462712 MSE test 11.68346813300504\n",
      "MAE train 1.5736297682397895 MAE test 2.391489518354588\n",
      "Epoch 6843 / 10000 loss: 13.019560813903809\n",
      "MSE train 5.227987989979802 MSE test 11.683184863555796\n",
      "MAE train 1.5736123907725674 MAE test 2.391453451582868\n",
      "Epoch 6844 / 10000 loss: 13.019099235534668\n",
      "MSE train 5.22786914166255 MSE test 11.68318751435502\n",
      "MAE train 1.5735891571013867 MAE test 2.3914596905671557\n",
      "Epoch 6845 / 10000 loss: 13.018708229064941\n",
      "MSE train 5.227745141868028 MSE test 11.682873225495074\n",
      "MAE train 1.5735717481341729 MAE test 2.391419614475074\n",
      "Epoch 6846 / 10000 loss: 13.018197536468506\n",
      "MSE train 5.227611849829418 MSE test 11.682880810801661\n",
      "MAE train 1.5735447776912725 MAE test 2.391426631532038\n",
      "Epoch 6847 / 10000 loss: 13.01781702041626\n",
      "MSE train 5.227481597992344 MSE test 11.682615196312208\n",
      "MAE train 1.5735248342522676 MAE test 2.391393025578684\n",
      "Epoch 6848 / 10000 loss: 13.017238855361938\n",
      "MSE train 5.227359435359373 MSE test 11.682583123883996\n",
      "MAE train 1.57350157806464 MAE test 2.3913948716528712\n",
      "Epoch 6849 / 10000 loss: 13.016790866851807\n",
      "MSE train 5.2272213840312025 MSE test 11.682243978021864\n",
      "MAE train 1.5734813627075372 MAE test 2.3913517389130403\n",
      "Epoch 6850 / 10000 loss: 13.016275644302368\n",
      "MSE train 5.2270588289181505 MSE test 11.682239783412044\n",
      "MAE train 1.5734475690311662 MAE test 2.391357496380838\n",
      "Epoch 6851 / 10000 loss: 13.015838146209717\n",
      "MSE train 5.226892235468218 MSE test 11.681988740896719\n",
      "MAE train 1.5734189190802974 MAE test 2.391326275501728\n",
      "Epoch 6852 / 10000 loss: 13.015125751495361\n",
      "MSE train 5.22669266032316 MSE test 11.681881568941424\n",
      "MAE train 1.5733787642914054 MAE test 2.3913188157308745\n",
      "Epoch 6853 / 10000 loss: 13.014479398727417\n",
      "MSE train 5.226433348376636 MSE test 11.681577208408557\n",
      "MAE train 1.5733289898871168 MAE test 2.3912809513648607\n",
      "Epoch 6854 / 10000 loss: 13.013635635375977\n",
      "MSE train 5.226120767633175 MSE test 11.68148637983596\n",
      "MAE train 1.5732612822140126 MAE test 2.3912759865197466\n",
      "Epoch 6855 / 10000 loss: 13.012564420700073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.225838722971902 MSE test 11.68109745394645\n",
      "MAE train 1.5732068977676283 MAE test 2.391226786894049\n",
      "Epoch 6856 / 10000 loss: 13.011131763458252\n",
      "MSE train 5.225648179592194 MSE test 11.681080893630254\n",
      "MAE train 1.5731662843994687 MAE test 2.391230570143466\n",
      "Epoch 6857 / 10000 loss: 13.00998330116272\n",
      "MSE train 5.225510807512759 MSE test 11.680848780952202\n",
      "MAE train 1.5731442561013371 MAE test 2.391200891252044\n",
      "Epoch 6858 / 10000 loss: 13.009127378463745\n",
      "MSE train 5.225384015046632 MSE test 11.68078234130005\n",
      "MAE train 1.5731207865641101 MAE test 2.391197566909787\n",
      "Epoch 6859 / 10000 loss: 13.008618831634521\n",
      "MSE train 5.22525970872973 MSE test 11.680537284117985\n",
      "MAE train 1.5731023034315144 MAE test 2.3911661410020106\n",
      "Epoch 6860 / 10000 loss: 13.008122205734253\n",
      "MSE train 5.225147814732914 MSE test 11.680525121737874\n",
      "MAE train 1.5730815258499626 MAE test 2.3911700269830556\n",
      "Epoch 6861 / 10000 loss: 13.00769829750061\n",
      "MSE train 5.225028246895682 MSE test 11.680211566406326\n",
      "MAE train 1.573065553543989 MAE test 2.3911296300941927\n",
      "Epoch 6862 / 10000 loss: 13.007237672805786\n",
      "MSE train 5.22489439358555 MSE test 11.680239193099016\n",
      "MAE train 1.5730382334862767 MAE test 2.391138870333883\n",
      "Epoch 6863 / 10000 loss: 13.006888628005981\n",
      "MSE train 5.224775790154606 MSE test 11.680029534889915\n",
      "MAE train 1.573020368832833 MAE test 2.391112181490673\n",
      "Epoch 6864 / 10000 loss: 13.006313800811768\n",
      "MSE train 5.224657320800519 MSE test 11.679970961619597\n",
      "MAE train 1.5729986222604495 MAE test 2.3911099957471147\n",
      "Epoch 6865 / 10000 loss: 13.005894184112549\n",
      "MSE train 5.224538558396021 MSE test 11.679737512498773\n",
      "MAE train 1.5729811234184456 MAE test 2.3910801888500783\n",
      "Epoch 6866 / 10000 loss: 13.005438566207886\n",
      "MSE train 5.2244297109640225 MSE test 11.679723123635101\n",
      "MAE train 1.5729609596284804 MAE test 2.3910838564340056\n",
      "Epoch 6867 / 10000 loss: 13.00503420829773\n",
      "MSE train 5.224312861191294 MSE test 11.679418138215224\n",
      "MAE train 1.5729453388948176 MAE test 2.3910446430917776\n",
      "Epoch 6868 / 10000 loss: 13.004589319229126\n",
      "MSE train 5.2241833106055715 MSE test 11.679446399647464\n",
      "MAE train 1.5729189922566058 MAE test 2.3910540065845596\n",
      "Epoch 6869 / 10000 loss: 13.004245519638062\n",
      "MSE train 5.224064768608274 MSE test 11.679223471751577\n",
      "MAE train 1.5729012539714369 MAE test 2.3910255790981148\n",
      "Epoch 6870 / 10000 loss: 13.003689527511597\n",
      "MSE train 5.223952963928072 MSE test 11.679187964912483\n",
      "MAE train 1.572880687007067 MAE test 2.3910264503400005\n",
      "Epoch 6871 / 10000 loss: 13.003278970718384\n",
      "MSE train 5.22383552647148 MSE test 11.678912886120086\n",
      "MAE train 1.572864260434217 MAE test 2.3909911917957856\n",
      "Epoch 6872 / 10000 loss: 13.00283432006836\n",
      "MSE train 5.223720375544199 MSE test 11.678931394941843\n",
      "MAE train 1.572841777968879 MAE test 2.3909992225579324\n",
      "Epoch 6873 / 10000 loss: 13.002466440200806\n",
      "MSE train 5.223602449606296 MSE test 11.67864009671809\n",
      "MAE train 1.572825536597525 MAE test 2.3909618068858314\n",
      "Epoch 6874 / 10000 loss: 13.001973867416382\n",
      "MSE train 5.2234812891483795 MSE test 11.67866301853304\n",
      "MAE train 1.5728014071070757 MAE test 2.390970446186827\n",
      "Epoch 6875 / 10000 loss: 13.00161600112915\n",
      "MSE train 5.223362181591153 MSE test 11.678400098689897\n",
      "MAE train 1.572784250181084 MAE test 2.3909367528087313\n",
      "Epoch 6876 / 10000 loss: 13.001094818115234\n",
      "MSE train 5.2232532034209 MSE test 11.67840646476298\n",
      "MAE train 1.5727635508811377 MAE test 2.390943157546357\n",
      "Epoch 6877 / 10000 loss: 13.000712394714355\n",
      "MSE train 5.223135930782364 MSE test 11.678094766658672\n",
      "MAE train 1.5727478608979142 MAE test 2.3909030461699396\n",
      "Epoch 6878 / 10000 loss: 13.000250101089478\n",
      "MSE train 5.223005597315427 MSE test 11.678122380847109\n",
      "MAE train 1.5727212264146158 MAE test 2.390912327497338\n",
      "Epoch 6879 / 10000 loss: 12.999911785125732\n",
      "MSE train 5.222888465121284 MSE test 11.677909187225085\n",
      "MAE train 1.5727036080258003 MAE test 2.39088517392073\n",
      "Epoch 6880 / 10000 loss: 12.999352216720581\n",
      "MSE train 5.2227731580754115 MSE test 11.677856956663948\n",
      "MAE train 1.5726824140113422 MAE test 2.390883845135222\n",
      "Epoch 6881 / 10000 loss: 12.998941421508789\n",
      "MSE train 5.2226555371612715 MSE test 11.677611470533995\n",
      "MAE train 1.572665285969624 MAE test 2.390852468535212\n",
      "Epoch 6882 / 10000 loss: 12.998492956161499\n",
      "MSE train 5.222548425345488 MSE test 11.677609242988506\n",
      "MAE train 1.5726452272424616 MAE test 2.3908577473806023\n",
      "Epoch 6883 / 10000 loss: 12.998102903366089\n",
      "MSE train 5.2224322482639165 MSE test 11.677293987622285\n",
      "MAE train 1.5726298679055781 MAE test 2.390817161268379\n",
      "Epoch 6884 / 10000 loss: 12.997657537460327\n",
      "MSE train 5.222299872422639 MSE test 11.67732277474169\n",
      "MAE train 1.572602664031893 MAE test 2.390826616801142\n",
      "Epoch 6885 / 10000 loss: 12.997324705123901\n",
      "MSE train 5.222184621482779 MSE test 11.67712236003791\n",
      "MAE train 1.572585260948617 MAE test 2.3908011530883884\n",
      "Epoch 6886 / 10000 loss: 12.996756076812744\n",
      "MSE train 5.222064722229996 MSE test 11.677049020513428\n",
      "MAE train 1.5725632166516972 MAE test 2.390797026568458\n",
      "Epoch 6887 / 10000 loss: 12.996343851089478\n",
      "MSE train 5.221948896672439 MSE test 11.676843589538796\n",
      "MAE train 1.5725458181098373 MAE test 2.390770926756638\n",
      "Epoch 6888 / 10000 loss: 12.99589204788208\n",
      "MSE train 5.221833155644243 MSE test 11.676791942283057\n",
      "MAE train 1.5725245051547736 MAE test 2.390769679476204\n",
      "Epoch 6889 / 10000 loss: 12.995482444763184\n",
      "MSE train 5.221716000128447 MSE test 11.676551009523259\n",
      "MAE train 1.5725073987862583 MAE test 2.3907388979567736\n",
      "Epoch 6890 / 10000 loss: 12.99503493309021\n",
      "MSE train 5.221609010967193 MSE test 11.676546137987895\n",
      "MAE train 1.5724874053533398 MAE test 2.390743842520106\n",
      "Epoch 6891 / 10000 loss: 12.994642972946167\n",
      "MSE train 5.221493157538383 MSE test 11.676232060472243\n",
      "MAE train 1.5724720871549056 MAE test 2.3907034136166936\n",
      "Epoch 6892 / 10000 loss: 12.994199752807617\n",
      "MSE train 5.221361038575788 MSE test 11.676260919546264\n",
      "MAE train 1.5724449442511064 MAE test 2.3907128756547595\n",
      "Epoch 6893 / 10000 loss: 12.993868112564087\n",
      "MSE train 5.2212456260066515 MSE test 11.676058685406234\n",
      "MAE train 1.5724275226227467 MAE test 2.3906871805375367\n",
      "Epoch 6894 / 10000 loss: 12.993300914764404\n",
      "MSE train 5.221126437770376 MSE test 11.675988567045039\n",
      "MAE train 1.5724055907322627 MAE test 2.3906834834842967\n",
      "Epoch 6895 / 10000 loss: 12.992888927459717\n",
      "MSE train 5.221010208945305 MSE test 11.675776911815351\n",
      "MAE train 1.5723881660101937 MAE test 2.390656571860358\n",
      "Epoch 6896 / 10000 loss: 12.992438077926636\n",
      "MSE train 5.220896708960662 MSE test 11.675734278833033\n",
      "MAE train 1.5723672575239511 MAE test 2.3906565257971524\n",
      "Epoch 6897 / 10000 loss: 12.99203085899353\n",
      "MSE train 5.220779907707837 MSE test 11.67547537126651\n",
      "MAE train 1.5723505601445387 MAE test 2.3906233813097906\n",
      "Epoch 6898 / 10000 loss: 12.991586446762085\n",
      "MSE train 5.220670538976559 MSE test 11.675484704387554\n",
      "MAE train 1.5723296929270958 MAE test 2.3906301951075624\n",
      "Epoch 6899 / 10000 loss: 12.991207838058472\n",
      "MSE train 5.220554155373754 MSE test 11.675172762411261\n",
      "MAE train 1.5723141767341176 MAE test 2.3905900383206955\n",
      "Epoch 6900 / 10000 loss: 12.990745306015015\n",
      "MSE train 5.220423521889466 MSE test 11.675200451473179\n",
      "MAE train 1.5722874284980686 MAE test 2.3905993501960507\n",
      "Epoch 6901 / 10000 loss: 12.990411043167114\n",
      "MSE train 5.220306997758302 MSE test 11.674989932850874\n",
      "MAE train 1.5722698796429946 MAE test 2.390572563597031\n",
      "Epoch 6902 / 10000 loss: 12.989850044250488\n",
      "MSE train 5.220190926709738 MSE test 11.67493301307096\n",
      "MAE train 1.572248517982148 MAE test 2.3905706130970037\n",
      "Epoch 6903 / 10000 loss: 12.989439964294434\n",
      "MSE train 5.2200735460413625 MSE test 11.674695658036667\n",
      "MAE train 1.5722312709315978 MAE test 2.3905402919375542\n",
      "Epoch 6904 / 10000 loss: 12.98899221420288\n",
      "MSE train 5.219966514277856 MSE test 11.674684648838268\n",
      "MAE train 1.572211346590296 MAE test 2.390544417755943\n",
      "Epoch 6905 / 10000 loss: 12.988597631454468\n",
      "MSE train 5.219850652371774 MSE test 11.674374937899577\n",
      "MAE train 1.5721959174376898 MAE test 2.390504567882588\n",
      "Epoch 6906 / 10000 loss: 12.988158226013184\n",
      "MSE train 5.219720478390969 MSE test 11.674402933357758\n",
      "MAE train 1.5721692806570982 MAE test 2.3905139240282685\n",
      "Epoch 6907 / 10000 loss: 12.987823486328125\n",
      "MSE train 5.219603711022691 MSE test 11.674189479203202\n",
      "MAE train 1.5721517031036216 MAE test 2.3904867393925358\n",
      "Epoch 6908 / 10000 loss: 12.987264633178711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.219488888759122 MSE test 11.674137567246365\n",
      "MAE train 1.5721305766574278 MAE test 2.3904854526273898\n",
      "Epoch 6909 / 10000 loss: 12.986855745315552\n",
      "MSE train 5.219371566453863 MSE test 11.673890555381153\n",
      "MAE train 1.5721134948254114 MAE test 2.3904538531538884\n",
      "Epoch 6910 / 10000 loss: 12.986409425735474\n",
      "MSE train 5.219264664027053 MSE test 11.673888768767583\n",
      "MAE train 1.572093437595203 MAE test 2.3904592148567567\n",
      "Epoch 6911 / 10000 loss: 12.986021757125854\n",
      "MSE train 5.219148688044052 MSE test 11.673573122224411\n",
      "MAE train 1.572078080242566 MAE test 2.3904185589671116\n",
      "Epoch 6912 / 10000 loss: 12.985576152801514\n",
      "MSE train 5.219016523094445 MSE test 11.673601272480878\n",
      "MAE train 1.5720509053311682 MAE test 2.390427955237348\n",
      "Epoch 6913 / 10000 loss: 12.9852454662323\n",
      "MSE train 5.218901638415829 MSE test 11.673400962456403\n",
      "MAE train 1.5720335407675323 MAE test 2.3904025050368864\n",
      "Epoch 6914 / 10000 loss: 12.984679222106934\n",
      "MSE train 5.2187818581912175 MSE test 11.673326391487048\n",
      "MAE train 1.5720114999435586 MAE test 2.3903982183016077\n",
      "Epoch 6915 / 10000 loss: 12.984268188476562\n",
      "MSE train 5.21866647912256 MSE test 11.673122149691185\n",
      "MAE train 1.5719941456255446 MAE test 2.390372282225974\n",
      "Epoch 6916 / 10000 loss: 12.983817338943481\n",
      "MSE train 5.218550445238737 MSE test 11.67306757919102\n",
      "MAE train 1.5719727563651922 MAE test 2.390370654872806\n",
      "Epoch 6917 / 10000 loss: 12.983408212661743\n",
      "MSE train 5.218433553495246 MSE test 11.672831118199227\n",
      "MAE train 1.5719555973956607 MAE test 2.3903404482366515\n",
      "Epoch 6918 / 10000 loss: 12.982961654663086\n",
      "MSE train 5.218326609619802 MSE test 11.672821112294839\n",
      "MAE train 1.571935671158236 MAE test 2.390344735446036\n",
      "Epoch 6919 / 10000 loss: 12.982569217681885\n",
      "MSE train 5.2182110502536965 MSE test 11.672510840669046\n",
      "MAE train 1.5719202955302596 MAE test 2.3903047840604956\n",
      "Epoch 6920 / 10000 loss: 12.982129096984863\n",
      "MSE train 5.21808056794557 MSE test 11.67253893788083\n",
      "MAE train 1.5718935676397834 MAE test 2.390314182037771\n",
      "Epoch 6921 / 10000 loss: 12.981796741485596\n",
      "MSE train 5.217964153666869 MSE test 11.67232760581917\n",
      "MAE train 1.5718760286205649 MAE test 2.3902872776305424\n",
      "Epoch 6922 / 10000 loss: 12.981235980987549\n",
      "MSE train 5.217848597135272 MSE test 11.672272052819812\n",
      "MAE train 1.5718547563968537 MAE test 2.390285522645011\n",
      "Epoch 6923 / 10000 loss: 12.980827331542969\n",
      "MSE train 5.217731397344825 MSE test 11.67203191808082\n",
      "MAE train 1.5718375649707392 MAE test 2.3902548195713145\n",
      "Epoch 6924 / 10000 loss: 12.98038101196289\n",
      "MSE train 5.217624698529716 MSE test 11.672023507657148\n",
      "MAE train 1.571817653509515 MAE test 2.3902593157612246\n",
      "Epoch 6925 / 10000 loss: 12.979989290237427\n",
      "MSE train 5.217508962536021 MSE test 11.671711395928488\n",
      "MAE train 1.5718022633093682 MAE test 2.3902191036562157\n",
      "Epoch 6926 / 10000 loss: 12.979549407958984\n",
      "MSE train 5.2173780166166495 MSE test 11.671739195328081\n",
      "MAE train 1.571775406308656 MAE test 2.3902284580454527\n",
      "Epoch 6927 / 10000 loss: 12.979217052459717\n",
      "MSE train 5.217262068109723 MSE test 11.671531407957081\n",
      "MAE train 1.571757924374676 MAE test 2.390202024385956\n",
      "Epoch 6928 / 10000 loss: 12.978654861450195\n",
      "MSE train 5.21714518759581 MSE test 11.671469992343328\n",
      "MAE train 1.5717363853318602 MAE test 2.3901994890162617\n",
      "Epoch 6929 / 10000 loss: 12.978245258331299\n",
      "MSE train 5.217028250522236 MSE test 11.671240799087064\n",
      "MAE train 1.5717190635680554 MAE test 2.3901702391496373\n",
      "Epoch 6930 / 10000 loss: 12.977797746658325\n",
      "MSE train 5.216920193687015 MSE test 11.671220592451913\n",
      "MAE train 1.5716990228884329 MAE test 2.3901731689389867\n",
      "Epoch 6931 / 10000 loss: 12.977399826049805\n",
      "MSE train 5.2168045060233545 MSE test 11.670921958175917\n",
      "MAE train 1.5716833744827785 MAE test 2.390134738962578\n",
      "Epoch 6932 / 10000 loss: 12.976962089538574\n",
      "MSE train 5.216679002421969 MSE test 11.670947916932123\n",
      "MAE train 1.5716580162772125 MAE test 2.3901438427782997\n",
      "Epoch 6933 / 10000 loss: 12.976619005203247\n",
      "MSE train 5.216560718503931 MSE test 11.670707926072174\n",
      "MAE train 1.5716405134829696 MAE test 2.3901131380926866\n",
      "Epoch 6934 / 10000 loss: 12.976080894470215\n",
      "MSE train 5.21645379003824 MSE test 11.670692220066714\n",
      "MAE train 1.5716206474187726 MAE test 2.390116657324502\n",
      "Epoch 6935 / 10000 loss: 12.975684881210327\n",
      "MSE train 5.216337670069337 MSE test 11.670385712589145\n",
      "MAE train 1.5716050396942447 MAE test 2.390077181144047\n",
      "Epoch 6936 / 10000 loss: 12.97524619102478\n",
      "MSE train 5.216209473676666 MSE test 11.670412162756985\n",
      "MAE train 1.5715789207548594 MAE test 2.3900863616283496\n",
      "Epoch 6937 / 10000 loss: 12.974908590316772\n",
      "MSE train 5.216091849226951 MSE test 11.67018862911746\n",
      "MAE train 1.571561279635139 MAE test 2.3900578313119993\n",
      "Epoch 6938 / 10000 loss: 12.974358320236206\n",
      "MSE train 5.215980916398315 MSE test 11.67015144669209\n",
      "MAE train 1.5715408186752151 MAE test 2.3900584937129854\n",
      "Epoch 6939 / 10000 loss: 12.973953247070312\n",
      "MSE train 5.215864190603749 MSE test 11.669876626678814\n",
      "MAE train 1.5715244176640066 MAE test 2.390023211083551\n",
      "Epoch 6940 / 10000 loss: 12.973514080047607\n",
      "MSE train 5.2157502920235315 MSE test 11.669893246185158\n",
      "MAE train 1.5715021692667988 MAE test 2.390031036840732\n",
      "Epoch 6941 / 10000 loss: 12.973148107528687\n",
      "MSE train 5.215633113235508 MSE test 11.669599770473557\n",
      "MAE train 1.5714860208190755 MAE test 2.3899932731612545\n",
      "Epoch 6942 / 10000 loss: 12.972661018371582\n",
      "MSE train 5.215511862196353 MSE test 11.669621998711328\n",
      "MAE train 1.5714617893235099 MAE test 2.3900018597140282\n",
      "Epoch 6943 / 10000 loss: 12.972310066223145\n",
      "MSE train 5.21539330112022 MSE test 11.66936237738818\n",
      "MAE train 1.571444587123654 MAE test 2.3899685681183422\n",
      "Epoch 6944 / 10000 loss: 12.97178864479065\n",
      "MSE train 5.215285819278215 MSE test 11.669364674472464\n",
      "MAE train 1.5714242457006258 MAE test 2.3899744712376108\n",
      "Epoch 6945 / 10000 loss: 12.97140645980835\n",
      "MSE train 5.2151692122712126 MSE test 11.669050808291553\n",
      "MAE train 1.5714086435971775 MAE test 2.389934008622165\n",
      "Epoch 6946 / 10000 loss: 12.970953226089478\n",
      "MSE train 5.2150387139573615 MSE test 11.669077725416265\n",
      "MAE train 1.571381885159665 MAE test 2.3899432490113153\n",
      "Epoch 6947 / 10000 loss: 12.970620155334473\n",
      "MSE train 5.2149227639599784 MSE test 11.668869225419673\n",
      "MAE train 1.5713643942463322 MAE test 2.3899167065315106\n",
      "Epoch 6948 / 10000 loss: 12.970060110092163\n",
      "MSE train 5.214806044781789 MSE test 11.668807717623947\n",
      "MAE train 1.5713428845886077 MAE test 2.3899141509328925\n",
      "Epoch 6949 / 10000 loss: 12.969650745391846\n",
      "MSE train 5.214689108631424 MSE test 11.668578324548136\n",
      "MAE train 1.57132555675271 MAE test 2.389884864202044\n",
      "Epoch 6950 / 10000 loss: 12.969204187393188\n",
      "MSE train 5.214581239930641 MSE test 11.668558182460458\n",
      "MAE train 1.571305541952489 MAE test 2.3898878003230952\n",
      "Epoch 6951 / 10000 loss: 12.968806743621826\n",
      "MSE train 5.2144656074310225 MSE test 11.668259329049347\n",
      "MAE train 1.571289897685073 MAE test 2.389849317546633\n",
      "Epoch 6952 / 10000 loss: 12.968369245529175\n",
      "MSE train 5.214340099753365 MSE test 11.668285245515486\n",
      "MAE train 1.5712645199250643 MAE test 2.38985842911551\n",
      "Epoch 6953 / 10000 loss: 12.968027353286743\n",
      "MSE train 5.214221918494127 MSE test 11.668046176719619\n",
      "MAE train 1.5712470120984028 MAE test 2.38982782799731\n",
      "Epoch 6954 / 10000 loss: 12.967489004135132\n",
      "MSE train 5.214115011530494 MSE test 11.668029443871061\n",
      "MAE train 1.5712271522608237 MAE test 2.3898312245522364\n",
      "Epoch 6955 / 10000 loss: 12.967092752456665\n",
      "MSE train 5.213998960906921 MSE test 11.667724134798306\n",
      "MAE train 1.5712115219947642 MAE test 2.3897918885510174\n",
      "Epoch 6956 / 10000 loss: 12.966655254364014\n",
      "MSE train 5.2138713283185645 MSE test 11.667750466362087\n",
      "MAE train 1.5711855442963159 MAE test 2.3898010653278186\n",
      "Epoch 6957 / 10000 loss: 12.96631669998169\n",
      "MSE train 5.213753641069484 MSE test 11.667524421163819\n",
      "MAE train 1.5711679185292142 MAE test 2.389772186882984\n",
      "Epoch 6958 / 10000 loss: 12.965769529342651\n",
      "MSE train 5.213643561313287 MSE test 11.667490726495725\n",
      "MAE train 1.571147596448341 MAE test 2.389773320997873\n",
      "Epoch 6959 / 10000 loss: 12.965365886688232\n",
      "MSE train 5.213527117536198 MSE test 11.667210088781324\n",
      "MAE train 1.571131368167432 MAE test 2.3897372397303265\n",
      "Epoch 6960 / 10000 loss: 12.964927673339844\n",
      "MSE train 5.213410667087961 MSE test 11.667229357925823\n",
      "MAE train 1.5711084069550643 MAE test 2.389745438396133\n",
      "Epoch 6961 / 10000 loss: 12.964567422866821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.213293099404898 MSE test 11.666947200246106\n",
      "MAE train 1.5710919182887293 MAE test 2.3897091498285667\n",
      "Epoch 6962 / 10000 loss: 12.964069366455078\n",
      "MSE train 5.213177451986423 MSE test 11.666964730221872\n",
      "MAE train 1.5710691681876985 MAE test 2.389717107110185\n",
      "Epoch 6963 / 10000 loss: 12.963707447052002\n",
      "MSE train 5.2130596774716915 MSE test 11.666680512460145\n",
      "MAE train 1.5710526693022318 MAE test 2.389680556662904\n",
      "Epoch 6964 / 10000 loss: 12.96321177482605\n",
      "MSE train 5.2129434305782 MSE test 11.66669834986235\n",
      "MAE train 1.5710297615211117 MAE test 2.3896885474914953\n",
      "Epoch 6965 / 10000 loss: 12.962851524353027\n",
      "MSE train 5.212825516415565 MSE test 11.66641691837211\n",
      "MAE train 1.5710131676118961 MAE test 2.3896523515306085\n",
      "Epoch 6966 / 10000 loss: 12.962353229522705\n",
      "MSE train 5.212710636949972 MSE test 11.666433356412233\n",
      "MAE train 1.5709906273672707 MAE test 2.389660162297609\n",
      "Epoch 6967 / 10000 loss: 12.961989402770996\n",
      "MSE train 5.212592919699006 MSE test 11.666146263002434\n",
      "MAE train 1.5709742027987554 MAE test 2.3896232144411873\n",
      "Epoch 6968 / 10000 loss: 12.961497068405151\n",
      "MSE train 5.212475334093674 MSE test 11.666165200762764\n",
      "MAE train 1.5709509262730101 MAE test 2.3896313597441536\n",
      "Epoch 6969 / 10000 loss: 12.96113920211792\n",
      "MSE train 5.212357204619305 MSE test 11.665889743292082\n",
      "MAE train 1.5709341539867674 MAE test 2.389595951460195\n",
      "Epoch 6970 / 10000 loss: 12.960635423660278\n",
      "MSE train 5.212244981635855 MSE test 11.66590286938837\n",
      "MAE train 1.5709123511760892 MAE test 2.3896033200873905\n",
      "Epoch 6971 / 10000 loss: 12.96026611328125\n",
      "MSE train 5.212127705188973 MSE test 11.665605435414609\n",
      "MAE train 1.5708962413474366 MAE test 2.389564991789571\n",
      "Epoch 6972 / 10000 loss: 12.959786891937256\n",
      "MSE train 5.212004944908154 MSE test 11.665628164756624\n",
      "MAE train 1.5708715962951543 MAE test 2.3895736745195673\n",
      "Epoch 6973 / 10000 loss: 12.959438562393188\n",
      "MSE train 5.211886421987394 MSE test 11.665377172248046\n",
      "MAE train 1.5708542093276823 MAE test 2.3895414897992318\n",
      "Epoch 6974 / 10000 loss: 12.958910703659058\n",
      "MSE train 5.211780164185649 MSE test 11.665371711597711\n",
      "MAE train 1.5708342989388493 MAE test 2.389546366599434\n",
      "Epoch 6975 / 10000 loss: 12.958522319793701\n",
      "MSE train 5.211663926485055 MSE test 11.66505779034916\n",
      "MAE train 1.5708187643547569 MAE test 2.3895058608363606\n",
      "Epoch 6976 / 10000 loss: 12.95807957649231\n",
      "MSE train 5.211533253514119 MSE test 11.665084737486044\n",
      "MAE train 1.5707919470019014 MAE test 2.3895151384908164\n",
      "Epoch 6977 / 10000 loss: 12.957747459411621\n",
      "MSE train 5.211417711938354 MSE test 11.664878422026183\n",
      "MAE train 1.5707744989351136 MAE test 2.3894888612243674\n",
      "Epoch 6978 / 10000 loss: 12.957187175750732\n",
      "MSE train 5.211300457505287 MSE test 11.66481403901453\n",
      "MAE train 1.5707528807605047 MAE test 2.3894859379361044\n",
      "Epoch 6979 / 10000 loss: 12.956778526306152\n",
      "MSE train 5.211184008811028 MSE test 11.664590482936918\n",
      "MAE train 1.5707355252014337 MAE test 2.389457391827035\n",
      "Epoch 6980 / 10000 loss: 12.956332206726074\n",
      "MSE train 5.2110748571584775 MSE test 11.664563241906123\n",
      "MAE train 1.5707153104118867 MAE test 2.389459402341483\n",
      "Epoch 6981 / 10000 loss: 12.955932378768921\n",
      "MSE train 5.210959133273041 MSE test 11.664275730113367\n",
      "MAE train 1.5706993947397034 MAE test 2.3894223826217993\n",
      "Epoch 6982 / 10000 loss: 12.955495595932007\n",
      "MSE train 5.210838910623012 MSE test 11.664298520967018\n",
      "MAE train 1.5706753968352551 MAE test 2.3894310760247333\n",
      "Epoch 6983 / 10000 loss: 12.95514464378357\n",
      "MSE train 5.210720896742815 MSE test 11.664034091554155\n",
      "MAE train 1.5706584093815432 MAE test 2.3893971176194224\n",
      "Epoch 6984 / 10000 loss: 12.954628467559814\n",
      "MSE train 5.210612113504129 MSE test 11.664041296622141\n",
      "MAE train 1.5706376227690237 MAE test 2.3894036984341165\n",
      "Epoch 6985 / 10000 loss: 12.954251766204834\n",
      "MSE train 5.2104955392349765 MSE test 11.663731561040052\n",
      "MAE train 1.5706219129556127 MAE test 2.3893637345335352\n",
      "Epoch 6986 / 10000 loss: 12.95379090309143\n",
      "MSE train 5.210366916018011 MSE test 11.663757672354798\n",
      "MAE train 1.570595640796356 MAE test 2.389372890256057\n",
      "Epoch 6987 / 10000 loss: 12.953455448150635\n",
      "MSE train 5.210249961520936 MSE test 11.663539489202774\n",
      "MAE train 1.5705780270566285 MAE test 2.389345045770169\n",
      "Epoch 6988 / 10000 loss: 12.952903270721436\n",
      "MSE train 5.210137323029808 MSE test 11.663493872760892\n",
      "MAE train 1.570557273045117 MAE test 2.3893445997225484\n",
      "Epoch 6989 / 10000 loss: 12.952497243881226\n",
      "MSE train 5.210020492548787 MSE test 11.663234358556991\n",
      "MAE train 1.5705404797741862 MAE test 2.3893112907056913\n",
      "Epoch 6990 / 10000 loss: 12.95205569267273\n",
      "MSE train 5.209911928769652 MSE test 11.663241986318631\n",
      "MAE train 1.5705197577677195 MAE test 2.389317933757661\n",
      "Epoch 6991 / 10000 loss: 12.951680183410645\n",
      "MSE train 5.209795805491429 MSE test 11.66293077328669\n",
      "MAE train 1.5705041926043424 MAE test 2.389277772004821\n",
      "Epoch 6992 / 10000 loss: 12.951221466064453\n",
      "MSE train 5.209666087755755 MSE test 11.662957497468735\n",
      "MAE train 1.5704776226258443 MAE test 2.3892870143027216\n",
      "Epoch 6993 / 10000 loss: 12.950888395309448\n",
      "MSE train 5.209549880982375 MSE test 11.662745738479218\n",
      "MAE train 1.570460090170221 MAE test 2.3892600145241887\n",
      "Epoch 6994 / 10000 loss: 12.950331926345825\n",
      "MSE train 5.209434909653978 MSE test 11.662690680735821\n",
      "MAE train 1.5704389052249785 MAE test 2.389258323043031\n",
      "Epoch 6995 / 10000 loss: 12.949924230575562\n",
      "MSE train 5.209318068326934 MSE test 11.662449334627157\n",
      "MAE train 1.570421755004418 MAE test 2.3892274133487783\n",
      "Epoch 6996 / 10000 loss: 12.949480295181274\n",
      "MSE train 5.209211748487176 MSE test 11.662442185086162\n",
      "MAE train 1.5704018784361273 MAE test 2.389232088517496\n",
      "Epoch 6997 / 10000 loss: 12.949090957641602\n",
      "MSE train 5.209096283874363 MSE test 11.662129762656493\n",
      "MAE train 1.5703864920044643 MAE test 2.389191763099371\n",
      "Epoch 6998 / 10000 loss: 12.948652029037476\n",
      "MSE train 5.208965589157244 MSE test 11.662157436989055\n",
      "MAE train 1.570359647312111 MAE test 2.3892011421396373\n",
      "Epoch 6999 / 10000 loss: 12.948322296142578\n",
      "MSE train 5.20885023316397 MSE test 11.661951756161834\n",
      "MAE train 1.5703422213027347 MAE test 2.3891749379534186\n",
      "Epoch 7000 / 10000 loss: 12.94776177406311\n",
      "MSE train 5.208733068143163 MSE test 11.661887351419347\n",
      "MAE train 1.570320605233097 MAE test 2.389172019195858\n",
      "Epoch 7001 / 10000 loss: 12.947354078292847\n",
      "MSE train 5.208616670160923 MSE test 11.661664221974341\n",
      "MAE train 1.5703032558827736 MAE test 2.389143517648342\n",
      "Epoch 7002 / 10000 loss: 12.946907043457031\n",
      "MSE train 5.208507630366121 MSE test 11.66163682321977\n",
      "MAE train 1.5702830500292018 MAE test 2.389145506079138\n",
      "Epoch 7003 / 10000 loss: 12.946507692337036\n",
      "MSE train 5.208392054425725 MSE test 11.66134995979271\n",
      "MAE train 1.570267136965574 MAE test 2.389108564326821\n",
      "Epoch 7004 / 10000 loss: 12.946071863174438\n",
      "MSE train 5.208272152023157 MSE test 11.661372633461932\n",
      "MAE train 1.5702432076952013 MAE test 2.3891172575303465\n",
      "Epoch 7005 / 10000 loss: 12.94572114944458\n",
      "MSE train 5.208154283520769 MSE test 11.66110750681029\n",
      "MAE train 1.5702262529867579 MAE test 2.389083173758031\n",
      "Epoch 7006 / 10000 loss: 12.94520616531372\n",
      "MSE train 5.208045374219401 MSE test 11.66111525681639\n",
      "MAE train 1.5702054096386444 MAE test 2.3890898410533805\n",
      "Epoch 7007 / 10000 loss: 12.944831371307373\n",
      "MSE train 5.207928818673176 MSE test 11.660806615743342\n",
      "MAE train 1.5701896682207945 MAE test 2.3890499918133266\n",
      "Epoch 7008 / 10000 loss: 12.944368839263916\n",
      "MSE train 5.207800745068598 MSE test 11.660832411299838\n",
      "MAE train 1.5701635379976706 MAE test 2.3890591235930843\n",
      "Epoch 7009 / 10000 loss: 12.944032669067383\n",
      "MSE train 5.207683672717514 MSE test 11.66061190428949\n",
      "MAE train 1.5701459103428874 MAE test 2.3890309527855083\n",
      "Epoch 7010 / 10000 loss: 12.943482875823975\n",
      "MSE train 5.207572051949346 MSE test 11.660570142982804\n",
      "MAE train 1.5701253305865213 MAE test 2.3890310189641517\n",
      "Epoch 7011 / 10000 loss: 12.943078517913818\n",
      "MSE train 5.207455433483658 MSE test 11.660303887471235\n",
      "MAE train 1.5701087131604747 MAE test 2.3889968064917144\n",
      "Epoch 7012 / 10000 loss: 12.942639589309692\n",
      "MSE train 5.207344987177146 MSE test 11.660315894586711\n",
      "MAE train 1.5700874019630546 MAE test 2.3890040394430088\n",
      "Epoch 7013 / 10000 loss: 12.94226884841919\n",
      "MSE train 5.207228641425437 MSE test 11.660011497827227\n",
      "MAE train 1.5700716237005374 MAE test 2.388964752367505\n",
      "Epoch 7014 / 10000 loss: 12.941799640655518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.207102173077661 MSE test 11.660036788307318\n",
      "MAE train 1.5700459334414902 MAE test 2.3889738014811095\n",
      "Epoch 7015 / 10000 loss: 12.941460371017456\n",
      "MSE train 5.20698443328765 MSE test 11.659807138964762\n",
      "MAE train 1.5700283263755153 MAE test 2.3889444128520783\n",
      "Epoch 7016 / 10000 loss: 12.940917253494263\n",
      "MSE train 5.206875847570209 MSE test 11.659778307382714\n",
      "MAE train 1.5700082325542455 MAE test 2.388946210123921\n",
      "Epoch 7017 / 10000 loss: 12.940517902374268\n",
      "MSE train 5.206759831477746 MSE test 11.659489782504382\n",
      "MAE train 1.56999221738464 MAE test 2.3889090189473423\n",
      "Epoch 7018 / 10000 loss: 12.94008183479309\n",
      "MSE train 5.206639966201814 MSE test 11.65951183122008\n",
      "MAE train 1.5699682978365006 MAE test 2.3889176318088436\n",
      "Epoch 7019 / 10000 loss: 12.939729690551758\n",
      "MSE train 5.206522047582487 MSE test 11.659247347042875\n",
      "MAE train 1.569951302100688 MAE test 2.3888836240682085\n",
      "Epoch 7020 / 10000 loss: 12.939215898513794\n",
      "MSE train 5.206413469051592 MSE test 11.659254228789832\n",
      "MAE train 1.5699305573465243 MAE test 2.388890171283391\n",
      "Epoch 7021 / 10000 loss: 12.93883991241455\n",
      "MSE train 5.20629698263458 MSE test 11.65894505213237\n",
      "MAE train 1.5699148235104798 MAE test 2.3888502434306975\n",
      "Epoch 7022 / 10000 loss: 12.938380002975464\n",
      "MSE train 5.20616872087988 MSE test 11.658971002390578\n",
      "MAE train 1.5698886284808766 MAE test 2.3888593913168914\n",
      "Epoch 7023 / 10000 loss: 12.938045024871826\n",
      "MSE train 5.206051853367693 MSE test 11.658752198040794\n",
      "MAE train 1.5698710191132046 MAE test 2.3888314485857927\n",
      "Epoch 7024 / 10000 loss: 12.937494039535522\n",
      "MSE train 5.205939646295203 MSE test 11.658707699749609\n",
      "MAE train 1.5698503332119003 MAE test 2.3888311478477475\n",
      "Epoch 7025 / 10000 loss: 12.937089681625366\n",
      "MSE train 5.205823043680681 MSE test 11.65844637816739\n",
      "MAE train 1.5698336043052534 MAE test 2.3887975758789817\n",
      "Epoch 7026 / 10000 loss: 12.936649799346924\n",
      "MSE train 5.205714137312428 MSE test 11.65845529941801\n",
      "MAE train 1.5698127425153803 MAE test 2.3888044084549658\n",
      "Epoch 7027 / 10000 loss: 12.936275482177734\n",
      "MSE train 5.205598074606027 MSE test 11.658146179152299\n",
      "MAE train 1.56979711549046 MAE test 2.388764479481603\n",
      "Epoch 7028 / 10000 loss: 12.93581485748291\n",
      "MSE train 5.205469369349255 MSE test 11.658172520200239\n",
      "MAE train 1.5697708021322512 MAE test 2.388773683321056\n",
      "Epoch 7029 / 10000 loss: 12.93548035621643\n",
      "MSE train 5.205352805398133 MSE test 11.657955881271745\n",
      "MAE train 1.5697532243413397 MAE test 2.3887460132666387\n",
      "Epoch 7030 / 10000 loss: 12.93492865562439\n",
      "MSE train 5.205239912332088 MSE test 11.657908356174438\n",
      "MAE train 1.5697324167548974 MAE test 2.3887453294534278\n",
      "Epoch 7031 / 10000 loss: 12.934523105621338\n",
      "MSE train 5.205123202942396 MSE test 11.657652926295794\n",
      "MAE train 1.5697155416503756 MAE test 2.388712525576917\n",
      "Epoch 7032 / 10000 loss: 12.934083938598633\n",
      "MSE train 5.205015760979737 MSE test 11.657657785432221\n",
      "MAE train 1.5696951305473554 MAE test 2.3887188111924993\n",
      "Epoch 7033 / 10000 loss: 12.933704614639282\n",
      "MSE train 5.204899972318971 MSE test 11.657344671820104\n",
      "MAE train 1.5696796484343898 MAE test 2.3886783518667443\n",
      "Epoch 7034 / 10000 loss: 12.933253049850464\n",
      "MSE train 5.204769598566021 MSE test 11.657371774304934\n",
      "MAE train 1.5696528616340015 MAE test 2.3886876656121134\n",
      "Epoch 7035 / 10000 loss: 12.932922124862671\n",
      "MSE train 5.204654350081081 MSE test 11.657166207764279\n",
      "MAE train 1.5696354368214973 MAE test 2.3886614723978754\n",
      "Epoch 7036 / 10000 loss: 12.932362794876099\n",
      "MSE train 5.204537314030778 MSE test 11.657101145280038\n",
      "MAE train 1.5696138449589825 MAE test 2.388658449136278\n",
      "Epoch 7037 / 10000 loss: 12.931956052780151\n",
      "MSE train 5.2044210745859045 MSE test 11.656879149047315\n",
      "MAE train 1.569596489637969 MAE test 2.3886300972240964\n",
      "Epoch 7038 / 10000 loss: 12.93151068687439\n",
      "MSE train 5.204311982231478 MSE test 11.656850607451913\n",
      "MAE train 1.5695762767255657 MAE test 2.388631938657889\n",
      "Epoch 7039 / 10000 loss: 12.931110858917236\n",
      "MSE train 5.204196456797508 MSE test 11.656565756383806\n",
      "MAE train 1.5695603026416225 MAE test 2.388595225694763\n",
      "Epoch 7040 / 10000 loss: 12.930675745010376\n",
      "MSE train 5.204077671783317 MSE test 11.65658764208398\n",
      "MAE train 1.5695366492118799 MAE test 2.3886038145942265\n",
      "Epoch 7041 / 10000 loss: 12.930323600769043\n",
      "MSE train 5.203960040604488 MSE test 11.656318472789264\n",
      "MAE train 1.5695198240581731 MAE test 2.388569188781311\n",
      "Epoch 7042 / 10000 loss: 12.929814100265503\n",
      "MSE train 5.203849927300624 MSE test 11.656329049884489\n",
      "MAE train 1.569498583883974 MAE test 2.3885762370206787\n",
      "Epoch 7043 / 10000 loss: 12.929444074630737\n",
      "MSE train 5.203733368813955 MSE test 11.656025454826345\n",
      "MAE train 1.5694827092988257 MAE test 2.388537029011416\n",
      "Epoch 7044 / 10000 loss: 12.928975105285645\n",
      "MSE train 5.203607744070457 MSE test 11.656050015659607\n",
      "MAE train 1.5694572330256389 MAE test 2.388545994105331\n",
      "Epoch 7045 / 10000 loss: 12.928634405136108\n",
      "MSE train 5.203489926960039 MSE test 11.655817111163522\n",
      "MAE train 1.5694396476204544 MAE test 2.3885161629067175\n",
      "Epoch 7046 / 10000 loss: 12.928095579147339\n",
      "MSE train 5.20338234948693 MSE test 11.655792220391465\n",
      "MAE train 1.5694197047666407 MAE test 2.3885184767176293\n",
      "Epoch 7047 / 10000 loss: 12.92769742012024\n",
      "MSE train 5.203266545999339 MSE test 11.655497842282296\n",
      "MAE train 1.5694038440621618 MAE test 2.3884805080168006\n",
      "Epoch 7048 / 10000 loss: 12.927263021469116\n",
      "MSE train 5.2031440037754875 MSE test 11.655521392151014\n",
      "MAE train 1.5693791998237827 MAE test 2.388489321431604\n",
      "Epoch 7049 / 10000 loss: 12.926917552947998\n",
      "MSE train 5.2030259900288485 MSE test 11.65527107155052\n",
      "MAE train 1.5693618872566693 MAE test 2.388457171362538\n",
      "Epoch 7050 / 10000 loss: 12.926392078399658\n",
      "MSE train 5.202920100232001 MSE test 11.655266071570122\n",
      "MAE train 1.5693420080399243 MAE test 2.3884621416707645\n",
      "Epoch 7051 / 10000 loss: 12.926005363464355\n",
      "MSE train 5.202804208035164 MSE test 11.654952808085937\n",
      "MAE train 1.5693264904164248 MAE test 2.388421644748353\n",
      "Epoch 7052 / 10000 loss: 12.92556357383728\n",
      "MSE train 5.202673955611387 MSE test 11.654979568330322\n",
      "MAE train 1.569299728384475 MAE test 2.3884309177729364\n",
      "Epoch 7053 / 10000 loss: 12.925233602523804\n",
      "MSE train 5.202558756640547 MSE test 11.65477379377896\n",
      "MAE train 1.569282306018215 MAE test 2.3884046811263633\n",
      "Epoch 7054 / 10000 loss: 12.924675703048706\n",
      "MSE train 5.202441855109412 MSE test 11.65470902238287\n",
      "MAE train 1.5692607365647686 MAE test 2.3884016973092326\n",
      "Epoch 7055 / 10000 loss: 12.9242684841156\n",
      "MSE train 5.202325707701389 MSE test 11.654486424095971\n",
      "MAE train 1.5692434025652475 MAE test 2.388373242227931\n",
      "Epoch 7056 / 10000 loss: 12.923824071884155\n",
      "MSE train 5.202216877003043 MSE test 11.654458392914245\n",
      "MAE train 1.5692232199716631 MAE test 2.3883751574579546\n",
      "Epoch 7057 / 10000 loss: 12.923425912857056\n",
      "MSE train 5.202101493171361 MSE test 11.654172631377651\n",
      "MAE train 1.5692072915661919 MAE test 2.388338324509277\n",
      "Epoch 7058 / 10000 loss: 12.922990560531616\n",
      "MSE train 5.201982224949192 MSE test 11.654194733860924\n",
      "MAE train 1.569183498882608 MAE test 2.3883469569336166\n",
      "Epoch 7059 / 10000 loss: 12.922639608383179\n",
      "MSE train 5.201864610550265 MSE test 11.653928251722283\n",
      "MAE train 1.5691666136888116 MAE test 2.3883126568583104\n",
      "Epoch 7060 / 10000 loss: 12.922127962112427\n",
      "MSE train 5.201755429661819 MSE test 11.653936897354823\n",
      "MAE train 1.5691456340498202 MAE test 2.3883194651033515\n",
      "Epoch 7061 / 10000 loss: 12.921756029129028\n",
      "MSE train 5.201639048790131 MSE test 11.653630477959341\n",
      "MAE train 1.5691298554457433 MAE test 2.3882798643419725\n",
      "Epoch 7062 / 10000 loss: 12.921292066574097\n",
      "MSE train 5.201512136287003 MSE test 11.653655701241096\n",
      "MAE train 1.5691040015560163 MAE test 2.388288937900075\n",
      "Epoch 7063 / 10000 loss: 12.920955419540405\n",
      "MSE train 5.201394895116702 MSE test 11.65343058522378\n",
      "MAE train 1.5690863962159958 MAE test 2.388260129279593\n",
      "Epoch 7064 / 10000 loss: 12.920410871505737\n",
      "MSE train 5.201285240592115 MSE test 11.653395407785828\n",
      "MAE train 1.5690661235556127 MAE test 2.388261085726318\n",
      "Epoch 7065 / 10000 loss: 12.92000937461853\n",
      "MSE train 5.201169123205382 MSE test 11.653117267822743\n",
      "MAE train 1.5690498573663596 MAE test 2.3882252397834187\n",
      "Epoch 7066 / 10000 loss: 12.919573545455933\n",
      "MSE train 5.201054149940356 MSE test 11.653135323002502\n",
      "MAE train 1.5690272105869523 MAE test 2.3882333228472796\n",
      "Epoch 7067 / 10000 loss: 12.919214487075806\n",
      "MSE train 5.200937123458444 MSE test 11.652850408294151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5690108506365086 MAE test 2.388196573569119\n",
      "Epoch 7068 / 10000 loss: 12.91872239112854\n",
      "MSE train 5.200820479322353 MSE test 11.652868973152424\n",
      "MAE train 1.5689877541346116 MAE test 2.3882047286411328\n",
      "Epoch 7069 / 10000 loss: 12.918365716934204\n",
      "MSE train 5.2007029242836165 MSE test 11.65259258626037\n",
      "MAE train 1.5689710831920185 MAE test 2.3881691147421287\n",
      "Epoch 7070 / 10000 loss: 12.917865991592407\n",
      "MSE train 5.200590411853829 MSE test 11.65260645130202\n",
      "MAE train 1.568949119446771 MAE test 2.38817662981872\n",
      "Epoch 7071 / 10000 loss: 12.917500734329224\n",
      "MSE train 5.200473428126361 MSE test 11.652312893888132\n",
      "MAE train 1.5689329353278652 MAE test 2.3881387287005897\n",
      "Epoch 7072 / 10000 loss: 12.917020320892334\n",
      "MSE train 5.200352900049883 MSE test 11.652334169246233\n",
      "MAE train 1.568908804989394 MAE test 2.3881472590959967\n",
      "Epoch 7073 / 10000 loss: 12.916670083999634\n",
      "MSE train 5.200234811203997 MSE test 11.65207599645453\n",
      "MAE train 1.5688916180173895 MAE test 2.3881140479826835\n",
      "Epoch 7074 / 10000 loss: 12.916153192520142\n",
      "MSE train 5.200128175237712 MSE test 11.65207713199572\n",
      "MAE train 1.5688714111605913 MAE test 2.388119863684632\n",
      "Epoch 7075 / 10000 loss: 12.915773391723633\n",
      "MSE train 5.2000121019405245 MSE test 11.651764430141817\n",
      "MAE train 1.5688558206287315 MAE test 2.3880794012130164\n",
      "Epoch 7076 / 10000 loss: 12.915323495864868\n",
      "MSE train 5.199882480560485 MSE test 11.65179074052457\n",
      "MAE train 1.5688292052782595 MAE test 2.388088643937187\n",
      "Epoch 7077 / 10000 loss: 12.914992809295654\n",
      "MSE train 5.199766979736502 MSE test 11.651582413681748\n",
      "MAE train 1.5688117479890245 MAE test 2.3880620537070385\n",
      "Epoch 7078 / 10000 loss: 12.914437770843506\n",
      "MSE train 5.199651180709098 MSE test 11.6515215230669\n",
      "MAE train 1.5687903768005098 MAE test 2.3880595931291952\n",
      "Epoch 7079 / 10000 loss: 12.914031267166138\n",
      "MSE train 5.199534743369802 MSE test 11.651291297399759\n",
      "MAE train 1.5687731110017764 MAE test 2.388030113981335\n",
      "Epoch 7080 / 10000 loss: 12.913587808609009\n",
      "MSE train 5.199427814981124 MSE test 11.651272419895516\n",
      "MAE train 1.568753204291286 MAE test 2.3880332527959944\n",
      "Epoch 7081 / 10000 loss: 12.913193464279175\n",
      "MSE train 5.199312729860424 MSE test 11.650972583153106\n",
      "MAE train 1.568737618973575 MAE test 2.3879945185681293\n",
      "Epoch 7082 / 10000 loss: 12.91275954246521\n",
      "MSE train 5.199187273467446 MSE test 11.650998332098938\n",
      "MAE train 1.5687121515231142 MAE test 2.388003676271055\n",
      "Epoch 7083 / 10000 loss: 12.912421703338623\n",
      "MSE train 5.199069750311865 MSE test 11.650764239857354\n",
      "MAE train 1.5686946445633085 MAE test 2.38797367196096\n",
      "Epoch 7084 / 10000 loss: 12.911883354187012\n",
      "MSE train 5.19896272672675 MSE test 11.650741841949312\n",
      "MAE train 1.5686747651335675 MAE test 2.3879763414037973\n",
      "Epoch 7085 / 10000 loss: 12.911487340927124\n",
      "MSE train 5.19884715877274 MSE test 11.650444414346442\n",
      "MAE train 1.5686590048206281 MAE test 2.387937914200388\n",
      "Epoch 7086 / 10000 loss: 12.911053895950317\n",
      "MSE train 5.198723251512565 MSE test 11.65046887511877\n",
      "MAE train 1.568633970100802 MAE test 2.3879468980907603\n",
      "Epoch 7087 / 10000 loss: 12.910712718963623\n",
      "MSE train 5.198605485933743 MSE test 11.650226723095885\n",
      "MAE train 1.5686165515195842 MAE test 2.38791581617243\n",
      "Epoch 7088 / 10000 loss: 12.910181045532227\n",
      "MSE train 5.198499592396862 MSE test 11.650213319738002\n",
      "MAE train 1.56859679187176 MAE test 2.3879196844274593\n",
      "Epoch 7089 / 10000 loss: 12.909789562225342\n",
      "MSE train 5.198384031485012 MSE test 11.649905592867295\n",
      "MAE train 1.5685812279125708 MAE test 2.387879892467358\n",
      "Epoch 7090 / 10000 loss: 12.909354209899902\n",
      "MSE train 5.19825585832964 MSE test 11.649931649262358\n",
      "MAE train 1.5685550075080341 MAE test 2.387889096188769\n",
      "Epoch 7091 / 10000 loss: 12.90902066230774\n",
      "MSE train 5.198139400491267 MSE test 11.649714265587717\n",
      "MAE train 1.5685374443774973 MAE test 2.3878613051317656\n",
      "Epoch 7092 / 10000 loss: 12.908471822738647\n",
      "MSE train 5.198027361126311 MSE test 11.649668375886328\n",
      "MAE train 1.568516765748714 MAE test 2.387860847157315\n",
      "Epoch 7093 / 10000 loss: 12.908068180084229\n",
      "MSE train 5.197910892711779 MSE test 11.649409732867188\n",
      "MAE train 1.5684999982319665 MAE test 2.3878275847151267\n",
      "Epoch 7094 / 10000 loss: 12.90762996673584\n",
      "MSE train 5.197802928193156 MSE test 11.649416769429841\n",
      "MAE train 1.5684793600894054 MAE test 2.3878342109432396\n",
      "Epoch 7095 / 10000 loss: 12.907255411148071\n",
      "MSE train 5.197687262718111 MSE test 11.649106545851327\n",
      "MAE train 1.5684638094041812 MAE test 2.387794075656826\n",
      "Epoch 7096 / 10000 loss: 12.906799554824829\n",
      "MSE train 5.197558260287505 MSE test 11.649132726846206\n",
      "MAE train 1.568437352628724 MAE test 2.3878033083914563\n",
      "Epoch 7097 / 10000 loss: 12.906467914581299\n",
      "MSE train 5.197442376462816 MSE test 11.648920782501891\n",
      "MAE train 1.5684198490125039 MAE test 2.3877762348400293\n",
      "Epoch 7098 / 10000 loss: 12.905914783477783\n",
      "MSE train 5.197328222959383 MSE test 11.64886638219293\n",
      "MAE train 1.5683987855269437 MAE test 2.3877746399992525\n",
      "Epoch 7099 / 10000 loss: 12.905510187149048\n",
      "MSE train 5.197211700308827 MSE test 11.64862383168009\n",
      "MAE train 1.568381698619683 MAE test 2.3877435102825575\n",
      "Epoch 7100 / 10000 loss: 12.905068635940552\n",
      "MSE train 5.197105907257094 MSE test 11.648617734784418\n",
      "MAE train 1.5683618446295255 MAE test 2.387748384368454\n",
      "Epoch 7101 / 10000 loss: 12.904683113098145\n",
      "MSE train 5.196990801070637 MSE test 11.648305300293124\n",
      "MAE train 1.5683464769452329 MAE test 2.3877079512921604\n",
      "Epoch 7102 / 10000 loss: 12.904245376586914\n",
      "MSE train 5.196860519399315 MSE test 11.648332414841676\n",
      "MAE train 1.5683196731646871 MAE test 2.38771731927465\n",
      "Epoch 7103 / 10000 loss: 12.903917074203491\n",
      "MSE train 5.196745731666475 MSE test 11.648128258140375\n",
      "MAE train 1.5683023003889023 MAE test 2.387691287467221\n",
      "Epoch 7104 / 10000 loss: 12.903359413146973\n",
      "MSE train 5.196628721958426 MSE test 11.648061429865502\n",
      "MAE train 1.568280697926132 MAE test 2.3876880504016733\n",
      "Epoch 7105 / 10000 loss: 12.902952909469604\n",
      "MSE train 5.196512934543198 MSE test 11.647842599028765\n",
      "MAE train 1.5682633566466104 MAE test 2.387660074729007\n",
      "Epoch 7106 / 10000 loss: 12.902508735656738\n",
      "MSE train 5.196403263215638 MSE test 11.647809844034759\n",
      "MAE train 1.5682430338854392 MAE test 2.3876613945121554\n",
      "Epoch 7107 / 10000 loss: 12.90211009979248\n",
      "MSE train 5.1962878639213645 MSE test 11.647532186690151\n",
      "MAE train 1.5682269122509018 MAE test 2.3876255915313442\n",
      "Epoch 7108 / 10000 loss: 12.90167498588562\n",
      "MSE train 5.196172471149566 MSE test 11.647551072264823\n",
      "MAE train 1.5682041281072372 MAE test 2.3876338210312786\n",
      "Epoch 7109 / 10000 loss: 12.901318311691284\n",
      "MSE train 5.196055670264327 MSE test 11.64726837759075\n",
      "MAE train 1.5681877633705066 MAE test 2.387597339388587\n",
      "Epoch 7110 / 10000 loss: 12.900825023651123\n",
      "MSE train 5.195939985352569 MSE test 11.647286154033946\n",
      "MAE train 1.5681648948535905 MAE test 2.3876054246095686\n",
      "Epoch 7111 / 10000 loss: 12.900468826293945\n",
      "MSE train 5.1958226984279285 MSE test 11.647006607248684\n",
      "MAE train 1.5681483385242603 MAE test 2.387569346752418\n",
      "Epoch 7112 / 10000 loss: 12.899972438812256\n",
      "MSE train 5.195708910656058 MSE test 11.647021963296094\n",
      "MAE train 1.5681259871199509 MAE test 2.3875771021075907\n",
      "Epoch 7113 / 10000 loss: 12.899611234664917\n",
      "MSE train 5.195591810285748 MSE test 11.646734541613768\n",
      "MAE train 1.5681096342502754 MAE test 2.3875399915417\n",
      "Epoch 7114 / 10000 loss: 12.89912462234497\n",
      "MSE train 5.1954744630932845 MSE test 11.646753412749534\n",
      "MAE train 1.568086313581668 MAE test 2.3875482279185145\n",
      "Epoch 7115 / 10000 loss: 12.898770332336426\n",
      "MSE train 5.195356863815793 MSE test 11.646481556339458\n",
      "MAE train 1.5680695188891238 MAE test 2.38751317315634\n",
      "Epoch 7116 / 10000 loss: 12.898267030715942\n",
      "MSE train 5.195246416246493 MSE test 11.646492156326422\n",
      "MAE train 1.5680481104022717 MAE test 2.387520271144132\n",
      "Epoch 7117 / 10000 loss: 12.897899150848389\n",
      "MSE train 5.195129849782123 MSE test 11.64619207898155\n",
      "MAE train 1.5680321352200712 MAE test 2.387481476410458\n",
      "Epoch 7118 / 10000 loss: 12.897428035736084\n",
      "MSE train 5.195006162692934 MSE test 11.646215093465942\n",
      "MAE train 1.5680071319747586 MAE test 2.3874902819880135\n",
      "Epoch 7119 / 10000 loss: 12.897086143493652\n",
      "MSE train 5.194888342942017 MSE test 11.64597421419051\n",
      "MAE train 1.567989670572431 MAE test 2.3874593553664853\n",
      "Epoch 7120 / 10000 loss: 12.896555662155151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.194782437214231 MSE test 11.645958314751386\n",
      "MAE train 1.5679699181439837 MAE test 2.3874629047268514\n",
      "Epoch 7121 / 10000 loss: 12.89616346359253\n",
      "MSE train 5.194666878024942 MSE test 11.645652525598454\n",
      "MAE train 1.567954309451956 MAE test 2.387423340272428\n",
      "Epoch 7122 / 10000 loss: 12.895729064941406\n",
      "MSE train 5.194539706622732 MSE test 11.645678004318233\n",
      "MAE train 1.5679283418258665 MAE test 2.3874324980951327\n",
      "Epoch 7123 / 10000 loss: 12.895395278930664\n",
      "MSE train 5.1944229116247715 MSE test 11.645455631315393\n",
      "MAE train 1.5679107719939671 MAE test 2.387404028665233\n",
      "Epoch 7124 / 10000 loss: 12.89484977722168\n",
      "MSE train 5.194312743661323 MSE test 11.645416883996397\n",
      "MAE train 1.5678903987865858 MAE test 2.387404543092027\n",
      "Epoch 7125 / 10000 loss: 12.89444899559021\n",
      "MSE train 5.194196689747551 MSE test 11.64514478772338\n",
      "MAE train 1.5678740127377733 MAE test 2.387369461618165\n",
      "Epoch 7126 / 10000 loss: 12.894012928009033\n",
      "MSE train 5.1940843593838695 MSE test 11.645159624205423\n",
      "MAE train 1.5678520523259465 MAE test 2.387377158786951\n",
      "Epoch 7127 / 10000 loss: 12.893650770187378\n",
      "MSE train 5.193967941894128 MSE test 11.644865453144018\n",
      "MAE train 1.56783600234576 MAE test 2.3873391385442786\n",
      "Epoch 7128 / 10000 loss: 12.893170833587646\n",
      "MSE train 5.193846746724468 MSE test 11.64488717087112\n",
      "MAE train 1.5678116537353095 MAE test 2.3873477728923955\n",
      "Epoch 7129 / 10000 loss: 12.89282512664795\n",
      "MSE train 5.1937288613405865 MSE test 11.644633392820442\n",
      "MAE train 1.5677944208478662 MAE test 2.3873151135131696\n",
      "Epoch 7130 / 10000 loss: 12.892305374145508\n",
      "MSE train 5.1936229747084175 MSE test 11.64463051137257\n",
      "MAE train 1.5677744344025462 MAE test 2.387320423890788\n",
      "Epoch 7131 / 10000 loss: 12.89192247390747\n",
      "MSE train 5.193507219421761 MSE test 11.64431754379832\n",
      "MAE train 1.5677588985332183 MAE test 2.387279900337336\n",
      "Epoch 7132 / 10000 loss: 12.8914794921875\n",
      "MSE train 5.193377467606583 MSE test 11.644343618778942\n",
      "MAE train 1.5677322266064166 MAE test 2.3872891532183744\n",
      "Epoch 7133 / 10000 loss: 12.89115047454834\n",
      "MSE train 5.193262487570075 MSE test 11.644137424836018\n",
      "MAE train 1.5677148289279188 MAE test 2.3872628443933377\n",
      "Epoch 7134 / 10000 loss: 12.890594482421875\n",
      "MSE train 5.1931461320707495 MSE test 11.644072961056214\n",
      "MAE train 1.5676933455952822 MAE test 2.3872599140746416\n",
      "Epoch 7135 / 10000 loss: 12.890189170837402\n",
      "MSE train 5.193030137781152 MSE test 11.64384881738562\n",
      "MAE train 1.5676760457587118 MAE test 2.3872312413263543\n",
      "Epoch 7136 / 10000 loss: 12.88974642753601\n",
      "MSE train 5.192922039853775 MSE test 11.643822213062542\n",
      "MAE train 1.5676559587524843 MAE test 2.3872333803746297\n",
      "Epoch 7137 / 10000 loss: 12.889350414276123\n",
      "MSE train 5.192806921930728 MSE test 11.643533497836346\n",
      "MAE train 1.5676401220146159 MAE test 2.387196088688656\n",
      "Epoch 7138 / 10000 loss: 12.888916492462158\n",
      "MSE train 5.192686560898804 MSE test 11.643555955572857\n",
      "MAE train 1.567615994765592 MAE test 2.3872048377546067\n",
      "Epoch 7139 / 10000 loss: 12.888570070266724\n",
      "MSE train 5.192569046730159 MSE test 11.64329665466682\n",
      "MAE train 1.567598963072904 MAE test 2.3871714563258073\n",
      "Epoch 7140 / 10000 loss: 12.888054847717285\n",
      "MSE train 5.192462089308938 MSE test 11.643299418324135\n",
      "MAE train 1.5675786002596097 MAE test 2.387177522019385\n",
      "Epoch 7141 / 10000 loss: 12.887677431106567\n",
      "MSE train 5.192346248225677 MSE test 11.642988014558494\n",
      "MAE train 1.5675630092579493 MAE test 2.3871372109181785\n",
      "Epoch 7142 / 10000 loss: 12.887226581573486\n",
      "MSE train 5.192217241471732 MSE test 11.643013583952277\n",
      "MAE train 1.5675365341478644 MAE test 2.3871463903038506\n",
      "Epoch 7143 / 10000 loss: 12.88689661026001\n",
      "MSE train 5.192101573517791 MSE test 11.642802890503019\n",
      "MAE train 1.5675190560527044 MAE test 2.3871194871038273\n",
      "Epoch 7144 / 10000 loss: 12.886343955993652\n",
      "MSE train 5.191986935821029 MSE test 11.642745572958082\n",
      "MAE train 1.5674978947457379 MAE test 2.3871175230059265\n",
      "Epoch 7145 / 10000 loss: 12.885939359664917\n",
      "MSE train 5.191870556317413 MSE test 11.642507641319199\n",
      "MAE train 1.5674807453910027 MAE test 2.3870869938011756\n",
      "Epoch 7146 / 10000 loss: 12.885498523712158\n",
      "MSE train 5.191764804396945 MSE test 11.642496535945137\n",
      "MAE train 1.5674609484913946 MAE test 2.3870912116266116\n",
      "Epoch 7147 / 10000 loss: 12.885110139846802\n",
      "MSE train 5.191649830796067 MSE test 11.642187802846387\n",
      "MAE train 1.5674455317665903 MAE test 2.3870512496711482\n",
      "Epoch 7148 / 10000 loss: 12.8846755027771\n",
      "MSE train 5.191520960586226 MSE test 11.6422140477319\n",
      "MAE train 1.5674190914191837 MAE test 2.387060526549603\n",
      "Epoch 7149 / 10000 loss: 12.884345531463623\n",
      "MSE train 5.191405182606551 MSE test 11.642001554052655\n",
      "MAE train 1.5674016081083226 MAE test 2.3870333726376485\n",
      "Epoch 7150 / 10000 loss: 12.883793592453003\n",
      "MSE train 5.191291430955888 MSE test 11.641948118832707\n",
      "MAE train 1.5673806080189296 MAE test 2.3870319375228584\n",
      "Epoch 7151 / 10000 loss: 12.883390665054321\n",
      "MSE train 5.191175033982374 MSE test 11.641703463907115\n",
      "MAE train 1.5673635758249482 MAE test 2.3870005180941787\n",
      "Epoch 7152 / 10000 loss: 12.882949590682983\n",
      "MSE train 5.191069270886271 MSE test 11.641698693903331\n",
      "MAE train 1.5673436682387547 MAE test 2.3870055944212987\n",
      "Epoch 7153 / 10000 loss: 12.882566213607788\n",
      "MSE train 5.1909541730209865 MSE test 11.641385700248899\n",
      "MAE train 1.56732830222906 MAE test 2.3869650586717963\n",
      "Epoch 7154 / 10000 loss: 12.882127523422241\n",
      "MSE train 5.190823826936361 MSE test 11.641412174611254\n",
      "MAE train 1.5673014599593111 MAE test 2.3869743712500493\n",
      "Epoch 7155 / 10000 loss: 12.881801128387451\n",
      "MSE train 5.190709342866759 MSE test 11.641209367815145\n",
      "MAE train 1.5672841247564493 MAE test 2.386948514869933\n",
      "Epoch 7156 / 10000 loss: 12.881243228912354\n",
      "MSE train 5.190591900314226 MSE test 11.641139438638055\n",
      "MAE train 1.5672624383830582 MAE test 2.3869448729052842\n",
      "Epoch 7157 / 10000 loss: 12.880837440490723\n",
      "MSE train 5.190476436585313 MSE test 11.640925329472546\n",
      "MAE train 1.5672450839297427 MAE test 2.3869175428220912\n",
      "Epoch 7158 / 10000 loss: 12.880393028259277\n",
      "MSE train 5.19036535486325 MSE test 11.64088541740847\n",
      "MAE train 1.5672245110537537 MAE test 2.3869179254484485\n",
      "Epoch 7159 / 10000 loss: 12.879993677139282\n",
      "MSE train 5.190249683216158 MSE test 11.640619789219874\n",
      "MAE train 1.567208077134392 MAE test 2.3868837040431385\n",
      "Epoch 7160 / 10000 loss: 12.879558086395264\n",
      "MSE train 5.1901392223310925 MSE test 11.640631947410329\n",
      "MAE train 1.5671866532196546 MAE test 2.386891050373812\n",
      "Epoch 7161 / 10000 loss: 12.879191398620605\n",
      "MSE train 5.190023289464963 MSE test 11.640329848059434\n",
      "MAE train 1.5671708768178076 MAE test 2.3868519735007054\n",
      "Epoch 7162 / 10000 loss: 12.87872314453125\n",
      "MSE train 5.1898981137074784 MSE test 11.640353680635421\n",
      "MAE train 1.567145459079197 MAE test 2.3868609292227947\n",
      "Epoch 7163 / 10000 loss: 12.878384590148926\n",
      "MSE train 5.189780592066784 MSE test 11.64012051890453\n",
      "MAE train 1.5671279284069384 MAE test 2.3868310308532963\n",
      "Epoch 7164 / 10000 loss: 12.877848386764526\n",
      "MSE train 5.189673473511418 MSE test 11.640095253871136\n",
      "MAE train 1.5671080227205265 MAE test 2.386833360756746\n",
      "Epoch 7165 / 10000 loss: 12.87745213508606\n",
      "MSE train 5.189557830721158 MSE test 11.63980059888639\n",
      "MAE train 1.5670921756476623 MAE test 2.386795275244073\n",
      "Epoch 7166 / 10000 loss: 12.87701940536499\n",
      "MSE train 5.189435451110124 MSE test 11.63982327256086\n",
      "MAE train 1.567067523328008 MAE test 2.3868040661982817\n",
      "Epoch 7167 / 10000 loss: 12.876676321029663\n",
      "MSE train 5.189317643206986 MSE test 11.639574320139705\n",
      "MAE train 1.567050215657201 MAE test 2.386772058201047\n",
      "Epoch 7168 / 10000 loss: 12.876152038574219\n",
      "MSE train 5.189212070557878 MSE test 11.639566755449431\n",
      "MAE train 1.5670303853412522 MAE test 2.3867767692435358\n",
      "Epoch 7169 / 10000 loss: 12.875766515731812\n",
      "MSE train 5.189096367914247 MSE test 11.639254547022379\n",
      "MAE train 1.5670148503021606 MAE test 2.386736338560909\n",
      "Epoch 7170 / 10000 loss: 12.875327587127686\n",
      "MSE train 5.188966847979698 MSE test 11.639280021162694\n",
      "MAE train 1.566988244310947 MAE test 2.386745522030109\n",
      "Epoch 7171 / 10000 loss: 12.874998569488525\n",
      "MSE train 5.18885155359851 MSE test 11.639071983304092\n",
      "MAE train 1.5669708122465054 MAE test 2.3867189806643405\n",
      "Epoch 7172 / 10000 loss: 12.874444723129272\n",
      "MSE train 5.188735756015751 MSE test 11.639009722425893\n",
      "MAE train 1.5669494334726903 MAE test 2.386716361597233\n",
      "Epoch 7173 / 10000 loss: 12.874039888381958\n",
      "MSE train 5.188619408595372 MSE test 11.638780126814416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5669321592086647 MAE test 2.3866869633779655\n",
      "Epoch 7174 / 10000 loss: 12.873598575592041\n",
      "MSE train 5.188512430919482 MSE test 11.638759144972253\n",
      "MAE train 1.5669122352364042 MAE test 2.386689885296856\n",
      "Epoch 7175 / 10000 loss: 12.873204946517944\n",
      "MSE train 5.18839727106769 MSE test 11.638460978779948\n",
      "MAE train 1.5668965771370726 MAE test 2.3866513394698106\n",
      "Epoch 7176 / 10000 loss: 12.872772455215454\n",
      "MSE train 5.188272744790984 MSE test 11.638485081719287\n",
      "MAE train 1.566871359237049 MAE test 2.3866603339566965\n",
      "Epoch 7177 / 10000 loss: 12.872432947158813\n",
      "MSE train 5.188155023277102 MSE test 11.638246403456446\n",
      "MAE train 1.5668538958270464 MAE test 2.3866297081571104\n",
      "Epoch 7178 / 10000 loss: 12.871899127960205\n",
      "MSE train 5.188048751869 MSE test 11.638227831790397\n",
      "MAE train 1.566834084289035 MAE test 2.3866329371077057\n",
      "Epoch 7179 / 10000 loss: 12.871506690979004\n",
      "MSE train 5.187933056499539 MSE test 11.63792416383646\n",
      "MAE train 1.5668184072698204 MAE test 2.3865936605215254\n",
      "Epoch 7180 / 10000 loss: 12.871074438095093\n",
      "MSE train 5.187806663540849 MSE test 11.63794835326232\n",
      "MAE train 1.56679268732557 MAE test 2.3866026714392756\n",
      "Epoch 7181 / 10000 loss: 12.87073802947998\n",
      "MSE train 5.18768928714223 MSE test 11.637720058587616\n",
      "MAE train 1.56677510384404 MAE test 2.386573424708144\n",
      "Epoch 7182 / 10000 loss: 12.870197296142578\n",
      "MSE train 5.187580585710563 MSE test 11.637687981639369\n",
      "MAE train 1.566754966233303 MAE test 2.386574856123237\n",
      "Epoch 7183 / 10000 loss: 12.869798421859741\n",
      "MSE train 5.1874645174455845 MSE test 11.637402928358087\n",
      "MAE train 1.5667388409344718 MAE test 2.3865380647424623\n",
      "Epoch 7184 / 10000 loss: 12.869364976882935\n",
      "MSE train 5.187346583040986 MSE test 11.637421920307824\n",
      "MAE train 1.5667153893849424 MAE test 2.3865463544166396\n",
      "Epoch 7185 / 10000 loss: 12.869012594223022\n",
      "MSE train 5.187228873295021 MSE test 11.637150070323734\n",
      "MAE train 1.5666985909544733 MAE test 2.386511325974559\n",
      "Epoch 7186 / 10000 loss: 12.86850905418396\n",
      "MSE train 5.187118048375629 MSE test 11.637159808707382\n",
      "MAE train 1.5666771198754998 MAE test 2.3865183649905326\n",
      "Epoch 7187 / 10000 loss: 12.86814022064209\n",
      "MSE train 5.187001137684847 MSE test 11.636859100397299\n",
      "MAE train 1.566661086851735 MAE test 2.3864794787545054\n",
      "Epoch 7188 / 10000 loss: 12.867669582366943\n",
      "MSE train 5.1868770882130475 MSE test 11.636880843675545\n",
      "MAE train 1.566636047989491 MAE test 2.3864881626787384\n",
      "Epoch 7189 / 10000 loss: 12.867327213287354\n",
      "MSE train 5.186758743488061 MSE test 11.636638887635154\n",
      "MAE train 1.5666185112081508 MAE test 2.3864571186011037\n",
      "Epoch 7190 / 10000 loss: 12.866796493530273\n",
      "MSE train 5.186652416541053 MSE test 11.636621742017276\n",
      "MAE train 1.566598696381288 MAE test 2.3864605521020503\n",
      "Epoch 7191 / 10000 loss: 12.866404294967651\n",
      "MSE train 5.1865362245303555 MSE test 11.636315286558254\n",
      "MAE train 1.5665829707091428 MAE test 2.3864209046783342\n",
      "Epoch 7192 / 10000 loss: 12.86596941947937\n",
      "MSE train 5.186408599281188 MSE test 11.636339014340034\n",
      "MAE train 1.5665569754257223 MAE test 2.3864298604149523\n",
      "Epoch 7193 / 10000 loss: 12.865633964538574\n",
      "MSE train 5.186291034986452 MSE test 11.636115052355935\n",
      "MAE train 1.566539303266464 MAE test 2.3864012170074935\n",
      "Epoch 7194 / 10000 loss: 12.865088701248169\n",
      "MSE train 5.186180263707691 MSE test 11.636075316875019\n",
      "MAE train 1.566518845629108 MAE test 2.386401640394852\n",
      "Epoch 7195 / 10000 loss: 12.864686250686646\n",
      "MSE train 5.1860633650760155 MSE test 11.63580109249667\n",
      "MAE train 1.566502339552553 MAE test 2.386366309757023\n",
      "Epoch 7196 / 10000 loss: 12.86424994468689\n",
      "MSE train 5.18594984785977 MSE test 11.635814299396868\n",
      "MAE train 1.5664801872631782 MAE test 2.386373840210608\n",
      "Epoch 7197 / 10000 loss: 12.863885402679443\n",
      "MSE train 5.185832250875732 MSE test 11.635519972134626\n",
      "MAE train 1.5664639192904444 MAE test 2.3863358141168916\n",
      "Epoch 7198 / 10000 loss: 12.863403558731079\n",
      "MSE train 5.185710672891415 MSE test 11.635539228827215\n",
      "MAE train 1.5664396192584213 MAE test 2.386344176545596\n",
      "Epoch 7199 / 10000 loss: 12.863053321838379\n",
      "MSE train 5.185591501876944 MSE test 11.635280569967586\n",
      "MAE train 1.5664222574786257 MAE test 2.3863109105872486\n",
      "Epoch 7200 / 10000 loss: 12.862534284591675\n",
      "MSE train 5.185483723177158 MSE test 11.635278169048398\n",
      "MAE train 1.5664019150820878 MAE test 2.3863163471342963\n",
      "Epoch 7201 / 10000 loss: 12.862150430679321\n",
      "MSE train 5.185366202927708 MSE test 11.63496390394689\n",
      "MAE train 1.566386073655133 MAE test 2.386275680908222\n",
      "Epoch 7202 / 10000 loss: 12.861700296401978\n",
      "MSE train 5.185235095707273 MSE test 11.63498698231577\n",
      "MAE train 1.5663592803355515 MAE test 2.386284588271821\n",
      "Epoch 7203 / 10000 loss: 12.861365795135498\n",
      "MSE train 5.185117710737848 MSE test 11.634776077212923\n",
      "MAE train 1.566341549086526 MAE test 2.386257716737417\n",
      "Epoch 7204 / 10000 loss: 12.860807418823242\n",
      "MSE train 5.184999930766705 MSE test 11.634712342420558\n",
      "MAE train 1.5663199040577853 MAE test 2.386254956100024\n",
      "Epoch 7205 / 10000 loss: 12.860396385192871\n",
      "MSE train 5.1848809953509045 MSE test 11.634478849299258\n",
      "MAE train 1.566302265179728 MAE test 2.386225098229525\n",
      "Epoch 7206 / 10000 loss: 12.85994839668274\n",
      "MSE train 5.184771413915894 MSE test 11.634456560188326\n",
      "MAE train 1.566281970875162 MAE test 2.3862278869810765\n",
      "Epoch 7207 / 10000 loss: 12.85954737663269\n",
      "MSE train 5.184652891115975 MSE test 11.634153202144736\n",
      "MAE train 1.5662658577973365 MAE test 2.3861887184002204\n",
      "Epoch 7208 / 10000 loss: 12.859106063842773\n",
      "MSE train 5.184523517138954 MSE test 11.634174159599915\n",
      "MAE train 1.5662398291092685 MAE test 2.3861973683457847\n",
      "Epoch 7209 / 10000 loss: 12.858757972717285\n",
      "MSE train 5.1844014583643085 MSE test 11.633937405299784\n",
      "MAE train 1.5662216302139973 MAE test 2.3861670861257225\n",
      "Epoch 7210 / 10000 loss: 12.858207941055298\n",
      "MSE train 5.184288906717386 MSE test 11.633907891192676\n",
      "MAE train 1.5662009404522244 MAE test 2.3861689487070668\n",
      "Epoch 7211 / 10000 loss: 12.857796669006348\n",
      "MSE train 5.184166837654185 MSE test 11.633608168502917\n",
      "MAE train 1.5661841199711135 MAE test 2.3861303019196773\n",
      "Epoch 7212 / 10000 loss: 12.857346057891846\n",
      "MSE train 5.1840366818775285 MSE test 11.633624890313422\n",
      "MAE train 1.566158322911973 MAE test 2.3861384118029063\n",
      "Epoch 7213 / 10000 loss: 12.856979846954346\n",
      "MSE train 5.183909536405844 MSE test 11.633370337099793\n",
      "MAE train 1.566139578376095 MAE test 2.3861058155738215\n",
      "Epoch 7214 / 10000 loss: 12.856428146362305\n",
      "MSE train 5.183792621058335 MSE test 11.63335489784613\n",
      "MAE train 1.5661180314810443 MAE test 2.3861096133664255\n",
      "Epoch 7215 / 10000 loss: 12.856008052825928\n",
      "MSE train 5.18366321896541 MSE test 11.633035220892127\n",
      "MAE train 1.5661003711001171 MAE test 2.386068379656714\n",
      "Epoch 7216 / 10000 loss: 12.855528593063354\n",
      "MSE train 5.183517382790903 MSE test 11.633051194677295\n",
      "MAE train 1.5660713043939227 MAE test 2.3860764889768173\n",
      "Epoch 7217 / 10000 loss: 12.855147361755371\n",
      "MSE train 5.1833825577019645 MSE test 11.632832487535822\n",
      "MAE train 1.5660508413281864 MAE test 2.3860487569274644\n",
      "Epoch 7218 / 10000 loss: 12.854529857635498\n",
      "MSE train 5.183245597610249 MSE test 11.632761155343509\n",
      "MAE train 1.566026242909475 MAE test 2.386045181049452\n",
      "Epoch 7219 / 10000 loss: 12.854048728942871\n",
      "MSE train 5.183107438899124 MSE test 11.632518859281937\n",
      "MAE train 1.5660056525745731 MAE test 2.3860143675279892\n",
      "Epoch 7220 / 10000 loss: 12.853523015975952\n",
      "MSE train 5.182981890256263 MSE test 11.632492033609061\n",
      "MAE train 1.5659828711872614 MAE test 2.3860167318211842\n",
      "Epoch 7221 / 10000 loss: 12.853045225143433\n",
      "MSE train 5.182853202565988 MSE test 11.63218469411756\n",
      "MAE train 1.5659651407035964 MAE test 2.3859771916295367\n",
      "Epoch 7222 / 10000 loss: 12.852538824081421\n",
      "MSE train 5.182719359184215 MSE test 11.632207362067494\n",
      "MAE train 1.5659382622435918 MAE test 2.3859861459953557\n",
      "Epoch 7223 / 10000 loss: 12.852149724960327\n",
      "MSE train 5.182598562801789 MSE test 11.631979655275888\n",
      "MAE train 1.565920101854071 MAE test 2.3859570885330244\n",
      "Epoch 7224 / 10000 loss: 12.85158109664917\n",
      "MSE train 5.182489454290238 MSE test 11.631953542957337\n",
      "MAE train 1.565899802472522 MAE test 2.3859593333278113\n",
      "Epoch 7225 / 10000 loss: 12.851168632507324\n",
      "MSE train 5.182373828589341 MSE test 11.631670889333945\n",
      "MAE train 1.565883691358781 MAE test 2.385922868259371\n",
      "Epoch 7226 / 10000 loss: 12.850730180740356\n",
      "MSE train 5.182255434572301 MSE test 11.63169640337635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5658599182139308 MAE test 2.3859320056908344\n",
      "Epoch 7227 / 10000 loss: 12.85037899017334\n",
      "MSE train 5.182138815132678 MSE test 11.631437457184866\n",
      "MAE train 1.5658429892530288 MAE test 2.3858986532701727\n",
      "Epoch 7228 / 10000 loss: 12.849868297576904\n",
      "MSE train 5.182031866745129 MSE test 11.631447825882622\n",
      "MAE train 1.5658223726199316 MAE test 2.3859057242856325\n",
      "Epoch 7229 / 10000 loss: 12.84949517250061\n",
      "MSE train 5.181916833743326 MSE test 11.631144563911397\n",
      "MAE train 1.565806690590476 MAE test 2.3858664523717725\n",
      "Epoch 7230 / 10000 loss: 12.849038362503052\n",
      "MSE train 5.181790700356151 MSE test 11.631173084272339\n",
      "MAE train 1.5657807983082168 MAE test 2.385875984835084\n",
      "Epoch 7231 / 10000 loss: 12.84870457649231\n",
      "MSE train 5.181675147254684 MSE test 11.630956433793353\n",
      "MAE train 1.5657632993111084 MAE test 2.3858482671262085\n",
      "Epoch 7232 / 10000 loss: 12.84816026687622\n",
      "MSE train 5.181565308772803 MSE test 11.630916907019195\n",
      "MAE train 1.5657428908201492 MAE test 2.3858486623063113\n",
      "Epoch 7233 / 10000 loss: 12.847759485244751\n",
      "MSE train 5.181450173052032 MSE test 11.630654803309172\n",
      "MAE train 1.5657263875554714 MAE test 2.3858149042875922\n",
      "Epoch 7234 / 10000 loss: 12.847325563430786\n",
      "MSE train 5.181341489354502 MSE test 11.630667967118573\n",
      "MAE train 1.5657052748250577 MAE test 2.385822348375566\n",
      "Epoch 7235 / 10000 loss: 12.846958637237549\n",
      "MSE train 5.181226452699636 MSE test 11.630367312376961\n",
      "MAE train 1.5656895509093391 MAE test 2.385783454715322\n",
      "Epoch 7236 / 10000 loss: 12.846494674682617\n",
      "MSE train 5.181101890493572 MSE test 11.630393449585867\n",
      "MAE train 1.56566413117067 MAE test 2.3857926877591678\n",
      "Epoch 7237 / 10000 loss: 12.846158027648926\n",
      "MSE train 5.180985540718479 MSE test 11.630165515135868\n",
      "MAE train 1.5656466651641177 MAE test 2.3857634750780274\n",
      "Epoch 7238 / 10000 loss: 12.84562087059021\n",
      "MSE train 5.180878746322076 MSE test 11.630138608779921\n",
      "MAE train 1.5656267588206427 MAE test 2.3857655499979415\n",
      "Epoch 7239 / 10000 loss: 12.845225095748901\n",
      "MSE train 5.180763963644388 MSE test 11.62985178833691\n",
      "MAE train 1.565610845216607 MAE test 2.3857285088179156\n",
      "Epoch 7240 / 10000 loss: 12.844794750213623\n",
      "MSE train 5.18064526569387 MSE test 11.629874330196094\n",
      "MAE train 1.5655870043997298 MAE test 2.385737249857998\n",
      "Epoch 7241 / 10000 loss: 12.844447612762451\n",
      "MSE train 5.180528487348225 MSE test 11.629614547110213\n",
      "MAE train 1.5655700557767611 MAE test 2.385703803717884\n",
      "Epoch 7242 / 10000 loss: 12.843937158584595\n",
      "MSE train 5.180422081870601 MSE test 11.629619539733973\n",
      "MAE train 1.5655496642165632 MAE test 2.3857101542340593\n",
      "Epoch 7243 / 10000 loss: 12.84356164932251\n",
      "MSE train 5.180306892011372 MSE test 11.629311264312797\n",
      "MAE train 1.5655340528914012 MAE test 2.385670254293867\n",
      "Epoch 7244 / 10000 loss: 12.843111038208008\n",
      "MSE train 5.180179545669121 MSE test 11.629337329073763\n",
      "MAE train 1.565507889740883 MAE test 2.3856794937957826\n",
      "Epoch 7245 / 10000 loss: 12.842780590057373\n",
      "MSE train 5.180064241734348 MSE test 11.629123545546605\n",
      "MAE train 1.5654904347811547 MAE test 2.3856521668908006\n",
      "Epoch 7246 / 10000 loss: 12.842233180999756\n",
      "MSE train 5.179952177903963 MSE test 11.629073851917141\n",
      "MAE train 1.5654696695484145 MAE test 2.385651213299588\n",
      "Epoch 7247 / 10000 loss: 12.84183120727539\n",
      "MSE train 5.179836518712976 MSE test 11.628824230525776\n",
      "MAE train 1.5654528104672158 MAE test 2.385619143248195\n",
      "Epoch 7248 / 10000 loss: 12.841395616531372\n",
      "MSE train 5.179731079389371 MSE test 11.628825027477859\n",
      "MAE train 1.5654327748515748 MAE test 2.385624940208583\n",
      "Epoch 7249 / 10000 loss: 12.84101676940918\n",
      "MSE train 5.17961651822689 MSE test 11.62851289930658\n",
      "MAE train 1.5654174088927757 MAE test 2.385584521524991\n",
      "Epoch 7250 / 10000 loss: 12.840574979782104\n",
      "MSE train 5.179487174803287 MSE test 11.628539564494748\n",
      "MAE train 1.5653907051289346 MAE test 2.3855938561357353\n",
      "Epoch 7251 / 10000 loss: 12.840249300003052\n",
      "MSE train 5.179373403735494 MSE test 11.628337051635148\n",
      "MAE train 1.5653734327265019 MAE test 2.3855680376958257\n",
      "Epoch 7252 / 10000 loss: 12.839693546295166\n",
      "MSE train 5.179256897284808 MSE test 11.628268211889432\n",
      "MAE train 1.5653518468136307 MAE test 2.385564532543797\n",
      "Epoch 7253 / 10000 loss: 12.839290380477905\n",
      "MSE train 5.179142123488261 MSE test 11.628053654837352\n",
      "MAE train 1.5653345755151806 MAE test 2.385537136934914\n",
      "Epoch 7254 / 10000 loss: 12.83884882926941\n",
      "MSE train 5.1790322437320695 MSE test 11.628015450233649\n",
      "MAE train 1.56531414519029 MAE test 2.3855377210147872\n",
      "Epoch 7255 / 10000 loss: 12.83845067024231\n",
      "MSE train 5.178917250479666 MSE test 11.627747903481513\n",
      "MAE train 1.5652978308100234 MAE test 2.385503268482875\n",
      "Epoch 7256 / 10000 loss: 12.838017702102661\n",
      "MSE train 5.178806669611428 MSE test 11.627761538852816\n",
      "MAE train 1.5652762245048764 MAE test 2.3855108109022964\n",
      "Epoch 7257 / 10000 loss: 12.83765459060669\n",
      "MSE train 5.178691257435695 MSE test 11.62746425489774\n",
      "MAE train 1.5652603708658743 MAE test 2.385472368967838\n",
      "Epoch 7258 / 10000 loss: 12.837183475494385\n",
      "MSE train 5.178568869306845 MSE test 11.62748690015994\n",
      "MAE train 1.565235579211727 MAE test 2.3854811491193435\n",
      "Epoch 7259 / 10000 loss: 12.836843729019165\n",
      "MSE train 5.1784518182114 MSE test 11.627243944033463\n",
      "MAE train 1.5652182461394988 MAE test 2.385449956073933\n",
      "Epoch 7260 / 10000 loss: 12.836317777633667\n",
      "MSE train 5.17834692351145 MSE test 11.627230578633627\n",
      "MAE train 1.5651985696159294 MAE test 2.385453861338706\n",
      "Epoch 7261 / 10000 loss: 12.835929870605469\n",
      "MSE train 5.178231967651051 MSE test 11.626923167362815\n",
      "MAE train 1.565183030695923 MAE test 2.385414067053486\n",
      "Epoch 7262 / 10000 loss: 12.835497617721558\n",
      "MSE train 5.1781048339874385 MSE test 11.626948080398773\n",
      "MAE train 1.5651569323315506 MAE test 2.3854231593411868\n",
      "Epoch 7263 / 10000 loss: 12.835167407989502\n",
      "MSE train 5.177989186842334 MSE test 11.62673115753743\n",
      "MAE train 1.5651394450837786 MAE test 2.38539544022073\n",
      "Epoch 7264 / 10000 loss: 12.834621667861938\n",
      "MSE train 5.177877865299949 MSE test 11.626683928445308\n",
      "MAE train 1.565118826212853 MAE test 2.385394816167222\n",
      "Epoch 7265 / 10000 loss: 12.834220170974731\n",
      "MSE train 5.177762176103374 MSE test 11.626426801348893\n",
      "MAE train 1.5651021079226892 MAE test 2.3853617516009793\n",
      "Epoch 7266 / 10000 loss: 12.83378553390503\n",
      "MSE train 5.177655380718418 MSE test 11.626431663611996\n",
      "MAE train 1.5650816463219892 MAE test 2.3853681000701137\n",
      "Epoch 7267 / 10000 loss: 12.833412647247314\n",
      "MSE train 5.177540420014767 MSE test 11.626121271730634\n",
      "MAE train 1.5650661519171376 MAE test 2.3853279172985418\n",
      "Epoch 7268 / 10000 loss: 12.832961320877075\n",
      "MSE train 5.177412276973652 MSE test 11.626146259977489\n",
      "MAE train 1.5650397724226128 MAE test 2.385337037794165\n",
      "Epoch 7269 / 10000 loss: 12.83263349533081\n",
      "MSE train 5.177297267808798 MSE test 11.625935441517614\n",
      "MAE train 1.5650223622466852 MAE test 2.385310126955759\n",
      "Epoch 7270 / 10000 loss: 12.832083463668823\n",
      "MSE train 5.177183590357454 MSE test 11.62587812495276\n",
      "MAE train 1.5650013104493463 MAE test 2.385308159748783\n",
      "Epoch 7271 / 10000 loss: 12.831681489944458\n",
      "MSE train 5.177067786856692 MSE test 11.625639176970008\n",
      "MAE train 1.5649842387837871 MAE test 2.385277515558275\n",
      "Epoch 7272 / 10000 loss: 12.831242799758911\n",
      "MSE train 5.176962754249046 MSE test 11.625628163571113\n",
      "MAE train 1.564964494852376 MAE test 2.3852817551209675\n",
      "Epoch 7273 / 10000 loss: 12.830857038497925\n",
      "MSE train 5.176848359881911 MSE test 11.625319110996863\n",
      "MAE train 1.564949126818515 MAE test 2.38524175546601\n",
      "Epoch 7274 / 10000 loss: 12.830425262451172\n",
      "MSE train 5.176720138216129 MSE test 11.625344378910679\n",
      "MAE train 1.5649227305849398 MAE test 2.385250909092905\n",
      "Epoch 7275 / 10000 loss: 12.83009672164917\n",
      "MSE train 5.176605067613663 MSE test 11.625132862671588\n",
      "MAE train 1.5649053164431568 MAE test 2.3852239141901346\n",
      "Epoch 7276 / 10000 loss: 12.82954716682434\n",
      "MSE train 5.1764916507926095 MSE test 11.625076708656747\n",
      "MAE train 1.56488431300596 MAE test 2.3852221053459677\n",
      "Epoch 7277 / 10000 loss: 12.829145431518555\n",
      "MSE train 5.176375882855994 MSE test 11.624835336496082\n",
      "MAE train 1.5648672860430697 MAE test 2.3851911532754118\n",
      "Epoch 7278 / 10000 loss: 12.828707933425903\n",
      "MSE train 5.1762709016539565 MSE test 11.624826334260911\n",
      "MAE train 1.5648475146704415 MAE test 2.3851956656337987\n",
      "Epoch 7279 / 10000 loss: 12.828323364257812\n",
      "MSE train 5.176156424803242 MSE test 11.624515597759611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5648321676769847 MAE test 2.3851554326757793\n",
      "Epoch 7280 / 10000 loss: 12.827890157699585\n",
      "MSE train 5.176027628439739 MSE test 11.624540706980321\n",
      "MAE train 1.5648056098468381 MAE test 2.385164581853402\n",
      "Epoch 7281 / 10000 loss: 12.827563524246216\n",
      "MSE train 5.1759130351164675 MSE test 11.624332579695507\n",
      "MAE train 1.5647882553971115 MAE test 2.38513803837958\n",
      "Epoch 7282 / 10000 loss: 12.827011108398438\n",
      "MSE train 5.175798149449948 MSE test 11.62427027018776\n",
      "MAE train 1.5647669682908467 MAE test 2.38513542113959\n",
      "Epoch 7283 / 10000 loss: 12.826607942581177\n",
      "MSE train 5.175682618412877 MSE test 11.624040280881749\n",
      "MAE train 1.564749797425282 MAE test 2.3851059808286506\n",
      "Epoch 7284 / 10000 loss: 12.826168775558472\n",
      "MSE train 5.175576388654266 MSE test 11.624018894108593\n",
      "MAE train 1.56472993453839 MAE test 2.3851088281047192\n",
      "Epoch 7285 / 10000 loss: 12.82577657699585\n",
      "MSE train 5.175462027242677 MSE test 11.623720527635127\n",
      "MAE train 1.5647143689469398 MAE test 2.385070270324147\n",
      "Epoch 7286 / 10000 loss: 12.825348138809204\n",
      "MSE train 5.175338213871826 MSE test 11.623743721875206\n",
      "MAE train 1.5646891952579687 MAE test 2.3850791487485044\n",
      "Epoch 7287 / 10000 loss: 12.825010538101196\n",
      "MSE train 5.175221319649396 MSE test 11.623505838737323\n",
      "MAE train 1.5646718155539472 MAE test 2.3850486430825\n",
      "Epoch 7288 / 10000 loss: 12.824480056762695\n",
      "MSE train 5.175115790394296 MSE test 11.623485533645967\n",
      "MAE train 1.5646520702398188 MAE test 2.3850516386397147\n",
      "Epoch 7289 / 10000 loss: 12.82408881187439\n",
      "MSE train 5.175000908506708 MSE test 11.623183389777331\n",
      "MAE train 1.5646364537298914 MAE test 2.3850125712108063\n",
      "Epoch 7290 / 10000 loss: 12.82365870475769\n",
      "MSE train 5.174876072314135 MSE test 11.623206317000962\n",
      "MAE train 1.5646109953606644 MAE test 2.3850214149033726\n",
      "Epoch 7291 / 10000 loss: 12.823322534561157\n",
      "MSE train 5.174759352605586 MSE test 11.622974379718865\n",
      "MAE train 1.564593533734695 MAE test 2.3849917064420465\n",
      "Epoch 7292 / 10000 loss: 12.822787761688232\n",
      "MSE train 5.174652462052688 MSE test 11.622945903839128\n",
      "MAE train 1.5645736187899106 MAE test 2.3849936222822024\n",
      "Epoch 7293 / 10000 loss: 12.822392702102661\n",
      "MSE train 5.174537405778937 MSE test 11.622654179505995\n",
      "MAE train 1.5645577530209513 MAE test 2.384955942303721\n",
      "Epoch 7294 / 10000 loss: 12.821962833404541\n",
      "MSE train 5.174417322719912 MSE test 11.622674505922266\n",
      "MAE train 1.5645335691380093 MAE test 2.3849644328701634\n",
      "Epoch 7295 / 10000 loss: 12.82161831855774\n",
      "MSE train 5.1743001681141125 MSE test 11.622417778739802\n",
      "MAE train 1.5645164788985633 MAE test 2.3849314275863103\n",
      "Epoch 7296 / 10000 loss: 12.82110333442688\n",
      "MSE train 5.174194578562084 MSE test 11.622415367547694\n",
      "MAE train 1.5644963993309855 MAE test 2.384936829594965\n",
      "Epoch 7297 / 10000 loss: 12.820725202560425\n",
      "MSE train 5.174079302113107 MSE test 11.622102744649817\n",
      "MAE train 1.5644808744401129 MAE test 2.3848963373429215\n",
      "Epoch 7298 / 10000 loss: 12.820281982421875\n",
      "MSE train 5.173950681793916 MSE test 11.6221264377553\n",
      "MAE train 1.5644543694786013 MAE test 2.3849053184625073\n",
      "Epoch 7299 / 10000 loss: 12.819953680038452\n",
      "MSE train 5.1738359246373875 MSE test 11.621916919047571\n",
      "MAE train 1.564436992756682 MAE test 2.3848786014379564\n",
      "Epoch 7300 / 10000 loss: 12.819403171539307\n",
      "MSE train 5.173721164532764 MSE test 11.621854314231523\n",
      "MAE train 1.5644157263308405 MAE test 2.384875954825749\n",
      "Epoch 7301 / 10000 loss: 12.818999528884888\n",
      "MSE train 5.173605486210432 MSE test 11.621622278364372\n",
      "MAE train 1.564398553616284 MAE test 2.38484624487213\n",
      "Epoch 7302 / 10000 loss: 12.818560361862183\n",
      "MSE train 5.1734995205067875 MSE test 11.621601749506924\n",
      "MAE train 1.5643787152611368 MAE test 2.384849233694399\n",
      "Epoch 7303 / 10000 loss: 12.818170309066772\n",
      "MSE train 5.1733849954849305 MSE test 11.621300901698229\n",
      "MAE train 1.5643631727341123 MAE test 2.3848103422482088\n",
      "Epoch 7304 / 10000 loss: 12.817739963531494\n",
      "MSE train 5.173260288965043 MSE test 11.62132363142365\n",
      "MAE train 1.5643377518211532 MAE test 2.3848191803533236\n",
      "Epoch 7305 / 10000 loss: 12.817403793334961\n",
      "MSE train 5.173143492156861 MSE test 11.621089747005044\n",
      "MAE train 1.564320306976997 MAE test 2.3847892110589783\n",
      "Epoch 7306 / 10000 loss: 12.816869735717773\n",
      "MSE train 5.173036992208792 MSE test 11.62106304925851\n",
      "MAE train 1.5643004402752267 MAE test 2.384791371970735\n",
      "Epoch 7307 / 10000 loss: 12.816476345062256\n",
      "MSE train 5.172921972817581 MSE test 11.620767700819268\n",
      "MAE train 1.5642846485394826 MAE test 2.3847532184225666\n",
      "Epoch 7308 / 10000 loss: 12.816045999526978\n",
      "MSE train 5.172800318619855 MSE test 11.620788269022254\n",
      "MAE train 1.5642600471143318 MAE test 2.3847617563028667\n",
      "Epoch 7309 / 10000 loss: 12.815704345703125\n",
      "MSE train 5.17268301771487 MSE test 11.62053862713211\n",
      "MAE train 1.5642427926692004 MAE test 2.3847296831911353\n",
      "Epoch 7310 / 10000 loss: 12.81518268585205\n",
      "MSE train 5.172578110480658 MSE test 11.620528751185464\n",
      "MAE train 1.5642230001933095 MAE test 2.3847341064281586\n",
      "Epoch 7311 / 10000 loss: 12.814798593521118\n",
      "MSE train 5.1724628772720305 MSE test 11.620216360123566\n",
      "MAE train 1.5642074948868103 MAE test 2.3846936632558955\n",
      "Epoch 7312 / 10000 loss: 12.8143630027771\n",
      "MSE train 5.172334323611347 MSE test 11.62023953716075\n",
      "MAE train 1.5641810000276624 MAE test 2.3847025598339044\n",
      "Epoch 7313 / 10000 loss: 12.81403398513794\n",
      "MSE train 5.172219393179034 MSE test 11.620028904805956\n",
      "MAE train 1.5641636005800474 MAE test 2.3846756967103806\n",
      "Epoch 7314 / 10000 loss: 12.813482999801636\n",
      "MSE train 5.172104912090628 MSE test 11.619967125515704\n",
      "MAE train 1.5641423836305886 MAE test 2.384673168845177\n",
      "Epoch 7315 / 10000 loss: 12.813079595565796\n",
      "MSE train 5.171989043436633 MSE test 11.619731890818715\n",
      "MAE train 1.5641252265811654 MAE test 2.384643048404927\n",
      "Epoch 7316 / 10000 loss: 12.812641382217407\n",
      "MSE train 5.17188334749503 MSE test 11.619713673643247\n",
      "MAE train 1.5641054085885426 MAE test 2.3846463587369904\n",
      "Epoch 7317 / 10000 loss: 12.812251806259155\n",
      "MSE train 5.171768786946387 MSE test 11.619408814973902\n",
      "MAE train 1.5640899292689654 MAE test 2.3846069391587457\n",
      "Epoch 7318 / 10000 loss: 12.811821460723877\n",
      "MSE train 5.171642513548741 MSE test 11.619431403914987\n",
      "MAE train 1.5640640667003747 MAE test 2.384615767725496\n",
      "Epoch 7319 / 10000 loss: 12.81148910522461\n",
      "MSE train 5.171526040822535 MSE test 11.619205782711322\n",
      "MAE train 1.5640465527489915 MAE test 2.384586908744655\n",
      "Epoch 7320 / 10000 loss: 12.81094765663147\n",
      "MSE train 5.171417072065514 MSE test 11.619166829196645\n",
      "MAE train 1.5640262960946925 MAE test 2.384587437210501\n",
      "Epoch 7321 / 10000 loss: 12.810549020767212\n",
      "MSE train 5.171301547013537 MSE test 11.61888907292766\n",
      "MAE train 1.5640100467651135 MAE test 2.3845516494902186\n",
      "Epoch 7322 / 10000 loss: 12.81011700630188\n",
      "MSE train 5.171188069273692 MSE test 11.618902506481158\n",
      "MAE train 1.5639876342076906 MAE test 2.3845592154185633\n",
      "Epoch 7323 / 10000 loss: 12.80975890159607\n",
      "MSE train 5.171071667613238 MSE test 11.618614185399057\n",
      "MAE train 1.563971361376197 MAE test 2.3845220093587556\n",
      "Epoch 7324 / 10000 loss: 12.809274435043335\n",
      "MSE train 5.170954791798828 MSE test 11.61862975136228\n",
      "MAE train 1.563948038649867 MAE test 2.384529869106434\n",
      "Epoch 7325 / 10000 loss: 12.808922290802002\n",
      "MSE train 5.170837529532862 MSE test 11.618356927833052\n",
      "MAE train 1.5639312560414005 MAE test 2.384494727060754\n",
      "Epoch 7326 / 10000 loss: 12.808422088623047\n",
      "MSE train 5.170727810133286 MSE test 11.618363629098978\n",
      "MAE train 1.5639099131819372 MAE test 2.384501377929211\n",
      "Epoch 7327 / 10000 loss: 12.808054447174072\n",
      "MSE train 5.1706115805708475 MSE test 11.61806167429709\n",
      "MAE train 1.5638939479434246 MAE test 2.384462333632595\n",
      "Epoch 7328 / 10000 loss: 12.807587146759033\n",
      "MSE train 5.170488417951519 MSE test 11.618080926754372\n",
      "MAE train 1.563868961895587 MAE test 2.3844707243330734\n",
      "Epoch 7329 / 10000 loss: 12.807246923446655\n",
      "MSE train 5.170370952136055 MSE test 11.617838380102997\n",
      "MAE train 1.5638515170409997 MAE test 2.384439604394869\n",
      "Epoch 7330 / 10000 loss: 12.806718587875366\n",
      "MSE train 5.170265466765543 MSE test 11.617818267362033\n",
      "MAE train 1.563831757499434 MAE test 2.384442674782402\n",
      "Epoch 7331 / 10000 loss: 12.806328296661377\n",
      "MSE train 5.1701501208914245 MSE test 11.617511943013215\n",
      "MAE train 1.5638161042954999 MAE test 2.384403053508573\n",
      "Epoch 7332 / 10000 loss: 12.805896520614624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.1700240612365755 MSE test 11.61753308904418\n",
      "MAE train 1.5637903224102827 MAE test 2.3844117148124537\n",
      "Epoch 7333 / 10000 loss: 12.805561542510986\n",
      "MSE train 5.1699073127028825 MSE test 11.617305231365481\n",
      "MAE train 1.5637727736693467 MAE test 2.384382557610005\n",
      "Epoch 7334 / 10000 loss: 12.805021286010742\n",
      "MSE train 5.169798566986995 MSE test 11.617267035476827\n",
      "MAE train 1.5637525586334484 MAE test 2.3843832120195487\n",
      "Epoch 7335 / 10000 loss: 12.804622888565063\n",
      "MSE train 5.169682866915974 MSE test 11.616985647621725\n",
      "MAE train 1.5637363388303207 MAE test 2.384346953043205\n",
      "Epoch 7336 / 10000 loss: 12.804190874099731\n",
      "MSE train 5.169567955903993 MSE test 11.616999506454851\n",
      "MAE train 1.5637135543470957 MAE test 2.384354601588931\n",
      "Epoch 7337 / 10000 loss: 12.803835391998291\n",
      "MSE train 5.169451132161478 MSE test 11.616715559177067\n",
      "MAE train 1.5636971033818443 MAE test 2.3843179845214015\n",
      "Epoch 7338 / 10000 loss: 12.803343534469604\n",
      "MSE train 5.1693365941539025 MSE test 11.61672795861461\n",
      "MAE train 1.563674422937929 MAE test 2.3843254355706613\n",
      "Epoch 7339 / 10000 loss: 12.802986145019531\n",
      "MSE train 5.1692195362812585 MSE test 11.61644350271531\n",
      "MAE train 1.5636579175794925 MAE test 2.3842887633637275\n",
      "Epoch 7340 / 10000 loss: 12.802496433258057\n",
      "MSE train 5.169105029172869 MSE test 11.616455280307502\n",
      "MAE train 1.5636352507794977 MAE test 2.3842961380253267\n",
      "Epoch 7341 / 10000 loss: 12.802137613296509\n",
      "MSE train 5.16898785844547 MSE test 11.616170570823723\n",
      "MAE train 1.5636187267396793 MAE test 2.3842594156481414\n",
      "Epoch 7342 / 10000 loss: 12.801648616790771\n",
      "MSE train 5.168873380441727 MSE test 11.616182187174731\n",
      "MAE train 1.563596063709976 MAE test 2.3842667695277555\n",
      "Epoch 7343 / 10000 loss: 12.801289558410645\n",
      "MSE train 5.168756119341665 MSE test 11.615897193493561\n",
      "MAE train 1.5635795284815834 MAE test 2.384230020908276\n",
      "Epoch 7344 / 10000 loss: 12.800800323486328\n",
      "MSE train 5.1686415509687595 MSE test 11.615908627903314\n",
      "MAE train 1.563556853044088 MAE test 2.3842373555418077\n",
      "Epoch 7345 / 10000 loss: 12.80044174194336\n",
      "MSE train 5.1685242535382185 MSE test 11.61562373482038\n",
      "MAE train 1.5635403015382172 MAE test 2.3842006214960865\n",
      "Epoch 7346 / 10000 loss: 12.799951791763306\n",
      "MSE train 5.168409745786219 MSE test 11.615634852556818\n",
      "MAE train 1.5635176389663035 MAE test 2.3842079142152346\n",
      "Epoch 7347 / 10000 loss: 12.799592733383179\n",
      "MSE train 5.168292372070571 MSE test 11.615349624454598\n",
      "MAE train 1.563501082709278 MAE test 2.3841711424979004\n",
      "Epoch 7348 / 10000 loss: 12.799103021621704\n",
      "MSE train 5.16817767113703 MSE test 11.615360755221493\n",
      "MAE train 1.5634783806416614 MAE test 2.3841784344476133\n",
      "Epoch 7349 / 10000 loss: 12.798743486404419\n",
      "MSE train 5.168060315970356 MSE test 11.615075795685033\n",
      "MAE train 1.563461813393621 MAE test 2.384141697487769\n",
      "Epoch 7350 / 10000 loss: 12.798253297805786\n",
      "MSE train 5.167945782873896 MSE test 11.615086562236925\n",
      "MAE train 1.5634391595099755 MAE test 2.384148953322979\n",
      "Epoch 7351 / 10000 loss: 12.79789400100708\n",
      "MSE train 5.167828368108951 MSE test 11.614800528295437\n",
      "MAE train 1.5634226043016217 MAE test 2.3841120659562645\n",
      "Epoch 7352 / 10000 loss: 12.797404289245605\n",
      "MSE train 5.167713339160008 MSE test 11.614811510260068\n",
      "MAE train 1.563399826924425 MAE test 2.3841193642460765\n",
      "Epoch 7353 / 10000 loss: 12.797045230865479\n",
      "MSE train 5.167595804153479 MSE test 11.614527093451889\n",
      "MAE train 1.563383212919186 MAE test 2.3840827073241515\n",
      "Epoch 7354 / 10000 loss: 12.79655408859253\n",
      "MSE train 5.167481541353617 MSE test 11.6145369961397\n",
      "MAE train 1.5633606425675883 MAE test 2.3840898579022527\n",
      "Epoch 7355 / 10000 loss: 12.79619312286377\n",
      "MSE train 5.167364105327242 MSE test 11.614249037514268\n",
      "MAE train 1.563344121965972 MAE test 2.3840527217745153\n",
      "Epoch 7356 / 10000 loss: 12.795705080032349\n",
      "MSE train 5.167248201932465 MSE test 11.614260393598293\n",
      "MAE train 1.5633211147568942 MAE test 2.3840600719859246\n",
      "Epoch 7357 / 10000 loss: 12.795346975326538\n",
      "MSE train 5.167130436237932 MSE test 11.613978997161935\n",
      "MAE train 1.5633043868921677 MAE test 2.38402381149282\n",
      "Epoch 7358 / 10000 loss: 12.794852018356323\n",
      "MSE train 5.167017532274663 MSE test 11.61398674713991\n",
      "MAE train 1.5632822034548892 MAE test 2.3840306819944903\n",
      "Epoch 7359 / 10000 loss: 12.794488191604614\n",
      "MSE train 5.166900163998422 MSE test 11.6136924285315\n",
      "MAE train 1.5632658188712403 MAE test 2.3839927043525635\n",
      "Epoch 7360 / 10000 loss: 12.794006824493408\n",
      "MSE train 5.166781230632148 MSE test 11.613705930514477\n",
      "MAE train 1.5632420114341963 MAE test 2.384000372721133\n",
      "Epoch 7361 / 10000 loss: 12.7936532497406\n",
      "MSE train 5.166662936519597 MSE test 11.613437136641673\n",
      "MAE train 1.5632248932092319 MAE test 2.383965801555391\n",
      "Epoch 7362 / 10000 loss: 12.793143510818481\n",
      "MSE train 5.166554617145211 MSE test 11.613436448481064\n",
      "MAE train 1.563204079515162 MAE test 2.3839715491457816\n",
      "Epoch 7363 / 10000 loss: 12.792768239974976\n",
      "MSE train 5.166437833843068 MSE test 11.613124692173558\n",
      "MAE train 1.563188181426125 MAE test 2.3839312300466546\n",
      "Epoch 7364 / 10000 loss: 12.792309761047363\n",
      "MSE train 5.166310428103456 MSE test 11.613142812871846\n",
      "MAE train 1.5631621026323164 MAE test 2.38393954901289\n",
      "Epoch 7365 / 10000 loss: 12.791973114013672\n",
      "MSE train 5.16619308020668 MSE test 11.612916398363897\n",
      "MAE train 1.563144395608943 MAE test 2.3839106421421046\n",
      "Epoch 7366 / 10000 loss: 12.791428327560425\n",
      "MSE train 5.166082041299884 MSE test 11.61286912217404\n",
      "MAE train 1.5631237973243997 MAE test 2.3839101486714056\n",
      "Epoch 7367 / 10000 loss: 12.79102349281311\n",
      "MSE train 5.165965114151179 MSE test 11.612596017637612\n",
      "MAE train 1.5631071334580384 MAE test 2.383875030866208\n",
      "Epoch 7368 / 10000 loss: 12.790587425231934\n",
      "MSE train 5.165853811272079 MSE test 11.612601480143553\n",
      "MAE train 1.5630854531305618 MAE test 2.3838816137199825\n",
      "Epoch 7369 / 10000 loss: 12.790218353271484\n",
      "MSE train 5.165736768997591 MSE test 11.61229704383399\n",
      "MAE train 1.5630693699406202 MAE test 2.383842288982499\n",
      "Epoch 7370 / 10000 loss: 12.7897469997406\n",
      "MSE train 5.165612426020062 MSE test 11.612313037995765\n",
      "MAE train 1.5630441680673444 MAE test 2.3838503379699585\n",
      "Epoch 7371 / 10000 loss: 12.789401292800903\n",
      "MSE train 5.165493809095987 MSE test 11.612067418192117\n",
      "MAE train 1.5630265308886122 MAE test 2.38381886235142\n",
      "Epoch 7372 / 10000 loss: 12.788869857788086\n",
      "MSE train 5.165387024960262 MSE test 11.612043475396115\n",
      "MAE train 1.563006548847436 MAE test 2.3838215088926225\n",
      "Epoch 7373 / 10000 loss: 12.788474082946777\n",
      "MSE train 5.165270419165884 MSE test 11.611734019984747\n",
      "MAE train 1.562990685461723 MAE test 2.383781522851154\n",
      "Epoch 7374 / 10000 loss: 12.788038492202759\n",
      "MSE train 5.165143250162922 MSE test 11.611751222170467\n",
      "MAE train 1.5629647158172804 MAE test 2.3837897490260094\n",
      "Epoch 7375 / 10000 loss: 12.787698984146118\n",
      "MSE train 5.16502509193662 MSE test 11.611518990963981\n",
      "MAE train 1.5629469467298047 MAE test 2.3837600733147744\n",
      "Epoch 7376 / 10000 loss: 12.787154912948608\n",
      "MSE train 5.16491511681502 MSE test 11.611477653591923\n",
      "MAE train 1.5629265173703268 MAE test 2.3837603954154947\n",
      "Epoch 7377 / 10000 loss: 12.78675103187561\n",
      "MSE train 5.164798023114317 MSE test 11.611191114692662\n",
      "MAE train 1.5629100991967282 MAE test 2.3837234874692776\n",
      "Epoch 7378 / 10000 loss: 12.786314010620117\n",
      "MSE train 5.164681087714397 MSE test 11.6112012885199\n",
      "MAE train 1.5628869110983696 MAE test 2.3837307427001697\n",
      "Epoch 7379 / 10000 loss: 12.785953998565674\n",
      "MSE train 5.164562632688498 MSE test 11.610915992996658\n",
      "MAE train 1.5628701364663076 MAE test 2.3836940062421794\n",
      "Epoch 7380 / 10000 loss: 12.785454750061035\n",
      "MSE train 5.164447641971387 MSE test 11.610922509062519\n",
      "MAE train 1.5628474899790699 MAE test 2.383700767573803\n",
      "Epoch 7381 / 10000 loss: 12.785089254379272\n",
      "MSE train 5.164329074092011 MSE test 11.610629286047622\n",
      "MAE train 1.5628308428845854 MAE test 2.3836629757933947\n",
      "Epoch 7382 / 10000 loss: 12.784599304199219\n",
      "MSE train 5.164210690046411 MSE test 11.610638617012583\n",
      "MAE train 1.562807291262191 MAE test 2.383670133828054\n",
      "Epoch 7383 / 10000 loss: 12.78423810005188\n",
      "MSE train 5.1640913553711165 MSE test 11.610359182731273\n",
      "MAE train 1.5627901978121566 MAE test 2.3836341714330063\n",
      "Epoch 7384 / 10000 loss: 12.783732891082764\n",
      "MSE train 5.1639791783239195 MSE test 11.610360588403513\n",
      "MAE train 1.5627683805126278 MAE test 2.383640259305418\n",
      "Epoch 7385 / 10000 loss: 12.783358573913574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.163860625696845 MSE test 11.61005501909764\n",
      "MAE train 1.56275199447736 MAE test 2.3836008020453314\n",
      "Epoch 7386 / 10000 loss: 12.782881498336792\n",
      "MSE train 5.163736225005965 MSE test 11.610067551828172\n",
      "MAE train 1.5627268733202575 MAE test 2.3836084243945814\n",
      "Epoch 7387 / 10000 loss: 12.782531023025513\n",
      "MSE train 5.16361631428929 MSE test 11.609814753189772\n",
      "MAE train 1.5627091177338894 MAE test 2.383576031556786\n",
      "Epoch 7388 / 10000 loss: 12.781999111175537\n",
      "MSE train 5.1635087788447915 MSE test 11.609793084009684\n",
      "MAE train 1.5626889418140573 MAE test 2.383579024974841\n",
      "Epoch 7389 / 10000 loss: 12.781602144241333\n",
      "MSE train 5.163390869560571 MSE test 11.609476827014856\n",
      "MAE train 1.5626729457204471 MAE test 2.3835381281780257\n",
      "Epoch 7390 / 10000 loss: 12.7811598777771\n",
      "MSE train 5.163260691536523 MSE test 11.609491763585044\n",
      "MAE train 1.562646275789078 MAE test 2.3835461171866505\n",
      "Epoch 7391 / 10000 loss: 12.780818939208984\n",
      "MSE train 5.16314209346315 MSE test 11.609266988545826\n",
      "MAE train 1.5626283155400718 MAE test 2.383517471900607\n",
      "Epoch 7392 / 10000 loss: 12.78026270866394\n",
      "MSE train 5.163027200793383 MSE test 11.609208040967735\n",
      "MAE train 1.5626070690926497 MAE test 2.38351547750988\n",
      "Epoch 7393 / 10000 loss: 12.779850721359253\n",
      "MSE train 5.162908120162241 MSE test 11.608945158839015\n",
      "MAE train 1.5625897504466624 MAE test 2.3834817787339087\n",
      "Epoch 7394 / 10000 loss: 12.779404401779175\n",
      "MSE train 5.162798688552264 MSE test 11.608936969771152\n",
      "MAE train 1.5625689113873038 MAE test 2.3834866209809173\n",
      "Epoch 7395 / 10000 loss: 12.779016256332397\n",
      "MSE train 5.16268021277579 MSE test 11.608616139200329\n",
      "MAE train 1.5625529018240543 MAE test 2.3834451450275265\n",
      "Epoch 7396 / 10000 loss: 12.778558254241943\n",
      "MSE train 5.162547982221911 MSE test 11.60863038357611\n",
      "MAE train 1.5625257268441133 MAE test 2.3834530756910506\n",
      "Epoch 7397 / 10000 loss: 12.778217792510986\n",
      "MSE train 5.162429572543999 MSE test 11.608412860019184\n",
      "MAE train 1.5625077437006465 MAE test 2.3834254319120487\n",
      "Epoch 7398 / 10000 loss: 12.777653694152832\n",
      "MSE train 5.162310708733264 MSE test 11.608338983470194\n",
      "MAE train 1.5624857638709462 MAE test 2.3834214812960255\n",
      "Epoch 7399 / 10000 loss: 12.777235984802246\n",
      "MSE train 5.162191003520591 MSE test 11.608100293923789\n",
      "MAE train 1.562467884147312 MAE test 2.3833910350698484\n",
      "Epoch 7400 / 10000 loss: 12.776781797409058\n",
      "MSE train 5.162080369745886 MSE test 11.608065995954512\n",
      "MAE train 1.5624472650750079 MAE test 2.3833924042275414\n",
      "Epoch 7401 / 10000 loss: 12.776374578475952\n",
      "MSE train 5.161961412529415 MSE test 11.60775998077313\n",
      "MAE train 1.562430886588175 MAE test 2.3833529721631415\n",
      "Epoch 7402 / 10000 loss: 12.775930166244507\n",
      "MSE train 5.161834379287753 MSE test 11.607770727998764\n",
      "MAE train 1.562405254103387 MAE test 2.383360428494561\n",
      "Epoch 7403 / 10000 loss: 12.775572776794434\n",
      "MSE train 5.161712506376313 MSE test 11.607515465331563\n",
      "MAE train 1.5623871695340188 MAE test 2.3833277665681756\n",
      "Epoch 7404 / 10000 loss: 12.775030612945557\n",
      "MSE train 5.161602652895263 MSE test 11.607489865960009\n",
      "MAE train 1.5623665927334471 MAE test 2.383330315941443\n",
      "Epoch 7405 / 10000 loss: 12.774625539779663\n",
      "MSE train 5.161482396360556 MSE test 11.607169877213934\n",
      "MAE train 1.562350213440993 MAE test 2.383289008582412\n",
      "Epoch 7406 / 10000 loss: 12.774174690246582\n",
      "MSE train 5.161349628169025 MSE test 11.607180847713183\n",
      "MAE train 1.5623230876849359 MAE test 2.383296539131025\n",
      "Epoch 7407 / 10000 loss: 12.773824214935303\n",
      "MSE train 5.16122830522973 MSE test 11.606952087910157\n",
      "MAE train 1.5623046744935718 MAE test 2.383267434008409\n",
      "Epoch 7408 / 10000 loss: 12.77325701713562\n",
      "MSE train 5.161110495671628 MSE test 11.606888390492182\n",
      "MAE train 1.5622829432503085 MAE test 2.383264880882619\n",
      "Epoch 7409 / 10000 loss: 12.772833824157715\n",
      "MSE train 5.160988326159491 MSE test 11.606621659874985\n",
      "MAE train 1.5622650987199476 MAE test 2.3832307227994733\n",
      "Epoch 7410 / 10000 loss: 12.77237606048584\n",
      "MSE train 5.160875730602883 MSE test 11.606608200529376\n",
      "MAE train 1.5622437536197935 MAE test 2.3832349260859647\n",
      "Epoch 7411 / 10000 loss: 12.771975040435791\n",
      "MSE train 5.160753736791044 MSE test 11.606282429679336\n",
      "MAE train 1.5622271629629034 MAE test 2.3831928655632235\n",
      "Epoch 7412 / 10000 loss: 12.771504402160645\n",
      "MSE train 5.160617667191251 MSE test 11.606291639703217\n",
      "MAE train 1.562199339334016 MAE test 2.3832001742356868\n",
      "Epoch 7413 / 10000 loss: 12.771150350570679\n",
      "MSE train 5.1604953136575915 MSE test 11.606069435540164\n",
      "MAE train 1.5621806908886564 MAE test 2.3831719756592165\n",
      "Epoch 7414 / 10000 loss: 12.770570039749146\n",
      "MSE train 5.160371881914702 MSE test 11.60598913707044\n",
      "MAE train 1.5621579576657385 MAE test 2.383167206124855\n",
      "Epoch 7415 / 10000 loss: 12.770136594772339\n",
      "MSE train 5.1602474672706204 MSE test 11.605746411459817\n",
      "MAE train 1.5621392593984817 MAE test 2.38313626498665\n",
      "Epoch 7416 / 10000 loss: 12.769664287567139\n",
      "MSE train 5.160131338835403 MSE test 11.605704233994695\n",
      "MAE train 1.5621177365046957 MAE test 2.383136607372177\n",
      "Epoch 7417 / 10000 loss: 12.769236087799072\n",
      "MSE train 5.160006662431519 MSE test 11.605394875384023\n",
      "MAE train 1.562100342115474 MAE test 2.3830967487874033\n",
      "Epoch 7418 / 10000 loss: 12.768768548965454\n",
      "MSE train 5.159874564281658 MSE test 11.605398144188372\n",
      "MAE train 1.5620740003551579 MAE test 2.3831032406711423\n",
      "Epoch 7419 / 10000 loss: 12.768387079238892\n",
      "MSE train 5.159745710713793 MSE test 11.605129807537045\n",
      "MAE train 1.5620548514836181 MAE test 2.3830688644757503\n",
      "Epoch 7420 / 10000 loss: 12.767823219299316\n",
      "MSE train 5.159628116735356 MSE test 11.605103109454967\n",
      "MAE train 1.562032889600344 MAE test 2.3830712785026815\n",
      "Epoch 7421 / 10000 loss: 12.767393112182617\n",
      "MSE train 5.159499062330896 MSE test 11.604772393091613\n",
      "MAE train 1.5620150614260442 MAE test 2.383028539949727\n",
      "Epoch 7422 / 10000 loss: 12.766904830932617\n",
      "MSE train 5.159355563503041 MSE test 11.604775341484137\n",
      "MAE train 1.5619860340409506 MAE test 2.383035006208822\n",
      "Epoch 7423 / 10000 loss: 12.766518354415894\n",
      "MSE train 5.159224019733104 MSE test 11.604545145642456\n",
      "MAE train 1.5619658293529053 MAE test 2.383005734705433\n",
      "Epoch 7424 / 10000 loss: 12.76590609550476\n",
      "MSE train 5.159090971765345 MSE test 11.604460897566122\n",
      "MAE train 1.5619414777185363 MAE test 2.38300038644834\n",
      "Epoch 7425 / 10000 loss: 12.765433549880981\n",
      "MSE train 5.1589544586674405 MSE test 11.60420561701867\n",
      "MAE train 1.5619207895177367 MAE test 2.3829677375991403\n",
      "Epoch 7426 / 10000 loss: 12.764917135238647\n",
      "MSE train 5.1588252579649545 MSE test 11.604161864598998\n",
      "MAE train 1.5618969913174818 MAE test 2.382967812733239\n",
      "Epoch 7427 / 10000 loss: 12.764438152313232\n",
      "MSE train 5.158683934328766 MSE test 11.603835620642402\n",
      "MAE train 1.5618769009068718 MAE test 2.3829256280063182\n",
      "Epoch 7428 / 10000 loss: 12.763908386230469\n",
      "MSE train 5.158528133772335 MSE test 11.603831613709291\n",
      "MAE train 1.5618461059021669 MAE test 2.3829310644921646\n",
      "Epoch 7429 / 10000 loss: 12.763457775115967\n",
      "MSE train 5.1583753651071245 MSE test 11.603573082221219\n",
      "MAE train 1.5618224815945203 MAE test 2.3828978837661823\n",
      "Epoch 7430 / 10000 loss: 12.762787818908691\n",
      "MSE train 5.158225686031522 MSE test 11.603513025034461\n",
      "MAE train 1.5617952405832125 MAE test 2.382895681830864\n",
      "Epoch 7431 / 10000 loss: 12.762234449386597\n",
      "MSE train 5.1580594444883205 MSE test 11.60319215128884\n",
      "MAE train 1.5617705816982657 MAE test 2.382854114559337\n",
      "Epoch 7432 / 10000 loss: 12.761614799499512\n",
      "MSE train 5.157878679019734 MSE test 11.60317719777748\n",
      "MAE train 1.5617360974492207 MAE test 2.3828579280849094\n",
      "Epoch 7433 / 10000 loss: 12.761039733886719\n",
      "MSE train 5.157687299483328 MSE test 11.602881169319557\n",
      "MAE train 1.5617064010847261 MAE test 2.3828196056606683\n",
      "Epoch 7434 / 10000 loss: 12.760250568389893\n",
      "MSE train 5.157493972719486 MSE test 11.602843247596185\n",
      "MAE train 1.5616712276025106 MAE test 2.3828202517651476\n",
      "Epoch 7435 / 10000 loss: 12.759535789489746\n",
      "MSE train 5.157283317537878 MSE test 11.60249416732164\n",
      "MAE train 1.561639241329131 MAE test 2.3827747524005147\n",
      "Epoch 7436 / 10000 loss: 12.758687019348145\n",
      "MSE train 5.157064133442906 MSE test 11.602476846970353\n",
      "MAE train 1.5615974588867403 MAE test 2.382778100170156\n",
      "Epoch 7437 / 10000 loss: 12.757912874221802\n",
      "MSE train 5.156872549624178 MSE test 11.602223657800266\n",
      "MAE train 1.5615673427038057 MAE test 2.3827451629272245\n",
      "Epoch 7438 / 10000 loss: 12.756937980651855\n",
      "MSE train 5.1567037443776105 MSE test 11.602133319351646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5615370602694985 MAE test 2.382738228576205\n",
      "Epoch 7439 / 10000 loss: 12.756179332733154\n",
      "MSE train 5.156546676097992 MSE test 11.601850034111878\n",
      "MAE train 1.561513189313548 MAE test 2.382700923558256\n",
      "Epoch 7440 / 10000 loss: 12.755481481552124\n",
      "MSE train 5.156409746136672 MSE test 11.601812723588088\n",
      "MAE train 1.5614876269076732 MAE test 2.3827008844658217\n",
      "Epoch 7441 / 10000 loss: 12.754914045333862\n",
      "MSE train 5.156268811262421 MSE test 11.601468011000277\n",
      "MAE train 1.561467590107016 MAE test 2.3826551524408703\n",
      "Epoch 7442 / 10000 loss: 12.754335403442383\n",
      "MSE train 5.156116742313145 MSE test 11.601459394460464\n",
      "MAE train 1.5614368483527623 MAE test 2.3826590022957803\n",
      "Epoch 7443 / 10000 loss: 12.753895282745361\n",
      "MSE train 5.155981385841707 MSE test 11.601222460885019\n",
      "MAE train 1.561415781949607 MAE test 2.3826277250714334\n",
      "Epoch 7444 / 10000 loss: 12.753246068954468\n",
      "MSE train 5.155845368162571 MSE test 11.601121557260615\n",
      "MAE train 1.5613906690946107 MAE test 2.3826191503213234\n",
      "Epoch 7445 / 10000 loss: 12.752754211425781\n",
      "MSE train 5.155710530439455 MSE test 11.600869075288252\n",
      "MAE train 1.561369822358393 MAE test 2.3825859121539046\n",
      "Epoch 7446 / 10000 loss: 12.75223183631897\n",
      "MSE train 5.155582655109842 MSE test 11.600801837371135\n",
      "MAE train 1.561346082242345 MAE test 2.382581957884309\n",
      "Epoch 7447 / 10000 loss: 12.751755475997925\n",
      "MSE train 5.155448397193734 MSE test 11.60049012044104\n",
      "MAE train 1.561326493332967 MAE test 2.3825408845081784\n",
      "Epoch 7448 / 10000 loss: 12.751246929168701\n",
      "MSE train 5.155313992878445 MSE test 11.600472237838318\n",
      "MAE train 1.5613000770814 MAE test 2.3825437042021247\n",
      "Epoch 7449 / 10000 loss: 12.75081467628479\n",
      "MSE train 5.155177851979726 MSE test 11.600157952321853\n",
      "MAE train 1.5612801003446297 MAE test 2.382502393782009\n",
      "Epoch 7450 / 10000 loss: 12.750245094299316\n",
      "MSE train 5.1550442439956985 MSE test 11.600135860484624\n",
      "MAE train 1.561253973491132 MAE test 2.3825047389292453\n",
      "Epoch 7451 / 10000 loss: 12.749808549880981\n",
      "MSE train 5.154907250982051 MSE test 11.599815769403044\n",
      "MAE train 1.5612339297788225 MAE test 2.3824626893480088\n",
      "Epoch 7452 / 10000 loss: 12.749243021011353\n",
      "MSE train 5.154771404162341 MSE test 11.599792964182239\n",
      "MAE train 1.5612072988931427 MAE test 2.3824649657844867\n",
      "Epoch 7453 / 10000 loss: 12.748806715011597\n",
      "MSE train 5.1546332614802415 MSE test 11.599477721755768\n",
      "MAE train 1.5611869605913615 MAE test 2.3824235458850715\n",
      "Epoch 7454 / 10000 loss: 12.748231887817383\n",
      "MSE train 5.15449963813494 MSE test 11.599449090823793\n",
      "MAE train 1.5611610811125385 MAE test 2.382424968066106\n",
      "Epoch 7455 / 10000 loss: 12.747786521911621\n",
      "MSE train 5.1543608906795555 MSE test 11.599118153581799\n",
      "MAE train 1.5611409353604115 MAE test 2.3823813737291264\n",
      "Epoch 7456 / 10000 loss: 12.747222900390625\n",
      "MSE train 5.1542199899404535 MSE test 11.599092858645426\n",
      "MAE train 1.5611131945230945 MAE test 2.382383169019536\n",
      "Epoch 7457 / 10000 loss: 12.746785402297974\n",
      "MSE train 5.154079128026391 MSE test 11.598785374620556\n",
      "MAE train 1.5610920828253299 MAE test 2.382342595167727\n",
      "Epoch 7458 / 10000 loss: 12.746190309524536\n",
      "MSE train 5.15394755939967 MSE test 11.598742232199326\n",
      "MAE train 1.5610671701277279 MAE test 2.382341812608521\n",
      "Epoch 7459 / 10000 loss: 12.745725154876709\n",
      "MSE train 5.153806279204047 MSE test 11.598387860971163\n",
      "MAE train 1.5610469931318427 MAE test 2.382294740857172\n",
      "Epoch 7460 / 10000 loss: 12.745176315307617\n",
      "MSE train 5.153653275298956 MSE test 11.598360165419699\n",
      "MAE train 1.5610163861092825 MAE test 2.3822958931573526\n",
      "Epoch 7461 / 10000 loss: 12.744744300842285\n",
      "MSE train 5.1535088420804165 MSE test 11.598087310258354\n",
      "MAE train 1.5609939150698142 MAE test 2.382259578721591\n",
      "Epoch 7462 / 10000 loss: 12.744098901748657\n",
      "MSE train 5.153368769821639 MSE test 11.59798908022709\n",
      "MAE train 1.5609682405524918 MAE test 2.382250926593583\n",
      "Epoch 7463 / 10000 loss: 12.743589162826538\n",
      "MSE train 5.153220706299538 MSE test 11.597665224503931\n",
      "MAE train 1.56094609678358 MAE test 2.3822075141257413\n",
      "Epoch 7464 / 10000 loss: 12.74303913116455\n",
      "MSE train 5.153076223432388 MSE test 11.597613447557691\n",
      "MAE train 1.560918642517162 MAE test 2.382204866411695\n",
      "Epoch 7465 / 10000 loss: 12.742547035217285\n",
      "MSE train 5.152922653710934 MSE test 11.597249547612691\n",
      "MAE train 1.560896160419508 MAE test 2.382155763689332\n",
      "Epoch 7466 / 10000 loss: 12.741945028305054\n",
      "MSE train 5.152757997482417 MSE test 11.597202794975326\n",
      "MAE train 1.5608638218662623 MAE test 2.382153492783083\n",
      "Epoch 7467 / 10000 loss: 12.74145770072937\n",
      "MSE train 5.152596150193134 MSE test 11.596895557334978\n",
      "MAE train 1.5608385070335369 MAE test 2.382111658284129\n",
      "Epoch 7468 / 10000 loss: 12.740764617919922\n",
      "MSE train 5.152442195957042 MSE test 11.596798280639101\n",
      "MAE train 1.5608102668352235 MAE test 2.3821021992951534\n",
      "Epoch 7469 / 10000 loss: 12.740195035934448\n",
      "MSE train 5.152275918516688 MSE test 11.596423369229928\n",
      "MAE train 1.5607854735699924 MAE test 2.382051016546854\n",
      "Epoch 7470 / 10000 loss: 12.739571332931519\n",
      "MSE train 5.152099330024147 MSE test 11.596366379397733\n",
      "MAE train 1.560750970548579 MAE test 2.382046841586415\n",
      "Epoch 7471 / 10000 loss: 12.739028453826904\n",
      "MSE train 5.1519288790675075 MSE test 11.596051728653237\n",
      "MAE train 1.5607240897964159 MAE test 2.382003574366823\n",
      "Epoch 7472 / 10000 loss: 12.738285303115845\n",
      "MSE train 5.151771514709816 MSE test 11.595953918227904\n",
      "MAE train 1.5606952262302052 MAE test 2.3819938059827326\n",
      "Epoch 7473 / 10000 loss: 12.737679243087769\n",
      "MSE train 5.151608662818315 MSE test 11.595583217759158\n",
      "MAE train 1.560670965595483 MAE test 2.3819431091030974\n",
      "Epoch 7474 / 10000 loss: 12.737040281295776\n",
      "MSE train 5.151442491282185 MSE test 11.595538923420836\n",
      "MAE train 1.560638203519647 MAE test 2.3819407713965735\n",
      "Epoch 7475 / 10000 loss: 12.736512422561646\n",
      "MSE train 5.151290229964522 MSE test 11.595247615944265\n",
      "MAE train 1.5606144117215468 MAE test 2.381901108302022\n",
      "Epoch 7476 / 10000 loss: 12.735812187194824\n",
      "MSE train 5.1511554921059375 MSE test 11.595171996186966\n",
      "MAE train 1.5605894804430012 MAE test 2.3818949817487334\n",
      "Epoch 7477 / 10000 loss: 12.735278367996216\n",
      "MSE train 5.15101831300319 MSE test 11.594835756759032\n",
      "MAE train 1.5605697740505948 MAE test 2.381849839380828\n",
      "Epoch 7478 / 10000 loss: 12.734735488891602\n",
      "MSE train 5.150879562707719 MSE test 11.594821333907671\n",
      "MAE train 1.5605421080822315 MAE test 2.381852483639885\n",
      "Epoch 7479 / 10000 loss: 12.734307289123535\n",
      "MSE train 5.150750195713592 MSE test 11.594549919422459\n",
      "MAE train 1.5605226299689077 MAE test 2.381816474253469\n",
      "Epoch 7480 / 10000 loss: 12.7337167263031\n",
      "MSE train 5.150636405135433 MSE test 11.59451396912726\n",
      "MAE train 1.5605013420476836 MAE test 2.3818165282700843\n",
      "Epoch 7481 / 10000 loss: 12.733281373977661\n",
      "MSE train 5.150515366038069 MSE test 11.594190122973536\n",
      "MAE train 1.5604847181149366 MAE test 2.381773800897343\n",
      "Epoch 7482 / 10000 loss: 12.732810258865356\n",
      "MSE train 5.150383984143008 MSE test 11.594199109163005\n",
      "MAE train 1.5604577876487131 MAE test 2.3817802442267215\n",
      "Epoch 7483 / 10000 loss: 12.732454299926758\n",
      "MSE train 5.150265939282171 MSE test 11.59397510117426\n",
      "MAE train 1.5604398028134587 MAE test 2.3817511463457195\n",
      "Epoch 7484 / 10000 loss: 12.731889009475708\n",
      "MSE train 5.150152642098991 MSE test 11.593916076969357\n",
      "MAE train 1.560418720562475 MAE test 2.3817485216967085\n",
      "Epoch 7485 / 10000 loss: 12.731472492218018\n",
      "MSE train 5.150036322688944 MSE test 11.593660442949567\n",
      "MAE train 1.5604017194235555 MAE test 2.3817153302275362\n",
      "Epoch 7486 / 10000 loss: 12.731027841567993\n",
      "MSE train 5.14993059170446 MSE test 11.59365599036166\n",
      "MAE train 1.5603814574248178 MAE test 2.381720156633782\n",
      "Epoch 7487 / 10000 loss: 12.730643510818481\n",
      "MSE train 5.149816333712927 MSE test 11.59334458480294\n",
      "MAE train 1.560366000211865 MAE test 2.381679590462943\n",
      "Epoch 7488 / 10000 loss: 12.730194568634033\n",
      "MSE train 5.149688648329277 MSE test 11.593367068183879\n",
      "MAE train 1.5603394912149091 MAE test 2.381688204077609\n",
      "Epoch 7489 / 10000 loss: 12.729864358901978\n",
      "MSE train 5.14957553659439 MSE test 11.593162950344139\n",
      "MAE train 1.560322245478227 MAE test 2.381662067223262\n",
      "Epoch 7490 / 10000 loss: 12.729310035705566\n",
      "MSE train 5.149461846021847 MSE test 11.593098324495166\n",
      "MAE train 1.560301002400923 MAE test 2.381658940113462\n",
      "Epoch 7491 / 10000 loss: 12.728906154632568\n",
      "MSE train 5.149348085549299 MSE test 11.59287728654062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5602839054643525 MAE test 2.3816305862572555\n",
      "Epoch 7492 / 10000 loss: 12.728466510772705\n",
      "MSE train 5.149242871291193 MSE test 11.592851836020635\n",
      "MAE train 1.560264102815706 MAE test 2.381632740445229\n",
      "Epoch 7493 / 10000 loss: 12.728073835372925\n",
      "MSE train 5.149130158792071 MSE test 11.59256800830151\n",
      "MAE train 1.5602484640979906 MAE test 2.3815960115094943\n",
      "Epoch 7494 / 10000 loss: 12.727644681930542\n",
      "MSE train 5.149012614816692 MSE test 11.592590980525824\n",
      "MAE train 1.5602245871134026 MAE test 2.3816047193397285\n",
      "Epoch 7495 / 10000 loss: 12.727301120758057\n",
      "MSE train 5.148897685484887 MSE test 11.59233994216829\n",
      "MAE train 1.5602077475517566 MAE test 2.3815723963738202\n",
      "Epoch 7496 / 10000 loss: 12.7267906665802\n",
      "MSE train 5.148794171746192 MSE test 11.592342473183333\n",
      "MAE train 1.5601878127276427 MAE test 2.3815783223680045\n",
      "Epoch 7497 / 10000 loss: 12.726415395736694\n",
      "MSE train 5.148680901775466 MSE test 11.59203860969094\n",
      "MAE train 1.5601724191475859 MAE test 2.3815389329002166\n",
      "Epoch 7498 / 10000 loss: 12.725973844528198\n",
      "MSE train 5.148555360664298 MSE test 11.5920658390948\n",
      "MAE train 1.5601463318819848 MAE test 2.3815482537891737\n",
      "Epoch 7499 / 10000 loss: 12.725646495819092\n",
      "MSE train 5.148442594240559 MSE test 11.591861771380279\n",
      "MAE train 1.560129150414765 MAE test 2.3815222441201342\n",
      "Epoch 7500 / 10000 loss: 12.725101232528687\n",
      "MSE train 5.148331465700012 MSE test 11.591808357084675\n",
      "MAE train 1.560108357512512 MAE test 2.3815206559081434\n",
      "Epoch 7501 / 10000 loss: 12.72470211982727\n",
      "MSE train 5.1482179739713105 MSE test 11.59157663707699\n",
      "MAE train 1.5600915281332932 MAE test 2.3814909456723763\n",
      "Epoch 7502 / 10000 loss: 12.724268913269043\n",
      "MSE train 5.148115445761783 MSE test 11.59156951548254\n",
      "MAE train 1.5600720383466087 MAE test 2.3814955718952815\n",
      "Epoch 7503 / 10000 loss: 12.723885536193848\n",
      "MSE train 5.148003139774475 MSE test 11.591269299414446\n",
      "MAE train 1.560056834456455 MAE test 2.3814566780565025\n",
      "Epoch 7504 / 10000 loss: 12.723456859588623\n",
      "MSE train 5.147877863128096 MSE test 11.591298207049764\n",
      "MAE train 1.5600307986906468 MAE test 2.3814662323846\n",
      "Epoch 7505 / 10000 loss: 12.72313117980957\n",
      "MSE train 5.14776504612198 MSE test 11.59109338097707\n",
      "MAE train 1.5600136178629176 MAE test 2.381440111936277\n",
      "Epoch 7506 / 10000 loss: 12.72258734703064\n",
      "MSE train 5.147654772077176 MSE test 11.591043904966595\n",
      "MAE train 1.5599929851923064 MAE test 2.381439052098057\n",
      "Epoch 7507 / 10000 loss: 12.722189903259277\n",
      "MSE train 5.147541313511013 MSE test 11.590807199121688\n",
      "MAE train 1.559976267368253 MAE test 2.3814086609324034\n",
      "Epoch 7508 / 10000 loss: 12.721757650375366\n",
      "MSE train 5.147438907581311 MSE test 11.590806062067715\n",
      "MAE train 1.559956705817528 MAE test 2.381414082737358\n",
      "Epoch 7509 / 10000 loss: 12.721378803253174\n",
      "MSE train 5.147326512448362 MSE test 11.590503344199718\n",
      "MAE train 1.559941547768685 MAE test 2.3813748396935135\n",
      "Epoch 7510 / 10000 loss: 12.720947504043579\n",
      "MSE train 5.147200343801998 MSE test 11.590532840344876\n",
      "MAE train 1.559915237763026 MAE test 2.3813844542729776\n",
      "Epoch 7511 / 10000 loss: 12.72062349319458\n",
      "MSE train 5.1470883845470325 MSE test 11.590335507610359\n",
      "MAE train 1.5598981687736542 MAE test 2.3813593313034125\n",
      "Epoch 7512 / 10000 loss: 12.720076560974121\n",
      "MSE train 5.1469755472458525 MSE test 11.590274821436639\n",
      "MAE train 1.5598770477746957 MAE test 2.3813567555991138\n",
      "Epoch 7513 / 10000 loss: 12.719676971435547\n",
      "MSE train 5.146862600941744 MSE test 11.590060135305267\n",
      "MAE train 1.5598600595907146 MAE test 2.3813293124489374\n",
      "Epoch 7514 / 10000 loss: 12.719242572784424\n",
      "MSE train 5.146757730072303 MSE test 11.590036069840867\n",
      "MAE train 1.5598403085679873 MAE test 2.381331625082661\n",
      "Epoch 7515 / 10000 loss: 12.718851804733276\n",
      "MSE train 5.146645410200903 MSE test 11.589759231609307\n",
      "MAE train 1.5598246864585807 MAE test 2.3812958567778786\n",
      "Epoch 7516 / 10000 loss: 12.718425512313843\n",
      "MSE train 5.146529932947563 MSE test 11.589784064652813\n",
      "MAE train 1.5598012794232154 MAE test 2.3813047913543306\n",
      "Epoch 7517 / 10000 loss: 12.718082427978516\n",
      "MSE train 5.146415527712093 MSE test 11.589528553216518\n",
      "MAE train 1.5597847043955213 MAE test 2.3812718671518645\n",
      "Epoch 7518 / 10000 loss: 12.717580080032349\n",
      "MSE train 5.1463106144481525 MSE test 11.589538728068879\n",
      "MAE train 1.559764259482671 MAE test 2.3812787782511906\n",
      "Epoch 7519 / 10000 loss: 12.717212915420532\n",
      "MSE train 5.146197402911768 MSE test 11.589241966385169\n",
      "MAE train 1.559748777403175 MAE test 2.381240315370148\n",
      "Epoch 7520 / 10000 loss: 12.716761827468872\n",
      "MSE train 5.146074401083645 MSE test 11.589269905230188\n",
      "MAE train 1.5597233453678587 MAE test 2.381249683717007\n",
      "Epoch 7521 / 10000 loss: 12.716431379318237\n",
      "MSE train 5.145960603999185 MSE test 11.589054573719544\n",
      "MAE train 1.5597061164550412 MAE test 2.381222130870334\n",
      "Epoch 7522 / 10000 loss: 12.715897560119629\n",
      "MSE train 5.145854425146365 MSE test 11.589021759083293\n",
      "MAE train 1.55968617769948 MAE test 2.3812232426239084\n",
      "Epoch 7523 / 10000 loss: 12.715502738952637\n",
      "MSE train 5.145741460974042 MSE test 11.58875629345399\n",
      "MAE train 1.559670183465643 MAE test 2.3811889779955315\n",
      "Epoch 7524 / 10000 loss: 12.715075731277466\n",
      "MSE train 5.145631677422625 MSE test 11.58877568270968\n",
      "MAE train 1.5596482929219564 MAE test 2.381197137203955\n",
      "Epoch 7525 / 10000 loss: 12.714720487594604\n",
      "MSE train 5.145518008892354 MSE test 11.588496318903598\n",
      "MAE train 1.5596323842782127 MAE test 2.381161004773982\n",
      "Epoch 7526 / 10000 loss: 12.714245080947876\n",
      "MSE train 5.145403227558093 MSE test 11.588519597316864\n",
      "MAE train 1.5596091359379667 MAE test 2.381169701445805\n",
      "Epoch 7527 / 10000 loss: 12.713898420333862\n",
      "MSE train 5.145288546757707 MSE test 11.588263283115653\n",
      "MAE train 1.5595925189492434 MAE test 2.3811366389448425\n",
      "Epoch 7528 / 10000 loss: 12.713399410247803\n",
      "MSE train 5.145183681266414 MSE test 11.588273546567168\n",
      "MAE train 1.5595720533053443 MAE test 2.381143531527621\n",
      "Epoch 7529 / 10000 loss: 12.713031530380249\n",
      "MSE train 5.145070419521465 MSE test 11.587977752388372\n",
      "MAE train 1.559556553910795 MAE test 2.3811051807950157\n",
      "Epoch 7530 / 10000 loss: 12.712578773498535\n",
      "MSE train 5.14494788532159 MSE test 11.588005583353977\n",
      "MAE train 1.559531219154746 MAE test 2.381114516127703\n",
      "Epoch 7531 / 10000 loss: 12.712247848510742\n",
      "MSE train 5.144833950115004 MSE test 11.587788776506326\n",
      "MAE train 1.5595139916795104 MAE test 2.38108673895804\n",
      "Epoch 7532 / 10000 loss: 12.711714506149292\n",
      "MSE train 5.144728435580669 MSE test 11.58775855098516\n",
      "MAE train 1.5594941534690105 MAE test 2.3810881823485923\n",
      "Epoch 7533 / 10000 loss: 12.711320638656616\n",
      "MSE train 5.144615564384022 MSE test 11.587489712591005\n",
      "MAE train 1.5594782485843843 MAE test 2.381053447511753\n",
      "Epoch 7534 / 10000 loss: 12.710894107818604\n",
      "MSE train 5.144504245582677 MSE test 11.587510927109758\n",
      "MAE train 1.5594559186192118 MAE test 2.3810618280363793\n",
      "Epoch 7535 / 10000 loss: 12.71054220199585\n",
      "MSE train 5.144390352931685 MSE test 11.587238679751188\n",
      "MAE train 1.559439829217019 MAE test 2.3810266309308363\n",
      "Epoch 7536 / 10000 loss: 12.710058212280273\n",
      "MSE train 5.144278878268596 MSE test 11.587259213453121\n",
      "MAE train 1.5594174492163464 MAE test 2.3810349068040355\n",
      "Epoch 7537 / 10000 loss: 12.709705591201782\n",
      "MSE train 5.144164731261562 MSE test 11.586988938980907\n",
      "MAE train 1.5594012423422656 MAE test 2.380999978943701\n",
      "Epoch 7538 / 10000 loss: 12.709220170974731\n",
      "MSE train 5.144054412145402 MSE test 11.587008179257317\n",
      "MAE train 1.559379181212763 MAE test 2.3810080735734394\n",
      "Epoch 7539 / 10000 loss: 12.70886492729187\n",
      "MSE train 5.143940376500266 MSE test 11.586733363303527\n",
      "MAE train 1.5593630929800757 MAE test 2.3809725287621806\n",
      "Epoch 7540 / 10000 loss: 12.70838475227356\n",
      "MSE train 5.143827948949723 MSE test 11.586754481221396\n",
      "MAE train 1.5593404525280306 MAE test 2.3809808886665316\n",
      "Epoch 7541 / 10000 loss: 12.708032369613647\n",
      "MSE train 5.143713572054486 MSE test 11.586488700504951\n",
      "MAE train 1.5593240997934592 MAE test 2.3809465379498085\n",
      "Epoch 7542 / 10000 loss: 12.707542419433594\n",
      "MSE train 5.143605269297499 MSE test 11.586505582826568\n",
      "MAE train 1.559302589480806 MAE test 2.380954314993287\n",
      "Epoch 7543 / 10000 loss: 12.70718264579773\n",
      "MSE train 5.143491517666983 MSE test 11.586223045427175\n",
      "MAE train 1.559286700903206 MAE test 2.380917707584455\n",
      "Epoch 7544 / 10000 loss: 12.706712007522583\n",
      "MSE train 5.143375361423016 MSE test 11.586247555712298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5592630533766796 MAE test 2.3809265401466977\n",
      "Epoch 7545 / 10000 loss: 12.706366777420044\n",
      "MSE train 5.143260658791936 MSE test 11.585999118406868\n",
      "MAE train 1.5592462461467282 MAE test 2.3808944866019726\n",
      "Epoch 7546 / 10000 loss: 12.705859422683716\n",
      "MSE train 5.143157652137526 MSE test 11.58600409273736\n",
      "MAE train 1.5592263490717555 MAE test 2.380900642586004\n",
      "Epoch 7547 / 10000 loss: 12.705485105514526\n",
      "MSE train 5.143044672197104 MSE test 11.585704223408467\n",
      "MAE train 1.5592109848575881 MAE test 2.3808617019592058\n",
      "Epoch 7548 / 10000 loss: 12.705042600631714\n",
      "MSE train 5.14292000165219 MSE test 11.585733790288964\n",
      "MAE train 1.5591850020445965 MAE test 2.380871251792366\n",
      "Epoch 7549 / 10000 loss: 12.704715251922607\n",
      "MSE train 5.142807377060398 MSE test 11.585530516099046\n",
      "MAE train 1.5591678373775348 MAE test 2.380845238097407\n",
      "Epoch 7550 / 10000 loss: 12.70417070388794\n",
      "MSE train 5.142697289171749 MSE test 11.585481907696566\n",
      "MAE train 1.5591471793728455 MAE test 2.380844207373939\n",
      "Epoch 7551 / 10000 loss: 12.703770399093628\n",
      "MSE train 5.1425840208200215 MSE test 11.585247910780287\n",
      "MAE train 1.559130466446093 MAE test 2.3808140776922473\n",
      "Epoch 7552 / 10000 loss: 12.70333743095398\n",
      "MSE train 5.142481854891749 MSE test 11.585247137375411\n",
      "MAE train 1.559110891296503 MAE test 2.3808194654341635\n",
      "Epoch 7553 / 10000 loss: 12.702956199645996\n",
      "MSE train 5.142369730944239 MSE test 11.58494682000379\n",
      "MAE train 1.559095749513586 MAE test 2.3807804376601056\n",
      "Epoch 7554 / 10000 loss: 12.702523708343506\n",
      "MSE train 5.1422439795620125 MSE test 11.584977580930898\n",
      "MAE train 1.5590694494760597 MAE test 2.3807901539484626\n",
      "Epoch 7555 / 10000 loss: 12.702198028564453\n",
      "MSE train 5.1421320414369625 MSE test 11.584780342332918\n",
      "MAE train 1.5590523478351515 MAE test 2.3807649315547215\n",
      "Epoch 7556 / 10000 loss: 12.701649904251099\n",
      "MSE train 5.14201989926688 MSE test 11.584723374646531\n",
      "MAE train 1.5590312801479365 MAE test 2.3807627848426325\n",
      "Epoch 7557 / 10000 loss: 12.701247215270996\n",
      "MSE train 5.141906858740943 MSE test 11.584505923351667\n",
      "MAE train 1.559014305623238 MAE test 2.3807348644872732\n",
      "Epoch 7558 / 10000 loss: 12.70081090927124\n",
      "MSE train 5.141803162501163 MSE test 11.584488447185992\n",
      "MAE train 1.5589946449564525 MAE test 2.3807379965388926\n",
      "Epoch 7559 / 10000 loss: 12.700419425964355\n",
      "MSE train 5.141691022715614 MSE test 11.584205266561485\n",
      "MAE train 1.5589791696418058 MAE test 2.380701276917956\n",
      "Epoch 7560 / 10000 loss: 12.699991941452026\n",
      "MSE train 5.141572038729341 MSE test 11.584233278096438\n",
      "MAE train 1.5589547311379783 MAE test 2.3807105801631367\n",
      "Epoch 7561 / 10000 loss: 12.69965147972107\n",
      "MSE train 5.141457445881093 MSE test 11.583996958202102\n",
      "MAE train 1.5589377078829971 MAE test 2.380680125357686\n",
      "Epoch 7562 / 10000 loss: 12.69913125038147\n",
      "MSE train 5.141355341146265 MSE test 11.583992843611238\n",
      "MAE train 1.5589181772307774 MAE test 2.380685053791592\n",
      "Epoch 7563 / 10000 loss: 12.698747158050537\n",
      "MSE train 5.141242556122747 MSE test 11.583694103706753\n",
      "MAE train 1.5589028462429841 MAE test 2.38064622479224\n",
      "Epoch 7564 / 10000 loss: 12.698315382003784\n",
      "MSE train 5.141117560060429 MSE test 11.583724063064059\n",
      "MAE train 1.5588767570602606 MAE test 2.3806558368542334\n",
      "Epoch 7565 / 10000 loss: 12.697986364364624\n",
      "MSE train 5.141004714990692 MSE test 11.583521408458882\n",
      "MAE train 1.5588595205059517 MAE test 2.3806298846470217\n",
      "Epoch 7566 / 10000 loss: 12.69744086265564\n",
      "MSE train 5.140894281918871 MSE test 11.583472558838208\n",
      "MAE train 1.558838783211259 MAE test 2.380628814496938\n",
      "Epoch 7567 / 10000 loss: 12.697039604187012\n",
      "MSE train 5.140780691547486 MSE test 11.583239058308685\n",
      "MAE train 1.5588219959849183 MAE test 2.380598733942506\n",
      "Epoch 7568 / 10000 loss: 12.69660496711731\n",
      "MSE train 5.140678217987756 MSE test 11.58323766532492\n",
      "MAE train 1.5588023627387009 MAE test 2.380604041106696\n",
      "Epoch 7569 / 10000 loss: 12.69622278213501\n",
      "MSE train 5.14056571109349 MSE test 11.58293757923987\n",
      "MAE train 1.558787145895289 MAE test 2.380565034940032\n",
      "Epoch 7570 / 10000 loss: 12.695789575576782\n",
      "MSE train 5.140439617976993 MSE test 11.582967764843248\n",
      "MAE train 1.558760804107328 MAE test 2.3805746944853037\n",
      "Epoch 7571 / 10000 loss: 12.69546365737915\n",
      "MSE train 5.140327088728984 MSE test 11.582769420369067\n",
      "MAE train 1.5587436200434301 MAE test 2.3805493145582237\n",
      "Epoch 7572 / 10000 loss: 12.694915294647217\n",
      "MSE train 5.140214670289898 MSE test 11.582713080601497\n",
      "MAE train 1.5587225272473277 MAE test 2.380547266785119\n",
      "Epoch 7573 / 10000 loss: 12.69451379776001\n",
      "MSE train 5.140101040133984 MSE test 11.58249261374601\n",
      "MAE train 1.5587055172561959 MAE test 2.3805189427038083\n",
      "Epoch 7574 / 10000 loss: 12.694077968597412\n",
      "MSE train 5.139997177118031 MSE test 11.58247700850745\n",
      "MAE train 1.5586858565971924 MAE test 2.3805223595763856\n",
      "Epoch 7575 / 10000 loss: 12.693688154220581\n",
      "MSE train 5.139884417662773 MSE test 11.582189449962337\n",
      "MAE train 1.5586703982929586 MAE test 2.380485044598152\n",
      "Epoch 7576 / 10000 loss: 12.693261861801147\n",
      "MSE train 5.139763163647108 MSE test 11.582217251942165\n",
      "MAE train 1.5586454702408157 MAE test 2.3804943621541375\n",
      "Epoch 7577 / 10000 loss: 12.692925691604614\n",
      "MSE train 5.139647982046447 MSE test 11.58198838370985\n",
      "MAE train 1.5586282490746906 MAE test 2.380464919494074\n",
      "Epoch 7578 / 10000 loss: 12.692400217056274\n",
      "MSE train 5.139544519985816 MSE test 11.581974089127362\n",
      "MAE train 1.5586086769542826 MAE test 2.3804685044244227\n",
      "Epoch 7579 / 10000 loss: 12.69201135635376\n",
      "MSE train 5.139431038776651 MSE test 11.581681896723667\n",
      "MAE train 1.5585931609828392 MAE test 2.3804305810987523\n",
      "Epoch 7580 / 10000 loss: 12.69158411026001\n",
      "MSE train 5.139308289303457 MSE test 11.581709475843715\n",
      "MAE train 1.5585678720384344 MAE test 2.3804398820347035\n",
      "Epoch 7581 / 10000 loss: 12.691250562667847\n",
      "MSE train 5.1391930679650395 MSE test 11.581487507749808\n",
      "MAE train 1.5585505346068789 MAE test 2.380411359615194\n",
      "Epoch 7582 / 10000 loss: 12.690720558166504\n",
      "MSE train 5.1390878661072295 MSE test 11.581463443722617\n",
      "MAE train 1.55853075024633 MAE test 2.3804136479476004\n",
      "Epoch 7583 / 10000 loss: 12.690327882766724\n",
      "MSE train 5.1389740782165 MSE test 11.581183385886282\n",
      "MAE train 1.5585149590008658 MAE test 2.38037735344512\n",
      "Epoch 7584 / 10000 loss: 12.689902067184448\n",
      "MSE train 5.138856547661712 MSE test 11.58120764237268\n",
      "MAE train 1.5584911259932106 MAE test 2.3803861965694026\n",
      "Epoch 7585 / 10000 loss: 12.689556360244751\n",
      "MSE train 5.138740710036557 MSE test 11.580957145074255\n",
      "MAE train 1.5584742473634197 MAE test 2.3803538683294763\n",
      "Epoch 7586 / 10000 loss: 12.689050197601318\n",
      "MSE train 5.138635984642055 MSE test 11.580962353894993\n",
      "MAE train 1.5584540565477378 MAE test 2.380360085054132\n",
      "Epoch 7587 / 10000 loss: 12.688676595687866\n",
      "MSE train 5.138521596025907 MSE test 11.580661989304536\n",
      "MAE train 1.5584385321360912 MAE test 2.3803210603207066\n",
      "Epoch 7588 / 10000 loss: 12.688232898712158\n",
      "MSE train 5.138395705650239 MSE test 11.580689866226422\n",
      "MAE train 1.5584124516895854 MAE test 2.3803304452525023\n",
      "Epoch 7589 / 10000 loss: 12.687904357910156\n",
      "MSE train 5.1382813539702 MSE test 11.580483607860524\n",
      "MAE train 1.558395093376687 MAE test 2.3803040223279646\n",
      "Epoch 7590 / 10000 loss: 12.687361717224121\n",
      "MSE train 5.138170402245674 MSE test 11.580436121558566\n",
      "MAE train 1.5583743910122045 MAE test 2.380303183188902\n",
      "Epoch 7591 / 10000 loss: 12.686962366104126\n",
      "MSE train 5.138055479878929 MSE test 11.580195545035405\n",
      "MAE train 1.5583576026161896 MAE test 2.380272183088568\n",
      "Epoch 7592 / 10000 loss: 12.686530113220215\n",
      "MSE train 5.137951311960721 MSE test 11.580197454704745\n",
      "MAE train 1.558337670080019 MAE test 2.380277978933801\n",
      "Epoch 7593 / 10000 loss: 12.686153411865234\n",
      "MSE train 5.137837345127286 MSE test 11.579895006614601\n",
      "MAE train 1.5583223297572246 MAE test 2.3802386627783996\n",
      "Epoch 7594 / 10000 loss: 12.685715913772583\n",
      "MSE train 5.1377097602884865 MSE test 11.579923721043368\n",
      "MAE train 1.558295816564601 MAE test 2.3802481606757064\n",
      "Epoch 7595 / 10000 loss: 12.685389995574951\n",
      "MSE train 5.1375962632908125 MSE test 11.579725864409655\n",
      "MAE train 1.5582785706507767 MAE test 2.380222861471508\n",
      "Epoch 7596 / 10000 loss: 12.684842109680176\n",
      "MSE train 5.137481977342457 MSE test 11.579665273919188\n",
      "MAE train 1.5582572599128262 MAE test 2.3802202910636385\n",
      "Epoch 7597 / 10000 loss: 12.684439897537231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.137367369480484 MSE test 11.579449640220368\n",
      "MAE train 1.558240091684701 MAE test 2.380192617961482\n",
      "Epoch 7598 / 10000 loss: 12.684003353118896\n",
      "MSE train 5.137261038770541 MSE test 11.579426021376271\n",
      "MAE train 1.5582201314133377 MAE test 2.3801949991699693\n",
      "Epoch 7599 / 10000 loss: 12.683609962463379\n",
      "MSE train 5.137147040765067 MSE test 11.579147826628787\n",
      "MAE train 1.5582043508346481 MAE test 2.3801589424444343\n",
      "Epoch 7600 / 10000 loss: 12.68318223953247\n",
      "MSE train 5.137029296598668 MSE test 11.579172031409522\n",
      "MAE train 1.5581805474260948 MAE test 2.3801677916351798\n",
      "Epoch 7601 / 10000 loss: 12.682836532592773\n",
      "MSE train 5.136913015330934 MSE test 11.578919314552138\n",
      "MAE train 1.558163676080639 MAE test 2.3801351504243073\n",
      "Epoch 7602 / 10000 loss: 12.682330131530762\n",
      "MSE train 5.136807090809572 MSE test 11.578926474586005\n",
      "MAE train 1.5581432240593105 MAE test 2.3801416582823562\n",
      "Epoch 7603 / 10000 loss: 12.68195652961731\n",
      "MSE train 5.136692096066481 MSE test 11.578627480259149\n",
      "MAE train 1.558127582627496 MAE test 2.380102798148417\n",
      "Epoch 7604 / 10000 loss: 12.681507110595703\n",
      "MSE train 5.136566290377391 MSE test 11.57865487217284\n",
      "MAE train 1.558101615493805 MAE test 2.3801121157584575\n",
      "Epoch 7605 / 10000 loss: 12.681175470352173\n",
      "MSE train 5.136451008813669 MSE test 11.578444830327651\n",
      "MAE train 1.5580841540940158 MAE test 2.3800851795171707\n",
      "Epoch 7606 / 10000 loss: 12.680634498596191\n",
      "MSE train 5.136340921443937 MSE test 11.578402892845029\n",
      "MAE train 1.5580636235669874 MAE test 2.380085079889458\n",
      "Epoch 7607 / 10000 loss: 12.680234432220459\n",
      "MSE train 5.136225588377303 MSE test 11.578151910670242\n",
      "MAE train 1.5580470006591587 MAE test 2.3800526750553654\n",
      "Epoch 7608 / 10000 loss: 12.679801225662231\n",
      "MSE train 5.136118877476392 MSE test 11.578161605595668\n",
      "MAE train 1.558026319287862 MAE test 2.380059516641423\n",
      "Epoch 7609 / 10000 loss: 12.679428577423096\n",
      "MSE train 5.1360039652048375 MSE test 11.577863650969697\n",
      "MAE train 1.5580107032588062 MAE test 2.380020800337807\n",
      "Epoch 7610 / 10000 loss: 12.678977012634277\n",
      "MSE train 5.135878010058891 MSE test 11.577891152771132\n",
      "MAE train 1.5579847188863682 MAE test 2.38003011778963\n",
      "Epoch 7611 / 10000 loss: 12.678644180297852\n",
      "MSE train 5.13576247464206 MSE test 11.577680791816926\n",
      "MAE train 1.5579672202025265 MAE test 2.3800031410235976\n",
      "Epoch 7612 / 10000 loss: 12.678101301193237\n",
      "MSE train 5.1356523489485255 MSE test 11.57763973523535\n",
      "MAE train 1.5579466865237495 MAE test 2.380003154674009\n",
      "Epoch 7613 / 10000 loss: 12.677700996398926\n",
      "MSE train 5.135536812411253 MSE test 11.57738726084131\n",
      "MAE train 1.5579300619511764 MAE test 2.379970550382749\n",
      "Epoch 7614 / 10000 loss: 12.677266597747803\n",
      "MSE train 5.135429472808078 MSE test 11.577398009073974\n",
      "MAE train 1.557909222342668 MAE test 2.3799775268373193\n",
      "Epoch 7615 / 10000 loss: 12.676895141601562\n",
      "MSE train 5.135314257449405 MSE test 11.577101377950935\n",
      "MAE train 1.557893524730841 MAE test 2.3799389924823973\n",
      "Epoch 7616 / 10000 loss: 12.676438570022583\n",
      "MSE train 5.135188669534274 MSE test 11.57712859185503\n",
      "MAE train 1.5578676731468546 MAE test 2.3799482591867642\n",
      "Epoch 7617 / 10000 loss: 12.676103591918945\n",
      "MSE train 5.135072612124522 MSE test 11.576914557281398\n",
      "MAE train 1.5578501272697727 MAE test 2.3799207816461787\n",
      "Epoch 7618 / 10000 loss: 12.675562858581543\n",
      "MSE train 5.1349635177905055 MSE test 11.576878692688798\n",
      "MAE train 1.5578297600131308 MAE test 2.379921479699053\n",
      "Epoch 7619 / 10000 loss: 12.675162553787231\n",
      "MSE train 5.134847950494163 MSE test 11.576617066608925\n",
      "MAE train 1.5578133316612586 MAE test 2.3798876430875557\n",
      "Epoch 7620 / 10000 loss: 12.674728870391846\n",
      "MSE train 5.134737278964402 MSE test 11.576633152262527\n",
      "MAE train 1.5577915363963182 MAE test 2.3798953490242\n",
      "Epoch 7621 / 10000 loss: 12.674363851547241\n",
      "MSE train 5.13462131640725 MSE test 11.576347283193057\n",
      "MAE train 1.557775464108144 MAE test 2.379858243596467\n",
      "Epoch 7622 / 10000 loss: 12.673890352249146\n",
      "MSE train 5.134500808600257 MSE test 11.57637143466624\n",
      "MAE train 1.5577510052582384 MAE test 2.379867069031458\n",
      "Epoch 7623 / 10000 loss: 12.673542499542236\n",
      "MSE train 5.13438337032504 MSE test 11.576129854400387\n",
      "MAE train 1.557733698179483 MAE test 2.3798359049993514\n",
      "Epoch 7624 / 10000 loss: 12.673023462295532\n",
      "MSE train 5.134278589808359 MSE test 11.576126404665752\n",
      "MAE train 1.5577137926632896 MAE test 2.379840958651793\n",
      "Epoch 7625 / 10000 loss: 12.67263674736023\n",
      "MSE train 5.1341630410120285 MSE test 11.575825238556897\n",
      "MAE train 1.5576981180369631 MAE test 2.3798018067229774\n",
      "Epoch 7626 / 10000 loss: 12.672198295593262\n",
      "MSE train 5.13403527748545 MSE test 11.575853065126191\n",
      "MAE train 1.5576716992450554 MAE test 2.3798111662825345\n",
      "Epoch 7627 / 10000 loss: 12.671865224838257\n",
      "MSE train 5.133919940476222 MSE test 11.575650052289816\n",
      "MAE train 1.5576541797284653 MAE test 2.379785140969074\n",
      "Epoch 7628 / 10000 loss: 12.671314239501953\n",
      "MSE train 5.133806415784589 MSE test 11.575597227849418\n",
      "MAE train 1.5576330436748658 MAE test 2.3797835854098253\n",
      "Epoch 7629 / 10000 loss: 12.670908689498901\n",
      "MSE train 5.133690262021863 MSE test 11.575366355345746\n",
      "MAE train 1.5576158925940429 MAE test 2.379753859216067\n",
      "Epoch 7630 / 10000 loss: 12.670468091964722\n",
      "MSE train 5.133585154850539 MSE test 11.575359242273915\n",
      "MAE train 1.5575960205746073 MAE test 2.379758425764894\n",
      "Epoch 7631 / 10000 loss: 12.670078992843628\n",
      "MSE train 5.133470123862068 MSE test 11.575060625773371\n",
      "MAE train 1.5575804503754112 MAE test 2.3797195998260183\n",
      "Epoch 7632 / 10000 loss: 12.669642925262451\n",
      "MSE train 5.133342496409308 MSE test 11.575088781211557\n",
      "MAE train 1.5575540908221128 MAE test 2.379729006878915\n",
      "Epoch 7633 / 10000 loss: 12.669309377670288\n",
      "MSE train 5.133226763211146 MSE test 11.574883401103474\n",
      "MAE train 1.5575365288029475 MAE test 2.3797026896305824\n",
      "Epoch 7634 / 10000 loss: 12.6687593460083\n",
      "MSE train 5.133114183247208 MSE test 11.57483500470317\n",
      "MAE train 1.5575155655521205 MAE test 2.37970170682602\n",
      "Epoch 7635 / 10000 loss: 12.668353796005249\n",
      "MSE train 5.132997896323717 MSE test 11.574595949262202\n",
      "MAE train 1.557498541720982 MAE test 2.379670883989987\n",
      "Epoch 7636 / 10000 loss: 12.667914628982544\n",
      "MSE train 5.132892464200457 MSE test 11.574596353351653\n",
      "MAE train 1.5574784515524474 MAE test 2.379676457308615\n",
      "Epoch 7637 / 10000 loss: 12.667530059814453\n",
      "MSE train 5.132777197533218 MSE test 11.574294068390694\n",
      "MAE train 1.557462879781749 MAE test 2.3796371468436446\n",
      "Epoch 7638 / 10000 loss: 12.66708779335022\n",
      "MSE train 5.132648371318199 MSE test 11.574322401831836\n",
      "MAE train 1.5574361819619875 MAE test 2.379646579323867\n",
      "Epoch 7639 / 10000 loss: 12.666756629943848\n",
      "MSE train 5.1325335698003745 MSE test 11.57412440533757\n",
      "MAE train 1.5574187178713117 MAE test 2.3796212280348636\n",
      "Epoch 7640 / 10000 loss: 12.66620135307312\n",
      "MSE train 5.132418123658875 MSE test 11.574063659903684\n",
      "MAE train 1.5573972131229654 MAE test 2.3796185961372323\n",
      "Epoch 7641 / 10000 loss: 12.66579270362854\n",
      "MSE train 5.132302323321805 MSE test 11.573847571375827\n",
      "MAE train 1.5573798520269808 MAE test 2.379590840969179\n",
      "Epoch 7642 / 10000 loss: 12.665351152420044\n",
      "MSE train 5.132195000584572 MSE test 11.57382386214944\n",
      "MAE train 1.5573597312884628 MAE test 2.3795931796056835\n",
      "Epoch 7643 / 10000 loss: 12.664952754974365\n",
      "MSE train 5.132079893418535 MSE test 11.573545142044702\n",
      "MAE train 1.5573437505919465 MAE test 2.379557025569226\n",
      "Epoch 7644 / 10000 loss: 12.664520263671875\n",
      "MSE train 5.131960968120092 MSE test 11.5735691982733\n",
      "MAE train 1.5573197360180826 MAE test 2.379565830314004\n",
      "Epoch 7645 / 10000 loss: 12.664169311523438\n",
      "MSE train 5.131843702361199 MSE test 11.573317490913569\n",
      "MAE train 1.5573026656189837 MAE test 2.3795333043356415\n",
      "Epoch 7646 / 10000 loss: 12.66365671157837\n",
      "MSE train 5.131737211879965 MSE test 11.573323057911665\n",
      "MAE train 1.5572821709344553 MAE test 2.3795395701039865\n",
      "Epoch 7647 / 10000 loss: 12.663278341293335\n",
      "MSE train 5.131621475959379 MSE test 11.573023556113927\n",
      "MAE train 1.5572663939271032 MAE test 2.37950061432398\n",
      "Epoch 7648 / 10000 loss: 12.662826299667358\n",
      "MSE train 5.13149479007616 MSE test 11.573050453185727\n",
      "MAE train 1.5572402712461497 MAE test 2.379509839085938\n",
      "Epoch 7649 / 10000 loss: 12.662490844726562\n",
      "MSE train 5.131379006827601 MSE test 11.572841836357124\n",
      "MAE train 1.5572227231981604 MAE test 2.379483077060139\n",
      "Epoch 7650 / 10000 loss: 12.661946058273315\n",
      "MSE train 5.131267894558811 MSE test 11.572797178895012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5572020327880234 MAE test 2.3794825779085857\n",
      "Epoch 7651 / 10000 loss: 12.661542654037476\n",
      "MSE train 5.131152095760233 MSE test 11.572550077667909\n",
      "MAE train 1.5571852317758208 MAE test 2.3794506689952657\n",
      "Epoch 7652 / 10000 loss: 12.66110610961914\n",
      "MSE train 5.131046085668618 MSE test 11.57255622937444\n",
      "MAE train 1.5571648374917286 MAE test 2.3794570088604647\n",
      "Epoch 7653 / 10000 loss: 12.66072940826416\n",
      "MSE train 5.130931040787463 MSE test 11.57225548354305\n",
      "MAE train 1.5571492403857583 MAE test 2.3794178932932706\n",
      "Epoch 7654 / 10000 loss: 12.660281658172607\n",
      "MSE train 5.13080387280294 MSE test 11.572282967079627\n",
      "MAE train 1.557122931371422 MAE test 2.379427201025804\n",
      "Epoch 7655 / 10000 loss: 12.659950494766235\n",
      "MSE train 5.130689065694031 MSE test 11.572079262593954\n",
      "MAE train 1.5571054963996107 MAE test 2.3794010804174754\n",
      "Epoch 7656 / 10000 loss: 12.65940237045288\n",
      "MSE train 5.13057649941664 MSE test 11.572026923583888\n",
      "MAE train 1.557084518951688 MAE test 2.3793995772607808\n",
      "Epoch 7657 / 10000 loss: 12.658999919891357\n",
      "MSE train 5.130461138500406 MSE test 11.571794079042393\n",
      "MAE train 1.5570675052547334 MAE test 2.379369562232846\n",
      "Epoch 7658 / 10000 loss: 12.658563375473022\n",
      "MSE train 5.130356966973521 MSE test 11.571788110610875\n",
      "MAE train 1.5570477479679412 MAE test 2.379374269595276\n",
      "Epoch 7659 / 10000 loss: 12.65817904472351\n",
      "MSE train 5.130242927217033 MSE test 11.57148816611127\n",
      "MAE train 1.5570323305589238 MAE test 2.379335256836312\n",
      "Epoch 7660 / 10000 loss: 12.65774655342102\n",
      "MSE train 5.130115994570174 MSE test 11.571515903066269\n",
      "MAE train 1.5570060355973283 MAE test 2.3793445901324692\n",
      "Epoch 7661 / 10000 loss: 12.657418966293335\n",
      "MSE train 5.130001776548778 MSE test 11.571312724797416\n",
      "MAE train 1.5569886924557503 MAE test 2.379318548777641\n",
      "Epoch 7662 / 10000 loss: 12.656873226165771\n",
      "MSE train 5.1298894989306545 MSE test 11.571259801844693\n",
      "MAE train 1.5569677503549995 MAE test 2.379316965340918\n",
      "Epoch 7663 / 10000 loss: 12.656472444534302\n",
      "MSE train 5.1297746229399515 MSE test 11.571028236797215\n",
      "MAE train 1.5569508003265558 MAE test 2.379287122862093\n",
      "Epoch 7664 / 10000 loss: 12.656038045883179\n",
      "MSE train 5.129670911845209 MSE test 11.571020930563195\n",
      "MAE train 1.5569311310020155 MAE test 2.3792916505886046\n",
      "Epoch 7665 / 10000 loss: 12.65565538406372\n",
      "MSE train 5.1295574267484625 MSE test 11.570721771549799\n",
      "MAE train 1.5569157899018709 MAE test 2.379252739177296\n",
      "Epoch 7666 / 10000 loss: 12.655226469039917\n",
      "MSE train 5.129431233442002 MSE test 11.570749479621087\n",
      "MAE train 1.5568896406188095 MAE test 2.3792620751649842\n",
      "Epoch 7667 / 10000 loss: 12.654900312423706\n",
      "MSE train 5.12931725671208 MSE test 11.570544622739185\n",
      "MAE train 1.5568723447748969 MAE test 2.379235803855867\n",
      "Epoch 7668 / 10000 loss: 12.654356956481934\n",
      "MSE train 5.129206138426161 MSE test 11.57049448308642\n",
      "MAE train 1.5568515985856697 MAE test 2.379234596033599\n",
      "Epoch 7669 / 10000 loss: 12.653958797454834\n",
      "MSE train 5.129091678462702 MSE test 11.570257464350126\n",
      "MAE train 1.5568348154290133 MAE test 2.3792040215931243\n",
      "Epoch 7670 / 10000 loss: 12.65352749824524\n",
      "MSE train 5.1289883502105145 MSE test 11.570255238010795\n",
      "MAE train 1.5568151100299839 MAE test 2.379209240616704\n",
      "Epoch 7671 / 10000 loss: 12.65315055847168\n",
      "MSE train 5.1288750941017645 MSE test 11.569953328781287\n",
      "MAE train 1.556799835691137 MAE test 2.379169947931848\n",
      "Epoch 7672 / 10000 loss: 12.65272045135498\n",
      "MSE train 5.128748466980709 MSE test 11.569981034132415\n",
      "MAE train 1.556773514973998 MAE test 2.3791793017463823\n",
      "Epoch 7673 / 10000 loss: 12.652397394180298\n",
      "MSE train 5.128635594227289 MSE test 11.569781723412373\n",
      "MAE train 1.5567563637647577 MAE test 2.37915375773023\n",
      "Epoch 7674 / 10000 loss: 12.651853322982788\n",
      "MSE train 5.128522748862748 MSE test 11.56972239477766\n",
      "MAE train 1.5567352864491435 MAE test 2.3791513196055956\n",
      "Epoch 7675 / 10000 loss: 12.65145492553711\n",
      "MSE train 5.12840894982608 MSE test 11.569502319317005\n",
      "MAE train 1.5567182968290216 MAE test 2.379123018628346\n",
      "Epoch 7676 / 10000 loss: 12.651024341583252\n",
      "MSE train 5.128304621521905 MSE test 11.569482608558046\n",
      "MAE train 1.5566986410572725 MAE test 2.37912588979653\n",
      "Epoch 7677 / 10000 loss: 12.65063738822937\n",
      "MSE train 5.128191904810702 MSE test 11.569197120257481\n",
      "MAE train 1.5566831684261246 MAE test 2.3790888073692895\n",
      "Epoch 7678 / 10000 loss: 12.65021538734436\n",
      "MSE train 5.128072263188388 MSE test 11.569222283139327\n",
      "MAE train 1.5566587328331347 MAE test 2.379097776710957\n",
      "Epoch 7679 / 10000 loss: 12.64988088607788\n",
      "MSE train 5.1279571264474395 MSE test 11.56898517235109\n",
      "MAE train 1.5566417203157406 MAE test 2.3790671835188273\n",
      "Epoch 7680 / 10000 loss: 12.64936637878418\n",
      "MSE train 5.127854598576643 MSE test 11.568976902970165\n",
      "MAE train 1.5566222533873744 MAE test 2.379071583913226\n",
      "Epoch 7681 / 10000 loss: 12.648987054824829\n",
      "MSE train 5.127741539404489 MSE test 11.568677632186027\n",
      "MAE train 1.556606925272984 MAE test 2.379032664503999\n",
      "Epoch 7682 / 10000 loss: 12.64856243133545\n",
      "MSE train 5.127616813130826 MSE test 11.56870449526959\n",
      "MAE train 1.5565810744001136 MAE test 2.3790418728204235\n",
      "Epoch 7683 / 10000 loss: 12.648239135742188\n",
      "MSE train 5.127503444168669 MSE test 11.568497118808402\n",
      "MAE train 1.556563887039063 MAE test 2.3790152741604436\n",
      "Epoch 7684 / 10000 loss: 12.647702693939209\n",
      "MSE train 5.127394067393976 MSE test 11.568450053932601\n",
      "MAE train 1.5565434371303482 MAE test 2.37901447616705\n",
      "Epoch 7685 / 10000 loss: 12.647309064865112\n",
      "MSE train 5.127280424260547 MSE test 11.568206746348551\n",
      "MAE train 1.5565269016525174 MAE test 2.3789830575488655\n",
      "Epoch 7686 / 10000 loss: 12.646883010864258\n",
      "MSE train 5.127177270993342 MSE test 11.568209578264103\n",
      "MAE train 1.5565070692801604 MAE test 2.3789889670289797\n",
      "Epoch 7687 / 10000 loss: 12.646513223648071\n",
      "MSE train 5.1270645537028505 MSE test 11.567907707860181\n",
      "MAE train 1.556491870993657 MAE test 2.37894968426313\n",
      "Epoch 7688 / 10000 loss: 12.646080255508423\n",
      "MSE train 5.126938856342843 MSE test 11.567935030147433\n",
      "MAE train 1.5564657235903157 MAE test 2.3789589758660226\n",
      "Epoch 7689 / 10000 loss: 12.645760297775269\n",
      "MSE train 5.126826592723581 MSE test 11.567734856506993\n",
      "MAE train 1.5564486845650638 MAE test 2.3789333297802226\n",
      "Epoch 7690 / 10000 loss: 12.645220041275024\n",
      "MSE train 5.126714650049519 MSE test 11.567676430771904\n",
      "MAE train 1.5564277681037708 MAE test 2.3789310183352437\n",
      "Epoch 7691 / 10000 loss: 12.644825220108032\n",
      "MSE train 5.126601381838633 MSE test 11.567454564583786\n",
      "MAE train 1.5564109071590528 MAE test 2.378902463191006\n",
      "Epoch 7692 / 10000 loss: 12.644397735595703\n",
      "MSE train 5.126498075975209 MSE test 11.567436880851883\n",
      "MAE train 1.556391415054723 MAE test 2.3789056275140186\n",
      "Epoch 7693 / 10000 loss: 12.644014596939087\n",
      "MSE train 5.126385869076375 MSE test 11.567148665957347\n",
      "MAE train 1.5563760727384128 MAE test 2.37886819043252\n",
      "Epoch 7694 / 10000 loss: 12.643595457077026\n",
      "MSE train 5.126265611896127 MSE test 11.567174322535095\n",
      "MAE train 1.5563514056877878 MAE test 2.378877232573569\n",
      "Epoch 7695 / 10000 loss: 12.643266439437866\n",
      "MSE train 5.126151157927713 MSE test 11.56694378596719\n",
      "MAE train 1.5563343783938102 MAE test 2.3788475102199507\n",
      "Epoch 7696 / 10000 loss: 12.642748355865479\n",
      "MSE train 5.126048644677407 MSE test 11.566928491960086\n",
      "MAE train 1.5563150001089254 MAE test 2.3788509915619493\n",
      "Epoch 7697 / 10000 loss: 12.642367124557495\n",
      "MSE train 5.125936164744801 MSE test 11.566635419861804\n",
      "MAE train 1.556299659674513 MAE test 2.3788128999922913\n",
      "Epoch 7698 / 10000 loss: 12.641947984695435\n",
      "MSE train 5.12581437683264 MSE test 11.566661230520975\n",
      "MAE train 1.556274572022886 MAE test 2.378821970969406\n",
      "Epoch 7699 / 10000 loss: 12.641621351242065\n",
      "MSE train 5.12570033389006 MSE test 11.566439765904573\n",
      "MAE train 1.5562574443309252 MAE test 2.378793470489745\n",
      "Epoch 7700 / 10000 loss: 12.641097784042358\n",
      "MSE train 5.125596094070438 MSE test 11.566413039521352\n",
      "MAE train 1.5562378462968485 MAE test 2.378795411462422\n",
      "Epoch 7701 / 10000 loss: 12.640711307525635\n",
      "MSE train 5.12548344066774 MSE test 11.566134877128192\n",
      "MAE train 1.5562221883473393 MAE test 2.378759324565119\n",
      "Epoch 7702 / 10000 loss: 12.640292167663574\n",
      "MSE train 5.125368436159548 MSE test 11.566156805128978\n",
      "MAE train 1.556198908587829 MAE test 2.3787678361137883\n",
      "Epoch 7703 / 10000 loss: 12.63995361328125\n",
      "MSE train 5.125254075843816 MSE test 11.565901362994488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5561823797268644 MAE test 2.3787347939290564\n",
      "Epoch 7704 / 10000 loss: 12.639459371566772\n",
      "MSE train 5.125149646686035 MSE test 11.565908821366033\n",
      "MAE train 1.5561620549907107 MAE test 2.3787413446765884\n",
      "Epoch 7705 / 10000 loss: 12.63909649848938\n",
      "MSE train 5.125036563062149 MSE test 11.565612248254258\n",
      "MAE train 1.5561466158072983 MAE test 2.3787027783607195\n",
      "Epoch 7706 / 10000 loss: 12.63865351676941\n",
      "MSE train 5.124914181821394 MSE test 11.565637776369865\n",
      "MAE train 1.556121334318297 MAE test 2.378711817251942\n",
      "Epoch 7707 / 10000 loss: 12.638327360153198\n",
      "MSE train 5.124800522011364 MSE test 11.565421473266007\n",
      "MAE train 1.5561041888315912 MAE test 2.378684008566131\n",
      "Epoch 7708 / 10000 loss: 12.637802362442017\n",
      "MSE train 5.124694816696632 MSE test 11.5653871422501\n",
      "MAE train 1.5560843556608526 MAE test 2.378684927870755\n",
      "Epoch 7709 / 10000 loss: 12.63741397857666\n",
      "MSE train 5.124582012357283 MSE test 11.565120908922\n",
      "MAE train 1.5560684333737171 MAE test 2.3786504454500403\n",
      "Epoch 7710 / 10000 loss: 12.636993646621704\n",
      "MSE train 5.124472450128744 MSE test 11.565138022365266\n",
      "MAE train 1.5560465984557752 MAE test 2.3786583068789056\n",
      "Epoch 7711 / 10000 loss: 12.636645078659058\n",
      "MSE train 5.124358991191636 MSE test 11.564859380484341\n",
      "MAE train 1.5560307249281968 MAE test 2.3786221530913645\n",
      "Epoch 7712 / 10000 loss: 12.636176347732544\n",
      "MSE train 5.12424509168707 MSE test 11.564879839845062\n",
      "MAE train 1.556007719393673 MAE test 2.378630480531917\n",
      "Epoch 7713 / 10000 loss: 12.635834455490112\n",
      "MSE train 5.12413077298253 MSE test 11.564621096085366\n",
      "MAE train 1.5559912539297238 MAE test 2.3785970037002677\n",
      "Epoch 7714 / 10000 loss: 12.635344982147217\n",
      "MSE train 5.124025650073348 MSE test 11.564630292055188\n",
      "MAE train 1.555970686752619 MAE test 2.3786037831985225\n",
      "Epoch 7715 / 10000 loss: 12.63498592376709\n",
      "MSE train 5.123912475334261 MSE test 11.564336600705536\n",
      "MAE train 1.5559551561222538 MAE test 2.378565610175368\n",
      "Epoch 7716 / 10000 loss: 12.63453722000122\n",
      "MSE train 5.123791663081227 MSE test 11.564361313230823\n",
      "MAE train 1.555930292850376 MAE test 2.3785745366290074\n",
      "Epoch 7717 / 10000 loss: 12.634209871292114\n",
      "MSE train 5.1236775945226904 MSE test 11.5641371785511\n",
      "MAE train 1.555913189769305 MAE test 2.378545679088384\n",
      "Epoch 7718 / 10000 loss: 12.633689880371094\n",
      "MSE train 5.123574237794387 MSE test 11.564113208716206\n",
      "MAE train 1.5558937245152076 MAE test 2.3785480034376616\n",
      "Epoch 7719 / 10000 loss: 12.63330602645874\n",
      "MSE train 5.123461796132377 MSE test 11.56383073123039\n",
      "MAE train 1.5558781726231419 MAE test 2.378511336829238\n",
      "Epoch 7720 / 10000 loss: 12.632888555526733\n",
      "MSE train 5.123345001937817 MSE test 11.563853933477423\n",
      "MAE train 1.5558543855312728 MAE test 2.378520041411128\n",
      "Epoch 7721 / 10000 loss: 12.632554531097412\n",
      "MSE train 5.123230719803012 MSE test 11.563608363958352\n",
      "MAE train 1.5558376511068157 MAE test 2.378488320757724\n",
      "Epoch 7722 / 10000 loss: 12.632051467895508\n",
      "MSE train 5.12312858207091 MSE test 11.56360781068233\n",
      "MAE train 1.555818038831047 MAE test 2.378493792534278\n",
      "Epoch 7723 / 10000 loss: 12.631682634353638\n",
      "MSE train 5.123015986349327 MSE test 11.563306710430169\n",
      "MAE train 1.5558027781120518 MAE test 2.378454634046091\n",
      "Epoch 7724 / 10000 loss: 12.631253480911255\n",
      "MSE train 5.122891564231142 MSE test 11.563333395062342\n",
      "MAE train 1.5557769035084983 MAE test 2.378463851853101\n",
      "Epoch 7725 / 10000 loss: 12.630934000015259\n",
      "MSE train 5.122779362674023 MSE test 11.563129985245887\n",
      "MAE train 1.5557598648441284 MAE test 2.3784377703774755\n",
      "Epoch 7726 / 10000 loss: 12.630398988723755\n",
      "MSE train 5.1226692354122 MSE test 11.563076692687801\n",
      "MAE train 1.555739257484173 MAE test 2.378436175162212\n",
      "Epoch 7727 / 10000 loss: 12.63000750541687\n",
      "MSE train 5.122556294149864 MSE test 11.562845278890435\n",
      "MAE train 1.5557226075989163 MAE test 2.3784063397558306\n",
      "Epoch 7728 / 10000 loss: 12.629582643508911\n",
      "MSE train 5.122454464783068 MSE test 11.562837731811548\n",
      "MAE train 1.5557032213754116 MAE test 2.378410890756972\n",
      "Epoch 7729 / 10000 loss: 12.629208087921143\n",
      "MSE train 5.122342700469322 MSE test 11.562539122920764\n",
      "MAE train 1.5556881156208735 MAE test 2.3783720607051557\n",
      "Epoch 7730 / 10000 loss: 12.628787279129028\n",
      "MSE train 5.12221851481219 MSE test 11.562566260209456\n",
      "MAE train 1.5556623009930324 MAE test 2.3783813449914817\n",
      "Epoch 7731 / 10000 loss: 12.62846827507019\n",
      "MSE train 5.122106184727227 MSE test 11.562361073182315\n",
      "MAE train 1.5556452620357195 MAE test 2.378355022556426\n",
      "Epoch 7732 / 10000 loss: 12.62793517112732\n",
      "MSE train 5.1219969583765 MSE test 11.562311551507236\n",
      "MAE train 1.5556248085637217 MAE test 2.3783539423372675\n",
      "Epoch 7733 / 10000 loss: 12.627544403076172\n",
      "MSE train 5.1218840307959566 MSE test 11.562073377257978\n",
      "MAE train 1.5556082891289624 MAE test 2.3783232177515097\n",
      "Epoch 7734 / 10000 loss: 12.62712049484253\n",
      "MSE train 5.121782100928951 MSE test 11.562072064248573\n",
      "MAE train 1.5555887517487492 MAE test 2.378328602544413\n",
      "Epoch 7735 / 10000 loss: 12.626751184463501\n",
      "MSE train 5.121670180936453 MSE test 11.561770699543166\n",
      "MAE train 1.5555736624469823 MAE test 2.37828940577887\n",
      "Epoch 7736 / 10000 loss: 12.626325845718384\n",
      "MSE train 5.121545101236305 MSE test 11.561797874707295\n",
      "MAE train 1.5555475843335478 MAE test 2.37829871304525\n",
      "Epoch 7737 / 10000 loss: 12.62600827217102\n",
      "MSE train 5.121433512511125 MSE test 11.561599032200492\n",
      "MAE train 1.5555306312438026 MAE test 2.3782732285254453\n",
      "Epoch 7738 / 10000 loss: 12.625471115112305\n",
      "MSE train 5.121321959387227 MSE test 11.561539266816004\n",
      "MAE train 1.5555097470610657 MAE test 2.378270777825019\n",
      "Epoch 7739 / 10000 loss: 12.625078678131104\n",
      "MSE train 5.121209360366857 MSE test 11.561320086553753\n",
      "MAE train 1.5554929342592758 MAE test 2.3782425970494017\n",
      "Epoch 7740 / 10000 loss: 12.624652624130249\n",
      "MSE train 5.121106174672369 MSE test 11.561299562438778\n",
      "MAE train 1.555473449443655 MAE test 2.3782454114940146\n",
      "Epoch 7741 / 10000 loss: 12.624271392822266\n",
      "MSE train 5.120994442566464 MSE test 11.561015724895325\n",
      "MAE train 1.5554580876753987 MAE test 2.378208569573687\n",
      "Epoch 7742 / 10000 loss: 12.623854637145996\n",
      "MSE train 5.120876449097066 MSE test 11.56104022989743\n",
      "MAE train 1.5554339487088797 MAE test 2.378217479338058\n",
      "Epoch 7743 / 10000 loss: 12.623523950576782\n",
      "MSE train 5.120762329947675 MSE test 11.560801206986524\n",
      "MAE train 1.55541712924327 MAE test 2.378186630995917\n",
      "Epoch 7744 / 10000 loss: 12.623016357421875\n",
      "MSE train 5.1206608118010575 MSE test 11.560795194589755\n",
      "MAE train 1.555397761266327 MAE test 2.3781913931568837\n",
      "Epoch 7745 / 10000 loss: 12.622642755508423\n",
      "MSE train 5.120548607209753 MSE test 11.560495417222723\n",
      "MAE train 1.5553825527971856 MAE test 2.3781524010413517\n",
      "Epoch 7746 / 10000 loss: 12.622220516204834\n",
      "MSE train 5.120424510056833 MSE test 11.560522034420991\n",
      "MAE train 1.5553567551518575 MAE test 2.3781616292754864\n",
      "Epoch 7747 / 10000 loss: 12.621901512145996\n",
      "MSE train 5.120312275873399 MSE test 11.560317209564966\n",
      "MAE train 1.5553397231327726 MAE test 2.3781353525867432\n",
      "Epoch 7748 / 10000 loss: 12.621368169784546\n",
      "MSE train 5.120202923309697 MSE test 11.560266650896585\n",
      "MAE train 1.5553192428694942 MAE test 2.3781341427908242\n",
      "Epoch 7749 / 10000 loss: 12.620977401733398\n",
      "MSE train 5.120090018385367 MSE test 11.560030230625479\n",
      "MAE train 1.555302695646118 MAE test 2.3781036515632956\n",
      "Epoch 7750 / 10000 loss: 12.620554447174072\n",
      "MSE train 5.11998832715296 MSE test 11.560027473174761\n",
      "MAE train 1.5552832299720574 MAE test 2.3781088541759545\n",
      "Epoch 7751 / 10000 loss: 12.62018346786499\n",
      "MSE train 5.119876556719258 MSE test 11.559726493089638\n",
      "MAE train 1.5552681545515088 MAE test 2.3780697018536103\n",
      "Epoch 7752 / 10000 loss: 12.619759559631348\n",
      "MSE train 5.119751630139927 MSE test 11.559753698941298\n",
      "MAE train 1.5552421170332635 MAE test 2.378079015759501\n",
      "Epoch 7753 / 10000 loss: 12.6194429397583\n",
      "MSE train 5.119640018798969 MSE test 11.559553897649986\n",
      "MAE train 1.5552251590180808 MAE test 2.378053422137159\n",
      "Epoch 7754 / 10000 loss: 12.618905782699585\n",
      "MSE train 5.119528865094048 MSE test 11.55949582392266\n",
      "MAE train 1.555204354863026 MAE test 2.37805119868275\n",
      "Epoch 7755 / 10000 loss: 12.61851453781128\n",
      "MSE train 5.119416256134909 MSE test 11.559273872394416\n",
      "MAE train 1.555187582650286 MAE test 2.378022650191435\n",
      "Epoch 7756 / 10000 loss: 12.6180899143219\n",
      "MSE train 5.119313683119453 MSE test 11.55925648405047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.555168182062333 MAE test 2.3780258951013336\n",
      "Epoch 7757 / 10000 loss: 12.61771035194397\n",
      "MSE train 5.119202092805523 MSE test 11.558968279177625\n",
      "MAE train 1.5551529119248642 MAE test 2.377988460742734\n",
      "Epoch 7758 / 10000 loss: 12.6172935962677\n",
      "MSE train 5.119082169242074 MSE test 11.55899371336482\n",
      "MAE train 1.5551282605490402 MAE test 2.377997509170253\n",
      "Epoch 7759 / 10000 loss: 12.616966724395752\n",
      "MSE train 5.118968252223627 MSE test 11.558765191809892\n",
      "MAE train 1.5551112774116085 MAE test 2.377968070960966\n",
      "Epoch 7760 / 10000 loss: 12.616451025009155\n",
      "MSE train 5.118866148479081 MSE test 11.558747860360114\n",
      "MAE train 1.5550919683828461 MAE test 2.377971311364553\n",
      "Epoch 7761 / 10000 loss: 12.616071939468384\n",
      "MSE train 5.118754099861958 MSE test 11.558457411638463\n",
      "MAE train 1.5550766176074802 MAE test 2.3779335805863684\n",
      "Epoch 7762 / 10000 loss: 12.615653991699219\n",
      "MSE train 5.118633780132262 MSE test 11.558482556885492\n",
      "MAE train 1.555051864872884 MAE test 2.3779425844675335\n",
      "Epoch 7763 / 10000 loss: 12.615327835083008\n",
      "MSE train 5.118519993168119 MSE test 11.558256509264053\n",
      "MAE train 1.5550348367022169 MAE test 2.3779134866532576\n",
      "Epoch 7764 / 10000 loss: 12.614810228347778\n",
      "MSE train 5.118417345250532 MSE test 11.558235562353968\n",
      "MAE train 1.5550154699835117 MAE test 2.3779162470153348\n",
      "Epoch 7765 / 10000 loss: 12.614429712295532\n",
      "MSE train 5.118305188229976 MSE test 11.557949555227736\n",
      "MAE train 1.5550000191120286 MAE test 2.3778791156143133\n",
      "Epoch 7766 / 10000 loss: 12.614012479782104\n",
      "MSE train 5.118186897824118 MSE test 11.557973574466423\n",
      "MAE train 1.5549758005405696 MAE test 2.377887964836617\n",
      "Epoch 7767 / 10000 loss: 12.61368203163147\n",
      "MSE train 5.118072771485224 MSE test 11.557737372615335\n",
      "MAE train 1.5549589180206251 MAE test 2.3778575036733964\n",
      "Epoch 7768 / 10000 loss: 12.613173723220825\n",
      "MSE train 5.117971303484724 MSE test 11.557727937200424\n",
      "MAE train 1.554939615630493 MAE test 2.377861810894063\n",
      "Epoch 7769 / 10000 loss: 12.612799167633057\n",
      "MSE train 5.117859169567311 MSE test 11.557429976062005\n",
      "MAE train 1.5549243760681382 MAE test 2.377823078125437\n",
      "Epoch 7770 / 10000 loss: 12.6123788356781\n",
      "MSE train 5.117735897224191 MSE test 11.557456216961718\n",
      "MAE train 1.5548988005134476 MAE test 2.37783224426628\n",
      "Epoch 7771 / 10000 loss: 12.612058639526367\n",
      "MSE train 5.117623222947738 MSE test 11.557247336075541\n",
      "MAE train 1.5548817186024446 MAE test 2.3778054481622752\n",
      "Epoch 7772 / 10000 loss: 12.611528873443604\n",
      "MSE train 5.117515475884516 MSE test 11.5572028793631\n",
      "MAE train 1.5548615304865363 MAE test 2.377805053514579\n",
      "Epoch 7773 / 10000 loss: 12.611139297485352\n",
      "MSE train 5.1174027316433195 MSE test 11.556954792699944\n",
      "MAE train 1.5548452110679545 MAE test 2.3777730177215335\n",
      "Epoch 7774 / 10000 loss: 12.610718011856079\n",
      "MSE train 5.117299418431654 MSE test 11.556961066145728\n",
      "MAE train 1.55482517053339 MAE test 2.3777794330287105\n",
      "Epoch 7775 / 10000 loss: 12.61035704612732\n",
      "MSE train 5.117187237075733 MSE test 11.556662043207579\n",
      "MAE train 1.5548099398669473 MAE test 2.377740551988932\n",
      "Epoch 7776 / 10000 loss: 12.609920501708984\n",
      "MSE train 5.1170635631589665 MSE test 11.55668833648434\n",
      "MAE train 1.554784253903212 MAE test 2.377749741746927\n",
      "Epoch 7777 / 10000 loss: 12.609601259231567\n",
      "MSE train 5.116951134230547 MSE test 11.55648167820588\n",
      "MAE train 1.5547671970271024 MAE test 2.3777232501357473\n",
      "Epoch 7778 / 10000 loss: 12.609069347381592\n",
      "MSE train 5.116842515823432 MSE test 11.556433602738325\n",
      "MAE train 1.5547468456129718 MAE test 2.3777223722418404\n",
      "Epoch 7779 / 10000 loss: 12.608679294586182\n",
      "MSE train 5.116729734259268 MSE test 11.556192137398918\n",
      "MAE train 1.5547303913329733 MAE test 2.3776912132709485\n",
      "Epoch 7780 / 10000 loss: 12.60825777053833\n",
      "MSE train 5.116627581992648 MSE test 11.556193068858498\n",
      "MAE train 1.5547107456485008 MAE test 2.3776969265850436\n",
      "Epoch 7781 / 10000 loss: 12.607891321182251\n",
      "MSE train 5.116515658018827 MSE test 11.555891898757277\n",
      "MAE train 1.5546956222821935 MAE test 2.3776577524968583\n",
      "Epoch 7782 / 10000 loss: 12.607462882995605\n",
      "MSE train 5.1163908732855585 MSE test 11.555918592030249\n",
      "MAE train 1.554669618920923 MAE test 2.3776670123265293\n",
      "Epoch 7783 / 10000 loss: 12.607146978378296\n",
      "MSE train 5.1162792667495385 MSE test 11.555718725597936\n",
      "MAE train 1.5546526532966691 MAE test 2.3776414167480877\n",
      "Epoch 7784 / 10000 loss: 12.606610298156738\n",
      "MSE train 5.116168084590022 MSE test 11.555659949045088\n",
      "MAE train 1.5546318475774152 MAE test 2.3776391144125286\n",
      "Epoch 7785 / 10000 loss: 12.606219291687012\n",
      "MSE train 5.116055524837923 MSE test 11.555438352554694\n",
      "MAE train 1.5546150620996257 MAE test 2.3776106270477033\n",
      "Epoch 7786 / 10000 loss: 12.605793714523315\n",
      "MSE train 5.115952836529737 MSE test 11.555419881083973\n",
      "MAE train 1.5545956534369358 MAE test 2.3776137261864165\n",
      "Epoch 7787 / 10000 loss: 12.605414628982544\n",
      "MSE train 5.115841229102774 MSE test 11.555132420806526\n",
      "MAE train 1.5545803593915632 MAE test 2.3775764043908305\n",
      "Epoch 7788 / 10000 loss: 12.604998111724854\n",
      "MSE train 5.11572169371604 MSE test 11.555157214072343\n",
      "MAE train 1.5545558190387627 MAE test 2.377585374549771\n",
      "Epoch 7789 / 10000 loss: 12.604671239852905\n",
      "MSE train 5.115607783182741 MSE test 11.554926473067315\n",
      "MAE train 1.5545388571176608 MAE test 2.3775556640152318\n",
      "Epoch 7790 / 10000 loss: 12.60415768623352\n",
      "MSE train 5.115505870291097 MSE test 11.554910944463476\n",
      "MAE train 1.5545195650932193 MAE test 2.377559159521552\n",
      "Epoch 7791 / 10000 loss: 12.603778839111328\n",
      "MSE train 5.115393779392746 MSE test 11.554617913265773\n",
      "MAE train 1.554504241240941 MAE test 2.377521092788031\n",
      "Epoch 7792 / 10000 loss: 12.60336184501648\n",
      "MSE train 5.115272468633183 MSE test 11.554642864056374\n",
      "MAE train 1.5544792298465426 MAE test 2.377530096915527\n",
      "Epoch 7793 / 10000 loss: 12.603037357330322\n",
      "MSE train 5.115158867745846 MSE test 11.554422028450775\n",
      "MAE train 1.5544621402285483 MAE test 2.377501709418507\n",
      "Epoch 7794 / 10000 loss: 12.602516889572144\n",
      "MSE train 5.115054942863177 MSE test 11.554393682036974\n",
      "MAE train 1.5544425908242747 MAE test 2.3775034681182685\n",
      "Epoch 7795 / 10000 loss: 12.602132558822632\n",
      "MSE train 5.114942668738921 MSE test 11.55411699433158\n",
      "MAE train 1.5544269198430745 MAE test 2.3774676148038556\n",
      "Epoch 7796 / 10000 loss: 12.601715326309204\n",
      "MSE train 5.114828685603028 MSE test 11.554137469299887\n",
      "MAE train 1.5544038834749365 MAE test 2.3774759953602094\n",
      "Epoch 7797 / 10000 loss: 12.601377010345459\n",
      "MSE train 5.114714676626171 MSE test 11.553879313225845\n",
      "MAE train 1.5543874460568723 MAE test 2.377442605021897\n",
      "Epoch 7798 / 10000 loss: 12.600888013839722\n",
      "MSE train 5.11460976404589 MSE test 11.553887508557507\n",
      "MAE train 1.5543669295242037 MAE test 2.377449305792713\n",
      "Epoch 7799 / 10000 loss: 12.60053014755249\n",
      "MSE train 5.1144967964539125 MSE test 11.553593877029313\n",
      "MAE train 1.5543514032142411 MAE test 2.3774111576790498\n",
      "Epoch 7800 / 10000 loss: 12.60008430480957\n",
      "MSE train 5.1143761367966665 MSE test 11.553617461016238\n",
      "MAE train 1.5543265749856603 MAE test 2.3774199936133185\n",
      "Epoch 7801 / 10000 loss: 12.599757432937622\n",
      "MSE train 5.114262244609515 MSE test 11.553393295756107\n",
      "MAE train 1.5543094750386843 MAE test 2.377391147837252\n",
      "Epoch 7802 / 10000 loss: 12.599239110946655\n",
      "MSE train 5.114158912377714 MSE test 11.553367804593663\n",
      "MAE train 1.5542900275792513 MAE test 2.3773933066688713\n",
      "Epoch 7803 / 10000 loss: 12.598855972290039\n",
      "MSE train 5.114046498578572 MSE test 11.553085932113856\n",
      "MAE train 1.5542744316343573 MAE test 2.377356753731926\n",
      "Epoch 7804 / 10000 loss: 12.59843921661377\n",
      "MSE train 5.11393023086668 MSE test 11.553107409543271\n",
      "MAE train 1.554250790186549 MAE test 2.377365279791835\n",
      "Epoch 7805 / 10000 loss: 12.598105430603027\n",
      "MSE train 5.113815937100673 MSE test 11.552859427472818\n",
      "MAE train 1.5542340808609596 MAE test 2.3773332649636956\n",
      "Epoch 7806 / 10000 loss: 12.597605466842651\n",
      "MSE train 5.113713538197228 MSE test 11.55285914071653\n",
      "MAE train 1.55421437694986 MAE test 2.377338826536921\n",
      "Epoch 7807 / 10000 loss: 12.597239017486572\n",
      "MSE train 5.113600840739229 MSE test 11.552558074355362\n",
      "MAE train 1.5541990618276582 MAE test 2.377299683952901\n",
      "Epoch 7808 / 10000 loss: 12.596807956695557\n",
      "MSE train 5.113476742046238 MSE test 11.552582854645845\n",
      "MAE train 1.5541732938578703 MAE test 2.3773086894725286\n",
      "Epoch 7809 / 10000 loss: 12.59648871421814\n",
      "MSE train 5.113364186171981 MSE test 11.552376894944485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5541562013913814 MAE test 2.3772823097527502\n",
      "Epoch 7810 / 10000 loss: 12.595956802368164\n",
      "MSE train 5.113254648309973 MSE test 11.552324817331646\n",
      "MAE train 1.554135714825 MAE test 2.3772809178739456\n",
      "Epoch 7811 / 10000 loss: 12.595565557479858\n",
      "MSE train 5.113141450186751 MSE test 11.552087019533172\n",
      "MAE train 1.5541191099589335 MAE test 2.3772502821521075\n",
      "Epoch 7812 / 10000 loss: 12.595142841339111\n",
      "MSE train 5.113039392440808 MSE test 11.552082315815527\n",
      "MAE train 1.554099608678352 MAE test 2.3772552526743604\n",
      "Epoch 7813 / 10000 loss: 12.594771146774292\n",
      "MSE train 5.112927142492417 MSE test 11.551780378536392\n",
      "MAE train 1.5540844377432266 MAE test 2.377216000421073\n",
      "Epoch 7814 / 10000 loss: 12.594348669052124\n",
      "MSE train 5.11280199204224 MSE test 11.551805418152263\n",
      "MAE train 1.554058403378467 MAE test 2.3772250747081785\n",
      "Epoch 7815 / 10000 loss: 12.594030857086182\n",
      "MSE train 5.112689838034185 MSE test 11.55160333474304\n",
      "MAE train 1.5540413561188806 MAE test 2.3771992182778066\n",
      "Epoch 7816 / 10000 loss: 12.593494176864624\n",
      "MSE train 5.1125784346661085 MSE test 11.551543977228727\n",
      "MAE train 1.5540205402416558 MAE test 2.3771968588136825\n",
      "Epoch 7817 / 10000 loss: 12.59310269355774\n",
      "MSE train 5.11246515282613 MSE test 11.551318262491513\n",
      "MAE train 1.5540036897164071 MAE test 2.377167855284215\n",
      "Epoch 7818 / 10000 loss: 12.592675924301147\n",
      "MSE train 5.1123621631781475 MSE test 11.551300201700284\n",
      "MAE train 1.5539842374199002 MAE test 2.377171048116411\n",
      "Epoch 7819 / 10000 loss: 12.592296361923218\n",
      "MSE train 5.1122498128422 MSE test 11.551007617654703\n",
      "MAE train 1.5539688901542423 MAE test 2.3771330820631102\n",
      "Epoch 7820 / 10000 loss: 12.591878414154053\n",
      "MSE train 5.112128162705419 MSE test 11.551030433962767\n",
      "MAE train 1.5539438865239055 MAE test 2.377141857355942\n",
      "Epoch 7821 / 10000 loss: 12.591551303863525\n",
      "MSE train 5.11201354332504 MSE test 11.550804524436145\n",
      "MAE train 1.5539266916049257 MAE test 2.3771128292782833\n",
      "Epoch 7822 / 10000 loss: 12.591030359268188\n",
      "MSE train 5.111909388241932 MSE test 11.550777374069721\n",
      "MAE train 1.553907127740341 MAE test 2.3771148140647163\n",
      "Epoch 7823 / 10000 loss: 12.590645790100098\n",
      "MSE train 5.111796072172506 MSE test 11.55049237779443\n",
      "MAE train 1.5538914275547575 MAE test 2.3770778756201763\n",
      "Epoch 7824 / 10000 loss: 12.590226888656616\n",
      "MSE train 5.111678314142906 MSE test 11.550511317454108\n",
      "MAE train 1.5538675219318177 MAE test 2.3770861169857223\n",
      "Epoch 7825 / 10000 loss: 12.589890718460083\n",
      "MSE train 5.111562696224417 MSE test 11.550262074737118\n",
      "MAE train 1.553850589686674 MAE test 2.3770539800329797\n",
      "Epoch 7826 / 10000 loss: 12.58938717842102\n",
      "MSE train 5.111459098415515 MSE test 11.550256819184542\n",
      "MAE train 1.5538307746995441 MAE test 2.3770589295649542\n",
      "Epoch 7827 / 10000 loss: 12.589014768600464\n",
      "MSE train 5.111344789881059 MSE test 11.549951853635445\n",
      "MAE train 1.5538152407734713 MAE test 2.3770193413969567\n",
      "Epoch 7828 / 10000 loss: 12.588582992553711\n",
      "MSE train 5.111218577370278 MSE test 11.549972500296574\n",
      "MAE train 1.5537891444110041 MAE test 2.3770278644787113\n",
      "Epoch 7829 / 10000 loss: 12.588258266448975\n",
      "MSE train 5.111103888727586 MSE test 11.549762724411895\n",
      "MAE train 1.5537717413119467 MAE test 2.3770010516073348\n",
      "Epoch 7830 / 10000 loss: 12.587719917297363\n",
      "MSE train 5.110991394211055 MSE test 11.549703692456312\n",
      "MAE train 1.5537508147949197 MAE test 2.3769988132954296\n",
      "Epoch 7831 / 10000 loss: 12.587322473526001\n",
      "MSE train 5.11087505054914 MSE test 11.549462848084604\n",
      "MAE train 1.5537336976110534 MAE test 2.3769678771858813\n",
      "Epoch 7832 / 10000 loss: 12.58688998222351\n",
      "MSE train 5.110769382096892 MSE test 11.549448473054587\n",
      "MAE train 1.5537137183364536 MAE test 2.376971677637257\n",
      "Epoch 7833 / 10000 loss: 12.58650803565979\n",
      "MSE train 5.110652699220266 MSE test 11.549139895064673\n",
      "MAE train 1.5536978770816552 MAE test 2.376931674371067\n",
      "Epoch 7834 / 10000 loss: 12.586073637008667\n",
      "MSE train 5.110522346552913 MSE test 11.549155409012949\n",
      "MAE train 1.5536710973691095 MAE test 2.3769396210383316\n",
      "Epoch 7835 / 10000 loss: 12.585740327835083\n",
      "MSE train 5.11040284248581 MSE test 11.548939953523004\n",
      "MAE train 1.5536529420699579 MAE test 2.3769121776413678\n",
      "Epoch 7836 / 10000 loss: 12.585186958312988\n",
      "MSE train 5.110283504758167 MSE test 11.548871407729056\n",
      "MAE train 1.5536309422890138 MAE test 2.376908801428502\n",
      "Epoch 7837 / 10000 loss: 12.584770679473877\n",
      "MSE train 5.110158424162994 MSE test 11.548622612522653\n",
      "MAE train 1.553612422721024 MAE test 2.376876968954797\n",
      "Epoch 7838 / 10000 loss: 12.584314584732056\n",
      "MSE train 5.110040564782072 MSE test 11.548593110113964\n",
      "MAE train 1.5535905860430776 MAE test 2.376878948033824\n",
      "Epoch 7839 / 10000 loss: 12.583897352218628\n",
      "MSE train 5.109907059776494 MSE test 11.548269306882087\n",
      "MAE train 1.5535720533482653 MAE test 2.3768371679178033\n",
      "Epoch 7840 / 10000 loss: 12.583417415618896\n",
      "MSE train 5.109753902267346 MSE test 11.548263891730313\n",
      "MAE train 1.5535416162405182 MAE test 2.3768426158490126\n",
      "Epoch 7841 / 10000 loss: 12.583014726638794\n",
      "MSE train 5.109603962555586 MSE test 11.548020036495965\n",
      "MAE train 1.553518488203556 MAE test 2.3768117235126973\n",
      "Epoch 7842 / 10000 loss: 12.582369565963745\n",
      "MSE train 5.109453963403033 MSE test 11.547929611774972\n",
      "MAE train 1.5534913612105727 MAE test 2.376805796304272\n",
      "Epoch 7843 / 10000 loss: 12.581829309463501\n",
      "MSE train 5.10930907065682 MSE test 11.547651411111552\n",
      "MAE train 1.5534697536315856 MAE test 2.3767702524451106\n",
      "Epoch 7844 / 10000 loss: 12.581243753433228\n",
      "MSE train 5.1091925522098744 MSE test 11.547629088846822\n",
      "MAE train 1.5534478325606553 MAE test 2.3767730369507407\n",
      "Epoch 7845 / 10000 loss: 12.580751657485962\n",
      "MSE train 5.109077096000453 MSE test 11.547323854286283\n",
      "MAE train 1.5534321938275124 MAE test 2.376733240453282\n",
      "Epoch 7846 / 10000 loss: 12.580272912979126\n",
      "MSE train 5.108952433296642 MSE test 11.54735565120735\n",
      "MAE train 1.5534061502558658 MAE test 2.376742972409367\n",
      "Epoch 7847 / 10000 loss: 12.579943656921387\n",
      "MSE train 5.108841670293905 MSE test 11.547164811973886\n",
      "MAE train 1.5533891736218248 MAE test 2.3767183775413403\n",
      "Epoch 7848 / 10000 loss: 12.579404592514038\n",
      "MSE train 5.108731747800337 MSE test 11.547116530847827\n",
      "MAE train 1.5533684641163408 MAE test 2.37671727747255\n",
      "Epoch 7849 / 10000 loss: 12.579012870788574\n",
      "MSE train 5.108620200521957 MSE test 11.546904106598893\n",
      "MAE train 1.5533517072417027 MAE test 2.376689831704633\n",
      "Epoch 7850 / 10000 loss: 12.578588485717773\n",
      "MSE train 5.108518828108475 MSE test 11.546895910074788\n",
      "MAE train 1.5533324018276344 MAE test 2.3766941227806098\n",
      "Epoch 7851 / 10000 loss: 12.578208684921265\n",
      "MSE train 5.108408180863351 MSE test 11.546616403340485\n",
      "MAE train 1.5533171557630667 MAE test 2.376657700845428\n",
      "Epoch 7852 / 10000 loss: 12.57779335975647\n",
      "MSE train 5.108289210508188 MSE test 11.546649440094349\n",
      "MAE train 1.5532925519719534 MAE test 2.3766676078511852\n",
      "Epoch 7853 / 10000 loss: 12.577466487884521\n",
      "MSE train 5.108176307212715 MSE test 11.546429606950865\n",
      "MAE train 1.5532755908773572 MAE test 2.376639189120679\n",
      "Epoch 7854 / 10000 loss: 12.576952695846558\n",
      "MSE train 5.108075018958572 MSE test 11.546417733434293\n",
      "MAE train 1.5532563482645418 MAE test 2.3766430102229044\n",
      "Epoch 7855 / 10000 loss: 12.576572179794312\n",
      "MSE train 5.107963799888751 MSE test 11.546135960373118\n",
      "MAE train 1.5532409921954475 MAE test 2.376606311348931\n",
      "Epoch 7856 / 10000 loss: 12.576157093048096\n",
      "MSE train 5.107845187310292 MSE test 11.546166224505072\n",
      "MAE train 1.5532165155962503 MAE test 2.3766158676766636\n",
      "Epoch 7857 / 10000 loss: 12.575830221176147\n",
      "MSE train 5.107732077883449 MSE test 11.54594270101394\n",
      "MAE train 1.5531995757989348 MAE test 2.3765869855171244\n",
      "Epoch 7858 / 10000 loss: 12.575317144393921\n",
      "MSE train 5.107630987356184 MSE test 11.545930853636888\n",
      "MAE train 1.553180364850686 MAE test 2.3765908428866243\n",
      "Epoch 7859 / 10000 loss: 12.574939489364624\n",
      "MSE train 5.107519667181076 MSE test 11.545645534873573\n",
      "MAE train 1.5531650441593907 MAE test 2.3765536842584507\n",
      "Epoch 7860 / 10000 loss: 12.574524164199829\n",
      "MSE train 5.107400119324243 MSE test 11.545674754384082\n",
      "MAE train 1.5531403306930982 MAE test 2.376563133394909\n",
      "Epoch 7861 / 10000 loss: 12.574198961257935\n",
      "MSE train 5.107287150794358 MSE test 11.545454999725155\n",
      "MAE train 1.55312332659038 MAE test 2.37653478559344\n",
      "Epoch 7862 / 10000 loss: 12.573681831359863\n",
      "MSE train 5.1071851005144016 MSE test 11.545436232101046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5531040138554773 MAE test 2.3765377372075025\n",
      "Epoch 7863 / 10000 loss: 12.573300838470459\n",
      "MSE train 5.1070737339972645 MSE test 11.545157054414409\n",
      "MAE train 1.5530885637686893 MAE test 2.3765014259000656\n",
      "Epoch 7864 / 10000 loss: 12.572886228561401\n",
      "MSE train 5.106957394055893 MSE test 11.54518360053572\n",
      "MAE train 1.5530647157280704 MAE test 2.3765105251736998\n",
      "Epoch 7865 / 10000 loss: 12.572555780410767\n",
      "MSE train 5.106844026123573 MSE test 11.544945915396607\n",
      "MAE train 1.5530479842100309 MAE test 2.376479777812364\n",
      "Epoch 7866 / 10000 loss: 12.57205319404602\n",
      "MSE train 5.106743267849086 MSE test 11.544944902344334\n",
      "MAE train 1.5530286311389392 MAE test 2.3764851310713566\n",
      "Epoch 7867 / 10000 loss: 12.571683645248413\n",
      "MSE train 5.106631713489901 MSE test 11.544648683473826\n",
      "MAE train 1.5530134447165642 MAE test 2.3764465548175333\n",
      "Epoch 7868 / 10000 loss: 12.571260929107666\n",
      "MSE train 5.106508636142313 MSE test 11.5446775321307\n",
      "MAE train 1.5529877627636952 MAE test 2.3764560141936233\n",
      "Epoch 7869 / 10000 loss: 12.570942878723145\n",
      "MSE train 5.106397210006186 MSE test 11.54447660589239\n",
      "MAE train 1.5529707786377502 MAE test 2.376430215683304\n",
      "Epoch 7870 / 10000 loss: 12.570412874221802\n",
      "MSE train 5.106288580707459 MSE test 11.54442770807423\n",
      "MAE train 1.5529503840461605 MAE test 2.376429133286468\n",
      "Epoch 7871 / 10000 loss: 12.570023536682129\n",
      "MSE train 5.106176538222952 MSE test 11.544195864850227\n",
      "MAE train 1.5529338612498722 MAE test 2.376399205765428\n",
      "Epoch 7872 / 10000 loss: 12.569602251052856\n",
      "MSE train 5.10607564976335 MSE test 11.544193655092087\n",
      "MAE train 1.5529145201034764 MAE test 2.376404424506086\n",
      "Epoch 7873 / 10000 loss: 12.56923222541809\n",
      "MSE train 5.105964617846041 MSE test 11.54389705847184\n",
      "MAE train 1.5528994706419126 MAE test 2.3763658111202974\n",
      "Epoch 7874 / 10000 loss: 12.568812131881714\n",
      "MSE train 5.1058410118683195 MSE test 11.543925917750311\n",
      "MAE train 1.552873644390034 MAE test 2.3763752952632515\n",
      "Epoch 7875 / 10000 loss: 12.568495273590088\n",
      "MSE train 5.105729899735922 MSE test 11.543726794237841\n",
      "MAE train 1.5528566969810693 MAE test 2.3763497572016745\n",
      "Epoch 7876 / 10000 loss: 12.567963600158691\n",
      "MSE train 5.105620438582513 MSE test 11.543674066324757\n",
      "MAE train 1.552836156964867 MAE test 2.3763481931572508\n",
      "Epoch 7877 / 10000 loss: 12.56757378578186\n",
      "MSE train 5.105508468323875 MSE test 11.543448324290022\n",
      "MAE train 1.5528195243628147 MAE test 2.3763190939311842\n",
      "Epoch 7878 / 10000 loss: 12.567151546478271\n",
      "MSE train 5.105407499915113 MSE test 11.543439549810314\n",
      "MAE train 1.5528002812313466 MAE test 2.3763234467731262\n",
      "Epoch 7879 / 10000 loss: 12.566777229309082\n",
      "MSE train 5.105296575485619 MSE test 11.543146686357403\n",
      "MAE train 1.5527851764413048 MAE test 2.3762853443725755\n",
      "Epoch 7880 / 10000 loss: 12.56636095046997\n",
      "MSE train 5.1051745049600825 MSE test 11.543174800338951\n",
      "MAE train 1.5527597895149645 MAE test 2.376294719977833\n",
      "Epoch 7881 / 10000 loss: 12.566041946411133\n",
      "MSE train 5.105062363006188 MSE test 11.54296578698643\n",
      "MAE train 1.5527427542586274 MAE test 2.376267875437467\n",
      "Epoch 7882 / 10000 loss: 12.565515995025635\n",
      "MSE train 5.10495652901358 MSE test 11.542927417198413\n",
      "MAE train 1.5527228532214374 MAE test 2.3762682421536905\n",
      "Epoch 7883 / 10000 loss: 12.565129518508911\n",
      "MSE train 5.104844577427053 MSE test 11.542674272689096\n",
      "MAE train 1.5527067546505195 MAE test 2.3762354914754225\n",
      "Epoch 7884 / 10000 loss: 12.564711809158325\n",
      "MSE train 5.104739953488814 MSE test 11.542686934407048\n",
      "MAE train 1.5526861447997848 MAE test 2.3762427421110726\n",
      "Epoch 7885 / 10000 loss: 12.564358472824097\n",
      "MSE train 5.104628097917584 MSE test 11.542397523554797\n",
      "MAE train 1.5526707404417401 MAE test 2.3762051143427865\n",
      "Epoch 7886 / 10000 loss: 12.563910961151123\n",
      "MSE train 5.104508534977581 MSE test 11.542423356607417\n",
      "MAE train 1.5526460427219226 MAE test 2.376214172933788\n",
      "Epoch 7887 / 10000 loss: 12.563585758209229\n",
      "MSE train 5.104395419448081 MSE test 11.542200957571428\n",
      "MAE train 1.552629027071858 MAE test 2.376185542816636\n",
      "Epoch 7888 / 10000 loss: 12.56307077407837\n",
      "MSE train 5.104293294481272 MSE test 11.542179228603278\n",
      "MAE train 1.552609720202977 MAE test 2.376188153874648\n",
      "Epoch 7889 / 10000 loss: 12.562689781188965\n",
      "MSE train 5.1041817791033 MSE test 11.541898348008129\n",
      "MAE train 1.552594245594842 MAE test 2.376151682909917\n",
      "Epoch 7890 / 10000 loss: 12.562275409698486\n",
      "MSE train 5.104065590987437 MSE test 11.541922574799084\n",
      "MAE train 1.5525704455397193 MAE test 2.3761605095672063\n",
      "Epoch 7891 / 10000 loss: 12.561944484710693\n",
      "MSE train 5.1039521614602155 MSE test 11.541682180308172\n",
      "MAE train 1.5525537271935042 MAE test 2.3761294754611932\n",
      "Epoch 7892 / 10000 loss: 12.561443567276001\n",
      "MSE train 5.1038513160116015 MSE test 11.541679739788036\n",
      "MAE train 1.5525343396682392 MAE test 2.3761346722292926\n",
      "Epoch 7893 / 10000 loss: 12.56107497215271\n",
      "MSE train 5.103739641138703 MSE test 11.541382041213065\n",
      "MAE train 1.552519135463731 MAE test 2.3760959518661275\n",
      "Epoch 7894 / 10000 loss: 12.560652494430542\n",
      "MSE train 5.103616533040428 MSE test 11.541409175239579\n",
      "MAE train 1.5524934438429072 MAE test 2.376105202858099\n",
      "Epoch 7895 / 10000 loss: 12.5603346824646\n",
      "MSE train 5.103505018751048 MSE test 11.541206746917451\n",
      "MAE train 1.5524764389480772 MAE test 2.3760792581009476\n",
      "Epoch 7896 / 10000 loss: 12.55980396270752\n",
      "MSE train 5.103396443464632 MSE test 11.54115638059644\n",
      "MAE train 1.552456053768587 MAE test 2.3760780252023594\n",
      "Epoch 7897 / 10000 loss: 12.559415817260742\n",
      "MSE train 5.10328428665506 MSE test 11.54092330104032\n",
      "MAE train 1.5524395101954127 MAE test 2.376047974514616\n",
      "Epoch 7898 / 10000 loss: 12.558995246887207\n",
      "MSE train 5.10318339964361 MSE test 11.540919700791441\n",
      "MAE train 1.55242016410013 MAE test 2.3760530361947936\n",
      "Epoch 7899 / 10000 loss: 12.558624744415283\n",
      "MSE train 5.103072271447615 MSE test 11.540622011310148\n",
      "MAE train 1.5524050913789593 MAE test 2.3760143143082857\n",
      "Epoch 7900 / 10000 loss: 12.558205366134644\n",
      "MSE train 5.102948735384503 MSE test 11.54064973109524\n",
      "MAE train 1.5523792730761148 MAE test 2.3760236591125588\n",
      "Epoch 7901 / 10000 loss: 12.557889699935913\n",
      "MSE train 5.102837504454829 MSE test 11.540449167339727\n",
      "MAE train 1.5523623028036513 MAE test 2.3759979591754\n",
      "Epoch 7902 / 10000 loss: 12.5573570728302\n",
      "MSE train 5.102728199757343 MSE test 11.540395831759486\n",
      "MAE train 1.552341784611959 MAE test 2.37599633728294\n",
      "Epoch 7903 / 10000 loss: 12.556967973709106\n",
      "MSE train 5.102616112877153 MSE test 11.540167988994785\n",
      "MAE train 1.5523251520976462 MAE test 2.375966989996645\n",
      "Epoch 7904 / 10000 loss: 12.556546688079834\n",
      "MSE train 5.102515152412814 MSE test 11.540159335931934\n",
      "MAE train 1.5523058785355832 MAE test 2.3759713748297573\n",
      "Epoch 7905 / 10000 loss: 12.556174039840698\n",
      "MSE train 5.102404127701999 MSE test 11.539864804829456\n",
      "MAE train 1.552290772779383 MAE test 2.3759330831752226\n",
      "Epoch 7906 / 10000 loss: 12.55575704574585\n",
      "MSE train 5.102281667574403 MSE test 11.539891901863593\n",
      "MAE train 1.5522652634836067 MAE test 2.375942337963584\n",
      "Epoch 7907 / 10000 loss: 12.555439233779907\n",
      "MSE train 5.102169641573905 MSE test 11.539684184120615\n",
      "MAE train 1.5522482132489113 MAE test 2.3759156963894705\n",
      "Epoch 7908 / 10000 loss: 12.554911613464355\n",
      "MSE train 5.102062961874052 MSE test 11.539641624760018\n",
      "MAE train 1.5522281552741437 MAE test 2.375915500699591\n",
      "Epoch 7909 / 10000 loss: 12.554524660110474\n",
      "MSE train 5.10195087443469 MSE test 11.539393754012357\n",
      "MAE train 1.5522119049699576 MAE test 2.375883491057124\n",
      "Epoch 7910 / 10000 loss: 12.554105997085571\n",
      "MSE train 5.101847903652059 MSE test 11.53940154175371\n",
      "MAE train 1.5521917834546088 MAE test 2.375890075985179\n",
      "Epoch 7911 / 10000 loss: 12.553748369216919\n",
      "MSE train 5.1017362534840345 MSE test 11.539106055524128\n",
      "MAE train 1.552176534832226 MAE test 2.3758516647061687\n",
      "Epoch 7912 / 10000 loss: 12.553311109542847\n",
      "MSE train 5.101614082229078 MSE test 11.539132321792454\n",
      "MAE train 1.5521511028687842 MAE test 2.3758608003238035\n",
      "Epoch 7913 / 10000 loss: 12.55299162864685\n",
      "MSE train 5.1015019072381405 MSE test 11.538923336746743\n",
      "MAE train 1.552134027652405 MAE test 2.3758339884480364\n",
      "Epoch 7914 / 10000 loss: 12.55246615409851\n",
      "MSE train 5.10139547320039 MSE test 11.53888172250996\n",
      "MAE train 1.5521140172915235 MAE test 2.375833922399614\n",
      "Epoch 7915 / 10000 loss: 12.552079200744629\n",
      "MSE train 5.101283364039602 MSE test 11.538631422591479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5520978035249986 MAE test 2.3758015858373702\n",
      "Epoch 7916 / 10000 loss: 12.551661014556885\n",
      "MSE train 5.101179768057244 MSE test 11.53864058528002\n",
      "MAE train 1.552077493627306 MAE test 2.3758083610935365\n",
      "Epoch 7917 / 10000 loss: 12.551304340362549\n",
      "MSE train 5.101067988077143 MSE test 11.538346550189875\n",
      "MAE train 1.5520621727693478 MAE test 2.3757701446791324\n",
      "Epoch 7918 / 10000 loss: 12.550864696502686\n",
      "MSE train 5.100946683249192 MSE test 11.538372274813154\n",
      "MAE train 1.5520369714640332 MAE test 2.3757792065152032\n",
      "Epoch 7919 / 10000 loss: 12.550543069839478\n",
      "MSE train 5.100834042545678 MSE test 11.538158509249556\n",
      "MAE train 1.552019882167627 MAE test 2.3757517482188253\n",
      "Epoch 7920 / 10000 loss: 12.550021648406982\n",
      "MSE train 5.1007291884198915 MSE test 11.538123297462185\n",
      "MAE train 1.5520001276092918 MAE test 2.3757525518310447\n",
      "Epoch 7921 / 10000 loss: 12.549635648727417\n",
      "MSE train 5.100617250507993 MSE test 11.537861142612062\n",
      "MAE train 1.5519841899892362 MAE test 2.375718625914113\n",
      "Epoch 7922 / 10000 loss: 12.549219608306885\n",
      "MSE train 5.1005096368608225 MSE test 11.537876769027969\n",
      "MAE train 1.5519626987332886 MAE test 2.3757262759973936\n",
      "Epoch 7923 / 10000 loss: 12.548872470855713\n",
      "MSE train 5.100397108061875 MSE test 11.537597324682517\n",
      "MAE train 1.5519469316870198 MAE test 2.375690035388398\n",
      "Epoch 7924 / 10000 loss: 12.54841136932373\n",
      "MSE train 5.100282956679188 MSE test 11.53761823029248\n",
      "MAE train 1.551923659013025 MAE test 2.3756984100614815\n",
      "Epoch 7925 / 10000 loss: 12.548076391220093\n",
      "MSE train 5.100169301497834 MSE test 11.537367914133915\n",
      "MAE train 1.5519070518948777 MAE test 2.3756660652495247\n",
      "Epoch 7926 / 10000 loss: 12.547584772109985\n",
      "MSE train 5.100066978356416 MSE test 11.537371817677991\n",
      "MAE train 1.5518871297037646 MAE test 2.375672130942486\n",
      "Epoch 7927 / 10000 loss: 12.547222375869751\n",
      "MSE train 5.099954822151409 MSE test 11.537075240398167\n",
      "MAE train 1.5518717673549305 MAE test 2.3756335764438896\n",
      "Epoch 7928 / 10000 loss: 12.546789407730103\n",
      "MSE train 5.099832790741732 MSE test 11.537100488628564\n",
      "MAE train 1.551846361371598 MAE test 2.375642570023871\n",
      "Epoch 7929 / 10000 loss: 12.54646921157837\n",
      "MSE train 5.099720478493918 MSE test 11.536890644029121\n",
      "MAE train 1.5518292611820566 MAE test 2.3756156522755454\n",
      "Epoch 7930 / 10000 loss: 12.54594349861145\n",
      "MSE train 5.0996140986687655 MSE test 11.536848752337274\n",
      "MAE train 1.5518092376501393 MAE test 2.375615562150724\n",
      "Epoch 7931 / 10000 loss: 12.545557022094727\n",
      "MSE train 5.09950185830814 MSE test 11.536597242018637\n",
      "MAE train 1.5517930069148702 MAE test 2.3755830731586722\n",
      "Epoch 7932 / 10000 loss: 12.545139074325562\n",
      "MSE train 5.099397996309122 MSE test 11.536606228454916\n",
      "MAE train 1.5517726029282175 MAE test 2.3755898136287974\n",
      "Epoch 7933 / 10000 loss: 12.544782638549805\n",
      "MSE train 5.099286056905929 MSE test 11.536312729420661\n",
      "MAE train 1.5517572317457071 MAE test 2.375551686818975\n",
      "Epoch 7934 / 10000 loss: 12.544341564178467\n",
      "MSE train 5.099165044027506 MSE test 11.536337500106999\n",
      "MAE train 1.5517321054047437 MAE test 2.3755606219816956\n",
      "Epoch 7935 / 10000 loss: 12.544018983840942\n",
      "MSE train 5.09905218578452 MSE test 11.53612112688524\n",
      "MAE train 1.5517149875932656 MAE test 2.375532821225359\n",
      "Epoch 7936 / 10000 loss: 12.54349946975708\n",
      "MSE train 5.09894790839751 MSE test 11.536088315371963\n",
      "MAE train 1.5516953085457892 MAE test 2.3755339518120473\n",
      "Epoch 7937 / 10000 loss: 12.543115615844727\n",
      "MSE train 5.098835993639375 MSE test 11.535820907672932\n",
      "MAE train 1.5516794506809974 MAE test 2.3754993284934685\n",
      "Epoch 7938 / 10000 loss: 12.542699575424194\n",
      "MSE train 5.098726332492443 MSE test 11.535838147755845\n",
      "MAE train 1.5516573820897774 MAE test 2.3755072097722794\n",
      "Epoch 7939 / 10000 loss: 12.54235577583313\n",
      "MSE train 5.098613386296884 MSE test 11.53556620127065\n",
      "MAE train 1.5516413587358902 MAE test 2.3754719881267916\n",
      "Epoch 7940 / 10000 loss: 12.541885614395142\n",
      "MSE train 5.0985030286440045 MSE test 11.53558313076732\n",
      "MAE train 1.551619097375108 MAE test 2.3754798182226438\n",
      "Epoch 7941 / 10000 loss: 12.541542291641235\n",
      "MSE train 5.098389701735473 MSE test 11.535314954296416\n",
      "MAE train 1.5516029115198642 MAE test 2.3754450942762944\n",
      "Epoch 7942 / 10000 loss: 12.541067838668823\n",
      "MSE train 5.09828131869458 MSE test 11.535329291365349\n",
      "MAE train 1.551581198210595 MAE test 2.3754525806472717\n",
      "Epoch 7943 / 10000 loss: 12.54072093963623\n",
      "MSE train 5.098168177736627 MSE test 11.535052908367067\n",
      "MAE train 1.5515651974061306 MAE test 2.3754167597111135\n",
      "Epoch 7944 / 10000 loss: 12.540256261825562\n",
      "MSE train 5.098056138482994 MSE test 11.535070889174968\n",
      "MAE train 1.551542482343759 MAE test 2.3754247407004185\n",
      "Epoch 7945 / 10000 loss: 12.539915800094604\n",
      "MSE train 5.097942486969483 MSE test 11.534809974530754\n",
      "MAE train 1.5515260675500993 MAE test 2.3753909924765746\n",
      "Epoch 7946 / 10000 loss: 12.53943395614624\n",
      "MSE train 5.09783710902327 MSE test 11.534819755191656\n",
      "MAE train 1.5515052064860295 MAE test 2.3753978674342697\n",
      "Epoch 7947 / 10000 loss: 12.539078950881958\n",
      "MSE train 5.097724390226169 MSE test 11.534531698352543\n",
      "MAE train 1.5514895156106765 MAE test 2.3753604887043487\n",
      "Epoch 7948 / 10000 loss: 12.53863000869751\n",
      "MSE train 5.097606612697007 MSE test 11.534553494190478\n",
      "MAE train 1.5514652545737173 MAE test 2.375369002513834\n",
      "Epoch 7949 / 10000 loss: 12.538300275802612\n",
      "MSE train 5.097492809653635 MSE test 11.534319021200396\n",
      "MAE train 1.5514482594951076 MAE test 2.37533880043762\n",
      "Epoch 7950 / 10000 loss: 12.537793159484863\n",
      "MSE train 5.097391755684593 MSE test 11.53430609207974\n",
      "MAE train 1.551428943604828 MAE test 2.375342606751604\n",
      "Epoch 7951 / 10000 loss: 12.537417888641357\n",
      "MSE train 5.09727985490276 MSE test 11.534011108841964\n",
      "MAE train 1.5514135769783806 MAE test 2.375304292655987\n",
      "Epoch 7952 / 10000 loss: 12.537000894546509\n",
      "MSE train 5.097158113717684 MSE test 11.534035259378342\n",
      "MAE train 1.5513882351629382 MAE test 2.375313160795109\n",
      "Epoch 7953 / 10000 loss: 12.536679744720459\n",
      "MSE train 5.097045325315197 MSE test 11.533821095705505\n",
      "MAE train 1.5513710572154071 MAE test 2.375285666211512\n",
      "Epoch 7954 / 10000 loss: 12.536155939102173\n",
      "MSE train 5.096940009024145 MSE test 11.533783276250276\n",
      "MAE train 1.5513511731488405 MAE test 2.3752861427897116\n",
      "Epoch 7955 / 10000 loss: 12.535770416259766\n",
      "MSE train 5.0968277367926484 MSE test 11.533521562529288\n",
      "MAE train 1.5513350824495853 MAE test 2.375252304269935\n",
      "Epoch 7956 / 10000 loss: 12.535353422164917\n",
      "MSE train 5.096720534473418 MSE test 11.533534474602474\n",
      "MAE train 1.5513136846444067 MAE test 2.3752596065325937\n",
      "Epoch 7957 / 10000 loss: 12.535003900527954\n",
      "MSE train 5.096607704283346 MSE test 11.533250993851999\n",
      "MAE train 1.5512978654467573 MAE test 2.3752228494701204\n",
      "Epoch 7958 / 10000 loss: 12.534546136856079\n",
      "MSE train 5.096491954761789 MSE test 11.533271093478541\n",
      "MAE train 1.551274121806698 MAE test 2.3752311548529645\n",
      "Epoch 7959 / 10000 loss: 12.534212112426758\n",
      "MSE train 5.096377863982045 MSE test 11.533025670458553\n",
      "MAE train 1.551257258942677 MAE test 2.3751994851028235\n",
      "Epoch 7960 / 10000 loss: 12.533713340759277\n",
      "MSE train 5.0962763060822684 MSE test 11.533022172475112\n",
      "MAE train 1.5512375850669646 MAE test 2.3752045898362755\n",
      "Epoch 7961 / 10000 loss: 12.533345222473145\n",
      "MSE train 5.09616403796688 MSE test 11.532722228432988\n",
      "MAE train 1.5512221803300008 MAE test 2.3751655969572134\n",
      "Epoch 7962 / 10000 loss: 12.532918930053711\n",
      "MSE train 5.0960406139953935 MSE test 11.532745990672273\n",
      "MAE train 1.551196349644314 MAE test 2.375174438549073\n",
      "Epoch 7963 / 10000 loss: 12.532599687576294\n",
      "MSE train 5.095928478675644 MSE test 11.532539970770523\n",
      "MAE train 1.551179147959893 MAE test 2.375148051784379\n",
      "Epoch 7964 / 10000 loss: 12.532069206237793\n",
      "MSE train 5.095819634413983 MSE test 11.532487636342589\n",
      "MAE train 1.5511586119626732 MAE test 2.3751465990820493\n",
      "Epoch 7965 / 10000 loss: 12.531678676605225\n",
      "MSE train 5.095706859716954 MSE test 11.532249579478984\n",
      "MAE train 1.5511419014890517 MAE test 2.3751159378327498\n",
      "Epoch 7966 / 10000 loss: 12.531257629394531\n",
      "MSE train 5.095605264659311 MSE test 11.532244594061718\n",
      "MAE train 1.5511222494584738 MAE test 2.375120846561283\n",
      "Epoch 7967 / 10000 loss: 12.530887365341187\n",
      "MSE train 5.095493344564638 MSE test 11.531943617024922\n",
      "MAE train 1.5511069221580644 MAE test 2.375081748549668\n",
      "Epoch 7968 / 10000 loss: 12.530464172363281\n",
      "MSE train 5.095369007748392 MSE test 11.531967417097421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.551080820966944 MAE test 2.375090602241947\n",
      "Epoch 7969 / 10000 loss: 12.53014612197876\n",
      "MSE train 5.095257115093809 MSE test 11.531764683444496\n",
      "MAE train 1.5510635911870843 MAE test 2.3750646726110833\n",
      "Epoch 7970 / 10000 loss: 12.529611587524414\n",
      "MSE train 5.095146732915492 MSE test 11.531706155216176\n",
      "MAE train 1.5510427386130625 MAE test 2.3750624015927566\n",
      "Epoch 7971 / 10000 loss: 12.52921986579895\n",
      "MSE train 5.095033817457989 MSE test 11.531477746214122\n",
      "MAE train 1.5510257513598775 MAE test 2.375033042245858\n",
      "Epoch 7972 / 10000 loss: 12.528795957565308\n",
      "MSE train 5.09493173316144 MSE test 11.531461980792114\n",
      "MAE train 1.5510061625631044 MAE test 2.3750365148936106\n",
      "Epoch 7973 / 10000 loss: 12.528417825698853\n",
      "MSE train 5.094819778261865 MSE test 11.531166886579213\n",
      "MAE train 1.5509906591991667 MAE test 2.3749982243277574\n",
      "Epoch 7974 / 10000 loss: 12.528000354766846\n",
      "MSE train 5.094697563169568 MSE test 11.531189019722742\n",
      "MAE train 1.5509651337311192 MAE test 2.3750068681646335\n",
      "Epoch 7975 / 10000 loss: 12.52767539024353\n",
      "MSE train 5.094583837489956 MSE test 11.53097064146764\n",
      "MAE train 1.5509476803951345 MAE test 2.374978873728982\n",
      "Epoch 7976 / 10000 loss: 12.527149677276611\n",
      "MSE train 5.094478324354058 MSE test 11.530933096274412\n",
      "MAE train 1.5509276100896316 MAE test 2.374979426388621\n",
      "Epoch 7977 / 10000 loss: 12.526761054992676\n",
      "MSE train 5.094365200760369 MSE test 11.53066394784536\n",
      "MAE train 1.5509113027488588 MAE test 2.374944644147068\n",
      "Epoch 7978 / 10000 loss: 12.526341438293457\n",
      "MSE train 5.094255055049076 MSE test 11.530676192479282\n",
      "MAE train 1.5508890188052031 MAE test 2.374951922483736\n",
      "Epoch 7979 / 10000 loss: 12.525991916656494\n",
      "MSE train 5.094140873699075 MSE test 11.530397630278078\n",
      "MAE train 1.550872586529477 MAE test 2.3749158931399297\n",
      "Epoch 7980 / 10000 loss: 12.525519371032715\n",
      "MSE train 5.094027730527603 MSE test 11.530411118298211\n",
      "MAE train 1.5508494765827094 MAE test 2.374923356919559\n",
      "Epoch 7981 / 10000 loss: 12.52517318725586\n",
      "MSE train 5.093912627815159 MSE test 11.53014433842332\n",
      "MAE train 1.5508325684346662 MAE test 2.3748889208593336\n",
      "Epoch 7982 / 10000 loss: 12.524686574935913\n",
      "MSE train 5.093804930880325 MSE test 11.530150188727431\n",
      "MAE train 1.5508109445914957 MAE test 2.3748953487917186\n",
      "Epoch 7983 / 10000 loss: 12.524327039718628\n",
      "MSE train 5.093690244767149 MSE test 11.529859626387843\n",
      "MAE train 1.5507945287660811 MAE test 2.3748577370276633\n",
      "Epoch 7984 / 10000 loss: 12.523866653442383\n",
      "MSE train 5.093571614090813 MSE test 11.529875059922645\n",
      "MAE train 1.5507698863154475 MAE test 2.374865503785324\n",
      "Epoch 7985 / 10000 loss: 12.523526668548584\n",
      "MSE train 5.0934554272083 MSE test 11.529629204596322\n",
      "MAE train 1.550752196446544 MAE test 2.3748338873467065\n",
      "Epoch 7986 / 10000 loss: 12.523016214370728\n",
      "MSE train 5.093351948356819 MSE test 11.529615702069496\n",
      "MAE train 1.5507319239144484 MAE test 2.374837731948343\n",
      "Epoch 7987 / 10000 loss: 12.522634506225586\n",
      "MSE train 5.093237056015281 MSE test 11.529310864999713\n",
      "MAE train 1.550715597329986 MAE test 2.3747982560626517\n",
      "Epoch 7988 / 10000 loss: 12.522202730178833\n",
      "MSE train 5.093110952198469 MSE test 11.529327984949601\n",
      "MAE train 1.5506888444002007 MAE test 2.3748063015707195\n",
      "Epoch 7989 / 10000 loss: 12.521869897842407\n",
      "MSE train 5.092995196577349 MSE test 11.529113496358987\n",
      "MAE train 1.5506704591967533 MAE test 2.3747789529082786\n",
      "Epoch 7990 / 10000 loss: 12.521327257156372\n",
      "MSE train 5.09288318346186 MSE test 11.529056109799642\n",
      "MAE train 1.5506487449102124 MAE test 2.3747769486308927\n",
      "Epoch 7991 / 10000 loss: 12.520921230316162\n",
      "MSE train 5.092765989166734 MSE test 11.528804906672958\n",
      "MAE train 1.5506306184551286 MAE test 2.3747447117645364\n",
      "Epoch 7992 / 10000 loss: 12.52048397064209\n",
      "MSE train 5.0926588144740546 MSE test 11.528794739461839\n",
      "MAE train 1.5506090431065969 MAE test 2.374749092065559\n",
      "Epoch 7993 / 10000 loss: 12.520097494125366\n",
      "MSE train 5.092540787405321 MSE test 11.528483904747045\n",
      "MAE train 1.5505916495329315 MAE test 2.3747088944329406\n",
      "Epoch 7994 / 10000 loss: 12.51964545249939\n",
      "MSE train 5.092409787072275 MSE test 11.528496366923642\n",
      "MAE train 1.5505632552357098 MAE test 2.3747164459150762\n",
      "Epoch 7995 / 10000 loss: 12.51930022239685\n",
      "MSE train 5.092289672539669 MSE test 11.528280566724456\n",
      "MAE train 1.5505432417937564 MAE test 2.374689053170099\n",
      "Epoch 7996 / 10000 loss: 12.518734455108643\n",
      "MSE train 5.092169808881629 MSE test 11.528209101342886\n",
      "MAE train 1.5505191279469845 MAE test 2.37468531389344\n",
      "Epoch 7997 / 10000 loss: 12.518305778503418\n",
      "MSE train 5.092045199219598 MSE test 11.527963738080894\n",
      "MAE train 1.5504981802447728 MAE test 2.3746540409633483\n",
      "Epoch 7998 / 10000 loss: 12.517837524414062\n",
      "MSE train 5.091929138379278 MSE test 11.527931980635568\n",
      "MAE train 1.5504737393351986 MAE test 2.374655726079506\n",
      "Epoch 7999 / 10000 loss: 12.517406940460205\n",
      "MSE train 5.091799731989051 MSE test 11.52761556252448\n",
      "MAE train 1.5504522236285845 MAE test 2.37461502823824\n",
      "Epoch 8000 / 10000 loss: 12.516923189163208\n",
      "MSE train 5.091655158115496 MSE test 11.527614902689095\n",
      "MAE train 1.550418997845698 MAE test 2.374621054765272\n",
      "Epoch 8001 / 10000 loss: 12.516518115997314\n",
      "MSE train 5.091514314560989 MSE test 11.527373787524185\n",
      "MAE train 1.5503919775642838 MAE test 2.374590604136523\n",
      "Epoch 8002 / 10000 loss: 12.515890121459961\n",
      "MSE train 5.091372702392126 MSE test 11.527300869369975\n",
      "MAE train 1.5503594601519197 MAE test 2.374587041151609\n",
      "Epoch 8003 / 10000 loss: 12.515373229980469\n",
      "MSE train 5.091214519826129 MSE test 11.527005010801673\n",
      "MAE train 1.5503269838653166 MAE test 2.3745495120271576\n",
      "Epoch 8004 / 10000 loss: 12.514789342880249\n",
      "MSE train 5.091050092319995 MSE test 11.526972288737998\n",
      "MAE train 1.5502848500173265 MAE test 2.374551637505957\n",
      "Epoch 8005 / 10000 loss: 12.514223337173462\n",
      "MSE train 5.090864527064278 MSE test 11.52663540389189\n",
      "MAE train 1.5502423711527875 MAE test 2.374508900738873\n",
      "Epoch 8006 / 10000 loss: 12.513499021530151\n",
      "MSE train 5.090660025880199 MSE test 11.526602932295843\n",
      "MAE train 1.5501854535443067 MAE test 2.3745113070477846\n",
      "Epoch 8007 / 10000 loss: 12.512826442718506\n",
      "MSE train 5.09045332227767 MSE test 11.526313845002196\n",
      "MAE train 1.5501329264379244 MAE test 2.374475108757374\n",
      "Epoch 8008 / 10000 loss: 12.511911869049072\n",
      "MSE train 5.090265497389011 MSE test 11.526247668224725\n",
      "MAE train 1.5500792392914287 MAE test 2.3744728462947613\n",
      "Epoch 8009 / 10000 loss: 12.511096000671387\n",
      "MSE train 5.09008419522666 MSE test 11.525911168632062\n",
      "MAE train 1.550035880893453 MAE test 2.374429877982611\n",
      "Epoch 8010 / 10000 loss: 12.510266542434692\n",
      "MSE train 5.089913045472781 MSE test 11.525904102274133\n",
      "MAE train 1.5499907150842462 MAE test 2.3744349903866055\n",
      "Epoch 8011 / 10000 loss: 12.509613275527954\n",
      "MSE train 5.089765729021081 MSE test 11.5256690527951\n",
      "MAE train 1.5499601070035345 MAE test 2.374404985812327\n",
      "Epoch 8012 / 10000 loss: 12.508854866027832\n",
      "MSE train 5.089636879740304 MSE test 11.525622806564174\n",
      "MAE train 1.5499312848368096 MAE test 2.3744042683185813\n",
      "Epoch 8013 / 10000 loss: 12.50830864906311\n",
      "MSE train 5.089506984713165 MSE test 11.525352551281877\n",
      "MAE train 1.549909080174381 MAE test 2.3743692059567825\n",
      "Epoch 8014 / 10000 loss: 12.507783651351929\n",
      "MSE train 5.089384763274062 MSE test 11.525366291674965\n",
      "MAE train 1.5498827915083568 MAE test 2.3743763605785406\n",
      "Epoch 8015 / 10000 loss: 12.50735878944397\n",
      "MSE train 5.089261200273424 MSE test 11.525091519270228\n",
      "MAE train 1.549863443499708 MAE test 2.3743405923607988\n",
      "Epoch 8016 / 10000 loss: 12.506836652755737\n",
      "MSE train 5.089140149690131 MSE test 11.525111922652254\n",
      "MAE train 1.549837978436209 MAE test 2.374348598804333\n",
      "Epoch 8017 / 10000 loss: 12.506453275680542\n",
      "MSE train 5.089019306883102 MSE test 11.524855984565662\n",
      "MAE train 1.5498194068531845 MAE test 2.3743153199012497\n",
      "Epoch 8018 / 10000 loss: 12.505936622619629\n",
      "MSE train 5.0889080382036855 MSE test 11.524868668268892\n",
      "MAE train 1.549796885348043 MAE test 2.374322251720962\n",
      "Epoch 8019 / 10000 loss: 12.505555391311646\n",
      "MSE train 5.088790007868831 MSE test 11.524584791391787\n",
      "MAE train 1.5497797377977254 MAE test 2.374285240435247\n",
      "Epoch 8020 / 10000 loss: 12.505085229873657\n",
      "MSE train 5.088667140462987 MSE test 11.524611251988317\n",
      "MAE train 1.5497541202317506 MAE test 2.3742940693447645\n",
      "Epoch 8021 / 10000 loss: 12.504738330841064\n",
      "MSE train 5.088549223825152 MSE test 11.52438486158441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5497359860704427 MAE test 2.374264774884669\n",
      "Epoch 8022 / 10000 loss: 12.504214763641357\n",
      "MSE train 5.088444326498666 MSE test 11.524373953911482\n",
      "MAE train 1.5497157467034992 MAE test 2.3742685308921048\n",
      "Epoch 8023 / 10000 loss: 12.503825426101685\n",
      "MSE train 5.088329135405737 MSE test 11.524087321182837\n",
      "MAE train 1.5496994793440901 MAE test 2.3742311646172176\n",
      "Epoch 8024 / 10000 loss: 12.503397941589355\n",
      "MSE train 5.088205609668051 MSE test 11.524115819256247\n",
      "MAE train 1.549673725750975 MAE test 2.3742403031053976\n",
      "Epoch 8025 / 10000 loss: 12.503065824508667\n",
      "MSE train 5.088089723975338 MSE test 11.523901329744284\n",
      "MAE train 1.549655892286934 MAE test 2.374212623385334\n",
      "Epoch 8026 / 10000 loss: 12.502539157867432\n",
      "MSE train 5.087983886141765 MSE test 11.523876419355277\n",
      "MAE train 1.5496357642123737 MAE test 2.374214518870318\n",
      "Epoch 8027 / 10000 loss: 12.5021493434906\n",
      "MSE train 5.087869734567226 MSE test 11.52360739349158\n",
      "MAE train 1.5496194381179837 MAE test 2.3741795313679748\n",
      "Epoch 8028 / 10000 loss: 12.501729488372803\n",
      "MSE train 5.087755172737834 MSE test 11.523630723992822\n",
      "MAE train 1.5495961036051042 MAE test 2.3741879811588253\n",
      "Epoch 8029 / 10000 loss: 12.50138545036316\n",
      "MSE train 5.08763988411604 MSE test 11.523375950470097\n",
      "MAE train 1.54957923876507 MAE test 2.3741549105310176\n",
      "Epoch 8030 / 10000 loss: 12.500898599624634\n",
      "MSE train 5.087533192837226 MSE test 11.523388921056434\n",
      "MAE train 1.5495580637197597 MAE test 2.374161949975912\n",
      "Epoch 8031 / 10000 loss: 12.500540256500244\n",
      "MSE train 5.087419032244719 MSE test 11.523104800693496\n",
      "MAE train 1.549542002710809 MAE test 2.374124959331019\n",
      "Epoch 8032 / 10000 loss: 12.500088930130005\n",
      "MSE train 5.087299595340383 MSE test 11.523130169564604\n",
      "MAE train 1.549517314648123 MAE test 2.374133708233539\n",
      "Epoch 8033 / 10000 loss: 12.49975872039795\n",
      "MSE train 5.087184641008922 MSE test 11.522902502934025\n",
      "MAE train 1.5494999594679308 MAE test 2.374104283735779\n",
      "Epoch 8034 / 10000 loss: 12.49924921989441\n",
      "MSE train 5.087082324369943 MSE test 11.522890169267145\n",
      "MAE train 1.549480384400973 MAE test 2.3741079138198353\n",
      "Epoch 8035 / 10000 loss: 12.498871326446533\n",
      "MSE train 5.086969516125113 MSE test 11.522602004565874\n",
      "MAE train 1.549464709496181 MAE test 2.3740703951021067\n",
      "Epoch 8036 / 10000 loss: 12.498456001281738\n",
      "MSE train 5.086848011266364 MSE test 11.522628763242777\n",
      "MAE train 1.5494394653785801 MAE test 2.37407936681961\n",
      "Epoch 8037 / 10000 loss: 12.498132705688477\n",
      "MSE train 5.086734102730528 MSE test 11.52241293095986\n",
      "MAE train 1.549422093710402 MAE test 2.3740515493464525\n",
      "Epoch 8038 / 10000 loss: 12.49761438369751\n",
      "MSE train 5.086629913311781 MSE test 11.522385809610032\n",
      "MAE train 1.5494023603477778 MAE test 2.374053184321011\n",
      "Epoch 8039 / 10000 loss: 12.497232437133789\n",
      "MSE train 5.086517315229776 MSE test 11.522115966775587\n",
      "MAE train 1.549386398862575 MAE test 2.374018145012344\n",
      "Epoch 8040 / 10000 loss: 12.49681806564331\n",
      "MSE train 5.086404430380973 MSE test 11.52213741051779\n",
      "MAE train 1.5493634645040455 MAE test 2.374026376462809\n",
      "Epoch 8041 / 10000 loss: 12.496479988098145\n",
      "MSE train 5.086290452095127 MSE test 11.521880218736444\n",
      "MAE train 1.549346928716239 MAE test 2.3739930249168113\n",
      "Epoch 8042 / 10000 loss: 12.495998859405518\n",
      "MSE train 5.0861844323527965 MSE test 11.521892679111602\n",
      "MAE train 1.5493258922624524 MAE test 2.3740000247570183\n",
      "Epoch 8043 / 10000 loss: 12.495646476745605\n",
      "MSE train 5.086071351534991 MSE test 11.521609029310001\n",
      "MAE train 1.5493100543089948 MAE test 2.3739631335503395\n",
      "Epoch 8044 / 10000 loss: 12.495198488235474\n",
      "MSE train 5.08595365834045 MSE test 11.521633110778206\n",
      "MAE train 1.5492858112232928 MAE test 2.3739717357570136\n",
      "Epoch 8045 / 10000 loss: 12.494869709014893\n",
      "MSE train 5.0858395231844575 MSE test 11.521400703810542\n",
      "MAE train 1.5492687303017583 MAE test 2.373941715187924\n",
      "Epoch 8046 / 10000 loss: 12.494367837905884\n",
      "MSE train 5.085738323669751 MSE test 11.521391799791436\n",
      "MAE train 1.5492493405659968 MAE test 2.3739458265407576\n",
      "Epoch 8047 / 10000 loss: 12.493995904922485\n",
      "MSE train 5.085626197409064 MSE test 11.521099731590285\n",
      "MAE train 1.5492338881582703 MAE test 2.373907804708214\n",
      "Epoch 8048 / 10000 loss: 12.493579864501953\n",
      "MSE train 5.0855041591215775 MSE test 11.521126611195296\n",
      "MAE train 1.5492084500544707 MAE test 2.3739168142934366\n",
      "Epoch 8049 / 10000 loss: 12.493262529373169\n",
      "MSE train 5.0853914518345515 MSE test 11.520917966370165\n",
      "MAE train 1.549191217628038 MAE test 2.3738899815297483\n",
      "Epoch 8050 / 10000 loss: 12.492740392684937\n",
      "MSE train 5.0852855025371975 MSE test 11.520880264661848\n",
      "MAE train 1.549171228791092 MAE test 2.3738902418187964\n",
      "Epoch 8051 / 10000 loss: 12.49235725402832\n",
      "MSE train 5.08517319959251 MSE test 11.520627550955137\n",
      "MAE train 1.549155000969189 MAE test 2.373857516135657\n",
      "Epoch 8052 / 10000 loss: 12.491943597793579\n",
      "MSE train 5.0850679093785995 MSE test 11.520640520634654\n",
      "MAE train 1.549134143967442 MAE test 2.373864598907355\n",
      "Epoch 8053 / 10000 loss: 12.49159288406372\n",
      "MSE train 5.084955596806209 MSE test 11.520354962619821\n",
      "MAE train 1.5491185286337181 MAE test 2.3738274710691356\n",
      "Epoch 8054 / 10000 loss: 12.491147756576538\n",
      "MSE train 5.084836933572977 MSE test 11.520380024802732\n",
      "MAE train 1.5490939983352705 MAE test 2.3738362310098555\n",
      "Epoch 8055 / 10000 loss: 12.49082326889038\n",
      "MSE train 5.08472335168835 MSE test 11.520154733668058\n",
      "MAE train 1.5490768946729137 MAE test 2.3738071713113214\n",
      "Epoch 8056 / 10000 loss: 12.490315914154053\n",
      "MSE train 5.084621916948918 MSE test 11.520138561247913\n",
      "MAE train 1.5490575978730479 MAE test 2.373810326887951\n",
      "Epoch 8057 / 10000 loss: 12.489940881729126\n",
      "MSE train 5.084510276389538 MSE test 11.519853420102436\n",
      "MAE train 1.5490421252913933 MAE test 2.373773258787808\n",
      "Epoch 8058 / 10000 loss: 12.489529371261597\n",
      "MSE train 5.084391340101581 MSE test 11.519879167639308\n",
      "MAE train 1.549017520924936 MAE test 2.373782105147061\n",
      "Epoch 8059 / 10000 loss: 12.489206790924072\n",
      "MSE train 5.084277950339595 MSE test 11.519655351069515\n",
      "MAE train 1.549000436778983 MAE test 2.3737532583286556\n",
      "Epoch 8060 / 10000 loss: 12.48869800567627\n",
      "MSE train 5.084176458914379 MSE test 11.519637910580691\n",
      "MAE train 1.5489811523973778 MAE test 2.3737562410687656\n",
      "Epoch 8061 / 10000 loss: 12.488322734832764\n",
      "MSE train 5.0840649144290335 MSE test 11.519354601249278\n",
      "MAE train 1.548965673034328 MAE test 2.3737194200551923\n",
      "Epoch 8062 / 10000 loss: 12.48791217803955\n",
      "MSE train 5.083946743949688 MSE test 11.51938001752453\n",
      "MAE train 1.548941279263503 MAE test 2.3737282231007244\n",
      "Epoch 8063 / 10000 loss: 12.48758864402771\n",
      "MSE train 5.083833450719294 MSE test 11.519152471121089\n",
      "MAE train 1.5489242876463862 MAE test 2.3736988769495513\n",
      "Epoch 8064 / 10000 loss: 12.487083673477173\n",
      "MSE train 5.083732564536652 MSE test 11.51913937387546\n",
      "MAE train 1.5489050604493773 MAE test 2.373702442906679\n",
      "Epoch 8065 / 10000 loss: 12.486711025238037\n",
      "MSE train 5.083621103832478 MSE test 11.518851422552693\n",
      "MAE train 1.5488896805325338 MAE test 2.373665000592499\n",
      "Epoch 8066 / 10000 loss: 12.48629879951477\n",
      "MSE train 5.08350098602887 MSE test 11.518877638349096\n",
      "MAE train 1.5488647523462127 MAE test 2.3736739195426404\n",
      "Epoch 8067 / 10000 loss: 12.485979080200195\n",
      "MSE train 5.083388196356842 MSE test 11.518661371947722\n",
      "MAE train 1.5488476353340002 MAE test 2.37364609079895\n",
      "Epoch 8068 / 10000 loss: 12.48546576499939\n",
      "MSE train 5.083285278720678 MSE test 11.518634922370873\n",
      "MAE train 1.5488281884899198 MAE test 2.3736478603095166\n",
      "Epoch 8069 / 10000 loss: 12.485086917877197\n",
      "MSE train 5.0831736929416556 MSE test 11.518364231897191\n",
      "MAE train 1.548812458631024 MAE test 2.373612743629377\n",
      "Epoch 8070 / 10000 loss: 12.484676361083984\n",
      "MSE train 5.083061454828061 MSE test 11.518385965354419\n",
      "MAE train 1.5487896503032887 MAE test 2.3736210199984464\n",
      "Epoch 8071 / 10000 loss: 12.484342575073242\n",
      "MSE train 5.082948441151761 MSE test 11.51813105134808\n",
      "MAE train 1.5487732714219145 MAE test 2.373588017466578\n",
      "Epoch 8072 / 10000 loss: 12.483862400054932\n",
      "MSE train 5.082844113279835 MSE test 11.518142291383148\n",
      "MAE train 1.5487526607562132 MAE test 2.37359486102394\n",
      "Epoch 8073 / 10000 loss: 12.483510494232178\n",
      "MSE train 5.0827319302634715 MSE test 11.51785674186085\n",
      "MAE train 1.5487370594206238 MAE test 2.3735577499385077\n",
      "Epoch 8074 / 10000 loss: 12.483068943023682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.0826139674690385 MSE test 11.51788153816948\n",
      "MAE train 1.548712703624114 MAE test 2.3735664577645554\n",
      "Epoch 8075 / 10000 loss: 12.48274564743042\n",
      "MSE train 5.082500811022857 MSE test 11.517655644511633\n",
      "MAE train 1.5486956986029028 MAE test 2.373537338794384\n",
      "Epoch 8076 / 10000 loss: 12.482239723205566\n",
      "MSE train 5.082399914124605 MSE test 11.51764031260764\n",
      "MAE train 1.5486765138870904 MAE test 2.3735406005474533\n",
      "Epoch 8077 / 10000 loss: 12.481866121292114\n",
      "MSE train 5.082288665941093 MSE test 11.517354707444637\n",
      "MAE train 1.5486611292058008 MAE test 2.373503483350713\n",
      "Epoch 8078 / 10000 loss: 12.481456279754639\n",
      "MSE train 5.0821697549488025 MSE test 11.517380657260265\n",
      "MAE train 1.5486365243918758 MAE test 2.373512350152125\n",
      "Epoch 8079 / 10000 loss: 12.48113489151001\n",
      "MSE train 5.08205691816306 MSE test 11.517159104718033\n",
      "MAE train 1.5486194970127973 MAE test 2.373483820341171\n",
      "Epoch 8080 / 10000 loss: 12.480626106262207\n",
      "MSE train 5.081955429124276 MSE test 11.517139395035427\n",
      "MAE train 1.5486002662855516 MAE test 2.373486481346051\n",
      "Epoch 8081 / 10000 loss: 12.480249881744385\n",
      "MSE train 5.08184420729436 MSE test 11.516859301688713\n",
      "MAE train 1.5485847830398323 MAE test 2.373450108352522\n",
      "Epoch 8082 / 10000 loss: 12.479841232299805\n",
      "MSE train 5.081727780993244 MSE test 11.5168841477145\n",
      "MAE train 1.54856083868069 MAE test 2.3734588101843515\n",
      "Epoch 8083 / 10000 loss: 12.479515314102173\n",
      "MSE train 5.08161469498625 MSE test 11.51665016536349\n",
      "MAE train 1.548544017831754 MAE test 2.3734286217098046\n",
      "Epoch 8084 / 10000 loss: 12.479016780853271\n",
      "MSE train 5.081514459263099 MSE test 11.516644351196634\n",
      "MAE train 1.5485247986259787 MAE test 2.373433141870248\n",
      "Epoch 8085 / 10000 loss: 12.47864842414856\n",
      "MSE train 5.081403203743975 MSE test 11.51635131330076\n",
      "MAE train 1.5485095458347042 MAE test 2.373395038745533\n",
      "Epoch 8086 / 10000 loss: 12.478234767913818\n",
      "MSE train 5.081281429982798 MSE test 11.516378552560457\n",
      "MAE train 1.5484841361319817 MAE test 2.3734040823859233\n",
      "Epoch 8087 / 10000 loss: 12.477919816970825\n",
      "MSE train 5.08116983418732 MSE test 11.516174117130163\n",
      "MAE train 1.5484670703099153 MAE test 2.3733778371624874\n",
      "Epoch 8088 / 10000 loss: 12.47739839553833\n",
      "MSE train 5.081063488918467 MSE test 11.516131312473235\n",
      "MAE train 1.5484470633725966 MAE test 2.3733774129436873\n",
      "Epoch 8089 / 10000 loss: 12.477015733718872\n",
      "MSE train 5.080951746563123 MSE test 11.515888785722673\n",
      "MAE train 1.5484307640969839 MAE test 2.3733460768678714\n",
      "Epoch 8090 / 10000 loss: 12.476601839065552\n",
      "MSE train 5.080849897052173 MSE test 11.515895743660362\n",
      "MAE train 1.548410890773251 MAE test 2.373352331352124\n",
      "Epoch 8091 / 10000 loss: 12.476245403289795\n",
      "MSE train 5.080738766692295 MSE test 11.515602632062837\n",
      "MAE train 1.5483956661839846 MAE test 2.373314209304535\n",
      "Epoch 8092 / 10000 loss: 12.475818157196045\n",
      "MSE train 5.080616957139975 MSE test 11.515630051096206\n",
      "MAE train 1.5483702383891178 MAE test 2.3733232738072276\n",
      "Epoch 8093 / 10000 loss: 12.47550344467163\n",
      "MSE train 5.080505516254923 MSE test 11.515426367448887\n",
      "MAE train 1.5483531935721042 MAE test 2.37329713442789\n",
      "Epoch 8094 / 10000 loss: 12.47498083114624\n",
      "MSE train 5.080398970286369 MSE test 11.515382592598622\n",
      "MAE train 1.5483331532173499 MAE test 2.3732965732880316\n",
      "Epoch 8095 / 10000 loss: 12.474598169326782\n",
      "MSE train 5.080287272153761 MSE test 11.515142202820938\n",
      "MAE train 1.5483168219929107 MAE test 2.3732655201573127\n",
      "Epoch 8096 / 10000 loss: 12.47418475151062\n",
      "MSE train 5.080185915618247 MSE test 11.515147681006384\n",
      "MAE train 1.5482971048925354 MAE test 2.373271565621147\n",
      "Epoch 8097 / 10000 loss: 12.473827362060547\n",
      "MSE train 5.080074925191991 MSE test 11.514853736644636\n",
      "MAE train 1.5482819297480714 MAE test 2.3732333383223496\n",
      "Epoch 8098 / 10000 loss: 12.47340178489685\n",
      "MSE train 5.079952740098002 MSE test 11.514881483530859\n",
      "MAE train 1.5482563878522915 MAE test 2.3732424492822024\n",
      "Epoch 8099 / 10000 loss: 12.473088264465332\n",
      "MSE train 5.079841703940836 MSE test 11.514680477622832\n",
      "MAE train 1.5482393913140375 MAE test 2.373216657943549\n",
      "Epoch 8100 / 10000 loss: 12.472565174102783\n",
      "MSE train 5.079734203715911 MSE test 11.514632801004787\n",
      "MAE train 1.5482191843892217 MAE test 2.3732155699801423\n",
      "Epoch 8101 / 10000 loss: 12.47218108177185\n",
      "MSE train 5.079622593945569 MSE test 11.514399572806855\n",
      "MAE train 1.5482027307732364 MAE test 2.373185474615343\n",
      "Epoch 8102 / 10000 loss: 12.471767663955688\n",
      "MSE train 5.079522190136405 MSE test 11.514399357504255\n",
      "MAE train 1.5481833755147991 MAE test 2.373190744895254\n",
      "Epoch 8103 / 10000 loss: 12.4714035987854\n",
      "MSE train 5.079411516567339 MSE test 11.514104750135706\n",
      "MAE train 1.5481682912724712 MAE test 2.373152426422396\n",
      "Epoch 8104 / 10000 loss: 12.470987558364868\n",
      "MSE train 5.079288840170854 MSE test 11.514132742215871\n",
      "MAE train 1.5481426038341635 MAE test 2.373161561603509\n",
      "Epoch 8105 / 10000 loss: 12.470675706863403\n",
      "MSE train 5.079178180133321 MSE test 11.513935020483476\n",
      "MAE train 1.54812565316585 MAE test 2.3731362149209088\n",
      "Epoch 8106 / 10000 loss: 12.470149755477905\n",
      "MSE train 5.079069632794607 MSE test 11.51388283594533\n",
      "MAE train 1.5481052554323655 MAE test 2.373134518115421\n",
      "Epoch 8107 / 10000 loss: 12.469765901565552\n",
      "MSE train 5.078958172068967 MSE test 11.513658429548041\n",
      "MAE train 1.548088655836887 MAE test 2.373105595971416\n",
      "Epoch 8108 / 10000 loss: 12.469349384307861\n",
      "MSE train 5.078857886003192 MSE test 11.513650096597653\n",
      "MAE train 1.548069501216523 MAE test 2.3731097737709272\n",
      "Epoch 8109 / 10000 loss: 12.468981266021729\n",
      "MSE train 5.0787474651294 MSE test 11.513360118344453\n",
      "MAE train 1.5480543873652413 MAE test 2.373072083065209\n",
      "Epoch 8110 / 10000 loss: 12.468570709228516\n",
      "MSE train 5.078626376001411 MSE test 11.513387906922711\n",
      "MAE train 1.548029153215386 MAE test 2.3730811790833872\n",
      "Epoch 8111 / 10000 loss: 12.468255519866943\n",
      "MSE train 5.078514792488536 MSE test 11.513180578261268\n",
      "MAE train 1.5480121304066092 MAE test 2.3730545268967433\n",
      "Epoch 8112 / 10000 loss: 12.46773624420166\n",
      "MSE train 5.078409874311703 MSE test 11.51314326042324\n",
      "MAE train 1.5479923876544566 MAE test 2.3730548195792753\n",
      "Epoch 8113 / 10000 loss: 12.467354774475098\n",
      "MSE train 5.078298540629112 MSE test 11.512891803238686\n",
      "MAE train 1.5479763488845601 MAE test 2.3730222805016\n",
      "Epoch 8114 / 10000 loss: 12.466944456100464\n",
      "MSE train 5.078194331192383 MSE test 11.512905140776024\n",
      "MAE train 1.547955742907489 MAE test 2.3730293648990504\n",
      "Epoch 8115 / 10000 loss: 12.46659517288208\n",
      "MSE train 5.078082999163731 MSE test 11.512620356558267\n",
      "MAE train 1.5479403054823415 MAE test 2.3729923840641294\n",
      "Epoch 8116 / 10000 loss: 12.466153144836426\n",
      "MSE train 5.077965249176769 MSE test 11.512645831793208\n",
      "MAE train 1.5479159794025745 MAE test 2.3730011234445456\n",
      "Epoch 8117 / 10000 loss: 12.46583080291748\n",
      "MSE train 5.077852615712092 MSE test 11.512421639043332\n",
      "MAE train 1.5478990400301416 MAE test 2.3729722282198145\n",
      "Epoch 8118 / 10000 loss: 12.465325593948364\n",
      "MSE train 5.077752034013745 MSE test 11.512405508210223\n",
      "MAE train 1.5478799550767823 MAE test 2.372975340075753\n",
      "Epoch 8119 / 10000 loss: 12.464951992034912\n",
      "MSE train 5.077641159975562 MSE test 11.512122016085367\n",
      "MAE train 1.5478646107738545 MAE test 2.3729385094552375\n",
      "Epoch 8120 / 10000 loss: 12.464542865753174\n",
      "MSE train 5.077523359365454 MSE test 11.51214775054521\n",
      "MAE train 1.5478402705725323 MAE test 2.3729472816749877\n",
      "Epoch 8121 / 10000 loss: 12.464221954345703\n",
      "MSE train 5.077410767988554 MSE test 11.511923498295998\n",
      "MAE train 1.5478233507494639 MAE test 2.3729183797462166\n",
      "Epoch 8122 / 10000 loss: 12.463716268539429\n",
      "MSE train 5.0773102954274645 MSE test 11.511907978097804\n",
      "MAE train 1.5478042754167096 MAE test 2.3729215585400305\n",
      "Epoch 8123 / 10000 loss: 12.463343620300293\n",
      "MSE train 5.077199429884755 MSE test 11.511623906597443\n",
      "MAE train 1.5477889477866897 MAE test 2.372884671369559\n",
      "Epoch 8124 / 10000 loss: 12.462933778762817\n",
      "MSE train 5.077081386997523 MSE test 11.511649896189391\n",
      "MAE train 1.547764541050982 MAE test 2.3728934709166865\n",
      "Epoch 8125 / 10000 loss: 12.462613344192505\n",
      "MSE train 5.076968865618245 MSE test 11.51142710831825\n",
      "MAE train 1.5477476027846875 MAE test 2.372864756451394\n",
      "Epoch 8126 / 10000 loss: 12.462106466293335\n",
      "MSE train 5.076868212948782 MSE test 11.511409979879131\n",
      "MAE train 1.5477285214118006 MAE test 2.3728677126108653\n",
      "Epoch 8127 / 10000 loss: 12.461732864379883\n",
      "MSE train 5.076757362402137 MSE test 11.511127918587196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5477131542241855 MAE test 2.3728310915603115\n",
      "Epoch 8128 / 10000 loss: 12.461323976516724\n",
      "MSE train 5.076640163311066 MSE test 11.511153412157846\n",
      "MAE train 1.5476889761823909 MAE test 2.3728398141119085\n",
      "Epoch 8129 / 10000 loss: 12.461000919342041\n",
      "MSE train 5.076527531214209 MSE test 11.510926248562138\n",
      "MAE train 1.5476721098815647 MAE test 2.372810514764898\n",
      "Epoch 8130 / 10000 loss: 12.460498809814453\n",
      "MSE train 5.07642740005548 MSE test 11.510914187764012\n",
      "MAE train 1.5476530492680083 MAE test 2.3728141456111795\n",
      "Epoch 8131 / 10000 loss: 12.460127830505371\n",
      "MSE train 5.076316607815891 MSE test 11.51062677988824\n",
      "MAE train 1.5476377873125695 MAE test 2.3727768062405197\n",
      "Epoch 8132 / 10000 loss: 12.459717750549316\n",
      "MSE train 5.076197161212338 MSE test 11.510653454421996\n",
      "MAE train 1.5476130042070848 MAE test 2.372785693360704\n",
      "Epoch 8133 / 10000 loss: 12.459399223327637\n",
      "MSE train 5.076085031396818 MSE test 11.510438539940436\n",
      "MAE train 1.5475959896669382 MAE test 2.3727580310464367\n",
      "Epoch 8134 / 10000 loss: 12.458886623382568\n",
      "MSE train 5.0759826249495905 MSE test 11.510411709673324\n",
      "MAE train 1.5475766808545002 MAE test 2.372759681688701\n",
      "Epoch 8135 / 10000 loss: 12.458508491516113\n",
      "MSE train 5.0758717069863435 MSE test 11.510143123354023\n",
      "MAE train 1.5475610428715398 MAE test 2.372724853395888\n",
      "Epoch 8136 / 10000 loss: 12.458099126815796\n",
      "MSE train 5.075760575121364 MSE test 11.510164682327094\n",
      "MAE train 1.5475385103330084 MAE test 2.3727330165022114\n",
      "Epoch 8137 / 10000 loss: 12.457765340805054\n",
      "MSE train 5.07564817315897 MSE test 11.509908603046176\n",
      "MAE train 1.547522286922192 MAE test 2.3726998594084607\n",
      "Epoch 8138 / 10000 loss: 12.457289695739746\n",
      "MSE train 5.075543670022869 MSE test 11.509921502222314\n",
      "MAE train 1.547501592847281 MAE test 2.3727068379286735\n",
      "Epoch 8139 / 10000 loss: 12.45694088935852\n",
      "MSE train 5.075431936386809 MSE test 11.509639640903583\n",
      "MAE train 1.547486003459139 MAE test 2.3726702322338045\n",
      "Epoch 8140 / 10000 loss: 12.45649528503418\n",
      "MSE train 5.075315916125046 MSE test 11.50966384944605\n",
      "MAE train 1.547462149792513 MAE test 2.3726787569458283\n",
      "Epoch 8141 / 10000 loss: 12.456169366836548\n",
      "MSE train 5.075203075765859 MSE test 11.509431860145623\n",
      "MAE train 1.547445329377043 MAE test 2.3726488059843263\n",
      "Epoch 8142 / 10000 loss: 12.455671072006226\n",
      "MSE train 5.075103227070118 MSE test 11.5094242452009\n",
      "MAE train 1.5474262463057333 MAE test 2.372653012515484\n",
      "Epoch 8143 / 10000 loss: 12.455302953720093\n",
      "MSE train 5.074992251373319 MSE test 11.509133447715922\n",
      "MAE train 1.5474110126035496 MAE test 2.3726151922545906\n",
      "Epoch 8144 / 10000 loss: 12.454890251159668\n",
      "MSE train 5.0748714367611285 MSE test 11.509160526814021\n",
      "MAE train 1.547385844837545 MAE test 2.372624130397418\n",
      "Epoch 8145 / 10000 loss: 12.454574584960938\n",
      "MSE train 5.0747599387331315 MSE test 11.508953691545173\n",
      "MAE train 1.547368833732835 MAE test 2.3725975257824716\n",
      "Epoch 8146 / 10000 loss: 12.454055309295654\n",
      "MSE train 5.074654953242868 MSE test 11.508915811193042\n",
      "MAE train 1.547349091242246 MAE test 2.3725976680982903\n",
      "Epoch 8147 / 10000 loss: 12.453673839569092\n",
      "MSE train 5.074543655939377 MSE test 11.508665739934033\n",
      "MAE train 1.5473330331794397 MAE test 2.3725653080396563\n",
      "Epoch 8148 / 10000 loss: 12.453262329101562\n",
      "MSE train 5.074439878417585 MSE test 11.508678276234587\n",
      "MAE train 1.5473125537332486 MAE test 2.3725722141918095\n",
      "Epoch 8149 / 10000 loss: 12.452912330627441\n",
      "MSE train 5.074328567501589 MSE test 11.508392853254271\n",
      "MAE train 1.5472971476277335 MAE test 2.3725351222441655\n",
      "Epoch 8150 / 10000 loss: 12.452471733093262\n",
      "MSE train 5.0742103440259605 MSE test 11.50841865455584\n",
      "MAE train 1.5472726971582889 MAE test 2.3725438637013374\n",
      "Epoch 8151 / 10000 loss: 12.452149868011475\n",
      "MSE train 5.074097806156052 MSE test 11.50819771465995\n",
      "MAE train 1.5472557191850194 MAE test 2.372515365603763\n",
      "Epoch 8152 / 10000 loss: 12.451642274856567\n",
      "MSE train 5.07399676946598 MSE test 11.508178256383518\n",
      "MAE train 1.5472366050038218 MAE test 2.3725179726563237\n",
      "Epoch 8153 / 10000 loss: 12.451266765594482\n",
      "MSE train 5.073885834940583 MSE test 11.507899330391227\n",
      "MAE train 1.5472211697289826 MAE test 2.372481731430221\n",
      "Epoch 8154 / 10000 loss: 12.450857877731323\n",
      "MSE train 5.07376990653339 MSE test 11.507924103324065\n",
      "MAE train 1.547197347129643 MAE test 2.372490312796924\n",
      "Epoch 8155 / 10000 loss: 12.450531959533691\n",
      "MSE train 5.073657050357575 MSE test 11.50769064362708\n",
      "MAE train 1.5471805783347534 MAE test 2.372460146557032\n",
      "Epoch 8156 / 10000 loss: 12.450034141540527\n",
      "MSE train 5.0735571184109345 MSE test 11.507685233963139\n",
      "MAE train 1.5471614354851921 MAE test 2.3724646101844633\n",
      "Epoch 8157 / 10000 loss: 12.449666261672974\n",
      "MSE train 5.073446136588782 MSE test 11.507393305141223\n",
      "MAE train 1.5471462244573628 MAE test 2.3724266090991586\n",
      "Epoch 8158 / 10000 loss: 12.449251890182495\n",
      "MSE train 5.073324669335144 MSE test 11.507420592950455\n",
      "MAE train 1.5471209022459138 MAE test 2.3724355532524957\n",
      "Epoch 8159 / 10000 loss: 12.448936462402344\n",
      "MSE train 5.0732132635847105 MSE test 11.507216567887305\n",
      "MAE train 1.5471038801215666 MAE test 2.3724092891578947\n",
      "Epoch 8160 / 10000 loss: 12.448415040969849\n",
      "MSE train 5.073107163394071 MSE test 11.507174339416341\n",
      "MAE train 1.5470839520296886 MAE test 2.3724088349327825\n",
      "Epoch 8161 / 10000 loss: 12.448031663894653\n",
      "MSE train 5.0729955625563194 MSE test 11.506931859301748\n",
      "MAE train 1.547067703569184 MAE test 2.372377434904885\n",
      "Epoch 8162 / 10000 loss: 12.447618007659912\n",
      "MSE train 5.072893658423967 MSE test 11.50693934113797\n",
      "MAE train 1.5470478287604557 MAE test 2.3723836304909405\n",
      "Epoch 8163 / 10000 loss: 12.44726037979126\n",
      "MSE train 5.072782528996127 MSE test 11.506647551220388\n",
      "MAE train 1.5470325983652036 MAE test 2.372345644556138\n",
      "Epoch 8164 / 10000 loss: 12.446830987930298\n",
      "MSE train 5.072661085794809 MSE test 11.506674775479127\n",
      "MAE train 1.5470072888616584 MAE test 2.3723545422135346\n",
      "Epoch 8165 / 10000 loss: 12.44651484489441\n",
      "MSE train 5.072549498655599 MSE test 11.506470105323986\n",
      "MAE train 1.5469902466328007 MAE test 2.372328170805522\n",
      "Epoch 8166 / 10000 loss: 12.445993185043335\n",
      "MSE train 5.072443406627864 MSE test 11.506428615553393\n",
      "MAE train 1.5469703288996632 MAE test 2.3723277976705446\n",
      "Epoch 8167 / 10000 loss: 12.445609092712402\n",
      "MSE train 5.072331689461513 MSE test 11.506184567023071\n",
      "MAE train 1.5469540937434192 MAE test 2.3722961728896688\n",
      "Epoch 8168 / 10000 loss: 12.445194244384766\n",
      "MSE train 5.07222925307017 MSE test 11.506192685310015\n",
      "MAE train 1.546934079383143 MAE test 2.372302427381514\n",
      "Epoch 8169 / 10000 loss: 12.444837808609009\n",
      "MSE train 5.07211776966905 MSE test 11.505901941491807\n",
      "MAE train 1.5469187683746075 MAE test 2.372264556139574\n",
      "Epoch 8170 / 10000 loss: 12.444405317306519\n",
      "MSE train 5.071996591150287 MSE test 11.505928705326951\n",
      "MAE train 1.5468935649370208 MAE test 2.3722733723598988\n",
      "Epoch 8171 / 10000 loss: 12.444086790084839\n",
      "MSE train 5.071884439538378 MSE test 11.505721096689111\n",
      "MAE train 1.5468764638859551 MAE test 2.372246579264554\n",
      "Epoch 8172 / 10000 loss: 12.443565607070923\n",
      "MSE train 5.07177907091426 MSE test 11.50568320125322\n",
      "MAE train 1.546856678067607 MAE test 2.372246655697648\n",
      "Epoch 8173 / 10000 loss: 12.443181276321411\n",
      "MSE train 5.0716670638001204 MSE test 11.50543184706002\n",
      "MAE train 1.5468405426336864 MAE test 2.3722140214236345\n",
      "Epoch 8174 / 10000 loss: 12.442766666412354\n",
      "MSE train 5.071562240137572 MSE test 11.505444279889698\n",
      "MAE train 1.54681987390217 MAE test 2.372220830424629\n",
      "Epoch 8175 / 10000 loss: 12.442414283752441\n",
      "MSE train 5.07144999284173 MSE test 11.505159452753512\n",
      "MAE train 1.5468043026989649 MAE test 2.3721836987901526\n",
      "Epoch 8176 / 10000 loss: 12.4419686794281\n",
      "MSE train 5.071331344797044 MSE test 11.505184091625248\n",
      "MAE train 1.5467798628988239 MAE test 2.3721921697677115\n",
      "Epoch 8177 / 10000 loss: 12.441641569137573\n",
      "MSE train 5.071217597475124 MSE test 11.504959674579155\n",
      "MAE train 1.5467627647405089 MAE test 2.3721631125439044\n",
      "Epoch 8178 / 10000 loss: 12.441131353378296\n",
      "MSE train 5.071115776662401 MSE test 11.504942457550044\n",
      "MAE train 1.5467435160088447 MAE test 2.3721658906866727\n",
      "Epoch 8179 / 10000 loss: 12.440752029418945\n",
      "MSE train 5.071003469135235 MSE test 11.504658743426237\n",
      "MAE train 1.5467279596982835 MAE test 2.372128888793866\n",
      "Epoch 8180 / 10000 loss: 12.44033694267273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.07088422336817 MSE test 11.504683067490136\n",
      "MAE train 1.5467034435270135 MAE test 2.3721372828087492\n",
      "Epoch 8181 / 10000 loss: 12.440007448196411\n",
      "MSE train 5.070769667138905 MSE test 11.504457357129366\n",
      "MAE train 1.5466862425160532 MAE test 2.3721080074339955\n",
      "Epoch 8182 / 10000 loss: 12.439494848251343\n",
      "MSE train 5.07066702043057 MSE test 11.504440863348309\n",
      "MAE train 1.5466668569815851 MAE test 2.3721108270831026\n",
      "Epoch 8183 / 10000 loss: 12.439111948013306\n",
      "MSE train 5.070553589190143 MSE test 11.504154980152846\n",
      "MAE train 1.5466511546059933 MAE test 2.3720734875440317\n",
      "Epoch 8184 / 10000 loss: 12.438692331314087\n",
      "MSE train 5.070432371136301 MSE test 11.504178865150918\n",
      "MAE train 1.5466262584927974 MAE test 2.372081763599928\n",
      "Epoch 8185 / 10000 loss: 12.438358545303345\n",
      "MSE train 5.070316332440791 MSE test 11.503955369722616\n",
      "MAE train 1.5466087772152692 MAE test 2.372052701503769\n",
      "Epoch 8186 / 10000 loss: 12.437837839126587\n",
      "MSE train 5.070211189094694 MSE test 11.503934129445275\n",
      "MAE train 1.5465890476925148 MAE test 2.37205482562582\n",
      "Epoch 8187 / 10000 loss: 12.437446117401123\n",
      "MSE train 5.070095193368689 MSE test 11.503651457002446\n",
      "MAE train 1.5465728765708433 MAE test 2.3720178116672264\n",
      "Epoch 8188 / 10000 loss: 12.43701696395874\n",
      "MSE train 5.0699727303153725 MSE test 11.503672935919393\n",
      "MAE train 1.5465480222759609 MAE test 2.3720256733045937\n",
      "Epoch 8189 / 10000 loss: 12.436667919158936\n",
      "MSE train 5.069852404313528 MSE test 11.503438102068039\n",
      "MAE train 1.5465300754656977 MAE test 2.371994981480391\n",
      "Epoch 8190 / 10000 loss: 12.436140775680542\n",
      "MSE train 5.069743289243696 MSE test 11.503425834490956\n",
      "MAE train 1.546509603475551 MAE test 2.3719981563810655\n",
      "Epoch 8191 / 10000 loss: 12.435736894607544\n",
      "MSE train 5.069620680774523 MSE test 11.503130218523369\n",
      "MAE train 1.546492620302583 MAE test 2.3719592288865443\n",
      "Epoch 8192 / 10000 loss: 12.435280799865723\n",
      "MSE train 5.069485331834192 MSE test 11.503151076137415\n",
      "MAE train 1.5464652595955277 MAE test 2.3719668131183202\n",
      "Epoch 8193 / 10000 loss: 12.434910297393799\n",
      "MSE train 5.0693553277159396 MSE test 11.502937074108797\n",
      "MAE train 1.5464454708341806 MAE test 2.3719386579985464\n",
      "Epoch 8194 / 10000 loss: 12.434324502944946\n",
      "MSE train 5.069227317684196 MSE test 11.502891334352343\n",
      "MAE train 1.5464222580716775 MAE test 2.371937090562047\n",
      "Epoch 8195 / 10000 loss: 12.433856010437012\n",
      "MSE train 5.069087532851582 MSE test 11.502631922935613\n",
      "MAE train 1.5464018470637364 MAE test 2.371902672828575\n",
      "Epoch 8196 / 10000 loss: 12.433336019515991\n",
      "MSE train 5.068950769903686 MSE test 11.502634691688218\n",
      "MAE train 1.546376172946427 MAE test 2.3719074260265685\n",
      "Epoch 8197 / 10000 loss: 12.432852983474731\n",
      "MSE train 5.068805302393871 MSE test 11.502340816091662\n",
      "MAE train 1.5463552981287192 MAE test 2.371868294605091\n",
      "Epoch 8198 / 10000 loss: 12.432257175445557\n",
      "MSE train 5.068657626545545 MSE test 11.502358293904868\n",
      "MAE train 1.546326275900436 MAE test 2.3718750981964556\n",
      "Epoch 8199 / 10000 loss: 12.431772470474243\n",
      "MSE train 5.068524011809768 MSE test 11.502131328546556\n",
      "MAE train 1.5463061703493992 MAE test 2.3718450612449438\n",
      "Epoch 8200 / 10000 loss: 12.431124925613403\n",
      "MSE train 5.068411720054341 MSE test 11.502113316775283\n",
      "MAE train 1.5462852594949688 MAE test 2.3718473031479403\n",
      "Epoch 8201 / 10000 loss: 12.430649757385254\n",
      "MSE train 5.068295673200544 MSE test 11.50183495725958\n",
      "MAE train 1.5462689632922293 MAE test 2.371810729318954\n",
      "Epoch 8202 / 10000 loss: 12.430181980133057\n",
      "MSE train 5.068176957013556 MSE test 11.501864765774712\n",
      "MAE train 1.5462445068076704 MAE test 2.371819773071384\n",
      "Epoch 8203 / 10000 loss: 12.429828882217407\n",
      "MSE train 5.068064048740421 MSE test 11.501642771074783\n",
      "MAE train 1.546227531797115 MAE test 2.371790980650061\n",
      "Epoch 8204 / 10000 loss: 12.429312944412231\n",
      "MSE train 5.067964573845015 MSE test 11.501636506660851\n",
      "MAE train 1.5462084880992404 MAE test 2.37179528350401\n",
      "Epoch 8205 / 10000 loss: 12.42893648147583\n",
      "MSE train 5.067854504034762 MSE test 11.501354328085739\n",
      "MAE train 1.5461933022648011 MAE test 2.371758550220634\n",
      "Epoch 8206 / 10000 loss: 12.428523063659668\n",
      "MSE train 5.067735828990654 MSE test 11.501385336693541\n",
      "MAE train 1.5461685483692347 MAE test 2.371768015055344\n",
      "Epoch 8207 / 10000 loss: 12.428202867507935\n",
      "MSE train 5.067624707295274 MSE test 11.501176224947196\n",
      "MAE train 1.5461516372356816 MAE test 2.3717411016010264\n",
      "Epoch 8208 / 10000 loss: 12.427689790725708\n",
      "MSE train 5.067522885460486 MSE test 11.50115112206855\n",
      "MAE train 1.546132376435466 MAE test 2.3717429767440654\n",
      "Epoch 8209 / 10000 loss: 12.427311420440674\n",
      "MSE train 5.06741268972425 MSE test 11.500889276753957\n",
      "MAE train 1.5461167731449417 MAE test 2.371709057176935\n",
      "Epoch 8210 / 10000 loss: 12.426903486251831\n",
      "MSE train 5.067303854513094 MSE test 11.500912207285493\n",
      "MAE train 1.5460947208578284 MAE test 2.371717422990628\n",
      "Epoch 8211 / 10000 loss: 12.426567554473877\n",
      "MSE train 5.067192350338828 MSE test 11.500653734088125\n",
      "MAE train 1.5460787391322648 MAE test 2.371683955831469\n",
      "Epoch 8212 / 10000 loss: 12.426099061965942\n",
      "MSE train 5.067086408377513 MSE test 11.500671956503878\n",
      "MAE train 1.5460575066537134 MAE test 2.3716916801602275\n",
      "Epoch 8213 / 10000 loss: 12.425756692886353\n",
      "MSE train 5.0669750490764915 MSE test 11.500401652754334\n",
      "MAE train 1.5460417694220217 MAE test 2.371656641630983\n",
      "Epoch 8214 / 10000 loss: 12.425301551818848\n",
      "MSE train 5.066864125224219 MSE test 11.50042422182809\n",
      "MAE train 1.546019183096855 MAE test 2.37166498107508\n",
      "Epoch 8215 / 10000 loss: 12.424969673156738\n",
      "MSE train 5.06675203460449 MSE test 11.500174483903702\n",
      "MAE train 1.5460028930615843 MAE test 2.371632690486009\n",
      "Epoch 8216 / 10000 loss: 12.424492359161377\n",
      "MSE train 5.066649795401905 MSE test 11.500185313569087\n",
      "MAE train 1.5459827464574578 MAE test 2.371639425440841\n",
      "Epoch 8217 / 10000 loss: 12.424141883850098\n",
      "MSE train 5.066538830743988 MSE test 11.499900830351802\n",
      "MAE train 1.5459673740461517 MAE test 2.3716024815044947\n",
      "Epoch 8218 / 10000 loss: 12.423706531524658\n",
      "MSE train 5.066421234088733 MSE test 11.499927457937982\n",
      "MAE train 1.545942987854203 MAE test 2.371611402562639\n",
      "Epoch 8219 / 10000 loss: 12.42338752746582\n",
      "MSE train 5.066309337475844 MSE test 11.49970917407523\n",
      "MAE train 1.545926084587657 MAE test 2.3715833148080145\n",
      "Epoch 8220 / 10000 loss: 12.422881364822388\n",
      "MSE train 5.066208804428606 MSE test 11.49968931437022\n",
      "MAE train 1.5459070402493205 MAE test 2.3715859351673623\n",
      "Epoch 8221 / 10000 loss: 12.422507762908936\n",
      "MSE train 5.066098459769572 MSE test 11.499414109131692\n",
      "MAE train 1.545891654648085 MAE test 2.371550230496765\n",
      "Epoch 8222 / 10000 loss: 12.422101020812988\n",
      "MSE train 5.065984195266713 MSE test 11.499438922736145\n",
      "MAE train 1.5458681871907136 MAE test 2.3715588974760315\n",
      "Epoch 8223 / 10000 loss: 12.421776056289673\n",
      "MSE train 5.065871988475911 MSE test 11.499202451634934\n",
      "MAE train 1.545851605082363 MAE test 2.371528385163168\n",
      "Epoch 8224 / 10000 loss: 12.421285152435303\n",
      "MSE train 5.06577250102834 MSE test 11.499202025500761\n",
      "MAE train 1.5458324045652463 MAE test 2.371533614673903\n",
      "Epoch 8225 / 10000 loss: 12.420924186706543\n",
      "MSE train 5.065661962009611 MSE test 11.4989104273535\n",
      "MAE train 1.5458172722317967 MAE test 2.3714957300410213\n",
      "Epoch 8226 / 10000 loss: 12.42050814628601\n",
      "MSE train 5.065541040921822 MSE test 11.498938126652405\n",
      "MAE train 1.5457919680704177 MAE test 2.3715048209163947\n",
      "Epoch 8227 / 10000 loss: 12.420195817947388\n",
      "MSE train 5.065430462373354 MSE test 11.498737222698916\n",
      "MAE train 1.5457750601859206 MAE test 2.3714790577422518\n",
      "Epoch 8228 / 10000 loss: 12.419677495956421\n",
      "MSE train 5.065324441483926 MSE test 11.498692581750483\n",
      "MAE train 1.545755115804418 MAE test 2.3714783690302945\n",
      "Epoch 8229 / 10000 loss: 12.419296503067017\n",
      "MSE train 5.065213535537694 MSE test 11.498456882539974\n",
      "MAE train 1.5457388570309427 MAE test 2.371447948666808\n",
      "Epoch 8230 / 10000 loss: 12.418885469436646\n",
      "MSE train 5.065113429872825 MSE test 11.498460296692006\n",
      "MAE train 1.5457194354452872 MAE test 2.371453719052343\n",
      "Epoch 8231 / 10000 loss: 12.418526649475098\n",
      "MSE train 5.065003227561941 MSE test 11.498168067782304\n",
      "MAE train 1.5457043971977917 MAE test 2.3714157393315936\n",
      "Epoch 8232 / 10000 loss: 12.418108224868774\n",
      "MSE train 5.064881688976955 MSE test 11.498196020052623\n",
      "MAE train 1.545678924971289 MAE test 2.371424870895634\n",
      "Epoch 8233 / 10000 loss: 12.417797803878784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.064771459800269 MSE test 11.49799791227364\n",
      "MAE train 1.5456620572041462 MAE test 2.371399477654243\n",
      "Epoch 8234 / 10000 loss: 12.417276382446289\n",
      "MSE train 5.064664327583279 MSE test 11.497948720824398\n",
      "MAE train 1.5456419014036344 MAE test 2.3713981994324387\n",
      "Epoch 8235 / 10000 loss: 12.41689419746399\n",
      "MSE train 5.064553393969481 MSE test 11.497720751997972\n",
      "MAE train 1.545625488064003 MAE test 2.3713688252956118\n",
      "Epoch 8236 / 10000 loss: 12.41648244857788\n",
      "MSE train 5.0644538971949284 MSE test 11.49771719120666\n",
      "MAE train 1.5456063627462433 MAE test 2.3713736433269514\n",
      "Epoch 8237 / 10000 loss: 12.416118621826172\n",
      "MSE train 5.064343874388798 MSE test 11.497425944577284\n",
      "MAE train 1.5455913542268171 MAE test 2.371335800027387\n",
      "Epoch 8238 / 10000 loss: 12.415706872940063\n",
      "MSE train 5.064222530401396 MSE test 11.497453720319378\n",
      "MAE train 1.545565932578109 MAE test 2.371344913307227\n",
      "Epoch 8239 / 10000 loss: 12.415395736694336\n",
      "MSE train 5.064112090871102 MSE test 11.49725390583271\n",
      "MAE train 1.5455490409586738 MAE test 2.371319291023971\n",
      "Epoch 8240 / 10000 loss: 12.414875030517578\n",
      "MSE train 5.064005568515103 MSE test 11.497207146941516\n",
      "MAE train 1.5455289999032094 MAE test 2.3713183305020604\n",
      "Epoch 8241 / 10000 loss: 12.414494276046753\n",
      "MSE train 5.063894520580737 MSE test 11.496974009297121\n",
      "MAE train 1.5455126584643137 MAE test 2.371288266574997\n",
      "Epoch 8242 / 10000 loss: 12.41408109664917\n",
      "MSE train 5.063794672608779 MSE test 11.496974652176359\n",
      "MAE train 1.5454933561771724 MAE test 2.371293655000801\n",
      "Epoch 8243 / 10000 loss: 12.413720846176147\n",
      "MSE train 5.063684455813573 MSE test 11.496681959640606\n",
      "MAE train 1.5454783255712858 MAE test 2.371255619754315\n",
      "Epoch 8244 / 10000 loss: 12.413305044174194\n",
      "MSE train 5.063562697577897 MSE test 11.496709553705502\n",
      "MAE train 1.545452792759943 MAE test 2.3712647102283957\n",
      "Epoch 8245 / 10000 loss: 12.412994623184204\n",
      "MSE train 5.063452403497867 MSE test 11.49651175901704\n",
      "MAE train 1.5454359097815318 MAE test 2.371239355020009\n",
      "Epoch 8246 / 10000 loss: 12.412472248077393\n",
      "MSE train 5.063344865850607 MSE test 11.496461075903172\n",
      "MAE train 1.5454156749644352 MAE test 2.3712378849390623\n",
      "Epoch 8247 / 10000 loss: 12.412088871002197\n",
      "MSE train 5.063233813592316 MSE test 11.496234952324137\n",
      "MAE train 1.5453991928426163 MAE test 2.371208753552028\n",
      "Epoch 8248 / 10000 loss: 12.411675453186035\n",
      "MSE train 5.063134109233189 MSE test 11.496228957518255\n",
      "MAE train 1.5453800728990301 MAE test 2.3712132429787895\n",
      "Epoch 8249 / 10000 loss: 12.411309957504272\n",
      "MSE train 5.063023994783001 MSE test 11.495938599859617\n",
      "MAE train 1.5453650322973782 MAE test 2.371175517276183\n",
      "Epoch 8250 / 10000 loss: 12.41089916229248\n",
      "MSE train 5.062902835115548 MSE test 11.495965997260774\n",
      "MAE train 1.5453396931220515 MAE test 2.371184582147573\n",
      "Epoch 8251 / 10000 loss: 12.410586833953857\n",
      "MSE train 5.062791954263754 MSE test 11.49576313715372\n",
      "MAE train 1.545322743140031 MAE test 2.3711585570862925\n",
      "Epoch 8252 / 10000 loss: 12.410066366195679\n",
      "MSE train 5.06268620253501 MSE test 11.495720080123776\n",
      "MAE train 1.545302845465553 MAE test 2.371158095963522\n",
      "Epoch 8253 / 10000 loss: 12.409684896469116\n",
      "MSE train 5.0625749320111915 MSE test 11.495479516954875\n",
      "MAE train 1.545286615398733 MAE test 2.371127040369455\n",
      "Epoch 8254 / 10000 loss: 12.409273624420166\n",
      "MSE train 5.062473711450559 MSE test 11.495485486143217\n",
      "MAE train 1.5452668665212446 MAE test 2.3711331426175675\n",
      "Epoch 8255 / 10000 loss: 12.408916473388672\n",
      "MSE train 5.062362968691883 MSE test 11.495194121857333\n",
      "MAE train 1.5452516909722918 MAE test 2.3710952826174347\n",
      "Epoch 8256 / 10000 loss: 12.408491134643555\n",
      "MSE train 5.062241801387576 MSE test 11.495220798191568\n",
      "MAE train 1.545226369673384 MAE test 2.371104253486979\n",
      "Epoch 8257 / 10000 loss: 12.40817642211914\n",
      "MSE train 5.062130662211162 MSE test 11.495017764510658\n",
      "MAE train 1.5452093745481064 MAE test 2.3710781994155448\n",
      "Epoch 8258 / 10000 loss: 12.4076566696167\n",
      "MSE train 5.062024677812086 MSE test 11.494974257640765\n",
      "MAE train 1.5451894390809535 MAE test 2.3710776819909123\n",
      "Epoch 8259 / 10000 loss: 12.407273054122925\n",
      "MSE train 5.061913196220148 MSE test 11.49473385335971\n",
      "MAE train 1.5451731592827562 MAE test 2.371046641739461\n",
      "Epoch 8260 / 10000 loss: 12.406861543655396\n",
      "MSE train 5.061811937755799 MSE test 11.49473932669908\n",
      "MAE train 1.5451534161424059 MAE test 2.3710526766456677\n",
      "Epoch 8261 / 10000 loss: 12.406503200531006\n",
      "MSE train 5.061700960003501 MSE test 11.494447556539926\n",
      "MAE train 1.5451382049084414 MAE test 2.371014779055856\n",
      "Epoch 8262 / 10000 loss: 12.406077146530151\n",
      "MSE train 5.061579525200613 MSE test 11.494474168935847\n",
      "MAE train 1.5451128314494107 MAE test 2.3710237366643074\n",
      "Epoch 8263 / 10000 loss: 12.405762195587158\n",
      "MSE train 5.061468237048524 MSE test 11.494271496750512\n",
      "MAE train 1.5450958053749342 MAE test 2.3709977211790605\n",
      "Epoch 8264 / 10000 loss: 12.405241012573242\n",
      "MSE train 5.061361932230354 MSE test 11.49422712971651\n",
      "MAE train 1.5450758214891886 MAE test 2.3709971018712865\n",
      "Epoch 8265 / 10000 loss: 12.404857158660889\n",
      "MSE train 5.061250279114613 MSE test 11.493987744911776\n",
      "MAE train 1.545059491363423 MAE test 2.3709661913135682\n",
      "Epoch 8266 / 10000 loss: 12.40444278717041\n",
      "MSE train 5.061148996610277 MSE test 11.49399210088501\n",
      "MAE train 1.5450397991925153 MAE test 2.370972082606438\n",
      "Epoch 8267 / 10000 loss: 12.404083251953125\n",
      "MSE train 5.061037916277542 MSE test 11.493699951488576\n",
      "MAE train 1.5450245894535815 MAE test 2.3709341312456367\n",
      "Epoch 8268 / 10000 loss: 12.403658390045166\n",
      "MSE train 5.060916063279347 MSE test 11.493726350922989\n",
      "MAE train 1.5449991331100703 MAE test 2.370943054095184\n",
      "Epoch 8269 / 10000 loss: 12.403342485427856\n",
      "MSE train 5.060804801535649 MSE test 11.493524789698576\n",
      "MAE train 1.5449821038188567 MAE test 2.37091720062438\n",
      "Epoch 8270 / 10000 loss: 12.402820110321045\n",
      "MSE train 5.060697798333585 MSE test 11.493478198742837\n",
      "MAE train 1.5449619964347951 MAE test 2.3709162647158575\n",
      "Epoch 8271 / 10000 loss: 12.402434587478638\n",
      "MSE train 5.060586052936353 MSE test 11.493242409450776\n",
      "MAE train 1.5449455656860354 MAE test 2.370885847614096\n",
      "Epoch 8272 / 10000 loss: 12.402020692825317\n",
      "MSE train 5.060485310457961 MSE test 11.493243793245286\n",
      "MAE train 1.544926073651198 MAE test 2.3708913339216093\n",
      "Epoch 8273 / 10000 loss: 12.401658535003662\n",
      "MSE train 5.06037429966477 MSE test 11.492950487396598\n",
      "MAE train 1.5449108828172735 MAE test 2.370853225348054\n",
      "Epoch 8274 / 10000 loss: 12.40123701095581\n",
      "MSE train 5.060252028922726 MSE test 11.492977065964988\n",
      "MAE train 1.544885285233439 MAE test 2.370862186787809\n",
      "Epoch 8275 / 10000 loss: 12.400923013687134\n",
      "MSE train 5.060141123628705 MSE test 11.49277805508083\n",
      "MAE train 1.5448682848104829 MAE test 2.3708366662438185\n",
      "Epoch 8276 / 10000 loss: 12.400397539138794\n",
      "MSE train 5.060033304988312 MSE test 11.492727177720836\n",
      "MAE train 1.5448480147627655 MAE test 2.3708351761567554\n",
      "Epoch 8277 / 10000 loss: 12.400012969970703\n",
      "MSE train 5.059921762133199 MSE test 11.492498579729824\n",
      "MAE train 1.5448314567546246 MAE test 2.370805709707076\n",
      "Epoch 8278 / 10000 loss: 12.399598360061646\n",
      "MSE train 5.059821718444584 MSE test 11.492493331888028\n",
      "MAE train 1.5448122592829625 MAE test 2.3708103214080034\n",
      "Epoch 8279 / 10000 loss: 12.39923095703125\n",
      "MSE train 5.059711223476143 MSE test 11.492201474891672\n",
      "MAE train 1.5447971434365892 MAE test 2.3707724148423566\n",
      "Epoch 8280 / 10000 loss: 12.398818731307983\n",
      "MSE train 5.0595896213525595 MSE test 11.492227812415877\n",
      "MAE train 1.5447717075567453 MAE test 2.370781341498855\n",
      "Epoch 8281 / 10000 loss: 12.398504257202148\n",
      "MSE train 5.059478747949072 MSE test 11.492026099276195\n",
      "MAE train 1.5447547211135393 MAE test 2.370755472847257\n",
      "Epoch 8282 / 10000 loss: 12.397984027862549\n",
      "MSE train 5.059372335874598 MSE test 11.491979284930398\n",
      "MAE train 1.5447347098368183 MAE test 2.3707545177887983\n",
      "Epoch 8283 / 10000 loss: 12.39760136604309\n",
      "MSE train 5.059261101059462 MSE test 11.491743012464621\n",
      "MAE train 1.5447183616146838 MAE test 2.3707240438383788\n",
      "Epoch 8284 / 10000 loss: 12.397189617156982\n",
      "MSE train 5.059160988787221 MSE test 11.491743996570236\n",
      "MAE train 1.5446989709728067 MAE test 2.370729484628914\n",
      "Epoch 8285 / 10000 loss: 12.396831035614014\n",
      "MSE train 5.059050616887735 MSE test 11.49145060674286\n",
      "MAE train 1.544683878401274 MAE test 2.37069138640836\n",
      "Epoch 8286 / 10000 loss: 12.396413326263428\n",
      "MSE train 5.058929082710549 MSE test 11.491476692542207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5446584053287369 MAE test 2.3707002870124256\n",
      "Epoch 8287 / 10000 loss: 12.39610242843628\n",
      "MSE train 5.058818879307134 MSE test 11.491277157066525\n",
      "MAE train 1.54464150686567 MAE test 2.3706747106918415\n",
      "Epoch 8288 / 10000 loss: 12.395582675933838\n",
      "MSE train 5.058711873117415 MSE test 11.491226499315522\n",
      "MAE train 1.5446213582490116 MAE test 2.370673266952786\n",
      "Epoch 8289 / 10000 loss: 12.395201921463013\n",
      "MSE train 5.058601061169517 MSE test 11.49099705230239\n",
      "MAE train 1.5446049313532413 MAE test 2.3706437118607098\n",
      "Epoch 8290 / 10000 loss: 12.3947913646698\n",
      "MSE train 5.0585018411447145 MSE test 11.49099182483705\n",
      "MAE train 1.54458585137885 MAE test 2.370648327631173\n",
      "Epoch 8291 / 10000 loss: 12.394429206848145\n",
      "MSE train 5.05839200774535 MSE test 11.490699571445814\n",
      "MAE train 1.5445708409856054 MAE test 2.3706103853766582\n",
      "Epoch 8292 / 10000 loss: 12.394019603729248\n",
      "MSE train 5.058271077266542 MSE test 11.490725734929436\n",
      "MAE train 1.5445455039474651 MAE test 2.370619293922724\n",
      "Epoch 8293 / 10000 loss: 12.393710613250732\n",
      "MSE train 5.058160926348182 MSE test 11.490524252145791\n",
      "MAE train 1.544528640191435 MAE test 2.3705934664472954\n",
      "Epoch 8294 / 10000 loss: 12.393193006515503\n",
      "MSE train 5.058054974910373 MSE test 11.490476641353606\n",
      "MAE train 1.5445087029400428 MAE test 2.370592427092632\n",
      "Epoch 8295 / 10000 loss: 12.39281415939331\n",
      "MSE train 5.0579443739509555 MSE test 11.490241469332659\n",
      "MAE train 1.5444924276960235 MAE test 2.3705621077035746\n",
      "Epoch 8296 / 10000 loss: 12.39240550994873\n",
      "MSE train 5.057844924065388 MSE test 11.49024133429777\n",
      "MAE train 1.5444731813200918 MAE test 2.370567420622352\n",
      "Epoch 8297 / 10000 loss: 12.392048835754395\n",
      "MSE train 5.057735168266083 MSE test 11.489947974802083\n",
      "MAE train 1.544458189113379 MAE test 2.370529317928024\n",
      "Epoch 8298 / 10000 loss: 12.391635179519653\n",
      "MSE train 5.057614079489836 MSE test 11.489974113085134\n",
      "MAE train 1.544432793094626 MAE test 2.3705382351345268\n",
      "Epoch 8299 / 10000 loss: 12.391327142715454\n",
      "MSE train 5.057504282554254 MSE test 11.489774833527605\n",
      "MAE train 1.5444159716684314 MAE test 2.3705127051007744\n",
      "Epoch 8300 / 10000 loss: 12.390808820724487\n",
      "MSE train 5.057397603523174 MSE test 11.48972364541364\n",
      "MAE train 1.5443958908476743 MAE test 2.3705111844652107\n",
      "Epoch 8301 / 10000 loss: 12.390430212020874\n",
      "MSE train 5.057287154768106 MSE test 11.489495141265571\n",
      "MAE train 1.544379511054461 MAE test 2.3704817562546445\n",
      "Epoch 8302 / 10000 loss: 12.390021562576294\n",
      "MSE train 5.057188241698357 MSE test 11.489489414499504\n",
      "MAE train 1.5443605042066633 MAE test 2.3704863187617495\n",
      "Epoch 8303 / 10000 loss: 12.389661073684692\n",
      "MSE train 5.057078721533945 MSE test 11.48919761564608\n",
      "MAE train 1.5443455381095714 MAE test 2.3704484366843883\n",
      "Epoch 8304 / 10000 loss: 12.389252662658691\n",
      "MSE train 5.056958210990227 MSE test 11.489223837775613\n",
      "MAE train 1.5443202892753198 MAE test 2.370457346884108\n",
      "Epoch 8305 / 10000 loss: 12.388943910598755\n",
      "MSE train 5.056848178275501 MSE test 11.489021727825305\n",
      "MAE train 1.5443034455076567 MAE test 2.3704314427211206\n",
      "Epoch 8306 / 10000 loss: 12.388427972793579\n",
      "MSE train 5.056742752754579 MSE test 11.48897536260681\n",
      "MAE train 1.5442835984818344 MAE test 2.3704305669349663\n",
      "Epoch 8307 / 10000 loss: 12.388050556182861\n",
      "MSE train 5.056632383244294 MSE test 11.488738376831968\n",
      "MAE train 1.5442673922488372 MAE test 2.3703999958690667\n",
      "Epoch 8308 / 10000 loss: 12.387642860412598\n",
      "MSE train 5.056532834423223 MSE test 11.488740135410648\n",
      "MAE train 1.5442480729244925 MAE test 2.370405557562478\n",
      "Epoch 8309 / 10000 loss: 12.387288093566895\n",
      "MSE train 5.056423164574455 MSE test 11.488447033104203\n",
      "MAE train 1.5442330780304179 MAE test 2.3703674988037866\n",
      "Epoch 8310 / 10000 loss: 12.386873245239258\n",
      "MSE train 5.056302408909713 MSE test 11.488473153767087\n",
      "MAE train 1.5442077579056375 MAE test 2.3703764088943724\n",
      "Epoch 8311 / 10000 loss: 12.386565446853638\n",
      "MSE train 5.05619270413179 MSE test 11.488273372303889\n",
      "MAE train 1.5441909435130197 MAE test 2.370350808857565\n",
      "Epoch 8312 / 10000 loss: 12.386047840118408\n",
      "MSE train 5.056086488907139 MSE test 11.488223465578109\n",
      "MAE train 1.5441709510887318 MAE test 2.3703494494168464\n",
      "Epoch 8313 / 10000 loss: 12.385669231414795\n",
      "MSE train 5.055976165240679 MSE test 11.487992965113012\n",
      "MAE train 1.5441546243138162 MAE test 2.3703197459176475\n",
      "Epoch 8314 / 10000 loss: 12.385261535644531\n",
      "MSE train 5.055877281456853 MSE test 11.48798932286993\n",
      "MAE train 1.5441355822876186 MAE test 2.370324590368478\n",
      "Epoch 8315 / 10000 loss: 12.384902238845825\n",
      "MSE train 5.055767870396694 MSE test 11.487696999594512\n",
      "MAE train 1.544120632848163 MAE test 2.3702866459661576\n",
      "Epoch 8316 / 10000 loss: 12.384493827819824\n",
      "MSE train 5.055647232786538 MSE test 11.487723397882167\n",
      "MAE train 1.544095329739574 MAE test 2.370295581858565\n",
      "Epoch 8317 / 10000 loss: 12.384185791015625\n",
      "MSE train 5.055537536084581 MSE test 11.487523059331894\n",
      "MAE train 1.5440785193821163 MAE test 2.370269897479616\n",
      "Epoch 8318 / 10000 loss: 12.383669137954712\n",
      "MSE train 5.055431550994112 MSE test 11.48747416494071\n",
      "MAE train 1.54405856931876 MAE test 2.3702686881798547\n",
      "Epoch 8319 / 10000 loss: 12.383291006088257\n",
      "MSE train 5.055321300675111 MSE test 11.48724224382788\n",
      "MAE train 1.5440422847074473 MAE test 2.3702387913673952\n",
      "Epoch 8320 / 10000 loss: 12.382883310317993\n",
      "MSE train 5.055222394916013 MSE test 11.487239988843411\n",
      "MAE train 1.5440231950117074 MAE test 2.370243804408139\n",
      "Epoch 8321 / 10000 loss: 12.382525444030762\n",
      "MSE train 5.055112991072738 MSE test 11.486947260256091\n",
      "MAE train 1.544008252152646 MAE test 2.370205799186098\n",
      "Epoch 8322 / 10000 loss: 12.382115602493286\n",
      "MSE train 5.054992258684233 MSE test 11.486973741890692\n",
      "MAE train 1.5439829158876308 MAE test 2.370214748806474\n",
      "Epoch 8323 / 10000 loss: 12.381808042526245\n",
      "MSE train 5.054882698161726 MSE test 11.48677437371382\n",
      "MAE train 1.5439661188522547 MAE test 2.3701892059548437\n",
      "Epoch 8324 / 10000 loss: 12.381290674209595\n",
      "MSE train 5.0547764801496795 MSE test 11.486724226820572\n",
      "MAE train 1.5439461217941153 MAE test 2.3701878240061314\n",
      "Epoch 8325 / 10000 loss: 12.38091254234314\n",
      "MSE train 5.054666250358809 MSE test 11.486494635389294\n",
      "MAE train 1.5439297973055874 MAE test 2.3701582324285644\n",
      "Epoch 8326 / 10000 loss: 12.380505084991455\n",
      "MSE train 5.054567532731474 MSE test 11.486490352360745\n",
      "MAE train 1.5439107903637144 MAE test 2.3701629736004395\n",
      "Epoch 8327 / 10000 loss: 12.380145072937012\n",
      "MSE train 5.054458219885624 MSE test 11.486198556820517\n",
      "MAE train 1.5438958489143852 MAE test 2.3701250844747546\n",
      "Epoch 8328 / 10000 loss: 12.379737138748169\n",
      "MSE train 5.054337766007802 MSE test 11.486224848666566\n",
      "MAE train 1.5438705878070489 MAE test 2.370134020640748\n",
      "Epoch 8329 / 10000 loss: 12.379429340362549\n",
      "MSE train 5.054228146020631 MSE test 11.486024300257265\n",
      "MAE train 1.5438537843465638 MAE test 2.370108292345914\n",
      "Epoch 8330 / 10000 loss: 12.378913164138794\n",
      "MSE train 5.054122498464498 MSE test 11.485976511790724\n",
      "MAE train 1.5438338935514484 MAE test 2.370107233239405\n",
      "Epoch 8331 / 10000 loss: 12.378535985946655\n",
      "MSE train 5.054012279806253 MSE test 11.485742837677357\n",
      "MAE train 1.5438176449940986 MAE test 2.3700770965432874\n",
      "Epoch 8332 / 10000 loss: 12.37812852859497\n",
      "MSE train 5.053913327972896 MSE test 11.485742213089457\n",
      "MAE train 1.5437985006457664 MAE test 2.3700823377954343\n",
      "Epoch 8333 / 10000 loss: 12.377771615982056\n",
      "MSE train 5.05380393923432 MSE test 11.485449534755485\n",
      "MAE train 1.543783554998682 MAE test 2.370044328439038\n",
      "Epoch 8334 / 10000 loss: 12.377360582351685\n",
      "MSE train 5.053683261742786 MSE test 11.485475784930893\n",
      "MAE train 1.5437582201293791 MAE test 2.3700532530808553\n",
      "Epoch 8335 / 10000 loss: 12.377053022384644\n",
      "MSE train 5.053573839031076 MSE test 11.485276929448384\n",
      "MAE train 1.5437414389731066 MAE test 2.370027761921551\n",
      "Epoch 8336 / 10000 loss: 12.37653636932373\n",
      "MSE train 5.053467615843286 MSE test 11.485226517977189\n",
      "MAE train 1.5437214347317607 MAE test 2.370026338097376\n",
      "Epoch 8337 / 10000 loss: 12.376157999038696\n",
      "MSE train 5.053357507284785 MSE test 11.48499773950531\n",
      "MAE train 1.5437051077614656 MAE test 2.369996849147845\n",
      "Epoch 8338 / 10000 loss: 12.375749826431274\n",
      "MSE train 5.053258839137989 MSE test 11.48499294519919\n",
      "MAE train 1.5436861245238844 MAE test 2.370001528101467\n",
      "Epoch 8339 / 10000 loss: 12.375389575958252\n",
      "MSE train 5.053149593410821 MSE test 11.484701485539563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5436711910209187 MAE test 2.3699636777418287\n",
      "Epoch 8340 / 10000 loss: 12.374983549118042\n",
      "MSE train 5.053029359913262 MSE test 11.484727830333041\n",
      "MAE train 1.5436459709800128 MAE test 2.369972611351125\n",
      "Epoch 8341 / 10000 loss: 12.374675273895264\n",
      "MSE train 5.052919697804703 MSE test 11.484526753178203\n",
      "MAE train 1.5436291665263515 MAE test 2.369946817518282\n",
      "Epoch 8342 / 10000 loss: 12.374159812927246\n",
      "MSE train 5.052814362368799 MSE test 11.484479851395518\n",
      "MAE train 1.5436093272127196 MAE test 2.3699458814941767\n",
      "Epoch 8343 / 10000 loss: 12.373782634735107\n",
      "MSE train 5.052704214541591 MSE test 11.484244792087754\n",
      "MAE train 1.5435931146066115 MAE test 2.369915540710649\n",
      "Epoch 8344 / 10000 loss: 12.373375654220581\n",
      "MSE train 5.052605121778566 MSE test 11.484245453991006\n",
      "MAE train 1.543573904127033 MAE test 2.3699209655343565\n",
      "Epoch 8345 / 10000 loss: 12.37302041053772\n",
      "MSE train 5.052495772717341 MSE test 11.483952909474308\n",
      "MAE train 1.5435589555042384 MAE test 2.3698829568628867\n",
      "Epoch 8346 / 10000 loss: 12.372607469558716\n",
      "MSE train 5.052375266754675 MSE test 11.483979152516516\n",
      "MAE train 1.5435336531904886 MAE test 2.369891883914964\n",
      "Epoch 8347 / 10000 loss: 12.372300386428833\n",
      "MSE train 5.052265804338186 MSE test 11.483780046199277\n",
      "MAE train 1.5435168647450404 MAE test 2.3698663392300476\n",
      "Epoch 8348 / 10000 loss: 12.371784210205078\n",
      "MSE train 5.052159764227302 MSE test 11.48373004596308\n",
      "MAE train 1.543496890693655 MAE test 2.3698649897445305\n",
      "Epoch 8349 / 10000 loss: 12.371406555175781\n",
      "MSE train 5.052049662030946 MSE test 11.48350065226149\n",
      "MAE train 1.5434805760945798 MAE test 2.3698354035268223\n",
      "Epoch 8350 / 10000 loss: 12.37099838256836\n",
      "MSE train 5.0519510235399325 MSE test 11.483496446407294\n",
      "MAE train 1.5434615798917573 MAE test 2.3698401718859077\n",
      "Epoch 8351 / 10000 loss: 12.370639324188232\n",
      "MSE train 5.051841872410663 MSE test 11.483204967322042\n",
      "MAE train 1.5434466632990953 MAE test 2.369802304906537\n",
      "Epoch 8352 / 10000 loss: 12.370231866836548\n",
      "MSE train 5.05172161090165 MSE test 11.48323123515427\n",
      "MAE train 1.5434214221080067 MAE test 2.369811236511179\n",
      "Epoch 8353 / 10000 loss: 12.369923830032349\n",
      "MSE train 5.051612028698399 MSE test 11.483030796181556\n",
      "MAE train 1.543404624563419 MAE test 2.369785512216047\n",
      "Epoch 8354 / 10000 loss: 12.369408369064331\n",
      "MSE train 5.051506574130631 MSE test 11.482983152691718\n",
      "MAE train 1.543384757632075 MAE test 2.3697844833405135\n",
      "Epoch 8355 / 10000 loss: 12.369031190872192\n",
      "MSE train 5.051396448537286 MSE test 11.482749514983194\n",
      "MAE train 1.5433685202766387 MAE test 2.369754323076202\n",
      "Epoch 8356 / 10000 loss: 12.368623971939087\n",
      "MSE train 5.051297595399691 MSE test 11.482749058756548\n",
      "MAE train 1.5433493838599348 MAE test 2.369759594672825\n",
      "Epoch 8357 / 10000 loss: 12.36826777458191\n",
      "MSE train 5.051188275022734 MSE test 11.482456639614968\n",
      "MAE train 1.54333443982853 MAE test 2.3697216028843395\n",
      "Epoch 8358 / 10000 loss: 12.36785626411438\n",
      "MSE train 5.05106781680516 MSE test 11.482482829833332\n",
      "MAE train 1.5433091418245455 MAE test 2.36973051860341\n",
      "Epoch 8359 / 10000 loss: 12.367549657821655\n",
      "MSE train 5.050958423878891 MSE test 11.482284039032692\n",
      "MAE train 1.5432923610080713 MAE test 2.3697050125287342\n",
      "Epoch 8360 / 10000 loss: 12.367033004760742\n",
      "MSE train 5.050852421906161 MSE test 11.482233831011378\n",
      "MAE train 1.54327238733988 MAE test 2.369703632064341\n",
      "Epoch 8361 / 10000 loss: 12.366655826568604\n",
      "MSE train 5.050742346125523 MSE test 11.482004692160864\n",
      "MAE train 1.5432560706624552 MAE test 2.3696740680616757\n",
      "Epoch 8362 / 10000 loss: 12.36624789237976\n",
      "MSE train 5.050643757721321 MSE test 11.482000359075053\n",
      "MAE train 1.5432370849110986 MAE test 2.369678839436347\n",
      "Epoch 8363 / 10000 loss: 12.365889310836792\n",
      "MSE train 5.050534645413832 MSE test 11.481708961288424\n",
      "MAE train 1.5432221712475005 MAE test 2.3696409722857545\n",
      "Epoch 8364 / 10000 loss: 12.365481853485107\n",
      "MSE train 5.05041447039833 MSE test 11.481735240151798\n",
      "MAE train 1.543196944488178 MAE test 2.369649912037061\n",
      "Epoch 8365 / 10000 loss: 12.365174531936646\n",
      "MSE train 5.050304933025445 MSE test 11.481534755572508\n",
      "MAE train 1.5431801527903235 MAE test 2.369624173327657\n",
      "Epoch 8366 / 10000 loss: 12.36465859413147\n",
      "MSE train 5.0501995191444164 MSE test 11.481487187637489\n",
      "MAE train 1.5431602914653058 MAE test 2.369623153659657\n",
      "Epoch 8367 / 10000 loss: 12.36428189277649\n",
      "MSE train 5.050089474187072 MSE test 11.481253355282357\n",
      "MAE train 1.5431440730126595 MAE test 2.3695929648594083\n",
      "Epoch 8368 / 10000 loss: 12.363874673843384\n",
      "MSE train 5.04999061555821 MSE test 11.481253120445755\n",
      "MAE train 1.5431249212775788 MAE test 2.3695982759809753\n",
      "Epoch 8369 / 10000 loss: 12.363519430160522\n",
      "MSE train 5.049881323021878 MSE test 11.480960826076512\n",
      "MAE train 1.5431099787514804 MAE test 2.3695602933024107\n",
      "Epoch 8370 / 10000 loss: 12.363107681274414\n",
      "MSE train 5.049760899506459 MSE test 11.480987112206016\n",
      "MAE train 1.543084684808797 MAE test 2.369569241141395\n",
      "Epoch 8371 / 10000 loss: 12.362800121307373\n",
      "MSE train 5.049651515182112 MSE test 11.480788064794437\n",
      "MAE train 1.5430679036509214 MAE test 2.369543687341537\n",
      "Epoch 8372 / 10000 loss: 12.362284660339355\n",
      "MSE train 5.049545622748077 MSE test 11.480738108519756\n",
      "MAE train 1.543047949737777 MAE test 2.3695423351844935\n",
      "Epoch 8373 / 10000 loss: 12.361907243728638\n",
      "MSE train 5.049435546856815 MSE test 11.480508623316593\n",
      "MAE train 1.5430316372590707 MAE test 2.3695127373215854\n",
      "Epoch 8374 / 10000 loss: 12.361499547958374\n",
      "MSE train 5.049337066918262 MSE test 11.480504583279933\n",
      "MAE train 1.5430126571865832 MAE test 2.369517551400319\n",
      "Epoch 8375 / 10000 loss: 12.361140727996826\n",
      "MSE train 5.0492279015531905 MSE test 11.480213232411193\n",
      "MAE train 1.542997727061944 MAE test 2.3694796833898826\n",
      "Epoch 8376 / 10000 loss: 12.360733270645142\n",
      "MSE train 5.049107705579357 MSE test 11.480239506930994\n",
      "MAE train 1.5429724993349299 MAE test 2.3694886204930743\n",
      "Epoch 8377 / 10000 loss: 12.3604257106781\n",
      "MSE train 5.04899820285613 MSE test 11.480038994908695\n",
      "MAE train 1.542955704782207 MAE test 2.3694628779532354\n",
      "Epoch 8378 / 10000 loss: 12.359910726547241\n",
      "MSE train 5.048892868022692 MSE test 11.479991354142483\n",
      "MAE train 1.5429358575968535 MAE test 2.369461848059826\n",
      "Epoch 8379 / 10000 loss: 12.359533548355103\n",
      "MSE train 5.048782821760014 MSE test 11.479757686058516\n",
      "MAE train 1.5429196258123827 MAE test 2.3694316861478186\n",
      "Epoch 8380 / 10000 loss: 12.359127044677734\n",
      "MSE train 5.04868399449894 MSE test 11.47975718323405\n",
      "MAE train 1.5429004861181808 MAE test 2.3694369639381963\n",
      "Epoch 8381 / 10000 loss: 12.358771085739136\n",
      "MSE train 5.048574720566725 MSE test 11.47946499926726\n",
      "MAE train 1.5428855401150656 MAE test 2.369398987881269\n",
      "Epoch 8382 / 10000 loss: 12.358359813690186\n",
      "MSE train 5.048454340784539 MSE test 11.479491169780205\n",
      "MAE train 1.5428602521481576 MAE test 2.3694079101478156\n",
      "Epoch 8383 / 10000 loss: 12.358052730560303\n",
      "MSE train 5.048345008203778 MSE test 11.47929221563792\n",
      "MAE train 1.5428434754037936 MAE test 2.369382370890411\n",
      "Epoch 8384 / 10000 loss: 12.357536792755127\n",
      "MSE train 5.048239116859193 MSE test 11.479242141158926\n",
      "MAE train 1.5428235220705186 MAE test 2.369381025632557\n",
      "Epoch 8385 / 10000 loss: 12.357160091400146\n",
      "MSE train 5.048129105787332 MSE test 11.479012750301328\n",
      "MAE train 1.5428072123290097 MAE test 2.3693514301142424\n",
      "Epoch 8386 / 10000 loss: 12.356751918792725\n",
      "MSE train 5.04803056856441 MSE test 11.479008543323038\n",
      "MAE train 1.5427882238150505 MAE test 2.3693562015539147\n",
      "Epoch 8387 / 10000 loss: 12.356393098831177\n",
      "MSE train 5.047921431950287 MSE test 11.478717235106181\n",
      "MAE train 1.5427732990247718 MAE test 2.3693183575044827\n",
      "Epoch 8388 / 10000 loss: 12.35598635673523\n",
      "MSE train 5.047801256178498 MSE test 11.478743449181238\n",
      "MAE train 1.5427480680545136 MAE test 2.369327279792076\n",
      "Epoch 8389 / 10000 loss: 12.355678796768188\n",
      "MSE train 5.0476918047914765 MSE test 11.478543125542416\n",
      "MAE train 1.542731276699083 MAE test 2.369301565662048\n",
      "Epoch 8390 / 10000 loss: 12.355163335800171\n",
      "MSE train 5.047586431673701 MSE test 11.478495138985197\n",
      "MAE train 1.5427114232193406 MAE test 2.369300497119911\n",
      "Epoch 8391 / 10000 loss: 12.354786396026611\n",
      "MSE train 5.047476420822379 MSE test 11.478261846842353\n",
      "MAE train 1.5426951850784305 MAE test 2.3692703749744517\n",
      "Epoch 8392 / 10000 loss: 12.354379653930664\n",
      "MSE train 5.047377637478815 MSE test 11.478261092762528\n",
      "MAE train 1.5426760589114787 MAE test 2.3692756300909625\n",
      "Epoch 8393 / 10000 loss: 12.354024171829224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.047268363706621 MSE test 11.477969045207935\n",
      "MAE train 1.5426611129029106 MAE test 2.369237678379575\n",
      "Epoch 8394 / 10000 loss: 12.353613138198853\n",
      "MSE train 5.047148011718883 MSE test 11.477995038661215\n",
      "MAE train 1.5426358293082638 MAE test 2.369246575437015\n",
      "Epoch 8395 / 10000 loss: 12.35330605506897\n",
      "MSE train 5.047038673235917 MSE test 11.47779601215162\n",
      "MAE train 1.5426190475339312 MAE test 2.3692210235781754\n",
      "Epoch 8396 / 10000 loss: 12.352790594100952\n",
      "MSE train 5.046932796860976 MSE test 11.477746022772665\n",
      "MAE train 1.5425991003855506 MAE test 2.3692196831300163\n",
      "Epoch 8397 / 10000 loss: 12.352412462234497\n",
      "MSE train 5.046822805350469 MSE test 11.477516437024159\n",
      "MAE train 1.5425827877967555 MAE test 2.3691900699015713\n",
      "Epoch 8398 / 10000 loss: 12.35200572013855\n",
      "MSE train 5.04672426468107 MSE test 11.477512375636726\n",
      "MAE train 1.5425637951524491 MAE test 2.369194861637268\n",
      "Epoch 8399 / 10000 loss: 12.35164737701416\n",
      "MSE train 5.0466151128524555 MSE test 11.47722109023265\n",
      "MAE train 1.5425488593937473 MAE test 2.3691570118979612\n",
      "Epoch 8400 / 10000 loss: 12.351239681243896\n",
      "MSE train 5.046494962339885 MSE test 11.477246987389275\n",
      "MAE train 1.5425236363534691 MAE test 2.3691658967576723\n",
      "Epoch 8401 / 10000 loss: 12.350931644439697\n",
      "MSE train 5.04638546979833 MSE test 11.477046760094058\n",
      "MAE train 1.5425068346336974 MAE test 2.369140192923871\n",
      "Epoch 8402 / 10000 loss: 12.350416898727417\n",
      "MSE train 5.046280150078372 MSE test 11.476998749758646\n",
      "MAE train 1.5424869866971085 MAE test 2.3691391147102787\n",
      "Epoch 8403 / 10000 loss: 12.3500394821167\n",
      "MSE train 5.046170089864752 MSE test 11.47676537057217\n",
      "MAE train 1.542470739505666 MAE test 2.369108994379301\n",
      "Epoch 8404 / 10000 loss: 12.349633932113647\n",
      "MSE train 5.046071309394547 MSE test 11.476764507695442\n",
      "MAE train 1.5424516167314481 MAE test 2.3691142160531524\n",
      "Epoch 8405 / 10000 loss: 12.349277973175049\n",
      "MSE train 5.045962018941374 MSE test 11.4764725137233\n",
      "MAE train 1.5424366506897331 MAE test 2.369076285620809\n",
      "Epoch 8406 / 10000 loss: 12.34886622428894\n",
      "MSE train 5.045841769311762 MSE test 11.476498454639938\n",
      "MAE train 1.5424113891806708 MAE test 2.36908517906294\n",
      "Epoch 8407 / 10000 loss: 12.348559141159058\n",
      "MSE train 5.045732384984756 MSE test 11.476299246809925\n",
      "MAE train 1.54239459740154 MAE test 2.3690595964864745\n",
      "Epoch 8408 / 10000 loss: 12.34804391860962\n",
      "MSE train 5.045626584435359 MSE test 11.47624943657999\n",
      "MAE train 1.5423746626170973 MAE test 2.3690582902190376\n",
      "Epoch 8409 / 10000 loss: 12.347665786743164\n",
      "MSE train 5.045516495083852 MSE test 11.476019150466271\n",
      "MAE train 1.5423583410914172 MAE test 2.369028569864622\n",
      "Epoch 8410 / 10000 loss: 12.347258806228638\n",
      "MSE train 5.04541800816722 MSE test 11.47601555731272\n",
      "MAE train 1.5423393464568338 MAE test 2.369033443367561\n",
      "Epoch 8411 / 10000 loss: 12.346900463104248\n",
      "MSE train 5.045308818602142 MSE test 11.47572401564956\n",
      "MAE train 1.5423243946626415 MAE test 2.3689955533183604\n",
      "Epoch 8412 / 10000 loss: 12.346492528915405\n",
      "MSE train 5.045188635436964 MSE test 11.475749987060894\n",
      "MAE train 1.5422991597208824 MAE test 2.369004449788446\n",
      "Epoch 8413 / 10000 loss: 12.34618616104126\n",
      "MSE train 5.045079145308187 MSE test 11.47554968569671\n",
      "MAE train 1.5422823583398473 MAE test 2.368978731490859\n",
      "Epoch 8414 / 10000 loss: 12.345670223236084\n",
      "MSE train 5.044973732782128 MSE test 11.475501442292725\n",
      "MAE train 1.54226249354937 MAE test 2.3689776307000847\n",
      "Epoch 8415 / 10000 loss: 12.345293521881104\n",
      "MSE train 5.044863711486092 MSE test 11.47526837681829\n",
      "MAE train 1.542246242572918 MAE test 2.368947554330507\n",
      "Epoch 8416 / 10000 loss: 12.344886779785156\n",
      "MSE train 5.044764964072203 MSE test 11.47526710783169\n",
      "MAE train 1.5422271282198472 MAE test 2.3689527296657804\n",
      "Epoch 8417 / 10000 loss: 12.3445303440094\n",
      "MSE train 5.044655645121594 MSE test 11.474975160694918\n",
      "MAE train 1.5422121529571808 MAE test 2.3689147890242928\n",
      "Epoch 8418 / 10000 loss: 12.344120502471924\n",
      "MSE train 5.04453539720963 MSE test 11.475000993489164\n",
      "MAE train 1.542186896857803 MAE test 2.3689236750020064\n",
      "Epoch 8419 / 10000 loss: 12.343812227249146\n",
      "MSE train 5.044425994439292 MSE test 11.474801453205188\n",
      "MAE train 1.5421701013103342 MAE test 2.3688980490111913\n",
      "Epoch 8420 / 10000 loss: 12.343297004699707\n",
      "MSE train 5.0443201934864605 MSE test 11.47475177843773\n",
      "MAE train 1.5421501651409146 MAE test 2.368896769512096\n",
      "Epoch 8421 / 10000 loss: 12.342920064926147\n",
      "MSE train 5.04421010453554 MSE test 11.474521304396406\n",
      "MAE train 1.5421338505861977 MAE test 2.368867016319781\n",
      "Epoch 8422 / 10000 loss: 12.342512845993042\n",
      "MSE train 5.044111555813023 MSE test 11.474517570282242\n",
      "MAE train 1.5421148329198315 MAE test 2.368871876542798\n",
      "Epoch 8423 / 10000 loss: 12.342154264450073\n",
      "MSE train 5.0440023372607135 MSE test 11.474226168950475\n",
      "MAE train 1.5420998747333534 MAE test 2.368834010908759\n",
      "Epoch 8424 / 10000 loss: 12.341746091842651\n",
      "MSE train 5.043882149380106 MSE test 11.474251898105468\n",
      "MAE train 1.5420746378951953 MAE test 2.3688428860470276\n",
      "Epoch 8425 / 10000 loss: 12.34143877029419\n",
      "MSE train 5.043772653279475 MSE test 11.474051628230571\n",
      "MAE train 1.5420578288473634 MAE test 2.368817152235176\n",
      "Epoch 8426 / 10000 loss: 12.340923309326172\n",
      "MSE train 5.043667138233641 MSE test 11.474003141190714\n",
      "MAE train 1.542037949840402 MAE test 2.3688160345860654\n",
      "Epoch 8427 / 10000 loss: 12.340546369552612\n",
      "MSE train 5.043557096897881 MSE test 11.473770303081437\n",
      "MAE train 1.5420216835228013 MAE test 2.3687859745442794\n",
      "Epoch 8428 / 10000 loss: 12.340139627456665\n",
      "MSE train 5.043458284620034 MSE test 11.473768608594945\n",
      "MAE train 1.5420025642291437 MAE test 2.3687911039205933\n",
      "Epoch 8429 / 10000 loss: 12.339782476425171\n",
      "MSE train 5.0433489758140455 MSE test 11.473476752803577\n",
      "MAE train 1.541987589341997 MAE test 2.36875318477798\n",
      "Epoch 8430 / 10000 loss: 12.339372396469116\n",
      "MSE train 5.04322871904945 MSE test 11.473502386925205\n",
      "MAE train 1.5419623333889492 MAE test 2.3687620401194023\n",
      "Epoch 8431 / 10000 loss: 12.339064359664917\n",
      "MSE train 5.043119273750738 MSE test 11.473302622277822\n",
      "MAE train 1.5419455257598689 MAE test 2.3687363893445186\n",
      "Epoch 8432 / 10000 loss: 12.3385488986969\n",
      "MSE train 5.0430135209260545 MSE test 11.473253185842864\n",
      "MAE train 1.5419256031213204 MAE test 2.3687351441665037\n",
      "Epoch 8433 / 10000 loss: 12.338171243667603\n",
      "MSE train 5.042903424413817 MSE test 11.473021835627497\n",
      "MAE train 1.5419092932154004 MAE test 2.368705269422249\n",
      "Epoch 8434 / 10000 loss: 12.337765216827393\n",
      "MSE train 5.0428047532551 MSE test 11.473018705918626\n",
      "MAE train 1.5418902415491929 MAE test 2.3687102247408753\n",
      "Epoch 8435 / 10000 loss: 12.337407350540161\n",
      "MSE train 5.042695457325982 MSE test 11.47272710016205\n",
      "MAE train 1.5418752641493132 MAE test 2.3686723316249094\n",
      "Epoch 8436 / 10000 loss: 12.336997747421265\n",
      "MSE train 5.042575231541477 MSE test 11.472752636786772\n",
      "MAE train 1.5418500197351772 MAE test 2.3686811756361146\n",
      "Epoch 8437 / 10000 loss: 12.336690187454224\n",
      "MSE train 5.042465691230978 MSE test 11.472552443457937\n",
      "MAE train 1.5418332019330085 MAE test 2.368655463120333\n",
      "Epoch 8438 / 10000 loss: 12.336174726486206\n",
      "MSE train 5.042360096937092 MSE test 11.472503415964463\n",
      "MAE train 1.541813306835448 MAE test 2.3686542824204175\n",
      "Epoch 8439 / 10000 loss: 12.33579707145691\n",
      "MSE train 5.042249922269211 MSE test 11.472271155968741\n",
      "MAE train 1.5417970047701506 MAE test 2.368624284933995\n",
      "Epoch 8440 / 10000 loss: 12.335390090942383\n",
      "MSE train 5.0421511346643015 MSE test 11.472268850244832\n",
      "MAE train 1.5417779063840575 MAE test 2.368629345169853\n",
      "Epoch 8441 / 10000 loss: 12.335033178329468\n",
      "MSE train 5.042041813116827 MSE test 11.471976961381408\n",
      "MAE train 1.541762921000556 MAE test 2.368591415419603\n",
      "Epoch 8442 / 10000 loss: 12.33462381362915\n",
      "MSE train 5.041921513742986 MSE test 11.472002468638552\n",
      "MAE train 1.5417376618884555 MAE test 2.3686002689370333\n",
      "Epoch 8443 / 10000 loss: 12.334315299987793\n",
      "MSE train 5.041811931593191 MSE test 11.471802538699775\n",
      "MAE train 1.5417208354497964 MAE test 2.368574585613903\n",
      "Epoch 8444 / 10000 loss: 12.333800315856934\n",
      "MSE train 5.041706209946753 MSE test 11.471753136064516\n",
      "MAE train 1.5417009158535186 MAE test 2.36857335478531\n",
      "Epoch 8445 / 10000 loss: 12.333422422409058\n",
      "MSE train 5.041596037651622 MSE test 11.471521610440872\n",
      "MAE train 1.5416845887032777 MAE test 2.3685434665058995\n",
      "Epoch 8446 / 10000 loss: 12.333014965057373\n",
      "MSE train 5.041497243948023 MSE test 11.471518378169005\n",
      "MAE train 1.54166551340674 MAE test 2.3685484091213156\n",
      "Epoch 8447 / 10000 loss: 12.33265733718872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.041387901997689 MSE test 11.471226673196728\n",
      "MAE train 1.5416505202121071 MAE test 2.368510504086641\n",
      "Epoch 8448 / 10000 loss: 12.332247972488403\n",
      "MSE train 5.041267637750062 MSE test 11.471252007851247\n",
      "MAE train 1.541625281848174 MAE test 2.3685193336818244\n",
      "Epoch 8449 / 10000 loss: 12.331939935684204\n",
      "MSE train 5.041158001029406 MSE test 11.471051552349936\n",
      "MAE train 1.5416084399292727 MAE test 2.368493584406564\n",
      "Epoch 8450 / 10000 loss: 12.331424474716187\n",
      "MSE train 5.041052414108704 MSE test 11.471002727823803\n",
      "MAE train 1.5415885504513283 MAE test 2.3684924256301687\n",
      "Epoch 8451 / 10000 loss: 12.33104658126831\n",
      "MSE train 5.04094216686981 MSE test 11.470769958618007\n",
      "MAE train 1.5415722354089731 MAE test 2.368462376812962\n",
      "Epoch 8452 / 10000 loss: 12.330639600753784\n",
      "MSE train 5.0408432803485885 MSE test 11.470767660453303\n",
      "MAE train 1.5415531143103696 MAE test 2.368467447159979\n",
      "Epoch 8453 / 10000 loss: 12.330281972885132\n",
      "MSE train 5.040733813938113 MSE test 11.470475829868022\n",
      "MAE train 1.5415380950745379 MAE test 2.368429525230082\n",
      "Epoch 8454 / 10000 loss: 12.329871892929077\n",
      "MSE train 5.0406134877853725 MSE test 11.470501030108501\n",
      "MAE train 1.541512843721176 MAE test 2.3684383366451396\n",
      "Epoch 8455 / 10000 loss: 12.32956314086914\n",
      "MSE train 5.04050383503183 MSE test 11.470300981267638\n",
      "MAE train 1.5414959964995991 MAE test 2.368412641752525\n",
      "Epoch 8456 / 10000 loss: 12.329047679901123\n",
      "MSE train 5.040398072373686 MSE test 11.470251340026467\n",
      "MAE train 1.5414760751031176 MAE test 2.368411392531356\n",
      "Epoch 8457 / 10000 loss: 12.328670024871826\n",
      "MSE train 5.040287848434579 MSE test 11.470019541767185\n",
      "MAE train 1.541459740312711 MAE test 2.3683814588097607\n",
      "Epoch 8458 / 10000 loss: 12.328262329101562\n",
      "MSE train 5.040189004273037 MSE test 11.470016338911229\n",
      "MAE train 1.5414406501082896 MAE test 2.368386414402902\n",
      "Epoch 8459 / 10000 loss: 12.32790493965149\n",
      "MSE train 5.040079497162964 MSE test 11.469724639992494\n",
      "MAE train 1.5414256202510033 MAE test 2.3683485123050794\n",
      "Epoch 8460 / 10000 loss: 12.327494859695435\n",
      "MSE train 5.039959136050124 MSE test 11.469749662863743\n",
      "MAE train 1.5414003674215715 MAE test 2.368357291562288\n",
      "Epoch 8461 / 10000 loss: 12.327186107635498\n",
      "MSE train 5.039849415221018 MSE test 11.469549435748803\n",
      "MAE train 1.541383505518523 MAE test 2.368331586957791\n",
      "Epoch 8462 / 10000 loss: 12.326670408248901\n",
      "MSE train 5.039743700193215 MSE test 11.469500110082041\n",
      "MAE train 1.5413635958428218 MAE test 2.368330377279414\n",
      "Epoch 8463 / 10000 loss: 12.326293230056763\n",
      "MSE train 5.039633390540535 MSE test 11.469267729491778\n",
      "MAE train 1.5413472498472964 MAE test 2.3683003755445897\n",
      "Epoch 8464 / 10000 loss: 12.32588529586792\n",
      "MSE train 5.039534450764262 MSE test 11.469264874581533\n",
      "MAE train 1.5413281327836115 MAE test 2.3683053731345804\n",
      "Epoch 8465 / 10000 loss: 12.32552719116211\n",
      "MSE train 5.039424941236213 MSE test 11.468972896339531\n",
      "MAE train 1.5413130972886417 MAE test 2.3682674385348808\n",
      "Epoch 8466 / 10000 loss: 12.325117111206055\n",
      "MSE train 5.039304523914995 MSE test 11.468997898155731\n",
      "MAE train 1.5412878335734432 MAE test 2.368276218568319\n",
      "Epoch 8467 / 10000 loss: 12.324808835983276\n",
      "MSE train 5.039194757127559 MSE test 11.468797659411296\n",
      "MAE train 1.541270955346069 MAE test 2.3682505132857172\n",
      "Epoch 8468 / 10000 loss: 12.32429313659668\n",
      "MSE train 5.039088940742258 MSE test 11.468748006791072\n",
      "MAE train 1.5412510305491143 MAE test 2.3682492515753464\n",
      "Epoch 8469 / 10000 loss: 12.323914289474487\n",
      "MSE train 5.038978550711585 MSE test 11.468516006588723\n",
      "MAE train 1.5412346643464985 MAE test 2.36821930212278\n",
      "Epoch 8470 / 10000 loss: 12.323506832122803\n",
      "MSE train 5.038879643597089 MSE test 11.468512582832824\n",
      "MAE train 1.5412155595363182 MAE test 2.3682242274736565\n",
      "Epoch 8471 / 10000 loss: 12.323148250579834\n",
      "MSE train 5.0387700518751135 MSE test 11.468220833600279\n",
      "MAE train 1.5412005095482746 MAE test 2.368186333588903\n",
      "Epoch 8472 / 10000 loss: 12.32273817062378\n",
      "MSE train 5.038649600243914 MSE test 11.468245742800429\n",
      "MAE train 1.5411752528775409 MAE test 2.3681951096122438\n",
      "Epoch 8473 / 10000 loss: 12.322429418563843\n",
      "MSE train 5.038539761820901 MSE test 11.468045335467629\n",
      "MAE train 1.541158362803572 MAE test 2.3681693815003184\n",
      "Epoch 8474 / 10000 loss: 12.321913719177246\n",
      "MSE train 5.038434042842213 MSE test 11.467995821873517\n",
      "MAE train 1.5411384609599184 MAE test 2.3681681513608974\n",
      "Epoch 8475 / 10000 loss: 12.321535110473633\n",
      "MSE train 5.038323611260377 MSE test 11.467763149166432\n",
      "MAE train 1.541122098227092 MAE test 2.3681381149773215\n",
      "Epoch 8476 / 10000 loss: 12.32112741470337\n",
      "MSE train 5.038224550088281 MSE test 11.46776024869812\n",
      "MAE train 1.5411029556010318 MAE test 2.3681431019326724\n",
      "Epoch 8477 / 10000 loss: 12.320769548416138\n",
      "MSE train 5.038114954505651 MSE test 11.467468339812847\n",
      "MAE train 1.5410878957046155 MAE test 2.368105197116195\n",
      "Epoch 8478 / 10000 loss: 12.320358514785767\n",
      "MSE train 5.037994460808043 MSE test 11.467493147114949\n",
      "MAE train 1.5410626289986618 MAE test 2.3681139543923306\n",
      "Epoch 8479 / 10000 loss: 12.320049524307251\n",
      "MSE train 5.037884622306996 MSE test 11.467292637655376\n",
      "MAE train 1.541045734479184 MAE test 2.3680882160061145\n",
      "Epoch 8480 / 10000 loss: 12.319533109664917\n",
      "MSE train 5.037778785333853 MSE test 11.467243072374364\n",
      "MAE train 1.5410258143155635 MAE test 2.368086988449264\n",
      "Epoch 8481 / 10000 loss: 12.319154977798462\n",
      "MSE train 5.037668287805727 MSE test 11.467010350530305\n",
      "MAE train 1.5410094339458973 MAE test 2.368056947362425\n",
      "Epoch 8482 / 10000 loss: 12.31874704360962\n",
      "MSE train 5.0375692439417605 MSE test 11.46700737458695\n",
      "MAE train 1.5409902984509063 MAE test 2.368061933288335\n",
      "Epoch 8483 / 10000 loss: 12.31838846206665\n",
      "MSE train 5.037459516378031 MSE test 11.466715420052457\n",
      "MAE train 1.5409752166576045 MAE test 2.3680240214119803\n",
      "Epoch 8484 / 10000 loss: 12.317977905273438\n",
      "MSE train 5.0373390313005375 MSE test 11.46674003300667\n",
      "MAE train 1.5409499553532788 MAE test 2.368032758467931\n",
      "Epoch 8485 / 10000 loss: 12.317669153213501\n",
      "MSE train 5.037229098659691 MSE test 11.466539634943466\n",
      "MAE train 1.5409330475881156 MAE test 2.368007037776905\n",
      "Epoch 8486 / 10000 loss: 12.31715178489685\n",
      "MSE train 5.037123234823388 MSE test 11.466489891074868\n",
      "MAE train 1.5409131205819786 MAE test 2.3680057853723904\n",
      "Epoch 8487 / 10000 loss: 12.316773891448975\n",
      "MSE train 5.0370127240587825 MSE test 11.466257432406898\n",
      "MAE train 1.5408967284740989 MAE test 2.3679757726082458\n",
      "Epoch 8488 / 10000 loss: 12.316365718841553\n",
      "MSE train 5.036913633953052 MSE test 11.466254152708197\n",
      "MAE train 1.540877593654442 MAE test 2.367980733017617\n",
      "Epoch 8489 / 10000 loss: 12.316007614135742\n",
      "MSE train 5.036803915989327 MSE test 11.465962226773675\n",
      "MAE train 1.540862504975476 MAE test 2.3679428362452786\n",
      "Epoch 8490 / 10000 loss: 12.315596103668213\n",
      "MSE train 5.03668340849696 MSE test 11.46598689758772\n",
      "MAE train 1.5408372441394922 MAE test 2.3679515752798475\n",
      "Epoch 8491 / 10000 loss: 12.31528639793396\n",
      "MSE train 5.036573458314409 MSE test 11.46578633085702\n",
      "MAE train 1.5408203270293093 MAE test 2.3679258355223967\n",
      "Epoch 8492 / 10000 loss: 12.314770698547363\n",
      "MSE train 5.0364675736682045 MSE test 11.465736604265878\n",
      "MAE train 1.5408004005174438 MAE test 2.367924577842282\n",
      "Epoch 8493 / 10000 loss: 12.314391613006592\n",
      "MSE train 5.036356992498947 MSE test 11.46550391746855\n",
      "MAE train 1.540783999691938 MAE test 2.3678945710272763\n",
      "Epoch 8494 / 10000 loss: 12.313983678817749\n",
      "MSE train 5.036257893702768 MSE test 11.465500673689103\n",
      "MAE train 1.540764862070518 MAE test 2.3678995288546183\n",
      "Epoch 8495 / 10000 loss: 12.313624620437622\n",
      "MSE train 5.036148150215532 MSE test 11.465208830853731\n",
      "MAE train 1.5407497706321747 MAE test 2.3678616415898746\n",
      "Epoch 8496 / 10000 loss: 12.313214302062988\n",
      "MSE train 5.036027608804989 MSE test 11.465233453607995\n",
      "MAE train 1.540724506450223 MAE test 2.3678703906284486\n",
      "Epoch 8497 / 10000 loss: 12.312904357910156\n",
      "MSE train 5.0359176600583355 MSE test 11.465032824839248\n",
      "MAE train 1.5407075887219095 MAE test 2.3678446451042747\n",
      "Epoch 8498 / 10000 loss: 12.312389135360718\n",
      "MSE train 5.035811739111506 MSE test 11.464983086053689\n",
      "MAE train 1.5406876658897584 MAE test 2.3678433794813483\n",
      "Epoch 8499 / 10000 loss: 12.312009811401367\n",
      "MSE train 5.035701176855974 MSE test 11.464750498558388\n",
      "MAE train 1.540671257583291 MAE test 2.367813388868579\n",
      "Epoch 8500 / 10000 loss: 12.311601877212524\n",
      "MSE train 5.035602079369541 MSE test 11.464747288685667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5406521223530503 MAE test 2.3678183466808047\n",
      "Epoch 8501 / 10000 loss: 12.311243295669556\n",
      "MSE train 5.035492324395716 MSE test 11.464455383798011\n",
      "MAE train 1.5406370302692367 MAE test 2.3677804575856043\n",
      "Epoch 8502 / 10000 loss: 12.310831785202026\n",
      "MSE train 5.035371826341866 MSE test 11.464479930336209\n",
      "MAE train 1.5406117701596758 MAE test 2.367789193152369\n",
      "Epoch 8503 / 10000 loss: 12.310521602630615\n",
      "MSE train 5.035261848712035 MSE test 11.464279295945085\n",
      "MAE train 1.5405948351076697 MAE test 2.36776343801862\n",
      "Epoch 8504 / 10000 loss: 12.310006618499756\n",
      "MSE train 5.03515603958544 MSE test 11.464229890697075\n",
      "MAE train 1.5405749301744571 MAE test 2.367762238062207\n",
      "Epoch 8505 / 10000 loss: 12.309627532958984\n",
      "MSE train 5.035045443074596 MSE test 11.463996738493995\n",
      "MAE train 1.5405585250612102 MAE test 2.36773215990725\n",
      "Epoch 8506 / 10000 loss: 12.309219598770142\n",
      "MSE train 5.034946327860739 MSE test 11.463994001813589\n",
      "MAE train 1.5405393738468949 MAE test 2.3677371878399547\n",
      "Epoch 8507 / 10000 loss: 12.30886197090149\n",
      "MSE train 5.034836564644447 MSE test 11.463702183683033\n",
      "MAE train 1.5405242729133906 MAE test 2.3676993137040037\n",
      "Epoch 8508 / 10000 loss: 12.308449268341064\n",
      "MSE train 5.034716081009816 MSE test 11.463726758710568\n",
      "MAE train 1.5404990132869265 MAE test 2.3677080434173376\n",
      "Epoch 8509 / 10000 loss: 12.30814003944397\n",
      "MSE train 5.034606167820767 MSE test 11.463526220305502\n",
      "MAE train 1.5404820874604488 MAE test 2.3676823177828066\n",
      "Epoch 8510 / 10000 loss: 12.307623863220215\n",
      "MSE train 5.034500280133238 MSE test 11.463476709934438\n",
      "MAE train 1.5404621724676464 MAE test 2.3676810877499883\n",
      "Epoch 8511 / 10000 loss: 12.307245254516602\n",
      "MSE train 5.0343898097927005 MSE test 11.463244039337495\n",
      "MAE train 1.540445783560168 MAE test 2.3676510785361415\n",
      "Epoch 8512 / 10000 loss: 12.306838035583496\n",
      "MSE train 5.034290736567905 MSE test 11.4632409554827\n",
      "MAE train 1.540426651067169 MAE test 2.3676560576230568\n",
      "Epoch 8513 / 10000 loss: 12.306479930877686\n",
      "MSE train 5.034181040901058 MSE test 11.462949423538042\n",
      "MAE train 1.5404115533709892 MAE test 2.3676182232159264\n",
      "Epoch 8514 / 10000 loss: 12.306068181991577\n",
      "MSE train 5.034060651442141 MSE test 11.462973936406371\n",
      "MAE train 1.5403863153123432 MAE test 2.3676269470591764\n",
      "Epoch 8515 / 10000 loss: 12.305758714675903\n",
      "MSE train 5.033950749044291 MSE test 11.462773427966686\n",
      "MAE train 1.540369385979066 MAE test 2.3676012209197252\n",
      "Epoch 8516 / 10000 loss: 12.305243968963623\n",
      "MSE train 5.033845024002636 MSE test 11.462724262080068\n",
      "MAE train 1.540349495162754 MAE test 2.367600046078629\n",
      "Epoch 8517 / 10000 loss: 12.304864883422852\n",
      "MSE train 5.033734597708676 MSE test 11.462491134749557\n",
      "MAE train 1.540333113829867 MAE test 2.3675699665023684\n",
      "Epoch 8518 / 10000 loss: 12.304457426071167\n",
      "MSE train 5.03363551553903 MSE test 11.462488690075443\n",
      "MAE train 1.540313969700456 MAE test 2.367575030868425\n",
      "Epoch 8519 / 10000 loss: 12.304100036621094\n",
      "MSE train 5.033525858688538 MSE test 11.462197147620266\n",
      "MAE train 1.5402988698823425 MAE test 2.3675371971018198\n",
      "Epoch 8520 / 10000 loss: 12.303688764572144\n",
      "MSE train 5.033405561150016 MSE test 11.462221767948687\n",
      "MAE train 1.5402736429284298 MAE test 2.367545927952531\n",
      "Epoch 8521 / 10000 loss: 12.303379774093628\n",
      "MSE train 5.0332957377789285 MSE test 11.462021541936823\n",
      "MAE train 1.5402567200514738 MAE test 2.367520234649567\n",
      "Epoch 8522 / 10000 loss: 12.30286431312561\n",
      "MSE train 5.033190106041062 MSE test 11.461972329665006\n",
      "MAE train 1.540236850113363 MAE test 2.367519050318338\n",
      "Epoch 8523 / 10000 loss: 12.302486181259155\n",
      "MSE train 5.0330797088406936 MSE test 11.461739591458592\n",
      "MAE train 1.5402204712632923 MAE test 2.36748902483356\n",
      "Epoch 8524 / 10000 loss: 12.302079200744629\n",
      "MSE train 5.032980807059735 MSE test 11.461737167195633\n",
      "MAE train 1.5402013514676889 MAE test 2.3674940759034535\n",
      "Epoch 8525 / 10000 loss: 12.301721334457397\n",
      "MSE train 5.0328712122321555 MSE test 11.461445822738714\n",
      "MAE train 1.5401862678025895 MAE test 2.367456266352756\n",
      "Epoch 8526 / 10000 loss: 12.301310062408447\n",
      "MSE train 5.0327510327130485 MSE test 11.461470646039011\n",
      "MAE train 1.540161058058008 MAE test 2.3674650337835286\n",
      "Epoch 8527 / 10000 loss: 12.301002025604248\n",
      "MSE train 5.032641262998876 MSE test 11.461270535237384\n",
      "MAE train 1.5401441452078697 MAE test 2.3674393301718357\n",
      "Epoch 8528 / 10000 loss: 12.300487041473389\n",
      "MSE train 5.032535761786255 MSE test 11.461221531487034\n",
      "MAE train 1.5401242940558975 MAE test 2.3674381820256136\n",
      "Epoch 8529 / 10000 loss: 12.300109386444092\n",
      "MSE train 5.0324255377587415 MSE test 11.460988761809567\n",
      "MAE train 1.5401079447739128 MAE test 2.3674081521180543\n",
      "Epoch 8530 / 10000 loss: 12.299702882766724\n",
      "MSE train 5.032326672827219 MSE test 11.460986671299155\n",
      "MAE train 1.5400888217445796 MAE test 2.3674132353315858\n",
      "Epoch 8531 / 10000 loss: 12.299345970153809\n",
      "MSE train 5.032217178488962 MSE test 11.460695662764074\n",
      "MAE train 1.5400737410029444 MAE test 2.36737547178488\n",
      "Epoch 8532 / 10000 loss: 12.298935174942017\n",
      "MSE train 5.032097105206553 MSE test 11.460720809445531\n",
      "MAE train 1.5400485561690758 MAE test 2.3673842758865358\n",
      "Epoch 8533 / 10000 loss: 12.298626899719238\n",
      "MSE train 5.03198747859942 MSE test 11.460520605073224\n",
      "MAE train 1.540031663306512 MAE test 2.367358567536565\n",
      "Epoch 8534 / 10000 loss: 12.298112392425537\n",
      "MSE train 5.031882126794423 MSE test 11.460471901332847\n",
      "MAE train 1.5400118293258862 MAE test 2.367357439202295\n",
      "Epoch 8535 / 10000 loss: 12.297735214233398\n",
      "MSE train 5.031771969318209 MSE test 11.460239338391611\n",
      "MAE train 1.5399954881478546 MAE test 2.3673274376140534\n",
      "Epoch 8536 / 10000 loss: 12.297329425811768\n",
      "MSE train 5.031673253008566 MSE test 11.46023750208029\n",
      "MAE train 1.539976377174433 MAE test 2.3673325672822325\n",
      "Epoch 8537 / 10000 loss: 12.296972513198853\n",
      "MSE train 5.0315638387488555 MSE test 11.459946854882707\n",
      "MAE train 1.5399613118875959 MAE test 2.367294837150525\n",
      "Epoch 8538 / 10000 loss: 12.296562433242798\n",
      "MSE train 5.031443931679431 MSE test 11.459971894956125\n",
      "MAE train 1.5399361419800741 MAE test 2.3673036068011557\n",
      "Epoch 8539 / 10000 loss: 12.29625391960144\n",
      "MSE train 5.03133444820755 MSE test 11.459772008635465\n",
      "MAE train 1.5399192730441418 MAE test 2.3672779459170536\n",
      "Epoch 8540 / 10000 loss: 12.295740365982056\n",
      "MSE train 5.031229203032845 MSE test 11.459723788646187\n",
      "MAE train 1.539899459078232 MAE test 2.3672768856882107\n",
      "Epoch 8541 / 10000 loss: 12.295363187789917\n",
      "MSE train 5.0311192174873645 MSE test 11.45949120081068\n",
      "MAE train 1.539883155731605 MAE test 2.3672468806987848\n",
      "Epoch 8542 / 10000 loss: 12.294957876205444\n",
      "MSE train 5.031020592654587 MSE test 11.459489788199635\n",
      "MAE train 1.5398640620352373 MAE test 2.3672520446938234\n",
      "Epoch 8543 / 10000 loss: 12.294602155685425\n",
      "MSE train 5.030911327116263 MSE test 11.459199263069936\n",
      "MAE train 1.5398490277999914 MAE test 2.3672143299106385\n",
      "Epoch 8544 / 10000 loss: 12.294191837310791\n",
      "MSE train 5.030791587765453 MSE test 11.459224618760564\n",
      "MAE train 1.5398238857866795 MAE test 2.367223140371186\n",
      "Epoch 8545 / 10000 loss: 12.293884992599487\n",
      "MSE train 5.0306821681145015 MSE test 11.45902496376603\n",
      "MAE train 1.5398070218517284 MAE test 2.3671974891091576\n",
      "Epoch 8546 / 10000 loss: 12.293372392654419\n",
      "MSE train 5.030577095875874 MSE test 11.458976917126973\n",
      "MAE train 1.5397872348922863 MAE test 2.3671964611879996\n",
      "Epoch 8547 / 10000 loss: 12.29299521446228\n",
      "MSE train 5.030467173117731 MSE test 11.458744698589237\n",
      "MAE train 1.5397709355701956 MAE test 2.367166491212783\n",
      "Epoch 8548 / 10000 loss: 12.292590379714966\n",
      "MSE train 5.0303686421968195 MSE test 11.458743415150282\n",
      "MAE train 1.539751854619873 MAE test 2.3671716770454148\n",
      "Epoch 8549 / 10000 loss: 12.292234420776367\n",
      "MSE train 5.030259505550182 MSE test 11.458453222211133\n",
      "MAE train 1.5397368385617536 MAE test 2.3671340105960144\n",
      "Epoch 8550 / 10000 loss: 12.29182481765747\n",
      "MSE train 5.030139909690197 MSE test 11.458478835989615\n",
      "MAE train 1.5397117219804972 MAE test 2.3671428374839945\n",
      "Epoch 8551 / 10000 loss: 12.29151725769043\n",
      "MSE train 5.030030615868875 MSE test 11.458279345254272\n",
      "MAE train 1.5396948819837386 MAE test 2.3671172134321568\n",
      "Epoch 8552 / 10000 loss: 12.291004657745361\n",
      "MSE train 5.029925691862893 MSE test 11.458231627715975\n",
      "MAE train 1.5396751216382554 MAE test 2.3671162051737076\n",
      "Epoch 8553 / 10000 loss: 12.290629148483276\n",
      "MSE train 5.029815870426391 MSE test 11.457999387478726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5396588426739677 MAE test 2.367086239092505\n",
      "Epoch 8554 / 10000 loss: 12.290223598480225\n",
      "MSE train 5.0297174716421145 MSE test 11.457998673265225\n",
      "MAE train 1.5396397769604817 MAE test 2.3670914944640447\n",
      "Epoch 8555 / 10000 loss: 12.2898690700531\n",
      "MSE train 5.029608421843672 MSE test 11.457708599657002\n",
      "MAE train 1.539624768159443 MAE test 2.367053825875849\n",
      "Epoch 8556 / 10000 loss: 12.289459705352783\n",
      "MSE train 5.0294889189457965 MSE test 11.45773451880102\n",
      "MAE train 1.5395996607846771 MAE test 2.3670626996603943\n",
      "Epoch 8557 / 10000 loss: 12.28915286064148\n",
      "MSE train 5.029379746921459 MSE test 11.457535198843743\n",
      "MAE train 1.5395828398773101 MAE test 2.3670370969551318\n",
      "Epoch 8558 / 10000 loss: 12.288640975952148\n",
      "MSE train 5.029274963662459 MSE test 11.457487770683946\n",
      "MAE train 1.5395630972252665 MAE test 2.3670361203124055\n",
      "Epoch 8559 / 10000 loss: 12.288265705108643\n",
      "MSE train 5.029165276455336 MSE test 11.457255756578608\n",
      "MAE train 1.5395468348165688 MAE test 2.3670061714915556\n",
      "Epoch 8560 / 10000 loss: 12.28786015510559\n",
      "MSE train 5.0290669605966825 MSE test 11.457255165047785\n",
      "MAE train 1.5395277731651271 MAE test 2.367011430000889\n",
      "Epoch 8561 / 10000 loss: 12.287506341934204\n",
      "MSE train 5.02895803712795 MSE test 11.456965463270203\n",
      "MAE train 1.5395127799136572 MAE test 2.3669738240488285\n",
      "Epoch 8562 / 10000 loss: 12.287097454071045\n",
      "MSE train 5.028838581164734 MSE test 11.456991382586203\n",
      "MAE train 1.5394876839164984 MAE test 2.3669826731598436\n",
      "Epoch 8563 / 10000 loss: 12.286790370941162\n",
      "MSE train 5.028729551654853 MSE test 11.456792453989884\n",
      "MAE train 1.5394708727458508 MAE test 2.366957107712531\n",
      "Epoch 8564 / 10000 loss: 12.28627872467041\n",
      "MSE train 5.028624844082051 MSE test 11.456745284142839\n",
      "MAE train 1.539451139157702 MAE test 2.3669561649093627\n",
      "Epoch 8565 / 10000 loss: 12.285903692245483\n",
      "MSE train 5.02851522266268 MSE test 11.456513275859391\n",
      "MAE train 1.53943488702713 MAE test 2.366926217852861\n",
      "Epoch 8566 / 10000 loss: 12.285499334335327\n",
      "MSE train 5.028417046981252 MSE test 11.4565129349581\n",
      "MAE train 1.5394158413672392 MAE test 2.3669315109781874\n",
      "Epoch 8567 / 10000 loss: 12.285145282745361\n",
      "MSE train 5.0283081579785085 MSE test 11.4562235380417\n",
      "MAE train 1.5394008461158517 MAE test 2.3668939351313676\n",
      "Epoch 8568 / 10000 loss: 12.284736156463623\n",
      "MSE train 5.02818888555425 MSE test 11.456249743954615\n",
      "MAE train 1.539375772129414 MAE test 2.3669028121005744\n",
      "Epoch 8569 / 10000 loss: 12.284429550170898\n",
      "MSE train 5.028079884863036 MSE test 11.456050926314816\n",
      "MAE train 1.5393589643862589 MAE test 2.3668772686408173\n",
      "Epoch 8570 / 10000 loss: 12.283918619155884\n",
      "MSE train 5.02797532913817 MSE test 11.456003870764015\n",
      "MAE train 1.5393392548426366 MAE test 2.3668763182250165\n",
      "Epoch 8571 / 10000 loss: 12.28354263305664\n",
      "MSE train 5.027865796081385 MSE test 11.455772246239244\n",
      "MAE train 1.5393230072495885 MAE test 2.3668464177292643\n",
      "Epoch 8572 / 10000 loss: 12.283139944076538\n",
      "MSE train 5.02776767849932 MSE test 11.455772123852999\n",
      "MAE train 1.5393039780005557 MAE test 2.3668517196915584\n",
      "Epoch 8573 / 10000 loss: 12.282786130905151\n",
      "MSE train 5.027658923102037 MSE test 11.455482852196285\n",
      "MAE train 1.5392889921382884 MAE test 2.3668141738541197\n",
      "Epoch 8574 / 10000 loss: 12.28237795829773\n",
      "MSE train 5.027539721732023 MSE test 11.455509304537236\n",
      "MAE train 1.5392639352567339 MAE test 2.3668230649178494\n",
      "Epoch 8575 / 10000 loss: 12.282071113586426\n",
      "MSE train 5.027430825209722 MSE test 11.455310579709396\n",
      "MAE train 1.5392471358830224 MAE test 2.3667975062064466\n",
      "Epoch 8576 / 10000 loss: 12.28156065940857\n",
      "MSE train 5.027326370324381 MSE test 11.455263839231796\n",
      "MAE train 1.5392274466945963 MAE test 2.3667966098613693\n",
      "Epoch 8577 / 10000 loss: 12.281184911727905\n",
      "MSE train 5.027216886219037 MSE test 11.455032170776672\n",
      "MAE train 1.5392112064125392 MAE test 2.366766704833338\n",
      "Epoch 8578 / 10000 loss: 12.280781507492065\n",
      "MSE train 5.027118902382367 MSE test 11.455032406385019\n",
      "MAE train 1.5391921949888938 MAE test 2.366772039600949\n",
      "Epoch 8579 / 10000 loss: 12.280427932739258\n",
      "MSE train 5.0270102107738746 MSE test 11.454743460227755\n",
      "MAE train 1.5391772216131248 MAE test 2.366734528820721\n",
      "Epoch 8580 / 10000 loss: 12.280020236968994\n",
      "MSE train 5.0268911523620226 MSE test 11.454769916129441\n",
      "MAE train 1.5391521857462835 MAE test 2.3667434164371373\n",
      "Epoch 8581 / 10000 loss: 12.279714345932007\n",
      "MSE train 5.0267822738496015 MSE test 11.454571262612863\n",
      "MAE train 1.539135396842882 MAE test 2.366717873707382\n",
      "Epoch 8582 / 10000 loss: 12.279203176498413\n",
      "MSE train 5.026677952640317 MSE test 11.454524975164732\n",
      "MAE train 1.5391157265372801 MAE test 2.366717019496316\n",
      "Epoch 8583 / 10000 loss: 12.278828859329224\n",
      "MSE train 5.026568600830203 MSE test 11.454293171048818\n",
      "MAE train 1.53909951015881 MAE test 2.366687086336731\n",
      "Epoch 8584 / 10000 loss: 12.278426170349121\n",
      "MSE train 5.026470660422054 MSE test 11.454293769359294\n",
      "MAE train 1.539080493889295 MAE test 2.366692468088407\n",
      "Epoch 8585 / 10000 loss: 12.278072595596313\n",
      "MSE train 5.026362014649153 MSE test 11.454005138595827\n",
      "MAE train 1.5390655188095477 MAE test 2.3666549827057417\n",
      "Epoch 8586 / 10000 loss: 12.277663469314575\n",
      "MSE train 5.026243054372172 MSE test 11.45403168905817\n",
      "MAE train 1.5390405010967279 MAE test 2.3666638881594237\n",
      "Epoch 8587 / 10000 loss: 12.277359008789062\n",
      "MSE train 5.026134293935548 MSE test 11.453833058560452\n",
      "MAE train 1.5390237252879524 MAE test 2.3666383423522186\n",
      "Epoch 8588 / 10000 loss: 12.276848554611206\n",
      "MSE train 5.026030075099188 MSE test 11.45378703515086\n",
      "MAE train 1.5390040679590578 MAE test 2.3666375187745685\n",
      "Epoch 8589 / 10000 loss: 12.276474475860596\n",
      "MSE train 5.025920824598653 MSE test 11.453555237075205\n",
      "MAE train 1.538987868112943 MAE test 2.366607585320469\n",
      "Epoch 8590 / 10000 loss: 12.276071548461914\n",
      "MSE train 5.025822899639561 MSE test 11.453556152806263\n",
      "MAE train 1.5389688442860077 MAE test 2.3666129961156335\n",
      "Epoch 8591 / 10000 loss: 12.275718927383423\n",
      "MSE train 5.025714358435606 MSE test 11.453267750756998\n",
      "MAE train 1.5389538904263231 MAE test 2.366575541684965\n",
      "Epoch 8592 / 10000 loss: 12.275310754776001\n",
      "MSE train 5.025595501798361 MSE test 11.453294396076497\n",
      "MAE train 1.538928883925032 MAE test 2.366584451663898\n",
      "Epoch 8593 / 10000 loss: 12.27500581741333\n",
      "MSE train 5.025486807183053 MSE test 11.453095964109748\n",
      "MAE train 1.5389121165736133 MAE test 2.3665589217168996\n",
      "Epoch 8594 / 10000 loss: 12.274495124816895\n",
      "MSE train 5.025382718320184 MSE test 11.453050106810432\n",
      "MAE train 1.5388924785350897 MAE test 2.3665581190556937\n",
      "Epoch 8595 / 10000 loss: 12.274121284484863\n",
      "MSE train 5.025273526317137 MSE test 11.452818190667903\n",
      "MAE train 1.5388762934967317 MAE test 2.366528165889233\n",
      "Epoch 8596 / 10000 loss: 12.27371859550476\n",
      "MSE train 5.0251756739110585 MSE test 11.452819587067996\n",
      "MAE train 1.5388572645913499 MAE test 2.366533629566693\n",
      "Epoch 8597 / 10000 loss: 12.273367166519165\n",
      "MSE train 5.025067216299443 MSE test 11.452531168890028\n",
      "MAE train 1.5388423243540217 MAE test 2.3664961779018467\n",
      "Epoch 8598 / 10000 loss: 12.272958278656006\n",
      "MSE train 5.024948471050742 MSE test 11.452558053369433\n",
      "MAE train 1.5388173302378714 MAE test 2.3665051047723726\n",
      "Epoch 8599 / 10000 loss: 12.272653579711914\n",
      "MSE train 5.024839877184813 MSE test 11.452359657979066\n",
      "MAE train 1.5388005767251505 MAE test 2.3664795699169208\n",
      "Epoch 8600 / 10000 loss: 12.272143602371216\n",
      "MSE train 5.0247358806752676 MSE test 11.45231396853143\n",
      "MAE train 1.5387809513375126 MAE test 2.3664787822894935\n",
      "Epoch 8601 / 10000 loss: 12.271770238876343\n",
      "MSE train 5.024626793550154 MSE test 11.45208218598704\n",
      "MAE train 1.5387647813318808 MAE test 2.3664488431503927\n",
      "Epoch 8602 / 10000 loss: 12.271368026733398\n",
      "MSE train 5.024529040504234 MSE test 11.452083678223477\n",
      "MAE train 1.5387457634996933 MAE test 2.366454314901814\n",
      "Epoch 8603 / 10000 loss: 12.271016359329224\n",
      "MSE train 5.024420655961505 MSE test 11.451795531478664\n",
      "MAE train 1.5387308275451694 MAE test 2.3664168975739157\n",
      "Epoch 8604 / 10000 loss: 12.270608901977539\n",
      "MSE train 5.024302027799918 MSE test 11.451822426923849\n",
      "MAE train 1.5387058495658619 MAE test 2.3664258080263827\n",
      "Epoch 8605 / 10000 loss: 12.270303726196289\n",
      "MSE train 5.024193513275222 MSE test 11.451624212439818\n",
      "MAE train 1.5386891063708275 MAE test 2.3664002914772277\n",
      "Epoch 8606 / 10000 loss: 12.269794225692749\n",
      "MSE train 5.024089629943438 MSE test 11.451578908928715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.538669494859173 MAE test 2.3663995563851783\n",
      "Epoch 8607 / 10000 loss: 12.269421577453613\n",
      "MSE train 5.0239806412933214 MSE test 11.451347095841522\n",
      "MAE train 1.5386533409168868 MAE test 2.366369603796105\n",
      "Epoch 8608 / 10000 loss: 12.26901912689209\n",
      "MSE train 5.023882954627997 MSE test 11.45134863832107\n",
      "MAE train 1.5386343263339368 MAE test 2.366375083928428\n",
      "Epoch 8609 / 10000 loss: 12.268667936325073\n",
      "MSE train 5.023774648753024 MSE test 11.451060690247367\n",
      "MAE train 1.538619402619306 MAE test 2.3663376846210324\n",
      "Epoch 8610 / 10000 loss: 12.26826000213623\n",
      "MSE train 5.023656180418147 MSE test 11.451087785268594\n",
      "MAE train 1.538594448215572 MAE test 2.3663466109317017\n",
      "Epoch 8611 / 10000 loss: 12.267956495285034\n",
      "MSE train 5.023547696383522 MSE test 11.450889592122754\n",
      "MAE train 1.5385777113646402 MAE test 2.366321102037998\n",
      "Epoch 8612 / 10000 loss: 12.267447233200073\n",
      "MSE train 5.023443954400242 MSE test 11.450844431475822\n",
      "MAE train 1.5385581287228638 MAE test 2.3663203736816496\n",
      "Epoch 8613 / 10000 loss: 12.267074584960938\n",
      "MSE train 5.023335037713455 MSE test 11.450612447024653\n",
      "MAE train 1.5385419912942961 MAE test 2.3662904043367394\n",
      "Epoch 8614 / 10000 loss: 12.26667308807373\n",
      "MSE train 5.02323749312147 MSE test 11.450614339627988\n",
      "MAE train 1.5385229924595394 MAE test 2.3662958986080467\n",
      "Epoch 8615 / 10000 loss: 12.266322374343872\n",
      "MSE train 5.023129222743142 MSE test 11.450326523269876\n",
      "MAE train 1.5385080692582727 MAE test 2.366258523929187\n",
      "Epoch 8616 / 10000 loss: 12.265914678573608\n",
      "MSE train 5.023010858072538 MSE test 11.450353675284722\n",
      "MAE train 1.538483131448859 MAE test 2.366267453924603\n",
      "Epoch 8617 / 10000 loss: 12.265610456466675\n",
      "MSE train 5.022902494279104 MSE test 11.450155624301141\n",
      "MAE train 1.538466407044708 MAE test 2.3662419631179534\n",
      "Epoch 8618 / 10000 loss: 12.265101671218872\n",
      "MSE train 5.0227988259955385 MSE test 11.450110622707447\n",
      "MAE train 1.5384468355458283 MAE test 2.3662412433405637\n",
      "Epoch 8619 / 10000 loss: 12.264729738235474\n",
      "MSE train 5.022690037651802 MSE test 11.449878612944039\n",
      "MAE train 1.538430721291636 MAE test 2.366211260693194\n",
      "Epoch 8620 / 10000 loss: 12.264328479766846\n",
      "MSE train 5.022592497897351 MSE test 11.449880836604253\n",
      "MAE train 1.5384117154975088 MAE test 2.3662168145352678\n",
      "Epoch 8621 / 10000 loss: 12.263977766036987\n",
      "MSE train 5.022484320047203 MSE test 11.449593175840821\n",
      "MAE train 1.5383967974565698 MAE test 2.366179456079886\n",
      "Epoch 8622 / 10000 loss: 12.263570785522461\n",
      "MSE train 5.022366099588152 MSE test 11.449620361159614\n",
      "MAE train 1.5383718877405734 MAE test 2.3661883836249435\n",
      "Epoch 8623 / 10000 loss: 12.263266563415527\n",
      "MSE train 5.022257816814758 MSE test 11.449421981442773\n",
      "MAE train 1.538355171388525 MAE test 2.3661628374223986\n",
      "Epoch 8624 / 10000 loss: 12.262758731842041\n",
      "MSE train 5.022154363669537 MSE test 11.449377540230568\n",
      "MAE train 1.5383356311729866 MAE test 2.3661621889600135\n",
      "Epoch 8625 / 10000 loss: 12.262386798858643\n",
      "MSE train 5.022045632034673 MSE test 11.449145006245475\n",
      "MAE train 1.538319536087808 MAE test 2.36613214780132\n",
      "Epoch 8626 / 10000 loss: 12.261986255645752\n",
      "MSE train 5.021948113184781 MSE test 11.449147651963628\n",
      "MAE train 1.5383005154076959 MAE test 2.366137743619975\n",
      "Epoch 8627 / 10000 loss: 12.26163625717163\n",
      "MSE train 5.021840031593629 MSE test 11.448860349005615\n",
      "MAE train 1.5382856060479522 MAE test 2.3661004290166665\n",
      "Epoch 8628 / 10000 loss: 12.261228322982788\n",
      "MSE train 5.021721923522642 MSE test 11.448887572908237\n",
      "MAE train 1.5382607228797758 MAE test 2.3661093478644535\n",
      "Epoch 8629 / 10000 loss: 12.260924816131592\n",
      "MSE train 5.021613672880194 MSE test 11.448689024865075\n",
      "MAE train 1.5382440084314235 MAE test 2.3660837906132555\n",
      "Epoch 8630 / 10000 loss: 12.260417222976685\n",
      "MSE train 5.021510407742275 MSE test 11.448644912061715\n",
      "MAE train 1.5382245056120951 MAE test 2.3660831919093783\n",
      "Epoch 8631 / 10000 loss: 12.260046482086182\n",
      "MSE train 5.021401774853103 MSE test 11.44841178088722\n",
      "MAE train 1.5382084319343816 MAE test 2.3660530561333983\n",
      "Epoch 8632 / 10000 loss: 12.259645462036133\n",
      "MSE train 5.0213042869598326 MSE test 11.448415104357084\n",
      "MAE train 1.5381893996730276 MAE test 2.3660587553069954\n",
      "Epoch 8633 / 10000 loss: 12.259296894073486\n",
      "MSE train 5.0211962586786365 MSE test 11.448127797185704\n",
      "MAE train 1.5381744944895641 MAE test 2.3660214296387774\n",
      "Epoch 8634 / 10000 loss: 12.258888483047485\n",
      "MSE train 5.021078333499488 MSE test 11.448155014283119\n",
      "MAE train 1.538149644696476 MAE test 2.3660303486437244\n",
      "Epoch 8635 / 10000 loss: 12.258585453033447\n",
      "MSE train 5.020970115494329 MSE test 11.447956206247838\n",
      "MAE train 1.5381329326147495 MAE test 2.3660047553064047\n",
      "Epoch 8636 / 10000 loss: 12.25807809829712\n",
      "MSE train 5.020867079222309 MSE test 11.447912574963667\n",
      "MAE train 1.5381134738869724 MAE test 2.3660041958824736\n",
      "Epoch 8637 / 10000 loss: 12.2577064037323\n",
      "MSE train 5.020758523555171 MSE test 11.447678644289315\n",
      "MAE train 1.5380974390612119 MAE test 2.365973967671185\n",
      "Epoch 8638 / 10000 loss: 12.257307291030884\n",
      "MSE train 5.020660952212756 MSE test 11.447682492169902\n",
      "MAE train 1.5380783609944255 MAE test 2.365979725102263\n",
      "Epoch 8639 / 10000 loss: 12.256959676742554\n",
      "MSE train 5.0205529910138065 MSE test 11.447395585572425\n",
      "MAE train 1.5380634586768591 MAE test 2.3659424652736787\n",
      "Epoch 8640 / 10000 loss: 12.256550312042236\n",
      "MSE train 5.020435269883499 MSE test 11.447422635565523\n",
      "MAE train 1.5380386576371858 MAE test 2.3659513547817084\n",
      "Epoch 8641 / 10000 loss: 12.25624680519104\n",
      "MSE train 5.020327109621349 MSE test 11.447223324135534\n",
      "MAE train 1.5380219623296059 MAE test 2.365925687222113\n",
      "Epoch 8642 / 10000 loss: 12.255741119384766\n",
      "MSE train 5.020224393932321 MSE test 11.447180537274523\n",
      "MAE train 1.5380025665750123 MAE test 2.3659252442797243\n",
      "Epoch 8643 / 10000 loss: 12.255370855331421\n",
      "MSE train 5.020115885601613 MSE test 11.446945092796165\n",
      "MAE train 1.5379865705120246 MAE test 2.3658948136480977\n",
      "Epoch 8644 / 10000 loss: 12.254971742630005\n",
      "MSE train 5.020018139062014 MSE test 11.446950197738234\n",
      "MAE train 1.5379674106802366 MAE test 2.3659007411590802\n",
      "Epoch 8645 / 10000 loss: 12.254625082015991\n",
      "MSE train 5.019910171064037 MSE test 11.446663768240503\n",
      "MAE train 1.5379524946162066 MAE test 2.365863544492306\n",
      "Epoch 8646 / 10000 loss: 12.2542142868042\n",
      "MSE train 5.019792818583814 MSE test 11.446690586787449\n",
      "MAE train 1.5379277927147592 MAE test 2.3658723907183683\n",
      "Epoch 8647 / 10000 loss: 12.253910064697266\n",
      "MSE train 5.019684560289764 MSE test 11.446489680110606\n",
      "MAE train 1.5379110877857856 MAE test 2.3658465218627858\n",
      "Epoch 8648 / 10000 loss: 12.253406047821045\n",
      "MSE train 5.019582480385548 MSE test 11.44644914811208\n",
      "MAE train 1.5378918099821237 MAE test 2.365846383171248\n",
      "Epoch 8649 / 10000 loss: 12.25303602218628\n",
      "MSE train 5.0194740926735975 MSE test 11.446209469005199\n",
      "MAE train 1.537875914975608 MAE test 2.365815384898464\n",
      "Epoch 8650 / 10000 loss: 12.25263786315918\n",
      "MSE train 5.019375545287614 MSE test 11.446217497325165\n",
      "MAE train 1.5378564753502386 MAE test 2.365821700258402\n",
      "Epoch 8651 / 10000 loss: 12.25229549407959\n",
      "MSE train 5.01926746994358 MSE test 11.4459332404955\n",
      "MAE train 1.537841487169852 MAE test 2.3657847909621768\n",
      "Epoch 8652 / 10000 loss: 12.2518789768219\n",
      "MSE train 5.019151295218263 MSE test 11.445959469141457\n",
      "MAE train 1.537817096445662 MAE test 2.3657935559643897\n",
      "Epoch 8653 / 10000 loss: 12.251573085784912\n",
      "MSE train 5.019042606425582 MSE test 11.445752560826024\n",
      "MAE train 1.5378003907069708 MAE test 2.3657669020260688\n",
      "Epoch 8654 / 10000 loss: 12.251073122024536\n",
      "MSE train 5.0189425682427595 MSE test 11.445720219723482\n",
      "MAE train 1.5377814622227202 MAE test 2.3657678401030853\n",
      "Epoch 8655 / 10000 loss: 12.25070571899414\n",
      "MSE train 5.018834488746941 MSE test 11.445466194521238\n",
      "MAE train 1.5377658923971005 MAE test 2.365734939996432\n",
      "Epoch 8656 / 10000 loss: 12.250309467315674\n",
      "MSE train 5.0187313362413235 MSE test 11.445482759013377\n",
      "MAE train 1.5377451058648235 MAE test 2.3657423995472056\n",
      "Epoch 8657 / 10000 loss: 12.24997878074646\n",
      "MSE train 5.018622600998863 MSE test 11.4452144776927\n",
      "MAE train 1.53772964231273 MAE test 2.3657075995164436\n",
      "Epoch 8658 / 10000 loss: 12.24953818321228\n",
      "MSE train 5.018514378084718 MSE test 11.445235407774781\n",
      "MAE train 1.53770745053658 MAE test 2.365715656761798\n",
      "Epoch 8659 / 10000 loss: 12.249216794967651\n",
      "MSE train 5.018404799261565 MSE test 11.44498952437841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5376913499796572 MAE test 2.36568382929609\n",
      "Epoch 8660 / 10000 loss: 12.24875259399414\n",
      "MSE train 5.018305991313364 MSE test 11.444997292021572\n",
      "MAE train 1.5376718135516818 MAE test 2.3656901021803862\n",
      "Epoch 8661 / 10000 loss: 12.248409748077393\n",
      "MSE train 5.018197485974241 MSE test 11.444715176150638\n",
      "MAE train 1.5376566648637184 MAE test 2.3656534938224723\n",
      "Epoch 8662 / 10000 loss: 12.247990608215332\n",
      "MSE train 5.0180830344492 MSE test 11.444739977331922\n",
      "MAE train 1.537632743305579 MAE test 2.3656620524566505\n",
      "Epoch 8663 / 10000 loss: 12.247680902481079\n",
      "MSE train 5.017973878124045 MSE test 11.44452501216953\n",
      "MAE train 1.5376160662481673 MAE test 2.365634340444124\n",
      "Epoch 8664 / 10000 loss: 12.247188568115234\n",
      "MSE train 5.017876041602729 MSE test 11.444502619905048\n",
      "MAE train 1.537597469436423 MAE test 2.3656366007378717\n",
      "Epoch 8665 / 10000 loss: 12.246825456619263\n",
      "MSE train 5.017768253662486 MSE test 11.444233295845727\n",
      "MAE train 1.5375822503641512 MAE test 2.365601680950771\n",
      "Epoch 8666 / 10000 loss: 12.246431112289429\n",
      "MSE train 5.017658645177211 MSE test 11.44425575380462\n",
      "MAE train 1.5375596679941208 MAE test 2.365609935111662\n",
      "Epoch 8667 / 10000 loss: 12.246113300323486\n",
      "MSE train 5.017549236211187 MSE test 11.444015684333094\n",
      "MAE train 1.537543467953772 MAE test 2.3655788848191883\n",
      "Epoch 8668 / 10000 loss: 12.24564242362976\n",
      "MSE train 5.017451815566328 MSE test 11.444019350908887\n",
      "MAE train 1.5375243759306607 MAE test 2.365584606759158\n",
      "Epoch 8669 / 10000 loss: 12.245296478271484\n",
      "MSE train 5.017343690929819 MSE test 11.443733655930656\n",
      "MAE train 1.5375093714744457 MAE test 2.365547526831715\n",
      "Epoch 8670 / 10000 loss: 12.244885921478271\n",
      "MSE train 5.017227473962361 MSE test 11.44375946105196\n",
      "MAE train 1.5374849449806383 MAE test 2.365556233911126\n",
      "Epoch 8671 / 10000 loss: 12.244580268859863\n",
      "MSE train 5.017119068278314 MSE test 11.443553889720846\n",
      "MAE train 1.5374682481977366 MAE test 2.365529750078635\n",
      "Epoch 8672 / 10000 loss: 12.244081020355225\n",
      "MSE train 5.0170187212738595 MSE test 11.443519036752264\n",
      "MAE train 1.5374492638479151 MAE test 2.365530358116496\n",
      "Epoch 8673 / 10000 loss: 12.243713140487671\n",
      "MSE train 5.016910703541285 MSE test 11.443268768593052\n",
      "MAE train 1.5374336225798455 MAE test 2.365497971634896\n",
      "Epoch 8674 / 10000 loss: 12.243317365646362\n",
      "MSE train 5.016809349281477 MSE test 11.443282948881205\n",
      "MAE train 1.5374133035788242 MAE test 2.365505110518222\n",
      "Epoch 8675 / 10000 loss: 12.2429838180542\n",
      "MSE train 5.016700998718301 MSE test 11.44300885987229\n",
      "MAE train 1.5373980244181586 MAE test 2.365469557735089\n",
      "Epoch 8676 / 10000 loss: 12.242551326751709\n",
      "MSE train 5.016590166606804 MSE test 11.443031683500228\n",
      "MAE train 1.5373750852198913 MAE test 2.3654778663119713\n",
      "Epoch 8677 / 10000 loss: 12.242235898971558\n",
      "MSE train 5.016480685414103 MSE test 11.442798622423732\n",
      "MAE train 1.5373586993320256 MAE test 2.365447760523027\n",
      "Epoch 8678 / 10000 loss: 12.241759061813354\n",
      "MSE train 5.016384404141097 MSE test 11.442795518724092\n",
      "MAE train 1.5373400459059448 MAE test 2.3654525844554617\n",
      "Epoch 8679 / 10000 loss: 12.241407871246338\n",
      "MSE train 5.016276574761263 MSE test 11.442508990793593\n",
      "MAE train 1.5373251055222341 MAE test 2.365415386611503\n",
      "Epoch 8680 / 10000 loss: 12.241005420684814\n",
      "MSE train 5.016159943420862 MSE test 11.442535009908491\n",
      "MAE train 1.5373005478092077 MAE test 2.3654241311434423\n",
      "Epoch 8681 / 10000 loss: 12.240701675415039\n",
      "MSE train 5.016051896694097 MSE test 11.442332255889836\n",
      "MAE train 1.5372838709281684 MAE test 2.3653980331123967\n",
      "Epoch 8682 / 10000 loss: 12.24020004272461\n",
      "MSE train 5.015950733346143 MSE test 11.442293413644165\n",
      "MAE train 1.5372647511546504 MAE test 2.365398113371634\n",
      "Epoch 8683 / 10000 loss: 12.239831686019897\n",
      "MSE train 5.015842715616761 MSE test 11.44204982528133\n",
      "MAE train 1.537248977157022 MAE test 2.36536660484561\n",
      "Epoch 8684 / 10000 loss: 12.239436626434326\n",
      "MSE train 5.015743519028436 MSE test 11.44205988656222\n",
      "MAE train 1.537229283134406 MAE test 2.3653731908442883\n",
      "Epoch 8685 / 10000 loss: 12.23909616470337\n",
      "MSE train 5.015635639251779 MSE test 11.44177845538034\n",
      "MAE train 1.5372142432669915 MAE test 2.3653366845061283\n",
      "Epoch 8686 / 10000 loss: 12.238676071166992\n",
      "MSE train 5.01552129215129 MSE test 11.441803381360229\n",
      "MAE train 1.5371903130880877 MAE test 2.3653452815482496\n",
      "Epoch 8687 / 10000 loss: 12.238368511199951\n",
      "MSE train 5.015412441390577 MSE test 11.441588409597559\n",
      "MAE train 1.5371736680820836 MAE test 2.365317565195065\n",
      "Epoch 8688 / 10000 loss: 12.237876176834106\n",
      "MSE train 5.015314819990029 MSE test 11.441565793625513\n",
      "MAE train 1.5371551062284476 MAE test 2.3653197922748377\n",
      "Epoch 8689 / 10000 loss: 12.237513780593872\n",
      "MSE train 5.015207198859569 MSE test 11.441296423488948\n",
      "MAE train 1.5371399032666104 MAE test 2.3652848694479385\n",
      "Epoch 8690 / 10000 loss: 12.237120151519775\n",
      "MSE train 5.015097910276534 MSE test 11.441318652800167\n",
      "MAE train 1.537117370235953 MAE test 2.3652930982760085\n",
      "Epoch 8691 / 10000 loss: 12.236802816390991\n",
      "MSE train 5.014988676617297 MSE test 11.441078398507468\n",
      "MAE train 1.5371011891567339 MAE test 2.3652620431327382\n",
      "Epoch 8692 / 10000 loss: 12.236332654953003\n",
      "MSE train 5.014891448221152 MSE test 11.441081874888729\n",
      "MAE train 1.5370821187288408 MAE test 2.3652677446683943\n",
      "Epoch 8693 / 10000 loss: 12.235987424850464\n",
      "MSE train 5.01478347841022 MSE test 11.440796303618534\n",
      "MAE train 1.5370671214974525 MAE test 2.3652306756407606\n",
      "Epoch 8694 / 10000 loss: 12.235577583312988\n",
      "MSE train 5.0146675690790445 MSE test 11.440821714443771\n",
      "MAE train 1.537042746727674 MAE test 2.3652393353911383\n",
      "Epoch 8695 / 10000 loss: 12.235271692276001\n",
      "MSE train 5.014559321836718 MSE test 11.44061567016648\n",
      "MAE train 1.5370260686701473 MAE test 2.3652128062404807\n",
      "Epoch 8696 / 10000 loss: 12.234773874282837\n",
      "MSE train 5.014459314241122 MSE test 11.440580930630452\n",
      "MAE train 1.5370071397266376 MAE test 2.365213420810939\n",
      "Epoch 8697 / 10000 loss: 12.234406471252441\n",
      "MSE train 5.01435153021659 MSE test 11.440330006920906\n",
      "MAE train 1.536991535913413 MAE test 2.3651809499395196\n",
      "Epoch 8698 / 10000 loss: 12.23401165008545\n",
      "MSE train 5.014250028255369 MSE test 11.44034427441656\n",
      "MAE train 1.536971155702745 MAE test 2.3651881083883315\n",
      "Epoch 8699 / 10000 loss: 12.233679056167603\n",
      "MSE train 5.014141885023076 MSE test 11.440071298233358\n",
      "MAE train 1.53695587020618 MAE test 2.365152712713305\n",
      "Epoch 8700 / 10000 loss: 12.233245849609375\n",
      "MSE train 5.014031817144534 MSE test 11.44009333803537\n",
      "MAE train 1.5369331192831082 MAE test 2.365160909183759\n",
      "Epoch 8701 / 10000 loss: 12.232929944992065\n",
      "MSE train 5.013922533822873 MSE test 11.439857671123075\n",
      "MAE train 1.5369168045071568 MAE test 2.365130472222166\n",
      "Epoch 8702 / 10000 loss: 12.23245644569397\n",
      "MSE train 5.013826186961255 MSE test 11.439856700345338\n",
      "MAE train 1.5368980592677939 MAE test 2.365135573885037\n",
      "Epoch 8703 / 10000 loss: 12.232107162475586\n",
      "MSE train 5.01371842579669 MSE test 11.43956993225084\n",
      "MAE train 1.5368831164059558 MAE test 2.3650983598062387\n",
      "Epoch 8704 / 10000 loss: 12.231703758239746\n",
      "MSE train 5.0136020374804415 MSE test 11.4395957241353\n",
      "MAE train 1.53685859963075 MAE test 2.3651070729344843\n",
      "Epoch 8705 / 10000 loss: 12.231399774551392\n",
      "MSE train 5.013494148757784 MSE test 11.43939291570264\n",
      "MAE train 1.5368419349958733 MAE test 2.3650809553705323\n",
      "Epoch 8706 / 10000 loss: 12.230899095535278\n",
      "MSE train 5.013393182861534 MSE test 11.439353806027247\n",
      "MAE train 1.536822843596517 MAE test 2.3650810163668883\n",
      "Epoch 8707 / 10000 loss: 12.230532169342041\n",
      "MSE train 5.013285305484908 MSE test 11.439110245643192\n",
      "MAE train 1.5368070721294078 MAE test 2.3650495288865883\n",
      "Epoch 8708 / 10000 loss: 12.230135679244995\n",
      "MSE train 5.01318639723249 MSE test 11.439119922606832\n",
      "MAE train 1.5367874298461774 MAE test 2.365056055192493\n",
      "Epoch 8709 / 10000 loss: 12.229796886444092\n",
      "MSE train 5.013078702187602 MSE test 11.438838373553642\n",
      "MAE train 1.5367724061058994 MAE test 2.3650195424737435\n",
      "Epoch 8710 / 10000 loss: 12.229377508163452\n",
      "MSE train 5.012964459272872 MSE test 11.438863108663432\n",
      "MAE train 1.5367484896430466 MAE test 2.365028111412455\n",
      "Epoch 8711 / 10000 loss: 12.229069232940674\n",
      "MSE train 5.012855815930767 MSE test 11.438648438401945\n",
      "MAE train 1.5367318607434086 MAE test 2.3650004411518366\n",
      "Epoch 8712 / 10000 loss: 12.228577613830566\n",
      "MSE train 5.012758290897038 MSE test 11.438625224090691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5367133152464179 MAE test 2.3650025937622594\n",
      "Epoch 8713 / 10000 loss: 12.228215456008911\n",
      "MSE train 5.012650849683483 MSE test 11.438356458058674\n",
      "MAE train 1.5366981124274905 MAE test 2.3649677736389467\n",
      "Epoch 8714 / 10000 loss: 12.227822542190552\n",
      "MSE train 5.012542006967317 MSE test 11.438378259582041\n",
      "MAE train 1.5366756796136518 MAE test 2.364975939271152\n",
      "Epoch 8715 / 10000 loss: 12.22750473022461\n",
      "MSE train 5.0124328971593215 MSE test 11.438136653718182\n",
      "MAE train 1.5366595423684872 MAE test 2.364944704338555\n",
      "Epoch 8716 / 10000 loss: 12.227035999298096\n",
      "MSE train 5.012335633352861 MSE test 11.438140851691836\n",
      "MAE train 1.5366404099882163 MAE test 2.364950496080917\n",
      "Epoch 8717 / 10000 loss: 12.226692914962769\n",
      "MSE train 5.0122277520722855 MSE test 11.437855953343943\n",
      "MAE train 1.5366254002921518 MAE test 2.3649135401655217\n",
      "Epoch 8718 / 10000 loss: 12.226281642913818\n",
      "MSE train 5.01211238609186 MSE test 11.437880951035913\n",
      "MAE train 1.536601152021546 MAE test 2.364922144553688\n",
      "Epoch 8719 / 10000 loss: 12.225975513458252\n",
      "MSE train 5.012004158090042 MSE test 11.437673153559127\n",
      "MAE train 1.5365844937968207 MAE test 2.3648953730430478\n",
      "Epoch 8720 / 10000 loss: 12.225479125976562\n",
      "MSE train 5.011904829645132 MSE test 11.4376407659832\n",
      "MAE train 1.5365656673772639 MAE test 2.3648963253096653\n",
      "Epoch 8721 / 10000 loss: 12.225114107131958\n",
      "MSE train 5.011797218742556 MSE test 11.437385763574653\n",
      "MAE train 1.536550159469261 MAE test 2.364863313476484\n",
      "Epoch 8722 / 10000 loss: 12.224720001220703\n",
      "MSE train 5.011694442837301 MSE test 11.43740174521641\n",
      "MAE train 1.5365293856692708 MAE test 2.364870693699602\n",
      "Epoch 8723 / 10000 loss: 12.224390983581543\n",
      "MSE train 5.011586150985691 MSE test 11.437134512568168\n",
      "MAE train 1.5365139366352947 MAE test 2.3648360778217343\n",
      "Epoch 8724 / 10000 loss: 12.2239511013031\n",
      "MSE train 5.011479162560429 MSE test 11.437154238785311\n",
      "MAE train 1.5364919913674975 MAE test 2.3648439616707204\n",
      "Epoch 8725 / 10000 loss: 12.223629236221313\n",
      "MSE train 5.011370065630945 MSE test 11.43690551581722\n",
      "MAE train 1.5364759996622765 MAE test 2.364811783774237\n",
      "Epoch 8726 / 10000 loss: 12.22316861152649\n",
      "MSE train 5.011271073487064 MSE test 11.436914339278246\n",
      "MAE train 1.5364563125946131 MAE test 2.364818217903739\n",
      "Epoch 8727 / 10000 loss: 12.222830295562744\n",
      "MSE train 5.0111629727982505 MSE test 11.436634822372888\n",
      "MAE train 1.5364411431476888 MAE test 2.3647819583372494\n",
      "Epoch 8728 / 10000 loss: 12.222409009933472\n",
      "MSE train 5.011050286550998 MSE test 11.436658178489612\n",
      "MAE train 1.5364176315966596 MAE test 2.364790349101279\n",
      "Epoch 8729 / 10000 loss: 12.222098588943481\n",
      "MSE train 5.010941326271416 MSE test 11.436436703555527\n",
      "MAE train 1.5364010687150367 MAE test 2.364761781747186\n",
      "Epoch 8730 / 10000 loss: 12.221612930297852\n",
      "MSE train 5.010845096422096 MSE test 11.436421000294468\n",
      "MAE train 1.5363826518872965 MAE test 2.3647649368940753\n",
      "Epoch 8731 / 10000 loss: 12.221254348754883\n",
      "MSE train 5.010737714521499 MSE test 11.436142679566982\n",
      "MAE train 1.536367636891877 MAE test 2.364728853543354\n",
      "Epoch 8732 / 10000 loss: 12.220860481262207\n",
      "MSE train 5.0106248350326785 MSE test 11.43616674102475\n",
      "MAE train 1.5363440652482447 MAE test 2.364737323978013\n",
      "Epoch 8733 / 10000 loss: 12.220551490783691\n",
      "MSE train 5.010516032816485 MSE test 11.435945645804706\n",
      "MAE train 1.5363275294667047 MAE test 2.364708809363658\n",
      "Epoch 8734 / 10000 loss: 12.22006630897522\n",
      "MSE train 5.010419803450981 MSE test 11.435930034932394\n",
      "MAE train 1.5363091098391737 MAE test 2.3647119804285928\n",
      "Epoch 8735 / 10000 loss: 12.219706773757935\n",
      "MSE train 5.010312517638754 MSE test 11.435651867214041\n",
      "MAE train 1.5362941127125804 MAE test 2.364675908730106\n",
      "Epoch 8736 / 10000 loss: 12.219314336776733\n",
      "MSE train 5.010199680337105 MSE test 11.435676087735386\n",
      "MAE train 1.536270542006132 MAE test 2.364684415451058\n",
      "Epoch 8737 / 10000 loss: 12.219004154205322\n",
      "MSE train 5.0100908497995045 MSE test 11.435454780132622\n",
      "MAE train 1.5362540060185574 MAE test 2.364655863794089\n",
      "Epoch 8738 / 10000 loss: 12.218517780303955\n",
      "MSE train 5.009994629830572 MSE test 11.435439278274028\n",
      "MAE train 1.536235583918714 MAE test 2.364659058518772\n",
      "Epoch 8739 / 10000 loss: 12.218160152435303\n",
      "MSE train 5.009887388810399 MSE test 11.435160994618743\n",
      "MAE train 1.5362205995536014 MAE test 2.3646229686033045\n",
      "Epoch 8740 / 10000 loss: 12.217766761779785\n",
      "MSE train 5.009774446324404 MSE test 11.435185216447707\n",
      "MAE train 1.536197004029563 MAE test 2.364631474300618\n",
      "Epoch 8741 / 10000 loss: 12.217458009719849\n",
      "MSE train 5.0096656687101895 MSE test 11.434964422518732\n",
      "MAE train 1.536180464472743 MAE test 2.36460299100001\n",
      "Epoch 8742 / 10000 loss: 12.216971635818481\n",
      "MSE train 5.009569419958349 MSE test 11.434948341914478\n",
      "MAE train 1.5361620470281556 MAE test 2.364606109084709\n",
      "Epoch 8743 / 10000 loss: 12.216612815856934\n",
      "MSE train 5.0094622009528464 MSE test 11.434670585938834\n",
      "MAE train 1.5361470486869335 MAE test 2.364570102905021\n",
      "Epoch 8744 / 10000 loss: 12.216219425201416\n",
      "MSE train 5.009349546681744 MSE test 11.43469460061089\n",
      "MAE train 1.5361235299852722 MAE test 2.3645785717723435\n",
      "Epoch 8745 / 10000 loss: 12.215909719467163\n",
      "MSE train 5.009240764281874 MSE test 11.434472567585724\n",
      "MAE train 1.5361070132959433 MAE test 2.364549951388774\n",
      "Epoch 8746 / 10000 loss: 12.215424060821533\n",
      "MSE train 5.009144688885871 MSE test 11.434457964613435\n",
      "MAE train 1.536088602705469 MAE test 2.3645532550541977\n",
      "Epoch 8747 / 10000 loss: 12.21506667137146\n",
      "MSE train 5.009037446151058 MSE test 11.434178631314365\n",
      "MAE train 1.5360736270436404 MAE test 2.3645170405375397\n",
      "Epoch 8748 / 10000 loss: 12.214674234390259\n",
      "MSE train 5.008924165871922 MSE test 11.434203005488865\n",
      "MAE train 1.5360499308358566 MAE test 2.3645255638967924\n",
      "Epoch 8749 / 10000 loss: 12.214364767074585\n",
      "MSE train 5.008815514956416 MSE test 11.4339843935517\n",
      "MAE train 1.536033366300159 MAE test 2.3644973715033095\n",
      "Epoch 8750 / 10000 loss: 12.21387791633606\n",
      "MSE train 5.008719010011089 MSE test 11.43396576321094\n",
      "MAE train 1.5360149304999413 MAE test 2.364500149175045\n",
      "Epoch 8751 / 10000 loss: 12.213517427444458\n",
      "MSE train 5.00861178865143 MSE test 11.433690976718694\n",
      "MAE train 1.5359998712492986 MAE test 2.3644645329339085\n",
      "Epoch 8752 / 10000 loss: 12.213124752044678\n",
      "MSE train 5.0085004481148765 MSE test 11.433714070924637\n",
      "MAE train 1.5359767138783653 MAE test 2.36447288577447\n",
      "Epoch 8753 / 10000 loss: 12.212812900543213\n",
      "MSE train 5.008391558999097 MSE test 11.433485640324077\n",
      "MAE train 1.535960303828958 MAE test 2.364443403041686\n",
      "Epoch 8754 / 10000 loss: 12.212333917617798\n",
      "MSE train 5.008295913462091 MSE test 11.433477819743281\n",
      "MAE train 1.5359418397201732 MAE test 2.3644476175697022\n",
      "Epoch 8755 / 10000 loss: 12.21198034286499\n",
      "MSE train 5.008188604404896 MSE test 11.433193253498025\n",
      "MAE train 1.5359269381100908 MAE test 2.3644107111310007\n",
      "Epoch 8756 / 10000 loss: 12.211583852767944\n",
      "MSE train 5.008073204190684 MSE test 11.433218400216546\n",
      "MAE train 1.5359026326664806 MAE test 2.3644193450078124\n",
      "Epoch 8757 / 10000 loss: 12.21127963066101\n",
      "MSE train 5.007965279246722 MSE test 11.433011678346391\n",
      "MAE train 1.5358859985361222 MAE test 2.364392720567965\n",
      "Epoch 8758 / 10000 loss: 12.210782527923584\n",
      "MSE train 5.007865805372109 MSE test 11.432977686002214\n",
      "MAE train 1.5358671463779137 MAE test 2.364393481024884\n",
      "Epoch 8759 / 10000 loss: 12.210417032241821\n",
      "MSE train 5.0077583609782925 MSE test 11.4327251136791\n",
      "MAE train 1.5358516036836471 MAE test 2.3643608034231276\n",
      "Epoch 8760 / 10000 loss: 12.210023880004883\n",
      "MSE train 5.007656663990386 MSE test 11.432739707597399\n",
      "MAE train 1.535831105359322 MAE test 2.3643680125962314\n",
      "Epoch 8761 / 10000 loss: 12.209693193435669\n",
      "MSE train 5.007548662552286 MSE test 11.432468966303764\n",
      "MAE train 1.5358157655180271 MAE test 2.3643329377134013\n",
      "Epoch 8762 / 10000 loss: 12.209258079528809\n",
      "MSE train 5.007440200866835 MSE test 11.432489782859113\n",
      "MAE train 1.5357933887133748 MAE test 2.3643409841671787\n",
      "Epoch 8763 / 10000 loss: 12.208940267562866\n",
      "MSE train 5.0073311880933 MSE test 11.43224867635548\n",
      "MAE train 1.5357772189668204 MAE test 2.3643098200324464\n",
      "Epoch 8764 / 10000 loss: 12.208473205566406\n",
      "MSE train 5.0072343807801465 MSE test 11.432251595789877\n",
      "MAE train 1.535758194221217 MAE test 2.3643154706626315\n",
      "Epoch 8765 / 10000 loss: 12.208128452301025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.007126730331322 MSE test 11.431966313822125\n",
      "MAE train 1.5357432037024297 MAE test 2.3642784586153045\n",
      "Epoch 8766 / 10000 loss: 12.207719564437866\n",
      "MSE train 5.007011524338837 MSE test 11.431991172994021\n",
      "MAE train 1.5357189568798708 MAE test 2.3642870729714893\n",
      "Epoch 8767 / 10000 loss: 12.207415103912354\n",
      "MSE train 5.006903556665135 MSE test 11.431783694542691\n",
      "MAE train 1.5357023095377174 MAE test 2.3642603449793085\n",
      "Epoch 8768 / 10000 loss: 12.206918478012085\n",
      "MSE train 5.006804349155732 MSE test 11.431750252015119\n",
      "MAE train 1.535683496183402 MAE test 2.3642611755210363\n",
      "Epoch 8769 / 10000 loss: 12.206552743911743\n",
      "MSE train 5.006696922245463 MSE test 11.431496588996078\n",
      "MAE train 1.5356679734320007 MAE test 2.364228361178396\n",
      "Epoch 8770 / 10000 loss: 12.206159591674805\n",
      "MSE train 5.006594885490904 MSE test 11.431511587971823\n",
      "MAE train 1.5356473649564413 MAE test 2.3642356320916553\n",
      "Epoch 8771 / 10000 loss: 12.205830335617065\n",
      "MSE train 5.006486838169437 MSE test 11.431242416458948\n",
      "MAE train 1.5356319855820033 MAE test 2.364200771351929\n",
      "Epoch 8772 / 10000 loss: 12.205393075942993\n",
      "MSE train 5.006379160540762 MSE test 11.431262349176334\n",
      "MAE train 1.5356098137301175 MAE test 2.364208699571452\n",
      "Epoch 8773 / 10000 loss: 12.205073833465576\n",
      "MSE train 5.006270211155838 MSE test 11.43101774804268\n",
      "MAE train 1.53559373359184 MAE test 2.3641770735949685\n",
      "Epoch 8774 / 10000 loss: 12.204609870910645\n",
      "MSE train 5.006172623512794 MSE test 11.43102337262778\n",
      "MAE train 1.5355744323975142 MAE test 2.3641831071001524\n",
      "Epoch 8775 / 10000 loss: 12.204268217086792\n",
      "MSE train 5.006064849256198 MSE test 11.430740114743095\n",
      "MAE train 1.5355593812026336 MAE test 2.364146361895772\n",
      "Epoch 8776 / 10000 loss: 12.203854084014893\n",
      "MSE train 5.005950732275109 MSE test 11.43076420763403\n",
      "MAE train 1.5355354217067416 MAE test 2.364154870213137\n",
      "Epoch 8777 / 10000 loss: 12.203547477722168\n",
      "MSE train 5.005842389624904 MSE test 11.430551273537953\n",
      "MAE train 1.5355187858242845 MAE test 2.364127429851731\n",
      "Epoch 8778 / 10000 loss: 12.20305585861206\n",
      "MSE train 5.005744659419097 MSE test 11.43052484024784\n",
      "MAE train 1.5355002030135918 MAE test 2.364129194333119\n",
      "Epoch 8779 / 10000 loss: 12.202692985534668\n",
      "MSE train 5.005637449412998 MSE test 11.430260098056149\n",
      "MAE train 1.5354849329519753 MAE test 2.364094916452302\n",
      "Epoch 8780 / 10000 loss: 12.202300071716309\n",
      "MSE train 5.005530869657269 MSE test 11.430279847505288\n",
      "MAE train 1.5354630513244227 MAE test 2.3641028222422866\n",
      "Epoch 8781 / 10000 loss: 12.201980113983154\n",
      "MSE train 5.005422200948798 MSE test 11.430029770851991\n",
      "MAE train 1.5354471496083488 MAE test 2.364070487941577\n",
      "Epoch 8782 / 10000 loss: 12.201521873474121\n",
      "MSE train 5.005322804351634 MSE test 11.430039584296457\n",
      "MAE train 1.535427297382055 MAE test 2.3640770807027294\n",
      "Epoch 8783 / 10000 loss: 12.201184749603271\n",
      "MSE train 5.0052148631356514 MSE test 11.429761905014217\n",
      "MAE train 1.5354120848869615 MAE test 2.364041077673414\n",
      "Epoch 8784 / 10000 loss: 12.20076036453247\n",
      "MSE train 5.005103438259475 MSE test 11.429784220876186\n",
      "MAE train 1.5353888772638853 MAE test 2.364049352319175\n",
      "Epoch 8785 / 10000 loss: 12.200447797775269\n",
      "MSE train 5.004994526349318 MSE test 11.429557578823315\n",
      "MAE train 1.5353724011434582 MAE test 2.3640201023401053\n",
      "Epoch 8786 / 10000 loss: 12.199968576431274\n",
      "MSE train 5.004898952676148 MSE test 11.429546913979355\n",
      "MAE train 1.5353539930246065 MAE test 2.3640239543140895\n",
      "Epoch 8787 / 10000 loss: 12.199613332748413\n",
      "MSE train 5.004791751564308 MSE test 11.429264007753984\n",
      "MAE train 1.5353390613410682 MAE test 2.3639872806248334\n",
      "Epoch 8788 / 10000 loss: 12.199218273162842\n",
      "MSE train 5.004677179909475 MSE test 11.429288474023291\n",
      "MAE train 1.5353149693566277 MAE test 2.363995838795824\n",
      "Epoch 8789 / 10000 loss: 12.198912858963013\n",
      "MSE train 5.004569009741903 MSE test 11.429077655335337\n",
      "MAE train 1.535298334669294 MAE test 2.3639686718257438\n",
      "Epoch 8790 / 10000 loss: 12.198419332504272\n",
      "MSE train 5.004470867545886 MSE test 11.429048724641167\n",
      "MAE train 1.5352796852206005 MAE test 2.363970128498668\n",
      "Epoch 8791 / 10000 loss: 12.198055505752563\n",
      "MSE train 5.004363564521608 MSE test 11.428787561863928\n",
      "MAE train 1.5352643210829193 MAE test 2.363936336381553\n",
      "Epoch 8792 / 10000 loss: 12.19766354560852\n",
      "MSE train 5.004258587197255 MSE test 11.42880570884502\n",
      "MAE train 1.53524288595687 MAE test 2.363944030065813\n",
      "Epoch 8793 / 10000 loss: 12.197339296340942\n",
      "MSE train 5.004150164676954 MSE test 11.428548883032521\n",
      "MAE train 1.535227150245502 MAE test 2.363910797858348\n",
      "Epoch 8794 / 10000 loss: 12.196888446807861\n",
      "MSE train 5.004048225034608 MSE test 11.428562626012209\n",
      "MAE train 1.5352065654027651 MAE test 2.363917915939307\n",
      "Epoch 8795 / 10000 loss: 12.196557521820068\n",
      "MSE train 5.003939949170217 MSE test 11.428294287289663\n",
      "MAE train 1.5351910818729144 MAE test 2.3638831595997405\n",
      "Epoch 8796 / 10000 loss: 12.196119785308838\n",
      "MSE train 5.003833188029589 MSE test 11.428313045593727\n",
      "MAE train 1.535169144914795 MAE test 2.363890959073942\n",
      "Epoch 8797 / 10000 loss: 12.195799350738525\n",
      "MSE train 5.003724257040018 MSE test 11.42806506347135\n",
      "MAE train 1.5351531202656885 MAE test 2.363858891043944\n",
      "Epoch 8798 / 10000 loss: 12.19533896446228\n",
      "MSE train 5.003625786789891 MSE test 11.42807249643135\n",
      "MAE train 1.5351335484713593 MAE test 2.363865164863859\n",
      "Epoch 8799 / 10000 loss: 12.194999694824219\n",
      "MSE train 5.003517905966924 MSE test 11.427792077896367\n",
      "MAE train 1.5351183904033794 MAE test 2.3638288114900416\n",
      "Epoch 8800 / 10000 loss: 12.194581031799316\n",
      "MSE train 5.003405245343155 MSE test 11.427814945250915\n",
      "MAE train 1.5350948301509535 MAE test 2.3638371752580056\n",
      "Epoch 8801 / 10000 loss: 12.194271326065063\n",
      "MSE train 5.003296590430895 MSE test 11.427594819578704\n",
      "MAE train 1.5350782560844944 MAE test 2.3638087914671817\n",
      "Epoch 8802 / 10000 loss: 12.193785429000854\n",
      "MSE train 5.003200361094285 MSE test 11.427576454377624\n",
      "MAE train 1.5350598407027982 MAE test 2.3638116281535537\n",
      "Epoch 8803 / 10000 loss: 12.19342565536499\n",
      "MSE train 5.003093153069895 MSE test 11.427300558777794\n",
      "MAE train 1.5350447808197354 MAE test 2.3637758825283623\n",
      "Epoch 8804 / 10000 loss: 12.193033695220947\n",
      "MSE train 5.002981601522232 MSE test 11.42732336838907\n",
      "MAE train 1.5350215251767347 MAE test 2.3637842244717757\n",
      "Epoch 8805 / 10000 loss: 12.19272255897522\n",
      "MSE train 5.002872849827511 MSE test 11.427096792512069\n",
      "MAE train 1.535005068438609 MAE test 2.363755005609467\n",
      "Epoch 8806 / 10000 loss: 12.192241430282593\n",
      "MSE train 5.002777272249979 MSE test 11.427086117256042\n",
      "MAE train 1.534986650595816 MAE test 2.36375887645648\n",
      "Epoch 8807 / 10000 loss: 12.19188642501831\n",
      "MSE train 5.002670097103024 MSE test 11.426802820252087\n",
      "MAE train 1.534971716953008 MAE test 2.363722139360374\n",
      "Epoch 8808 / 10000 loss: 12.191491842269897\n",
      "MSE train 5.002555446075658 MSE test 11.426827055370717\n",
      "MAE train 1.5349475968215454 MAE test 2.363730688391069\n",
      "Epoch 8809 / 10000 loss: 12.191185235977173\n",
      "MSE train 5.002447333648999 MSE test 11.426616669380987\n",
      "MAE train 1.5349309490633116 MAE test 2.363703597891724\n",
      "Epoch 8810 / 10000 loss: 12.190691709518433\n",
      "MSE train 5.002349031048873 MSE test 11.426586737241548\n",
      "MAE train 1.5349122693043196 MAE test 2.363704917548568\n",
      "Epoch 8811 / 10000 loss: 12.190327167510986\n",
      "MSE train 5.002241735373411 MSE test 11.4263264322796\n",
      "MAE train 1.5348968745749567 MAE test 2.36367123673735\n",
      "Epoch 8812 / 10000 loss: 12.189934492111206\n",
      "MSE train 5.002137190176429 MSE test 11.42634384630114\n",
      "MAE train 1.5348755538802001 MAE test 2.363678861994372\n",
      "Epoch 8813 / 10000 loss: 12.189610242843628\n",
      "MSE train 5.002028813311834 MSE test 11.426085150218515\n",
      "MAE train 1.534859842752326 MAE test 2.3636453830037008\n",
      "Epoch 8814 / 10000 loss: 12.189160346984863\n",
      "MSE train 5.001926107646626 MSE test 11.42609949394904\n",
      "MAE train 1.534839046642106 MAE test 2.3636526017896404\n",
      "Epoch 8815 / 10000 loss: 12.188830852508545\n",
      "MSE train 5.0018177401464365 MSE test 11.425833918441265\n",
      "MAE train 1.534823463660225 MAE test 2.363618213604557\n",
      "Epoch 8816 / 10000 loss: 12.188390731811523\n",
      "MSE train 5.001712250211118 MSE test 11.425851090556014\n",
      "MAE train 1.5348018938408252 MAE test 2.3636258152752414\n",
      "Epoch 8817 / 10000 loss: 12.188066482543945\n",
      "MSE train 5.0016034478466755 MSE test 11.425597107062378\n",
      "MAE train 1.5347859885169433 MAE test 2.3635929651126832\n",
      "Epoch 8818 / 10000 loss: 12.187612771987915\n",
      "MSE train 5.001503001030059 MSE test 11.42560800289203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5347658256411492 MAE test 2.363599723616521\n",
      "Epoch 8819 / 10000 loss: 12.187277793884277\n",
      "MSE train 5.001394804163411 MSE test 11.425334164825172\n",
      "MAE train 1.5347504553374909 MAE test 2.363564252492822\n",
      "Epoch 8820 / 10000 loss: 12.186847925186157\n",
      "MSE train 5.00128546548265 MSE test 11.4253544346752\n",
      "MAE train 1.5347278089906873 MAE test 2.363572269042893\n",
      "Epoch 8821 / 10000 loss: 12.186530113220215\n",
      "MSE train 5.001176366526981 MSE test 11.425117822828817\n",
      "MAE train 1.534711474029194 MAE test 2.3635417124422915\n",
      "Epoch 8822 / 10000 loss: 12.18605899810791\n",
      "MSE train 5.001080399496654 MSE test 11.425115570200493\n",
      "MAE train 1.534692748408808 MAE test 2.363546715929817\n",
      "Epoch 8823 / 10000 loss: 12.185710668563843\n",
      "MSE train 5.000972846880646 MSE test 11.424829108540349\n",
      "MAE train 1.5346777720266973 MAE test 2.363509580164852\n",
      "Epoch 8824 / 10000 loss: 12.185307025909424\n",
      "MSE train 5.000857151733367 MSE test 11.424853244539396\n",
      "MAE train 1.5346533540971719 MAE test 2.36351813734448\n",
      "Epoch 8825 / 10000 loss: 12.185002088546753\n",
      "MSE train 5.000749419605695 MSE test 11.424648335801036\n",
      "MAE train 1.5346366812056524 MAE test 2.363491775635105\n",
      "Epoch 8826 / 10000 loss: 12.184503316879272\n",
      "MSE train 5.000649263395315 MSE test 11.424609999217868\n",
      "MAE train 1.5346176883734197 MAE test 2.363492000602118\n",
      "Epoch 8827 / 10000 loss: 12.184137105941772\n",
      "MSE train 5.000541672814708 MSE test 11.424362784830597\n",
      "MAE train 1.534601977595685 MAE test 2.3634600515257373\n",
      "Epoch 8828 / 10000 loss: 12.183742046356201\n",
      "MSE train 5.000442056223847 MSE test 11.424372937580065\n",
      "MAE train 1.5345820577257443 MAE test 2.3634667161514535\n",
      "Epoch 8829 / 10000 loss: 12.18340539932251\n",
      "MSE train 5.000334369578669 MSE test 11.424094686523256\n",
      "MAE train 1.5345668980284728 MAE test 2.363430665576103\n",
      "Epoch 8830 / 10000 loss: 12.182981491088867\n",
      "MSE train 5.00022227056198 MSE test 11.424116757048601\n",
      "MAE train 1.5345434949749168 MAE test 2.363438961200302\n",
      "Epoch 8831 / 10000 loss: 12.182669162750244\n",
      "MSE train 5.000113360915446 MSE test 11.423892386368234\n",
      "MAE train 1.5345269329701057 MAE test 2.3634100272829848\n",
      "Epoch 8832 / 10000 loss: 12.182185888290405\n",
      "MSE train 5.000017508843712 MSE test 11.423878215600467\n",
      "MAE train 1.5345085099714788 MAE test 2.3634134547981147\n",
      "Epoch 8833 / 10000 loss: 12.181827306747437\n",
      "MSE train 4.999910197181026 MSE test 11.423597107051819\n",
      "MAE train 1.5344934936426835 MAE test 2.3633770298613914\n",
      "Epoch 8834 / 10000 loss: 12.181433916091919\n",
      "MSE train 4.999796515933481 MSE test 11.423620440228179\n",
      "MAE train 1.534469646609406 MAE test 2.3633854991362657\n",
      "Epoch 8835 / 10000 loss: 12.18112564086914\n",
      "MSE train 4.999687876235614 MSE test 11.423403579333188\n",
      "MAE train 1.5344529942161067 MAE test 2.3633575692069946\n",
      "Epoch 8836 / 10000 loss: 12.180634260177612\n",
      "MSE train 4.999590889427739 MSE test 11.423380794664858\n",
      "MAE train 1.5344344804474477 MAE test 2.363359858148672\n",
      "Epoch 8837 / 10000 loss: 12.180271863937378\n",
      "MSE train 4.999483534675116 MSE test 11.423109256875367\n",
      "MAE train 1.5344192732202626 MAE test 2.363324703044794\n",
      "Epoch 8838 / 10000 loss: 12.179879426956177\n",
      "MSE train 4.999374026083599 MSE test 11.423130078808391\n",
      "MAE train 1.5343965906012442 MAE test 2.3633328276823327\n",
      "Epoch 8839 / 10000 loss: 12.179562330245972\n",
      "MSE train 4.999264938392325 MSE test 11.422892048918536\n",
      "MAE train 1.5343802871317778 MAE test 2.3633021041661206\n",
      "Epoch 8840 / 10000 loss: 12.17909026145935\n",
      "MSE train 4.999168563732791 MSE test 11.422890990532666\n",
      "MAE train 1.5343614338442786 MAE test 2.3633072887823774\n",
      "Epoch 8841 / 10000 loss: 12.178741455078125\n",
      "MSE train 4.999060866102954 MSE test 11.42260437462788\n",
      "MAE train 1.534346418686187 MAE test 2.363270149095614\n",
      "Epoch 8842 / 10000 loss: 12.178335189819336\n",
      "MSE train 4.998945002369439 MSE test 11.422628059891641\n",
      "MAE train 1.5343219695212893 MAE test 2.3632786781462602\n",
      "Epoch 8843 / 10000 loss: 12.178030729293823\n",
      "MSE train 4.998836985275016 MSE test 11.422422491880646\n",
      "MAE train 1.5343052439747762 MAE test 2.3632522414636807\n",
      "Epoch 8844 / 10000 loss: 12.177530527114868\n",
      "MSE train 4.9987366403074445 MSE test 11.422383844271254\n",
      "MAE train 1.5342862142962164 MAE test 2.3632524661038365\n",
      "Epoch 8845 / 10000 loss: 12.177161931991577\n",
      "MSE train 4.998628806207187 MSE test 11.422136033133333\n",
      "MAE train 1.534270451200658 MAE test 2.3632204556226077\n",
      "Epoch 8846 / 10000 loss: 12.17676568031311\n",
      "MSE train 4.998528857024258 MSE test 11.422145943963653\n",
      "MAE train 1.5342504604884728 MAE test 2.3632271195578505\n",
      "Epoch 8847 / 10000 loss: 12.17642855644226\n",
      "MSE train 4.998420860130156 MSE test 11.421867484372234\n",
      "MAE train 1.5342352281886733 MAE test 2.3631910585255844\n",
      "Epoch 8848 / 10000 loss: 12.17600131034851\n",
      "MSE train 4.998308610231573 MSE test 11.421888920311618\n",
      "MAE train 1.534211810708948 MAE test 2.363199293091847\n",
      "Epoch 8849 / 10000 loss: 12.175688028335571\n",
      "MSE train 4.99819937213697 MSE test 11.421663372643925\n",
      "MAE train 1.534195205341935 MAE test 2.3631702332632507\n",
      "Epoch 8850 / 10000 loss: 12.175203561782837\n",
      "MSE train 4.998103302929112 MSE test 11.421649371497448\n",
      "MAE train 1.5341767265600945 MAE test 2.363173708622289\n",
      "Epoch 8851 / 10000 loss: 12.174844980239868\n",
      "MSE train 4.997995582412661 MSE test 11.421367240852133\n",
      "MAE train 1.5341616429508436 MAE test 2.3631371757887805\n",
      "Epoch 8852 / 10000 loss: 12.174447774887085\n",
      "MSE train 4.997881279515078 MSE test 11.421390055697211\n",
      "MAE train 1.5341376538807356 MAE test 2.363145603576151\n",
      "Epoch 8853 / 10000 loss: 12.174137353897095\n",
      "MSE train 4.997772313458168 MSE test 11.421174355586455\n",
      "MAE train 1.5341209024795306 MAE test 2.363117847789486\n",
      "Epoch 8854 / 10000 loss: 12.173644781112671\n",
      "MSE train 4.997674575805707 MSE test 11.421148712681909\n",
      "MAE train 1.5341022766092038 MAE test 2.3631198000421563\n",
      "Epoch 8855 / 10000 loss: 12.173279285430908\n",
      "MSE train 4.997566692570184 MSE test 11.420879747079727\n",
      "MAE train 1.5340869271036275 MAE test 2.363085012589691\n",
      "Epoch 8856 / 10000 loss: 12.172883749008179\n",
      "MSE train 4.997458000602877 MSE test 11.420898757723293\n",
      "MAE train 1.5340645025172022 MAE test 2.363092918778172\n",
      "Epoch 8857 / 10000 loss: 12.17256212234497\n",
      "MSE train 4.99734853206196 MSE test 11.420654586038781\n",
      "MAE train 1.5340482558578485 MAE test 2.3630614143082047\n",
      "Epoch 8858 / 10000 loss: 12.172093152999878\n",
      "MSE train 4.997250478014101 MSE test 11.420657447098888\n",
      "MAE train 1.5340289028433753 MAE test 2.363067155160351\n",
      "Epoch 8859 / 10000 loss: 12.171746253967285\n",
      "MSE train 4.997141972936797 MSE test 11.420372611663215\n",
      "MAE train 1.5340136821595 MAE test 2.363030267469865\n",
      "Epoch 8860 / 10000 loss: 12.171329975128174\n",
      "MSE train 4.997026804483044 MSE test 11.420394836838376\n",
      "MAE train 1.5339894867137833 MAE test 2.3630386356086923\n",
      "Epoch 8861 / 10000 loss: 12.171019077301025\n",
      "MSE train 4.996917688059106 MSE test 11.42018214247146\n",
      "MAE train 1.5339726484682934 MAE test 2.3630112978290394\n",
      "Epoch 8862 / 10000 loss: 12.17052149772644\n",
      "MSE train 4.996818731226889 MSE test 11.420151642912574\n",
      "MAE train 1.533953842711665 MAE test 2.3630126165296437\n",
      "Epoch 8863 / 10000 loss: 12.17015290260315\n",
      "MSE train 4.9967103808318285 MSE test 11.419888659411747\n",
      "MAE train 1.533938262224225 MAE test 2.362978621364133\n",
      "Epoch 8864 / 10000 loss: 12.169755697250366\n",
      "MSE train 4.996604184970423 MSE test 11.419904895499437\n",
      "MAE train 1.5339165833347845 MAE test 2.3629861821980014\n",
      "Epoch 8865 / 10000 loss: 12.169426918029785\n",
      "MSE train 4.996494580928296 MSE test 11.41964748415228\n",
      "MAE train 1.5339005853113301 MAE test 2.3629529389677675\n",
      "Epoch 8866 / 10000 loss: 12.168968915939331\n",
      "MSE train 4.996391896451777 MSE test 11.419658655212592\n",
      "MAE train 1.5338798923412151 MAE test 2.3629598154651026\n",
      "Epoch 8867 / 10000 loss: 12.168630599975586\n",
      "MSE train 4.996282307803079 MSE test 11.419387582274911\n",
      "MAE train 1.5338641720563704 MAE test 2.3629247610415036\n",
      "Epoch 8868 / 10000 loss: 12.16818881034851\n",
      "MSE train 4.996173662692978 MSE test 11.419404706530537\n",
      "MAE train 1.5338418379343168 MAE test 2.3629324496463697\n",
      "Epoch 8869 / 10000 loss: 12.167862892150879\n",
      "MSE train 4.996063293513607 MSE test 11.419157711195076\n",
      "MAE train 1.5338254660703963 MAE test 2.3629005977663122\n",
      "Epoch 8870 / 10000 loss: 12.16739296913147\n",
      "MSE train 4.995964159323842 MSE test 11.419160979323536\n",
      "MAE train 1.533805869695619 MAE test 2.3629064183020705\n",
      "Epoch 8871 / 10000 loss: 12.167043924331665\n",
      "MSE train 4.995854738724416 MSE test 11.41887674951869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5337904576816863 MAE test 2.362869627014007\n",
      "Epoch 8872 / 10000 loss: 12.16662049293518\n",
      "MSE train 4.995739545601816 MSE test 11.41889792851983\n",
      "MAE train 1.5337663283488376 MAE test 2.362877882365769\n",
      "Epoch 8873 / 10000 loss: 12.16630506515503\n",
      "MSE train 4.995629412829245 MSE test 11.418681030636376\n",
      "MAE train 1.5337493662645798 MAE test 2.3628500161439434\n",
      "Epoch 8874 / 10000 loss: 12.165806531906128\n",
      "MSE train 4.995530405777008 MSE test 11.418654245889753\n",
      "MAE train 1.5337305258207623 MAE test 2.362851856156975\n",
      "Epoch 8875 / 10000 loss: 12.165434837341309\n",
      "MSE train 4.995421264049744 MSE test 11.41838427566002\n",
      "MAE train 1.5337149443519027 MAE test 2.3628169756152344\n",
      "Epoch 8876 / 10000 loss: 12.16503381729126\n",
      "MSE train 4.995311314459355 MSE test 11.41840218462563\n",
      "MAE train 1.533692312666713 MAE test 2.362824778776118\n",
      "Epoch 8877 / 10000 loss: 12.164705514907837\n",
      "MSE train 4.995200408173709 MSE test 11.418156503192398\n",
      "MAE train 1.5336758285339995 MAE test 2.3627931236023225\n",
      "Epoch 8878 / 10000 loss: 12.164230585098267\n",
      "MSE train 4.99510086331873 MSE test 11.418158514983695\n",
      "MAE train 1.5336562021707538 MAE test 2.3627988106594056\n",
      "Epoch 8879 / 10000 loss: 12.163877248764038\n",
      "MSE train 4.994990884751278 MSE test 11.417872841518633\n",
      "MAE train 1.5336407243401835 MAE test 2.3627618411263556\n",
      "Epoch 8880 / 10000 loss: 12.163452386856079\n",
      "MSE train 4.994874390470157 MSE test 11.417893739875467\n",
      "MAE train 1.5336163194281756 MAE test 2.3627701042646336\n",
      "Epoch 8881 / 10000 loss: 12.163134336471558\n",
      "MSE train 4.9947636031625695 MSE test 11.417679254766146\n",
      "MAE train 1.5335992120087012 MAE test 2.362742559660963\n",
      "Epoch 8882 / 10000 loss: 12.1626296043396\n",
      "MSE train 4.994663153713632 MSE test 11.417648541222364\n",
      "MAE train 1.5335801614665079 MAE test 2.3627438945065067\n",
      "Epoch 8883 / 10000 loss: 12.162253141403198\n",
      "MSE train 4.994553236198136 MSE test 11.417383041705827\n",
      "MAE train 1.5335643504431367 MAE test 2.362709619785299\n",
      "Epoch 8884 / 10000 loss: 12.161847114562988\n",
      "MSE train 4.994444762962765 MSE test 11.417398646373849\n",
      "MAE train 1.5335422221116037 MAE test 2.362717148187739\n",
      "Epoch 8885 / 10000 loss: 12.16151213645935\n",
      "MSE train 4.994333312712574 MSE test 11.417142662093937\n",
      "MAE train 1.5335258602551218 MAE test 2.3626841313099467\n",
      "Epoch 8886 / 10000 loss: 12.161043167114258\n",
      "MSE train 4.994229956258789 MSE test 11.41715087045868\n",
      "MAE train 1.5335051814731495 MAE test 2.3626906650682047\n",
      "Epoch 8887 / 10000 loss: 12.160694599151611\n",
      "MSE train 4.9941187482263745 MSE test 11.416875035889147\n",
      "MAE train 1.5334892752067946 MAE test 2.3626550155506596\n",
      "Epoch 8888 / 10000 loss: 12.16024923324585\n",
      "MSE train 4.9940065437695935 MSE test 11.416892221068336\n",
      "MAE train 1.533466135767123 MAE test 2.3626627646935274\n",
      "Epoch 8889 / 10000 loss: 12.159917116165161\n",
      "MSE train 4.993894357530147 MSE test 11.416652785769278\n",
      "MAE train 1.5334492466268912 MAE test 2.3626319482506815\n",
      "Epoch 8890 / 10000 loss: 12.159430742263794\n",
      "MSE train 4.993795247046803 MSE test 11.41664789352905\n",
      "MAE train 1.5334299528711102 MAE test 2.3626367168824767\n",
      "Epoch 8891 / 10000 loss: 12.159066200256348\n",
      "MSE train 4.993684553845914 MSE test 11.416359096714487\n",
      "MAE train 1.5334144091095259 MAE test 2.3625993671926\n",
      "Epoch 8892 / 10000 loss: 12.158646821975708\n",
      "MSE train 4.993565904024548 MSE test 11.416380032630975\n",
      "MAE train 1.5333894765107539 MAE test 2.3626076354906362\n",
      "Epoch 8893 / 10000 loss: 12.158326148986816\n",
      "MSE train 4.993454975181908 MSE test 11.416172031475861\n",
      "MAE train 1.5333722381157782 MAE test 2.3625809878013766\n",
      "Epoch 8894 / 10000 loss: 12.157812356948853\n",
      "MSE train 4.993351865555961 MSE test 11.416131396424024\n",
      "MAE train 1.5333527396449294 MAE test 2.362581031156802\n",
      "Epoch 8895 / 10000 loss: 12.157429695129395\n",
      "MSE train 4.993241241961096 MSE test 11.415880442646957\n",
      "MAE train 1.5333364959792426 MAE test 2.362548699121724\n",
      "Epoch 8896 / 10000 loss: 12.157020092010498\n",
      "MSE train 4.993138367034747 MSE test 11.415888206821265\n",
      "MAE train 1.5333159589362644 MAE test 2.362555159473062\n",
      "Epoch 8897 / 10000 loss: 12.156668186187744\n",
      "MSE train 4.993027588471874 MSE test 11.415608595238778\n",
      "MAE train 1.533300213021266 MAE test 2.3625190091779724\n",
      "Epoch 8898 / 10000 loss: 12.156227350234985\n",
      "MSE train 4.992913475370891 MSE test 11.415627345187929\n",
      "MAE train 1.5332765365645167 MAE test 2.3625269841797163\n",
      "Epoch 8899 / 10000 loss: 12.155899047851562\n",
      "MSE train 4.992801718908303 MSE test 11.415397303068442\n",
      "MAE train 1.533259565736158 MAE test 2.3624974036933213\n",
      "Epoch 8900 / 10000 loss: 12.155405282974243\n",
      "MSE train 4.992703486057893 MSE test 11.415383412779327\n",
      "MAE train 1.5332406888516432 MAE test 2.3625009671642636\n",
      "Epoch 8901 / 10000 loss: 12.155035257339478\n",
      "MSE train 4.992593609144506 MSE test 11.415097513523069\n",
      "MAE train 1.5332252649483518 MAE test 2.362463977072047\n",
      "Epoch 8902 / 10000 loss: 12.15462613105774\n",
      "MSE train 4.992476703354273 MSE test 11.415118205425976\n",
      "MAE train 1.5332007533495566 MAE test 2.3624722084021825\n",
      "Epoch 8903 / 10000 loss: 12.154306888580322\n",
      "MSE train 4.992366208678506 MSE test 11.414904709997366\n",
      "MAE train 1.5331836748336225 MAE test 2.362444793562175\n",
      "Epoch 8904 / 10000 loss: 12.153801679611206\n",
      "MSE train 4.992265925725967 MSE test 11.414871823535389\n",
      "MAE train 1.5331646455939432 MAE test 2.3624458346494506\n",
      "Epoch 8905 / 10000 loss: 12.153424978256226\n",
      "MSE train 4.992156567205087 MSE test 11.414608673006837\n",
      "MAE train 1.533148877749531 MAE test 2.3624118516008417\n",
      "Epoch 8906 / 10000 loss: 12.153022527694702\n",
      "MSE train 4.992050044925113 MSE test 11.414622928567074\n",
      "MAE train 1.533127181552885 MAE test 2.36241917192807\n",
      "Epoch 8907 / 10000 loss: 12.152686357498169\n",
      "MSE train 4.991939793589731 MSE test 11.414362543804915\n",
      "MAE train 1.5331111025201705 MAE test 2.3623855362642847\n",
      "Epoch 8908 / 10000 loss: 12.152227878570557\n",
      "MSE train 4.991835987856003 MSE test 11.414373205539885\n",
      "MAE train 1.5330901295492563 MAE test 2.362392367398526\n",
      "Epoch 8909 / 10000 loss: 12.151888132095337\n",
      "MSE train 4.991726152231512 MSE test 11.414104119394835\n",
      "MAE train 1.5330742803733373 MAE test 2.3623575770050036\n",
      "Epoch 8910 / 10000 loss: 12.1514413356781\n",
      "MSE train 4.991618902622091 MSE test 11.414118596307999\n",
      "MAE train 1.5330523067196953 MAE test 2.3623649150811974\n",
      "Epoch 8911 / 10000 loss: 12.151110410690308\n",
      "MSE train 4.99150880821606 MSE test 11.41386478148762\n",
      "MAE train 1.5330360643106034 MAE test 2.362332138298201\n",
      "Epoch 8912 / 10000 loss: 12.15064811706543\n",
      "MSE train 4.991408267506419 MSE test 11.413871056356497\n",
      "MAE train 1.5330159428703214 MAE test 2.3623383544317527\n",
      "Epoch 8913 / 10000 loss: 12.150304555892944\n",
      "MSE train 4.991299203677856 MSE test 11.413592028889745\n",
      "MAE train 1.5330004170463245 MAE test 2.3623022298379426\n",
      "Epoch 8914 / 10000 loss: 12.149874687194824\n",
      "MSE train 4.9911876088252205 MSE test 11.41361017182682\n",
      "MAE train 1.5329771565810202 MAE test 2.3623100595566324\n",
      "Epoch 8915 / 10000 loss: 12.149555444717407\n",
      "MSE train 4.991077816701857 MSE test 11.413378431550964\n",
      "MAE train 1.5329604740198277 MAE test 2.3622801979786003\n",
      "Epoch 8916 / 10000 loss: 12.149072647094727\n",
      "MSE train 4.990981609598326 MSE test 11.413366601417483\n",
      "MAE train 1.5329418279862745 MAE test 2.3622839895500083\n",
      "Epoch 8917 / 10000 loss: 12.148714542388916\n",
      "MSE train 4.990873601248912 MSE test 11.413079978716516\n",
      "MAE train 1.532926669823646 MAE test 2.362246840234084\n",
      "Epoch 8918 / 10000 loss: 12.148314714431763\n",
      "MSE train 4.990758150872189 MSE test 11.413100892050409\n",
      "MAE train 1.532902293096499 MAE test 2.362255055004246\n",
      "Epoch 8919 / 10000 loss: 12.148006677627563\n",
      "MSE train 4.990649573054761 MSE test 11.412889916189219\n",
      "MAE train 1.5328854548461008 MAE test 2.3622279340483816\n",
      "Epoch 8920 / 10000 loss: 12.14750862121582\n",
      "MSE train 4.990550278580137 MSE test 11.412853976400658\n",
      "MAE train 1.5328665385960505 MAE test 2.362228521049997\n",
      "Epoch 8921 / 10000 loss: 12.147140264511108\n",
      "MSE train 4.990442400810127 MSE test 11.412595807442418\n",
      "MAE train 1.532850863090014 MAE test 2.3621951419871814\n",
      "Epoch 8922 / 10000 loss: 12.146745204925537\n",
      "MSE train 4.990339353983744 MSE test 11.412607603854065\n",
      "MAE train 1.5328299276821917 MAE test 2.3622020954509644\n",
      "Epoch 8923 / 10000 loss: 12.146414995193481\n",
      "MSE train 4.990230781435315 MSE test 11.41233896983648\n",
      "MAE train 1.5328142593086345 MAE test 2.3621673434769965\n",
      "Epoch 8924 / 10000 loss: 12.14597225189209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.990124440738882 MSE test 11.412353431909665\n",
      "MAE train 1.5327924012793666 MAE test 2.362174642698224\n",
      "Epoch 8925 / 10000 loss: 12.145648002624512\n",
      "MSE train 4.99001529834243 MSE test 11.4120993629051\n",
      "MAE train 1.53277628899784 MAE test 2.3621418180489857\n",
      "Epoch 8926 / 10000 loss: 12.14518928527832\n",
      "MSE train 4.989915376462798 MSE test 11.41210519022532\n",
      "MAE train 1.5327562333757467 MAE test 2.3621479588940337\n",
      "Epoch 8927 / 10000 loss: 12.144851446151733\n",
      "MSE train 4.989806959446129 MSE test 11.411826052196128\n",
      "MAE train 1.5327407786114433 MAE test 2.362111802155034\n",
      "Epoch 8928 / 10000 loss: 12.1444251537323\n",
      "MSE train 4.989695984392507 MSE test 11.411843511942404\n",
      "MAE train 1.532717607330732 MAE test 2.362119536819372\n",
      "Epoch 8929 / 10000 loss: 12.144109725952148\n",
      "MSE train 4.989586625341759 MSE test 11.411610597683422\n",
      "MAE train 1.5327009794700583 MAE test 2.362089517552169\n",
      "Epoch 8930 / 10000 loss: 12.143630981445312\n",
      "MSE train 4.989490786537467 MSE test 11.41159848510025\n",
      "MAE train 1.5326823437713548 MAE test 2.362093257588918\n",
      "Epoch 8931 / 10000 loss: 12.143276453018188\n",
      "MSE train 4.989383013630318 MSE test 11.411310887913336\n",
      "MAE train 1.5326671889990124 MAE test 2.3620559934979943\n",
      "Epoch 8932 / 10000 loss: 12.142878293991089\n",
      "MSE train 4.989267714869311 MSE test 11.411330883680785\n",
      "MAE train 1.5326427820488955 MAE test 2.3620640823875663\n",
      "Epoch 8933 / 10000 loss: 12.142570972442627\n",
      "MSE train 4.989159321449002 MSE test 11.4111191690524\n",
      "MAE train 1.5326259133485927 MAE test 2.36203686124322\n",
      "Epoch 8934 / 10000 loss: 12.142074823379517\n",
      "MSE train 4.989059985216658 MSE test 11.411081618038535\n",
      "MAE train 1.5326069306166143 MAE test 2.3620372420129803\n",
      "Epoch 8935 / 10000 loss: 12.1417076587677\n",
      "MSE train 4.988952099175958 MSE test 11.410823108334077\n",
      "MAE train 1.532591170437549 MAE test 2.362003841293007\n",
      "Epoch 8936 / 10000 loss: 12.141312599182129\n",
      "MSE train 4.988849273872225 MSE test 11.41083295036302\n",
      "MAE train 1.532570229629492 MAE test 2.362010541441532\n",
      "Epoch 8937 / 10000 loss: 12.140982151031494\n",
      "MSE train 4.988740631440274 MSE test 11.410561806614812\n",
      "MAE train 1.5325544995571045 MAE test 2.3619754686714147\n",
      "Epoch 8938 / 10000 loss: 12.140541076660156\n",
      "MSE train 4.988633569338188 MSE test 11.410575117644186\n",
      "MAE train 1.5325323683082168 MAE test 2.361982638083103\n",
      "Epoch 8939 / 10000 loss: 12.140218019485474\n",
      "MSE train 4.988524017492097 MSE test 11.41032197839341\n",
      "MAE train 1.5325160594154505 MAE test 2.361949957721702\n",
      "Epoch 8940 / 10000 loss: 12.139756917953491\n",
      "MSE train 4.98842467710316 MSE test 11.410324381535098\n",
      "MAE train 1.5324961236767871 MAE test 2.3619556714176815\n",
      "Epoch 8941 / 10000 loss: 12.139415264129639\n",
      "MSE train 4.988315968975984 MSE test 11.410040759583877\n",
      "MAE train 1.532480597442395 MAE test 2.361918961753229\n",
      "Epoch 8942 / 10000 loss: 12.138992547988892\n",
      "MSE train 4.988203303910259 MSE test 11.4100570657615\n",
      "MAE train 1.5324568939763281 MAE test 2.361926570135465\n",
      "Epoch 8943 / 10000 loss: 12.138677597045898\n",
      "MSE train 4.9880935944489515 MSE test 11.409828666076091\n",
      "MAE train 1.5324399783317204 MAE test 2.3618971575578542\n",
      "Epoch 8944 / 10000 loss: 12.138192653656006\n",
      "MSE train 4.987996919352141 MSE test 11.409807371449022\n",
      "MAE train 1.5324212286146397 MAE test 2.361899729340722\n",
      "Epoch 8945 / 10000 loss: 12.137830972671509\n",
      "MSE train 4.987888600486358 MSE test 11.409522796908483\n",
      "MAE train 1.532405790249188 MAE test 2.3618628901515297\n",
      "Epoch 8946 / 10000 loss: 12.137434720993042\n",
      "MSE train 4.987774729763824 MSE test 11.409539262022891\n",
      "MAE train 1.5323817396416308 MAE test 2.361870535310423\n",
      "Epoch 8947 / 10000 loss: 12.137121438980103\n",
      "MSE train 4.9876649399530235 MSE test 11.409313798605698\n",
      "MAE train 1.532364707943019 MAE test 2.361841545646492\n",
      "Epoch 8948 / 10000 loss: 12.13663101196289\n",
      "MSE train 4.987567445714412 MSE test 11.409287730074539\n",
      "MAE train 1.5323458115634363 MAE test 2.361843488293047\n",
      "Epoch 8949 / 10000 loss: 12.136266231536865\n",
      "MSE train 4.987458803758973 MSE test 11.409006198849143\n",
      "MAE train 1.5323301976723562 MAE test 2.3618070910422952\n",
      "Epoch 8950 / 10000 loss: 12.135869026184082\n",
      "MSE train 4.987346315176095 MSE test 11.409020556253035\n",
      "MAE train 1.532306520936556 MAE test 2.3618144865076554\n",
      "Epoch 8951 / 10000 loss: 12.135550498962402\n",
      "MSE train 4.987235798332612 MSE test 11.408784712039825\n",
      "MAE train 1.5322894802251823 MAE test 2.3617841390367578\n",
      "Epoch 8952 / 10000 loss: 12.135065793991089\n",
      "MSE train 4.987138546809224 MSE test 11.408767243285972\n",
      "MAE train 1.532270404557489 MAE test 2.3617872603552703\n",
      "Epoch 8953 / 10000 loss: 12.134705305099487\n",
      "MSE train 4.987029327923566 MSE test 11.408475471760704\n",
      "MAE train 1.5322547728062212 MAE test 2.3617495148979137\n",
      "Epoch 8954 / 10000 loss: 12.13430118560791\n",
      "MSE train 4.986912420014044 MSE test 11.408490241660706\n",
      "MAE train 1.5322298499228164 MAE test 2.3617570029123462\n",
      "Epoch 8955 / 10000 loss: 12.13398790359497\n",
      "MSE train 4.986802079516308 MSE test 11.40827253319204\n",
      "MAE train 1.5322123956095075 MAE test 2.361729073834265\n",
      "Epoch 8956 / 10000 loss: 12.133484601974487\n",
      "MSE train 4.986700846906387 MSE test 11.408230091978155\n",
      "MAE train 1.532192794121422 MAE test 2.361728902369442\n",
      "Epoch 8957 / 10000 loss: 12.133109092712402\n",
      "MSE train 4.986590631751645 MSE test 11.407964446665341\n",
      "MAE train 1.5321763477770016 MAE test 2.361694668432349\n",
      "Epoch 8958 / 10000 loss: 12.132704973220825\n",
      "MSE train 4.986484844628649 MSE test 11.407968281831996\n",
      "MAE train 1.532154510783294 MAE test 2.3617006755938075\n",
      "Epoch 8959 / 10000 loss: 12.132364988327026\n",
      "MSE train 4.986373331624399 MSE test 11.407692069944066\n",
      "MAE train 1.532137874288454 MAE test 2.361665038115349\n",
      "Epoch 8960 / 10000 loss: 12.131911039352417\n",
      "MSE train 4.986263994756783 MSE test 11.407697159910741\n",
      "MAE train 1.5321150336375267 MAE test 2.3616712283339845\n",
      "Epoch 8961 / 10000 loss: 12.131572484970093\n",
      "MSE train 4.9861510997208445 MSE test 11.407432831881396\n",
      "MAE train 1.5320977666813467 MAE test 2.3616371988974167\n",
      "Epoch 8962 / 10000 loss: 12.131101608276367\n",
      "MSE train 4.986046825291622 MSE test 11.4074289562215\n",
      "MAE train 1.5320763233316839 MAE test 2.361642203096374\n",
      "Epoch 8963 / 10000 loss: 12.130747556686401\n",
      "MSE train 4.985933737079008 MSE test 11.407140309351954\n",
      "MAE train 1.532059396454371 MAE test 2.3616049522190945\n",
      "Epoch 8964 / 10000 loss: 12.130300760269165\n",
      "MSE train 4.985818348186566 MSE test 11.40714555847836\n",
      "MAE train 1.5320348088002336 MAE test 2.361611234685783\n",
      "Epoch 8965 / 10000 loss: 12.129963636398315\n",
      "MSE train 4.985703217212416 MSE test 11.40689709902103\n",
      "MAE train 1.5320164467804422 MAE test 2.3615793305989112\n",
      "Epoch 8966 / 10000 loss: 12.129464387893677\n",
      "MSE train 4.985600795896183 MSE test 11.406874427522666\n",
      "MAE train 1.5319957154661386 MAE test 2.361581893081377\n",
      "Epoch 8967 / 10000 loss: 12.129085302352905\n",
      "MSE train 4.985485668259434 MSE test 11.406571489226586\n",
      "MAE train 1.5319783067364032 MAE test 2.361542802328151\n",
      "Epoch 8968 / 10000 loss: 12.128654956817627\n",
      "MSE train 4.985361862391488 MSE test 11.406575828184238\n",
      "MAE train 1.5319512547478824 MAE test 2.361549062691556\n",
      "Epoch 8969 / 10000 loss: 12.128314971923828\n",
      "MSE train 4.98524433989579 MSE test 11.406349505925885\n",
      "MAE train 1.5319315084292244 MAE test 2.3615201569944655\n",
      "Epoch 8970 / 10000 loss: 12.12777853012085\n",
      "MSE train 4.985133810765992 MSE test 11.406290807344512\n",
      "MAE train 1.5319091479029538 MAE test 2.361518017291106\n",
      "Epoch 8971 / 10000 loss: 12.12736701965332\n",
      "MSE train 4.985013775716213 MSE test 11.406017577138545\n",
      "MAE train 1.5318895448467051 MAE test 2.3614829499087406\n",
      "Epoch 8972 / 10000 loss: 12.126922845840454\n",
      "MSE train 4.984899167797223 MSE test 11.406003472034687\n",
      "MAE train 1.5318648498911063 MAE test 2.3614868120480113\n",
      "Epoch 8973 / 10000 loss: 12.126530170440674\n",
      "MSE train 4.984775001510445 MSE test 11.405702349158782\n",
      "MAE train 1.531844396404902 MAE test 2.3614481295951566\n",
      "Epoch 8974 / 10000 loss: 12.12603497505188\n",
      "MSE train 4.984646438152064 MSE test 11.405693004104796\n",
      "MAE train 1.5318156493643167 MAE test 2.36145271507602\n",
      "Epoch 8975 / 10000 loss: 12.125643014907837\n",
      "MSE train 4.984515976484958 MSE test 11.405428099445727\n",
      "MAE train 1.5317924393020548 MAE test 2.3614188819280963\n",
      "Epoch 8976 / 10000 loss: 12.125081062316895\n",
      "MSE train 4.984395673732409 MSE test 11.405387950118158\n",
      "MAE train 1.53176600237514 MAE test 2.361419402632108\n",
      "Epoch 8977 / 10000 loss: 12.12462830543518\n",
      "MSE train 4.984259788083636 MSE test 11.40506560085132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5317419485622292 MAE test 2.361378041067587\n",
      "Epoch 8978 / 10000 loss: 12.124110698699951\n",
      "MSE train 4.984112122428262 MSE test 11.405048714286332\n",
      "MAE train 1.5317071862820815 MAE test 2.361381801115304\n",
      "Epoch 8979 / 10000 loss: 12.12367057800293\n",
      "MSE train 4.983967396691913 MSE test 11.40480003766882\n",
      "MAE train 1.5316785921044085 MAE test 2.36135030407094\n",
      "Epoch 8980 / 10000 loss: 12.123019218444824\n",
      "MSE train 4.983826534165166 MSE test 11.404717144726765\n",
      "MAE train 1.531646291009842 MAE test 2.361345356242381\n",
      "Epoch 8981 / 10000 loss: 12.122475624084473\n",
      "MSE train 4.9836736896960065 MSE test 11.404419953966439\n",
      "MAE train 1.5316158729903824 MAE test 2.3613075268837624\n",
      "Epoch 8982 / 10000 loss: 12.121883869171143\n",
      "MSE train 4.983525023355261 MSE test 11.40438100001129\n",
      "MAE train 1.5315798376832832 MAE test 2.361308466171137\n",
      "Epoch 8983 / 10000 loss: 12.121331214904785\n",
      "MSE train 4.983367180431046 MSE test 11.404056322942273\n",
      "MAE train 1.5315480297546455 MAE test 2.3612670200735826\n",
      "Epoch 8984 / 10000 loss: 12.1206693649292\n",
      "MSE train 4.983207488243981 MSE test 11.40402660753382\n",
      "MAE train 1.5315086498667578 MAE test 2.3612692073052206\n",
      "Epoch 8985 / 10000 loss: 12.120113372802734\n",
      "MSE train 4.983051627834069 MSE test 11.403746628007768\n",
      "MAE train 1.531476667298018 MAE test 2.3612336043154922\n",
      "Epoch 8986 / 10000 loss: 12.119398832321167\n",
      "MSE train 4.982913589624676 MSE test 11.40369461513484\n",
      "MAE train 1.5314439289167823 MAE test 2.3612326656232017\n",
      "Epoch 8987 / 10000 loss: 12.118819236755371\n",
      "MSE train 4.982769114786967 MSE test 11.403368553637534\n",
      "MAE train 1.5314166447676594 MAE test 2.3611908258571965\n",
      "Epoch 8988 / 10000 loss: 12.118213415145874\n",
      "MSE train 4.982622746772042 MSE test 11.403355087910809\n",
      "MAE train 1.5313819862609923 MAE test 2.3611949282840343\n",
      "Epoch 8989 / 10000 loss: 12.117727756500244\n",
      "MSE train 4.982489112505025 MSE test 11.403116393822172\n",
      "MAE train 1.5313566891039303 MAE test 2.3611644919499764\n",
      "Epoch 8990 / 10000 loss: 12.117079019546509\n",
      "MSE train 4.982368781600303 MSE test 11.40305193634642\n",
      "MAE train 1.5313306776432913 MAE test 2.3611616021232193\n",
      "Epoch 8991 / 10000 loss: 12.116585969924927\n",
      "MSE train 4.982244407170264 MSE test 11.40277718478785\n",
      "MAE train 1.5313091092943731 MAE test 2.3611262765947028\n",
      "Epoch 8992 / 10000 loss: 12.116089344024658\n",
      "MSE train 4.9821301916359735 MSE test 11.402767794078795\n",
      "MAE train 1.5312840482503396 MAE test 2.3611305976772607\n",
      "Epoch 8993 / 10000 loss: 12.115672588348389\n",
      "MSE train 4.982011373106939 MSE test 11.4024770564028\n",
      "MAE train 1.5312648706181238 MAE test 2.3610930484201123\n",
      "Epoch 8994 / 10000 loss: 12.115174770355225\n",
      "MSE train 4.981893401347183 MSE test 11.402481058719054\n",
      "MAE train 1.5312390037737702 MAE test 2.361099068319168\n",
      "Epoch 8995 / 10000 loss: 12.114803314208984\n",
      "MSE train 4.98177733178182 MSE test 11.402231870180266\n",
      "MAE train 1.531220015769643 MAE test 2.3610669319127187\n",
      "Epoch 8996 / 10000 loss: 12.11428713798523\n",
      "MSE train 4.981675866449783 MSE test 11.40221661898657\n",
      "MAE train 1.5311990862364515 MAE test 2.3610702980597478\n",
      "Epoch 8997 / 10000 loss: 12.113901615142822\n",
      "MSE train 4.981563760224106 MSE test 11.40192083389259\n",
      "MAE train 1.5311822066890883 MAE test 2.361031954241579\n",
      "Epoch 8998 / 10000 loss: 12.113470077514648\n",
      "MSE train 4.981444911782856 MSE test 11.40193466101909\n",
      "MAE train 1.5311563001847657 MAE test 2.361039201242813\n",
      "Epoch 8999 / 10000 loss: 12.11314082145691\n",
      "MSE train 4.981334152853837 MSE test 11.401720755683364\n",
      "MAE train 1.5311383088887203 MAE test 2.3610116552100604\n",
      "Epoch 9000 / 10000 loss: 12.112624168395996\n",
      "MSE train 4.981232217409351 MSE test 11.401676109201514\n",
      "MAE train 1.531118315225924 MAE test 2.3610110542837877\n",
      "Epoch 9001 / 10000 loss: 12.11224102973938\n",
      "MSE train 4.981122885873041 MSE test 11.401420734036703\n",
      "MAE train 1.5311017359754773 MAE test 2.3609779991463347\n",
      "Epoch 9002 / 10000 loss: 12.111833810806274\n",
      "MSE train 4.98102136005711 MSE test 11.401425541367297\n",
      "MAE train 1.531080860968012 MAE test 2.36098393911592\n",
      "Epoch 9003 / 10000 loss: 12.111488342285156\n",
      "MSE train 4.980912393576065 MSE test 11.401145914874673\n",
      "MAE train 1.5310649498232562 MAE test 2.3609476551474224\n",
      "Epoch 9004 / 10000 loss: 12.111050844192505\n",
      "MSE train 4.980801449738151 MSE test 11.40116147573378\n",
      "MAE train 1.5310414816591509 MAE test 2.360955041448647\n",
      "Epoch 9005 / 10000 loss: 12.110728740692139\n",
      "MSE train 4.9806919661712366 MSE test 11.400925839328222\n",
      "MAE train 1.531024578175089 MAE test 2.3609245482394448\n",
      "Epoch 9006 / 10000 loss: 12.11024808883667\n",
      "MSE train 4.980596234467697 MSE test 11.400914752946688\n",
      "MAE train 1.5310056610244112 MAE test 2.3609283364186715\n",
      "Epoch 9007 / 10000 loss: 12.109890937805176\n",
      "MSE train 4.980488709364799 MSE test 11.400626782330013\n",
      "MAE train 1.5309903522184853 MAE test 2.360890908415037\n",
      "Epoch 9008 / 10000 loss: 12.109488725662231\n",
      "MSE train 4.98037378057217 MSE test 11.40064669758709\n",
      "MAE train 1.530965807320351 MAE test 2.3608988708194176\n",
      "Epoch 9009 / 10000 loss: 12.109180450439453\n",
      "MSE train 4.980266105015167 MSE test 11.400437279798785\n",
      "MAE train 1.5309489134498575 MAE test 2.3608718114947873\n",
      "Epoch 9010 / 10000 loss: 12.108683109283447\n",
      "MSE train 4.980167223151217 MSE test 11.400398694940074\n",
      "MAE train 1.5309298979260832 MAE test 2.3608719402073737\n",
      "Epoch 9011 / 10000 loss: 12.10831594467163\n",
      "MSE train 4.980060154279526 MSE test 11.400145082660622\n",
      "MAE train 1.530914138553328 MAE test 2.3608390324656474\n",
      "Epoch 9012 / 10000 loss: 12.107922315597534\n",
      "MSE train 4.979959737014658 MSE test 11.400155092980253\n",
      "MAE train 1.5308936742116792 MAE test 2.3608456090677126\n",
      "Epoch 9013 / 10000 loss: 12.10758924484253\n",
      "MSE train 4.979852427408817 MSE test 11.399882123263007\n",
      "MAE train 1.5308782400257068 MAE test 2.360810140721189\n",
      "Epoch 9014 / 10000 loss: 12.107157707214355\n",
      "MSE train 4.979744557124002 MSE test 11.399899516669244\n",
      "MAE train 1.530855711425696 MAE test 2.360817710943219\n",
      "Epoch 9015 / 10000 loss: 12.10684084892273\n",
      "MSE train 4.979636333086695 MSE test 11.399659539855037\n",
      "MAE train 1.5308394151246496 MAE test 2.360786595079922\n",
      "Epoch 9016 / 10000 loss: 12.10637354850769\n",
      "MSE train 4.979541019871842 MSE test 11.399657504871088\n",
      "MAE train 1.5308205478247696 MAE test 2.3607915246178814\n",
      "Epoch 9017 / 10000 loss: 12.106027841567993\n",
      "MSE train 4.979434319721309 MSE test 11.399371773993952\n",
      "MAE train 1.5308055484759158 MAE test 2.360754357482958\n",
      "Epoch 9018 / 10000 loss: 12.105624437332153\n",
      "MSE train 4.979320506190043 MSE test 11.399393655854448\n",
      "MAE train 1.5307813608318561 MAE test 2.3607625313140552\n",
      "Epoch 9019 / 10000 loss: 12.105321407318115\n",
      "MSE train 4.979213591441902 MSE test 11.399185678761084\n",
      "MAE train 1.5307647400431443 MAE test 2.3607356374992015\n",
      "Epoch 9020 / 10000 loss: 12.104828119277954\n",
      "MSE train 4.979115621925794 MSE test 11.399149725173919\n",
      "MAE train 1.5307460069136845 MAE test 2.3607360614227404\n",
      "Epoch 9021 / 10000 loss: 12.104464769363403\n",
      "MSE train 4.979009232505135 MSE test 11.398897046169509\n",
      "MAE train 1.5307304921126923 MAE test 2.3607032448675485\n",
      "Epoch 9022 / 10000 loss: 12.104075193405151\n",
      "MSE train 4.978909078097535 MSE test 11.398909151267274\n",
      "MAE train 1.5307101356002983 MAE test 2.360710056388124\n",
      "Epoch 9023 / 10000 loss: 12.103746891021729\n",
      "MSE train 4.978802287370011 MSE test 11.398639154441538\n",
      "MAE train 1.5306948420191775 MAE test 2.360674943749644\n",
      "Epoch 9024 / 10000 loss: 12.103316068649292\n",
      "MSE train 4.978695610136734 MSE test 11.398657433187198\n",
      "MAE train 1.5306726682259721 MAE test 2.3606825957451134\n",
      "Epoch 9025 / 10000 loss: 12.103000402450562\n",
      "MSE train 4.978587884466075 MSE test 11.398416038713055\n",
      "MAE train 1.5306566062187639 MAE test 2.3606512655250436\n",
      "Epoch 9026 / 10000 loss: 12.102538824081421\n",
      "MSE train 4.978492433827317 MSE test 11.398417704638819\n",
      "MAE train 1.5306376809120796 MAE test 2.3606566646683036\n",
      "Epoch 9027 / 10000 loss: 12.102198839187622\n",
      "MSE train 4.97838606366074 MSE test 11.398134309744616\n",
      "MAE train 1.530622768211357 MAE test 2.3606197722185214\n",
      "Epoch 9028 / 10000 loss: 12.101792573928833\n",
      "MSE train 4.978273195609458 MSE test 11.398157019408153\n",
      "MAE train 1.5305988637032393 MAE test 2.3606280206311374\n",
      "Epoch 9029 / 10000 loss: 12.101490020751953\n",
      "MSE train 4.978166398124845 MSE test 11.397947244943252\n",
      "MAE train 1.5305823499400384 MAE test 2.3606008628353408\n",
      "Epoch 9030 / 10000 loss: 12.101001262664795\n",
      "MSE train 4.978069647732577 MSE test 11.39791625079189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5305638632842336 MAE test 2.36060193793512\n",
      "Epoch 9031 / 10000 loss: 12.100641012191772\n",
      "MSE train 4.977963650161047 MSE test 11.397658253836115\n",
      "MAE train 1.5305485734703674 MAE test 2.3605683829553943\n",
      "Epoch 9032 / 10000 loss: 12.100253105163574\n",
      "MSE train 4.977861208344731 MSE test 11.397674435852336\n",
      "MAE train 1.5305275813578263 MAE test 2.360575729727101\n",
      "Epoch 9033 / 10000 loss: 12.099931240081787\n",
      "MSE train 4.977754279451906 MSE test 11.397415545882703\n",
      "MAE train 1.530512073948932 MAE test 2.360542066188211\n",
      "Epoch 9034 / 10000 loss: 12.099489688873291\n",
      "MSE train 4.977652683028627 MSE test 11.39743015322973\n",
      "MAE train 1.5304913162798723 MAE test 2.360549188355337\n",
      "Epoch 9035 / 10000 loss: 12.09916615486145\n",
      "MSE train 4.977545633950847 MSE test 11.397169154990015\n",
      "MAE train 1.5304758212826148 MAE test 2.3605152456620755\n",
      "Epoch 9036 / 10000 loss: 12.098727703094482\n",
      "MSE train 4.977443353686823 MSE test 11.397184476172157\n",
      "MAE train 1.5304548780311569 MAE test 2.360522477241957\n",
      "Epoch 9037 / 10000 loss: 12.098406076431274\n",
      "MSE train 4.977336212402387 MSE test 11.396926663824104\n",
      "MAE train 1.5304392915496197 MAE test 2.360488939993815\n",
      "Epoch 9038 / 10000 loss: 12.097963809967041\n",
      "MSE train 4.977235308474538 MSE test 11.39694046738756\n",
      "MAE train 1.5304187440742036 MAE test 2.3604959619613584\n",
      "Epoch 9039 / 10000 loss: 12.097639560699463\n",
      "MSE train 4.9771283705275655 MSE test 11.3966772756605\n",
      "MAE train 1.5304033167717102 MAE test 2.360461711780109\n",
      "Epoch 9040 / 10000 loss: 12.097203969955444\n",
      "MSE train 4.977025084067407 MSE test 11.396693820632976\n",
      "MAE train 1.5303820887880053 MAE test 2.36046909573078\n",
      "Epoch 9041 / 10000 loss: 12.096884489059448\n",
      "MSE train 4.9769178631585715 MSE test 11.39644085626561\n",
      "MAE train 1.5303664024506352 MAE test 2.360436204232873\n",
      "Epoch 9042 / 10000 loss: 12.096437692642212\n",
      "MSE train 4.976818875229957 MSE test 11.396452098281868\n",
      "MAE train 1.5303463884506157 MAE test 2.3604428800047343\n",
      "Epoch 9043 / 10000 loss: 12.09610891342163\n",
      "MSE train 4.976712221432881 MSE test 11.396182322494836\n",
      "MAE train 1.5303311651156366 MAE test 2.360407751156132\n",
      "Epoch 9044 / 10000 loss: 12.095683574676514\n",
      "MSE train 4.976605753029352 MSE test 11.396201995649344\n",
      "MAE train 1.530309047427982 MAE test 2.36041557295686\n",
      "Epoch 9045 / 10000 loss: 12.095369577407837\n",
      "MSE train 4.976498299620429 MSE test 11.395963530314619\n",
      "MAE train 1.5302930242874615 MAE test 2.3603845902884153\n",
      "Epoch 9046 / 10000 loss: 12.09490966796875\n",
      "MSE train 4.9764035851976764 MSE test 11.395965019053312\n",
      "MAE train 1.530274321734684 MAE test 2.360389951926657\n",
      "Epoch 9047 / 10000 loss: 12.094568490982056\n",
      "MSE train 4.976297577823377 MSE test 11.395682546935047\n",
      "MAE train 1.5302595093320452 MAE test 2.360353146626134\n",
      "Epoch 9048 / 10000 loss: 12.094166994094849\n",
      "MSE train 4.9761847338811425 MSE test 11.395706515812483\n",
      "MAE train 1.5302356046687273 MAE test 2.36036154740023\n",
      "Epoch 9049 / 10000 loss: 12.09386682510376\n",
      "MSE train 4.976078330240055 MSE test 11.395499585797637\n",
      "MAE train 1.530219166804126 MAE test 2.3603347415226112\n",
      "Epoch 9050 / 10000 loss: 12.09337830543518\n",
      "MSE train 4.975981477581322 MSE test 11.395467712309548\n",
      "MAE train 1.5302006857373869 MAE test 2.360335683118382\n",
      "Epoch 9051 / 10000 loss: 12.093018770217896\n",
      "MSE train 4.975875777654008 MSE test 11.395214049424133\n",
      "MAE train 1.5301854078805994 MAE test 2.3603026830969567\n",
      "Epoch 9052 / 10000 loss: 12.092632293701172\n",
      "MSE train 4.9757749616372795 MSE test 11.395229683787827\n",
      "MAE train 1.5301648588959695 MAE test 2.3603099422496445\n",
      "Epoch 9053 / 10000 loss: 12.09230923652649\n",
      "MSE train 4.975668483695329 MSE test 11.394966618028386\n",
      "MAE train 1.530149562703648 MAE test 2.3602757095791276\n",
      "Epoch 9054 / 10000 loss: 12.091876029968262\n",
      "MSE train 4.975564699899947 MSE test 11.394984708297464\n",
      "MAE train 1.5301281932907664 MAE test 2.360283303986586\n",
      "Epoch 9055 / 10000 loss: 12.091557502746582\n",
      "MSE train 4.975457627938848 MSE test 11.394734947879922\n",
      "MAE train 1.5301124987377601 MAE test 2.360250819423917\n",
      "Epoch 9056 / 10000 loss: 12.091109275817871\n",
      "MSE train 4.975359655974019 MSE test 11.39474543292058\n",
      "MAE train 1.5300927664939514 MAE test 2.360257382392172\n",
      "Epoch 9057 / 10000 loss: 12.090779066085815\n",
      "MSE train 4.97525327316738 MSE test 11.394473271738732\n",
      "MAE train 1.530077669658204 MAE test 2.360221942401067\n",
      "Epoch 9058 / 10000 loss: 12.09035873413086\n",
      "MSE train 4.975145380307617 MSE test 11.39449455511174\n",
      "MAE train 1.5300551418730872 MAE test 2.3602299793672543\n",
      "Epoch 9059 / 10000 loss: 12.090048789978027\n",
      "MSE train 4.975038161136362 MSE test 11.394263713885282\n",
      "MAE train 1.5300390054947228 MAE test 2.3602000024455574\n",
      "Epoch 9060 / 10000 loss: 12.089582443237305\n",
      "MSE train 4.974944360334057 MSE test 11.394259630270431\n",
      "MAE train 1.530020698985763 MAE test 2.360204610483845\n",
      "Epoch 9061 / 10000 loss: 12.089236497879028\n",
      "MSE train 4.974838696786517 MSE test 11.393977168022497\n",
      "MAE train 1.530005980870708 MAE test 2.360167809042516\n",
      "Epoch 9062 / 10000 loss: 12.088844060897827\n",
      "MSE train 4.9747255907611025 MSE test 11.394001947758436\n",
      "MAE train 1.5299819793236433 MAE test 2.3601763307091765\n",
      "Epoch 9063 / 10000 loss: 12.088544368743896\n",
      "MSE train 4.974619534473062 MSE test 11.393797760685528\n",
      "MAE train 1.5299655752629642 MAE test 2.3601498636803515\n",
      "Epoch 9064 / 10000 loss: 12.08805513381958\n",
      "MSE train 4.9745220742662335 MSE test 11.393763578427114\n",
      "MAE train 1.5299469992751806 MAE test 2.360150499523926\n",
      "Epoch 9065 / 10000 loss: 12.087695598602295\n",
      "MSE train 4.974416407031182 MSE test 11.393515137113411\n",
      "MAE train 1.529931641442396 MAE test 2.3601181947952514\n",
      "Epoch 9066 / 10000 loss: 12.087308645248413\n",
      "MSE train 4.974317465313189 MSE test 11.393528758195513\n",
      "MAE train 1.5299116097245966 MAE test 2.360125181649902\n",
      "Epoch 9067 / 10000 loss: 12.086982488632202\n",
      "MSE train 4.9742113878669425 MSE test 11.393259566820793\n",
      "MAE train 1.5298965381142675 MAE test 2.3600901392791664\n",
      "Epoch 9068 / 10000 loss: 12.086557388305664\n",
      "MSE train 4.974104405617984 MSE test 11.393280870687482\n",
      "MAE train 1.5298742621188144 MAE test 2.3600981730498027\n",
      "Epoch 9069 / 10000 loss: 12.086247205734253\n",
      "MSE train 4.973997296897129 MSE test 11.393046005593353\n",
      "MAE train 1.5298582443008806 MAE test 2.36006766305001\n",
      "Epoch 9070 / 10000 loss: 12.085784196853638\n",
      "MSE train 4.973903160865912 MSE test 11.393046039199987\n",
      "MAE train 1.5298397361678029 MAE test 2.360072829135696\n",
      "Epoch 9071 / 10000 loss: 12.085441827774048\n",
      "MSE train 4.973797438155651 MSE test 11.392763960916485\n",
      "MAE train 1.5298250025670155 MAE test 2.36003607485518\n",
      "Epoch 9072 / 10000 loss: 12.085044622421265\n",
      "MSE train 4.973684426845186 MSE test 11.392788954911207\n",
      "MAE train 1.529801021432274 MAE test 2.3600446301478124\n",
      "Epoch 9073 / 10000 loss: 12.084745645523071\n",
      "MSE train 4.973578408452847 MSE test 11.392584812728517\n",
      "MAE train 1.5297846285233478 MAE test 2.360018165722325\n",
      "Epoch 9074 / 10000 loss: 12.084257125854492\n",
      "MSE train 4.973481046498927 MSE test 11.392550977459502\n",
      "MAE train 1.5297660689201067 MAE test 2.3600188597156326\n",
      "Epoch 9075 / 10000 loss: 12.083897113800049\n",
      "MSE train 4.973375405710397 MSE test 11.392302471244662\n",
      "MAE train 1.5297507244667328 MAE test 2.359986539404341\n",
      "Epoch 9076 / 10000 loss: 12.08351182937622\n",
      "MSE train 4.973276398410705 MSE test 11.392316473587734\n",
      "MAE train 1.5297306696822481 MAE test 2.359993583048147\n",
      "Epoch 9077 / 10000 loss: 12.083184480667114\n",
      "MSE train 4.973170313538254 MSE test 11.392048024967572\n",
      "MAE train 1.5297155807539806 MAE test 2.3599586310420557\n",
      "Epoch 9078 / 10000 loss: 12.082760334014893\n",
      "MSE train 4.9730637147931445 MSE test 11.392069312420974\n",
      "MAE train 1.5296934003024858 MAE test 2.359966671426329\n",
      "Epoch 9079 / 10000 loss: 12.082448720932007\n",
      "MSE train 4.9729565969650205 MSE test 11.391833538401759\n",
      "MAE train 1.5296774063980845 MAE test 2.35993603658189\n",
      "Epoch 9080 / 10000 loss: 12.081987619400024\n",
      "MSE train 4.972862333148121 MSE test 11.391834848389847\n",
      "MAE train 1.5296588376910731 MAE test 2.3599413757504544\n",
      "Epoch 9081 / 10000 loss: 12.081647396087646\n",
      "MSE train 4.972756631398139 MSE test 11.39155326007294\n",
      "MAE train 1.5296440944365683 MAE test 2.3599046804958705\n",
      "Epoch 9082 / 10000 loss: 12.081248998641968\n",
      "MSE train 4.972643838568124 MSE test 11.391578201333848\n",
      "MAE train 1.5296201714727746 MAE test 2.359913229335793\n",
      "Epoch 9083 / 10000 loss: 12.080948829650879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.972537788383674 MSE test 11.391373557419989\n",
      "MAE train 1.5296037795903517 MAE test 2.3598867092123244\n",
      "Epoch 9084 / 10000 loss: 12.080461502075195\n",
      "MSE train 4.9724407602330345 MSE test 11.391340975590055\n",
      "MAE train 1.5295852729106298 MAE test 2.3598875683567915\n",
      "Epoch 9085 / 10000 loss: 12.080102682113647\n",
      "MSE train 4.972335153342295 MSE test 11.391091068351463\n",
      "MAE train 1.5295699583195534 MAE test 2.359855064520624\n",
      "Epoch 9086 / 10000 loss: 12.079716444015503\n",
      "MSE train 4.97223563766502 MSE test 11.391106049352521\n",
      "MAE train 1.5295497526390154 MAE test 2.359862246381037\n",
      "Epoch 9087 / 10000 loss: 12.079392433166504\n",
      "MSE train 4.972129484281169 MSE test 11.3908401128647\n",
      "MAE train 1.5295345922250947 MAE test 2.359827625572613\n",
      "Epoch 9088 / 10000 loss: 12.078964471817017\n",
      "MSE train 4.972024017701244 MSE test 11.39086058315916\n",
      "MAE train 1.5295127260964492 MAE test 2.359835558462375\n",
      "Epoch 9089 / 10000 loss: 12.078650951385498\n",
      "MSE train 4.971916977931182 MSE test 11.390620179838393\n",
      "MAE train 1.5294968517409697 MAE test 2.359804309565565\n",
      "Epoch 9090 / 10000 loss: 12.078194379806519\n",
      "MSE train 4.9718217667563716 MSE test 11.390625480898187\n",
      "MAE train 1.5294779498530762 MAE test 2.3598101895914927\n",
      "Epoch 9091 / 10000 loss: 12.077858686447144\n",
      "MSE train 4.971715918455143 MSE test 11.390346242693031\n",
      "MAE train 1.52946311325577 MAE test 2.3597737989806444\n",
      "Epoch 9092 / 10000 loss: 12.077453136444092\n",
      "MSE train 4.971604246776479 MSE test 11.39037076183307\n",
      "MAE train 1.5294395142333004 MAE test 2.3597822979309364\n",
      "Epoch 9093 / 10000 loss: 12.077151536941528\n",
      "MSE train 4.971497854921265 MSE test 11.390160452972065\n",
      "MAE train 1.5294231389980155 MAE test 2.3597550228394164\n",
      "Epoch 9094 / 10000 loss: 12.076669454574585\n",
      "MSE train 4.971402437707485 MSE test 11.390135445158927\n",
      "MAE train 1.5294048913386917 MAE test 2.359756896327166\n",
      "Epoch 9095 / 10000 loss: 12.07631254196167\n",
      "MSE train 4.971297004778256 MSE test 11.389874212498137\n",
      "MAE train 1.5293898220594169 MAE test 2.3597228866745996\n",
      "Epoch 9096 / 10000 loss: 12.075928449630737\n",
      "MSE train 4.971192744438439 MSE test 11.389894474957723\n",
      "MAE train 1.5293682852790011 MAE test 2.359730788245685\n",
      "Epoch 9097 / 10000 loss: 12.075613021850586\n",
      "MSE train 4.97108596512661 MSE test 11.389648379728104\n",
      "MAE train 1.529352591800014 MAE test 2.359698787273254\n",
      "Epoch 9098 / 10000 loss: 12.075163125991821\n",
      "MSE train 4.970988971701337 MSE test 11.389658487490959\n",
      "MAE train 1.529333129797111 MAE test 2.3597053193076585\n",
      "Epoch 9099 / 10000 loss: 12.074832439422607\n",
      "MSE train 4.970882869526117 MSE test 11.389384737595574\n",
      "MAE train 1.5293181271575327 MAE test 2.3596696544021776\n",
      "Epoch 9100 / 10000 loss: 12.074417352676392\n",
      "MSE train 4.970773900714006 MSE test 11.389407696457193\n",
      "MAE train 1.5292952788047554 MAE test 2.3596779428115884\n",
      "Epoch 9101 / 10000 loss: 12.074110746383667\n",
      "MSE train 4.970666953333477 MSE test 11.389184394205035\n",
      "MAE train 1.529279051896524 MAE test 2.359648947754248\n",
      "Epoch 9102 / 10000 loss: 12.073639154434204\n",
      "MSE train 4.970573485117381 MSE test 11.389174569805597\n",
      "MAE train 1.5292609554628134 MAE test 2.3596528374930688\n",
      "Epoch 9103 / 10000 loss: 12.07328987121582\n",
      "MSE train 4.97046812987714 MSE test 11.388896494864428\n",
      "MAE train 1.5292462263571296 MAE test 2.3596165983223454\n",
      "Epoch 9104 / 10000 loss: 12.072903633117676\n",
      "MSE train 4.9703564271949645 MSE test 11.38892145370979\n",
      "MAE train 1.5292226012150953 MAE test 2.3596251660555256\n",
      "Epoch 9105 / 10000 loss: 12.072602033615112\n",
      "MSE train 4.970250081934744 MSE test 11.388711475147486\n",
      "MAE train 1.52920624339114 MAE test 2.3595979229654764\n",
      "Epoch 9106 / 10000 loss: 12.072119235992432\n",
      "MSE train 4.9701547123832786 MSE test 11.388686813673086\n",
      "MAE train 1.5291879960887544 MAE test 2.359599841141845\n",
      "Epoch 9107 / 10000 loss: 12.071763038635254\n",
      "MSE train 4.970049352608194 MSE test 11.388425585525532\n",
      "MAE train 1.5291729467055206 MAE test 2.3595658306070932\n",
      "Epoch 9108 / 10000 loss: 12.07137942314148\n",
      "MSE train 4.9699449390735015 MSE test 11.388445986727378\n",
      "MAE train 1.5291513702857236 MAE test 2.3595737704774744\n",
      "Epoch 9109 / 10000 loss: 12.071064233779907\n",
      "MSE train 4.969838188172101 MSE test 11.388200600959964\n",
      "MAE train 1.5291356682879633 MAE test 2.359541859505881\n",
      "Epoch 9110 / 10000 loss: 12.070614576339722\n",
      "MSE train 4.969741397957347 MSE test 11.38821037037198\n",
      "MAE train 1.5291162562149574 MAE test 2.3595483692041257\n",
      "Epoch 9111 / 10000 loss: 12.070282697677612\n",
      "MSE train 4.969635349392714 MSE test 11.387936403089956\n",
      "MAE train 1.5291012718759776 MAE test 2.3595126716089676\n",
      "Epoch 9112 / 10000 loss: 12.069869041442871\n",
      "MSE train 4.969526172997809 MSE test 11.387959628531188\n",
      "MAE train 1.5290783642858787 MAE test 2.3595209985268313\n",
      "Epoch 9113 / 10000 loss: 12.069562911987305\n",
      "MSE train 4.969419207727485 MSE test 11.387737416769692\n",
      "MAE train 1.5290621176473422 MAE test 2.359492147884356\n",
      "Epoch 9114 / 10000 loss: 12.069090604782104\n",
      "MSE train 4.969325791122522 MSE test 11.387726613437254\n",
      "MAE train 1.5290440397597111 MAE test 2.359495908654637\n",
      "Epoch 9115 / 10000 loss: 12.068741083145142\n",
      "MSE train 4.969220388601309 MSE test 11.3874495055689\n",
      "MAE train 1.5290292881039005 MAE test 2.3594598091535386\n",
      "Epoch 9116 / 10000 loss: 12.068354368209839\n",
      "MSE train 4.969109074069279 MSE test 11.387474311408813\n",
      "MAE train 1.529005768940312 MAE test 2.359468356728355\n",
      "Epoch 9117 / 10000 loss: 12.068053722381592\n",
      "MSE train 4.969002618635058 MSE test 11.387262618651295\n",
      "MAE train 1.5289894250958507 MAE test 2.3594408985751993\n",
      "Epoch 9118 / 10000 loss: 12.067573070526123\n",
      "MSE train 4.968907734919322 MSE test 11.387240340267972\n",
      "MAE train 1.528971236222968 MAE test 2.3594431303884225\n",
      "Epoch 9119 / 10000 loss: 12.067217588424683\n",
      "MSE train 4.9688024365471515 MSE test 11.38697608464131\n",
      "MAE train 1.5289562596860387 MAE test 2.359408722182349\n",
      "Epoch 9120 / 10000 loss: 12.066833257675171\n",
      "MSE train 4.968696606927394 MSE test 11.386997633583055\n",
      "MAE train 1.5289342828153003 MAE test 2.359416834093696\n",
      "Epoch 9121 / 10000 loss: 12.066522121429443\n",
      "MSE train 4.9685897511765535 MSE test 11.386758719165902\n",
      "MAE train 1.5289184313183435 MAE test 2.359385777893585\n",
      "Epoch 9122 / 10000 loss: 12.066065549850464\n",
      "MSE train 4.9684947284142735 MSE test 11.386763825659663\n",
      "MAE train 1.5288995725397052 MAE test 2.3593916498849388\n",
      "Epoch 9123 / 10000 loss: 12.065728425979614\n",
      "MSE train 4.968388959060609 MSE test 11.38648477649416\n",
      "MAE train 1.5288847612255 MAE test 2.3593552888943106\n",
      "Epoch 9124 / 10000 loss: 12.065324783325195\n",
      "MSE train 4.968277115804693 MSE test 11.386509623715783\n",
      "MAE train 1.528861099336366 MAE test 2.3593638469385882\n",
      "Epoch 9125 / 10000 loss: 12.065024137496948\n",
      "MSE train 4.968170818959197 MSE test 11.386300542465925\n",
      "MAE train 1.5288447359498212 MAE test 2.3593367364197353\n",
      "Epoch 9126 / 10000 loss: 12.064541816711426\n",
      "MSE train 4.968075234006624 MSE test 11.386274555962123\n",
      "MAE train 1.528826448614535 MAE test 2.3593384887005127\n",
      "Epoch 9127 / 10000 loss: 12.064184665679932\n",
      "MSE train 4.967969808762786 MSE test 11.386015437325613\n",
      "MAE train 1.5288113433792596 MAE test 2.3593047635383324\n",
      "Epoch 9128 / 10000 loss: 12.063801050186157\n",
      "MSE train 4.967866351256571 MSE test 11.386035010226363\n",
      "MAE train 1.528790023066961 MAE test 2.3593125945428994\n",
      "Epoch 9129 / 10000 loss: 12.063485145568848\n",
      "MSE train 4.967759710151388 MSE test 11.385785811948047\n",
      "MAE train 1.5287744242776002 MAE test 2.3592801859260044\n",
      "Epoch 9130 / 10000 loss: 12.06303858757019\n",
      "MSE train 4.967661485781569 MSE test 11.38579818127897\n",
      "MAE train 1.5287545861621727 MAE test 2.359287039848682\n",
      "Epoch 9131 / 10000 loss: 12.062711238861084\n",
      "MSE train 4.967555235090033 MSE test 11.385529304450106\n",
      "MAE train 1.5287394546997073 MAE test 2.3592520237006447\n",
      "Epoch 9132 / 10000 loss: 12.062289714813232\n",
      "MSE train 4.967448430949156 MSE test 11.385550671290805\n",
      "MAE train 1.5287172082508058 MAE test 2.3592601117419636\n",
      "Epoch 9133 / 10000 loss: 12.0619797706604\n",
      "MSE train 4.967341349925184 MSE test 11.385317289859913\n",
      "MAE train 1.5287011705573526 MAE test 2.3592297968644442\n",
      "Epoch 9134 / 10000 loss: 12.061518430709839\n",
      "MSE train 4.967247412759536 MSE test 11.385317330788903\n",
      "MAE train 1.5286827104728133 MAE test 2.359234998351971\n",
      "Epoch 9135 / 10000 loss: 12.061177730560303\n",
      "MSE train 4.96714175030587 MSE test 11.385036280580524\n",
      "MAE train 1.5286679710021565 MAE test 2.359198372390668\n",
      "Epoch 9136 / 10000 loss: 12.060781478881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.967028984195552 MSE test 11.385061534554643\n",
      "MAE train 1.5286440281944302 MAE test 2.3592069976378616\n",
      "Epoch 9137 / 10000 loss: 12.0604829788208\n",
      "MSE train 4.966922988764062 MSE test 11.384857787568395\n",
      "MAE train 1.5286276497367894 MAE test 2.359180587201684\n",
      "Epoch 9138 / 10000 loss: 12.059995174407959\n",
      "MSE train 4.9668258645195715 MSE test 11.384824832914633\n",
      "MAE train 1.5286091062483325 MAE test 2.359181425633232\n",
      "Epoch 9139 / 10000 loss: 12.05963659286499\n",
      "MSE train 4.966720263860431 MSE test 11.384576572045546\n",
      "MAE train 1.5285937679565036 MAE test 2.359149143440639\n",
      "Epoch 9140 / 10000 loss: 12.059251308441162\n",
      "MSE train 4.966621139371825 MSE test 11.384591122881565\n",
      "MAE train 1.528573663013703 MAE test 2.3591563038890215\n",
      "Epoch 9141 / 10000 loss: 12.058926343917847\n",
      "MSE train 4.96651502195255 MSE test 11.384324395035785\n",
      "MAE train 1.528558534552024 MAE test 2.359121570183714\n",
      "Epoch 9142 / 10000 loss: 12.058502435684204\n",
      "MSE train 4.96640895610764 MSE test 11.384345314598395\n",
      "MAE train 1.528536488968249 MAE test 2.359129587486533\n",
      "Epoch 9143 / 10000 loss: 12.058191061019897\n",
      "MSE train 4.966301848087347 MSE test 11.384108528566598\n",
      "MAE train 1.5285205337162613 MAE test 2.359098836682662\n",
      "Epoch 9144 / 10000 loss: 12.057733297348022\n",
      "MSE train 4.966207225852728 MSE test 11.384111231004555\n",
      "MAE train 1.5285018255832468 MAE test 2.359104381551449\n",
      "Epoch 9145 / 10000 loss: 12.057394742965698\n",
      "MSE train 4.966101407878637 MSE test 11.383831392075425\n",
      "MAE train 1.5284870245710866 MAE test 2.3590679265375543\n",
      "Epoch 9146 / 10000 loss: 12.056994438171387\n",
      "MSE train 4.965989103779954 MSE test 11.383856181931522\n",
      "MAE train 1.5284632257000743 MAE test 2.3590764904252364\n",
      "Epoch 9147 / 10000 loss: 12.056694984436035\n",
      "MSE train 4.965882882841469 MSE test 11.383649544321187\n",
      "MAE train 1.5284468435902425 MAE test 2.359049702223249\n",
      "Epoch 9148 / 10000 loss: 12.0562105178833\n",
      "MSE train 4.965786440899678 MSE test 11.383620208803938\n",
      "MAE train 1.528428411438183 MAE test 2.359051034507287\n",
      "Epoch 9149 / 10000 loss: 12.05585265159607\n",
      "MSE train 4.965680858456648 MSE test 11.383366043444903\n",
      "MAE train 1.528413176636446 MAE test 2.3590179754741025\n",
      "Epoch 9150 / 10000 loss: 12.055469036102295\n",
      "MSE train 4.965579390477173 MSE test 11.383383386048061\n",
      "MAE train 1.5283924275390341 MAE test 2.3590255120487127\n",
      "Epoch 9151 / 10000 loss: 12.055148839950562\n",
      "MSE train 4.965472846130286 MSE test 11.383125261480124\n",
      "MAE train 1.5283770201425122 MAE test 2.3589919341222494\n",
      "Epoch 9152 / 10000 loss: 12.054712295532227\n",
      "MSE train 4.965370844468503 MSE test 11.383142124850238\n",
      "MAE train 1.528356125537786 MAE test 2.358999413685967\n",
      "Epoch 9153 / 10000 loss: 12.054392576217651\n",
      "MSE train 4.96526397496993 MSE test 11.382887091249493\n",
      "MAE train 1.528340580904629 MAE test 2.3589662427794935\n",
      "Epoch 9154 / 10000 loss: 12.053954124450684\n",
      "MSE train 4.96516358937768 MSE test 11.382901967492527\n",
      "MAE train 1.5283201415766825 MAE test 2.358973446291754\n",
      "Epoch 9155 / 10000 loss: 12.053630590438843\n",
      "MSE train 4.965056812517392 MSE test 11.382640798900217\n",
      "MAE train 1.528304733259051 MAE test 2.3589394590191097\n",
      "Epoch 9156 / 10000 loss: 12.05319881439209\n",
      "MSE train 4.964953611928434 MSE test 11.382658468019356\n",
      "MAE train 1.5282835224470284 MAE test 2.3589470521661413\n",
      "Epoch 9157 / 10000 loss: 12.05288052558899\n",
      "MSE train 4.9648465182561585 MSE test 11.382408119949048\n",
      "MAE train 1.5282678313296563 MAE test 2.3589145106775637\n",
      "Epoch 9158 / 10000 loss: 12.05243706703186\n",
      "MSE train 4.964747953403577 MSE test 11.382419859858295\n",
      "MAE train 1.5282479227840813 MAE test 2.3589212910111863\n",
      "Epoch 9159 / 10000 loss: 12.052108764648438\n",
      "MSE train 4.964641338211241 MSE test 11.382151493400082\n",
      "MAE train 1.528232700588393 MAE test 2.3588863487346767\n",
      "Epoch 9160 / 10000 loss: 12.051687002182007\n",
      "MSE train 4.964534692641257 MSE test 11.38217204995261\n",
      "MAE train 1.5282105235367807 MAE test 2.3588943448502104\n",
      "Epoch 9161 / 10000 loss: 12.0513756275177\n",
      "MSE train 4.964427295009758 MSE test 11.381936606955048\n",
      "MAE train 1.5281944614466036 MAE test 2.3588637679741256\n",
      "Epoch 9162 / 10000 loss: 12.050915718078613\n",
      "MSE train 4.964332779477053 MSE test 11.381937310693052\n",
      "MAE train 1.528175839318217 MAE test 2.358869079708673\n",
      "Epoch 9163 / 10000 loss: 12.050575494766235\n",
      "MSE train 4.964226632958828 MSE test 11.381656487130932\n",
      "MAE train 1.5281609915559884 MAE test 2.3588324888905463\n",
      "Epoch 9164 / 10000 loss: 12.050177097320557\n",
      "MSE train 4.96411376529671 MSE test 11.381680936156087\n",
      "MAE train 1.5281370599767248 MAE test 2.358841025960542\n",
      "Epoch 9165 / 10000 loss: 12.049877643585205\n",
      "MSE train 4.96400727242714 MSE test 11.381475517740338\n",
      "MAE train 1.528120600217903 MAE test 2.3588144249410643\n",
      "Epoch 9166 / 10000 loss: 12.049391031265259\n",
      "MSE train 4.963910111249345 MSE test 11.381443526108695\n",
      "MAE train 1.528102045481127 MAE test 2.3588154225866913\n",
      "Epoch 9167 / 10000 loss: 12.049031972885132\n",
      "MSE train 4.963804055687235 MSE test 11.38119224510289\n",
      "MAE train 1.5280866619734788 MAE test 2.3587827546107945\n",
      "Epoch 9168 / 10000 loss: 12.048647165298462\n",
      "MSE train 4.963703414748063 MSE test 11.381207232742469\n",
      "MAE train 1.5280661858261273 MAE test 2.3587900042922256\n",
      "Epoch 9169 / 10000 loss: 12.048323631286621\n",
      "MSE train 4.963596564714103 MSE test 11.380943729794874\n",
      "MAE train 1.5280508203975884 MAE test 2.3587557292019317\n",
      "Epoch 9170 / 10000 loss: 12.047892808914185\n",
      "MSE train 4.963491751234209 MSE test 11.380962294923238\n",
      "MAE train 1.5280291864748048 MAE test 2.3587634618017104\n",
      "Epoch 9171 / 10000 loss: 12.047576427459717\n",
      "MSE train 4.963384049333881 MSE test 11.380716342684176\n",
      "MAE train 1.5280132872147454 MAE test 2.3587315112793226\n",
      "Epoch 9172 / 10000 loss: 12.047125816345215\n",
      "MSE train 4.963286613372681 MSE test 11.380724456252702\n",
      "MAE train 1.527993765519964 MAE test 2.3587378452728105\n",
      "Epoch 9173 / 10000 loss: 12.046792268753052\n",
      "MSE train 4.963179576425589 MSE test 11.380449510723576\n",
      "MAE train 1.5279785873063683 MAE test 2.358702048215364\n",
      "Epoch 9174 / 10000 loss: 12.046377897262573\n",
      "MSE train 4.9630693598987925 MSE test 11.380471341951916\n",
      "MAE train 1.5279554699797204 MAE test 2.358710255427784\n",
      "Epoch 9175 / 10000 loss: 12.046069860458374\n",
      "MSE train 4.962961310854447 MSE test 11.380248767997813\n",
      "MAE train 1.5279389950450233 MAE test 2.358681408251742\n",
      "Epoch 9176 / 10000 loss: 12.045595407485962\n",
      "MSE train 4.962866519014366 MSE test 11.380235719143235\n",
      "MAE train 1.527920659822212 MAE test 2.3586849355561457\n",
      "Epoch 9177 / 10000 loss: 12.045243263244629\n",
      "MSE train 4.96275970403395 MSE test 11.379958288859523\n",
      "MAE train 1.5279056080560132 MAE test 2.358648829066078\n",
      "Epoch 9178 / 10000 loss: 12.044854164123535\n",
      "MSE train 4.9626472441252405 MSE test 11.37998105632879\n",
      "MAE train 1.527881886312874 MAE test 2.3586571933028146\n",
      "Epoch 9179 / 10000 loss: 12.044548511505127\n",
      "MSE train 4.962538893152106 MSE test 11.379766198066733\n",
      "MAE train 1.5278651985959741 MAE test 2.358629383034286\n",
      "Epoch 9180 / 10000 loss: 12.044065237045288\n",
      "MSE train 4.962442326702004 MSE test 11.379743750786595\n",
      "MAE train 1.5278466518050318 MAE test 2.3586317107346857\n",
      "Epoch 9181 / 10000 loss: 12.043705940246582\n",
      "MSE train 4.9623346317224835 MSE test 11.379475029482546\n",
      "MAE train 1.5278312331834687 MAE test 2.35859678053165\n",
      "Epoch 9182 / 10000 loss: 12.043317079544067\n",
      "MSE train 4.962225057893587 MSE test 11.379494711915628\n",
      "MAE train 1.5278084095885782 MAE test 2.3586047461410953\n",
      "Epoch 9183 / 10000 loss: 12.042999744415283\n",
      "MSE train 4.962114950155988 MSE test 11.379258815916337\n",
      "MAE train 1.5277917632188094 MAE test 2.3585742101038782\n",
      "Epoch 9184 / 10000 loss: 12.042529344558716\n",
      "MSE train 4.962017192783857 MSE test 11.37925622772301\n",
      "MAE train 1.5277725061671836 MAE test 2.3585791890524983\n",
      "Epoch 9185 / 10000 loss: 12.042179346084595\n",
      "MSE train 4.961906973987042 MSE test 11.378972221719826\n",
      "MAE train 1.5277568031346207 MAE test 2.3585422827901654\n",
      "Epoch 9186 / 10000 loss: 12.041770219802856\n",
      "MSE train 4.961788784583966 MSE test 11.378993352111907\n",
      "MAE train 1.5277317296713016 MAE test 2.3585505411335097\n",
      "Epoch 9187 / 10000 loss: 12.0414559841156\n",
      "MSE train 4.961675810610713 MSE test 11.378784927733452\n",
      "MAE train 1.5277138580913203 MAE test 2.3585236911361593\n",
      "Epoch 9188 / 10000 loss: 12.040950298309326\n",
      "MSE train 4.96156988057432 MSE test 11.378746938828046\n",
      "MAE train 1.5276934246215215 MAE test 2.3585240859483614\n",
      "Epoch 9189 / 10000 loss: 12.040566205978394\n",
      "MSE train 4.961452412719115 MSE test 11.378491870258761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5276754996670832 MAE test 2.3584911620865308\n",
      "Epoch 9190 / 10000 loss: 12.040147542953491\n",
      "MSE train 4.961336738916902 MSE test 11.378498598043626\n",
      "MAE train 1.527651745724067 MAE test 2.358497597953131\n",
      "Epoch 9191 / 10000 loss: 12.039777040481567\n",
      "MSE train 4.961207092054792 MSE test 11.378223480385255\n",
      "MAE train 1.5276312799872984 MAE test 2.3584621442867304\n",
      "Epoch 9192 / 10000 loss: 12.03928518295288\n",
      "MSE train 4.961066057524778 MSE test 11.378231161976752\n",
      "MAE train 1.5276012278392317 MAE test 2.358468923999264\n",
      "Epoch 9193 / 10000 loss: 12.0388765335083\n",
      "MSE train 4.960903498268802 MSE test 11.377975567473053\n",
      "MAE train 1.5275724002918214 MAE test 2.3584363257748677\n",
      "Epoch 9194 / 10000 loss: 12.0382719039917\n",
      "MSE train 4.960723734040489 MSE test 11.377957684111143\n",
      "MAE train 1.5275332150683942 MAE test 2.3584400499095213\n",
      "Epoch 9195 / 10000 loss: 12.037696361541748\n",
      "MSE train 4.960514499402755 MSE test 11.37765145327026\n",
      "MAE train 1.5274933041533794 MAE test 2.358401138809592\n",
      "Epoch 9196 / 10000 loss: 12.03692078590393\n",
      "MSE train 4.960332565975242 MSE test 11.377649438668143\n",
      "MAE train 1.52745231863678 MAE test 2.3584070913087314\n",
      "Epoch 9197 / 10000 loss: 12.03615689277649\n",
      "MSE train 4.9602032576483825 MSE test 11.37742491812145\n",
      "MAE train 1.5274296433987626 MAE test 2.358378332962276\n",
      "Epoch 9198 / 10000 loss: 12.035354614257812\n",
      "MSE train 4.960101894973143 MSE test 11.377392803325614\n",
      "MAE train 1.527409304702345 MAE test 2.358379366649386\n",
      "Epoch 9199 / 10000 loss: 12.034890174865723\n",
      "MSE train 4.9599947150377 MSE test 11.377129579852324\n",
      "MAE train 1.5273933358571965 MAE test 2.358345034925389\n",
      "Epoch 9200 / 10000 loss: 12.034476518630981\n",
      "MSE train 4.959890217873525 MSE test 11.377147539521339\n",
      "MAE train 1.5273714259817188 MAE test 2.3583525820240796\n",
      "Epoch 9201 / 10000 loss: 12.034149408340454\n",
      "MSE train 4.959783435183516 MSE test 11.376900260808455\n",
      "MAE train 1.5273554489781282 MAE test 2.3583203398909793\n",
      "Epoch 9202 / 10000 loss: 12.033695697784424\n",
      "MSE train 4.959686408153417 MSE test 11.376910118694177\n",
      "MAE train 1.5273357615767056 MAE test 2.358326769640332\n",
      "Epoch 9203 / 10000 loss: 12.033363580703735\n",
      "MSE train 4.95958055022898 MSE test 11.376638214403988\n",
      "MAE train 1.5273205561223064 MAE test 2.358291251036042\n",
      "Epoch 9204 / 10000 loss: 12.032946586608887\n",
      "MSE train 4.9594727696242495 MSE test 11.376660292414734\n",
      "MAE train 1.5272978862684217 MAE test 2.358299387859502\n",
      "Epoch 9205 / 10000 loss: 12.032638311386108\n",
      "MSE train 4.959366085984211 MSE test 11.37643422354584\n",
      "MAE train 1.5272816114849568 MAE test 2.358269957794454\n",
      "Epoch 9206 / 10000 loss: 12.032170534133911\n",
      "MSE train 4.959273173393428 MSE test 11.376427629680807\n",
      "MAE train 1.5272634648936403 MAE test 2.358274238576487\n",
      "Epoch 9207 / 10000 loss: 12.031823873519897\n",
      "MSE train 4.959168018845705 MSE test 11.376148487373795\n",
      "MAE train 1.5272486541512849 MAE test 2.358237787350889\n",
      "Epoch 9208 / 10000 loss: 12.031436204910278\n",
      "MSE train 4.959056199164698 MSE test 11.376173716974272\n",
      "MAE train 1.527224893373066 MAE test 2.3582463955105077\n",
      "Epoch 9209 / 10000 loss: 12.031136989593506\n",
      "MSE train 4.958950426902725 MSE test 11.375967854102452\n",
      "MAE train 1.5272084828789316 MAE test 2.35821964690313\n",
      "Epoch 9210 / 10000 loss: 12.030653476715088\n",
      "MSE train 4.958854648357913 MSE test 11.375938679715734\n",
      "MAE train 1.5271901312296698 MAE test 2.358220973442848\n",
      "Epoch 9211 / 10000 loss: 12.030297040939331\n",
      "MSE train 4.9587494816598445 MSE test 11.375685249992769\n",
      "MAE train 1.5271748657687032 MAE test 2.3581879591808446\n",
      "Epoch 9212 / 10000 loss: 12.029914617538452\n",
      "MSE train 4.958648665853236 MSE test 11.37570270870143\n",
      "MAE train 1.527154214505969 MAE test 2.3581955012508375\n",
      "Epoch 9213 / 10000 loss: 12.029595613479614\n",
      "MSE train 4.958542579564626 MSE test 11.375445490538704\n",
      "MAE train 1.527138788599077 MAE test 2.3581619888360734\n",
      "Epoch 9214 / 10000 loss: 12.02916145324707\n",
      "MSE train 4.958441191776697 MSE test 11.375462563533839\n",
      "MAE train 1.5271180004812874 MAE test 2.358169474043725\n",
      "Epoch 9215 / 10000 loss: 12.02884316444397\n",
      "MSE train 4.95833485109904 MSE test 11.375208386956263\n",
      "MAE train 1.527102457333543 MAE test 2.3581363687335597\n",
      "Epoch 9216 / 10000 loss: 12.028405904769897\n",
      "MSE train 4.9582350149772845 MSE test 11.375223515952833\n",
      "MAE train 1.527082102091853 MAE test 2.3581435889984412\n",
      "Epoch 9217 / 10000 loss: 12.02808403968811\n",
      "MSE train 4.958128759721124 MSE test 11.37496327355669\n",
      "MAE train 1.5270667032974474 MAE test 2.358109679827426\n",
      "Epoch 9218 / 10000 loss: 12.027654886245728\n",
      "MSE train 4.958026394991382 MSE test 11.374981362227093\n",
      "MAE train 1.5270456404805177 MAE test 2.3581173030424307\n",
      "Epoch 9219 / 10000 loss: 12.027338027954102\n",
      "MSE train 4.957919831329382 MSE test 11.374731545546437\n",
      "MAE train 1.5270299765972257 MAE test 2.3580847870138797\n",
      "Epoch 9220 / 10000 loss: 12.026896715164185\n",
      "MSE train 4.957821841838509 MSE test 11.374744000520948\n",
      "MAE train 1.5270101545204184 MAE test 2.3580916511762493\n",
      "Epoch 9221 / 10000 loss: 12.026570558547974\n",
      "MSE train 4.957715833709803 MSE test 11.3744769470948\n",
      "MAE train 1.526994954993529 MAE test 2.3580568431807256\n",
      "Epoch 9222 / 10000 loss: 12.026150941848755\n",
      "MSE train 4.957610132179339 MSE test 11.374497786775345\n",
      "MAE train 1.5269729634009814 MAE test 2.3580648498648085\n",
      "Epoch 9223 / 10000 loss: 12.025840044021606\n",
      "MSE train 4.957503368743144 MSE test 11.374262428159533\n",
      "MAE train 1.526956969032863 MAE test 2.3580342398865026\n",
      "Epoch 9224 / 10000 loss: 12.025384664535522\n",
      "MSE train 4.957409477383069 MSE test 11.374264654500074\n",
      "MAE train 1.526938423503375 MAE test 2.358039735998965\n",
      "Epoch 9225 / 10000 loss: 12.025047063827515\n",
      "MSE train 4.957304060457793 MSE test 11.373985103553954\n",
      "MAE train 1.5269236205908197 MAE test 2.3580032542743425\n",
      "Epoch 9226 / 10000 loss: 12.024649858474731\n",
      "MSE train 4.957192255673759 MSE test 11.374010111354277\n",
      "MAE train 1.5268999059242048 MAE test 2.3580118514696498\n",
      "Epoch 9227 / 10000 loss: 12.02435302734375\n",
      "MSE train 4.9570864315133125 MSE test 11.373804559445015\n",
      "MAE train 1.5268835299276342 MAE test 2.3579851757146844\n",
      "Epoch 9228 / 10000 loss: 12.023870468139648\n",
      "MSE train 4.95699048791326 MSE test 11.373774991744677\n",
      "MAE train 1.52686517902071 MAE test 2.3579864688728476\n",
      "Epoch 9229 / 10000 loss: 12.023515224456787\n",
      "MSE train 4.956885378996798 MSE test 11.373522353628708\n",
      "MAE train 1.526849945579192 MAE test 2.3579535617582894\n",
      "Epoch 9230 / 10000 loss: 12.023132801055908\n",
      "MSE train 4.956784726756477 MSE test 11.373539475927906\n",
      "MAE train 1.5268293676287588 MAE test 2.357961063727874\n",
      "Epoch 9231 / 10000 loss: 12.022814750671387\n",
      "MSE train 4.956678706762953 MSE test 11.373281222366689\n",
      "MAE train 1.526814008200995 MAE test 2.357927409192919\n",
      "Epoch 9232 / 10000 loss: 12.022382259368896\n",
      "MSE train 4.956576836542823 MSE test 11.373298834570235\n",
      "MAE train 1.5267930922518562 MAE test 2.357934973142658\n",
      "Epoch 9233 / 10000 loss: 12.022066354751587\n",
      "MSE train 4.956470467218135 MSE test 11.373046584614167\n",
      "MAE train 1.5267775230018221 MAE test 2.357902130278921\n",
      "Epoch 9234 / 10000 loss: 12.021626710891724\n",
      "MSE train 4.956371425380936 MSE test 11.373060596487248\n",
      "MAE train 1.5267574071863665 MAE test 2.357909194924446\n",
      "Epoch 9235 / 10000 loss: 12.021305322647095\n",
      "MSE train 4.956265264243366 MSE test 11.372797251770104\n",
      "MAE train 1.5267421100240979 MAE test 2.3578748824286353\n",
      "Epoch 9236 / 10000 loss: 12.020880222320557\n",
      "MSE train 4.9561613854505815 MSE test 11.372816572916081\n",
      "MAE train 1.5267206278386747 MAE test 2.357882679843298\n",
      "Epoch 9237 / 10000 loss: 12.020567893981934\n",
      "MSE train 4.956054707007417 MSE test 11.37257321677633\n",
      "MAE train 1.5267048298818087 MAE test 2.357851011183301\n",
      "Epoch 9238 / 10000 loss: 12.020119667053223\n",
      "MSE train 4.955958920070472 MSE test 11.37258136246812\n",
      "MAE train 1.5266856582683663 MAE test 2.357857300110485\n",
      "Epoch 9239 / 10000 loss: 12.019789218902588\n",
      "MSE train 4.955853189646744 MSE test 11.372307025633562\n",
      "MAE train 1.5266706833197718 MAE test 2.3578215081046525\n",
      "Epoch 9240 / 10000 loss: 12.019380569458008\n",
      "MSE train 4.955743929958276 MSE test 11.372330287591993\n",
      "MAE train 1.526647688043294 MAE test 2.3578298526160557\n",
      "Epoch 9241 / 10000 loss: 12.019078731536865\n",
      "MSE train 4.9556374023756025 MSE test 11.37211196598112\n",
      "MAE train 1.5266313979888269 MAE test 2.3578014991939487\n",
      "Epoch 9242 / 10000 loss: 12.018607378005981\n",
      "MSE train 4.955544117357558 MSE test 11.372097696746074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.526613385698281 MAE test 2.3578047907559796\n",
      "Epoch 9243 / 10000 loss: 12.018259286880493\n",
      "MSE train 4.955439089435352 MSE test 11.371824776811339\n",
      "MAE train 1.52659856371241 MAE test 2.3577691919053203\n",
      "Epoch 9244 / 10000 loss: 12.017877340316772\n",
      "MSE train 4.955329680238936 MSE test 11.37184863135874\n",
      "MAE train 1.5265755229701106 MAE test 2.3577776252053058\n",
      "Epoch 9245 / 10000 loss: 12.017575979232788\n",
      "MSE train 4.95522327153393 MSE test 11.371630385090125\n",
      "MAE train 1.5265592610876848 MAE test 2.357749268109164\n",
      "Epoch 9246 / 10000 loss: 12.017103910446167\n",
      "MSE train 4.955129955109001 MSE test 11.371616535178282\n",
      "MAE train 1.5265412391467348 MAE test 2.3577526177944184\n",
      "Epoch 9247 / 10000 loss: 12.016755819320679\n",
      "MSE train 4.955024973451373 MSE test 11.371343458032841\n",
      "MAE train 1.526526434521098 MAE test 2.3577169880150395\n",
      "Epoch 9248 / 10000 loss: 12.016374111175537\n",
      "MSE train 4.954915434284315 MSE test 11.37136739956398\n",
      "MAE train 1.5265033508321126 MAE test 2.357725427582365\n",
      "Epoch 9249 / 10000 loss: 12.016072988510132\n",
      "MSE train 4.954809062649398 MSE test 11.371149805177415\n",
      "MAE train 1.5264870824346337 MAE test 2.357697159751907\n",
      "Epoch 9250 / 10000 loss: 12.015600681304932\n",
      "MSE train 4.954715674185814 MSE test 11.371135168797368\n",
      "MAE train 1.5264690566818189 MAE test 2.357700408821748\n",
      "Epoch 9251 / 10000 loss: 12.015252351760864\n",
      "MSE train 4.9546107098088426 MSE test 11.37086275800938\n",
      "MAE train 1.526454235732267 MAE test 2.357664863898418\n",
      "Epoch 9252 / 10000 loss: 12.014870643615723\n",
      "MSE train 4.954501500672869 MSE test 11.370886593104359\n",
      "MAE train 1.5264312516200016 MAE test 2.3576732947404717\n",
      "Epoch 9253 / 10000 loss: 12.014569520950317\n",
      "MSE train 4.95439509262156 MSE test 11.370667334429713\n",
      "MAE train 1.526415005526361 MAE test 2.3576447957852964\n",
      "Epoch 9254 / 10000 loss: 12.014098405838013\n",
      "MSE train 4.954301912595461 MSE test 11.370654507738628\n",
      "MAE train 1.5263969880644823 MAE test 2.3576482853072966\n",
      "Epoch 9255 / 10000 loss: 12.01375126838684\n",
      "MSE train 4.95419693174695 MSE test 11.370380478168562\n",
      "MAE train 1.526382198472194 MAE test 2.3576125331195765\n",
      "Epoch 9256 / 10000 loss: 12.0133695602417\n",
      "MSE train 4.954086980782248 MSE test 11.370404611747537\n",
      "MAE train 1.5263589912939688 MAE test 2.3576209867240276\n",
      "Epoch 9257 / 10000 loss: 12.013068914413452\n",
      "MSE train 4.953980693061897 MSE test 11.370189194981144\n",
      "MAE train 1.5263426928295878 MAE test 2.3575930042745594\n",
      "Epoch 9258 / 10000 loss: 12.012595891952515\n",
      "MSE train 4.953887057966784 MSE test 11.370172139709672\n",
      "MAE train 1.526324658516913 MAE test 2.3575959358791754\n",
      "Epoch 9259 / 10000 loss: 12.012245655059814\n",
      "MSE train 4.953782071134505 MSE test 11.369902436261167\n",
      "MAE train 1.5263097774858343 MAE test 2.3575607552711633\n",
      "Epoch 9260 / 10000 loss: 12.011865377426147\n",
      "MSE train 4.953674124146912 MSE test 11.369925603844733\n",
      "MAE train 1.5262871358660557 MAE test 2.35756908241616\n",
      "Epoch 9261 / 10000 loss: 12.011561393737793\n",
      "MSE train 4.953567572352368 MSE test 11.369700221165019\n",
      "MAE train 1.5262709758198618 MAE test 2.357539782347825\n",
      "Epoch 9262 / 10000 loss: 12.011096239089966\n",
      "MSE train 4.953474653621593 MSE test 11.369693803643258\n",
      "MAE train 1.5262528906448074 MAE test 2.357544112508948\n",
      "Epoch 9263 / 10000 loss: 12.010753631591797\n",
      "MSE train 4.9533695773884885 MSE test 11.369415253970129\n",
      "MAE train 1.5262381530619742 MAE test 2.3575077484374227\n",
      "Epoch 9264 / 10000 loss: 12.010367393493652\n",
      "MSE train 4.9532578498258255 MSE test 11.36944023534181\n",
      "MAE train 1.526214443689065 MAE test 2.357516331834962\n",
      "Epoch 9265 / 10000 loss: 12.010071277618408\n",
      "MSE train 4.953152090701884 MSE test 11.36923437901234\n",
      "MAE train 1.5261980762691572 MAE test 2.3574895999615415\n",
      "Epoch 9266 / 10000 loss: 12.009590148925781\n",
      "MSE train 4.953056324475105 MSE test 11.369205142106406\n",
      "MAE train 1.5261797569950624 MAE test 2.3574909046582717\n",
      "Epoch 9267 / 10000 loss: 12.009235620498657\n",
      "MSE train 4.95295121622453 MSE test 11.368951875257883\n",
      "MAE train 1.526164531801193 MAE test 2.3574579191753777\n",
      "Epoch 9268 / 10000 loss: 12.008854150772095\n",
      "MSE train 4.9528504349548665 MSE test 11.368968938721858\n",
      "MAE train 1.5261439013412297 MAE test 2.3574653884000103\n",
      "Epoch 9269 / 10000 loss: 12.008537769317627\n",
      "MSE train 4.952744431660426 MSE test 11.368711989639912\n",
      "MAE train 1.5261285028165785 MAE test 2.3574319036392626\n",
      "Epoch 9270 / 10000 loss: 12.008105278015137\n",
      "MSE train 4.952643178182574 MSE test 11.368728787546875\n",
      "MAE train 1.5261077514844008 MAE test 2.3574393482104905\n",
      "Epoch 9271 / 10000 loss: 12.007788896560669\n",
      "MSE train 4.952536903975538 MSE test 11.368474431231332\n",
      "MAE train 1.526092234511455 MAE test 2.35740620791266\n",
      "Epoch 9272 / 10000 loss: 12.00735354423523\n",
      "MSE train 4.952437060926702 MSE test 11.368489296806091\n",
      "MAE train 1.5260718765453887 MAE test 2.3574133822002485\n",
      "Epoch 9273 / 10000 loss: 12.007034301757812\n",
      "MSE train 4.952330880980578 MSE test 11.36822987166242\n",
      "MAE train 1.5260564756305903 MAE test 2.3573795712452164\n",
      "Epoch 9274 / 10000 loss: 12.006605625152588\n",
      "MSE train 4.952228789144272 MSE test 11.368247371781715\n",
      "MAE train 1.5260354797822184 MAE test 2.357387099866577\n",
      "Epoch 9275 / 10000 loss: 12.006290674209595\n",
      "MSE train 4.952122333885562 MSE test 11.367996952969774\n",
      "MAE train 1.5260198463807457 MAE test 2.357354477646995\n",
      "Epoch 9276 / 10000 loss: 12.00585150718689\n",
      "MSE train 4.9520241668651 MSE test 11.3680094275207\n",
      "MAE train 1.5259999588012267 MAE test 2.357361320884481\n",
      "Epoch 9277 / 10000 loss: 12.005527973175049\n",
      "MSE train 4.951918148106121 MSE test 11.367743577207758\n",
      "MAE train 1.5259847221760607 MAE test 2.35732665574757\n",
      "Epoch 9278 / 10000 loss: 12.005107879638672\n",
      "MSE train 4.951813126265829 MSE test 11.367763739492476\n",
      "MAE train 1.5259628968575123 MAE test 2.357334547014273\n",
      "Epoch 9279 / 10000 loss: 12.00479793548584\n",
      "MSE train 4.951706465177633 MSE test 11.367526087941224\n",
      "MAE train 1.5259469603210625 MAE test 2.357303626794583\n",
      "Epoch 9280 / 10000 loss: 12.0043466091156\n",
      "MSE train 4.95161217950368 MSE test 11.36752971056107\n",
      "MAE train 1.5259282574313475 MAE test 2.357309279213503\n",
      "Epoch 9281 / 10000 loss: 12.004011392593384\n",
      "MSE train 4.951506749207723 MSE test 11.367251574390085\n",
      "MAE train 1.5259134042838585 MAE test 2.3572729700340966\n",
      "Epoch 9282 / 10000 loss: 12.003613471984863\n",
      "MSE train 4.951395684734067 MSE test 11.36727596304445\n",
      "MAE train 1.5258898653708062 MAE test 2.3572814582537407\n",
      "Epoch 9283 / 10000 loss: 12.003316640853882\n",
      "MSE train 4.9512897338761634 MSE test 11.367067386104019\n",
      "MAE train 1.5258734921800703 MAE test 2.357254363719221\n",
      "Epoch 9284 / 10000 loss: 12.002838134765625\n",
      "MSE train 4.951194696031618 MSE test 11.367041430143606\n",
      "MAE train 1.5258552780575423 MAE test 2.3572561076642056\n",
      "Epoch 9285 / 10000 loss: 12.002485513687134\n",
      "MSE train 4.951089688719193 MSE test 11.366783213740536\n",
      "MAE train 1.5258401459599271 MAE test 2.3572224387424923\n",
      "Epoch 9286 / 10000 loss: 12.00210452079773\n",
      "MSE train 4.950986779764748 MSE test 11.366802310084328\n",
      "MAE train 1.5258188979507372 MAE test 2.357230183827542\n",
      "Epoch 9287 / 10000 loss: 12.00179147720337\n",
      "MSE train 4.950880493034427 MSE test 11.366554452500223\n",
      "MAE train 1.5258032620432287 MAE test 2.357197906085951\n",
      "Epoch 9288 / 10000 loss: 12.001349449157715\n",
      "MSE train 4.950783005561353 MSE test 11.366566065759653\n",
      "MAE train 1.525783554308323 MAE test 2.3572046213041906\n",
      "Epoch 9289 / 10000 loss: 12.001025199890137\n",
      "MSE train 4.950677209123533 MSE test 11.366297884008025\n",
      "MAE train 1.5257683997854223 MAE test 2.3571696486561717\n",
      "Epoch 9290 / 10000 loss: 12.000608682632446\n",
      "MSE train 4.950570915931496 MSE test 11.366319055176076\n",
      "MAE train 1.525746207550043 MAE test 2.357177676019343\n",
      "Epoch 9291 / 10000 loss: 12.000301599502563\n",
      "MSE train 4.95046424132941 MSE test 11.366087118306007\n",
      "MAE train 1.525730123492154 MAE test 2.3571475067366587\n",
      "Epoch 9292 / 10000 loss: 11.999843835830688\n",
      "MSE train 4.950370963125076 MSE test 11.366086154521218\n",
      "MAE train 1.5257117801717226 MAE test 2.357152536259364\n",
      "Epoch 9293 / 10000 loss: 11.999505519866943\n",
      "MSE train 4.950265665096506 MSE test 11.365806594232998\n",
      "MAE train 1.5256969847829398 MAE test 2.35711602696523\n",
      "Epoch 9294 / 10000 loss: 11.999114513397217\n",
      "MSE train 4.950153715921694 MSE test 11.365831495568186\n",
      "MAE train 1.5256731739803355 MAE test 2.3571245980078905\n",
      "Epoch 9295 / 10000 loss: 11.998819351196289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.950048092666602 MSE test 11.365627401891757\n",
      "MAE train 1.525656780646952 MAE test 2.3570980786871973\n",
      "Epoch 9296 / 10000 loss: 11.998336791992188\n",
      "MSE train 4.94995190582734 MSE test 11.36559559981208\n",
      "MAE train 1.5256383565096434 MAE test 2.3570990461104273\n",
      "Epoch 9297 / 10000 loss: 11.997982263565063\n",
      "MSE train 4.949846731428484 MSE test 11.365346320836661\n",
      "MAE train 1.5256230181724728 MAE test 2.3570665637114647\n",
      "Epoch 9298 / 10000 loss: 11.997600793838501\n",
      "MSE train 4.949747534853631 MSE test 11.365361492095342\n",
      "MAE train 1.5256027925326312 MAE test 2.3570737602469896\n",
      "Epoch 9299 / 10000 loss: 11.997280597686768\n",
      "MSE train 4.949641713953834 MSE test 11.36509846653768\n",
      "MAE train 1.525587527708788 MAE test 2.357039464058722\n",
      "Epoch 9300 / 10000 loss: 11.996856689453125\n",
      "MSE train 4.949537629028091 MSE test 11.365118111077377\n",
      "MAE train 1.5255659324220685 MAE test 2.357047279563231\n",
      "Epoch 9301 / 10000 loss: 11.996545553207397\n",
      "MSE train 4.949431046499718 MSE test 11.364875961491325\n",
      "MAE train 1.5255500742996948 MAE test 2.3570157416456774\n",
      "Epoch 9302 / 10000 loss: 11.996097564697266\n",
      "MSE train 4.9493355316044605 MSE test 11.364883251856751\n",
      "MAE train 1.5255309424519914 MAE test 2.3570218726358196\n",
      "Epoch 9303 / 10000 loss: 11.99576735496521\n",
      "MSE train 4.949229889217744 MSE test 11.364608563676803\n",
      "MAE train 1.5255159329980676 MAE test 2.356986009332673\n",
      "Epoch 9304 / 10000 loss: 11.995361328125\n",
      "MSE train 4.949120298641907 MSE test 11.364631885165712\n",
      "MAE train 1.5254927801131184 MAE test 2.356994342025122\n",
      "Epoch 9305 / 10000 loss: 11.995060443878174\n",
      "MSE train 4.949013864212444 MSE test 11.364415152548858\n",
      "MAE train 1.5254764063044093 MAE test 2.3569661595642684\n",
      "Epoch 9306 / 10000 loss: 11.994588851928711\n",
      "MSE train 4.948920335278137 MSE test 11.364398940350569\n",
      "MAE train 1.5254583157705213 MAE test 2.3569691733524403\n",
      "Epoch 9307 / 10000 loss: 11.994239807128906\n",
      "MSE train 4.948815226719964 MSE test 11.364128308227913\n",
      "MAE train 1.5254433498840203 MAE test 2.356933837435034\n",
      "Epoch 9308 / 10000 loss: 11.993859052658081\n",
      "MSE train 4.948706709742381 MSE test 11.364151421108092\n",
      "MAE train 1.5254204834795664 MAE test 2.3569421412465914\n",
      "Epoch 9309 / 10000 loss: 11.993555545806885\n",
      "MSE train 4.948600078146351 MSE test 11.363928777732557\n",
      "MAE train 1.525404170187111 MAE test 2.356913180952031\n",
      "Epoch 9310 / 10000 loss: 11.993088722229004\n",
      "MSE train 4.948506963809996 MSE test 11.36391961419986\n",
      "MAE train 1.525386008088448 MAE test 2.3569171142407206\n",
      "Epoch 9311 / 10000 loss: 11.992742538452148\n",
      "MSE train 4.948401706535795 MSE test 11.363642919849509\n",
      "MAE train 1.5253711015876188 MAE test 2.356880974406811\n",
      "Epoch 9312 / 10000 loss: 11.992358207702637\n",
      "MSE train 4.948290389791022 MSE test 11.363667440338656\n",
      "MAE train 1.5253474089536883 MAE test 2.356889470390527\n",
      "Epoch 9313 / 10000 loss: 11.992059469223022\n",
      "MSE train 4.948184086935576 MSE test 11.363458415816448\n",
      "MAE train 1.5253308645496575 MAE test 2.3568622895260267\n",
      "Epoch 9314 / 10000 loss: 11.991580724716187\n",
      "MSE train 4.948088842161276 MSE test 11.363433506004064\n",
      "MAE train 1.525312473044701 MAE test 2.356864142307341\n",
      "Epoch 9315 / 10000 loss: 11.991226434707642\n",
      "MSE train 4.947983337799588 MSE test 11.36317404078492\n",
      "MAE train 1.5252971210245205 MAE test 2.3568302962952656\n",
      "Epoch 9316 / 10000 loss: 11.990844011306763\n",
      "MSE train 4.94787919836013 MSE test 11.363193789571525\n",
      "MAE train 1.525275419379084 MAE test 2.356838104999905\n",
      "Epoch 9317 / 10000 loss: 11.990530729293823\n",
      "MSE train 4.947772072130766 MSE test 11.362948572206951\n",
      "MAE train 1.525259362345298 MAE test 2.356806143406079\n",
      "Epoch 9318 / 10000 loss: 11.990083456039429\n",
      "MSE train 4.947674678398683 MSE test 11.36295848660893\n",
      "MAE train 1.525239534722438 MAE test 2.356812603762478\n",
      "Epoch 9319 / 10000 loss: 11.989753246307373\n",
      "MSE train 4.9475678194410735 MSE test 11.362687187366108\n",
      "MAE train 1.5252239689983493 MAE test 2.3567771691780752\n",
      "Epoch 9320 / 10000 loss: 11.989336967468262\n",
      "MSE train 4.947458630455198 MSE test 11.36270940975792\n",
      "MAE train 1.5252007383226691 MAE test 2.35678531744198\n",
      "Epoch 9321 / 10000 loss: 11.989027500152588\n",
      "MSE train 4.947350270384033 MSE test 11.362484854569045\n",
      "MAE train 1.5251837623680313 MAE test 2.356756069756236\n",
      "Epoch 9322 / 10000 loss: 11.98855710029602\n",
      "MSE train 4.947255140549303 MSE test 11.362476994094044\n",
      "MAE train 1.525164731572109 MAE test 2.356760144141999\n",
      "Epoch 9323 / 10000 loss: 11.988204956054688\n",
      "MSE train 4.947147036153387 MSE test 11.362199545326927\n",
      "MAE train 1.5251486809760013 MAE test 2.3567238535520985\n",
      "Epoch 9324 / 10000 loss: 11.987809896469116\n",
      "MSE train 4.947031688591775 MSE test 11.362223982359497\n",
      "MAE train 1.52512335659293 MAE test 2.356732297228511\n",
      "Epoch 9325 / 10000 loss: 11.987498998641968\n",
      "MSE train 4.9469200653932885 MSE test 11.362016570019945\n",
      "MAE train 1.525104561431119 MAE test 2.356705265129148\n",
      "Epoch 9326 / 10000 loss: 11.987000703811646\n",
      "MSE train 4.946816193159011 MSE test 11.361989604034294\n",
      "MAE train 1.5250827097834587 MAE test 2.356706782000893\n",
      "Epoch 9327 / 10000 loss: 11.9866201877594\n",
      "MSE train 4.94669712503337 MSE test 11.361733362409982\n",
      "MAE train 1.5250617052935551 MAE test 2.3566732662532703\n",
      "Epoch 9328 / 10000 loss: 11.986199855804443\n",
      "MSE train 4.946569922407464 MSE test 11.361751878489093\n",
      "MAE train 1.525030211865239 MAE test 2.356680761910742\n",
      "Epoch 9329 / 10000 loss: 11.985820531845093\n",
      "MSE train 4.946411497418128 MSE test 11.361501233546855\n",
      "MAE train 1.5249926271359435 MAE test 2.35664784768634\n",
      "Epoch 9330 / 10000 loss: 11.985267162322998\n",
      "MSE train 4.946183867082793 MSE test 11.361515923343664\n",
      "MAE train 1.5249167080251538 MAE test 2.3566545236240946\n",
      "Epoch 9331 / 10000 loss: 11.984704494476318\n",
      "MSE train 4.9458082020374805 MSE test 11.36125612653492\n",
      "MAE train 1.5247746913728635 MAE test 2.3566198249902093\n",
      "Epoch 9332 / 10000 loss: 11.983690023422241\n",
      "MSE train 4.945594598656448 MSE test 11.361281125968496\n",
      "MAE train 1.524695632769694 MAE test 2.356627634973189\n",
      "Epoch 9333 / 10000 loss: 11.982078790664673\n",
      "MSE train 4.945474311882937 MSE test 11.361040533751188\n",
      "MAE train 1.5246761695486875 MAE test 2.3565962407934795\n",
      "Epoch 9334 / 10000 loss: 11.981025218963623\n",
      "MSE train 4.945372414419598 MSE test 11.361046316004302\n",
      "MAE train 1.524655384299402 MAE test 2.3566021711666716\n",
      "Epoch 9335 / 10000 loss: 11.980629920959473\n",
      "MSE train 4.945263012457523 MSE test 11.360769932296677\n",
      "MAE train 1.5246393810712313 MAE test 2.3565660875623253\n",
      "Epoch 9336 / 10000 loss: 11.980194330215454\n",
      "MSE train 4.94515114778115 MSE test 11.36079141075773\n",
      "MAE train 1.5246156216333733 MAE test 2.3565742381243906\n",
      "Epoch 9337 / 10000 loss: 11.979875802993774\n",
      "MSE train 4.945043206635615 MSE test 11.360573810905132\n",
      "MAE train 1.5245988462972757 MAE test 2.3565460016276267\n",
      "Epoch 9338 / 10000 loss: 11.979392290115356\n",
      "MSE train 4.944948598134305 MSE test 11.360555932804893\n",
      "MAE train 1.524580493418919 MAE test 2.35654887865928\n",
      "Epoch 9339 / 10000 loss: 11.979034423828125\n",
      "MSE train 4.9448428022136985 MSE test 11.360285064248643\n",
      "MAE train 1.5245653431377917 MAE test 2.356513581217585\n",
      "Epoch 9340 / 10000 loss: 11.978647708892822\n",
      "MSE train 4.944734147117477 MSE test 11.360307179314534\n",
      "MAE train 1.5245424459660335 MAE test 2.356521817013463\n",
      "Epoch 9341 / 10000 loss: 11.978339910507202\n",
      "MSE train 4.9446272742911335 MSE test 11.360083183331666\n",
      "MAE train 1.5245261055264594 MAE test 2.356492749290481\n",
      "Epoch 9342 / 10000 loss: 11.977871417999268\n",
      "MSE train 4.944534137053621 MSE test 11.360074643446705\n",
      "MAE train 1.5245079300580509 MAE test 2.3564968588416915\n",
      "Epoch 9343 / 10000 loss: 11.977524757385254\n",
      "MSE train 4.944428946662165 MSE test 11.359797358810743\n",
      "MAE train 1.5244930636371221 MAE test 2.3564606963456898\n",
      "Epoch 9344 / 10000 loss: 11.97713851928711\n",
      "MSE train 4.94431778037885 MSE test 11.35982182662264\n",
      "MAE train 1.5244694188173455 MAE test 2.356469263130426\n",
      "Epoch 9345 / 10000 loss: 11.976840734481812\n",
      "MSE train 4.9442118664171115 MSE test 11.359613828681761\n",
      "MAE train 1.524452996764669 MAE test 2.3564422758970305\n",
      "Epoch 9346 / 10000 loss: 11.976360559463501\n",
      "MSE train 4.944116911656395 MSE test 11.359587760006377\n",
      "MAE train 1.5244347371468299 MAE test 2.3564440541170084\n",
      "Epoch 9347 / 10000 loss: 11.976006746292114\n",
      "MSE train 4.944011999822943 MSE test 11.359330627894062\n",
      "MAE train 1.5244195586376188 MAE test 2.3564105793165786\n",
      "Epoch 9348 / 10000 loss: 11.975625991821289\n",
      "MSE train 4.943909558934642 MSE test 11.359349594831928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5243983780251877 MAE test 2.3564183642541727\n",
      "Epoch 9349 / 10000 loss: 11.975312948226929\n",
      "MSE train 4.943803524283909 MSE test 11.359101398207219\n",
      "MAE train 1.5243827553249498 MAE test 2.3563860652360935\n",
      "Epoch 9350 / 10000 loss: 11.974872589111328\n",
      "MSE train 4.943705921769817 MSE test 11.359113635042977\n",
      "MAE train 1.5243629463816601 MAE test 2.356392925920951\n",
      "Epoch 9351 / 10000 loss: 11.974548816680908\n",
      "MSE train 4.943600246493394 MSE test 11.35884749635158\n",
      "MAE train 1.524347739874624 MAE test 2.3563582419042133\n",
      "Epoch 9352 / 10000 loss: 11.974130630493164\n",
      "MSE train 4.943495013204921 MSE test 11.358868278883246\n",
      "MAE train 1.5243257674753308 MAE test 2.356366255812599\n",
      "Epoch 9353 / 10000 loss: 11.97382378578186\n",
      "MSE train 4.943388634947205 MSE test 11.358633957479892\n",
      "MAE train 1.5243097845521825 MAE test 2.35633580207697\n",
      "Epoch 9354 / 10000 loss: 11.973369359970093\n",
      "MSE train 4.943295246264406 MSE test 11.358635831948177\n",
      "MAE train 1.52429129826322 MAE test 2.3563412584148935\n",
      "Epoch 9355 / 10000 loss: 11.973034858703613\n",
      "MSE train 4.943190191957121 MSE test 11.358357641987146\n",
      "MAE train 1.5242764969709865 MAE test 2.356304949290749\n",
      "Epoch 9356 / 10000 loss: 11.972640752792358\n",
      "MSE train 4.943079130596157 MSE test 11.358382408121434\n",
      "MAE train 1.5242528694574402 MAE test 2.356313523514018\n",
      "Epoch 9357 / 10000 loss: 11.972345113754272\n",
      "MSE train 4.942973753659177 MSE test 11.358176937039316\n",
      "MAE train 1.5242365357389567 MAE test 2.3562868535885424\n",
      "Epoch 9358 / 10000 loss: 11.971867084503174\n",
      "MSE train 4.942878536090898 MSE test 11.358148264882193\n",
      "MAE train 1.5242182710773071 MAE test 2.356288265772946\n",
      "Epoch 9359 / 10000 loss: 11.971514225006104\n",
      "MSE train 4.942773795670836 MSE test 11.357895635970962\n",
      "MAE train 1.5242030671490583 MAE test 2.3562553582169214\n",
      "Epoch 9360 / 10000 loss: 11.971134662628174\n",
      "MSE train 4.942673451636649 MSE test 11.357912960255394\n",
      "MAE train 1.5241824753997117 MAE test 2.356262884050499\n",
      "Epoch 9361 / 10000 loss: 11.970819234848022\n",
      "MSE train 4.942567826495919 MSE test 11.357657258170473\n",
      "MAE train 1.5241670975360886 MAE test 2.3562295607996053\n",
      "Epoch 9362 / 10000 loss: 11.970388889312744\n",
      "MSE train 4.942467380479391 MSE test 11.35767397359763\n",
      "MAE train 1.5241464778374223 MAE test 2.356237001814051\n",
      "Epoch 9363 / 10000 loss: 11.970073461532593\n",
      "MSE train 4.942361483579969 MSE test 11.35741984248332\n",
      "MAE train 1.5241310091818008 MAE test 2.3562038975413966\n",
      "Epoch 9364 / 10000 loss: 11.969641923904419\n",
      "MSE train 4.942261957785274 MSE test 11.357435146328562\n",
      "MAE train 1.5241106499596286 MAE test 2.356211137798701\n",
      "Epoch 9365 / 10000 loss: 11.969325065612793\n",
      "MSE train 4.942156165049359 MSE test 11.357177638023249\n",
      "MAE train 1.5240952682793156 MAE test 2.3561775795670146\n",
      "Epoch 9366 / 10000 loss: 11.968897342681885\n",
      "MSE train 4.942055094279884 MSE test 11.357194477306912\n",
      "MAE train 1.5240744860063478 MAE test 2.3561850201524153\n",
      "Epoch 9367 / 10000 loss: 11.968583106994629\n",
      "MSE train 4.9419491295060185 MSE test 11.356943025509043\n",
      "MAE train 1.5240589567288694 MAE test 2.3561522643600337\n",
      "Epoch 9368 / 10000 loss: 11.968149185180664\n",
      "MSE train 4.941850701613261 MSE test 11.356956721901504\n",
      "MAE train 1.5240389090755424 MAE test 2.3561592825408986\n",
      "Epoch 9369 / 10000 loss: 11.96782898902893\n",
      "MSE train 4.94174506594471 MSE test 11.356694926924273\n",
      "MAE train 1.5240236444073758 MAE test 2.3561251403944423\n",
      "Epoch 9370 / 10000 loss: 11.967408180236816\n",
      "MSE train 4.941642171701386 MSE test 11.356713749186797\n",
      "MAE train 1.524002336517195 MAE test 2.3561328589076216\n",
      "Epoch 9371 / 10000 loss: 11.967097759246826\n",
      "MSE train 4.94153600834238 MSE test 11.356470135215712\n",
      "MAE train 1.5239866147711534 MAE test 2.3561011411162673\n",
      "Epoch 9372 / 10000 loss: 11.966654300689697\n",
      "MSE train 4.941440568176816 MSE test 11.356478892350099\n",
      "MAE train 1.5239674392102123 MAE test 2.3561074879644384\n",
      "Epoch 9373 / 10000 loss: 11.96632719039917\n",
      "MSE train 4.941335269227237 MSE test 11.356206895165196\n",
      "MAE train 1.5239524613609574 MAE test 2.356071967992439\n",
      "Epoch 9374 / 10000 loss: 11.96592116355896\n",
      "MSE train 4.941227426498974 MSE test 11.356229637877133\n",
      "MAE train 1.5239297514745742 MAE test 2.3560802342446148\n",
      "Epoch 9375 / 10000 loss: 11.965619802474976\n",
      "MSE train 4.941121361374798 MSE test 11.356008640511726\n",
      "MAE train 1.5239135710748644 MAE test 2.356051493174782\n",
      "Epoch 9376 / 10000 loss: 11.965156555175781\n",
      "MSE train 4.94102896556938 MSE test 11.355997854713486\n",
      "MAE train 1.5238956446343945 MAE test 2.3560552367802714\n",
      "Epoch 9377 / 10000 loss: 11.964812278747559\n",
      "MSE train 4.94092437986493 MSE test 11.355723347669358\n",
      "MAE train 1.5238809026180067 MAE test 2.3560194067477545\n",
      "Epoch 9378 / 10000 loss: 11.964432001113892\n",
      "MSE train 4.940814620802122 MSE test 11.355747578571046\n",
      "MAE train 1.5238576463404543 MAE test 2.3560278587391426\n",
      "Epoch 9379 / 10000 loss: 11.964135646820068\n",
      "MSE train 4.940709025613342 MSE test 11.355535780894467\n",
      "MAE train 1.5238413982360366 MAE test 2.356000329487189\n",
      "Epoch 9380 / 10000 loss: 11.963663339614868\n",
      "MSE train 4.940615485809781 MSE test 11.355515140496786\n",
      "MAE train 1.5238233946445296 MAE test 2.3560027782546173\n",
      "Epoch 9381 / 10000 loss: 11.963314771652222\n",
      "MSE train 4.94051101982818 MSE test 11.355250938919713\n",
      "MAE train 1.5238084794741824 MAE test 2.3559683013064436\n",
      "Epoch 9382 / 10000 loss: 11.962937355041504\n",
      "MSE train 4.94040570149643 MSE test 11.355272466546648\n",
      "MAE train 1.5237864773504033 MAE test 2.35597639381628\n",
      "Epoch 9383 / 10000 loss: 11.962632179260254\n",
      "MSE train 4.94029967309081 MSE test 11.355038934257204\n",
      "MAE train 1.5237705785629057 MAE test 2.355945993905875\n",
      "Epoch 9384 / 10000 loss: 11.96217966079712\n",
      "MSE train 4.940206528900309 MSE test 11.355040718007444\n",
      "MAE train 1.5237521670433272 MAE test 2.3559514123164558\n",
      "Epoch 9385 / 10000 loss: 11.961845874786377\n",
      "MSE train 4.94010173082076 MSE test 11.354762687789371\n",
      "MAE train 1.5237374304042324 MAE test 2.3559150909878444\n",
      "Epoch 9386 / 10000 loss: 11.961453676223755\n",
      "MSE train 4.939990802695734 MSE test 11.354787254678639\n",
      "MAE train 1.5237138386603144 MAE test 2.355923594387404\n",
      "Epoch 9387 / 10000 loss: 11.961159229278564\n",
      "MSE train 4.939885567160768 MSE test 11.354582089446385\n",
      "MAE train 1.5236975501297814 MAE test 2.355896941896956\n",
      "Epoch 9388 / 10000 loss: 11.960681915283203\n",
      "MSE train 4.939790476240155 MSE test 11.354552927837785\n",
      "MAE train 1.5236793210596093 MAE test 2.355898261154462\n",
      "Epoch 9389 / 10000 loss: 11.96033000946045\n",
      "MSE train 4.9396859322774525 MSE test 11.354300811004778\n",
      "MAE train 1.5236641613660684 MAE test 2.3558653916847403\n",
      "Epoch 9390 / 10000 loss: 11.95995283126831\n",
      "MSE train 4.939585901045115 MSE test 11.354317745201234\n",
      "MAE train 1.5236436554234938 MAE test 2.3558728548726027\n",
      "Epoch 9391 / 10000 loss: 11.959636926651001\n",
      "MSE train 4.939480441253886 MSE test 11.354061388558195\n",
      "MAE train 1.5236283338615972 MAE test 2.355839420276709\n",
      "Epoch 9392 / 10000 loss: 11.959209203720093\n",
      "MSE train 4.93937976866308 MSE test 11.354078182892954\n",
      "MAE train 1.5236076483417669 MAE test 2.3558468591371473\n",
      "Epoch 9393 / 10000 loss: 11.9588942527771\n",
      "MSE train 4.939274011264341 MSE test 11.353825446176385\n",
      "MAE train 1.5235921827878207 MAE test 2.3558139107407325\n",
      "Epoch 9394 / 10000 loss: 11.958462715148926\n",
      "MSE train 4.939175176113617 MSE test 11.35383992618772\n",
      "MAE train 1.5235720126889716 MAE test 2.3558210288287045\n",
      "Epoch 9395 / 10000 loss: 11.958144664764404\n",
      "MSE train 4.939069534532405 MSE test 11.353580184867504\n",
      "MAE train 1.523556702790568 MAE test 2.355787139275365\n",
      "Epoch 9396 / 10000 loss: 11.95772099494934\n",
      "MSE train 4.938967667628768 MSE test 11.353597988833618\n",
      "MAE train 1.5235356848626274 MAE test 2.3557947125441885\n",
      "Epoch 9397 / 10000 loss: 11.957408905029297\n",
      "MSE train 4.938861692411477 MSE test 11.353350599099961\n",
      "MAE train 1.5235200735283772 MAE test 2.35576247093761\n",
      "Epoch 9398 / 10000 loss: 11.956971645355225\n",
      "MSE train 4.938765018311405 MSE test 11.353361694058927\n",
      "MAE train 1.523500523412067 MAE test 2.3557691255112494\n",
      "Epoch 9399 / 10000 loss: 11.956648349761963\n",
      "MSE train 4.938659658775181 MSE test 11.353094280920859\n",
      "MAE train 1.523485422436343 MAE test 2.355734211106947\n",
      "Epoch 9400 / 10000 loss: 11.956235885620117\n",
      "MSE train 4.938554127089142 MSE test 11.353115335860338\n",
      "MAE train 1.5234633694535626 MAE test 2.3557422412015505\n",
      "Epoch 9401 / 10000 loss: 11.955931663513184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.938448055494815 MSE test 11.352884133781407\n",
      "MAE train 1.5234473813577127 MAE test 2.355712130585448\n",
      "Epoch 9402 / 10000 loss: 11.955477476119995\n",
      "MSE train 4.938355396317721 MSE test 11.352883153638949\n",
      "MAE train 1.5234291560450284 MAE test 2.3557171719393257\n",
      "Epoch 9403 / 10000 loss: 11.955140829086304\n",
      "MSE train 4.938250672825516 MSE test 11.352604804155177\n",
      "MAE train 1.5234144370529352 MAE test 2.3556807962339854\n",
      "Epoch 9404 / 10000 loss: 11.954753637313843\n",
      "MSE train 4.938139671705928 MSE test 11.352629466124766\n",
      "MAE train 1.5233908172939499 MAE test 2.3556893185477286\n",
      "Epoch 9405 / 10000 loss: 11.954459190368652\n",
      "MSE train 4.938034606683519 MSE test 11.35242519755725\n",
      "MAE train 1.5233745346936725 MAE test 2.3556627560715144\n",
      "Epoch 9406 / 10000 loss: 11.95398235321045\n",
      "MSE train 4.937939316831661 MSE test 11.352394812451543\n",
      "MAE train 1.5233562826310985 MAE test 2.3556639257765135\n",
      "Epoch 9407 / 10000 loss: 11.953629493713379\n",
      "MSE train 4.93783474359012 MSE test 11.352144743939235\n",
      "MAE train 1.523341074396834 MAE test 2.3556313104273823\n",
      "Epoch 9408 / 10000 loss: 11.953251600265503\n",
      "MSE train 4.937735615220948 MSE test 11.352160555102362\n",
      "MAE train 1.5233208063340877 MAE test 2.355638620202194\n",
      "Epoch 9409 / 10000 loss: 11.952935695648193\n",
      "MSE train 4.937630324841867 MSE test 11.351901311674238\n",
      "MAE train 1.5233055687554926 MAE test 2.355604788577805\n",
      "Epoch 9410 / 10000 loss: 11.952511310577393\n",
      "MSE train 4.937528369553331 MSE test 11.351919528683299\n",
      "MAE train 1.5232845129472088 MAE test 2.3556124225304185\n",
      "Epoch 9411 / 10000 loss: 11.952200174331665\n",
      "MSE train 4.937422479878291 MSE test 11.35167275486081\n",
      "MAE train 1.5232689067068164 MAE test 2.3555802429919286\n",
      "Epoch 9412 / 10000 loss: 11.951761960983276\n",
      "MSE train 4.937325931799575 MSE test 11.351683676012444\n",
      "MAE train 1.5232493944485088 MAE test 2.3555868896511245\n",
      "Epoch 9413 / 10000 loss: 11.951438665390015\n",
      "MSE train 4.937220691687931 MSE test 11.351415938264537\n",
      "MAE train 1.5232343216845394 MAE test 2.355551923384764\n",
      "Epoch 9414 / 10000 loss: 11.951027393341064\n",
      "MSE train 4.9371149905003975 MSE test 11.35143697838798\n",
      "MAE train 1.5232122090662024 MAE test 2.3555599440958837\n",
      "Epoch 9415 / 10000 loss: 11.950723648071289\n",
      "MSE train 4.937008941564809 MSE test 11.35120698294133\n",
      "MAE train 1.5231961986048574 MAE test 2.3555299957943605\n",
      "Epoch 9416 / 10000 loss: 11.950268507003784\n",
      "MSE train 4.9369164387952384 MSE test 11.351205104922649\n",
      "MAE train 1.5231780349720487 MAE test 2.3555349131053807\n",
      "Epoch 9417 / 10000 loss: 11.949932098388672\n",
      "MSE train 4.936811840904088 MSE test 11.35092685843144\n",
      "MAE train 1.5231633364955162 MAE test 2.3554985504860806\n",
      "Epoch 9418 / 10000 loss: 11.949544906616211\n",
      "MSE train 4.936700885122076 MSE test 11.350951534477494\n",
      "MAE train 1.52313972222285 MAE test 2.3555070939809206\n",
      "Epoch 9419 / 10000 loss: 11.949251413345337\n",
      "MSE train 4.936595834813115 MSE test 11.350747339611882\n",
      "MAE train 1.5231234406433767 MAE test 2.3554805240303907\n",
      "Epoch 9420 / 10000 loss: 11.948774099349976\n",
      "MSE train 4.9365006025837825 MSE test 11.350716830822913\n",
      "MAE train 1.5231051973924994 MAE test 2.3554816777297996\n",
      "Epoch 9421 / 10000 loss: 11.948421716690063\n",
      "MSE train 4.936396109207455 MSE test 11.35046701715376\n",
      "MAE train 1.5230899981999049 MAE test 2.3554490943428155\n",
      "Epoch 9422 / 10000 loss: 11.948044776916504\n",
      "MSE train 4.936297056587379 MSE test 11.350482872244772\n",
      "MAE train 1.5230697481096704 MAE test 2.355456414323429\n",
      "Epoch 9423 / 10000 loss: 11.947728395462036\n",
      "MSE train 4.936191797654661 MSE test 11.350223396425356\n",
      "MAE train 1.5230545189957068 MAE test 2.355422537925715\n",
      "Epoch 9424 / 10000 loss: 11.947304725646973\n",
      "MSE train 4.9360897995594435 MSE test 11.350241740840298\n",
      "MAE train 1.5230334395881413 MAE test 2.355430190237328\n",
      "Epoch 9425 / 10000 loss: 11.946994304656982\n",
      "MSE train 4.935983994853001 MSE test 11.34999540719877\n",
      "MAE train 1.5230178321471577 MAE test 2.35539806510039\n",
      "Epoch 9426 / 10000 loss: 11.946555852890015\n",
      "MSE train 4.9358877070190195 MSE test 11.350006114033745\n",
      "MAE train 1.5229983852861901 MAE test 2.355404677062973\n",
      "Epoch 9427 / 10000 loss: 11.946232557296753\n",
      "MSE train 4.9357824822016845 MSE test 11.349737963175956\n",
      "MAE train 1.5229833212138215 MAE test 2.355369651252712\n",
      "Epoch 9428 / 10000 loss: 11.945821762084961\n",
      "MSE train 4.93567658752486 MSE test 11.349759198188956\n",
      "MAE train 1.522961151010436 MAE test 2.355377700319753\n",
      "Epoch 9429 / 10000 loss: 11.945518732070923\n",
      "MSE train 4.935570630961927 MSE test 11.349530417423091\n",
      "MAE train 1.52294512201495 MAE test 2.355347898924722\n",
      "Epoch 9430 / 10000 loss: 11.945063352584839\n",
      "MSE train 4.935478294292805 MSE test 11.349527380001529\n",
      "MAE train 1.5229270265583055 MAE test 2.3553526826612505\n",
      "Epoch 9431 / 10000 loss: 11.944725275039673\n",
      "MSE train 4.935373723418621 MSE test 11.349249368471325\n",
      "MAE train 1.5229123224184271 MAE test 2.355316323194093\n",
      "Epoch 9432 / 10000 loss: 11.944339752197266\n",
      "MSE train 4.935262879543317 MSE test 11.349274104216278\n",
      "MAE train 1.5228887284661456 MAE test 2.3553248757900334\n",
      "Epoch 9433 / 10000 loss: 11.94404673576355\n",
      "MSE train 4.935157882707325 MSE test 11.34906986777908\n",
      "MAE train 1.5228724528852045 MAE test 2.355298300977456\n",
      "Epoch 9434 / 10000 loss: 11.943569421768188\n",
      "MSE train 4.935062750044833 MSE test 11.349039644621312\n",
      "MAE train 1.522854227479268 MAE test 2.3552994954266553\n",
      "Epoch 9435 / 10000 loss: 11.943217992782593\n",
      "MSE train 4.934958302334578 MSE test 11.34878956169144\n",
      "MAE train 1.5228390382292158 MAE test 2.355266864450696\n",
      "Epoch 9436 / 10000 loss: 11.942841529846191\n",
      "MSE train 4.934859180400315 MSE test 11.348805422115658\n",
      "MAE train 1.5228187626119032 MAE test 2.3552741775978285\n",
      "Epoch 9437 / 10000 loss: 11.942524909973145\n",
      "MSE train 4.934754007881265 MSE test 11.348546786892765\n",
      "MAE train 1.5228035236908426 MAE test 2.3552404098236113\n",
      "Epoch 9438 / 10000 loss: 11.942100763320923\n",
      "MSE train 4.934652333081759 MSE test 11.348564774515921\n",
      "MAE train 1.5227825353177427 MAE test 2.355248015080186\n",
      "Epoch 9439 / 10000 loss: 11.941789627075195\n",
      "MSE train 4.934546541241631 MSE test 11.34831731475434\n",
      "MAE train 1.5227669520643374 MAE test 2.355215730350901\n",
      "Epoch 9440 / 10000 loss: 11.94135332107544\n",
      "MSE train 4.934449871471784 MSE test 11.348328672309309\n",
      "MAE train 1.5227473873587074 MAE test 2.3552224353002322\n",
      "Epoch 9441 / 10000 loss: 11.941031217575073\n",
      "MSE train 4.934344702063667 MSE test 11.348062074773564\n",
      "MAE train 1.522732286805402 MAE test 2.3551876127338844\n",
      "Epoch 9442 / 10000 loss: 11.94061827659607\n",
      "MSE train 4.934239583582063 MSE test 11.34808286655589\n",
      "MAE train 1.522710328508699 MAE test 2.3551955988881526\n",
      "Epoch 9443 / 10000 loss: 11.940313339233398\n",
      "MSE train 4.934133682238895 MSE test 11.347850751370661\n",
      "MAE train 1.5226943855673158 MAE test 2.3551653481014747\n",
      "Epoch 9444 / 10000 loss: 11.93986177444458\n",
      "MSE train 4.934040954840801 MSE test 11.347850657829328\n",
      "MAE train 1.5226761152637691 MAE test 2.355170525504251\n",
      "Epoch 9445 / 10000 loss: 11.939526557922363\n",
      "MSE train 4.933936378585401 MSE test 11.34757304039749\n",
      "MAE train 1.5226613890216991 MAE test 2.3551342251518173\n",
      "Epoch 9446 / 10000 loss: 11.939137697219849\n",
      "MSE train 4.933825723335286 MSE test 11.347597349394713\n",
      "MAE train 1.5226378433227923 MAE test 2.3551427079683327\n",
      "Epoch 9447 / 10000 loss: 11.938844680786133\n",
      "MSE train 4.93372071171835 MSE test 11.347392597129495\n",
      "MAE train 1.5226215681881612 MAE test 2.3551160649271488\n",
      "Epoch 9448 / 10000 loss: 11.938368082046509\n",
      "MSE train 4.93362583023911 MSE test 11.347363134172756\n",
      "MAE train 1.522603381100489 MAE test 2.3551173535198378\n",
      "Epoch 9449 / 10000 loss: 11.938016891479492\n",
      "MSE train 4.933521437715832 MSE test 11.3471118743726\n",
      "MAE train 1.5225882110081648 MAE test 2.355084571398317\n",
      "Epoch 9450 / 10000 loss: 11.937639713287354\n",
      "MSE train 4.933421898581824 MSE test 11.3471284350989\n",
      "MAE train 1.5225678151544797 MAE test 2.355091973962222\n",
      "Epoch 9451 / 10000 loss: 11.937325477600098\n",
      "MSE train 4.933316619036717 MSE test 11.346871593310771\n",
      "MAE train 1.522552513613231 MAE test 2.355058444574882\n",
      "Epoch 9452 / 10000 loss: 11.936899423599243\n",
      "MSE train 4.933215921533757 MSE test 11.346888781543893\n",
      "MAE train 1.5225317917619832 MAE test 2.3550659407676906\n",
      "Epoch 9453 / 10000 loss: 11.936586618423462\n",
      "MSE train 4.933110311741203 MSE test 11.346637863327606\n",
      "MAE train 1.5225162974984134 MAE test 2.3550332065794564\n",
      "Epoch 9454 / 10000 loss: 11.936153888702393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.933012313509515 MSE test 11.346651428590839\n",
      "MAE train 1.5224963451792362 MAE test 2.355040201497239\n",
      "Epoch 9455 / 10000 loss: 11.935834884643555\n",
      "MSE train 4.932906965226109 MSE test 11.346389837533494\n",
      "MAE train 1.5224811035073766 MAE test 2.355006029984222\n",
      "Epoch 9456 / 10000 loss: 11.935415506362915\n",
      "MSE train 4.932804378715904 MSE test 11.346408518883607\n",
      "MAE train 1.5224598424818603 MAE test 2.355013733477327\n",
      "Epoch 9457 / 10000 loss: 11.93510627746582\n",
      "MSE train 4.932698524050055 MSE test 11.346166119699893\n",
      "MAE train 1.5224441348694575 MAE test 2.3549821234452564\n",
      "Epoch 9458 / 10000 loss: 11.934664487838745\n",
      "MSE train 4.93260357198038 MSE test 11.3461741587526\n",
      "MAE train 1.5224250776484047 MAE test 2.354988379950375\n",
      "Epoch 9459 / 10000 loss: 11.934338331222534\n",
      "MSE train 4.932498604876707 MSE test 11.345902199005584\n",
      "MAE train 1.5224101328193205 MAE test 2.35495282537794\n",
      "Epoch 9460 / 10000 loss: 11.933934450149536\n",
      "MSE train 4.932390978404975 MSE test 11.345924817709152\n",
      "MAE train 1.5223874460023974 MAE test 2.3549610708796997\n",
      "Epoch 9461 / 10000 loss: 11.933634757995605\n",
      "MSE train 4.932285285204142 MSE test 11.345705346867623\n",
      "MAE train 1.5223712848263562 MAE test 2.354932489166704\n",
      "Epoch 9462 / 10000 loss: 11.93317174911499\n",
      "MSE train 4.9321931127124 MSE test 11.345693308917554\n",
      "MAE train 1.522353425615361 MAE test 2.3549360771503993\n",
      "Epoch 9463 / 10000 loss: 11.932828664779663\n",
      "MSE train 4.932088831210435 MSE test 11.345420299689254\n",
      "MAE train 1.522338676211428 MAE test 2.354900378184768\n",
      "Epoch 9464 / 10000 loss: 11.932450532913208\n",
      "MSE train 4.931979935108287 MSE test 11.34544409797984\n",
      "MAE train 1.5223156222034824 MAE test 2.3549087858924485\n",
      "Epoch 9465 / 10000 loss: 11.932153940200806\n",
      "MSE train 4.931874514053181 MSE test 11.345230465039817\n",
      "MAE train 1.522299412280077 MAE test 2.3548809762103895\n",
      "Epoch 9466 / 10000 loss: 11.931684732437134\n",
      "MSE train 4.931781689309719 MSE test 11.345212424622284\n",
      "MAE train 1.5222815232232902 MAE test 2.3548837688227584\n",
      "Epoch 9467 / 10000 loss: 11.931338787078857\n",
      "MSE train 4.931677510185631 MSE test 11.344945702385315\n",
      "MAE train 1.5222666691277889 MAE test 2.35484890579128\n",
      "Epoch 9468 / 10000 loss: 11.930962324142456\n",
      "MSE train 4.931571269914462 MSE test 11.344968026655533\n",
      "MAE train 1.5222443729545467 MAE test 2.3548571185702407\n",
      "Epoch 9469 / 10000 loss: 11.930660963058472\n",
      "MSE train 4.931465531124465 MSE test 11.344741174042465\n",
      "MAE train 1.5222283511621126 MAE test 2.354827572312129\n",
      "Epoch 9470 / 10000 loss: 11.930203437805176\n",
      "MSE train 4.931373421458056 MSE test 11.344737302825964\n",
      "MAE train 1.5222103237416877 MAE test 2.3548322371338584\n",
      "Epoch 9471 / 10000 loss: 11.929865598678589\n",
      "MSE train 4.931269097115141 MSE test 11.344459917407873\n",
      "MAE train 1.5221956391233242 MAE test 2.354795956487494\n",
      "Epoch 9472 / 10000 loss: 11.929482698440552\n",
      "MSE train 4.931158461043206 MSE test 11.344484488494087\n",
      "MAE train 1.5221720851638962 MAE test 2.3548044719504047\n",
      "Epoch 9473 / 10000 loss: 11.929189682006836\n",
      "MSE train 4.93105353718637 MSE test 11.344280223908155\n",
      "MAE train 1.5221558119142709 MAE test 2.35477789613113\n",
      "Epoch 9474 / 10000 loss: 11.928712129592896\n",
      "MSE train 4.9309586381948405 MSE test 11.344250366428433\n",
      "MAE train 1.5221376263836515 MAE test 2.3547791199751495\n",
      "Epoch 9475 / 10000 loss: 11.928361177444458\n",
      "MSE train 4.930854322138172 MSE test 11.344000071811926\n",
      "MAE train 1.5221224445870232 MAE test 2.3547464484907628\n",
      "Epoch 9476 / 10000 loss: 11.927984714508057\n",
      "MSE train 4.930755106046628 MSE test 11.344016147051917\n",
      "MAE train 1.5221021311884495 MAE test 2.35475380192071\n",
      "Epoch 9477 / 10000 loss: 11.927670001983643\n",
      "MSE train 4.930649987127244 MSE test 11.343758813150371\n",
      "MAE train 1.5220868552439353 MAE test 2.354720194566645\n",
      "Epoch 9478 / 10000 loss: 11.927245140075684\n",
      "MSE train 4.930548949379899 MSE test 11.343776277459625\n",
      "MAE train 1.5220660364728404 MAE test 2.354727738221286\n",
      "Epoch 9479 / 10000 loss: 11.92693281173706\n",
      "MSE train 4.930443348864978 MSE test 11.343527373119281\n",
      "MAE train 1.522050495777454 MAE test 2.354695246554656\n",
      "Epoch 9480 / 10000 loss: 11.926498413085938\n",
      "MSE train 4.9303461120447825 MSE test 11.343539648259107\n",
      "MAE train 1.5220307535610575 MAE test 2.3547020732156274\n",
      "Epoch 9481 / 10000 loss: 11.926178216934204\n",
      "MSE train 4.9302409016879825 MSE test 11.343276102373107\n",
      "MAE train 1.5220155668574882 MAE test 2.354667654442633\n",
      "Epoch 9482 / 10000 loss: 11.925762414932251\n",
      "MSE train 4.9301372215539825 MSE test 11.343295738211255\n",
      "MAE train 1.5219939987799493 MAE test 2.354675481123662\n",
      "Epoch 9483 / 10000 loss: 11.925456047058105\n",
      "MSE train 4.930031376777122 MSE test 11.343058269014753\n",
      "MAE train 1.5219781760569264 MAE test 2.3546445156565996\n",
      "Epoch 9484 / 10000 loss: 11.925009489059448\n",
      "MSE train 4.929937837689224 MSE test 11.343062725569931\n",
      "MAE train 1.5219595556157157 MAE test 2.3546502995288843\n",
      "Epoch 9485 / 10000 loss: 11.924679517745972\n",
      "MSE train 4.929833116765111 MSE test 11.342787451412415\n",
      "MAE train 1.5219447246508289 MAE test 2.354614299620014\n",
      "Epoch 9486 / 10000 loss: 11.924283266067505\n",
      "MSE train 4.929723737771091 MSE test 11.342811253091782\n",
      "MAE train 1.5219215247799815 MAE test 2.354622714808787\n",
      "Epoch 9487 / 10000 loss: 11.923987865447998\n",
      "MSE train 4.929618466973872 MSE test 11.342600914111935\n",
      "MAE train 1.5219052714204826 MAE test 2.3545953271978126\n",
      "Epoch 9488 / 10000 loss: 11.923516511917114\n",
      "MSE train 4.929525087422847 MSE test 11.342578568647493\n",
      "MAE train 1.5218873185653656 MAE test 2.354597553854919\n",
      "Epoch 9489 / 10000 loss: 11.923168182373047\n",
      "MSE train 4.929420923252592 MSE test 11.34231725935923\n",
      "MAE train 1.5218723523177031 MAE test 2.3545634116073257\n",
      "Epoch 9490 / 10000 loss: 11.922791719436646\n",
      "MSE train 4.929317091309512 MSE test 11.342337916158579\n",
      "MAE train 1.5218507360860616 MAE test 2.3545713883160926\n",
      "Epoch 9491 / 10000 loss: 11.922486305236816\n",
      "MSE train 4.929211453401349 MSE test 11.342100209067926\n",
      "MAE train 1.5218349709655392 MAE test 2.354540392704599\n",
      "Epoch 9492 / 10000 loss: 11.92203950881958\n",
      "MSE train 4.92911768528166 MSE test 11.342105628734503\n",
      "MAE train 1.5218162754259987 MAE test 2.3545462953863794\n",
      "Epoch 9493 / 10000 loss: 11.921710014343262\n",
      "MSE train 4.929013033725936 MSE test 11.341830876979229\n",
      "MAE train 1.5218014459482307 MAE test 2.354510377112902\n",
      "Epoch 9494 / 10000 loss: 11.921313524246216\n",
      "MSE train 4.928903861779146 MSE test 11.341854484773245\n",
      "MAE train 1.5217782991570006 MAE test 2.3545187578457365\n",
      "Epoch 9495 / 10000 loss: 11.921016693115234\n",
      "MSE train 4.928798523820344 MSE test 11.341643365169338\n",
      "MAE train 1.5217620488282704 MAE test 2.3544912697607754\n",
      "Epoch 9496 / 10000 loss: 11.920547246932983\n",
      "MSE train 4.928705325491298 MSE test 11.341622196416015\n",
      "MAE train 1.5217441149842637 MAE test 2.3544936498420834\n",
      "Epoch 9497 / 10000 loss: 11.920199394226074\n",
      "MSE train 4.928601153564518 MSE test 11.341359577845413\n",
      "MAE train 1.5217291765072372 MAE test 2.3544593356824843\n",
      "Epoch 9498 / 10000 loss: 11.919822931289673\n",
      "MSE train 4.928496710692374 MSE test 11.34138064805224\n",
      "MAE train 1.521707377056596 MAE test 2.354467366309469\n",
      "Epoch 9499 / 10000 loss: 11.91951870918274\n",
      "MSE train 4.92839102236263 MSE test 11.341146071987847\n",
      "MAE train 1.521691535426471 MAE test 2.3544367750381587\n",
      "Epoch 9500 / 10000 loss: 11.919067859649658\n",
      "MSE train 4.928297990405515 MSE test 11.341149000868771\n",
      "MAE train 1.5216730776946372 MAE test 2.3544423657351836\n",
      "Epoch 9501 / 10000 loss: 11.918736934661865\n",
      "MSE train 4.928193415077421 MSE test 11.340872588021627\n",
      "MAE train 1.5216582991692178 MAE test 2.3544062134732293\n",
      "Epoch 9502 / 10000 loss: 11.918343782424927\n",
      "MSE train 4.92808343273957 MSE test 11.34089683191084\n",
      "MAE train 1.5216349188371174 MAE test 2.3544146853124484\n",
      "Epoch 9503 / 10000 loss: 11.918049573898315\n",
      "MSE train 4.927978336659226 MSE test 11.340689803190925\n",
      "MAE train 1.5216186432088967 MAE test 2.354387737325325\n",
      "Epoch 9504 / 10000 loss: 11.917575359344482\n",
      "MSE train 4.927884282913672 MSE test 11.340663653206954\n",
      "MAE train 1.5216005920809759 MAE test 2.3543894573498814\n",
      "Epoch 9505 / 10000 loss: 11.917225122451782\n",
      "MSE train 4.927780024692188 MSE test 11.34040805881408\n",
      "MAE train 1.521585501173397 MAE test 2.3543560678542024\n",
      "Epoch 9506 / 10000 loss: 11.916849136352539\n",
      "MSE train 4.927678695087718 MSE test 11.340426521725458\n",
      "MAE train 1.5215645785290721 MAE test 2.354363742104876\n",
      "Epoch 9507 / 10000 loss: 11.91653823852539\n",
      "MSE train 4.927573252564308 MSE test 11.340178608250241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.521549056005912 MAE test 2.3543313855051444\n",
      "Epoch 9508 / 10000 loss: 11.91610336303711\n",
      "MSE train 4.927476237785423 MSE test 11.340191018830323\n",
      "MAE train 1.5215293593360615 MAE test 2.3543382415560865\n",
      "Epoch 9509 / 10000 loss: 11.915782690048218\n",
      "MSE train 4.92737109367892 MSE test 11.339926978360369\n",
      "MAE train 1.5215141892097406 MAE test 2.3543037343194233\n",
      "Epoch 9510 / 10000 loss: 11.915367364883423\n",
      "MSE train 4.927267152020107 MSE test 11.339946910019673\n",
      "MAE train 1.5214925351271258 MAE test 2.3543116174601844\n",
      "Epoch 9511 / 10000 loss: 11.915061473846436\n",
      "MSE train 4.927161325937963 MSE test 11.339711249115222\n",
      "MAE train 1.5214766705120801 MAE test 2.3542808772631965\n",
      "Epoch 9512 / 10000 loss: 11.914612531661987\n",
      "MSE train 4.927068125467215 MSE test 11.339714565801644\n",
      "MAE train 1.5214581587393374 MAE test 2.3542864966171266\n",
      "Epoch 9513 / 10000 loss: 11.914281368255615\n",
      "MSE train 4.92696348333272 MSE test 11.339438863184885\n",
      "MAE train 1.5214433445332924 MAE test 2.3542504478561295\n",
      "Epoch 9514 / 10000 loss: 11.91388726234436\n",
      "MSE train 4.926853786823771 MSE test 11.339462640224706\n",
      "MAE train 1.521420050834999 MAE test 2.354258847134525\n",
      "Epoch 9515 / 10000 loss: 11.913592100143433\n",
      "MSE train 4.926748615566511 MSE test 11.339254273706594\n",
      "MAE train 1.521403773350135 MAE test 2.3542317240983617\n",
      "Epoch 9516 / 10000 loss: 11.913118600845337\n",
      "MSE train 4.926654891995693 MSE test 11.339229876797404\n",
      "MAE train 1.521385775662692 MAE test 2.3542336729503863\n",
      "Epoch 9517 / 10000 loss: 11.912769794464111\n",
      "MSE train 4.926550675110109 MSE test 11.338971687254956\n",
      "MAE train 1.521370726384729 MAE test 2.3541999476381124\n",
      "Epoch 9518 / 10000 loss: 11.912393569946289\n",
      "MSE train 4.926448190894416 MSE test 11.338991297189848\n",
      "MAE train 1.5213494824168736 MAE test 2.354207772163543\n",
      "Epoch 9519 / 10000 loss: 11.912084102630615\n",
      "MSE train 4.926342643525249 MSE test 11.338748172859617\n",
      "MAE train 1.521333841884538 MAE test 2.3541760485258045\n",
      "Epoch 9520 / 10000 loss: 11.911643981933594\n",
      "MSE train 4.926247280465125 MSE test 11.338757500669388\n",
      "MAE train 1.5213146388168437 MAE test 2.3541824902412487\n",
      "Epoch 9521 / 10000 loss: 11.9113187789917\n",
      "MSE train 4.926142338073001 MSE test 11.338487921771124\n",
      "MAE train 1.5212996233407599 MAE test 2.3541472515058253\n",
      "Epoch 9522 / 10000 loss: 11.91091251373291\n",
      "MSE train 4.926035611840218 MSE test 11.338509893129347\n",
      "MAE train 1.5212771734038704 MAE test 2.354155414090983\n",
      "Epoch 9523 / 10000 loss: 11.910610914230347\n",
      "MSE train 4.925929835745901 MSE test 11.338287086733109\n",
      "MAE train 1.5212610361792924 MAE test 2.3541263749216963\n",
      "Epoch 9524 / 10000 loss: 11.91015076637268\n",
      "MSE train 4.925837910733033 MSE test 11.338278895628482\n",
      "MAE train 1.5212431453171122 MAE test 2.35413046919645\n",
      "Epoch 9525 / 10000 loss: 11.909809589385986\n",
      "MSE train 4.925733593757682 MSE test 11.338004010082804\n",
      "MAE train 1.5212283976324044 MAE test 2.3540945243491342\n",
      "Epoch 9526 / 10000 loss: 11.909428358078003\n",
      "MSE train 4.9256238015891105 MSE test 11.338028165204472\n",
      "MAE train 1.5212050661029166 MAE test 2.3541029803462084\n",
      "Epoch 9527 / 10000 loss: 11.909133434295654\n",
      "MSE train 4.925518643908371 MSE test 11.337820050456232\n",
      "MAE train 1.5211887878620998 MAE test 2.354075886436084\n",
      "Epoch 9528 / 10000 loss: 11.908660173416138\n",
      "MSE train 4.925424842684546 MSE test 11.337795578776054\n",
      "MAE train 1.5211707738832632 MAE test 2.3540778390220174\n",
      "Epoch 9529 / 10000 loss: 11.908310174942017\n",
      "MSE train 4.9253206279843305 MSE test 11.33753784908937\n",
      "MAE train 1.5211557153079793 MAE test 2.3540441719437846\n",
      "Epoch 9530 / 10000 loss: 11.907933950424194\n",
      "MSE train 4.925218179130034 MSE test 11.337557338807988\n",
      "MAE train 1.5211344856435365 MAE test 2.3540519957850217\n",
      "Epoch 9531 / 10000 loss: 11.907624006271362\n",
      "MSE train 4.925112632366892 MSE test 11.33731401997309\n",
      "MAE train 1.5211188397955944 MAE test 2.354020232969299\n",
      "Epoch 9532 / 10000 loss: 11.907183647155762\n",
      "MSE train 4.925017152632966 MSE test 11.337323512137443\n",
      "MAE train 1.521099606712666 MAE test 2.3540267120131984\n",
      "Epoch 9533 / 10000 loss: 11.906858682632446\n",
      "MSE train 4.924912158873108 MSE test 11.337054264504722\n",
      "MAE train 1.5210845668877444 MAE test 2.3539915088922294\n",
      "Epoch 9534 / 10000 loss: 11.906450748443604\n",
      "MSE train 4.924805549817736 MSE test 11.337076099967431\n",
      "MAE train 1.5210621563873283 MAE test 2.353999660260265\n",
      "Epoch 9535 / 10000 loss: 11.906148672103882\n",
      "MSE train 4.924699724242195 MSE test 11.336852693159676\n",
      "MAE train 1.5210460129098313 MAE test 2.353970542946207\n",
      "Epoch 9536 / 10000 loss: 11.905688285827637\n",
      "MSE train 4.924607724955211 MSE test 11.336845114826497\n",
      "MAE train 1.5210280958708855 MAE test 2.3539747295658264\n",
      "Epoch 9537 / 10000 loss: 11.905348300933838\n",
      "MSE train 4.924503335661677 MSE test 11.336569969682346\n",
      "MAE train 1.5210133271069592 MAE test 2.3539387494120474\n",
      "Epoch 9538 / 10000 loss: 11.90496563911438\n",
      "MSE train 4.924393356189109 MSE test 11.336594146888714\n",
      "MAE train 1.5209899520670715 MAE test 2.353947215109306\n",
      "Epoch 9539 / 10000 loss: 11.904670476913452\n",
      "MSE train 4.9242881961888845 MSE test 11.336386930935417\n",
      "MAE train 1.5209736506186318 MAE test 2.3539202545641573\n",
      "Epoch 9540 / 10000 loss: 11.904195785522461\n",
      "MSE train 4.9241941735440955 MSE test 11.336361513508091\n",
      "MAE train 1.5209556043675028 MAE test 2.3539220714078914\n",
      "Epoch 9541 / 10000 loss: 11.903844833374023\n",
      "MSE train 4.924089832101577 MSE test 11.336105057926371\n",
      "MAE train 1.520940487043126 MAE test 2.353888582836339\n",
      "Epoch 9542 / 10000 loss: 11.903467655181885\n",
      "MSE train 4.923987893537671 MSE test 11.336123926078757\n",
      "MAE train 1.520919408295253 MAE test 2.353896308892677\n",
      "Epoch 9543 / 10000 loss: 11.903156757354736\n",
      "MSE train 4.9238822928823245 MSE test 11.335878378831639\n",
      "MAE train 1.5209037917224335 MAE test 2.353864271407703\n",
      "Epoch 9544 / 10000 loss: 11.90271806716919\n",
      "MSE train 4.92378588451589 MSE test 11.335889339545515\n",
      "MAE train 1.5208842940280407 MAE test 2.3538709327458442\n",
      "Epoch 9545 / 10000 loss: 11.902393579483032\n",
      "MSE train 4.923680717967825 MSE test 11.335622970337722\n",
      "MAE train 1.5208691449790694 MAE test 2.3538361239563934\n",
      "Epoch 9546 / 10000 loss: 11.901981353759766\n",
      "MSE train 4.923575407638063 MSE test 11.33564381361909\n",
      "MAE train 1.5208471137431907 MAE test 2.3538441310272926\n",
      "Epoch 9547 / 10000 loss: 11.901675939559937\n",
      "MSE train 4.923469419716234 MSE test 11.335414011224637\n",
      "MAE train 1.5208310697842589 MAE test 2.3538141904705796\n",
      "Epoch 9548 / 10000 loss: 11.90122127532959\n",
      "MSE train 4.923376964468651 MSE test 11.335412349507608\n",
      "MAE train 1.5208128874434874 MAE test 2.353819163710093\n",
      "Epoch 9549 / 10000 loss: 11.90088438987732\n",
      "MSE train 4.92327230459268 MSE test 11.33513561608096\n",
      "MAE train 1.5207980834247152 MAE test 2.3537829724702175\n",
      "Epoch 9550 / 10000 loss: 11.900495052337646\n",
      "MSE train 4.923161735551355 MSE test 11.335159991765195\n",
      "MAE train 1.5207745495870753 MAE test 2.3537914705273795\n",
      "Epoch 9551 / 10000 loss: 11.900200128555298\n",
      "MSE train 4.923056632463971 MSE test 11.334955589864537\n",
      "MAE train 1.520758205381773 MAE test 2.353764897477506\n",
      "Epoch 9552 / 10000 loss: 11.899723291397095\n",
      "MSE train 4.922961660958895 MSE test 11.334926196248684\n",
      "MAE train 1.5207400072908979 MAE test 2.3537661871197733\n",
      "Epoch 9553 / 10000 loss: 11.899369955062866\n",
      "MSE train 4.922857179532181 MSE test 11.334675599587245\n",
      "MAE train 1.5207247499162546 MAE test 2.3537334869765925\n",
      "Epoch 9554 / 10000 loss: 11.89899206161499\n",
      "MSE train 4.922757522551958 MSE test 11.334691869205422\n",
      "MAE train 1.5207043276798826 MAE test 2.3537408742719412\n",
      "Epoch 9555 / 10000 loss: 11.898674488067627\n",
      "MSE train 4.922652115129507 MSE test 11.334436215468408\n",
      "MAE train 1.5206889243697121 MAE test 2.353707510125529\n",
      "Epoch 9556 / 10000 loss: 11.898246049880981\n",
      "MSE train 4.922551455665743 MSE test 11.334452905876601\n",
      "MAE train 1.5206682294600344 MAE test 2.3537149538923026\n",
      "Epoch 9557 / 10000 loss: 11.89793086051941\n",
      "MSE train 4.92244562240373 MSE test 11.334202204596798\n",
      "MAE train 1.5206526417392232 MAE test 2.35368224864362\n",
      "Epoch 9558 / 10000 loss: 11.897496938705444\n",
      "MSE train 4.922347278082936 MSE test 11.334215719876042\n",
      "MAE train 1.520632599185799 MAE test 2.353689261866101\n",
      "Epoch 9559 / 10000 loss: 11.897176265716553\n",
      "MSE train 4.922241654582915 MSE test 11.333955928648571\n",
      "MAE train 1.5206172132638096 MAE test 2.3536553476131545\n",
      "Epoch 9560 / 10000 loss: 11.896753549575806\n",
      "MSE train 4.922139304747219 MSE test 11.333973943051284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5205960459678889 MAE test 2.353662981666476\n",
      "Epoch 9561 / 10000 loss: 11.896440029144287\n",
      "MSE train 4.922033187011497 MSE test 11.333729957174429\n",
      "MAE train 1.5205802667854835 MAE test 2.3536311665468963\n",
      "Epoch 9562 / 10000 loss: 11.895998239517212\n",
      "MSE train 4.9219373712879255 MSE test 11.333739158266003\n",
      "MAE train 1.5205609752755835 MAE test 2.353637614754001\n",
      "Epoch 9563 / 10000 loss: 11.895670175552368\n",
      "MSE train 4.921831948130793 MSE test 11.333470189243577\n",
      "MAE train 1.520545820173965 MAE test 2.3536024840613385\n",
      "Epoch 9564 / 10000 loss: 11.895260572433472\n",
      "MSE train 4.9217251614085376 MSE test 11.33349172140682\n",
      "MAE train 1.5205233940302942 MAE test 2.35361060852409\n",
      "Epoch 9565 / 10000 loss: 11.894954919815063\n",
      "MSE train 4.921618966432033 MSE test 11.333267395198627\n",
      "MAE train 1.5205071775903372 MAE test 2.35358140703199\n",
      "Epoch 9566 / 10000 loss: 11.894493579864502\n",
      "MSE train 4.921526560796669 MSE test 11.333260525927821\n",
      "MAE train 1.5204891602210575 MAE test 2.353585706017337\n",
      "Epoch 9567 / 10000 loss: 11.894150733947754\n",
      "MSE train 4.921421707362906 MSE test 11.33298499328923\n",
      "MAE train 1.5204742874720962 MAE test 2.3535497013426365\n",
      "Epoch 9568 / 10000 loss: 11.893765687942505\n",
      "MSE train 4.921311149116492 MSE test 11.333008907671198\n",
      "MAE train 1.5204507932863411 MAE test 2.3535581603245497\n",
      "Epoch 9569 / 10000 loss: 11.89346694946289\n",
      "MSE train 4.921205528640471 MSE test 11.332802335091985\n",
      "MAE train 1.5204343780560599 MAE test 2.3535313203724852\n",
      "Epoch 9570 / 10000 loss: 11.892988920211792\n",
      "MSE train 4.921110870479483 MSE test 11.33277582200367\n",
      "MAE train 1.5204162114316475 MAE test 2.353533005364693\n",
      "Epoch 9571 / 10000 loss: 11.892635107040405\n",
      "MSE train 4.921005971007689 MSE test 11.33252075662028\n",
      "MAE train 1.5204009480104619 MAE test 2.3534997399930737\n",
      "Epoch 9572 / 10000 loss: 11.892253637313843\n",
      "MSE train 4.920904045881988 MSE test 11.332538753995742\n",
      "MAE train 1.5203799277309487 MAE test 2.3535073761129306\n",
      "Epoch 9573 / 10000 loss: 11.891937732696533\n",
      "MSE train 4.9207979493068645 MSE test 11.332290729969328\n",
      "MAE train 1.520364245423154 MAE test 2.3534750524235326\n",
      "Epoch 9574 / 10000 loss: 11.89149808883667\n",
      "MSE train 4.920700037319808 MSE test 11.332302889874821\n",
      "MAE train 1.5203443661552052 MAE test 2.353481904929013\n",
      "Epoch 9575 / 10000 loss: 11.891173601150513\n",
      "MSE train 4.920594096119725 MSE test 11.332039873092791\n",
      "MAE train 1.520328981138304 MAE test 2.3534475802937416\n",
      "Epoch 9576 / 10000 loss: 11.890751838684082\n",
      "MSE train 4.920489693587883 MSE test 11.332058934436615\n",
      "MAE train 1.5203072756708351 MAE test 2.353455364411245\n",
      "Epoch 9577 / 10000 loss: 11.89043927192688\n",
      "MSE train 4.920383032400823 MSE test 11.331821766710116\n",
      "MAE train 1.5202912439356822 MAE test 2.3534244814925627\n",
      "Epoch 9578 / 10000 loss: 11.889987707138062\n",
      "MSE train 4.920288542003649 MSE test 11.331825778648525\n",
      "MAE train 1.52027245037559 MAE test 2.353430245496593\n",
      "Epoch 9579 / 10000 loss: 11.88965106010437\n",
      "MSE train 4.920182879550515 MSE test 11.331551193677798\n",
      "MAE train 1.520257367514113 MAE test 2.3533943733901537\n",
      "Epoch 9580 / 10000 loss: 11.889249086380005\n",
      "MSE train 4.920072750684638 MSE test 11.33157420753143\n",
      "MAE train 1.5202340354108523 MAE test 2.353402724808907\n",
      "Epoch 9581 / 10000 loss: 11.888946294784546\n",
      "MSE train 4.919966373417254 MSE test 11.331363048943723\n",
      "MAE train 1.520217542014721 MAE test 2.35337529555571\n",
      "Epoch 9582 / 10000 loss: 11.888468980789185\n",
      "MSE train 4.919872063330988 MSE test 11.331341279768543\n",
      "MAE train 1.5201994041187572 MAE test 2.353377634012981\n",
      "Epoch 9583 / 10000 loss: 11.88811445236206\n",
      "MSE train 4.9197666488556715 MSE test 11.33107921214426\n",
      "MAE train 1.520184164387275 MAE test 2.353343440741868\n",
      "Epoch 9584 / 10000 loss: 11.887730598449707\n",
      "MSE train 4.919661207717152 MSE test 11.331099462879951\n",
      "MAE train 1.5201621901364668 MAE test 2.3533514165195895\n",
      "Epoch 9585 / 10000 loss: 11.887416362762451\n",
      "MSE train 4.919554194609642 MSE test 11.330864007786323\n",
      "MAE train 1.5201460692100042 MAE test 2.3533207675299397\n",
      "Epoch 9586 / 10000 loss: 11.88696026802063\n",
      "MSE train 4.919459544249498 MSE test 11.330866804845082\n",
      "MAE train 1.5201272871662699 MAE test 2.35332638760657\n",
      "Epoch 9587 / 10000 loss: 11.88662052154541\n",
      "MSE train 4.919353474179545 MSE test 11.330591148935394\n",
      "MAE train 1.5201121498022878 MAE test 2.353290402525226\n",
      "Epoch 9588 / 10000 loss: 11.886218070983887\n",
      "MSE train 4.919242287452706 MSE test 11.330614221485078\n",
      "MAE train 1.5200885708300884 MAE test 2.3532987778437944\n",
      "Epoch 9589 / 10000 loss: 11.885913610458374\n",
      "MSE train 4.919135477818188 MSE test 11.330405385318915\n",
      "MAE train 1.5200719471483148 MAE test 2.3532716717334616\n",
      "Epoch 9590 / 10000 loss: 11.885431289672852\n",
      "MSE train 4.919040027130709 MSE test 11.330380244156334\n",
      "MAE train 1.5200536252005103 MAE test 2.3532735836848144\n",
      "Epoch 9591 / 10000 loss: 11.885071754455566\n",
      "MSE train 4.9189339366721425 MSE test 11.330122001646314\n",
      "MAE train 1.5200381818384046 MAE test 2.3532399212085884\n",
      "Epoch 9592 / 10000 loss: 11.884684324264526\n",
      "MSE train 4.9188296009101276 MSE test 11.330140462473107\n",
      "MAE train 1.5200165966838435 MAE test 2.3532476778715488\n",
      "Epoch 9593 / 10000 loss: 11.884364604949951\n",
      "MSE train 4.918721979351074 MSE test 11.329896681104742\n",
      "MAE train 1.5200005257946638 MAE test 2.353215943194043\n",
      "Epoch 9594 / 10000 loss: 11.883912563323975\n",
      "MSE train 4.9186243842124915 MSE test 11.329905047508104\n",
      "MAE train 1.5199809106004376 MAE test 2.3532223468728266\n",
      "Epoch 9595 / 10000 loss: 11.883575439453125\n",
      "MSE train 4.918517130171277 MSE test 11.32963515966591\n",
      "MAE train 1.5199654140591212 MAE test 2.3531871520095367\n",
      "Epoch 9596 / 10000 loss: 11.883156538009644\n",
      "MSE train 4.918408145569979 MSE test 11.329655819234437\n",
      "MAE train 1.5199425739815804 MAE test 2.3531952329513772\n",
      "Epoch 9597 / 10000 loss: 11.882840633392334\n",
      "MSE train 4.918299767574328 MSE test 11.32943137553189\n",
      "MAE train 1.5199259470143902 MAE test 2.3531660998607182\n",
      "Epoch 9598 / 10000 loss: 11.882367849349976\n",
      "MSE train 4.918205061467074 MSE test 11.329422684911625\n",
      "MAE train 1.519907540746561 MAE test 2.3531702466774482\n",
      "Epoch 9599 / 10000 loss: 11.882011890411377\n",
      "MSE train 4.918097745290404 MSE test 11.329146779284082\n",
      "MAE train 1.5198922072710233 MAE test 2.3531342709820002\n",
      "Epoch 9600 / 10000 loss: 11.881614923477173\n",
      "MSE train 4.917984803584909 MSE test 11.329169381579296\n",
      "MAE train 1.519868318815276 MAE test 2.3531426638293014\n",
      "Epoch 9601 / 10000 loss: 11.88130235671997\n",
      "MSE train 4.917876344305478 MSE test 11.328960438737397\n",
      "MAE train 1.5198514219581485 MAE test 2.3531156136620197\n",
      "Epoch 9602 / 10000 loss: 11.8808114528656\n",
      "MSE train 4.91777885508017 MSE test 11.32893398089875\n",
      "MAE train 1.519832769234469 MAE test 2.353117431613869\n",
      "Epoch 9603 / 10000 loss: 11.880443572998047\n",
      "MSE train 4.917670719933197 MSE test 11.328675682121359\n",
      "MAE train 1.5198169713144842 MAE test 2.3530838540069405\n",
      "Epoch 9604 / 10000 loss: 11.880046844482422\n",
      "MSE train 4.917564521814107 MSE test 11.328692876281716\n",
      "MAE train 1.5197951321143695 MAE test 2.3530915423853918\n",
      "Epoch 9605 / 10000 loss: 11.879714965820312\n",
      "MSE train 4.917454523580449 MSE test 11.32844642795931\n",
      "MAE train 1.5197786990937574 MAE test 2.3530595770092404\n",
      "Epoch 9606 / 10000 loss: 11.87925410270691\n",
      "MSE train 4.917353756183514 MSE test 11.32845472439173\n",
      "MAE train 1.5197584888356905 MAE test 2.3530660886359387\n",
      "Epoch 9607 / 10000 loss: 11.87890625\n",
      "MSE train 4.917243455522367 MSE test 11.328185519093108\n",
      "MAE train 1.5197424517850557 MAE test 2.353031118732746\n",
      "Epoch 9608 / 10000 loss: 11.878470420837402\n",
      "MSE train 4.917132190774143 MSE test 11.328204290097064\n",
      "MAE train 1.5197193447210713 MAE test 2.3530390980805262\n",
      "Epoch 9609 / 10000 loss: 11.878138065338135\n",
      "MSE train 4.917020238223438 MSE test 11.327974247336828\n",
      "MAE train 1.5197022098345145 MAE test 2.3530093860687344\n",
      "Epoch 9610 / 10000 loss: 11.877652645111084\n",
      "MSE train 4.916921469824042 MSE test 11.327968063006578\n",
      "MAE train 1.5196830363194738 MAE test 2.3530140547971317\n",
      "Epoch 9611 / 10000 loss: 11.877281904220581\n",
      "MSE train 4.916809761098255 MSE test 11.327689143695618\n",
      "MAE train 1.5196670067892797 MAE test 2.3529778941719863\n",
      "Epoch 9612 / 10000 loss: 11.8768630027771\n",
      "MSE train 4.9166916239422 MSE test 11.327710182622381\n",
      "MAE train 1.519642225306478 MAE test 2.3529863051302478\n",
      "Epoch 9613 / 10000 loss: 11.876529455184937\n",
      "MSE train 4.916578062416896 MSE test 11.32750199170868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5196244576187055 MAE test 2.3529595887280306\n",
      "Epoch 9614 / 10000 loss: 11.876013278961182\n",
      "MSE train 4.916474146286612 MSE test 11.327469830698446\n",
      "MAE train 1.519604769576091 MAE test 2.352960924064958\n",
      "Epoch 9615 / 10000 loss: 11.875617742538452\n",
      "MSE train 4.916359564552684 MSE test 11.32721437153019\n",
      "MAE train 1.5195878213220444 MAE test 2.352928004942794\n",
      "Epoch 9616 / 10000 loss: 11.875191688537598\n",
      "MSE train 4.916248617699711 MSE test 11.327226636310636\n",
      "MAE train 1.5195654639294482 MAE test 2.35293533398309\n",
      "Epoch 9617 / 10000 loss: 11.87482476234436\n",
      "MSE train 4.916131282660529 MSE test 11.326968215389234\n",
      "MAE train 1.5195480020820946 MAE test 2.352902105670202\n",
      "Epoch 9618 / 10000 loss: 11.874338865280151\n",
      "MSE train 4.916018628017857 MSE test 11.32697832700052\n",
      "MAE train 1.5195253827661568 MAE test 2.352909219553941\n",
      "Epoch 9619 / 10000 loss: 11.873960971832275\n",
      "MSE train 4.915899094819686 MSE test 11.326718629835685\n",
      "MAE train 1.5195075333126926 MAE test 2.3528759066519997\n",
      "Epoch 9620 / 10000 loss: 11.873467206954956\n",
      "MSE train 4.915784645134832 MSE test 11.326726807204794\n",
      "MAE train 1.5194846510519622 MAE test 2.3528828456783293\n",
      "Epoch 9621 / 10000 loss: 11.873079299926758\n",
      "MSE train 4.915663138340287 MSE test 11.326464873433487\n",
      "MAE train 1.5194664675440062 MAE test 2.3528492899723763\n",
      "Epoch 9622 / 10000 loss: 11.872577428817749\n",
      "MSE train 4.915546704616237 MSE test 11.326471289577368\n",
      "MAE train 1.5194432159372273 MAE test 2.3528560491066335\n",
      "Epoch 9623 / 10000 loss: 11.872181177139282\n",
      "MSE train 4.915423485472143 MSE test 11.32620773912364\n",
      "MAE train 1.519424793408655 MAE test 2.352822306751678\n",
      "Epoch 9624 / 10000 loss: 11.871669054031372\n",
      "MSE train 4.91530593772853 MSE test 11.326211168905186\n",
      "MAE train 1.5194014511931095 MAE test 2.3528286808715375\n",
      "Epoch 9625 / 10000 loss: 11.871265172958374\n",
      "MSE train 4.915181563012874 MSE test 11.325943512222791\n",
      "MAE train 1.5193828895469192 MAE test 2.3527944179904807\n",
      "Epoch 9626 / 10000 loss: 11.870749950408936\n",
      "MSE train 4.915062528281306 MSE test 11.325944275548936\n",
      "MAE train 1.5193593435173314 MAE test 2.352800457204535\n",
      "Epoch 9627 / 10000 loss: 11.87034296989441\n",
      "MSE train 4.9149373101958425 MSE test 11.325675591796932\n",
      "MAE train 1.5193407210824266 MAE test 2.352766039376655\n",
      "Epoch 9628 / 10000 loss: 11.869821310043335\n",
      "MSE train 4.914818540858168 MSE test 11.325672613079602\n",
      "MAE train 1.5193174076371974 MAE test 2.3527715618894143\n",
      "Epoch 9629 / 10000 loss: 11.869410753250122\n",
      "MSE train 4.914693248896448 MSE test 11.325398068001519\n",
      "MAE train 1.519298945818941 MAE test 2.352736351189769\n",
      "Epoch 9630 / 10000 loss: 11.868892192840576\n",
      "MSE train 4.914573293174242 MSE test 11.325395207026233\n",
      "MAE train 1.5192754119658214 MAE test 2.3527418499160864\n",
      "Epoch 9631 / 10000 loss: 11.868485450744629\n",
      "MSE train 4.914448670178109 MSE test 11.32512578062411\n",
      "MAE train 1.5192570521821045 MAE test 2.3527072680502004\n",
      "Epoch 9632 / 10000 loss: 11.867962837219238\n",
      "MSE train 4.91433292293674 MSE test 11.325120147419172\n",
      "MAE train 1.5192345279003807 MAE test 2.3527123163174144\n",
      "Epoch 9633 / 10000 loss: 11.867557048797607\n",
      "MSE train 4.914211106445007 MSE test 11.32484271600553\n",
      "MAE train 1.5192168180632664 MAE test 2.3526765857763587\n",
      "Epoch 9634 / 10000 loss: 11.867056131362915\n",
      "MSE train 4.914094233615326 MSE test 11.324844949363522\n",
      "MAE train 1.519193616798891 MAE test 2.352682605388613\n",
      "Epoch 9635 / 10000 loss: 11.866671800613403\n",
      "MSE train 4.913975461001954 MSE test 11.324588344958308\n",
      "MAE train 1.519176049594871 MAE test 2.3526495004646395\n",
      "Epoch 9636 / 10000 loss: 11.866167783737183\n",
      "MSE train 4.913868884899025 MSE test 11.32458543668659\n",
      "MAE train 1.5191553368456996 MAE test 2.352654641500525\n",
      "Epoch 9637 / 10000 loss: 11.865784645080566\n",
      "MSE train 4.913753984242908 MSE test 11.32430727214884\n",
      "MAE train 1.5191389171421101 MAE test 2.352618504988488\n",
      "Epoch 9638 / 10000 loss: 11.865330934524536\n",
      "MSE train 4.91363868834534 MSE test 11.324322096867217\n",
      "MAE train 1.5191153668107251 MAE test 2.352625904058186\n",
      "Epoch 9639 / 10000 loss: 11.864987850189209\n",
      "MSE train 4.913525218915597 MSE test 11.324094584479345\n",
      "MAE train 1.5190981876568193 MAE test 2.3525963732223487\n",
      "Epoch 9640 / 10000 loss: 11.86449408531189\n",
      "MSE train 4.913426363842565 MSE test 11.32408354182251\n",
      "MAE train 1.5190793848402675 MAE test 2.352600142637224\n",
      "Epoch 9641 / 10000 loss: 11.864122152328491\n",
      "MSE train 4.913315662391991 MSE test 11.323807991266996\n",
      "MAE train 1.519063720419958 MAE test 2.3525641039015017\n",
      "Epoch 9642 / 10000 loss: 11.863714218139648\n",
      "MSE train 4.913200117741925 MSE test 11.323831618552953\n",
      "MAE train 1.5190396532542796 MAE test 2.3525725052194866\n",
      "Epoch 9643 / 10000 loss: 11.863393783569336\n",
      "MSE train 4.913089474701607 MSE test 11.323624148242583\n",
      "MAE train 1.519022604437645 MAE test 2.3525454571738624\n",
      "Epoch 9644 / 10000 loss: 11.862900018692017\n",
      "MSE train 4.9129906713928495 MSE test 11.323601686976744\n",
      "MAE train 1.519003948160374 MAE test 2.352547598546745\n",
      "Epoch 9645 / 10000 loss: 11.862529039382935\n",
      "MSE train 4.912881580587968 MSE test 11.323345831668384\n",
      "MAE train 1.5189882041799319 MAE test 2.3525141039886006\n",
      "Epoch 9646 / 10000 loss: 11.862133026123047\n",
      "MSE train 4.912774522566181 MSE test 11.323367534551481\n",
      "MAE train 1.5189663513830487 MAE test 2.3525221563964114\n",
      "Epoch 9647 / 10000 loss: 11.86180567741394\n",
      "MSE train 4.912664738671074 MSE test 11.32312797446906\n",
      "MAE train 1.5189500677985166 MAE test 2.3524908193065244\n",
      "Epoch 9648 / 10000 loss: 11.861347913742065\n",
      "MSE train 4.912565763693348 MSE test 11.323139056120235\n",
      "MAE train 1.5189304637042529 MAE test 2.3524974169821276\n",
      "Epoch 9649 / 10000 loss: 11.86100697517395\n",
      "MSE train 4.912457280110722 MSE test 11.322872003957107\n",
      "MAE train 1.5189149611152135 MAE test 2.352462408432345\n",
      "Epoch 9650 / 10000 loss: 11.860587120056152\n",
      "MSE train 4.912347266268422 MSE test 11.322896033465206\n",
      "MAE train 1.5188921152758512 MAE test 2.352470799500007\n",
      "Epoch 9651 / 10000 loss: 11.860272884368896\n",
      "MSE train 4.912238625875019 MSE test 11.322676682255528\n",
      "MAE train 1.5188756053062744 MAE test 2.352442155320769\n",
      "Epoch 9652 / 10000 loss: 11.859800577163696\n",
      "MSE train 4.912144145677609 MSE test 11.322669047663547\n",
      "MAE train 1.51885748826558 MAE test 2.3524462638675625\n",
      "Epoch 9653 / 10000 loss: 11.859447956085205\n",
      "MSE train 4.912037525761749 MSE test 11.322397139784371\n",
      "MAE train 1.5188424193620265 MAE test 2.3524106348128977\n",
      "Epoch 9654 / 10000 loss: 11.859060049057007\n",
      "MSE train 4.911926346845464 MSE test 11.322422017991206\n",
      "MAE train 1.518819070678509 MAE test 2.352419176543289\n",
      "Epoch 9655 / 10000 loss: 11.858756303787231\n",
      "MSE train 4.911819424712229 MSE test 11.322212807268956\n",
      "MAE train 1.518802622928752 MAE test 2.352391905020837\n",
      "Epoch 9656 / 10000 loss: 11.85827898979187\n",
      "MSE train 4.911724719471847 MSE test 11.32219168260965\n",
      "MAE train 1.5187845814105825 MAE test 2.352394253969062\n",
      "Epoch 9657 / 10000 loss: 11.857925176620483\n",
      "MSE train 4.911619302084264 MSE test 11.321931254607795\n",
      "MAE train 1.5187694615171392 MAE test 2.3523601833733028\n",
      "Epoch 9658 / 10000 loss: 11.857544898986816\n",
      "MSE train 4.911514514691281 MSE test 11.321951504641437\n",
      "MAE train 1.5187478159315522 MAE test 2.3523681067990725\n",
      "Epoch 9659 / 10000 loss: 11.857235670089722\n",
      "MSE train 4.911408047510799 MSE test 11.321715151211365\n",
      "MAE train 1.518731946893161 MAE test 2.3523372609570394\n",
      "Epoch 9660 / 10000 loss: 11.856786251068115\n",
      "MSE train 4.911313856590171 MSE test 11.321719037593407\n",
      "MAE train 1.5187133532738075 MAE test 2.352342963644236\n",
      "Epoch 9661 / 10000 loss: 11.856454610824585\n",
      "MSE train 4.911208687038458 MSE test 11.321444480462738\n",
      "MAE train 1.518698452914827 MAE test 2.3523070346113473\n",
      "Epoch 9662 / 10000 loss: 11.85605788230896\n",
      "MSE train 4.911099319375395 MSE test 11.32146701024859\n",
      "MAE train 1.5186753865533205 MAE test 2.35231531501989\n",
      "Epoch 9663 / 10000 loss: 11.855761051177979\n",
      "MSE train 4.910993773782559 MSE test 11.321255583939042\n",
      "MAE train 1.5186591314236833 MAE test 2.352287782159805\n",
      "Epoch 9664 / 10000 loss: 11.855291366577148\n",
      "MSE train 4.910900503843487 MSE test 11.32123297366725\n",
      "MAE train 1.5186412930609818 MAE test 2.3522899790537677\n",
      "Epoch 9665 / 10000 loss: 11.854943752288818\n",
      "MSE train 4.910796299815124 MSE test 11.320970717827656\n",
      "MAE train 1.5186263284378871 MAE test 2.352255688253631\n",
      "Epoch 9666 / 10000 loss: 11.854569673538208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.910692438967519 MSE test 11.320989913979242\n",
      "MAE train 1.5186047705756442 MAE test 2.3522635108344074\n",
      "Epoch 9667 / 10000 loss: 11.854265451431274\n",
      "MSE train 4.910586904967886 MSE test 11.320752991505767\n",
      "MAE train 1.5185889886588866 MAE test 2.352232615138884\n",
      "Epoch 9668 / 10000 loss: 11.853819608688354\n",
      "MSE train 4.9104937287430594 MSE test 11.320755515231744\n",
      "MAE train 1.5185705483604963 MAE test 2.352238153127053\n",
      "Epoch 9669 / 10000 loss: 11.853492259979248\n",
      "MSE train 4.910389332758344 MSE test 11.320479863292231\n",
      "MAE train 1.518555734790396 MAE test 2.3522021070371792\n",
      "Epoch 9670 / 10000 loss: 11.853099346160889\n",
      "MSE train 4.910280450055291 MSE test 11.320501870848448\n",
      "MAE train 1.5185326999916604 MAE test 2.352210312078688\n",
      "Epoch 9671 / 10000 loss: 11.852805137634277\n",
      "MSE train 4.910175560031051 MSE test 11.320290836305505\n",
      "MAE train 1.5185165021783982 MAE test 2.3521828545830523\n",
      "Epoch 9672 / 10000 loss: 11.852338075637817\n",
      "MSE train 4.910082608647299 MSE test 11.320266983363174\n",
      "MAE train 1.5184986946699963 MAE test 2.35218489661567\n",
      "Epoch 9673 / 10000 loss: 11.851992845535278\n",
      "MSE train 4.909978838318257 MSE test 11.320005785031476\n",
      "MAE train 1.5184837309827994 MAE test 2.3521507569380495\n",
      "Epoch 9674 / 10000 loss: 11.851620435714722\n",
      "MSE train 4.909875986465674 MSE test 11.320024468294722\n",
      "MAE train 1.5184623853079025 MAE test 2.3521585131666796\n",
      "Epoch 9675 / 10000 loss: 11.851316690444946\n",
      "MSE train 4.909770854587344 MSE test 11.319784876845675\n",
      "MAE train 1.5184466806213746 MAE test 2.352127262922767\n",
      "Epoch 9676 / 10000 loss: 11.850875854492188\n",
      "MSE train 4.909677365702506 MSE test 11.319789381395111\n",
      "MAE train 1.5184280589532417 MAE test 2.352133080439938\n",
      "Epoch 9677 / 10000 loss: 11.850550651550293\n",
      "MSE train 4.909573172046382 MSE test 11.319515571360522\n",
      "MAE train 1.5184131952895286 MAE test 2.352097276491359\n",
      "Epoch 9678 / 10000 loss: 11.85015606880188\n",
      "MSE train 4.909465392161608 MSE test 11.319537200617694\n",
      "MAE train 1.518390425534892 MAE test 2.3521054424284547\n",
      "Epoch 9679 / 10000 loss: 11.84986138343811\n",
      "MSE train 4.9093604973840685 MSE test 11.319322292667175\n",
      "MAE train 1.5183742617923879 MAE test 2.3520774517616543\n",
      "Epoch 9680 / 10000 loss: 11.849398851394653\n",
      "MSE train 4.909268523482329 MSE test 11.31930350849597\n",
      "MAE train 1.518356562721208 MAE test 2.35208016236721\n",
      "Epoch 9681 / 10000 loss: 11.849056482315063\n",
      "MSE train 4.909164923626854 MSE test 11.319036583998805\n",
      "MAE train 1.518341711039081 MAE test 2.3520452589935936\n",
      "Epoch 9682 / 10000 loss: 11.848684549331665\n",
      "MSE train 4.909059576097753 MSE test 11.31905746618042\n",
      "MAE train 1.5183196145539133 MAE test 2.352053305824411\n",
      "Epoch 9683 / 10000 loss: 11.848386526107788\n",
      "MSE train 4.908954511112813 MSE test 11.318830662653111\n",
      "MAE train 1.518303633661522 MAE test 2.3520237496265604\n",
      "Epoch 9684 / 10000 loss: 11.847933530807495\n",
      "MSE train 4.908863174272718 MSE test 11.318825156539766\n",
      "MAE train 1.5182858022671102 MAE test 2.35202821822594\n",
      "Epoch 9685 / 10000 loss: 11.847599983215332\n",
      "MSE train 4.908759497077712 MSE test 11.318548850745703\n",
      "MAE train 1.5182710974226887 MAE test 2.3519920549681927\n",
      "Epoch 9686 / 10000 loss: 11.847221612930298\n",
      "MSE train 4.908650121817866 MSE test 11.318571970502953\n",
      "MAE train 1.5182478484148827 MAE test 2.3520004279947635\n",
      "Epoch 9687 / 10000 loss: 11.846930980682373\n",
      "MSE train 4.90854581990302 MSE test 11.318365923749937\n",
      "MAE train 1.5182316417413635 MAE test 2.351973614956491\n",
      "Epoch 9688 / 10000 loss: 11.846461534500122\n",
      "MSE train 4.9084522563483475 MSE test 11.318337580423464\n",
      "MAE train 1.5182137234150062 MAE test 2.3519750574726204\n",
      "Epoch 9689 / 10000 loss: 11.846115589141846\n",
      "MSE train 4.908348688313945 MSE test 11.318084445729028\n",
      "MAE train 1.5181986216982122 MAE test 2.3519419692063144\n",
      "Epoch 9690 / 10000 loss: 11.84574294090271\n",
      "MSE train 4.908249160726744 MSE test 11.318100830523887\n",
      "MAE train 1.5181781724195118 MAE test 2.351949396930034\n",
      "Epoch 9691 / 10000 loss: 11.845434427261353\n",
      "MSE train 4.908144565391037 MSE test 11.317848967255697\n",
      "MAE train 1.5181627999964302 MAE test 2.351916499329579\n",
      "Epoch 9692 / 10000 loss: 11.845009326934814\n",
      "MSE train 4.908046705497994 MSE test 11.31786289983313\n",
      "MAE train 1.5181428144301425 MAE test 2.3519235778532197\n",
      "Epoch 9693 / 10000 loss: 11.844696283340454\n",
      "MSE train 4.9079420462970775 MSE test 11.317605504313663\n",
      "MAE train 1.5181275127265252 MAE test 2.3518899365979133\n",
      "Epoch 9694 / 10000 loss: 11.84427809715271\n",
      "MSE train 4.90784203787942 MSE test 11.317621800191196\n",
      "MAE train 1.5181069229865936 MAE test 2.351897337794331\n",
      "Epoch 9695 / 10000 loss: 11.843969583511353\n",
      "MSE train 4.907737102321554 MSE test 11.317373474564551\n",
      "MAE train 1.5180913978899107 MAE test 2.3518649003088603\n",
      "Epoch 9696 / 10000 loss: 11.843541383743286\n",
      "MSE train 4.907640830498922 MSE test 11.317385001896131\n",
      "MAE train 1.5180718713370152 MAE test 2.3518716462295544\n",
      "Epoch 9697 / 10000 loss: 11.843224287033081\n",
      "MSE train 4.907536304907306 MSE test 11.317122139363391\n",
      "MAE train 1.5180566955948251 MAE test 2.351837268754847\n",
      "Epoch 9698 / 10000 loss: 11.842813968658447\n",
      "MSE train 4.907433694847435 MSE test 11.317140999681696\n",
      "MAE train 1.5180353645508966 MAE test 2.3518450162493383\n",
      "Epoch 9699 / 10000 loss: 11.84251093864441\n",
      "MSE train 4.907328593660186 MSE test 11.316903673744614\n",
      "MAE train 1.5180195806316052 MAE test 2.3518140397588883\n",
      "Epoch 9700 / 10000 loss: 11.842070817947388\n",
      "MSE train 4.907235762599913 MSE test 11.316907861164653\n",
      "MAE train 1.5180011164667175 MAE test 2.351819798980973\n",
      "Epoch 9701 / 10000 loss: 11.841744422912598\n",
      "MSE train 4.907131729750705 MSE test 11.316634146943414\n",
      "MAE train 1.5179862624676668 MAE test 2.35178396715457\n",
      "Epoch 9702 / 10000 loss: 11.841352462768555\n",
      "MSE train 4.907023689997454 MSE test 11.316657026728889\n",
      "MAE train 1.5179633773587768 MAE test 2.351792289863466\n",
      "Epoch 9703 / 10000 loss: 11.841060161590576\n",
      "MSE train 4.906919037960485 MSE test 11.316445212340676\n",
      "MAE train 1.5179471874268076 MAE test 2.351764696055812\n",
      "Epoch 9704 / 10000 loss: 11.84059476852417\n",
      "MSE train 4.906826822448921 MSE test 11.31642496888433\n",
      "MAE train 1.5179294538199006 MAE test 2.35176718724573\n",
      "Epoch 9705 / 10000 loss: 11.840252876281738\n",
      "MSE train 4.906723325930661 MSE test 11.316162160939058\n",
      "MAE train 1.517914533267281 MAE test 2.3517328001053737\n",
      "Epoch 9706 / 10000 loss: 11.839881658554077\n",
      "MSE train 4.906619406716389 MSE test 11.316183079051436\n",
      "MAE train 1.5178928159136935 MAE test 2.3517408419342782\n",
      "Epoch 9707 / 10000 loss: 11.83958125114441\n",
      "MSE train 4.906514374753431 MSE test 11.315950884433343\n",
      "MAE train 1.5178769511713885 MAE test 2.351710536234928\n",
      "Epoch 9708 / 10000 loss: 11.839134931564331\n",
      "MSE train 4.906422382797092 MSE test 11.31595189365631\n",
      "MAE train 1.517858788250339 MAE test 2.351715868195646\n",
      "Epoch 9709 / 10000 loss: 11.838805913925171\n",
      "MSE train 4.906318537077883 MSE test 11.315676561762247\n",
      "MAE train 1.517844010018107 MAE test 2.351679814764234\n",
      "Epoch 9710 / 10000 loss: 11.838419914245605\n",
      "MSE train 4.906209384690844 MSE test 11.315700300630068\n",
      "MAE train 1.5178208101815036 MAE test 2.351688252486954\n",
      "Epoch 9711 / 10000 loss: 11.838129043579102\n",
      "MSE train 4.906105065473424 MSE test 11.315494193064799\n",
      "MAE train 1.5178045772677735 MAE test 2.351661408587389\n",
      "Epoch 9712 / 10000 loss: 11.837660789489746\n",
      "MSE train 4.906011630800208 MSE test 11.315467593803927\n",
      "MAE train 1.5177866674167635 MAE test 2.3516630693313454\n",
      "Epoch 9713 / 10000 loss: 11.837314367294312\n",
      "MSE train 4.9059079865085184 MSE test 11.315213853859845\n",
      "MAE train 1.517771556391987 MAE test 2.351629886775797\n",
      "Epoch 9714 / 10000 loss: 11.836943626403809\n",
      "MSE train 4.905807785185683 MSE test 11.315231521450439\n",
      "MAE train 1.5177509113656904 MAE test 2.3516374645886033\n",
      "Epoch 9715 / 10000 loss: 11.83663558959961\n",
      "MSE train 4.905703026962411 MSE test 11.314983019301042\n",
      "MAE train 1.5177354263575837 MAE test 2.3516049929450085\n",
      "Epoch 9716 / 10000 loss: 11.836206912994385\n",
      "MSE train 4.90560607360768 MSE test 11.314995900143083\n",
      "MAE train 1.5177157053218004 MAE test 2.351611920811884\n",
      "Epoch 9717 / 10000 loss: 11.835891246795654\n",
      "MSE train 4.905501450202813 MSE test 11.314735609284918\n",
      "MAE train 1.5177004521555035 MAE test 2.3515778652857096\n",
      "Epoch 9718 / 10000 loss: 11.835477828979492\n",
      "MSE train 4.905399523560766 MSE test 11.314754131152522\n",
      "MAE train 1.5176793149329786 MAE test 2.351585574172753\n",
      "Epoch 9719 / 10000 loss: 11.835172176361084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.905294285960898 MSE test 11.314513836421632\n",
      "MAE train 1.5176635617695056 MAE test 2.3515541783442258\n",
      "Epoch 9720 / 10000 loss: 11.83473539352417\n",
      "MSE train 4.90520031797825 MSE test 11.314520943107688\n",
      "MAE train 1.5176447433109748 MAE test 2.3515603245242613\n",
      "Epoch 9721 / 10000 loss: 11.834410905838013\n",
      "MSE train 4.905095932330699 MSE test 11.314250366270423\n",
      "MAE train 1.5176297355533985 MAE test 2.3515248909754587\n",
      "Epoch 9722 / 10000 loss: 11.83401346206665\n",
      "MSE train 4.904989060842669 MSE test 11.314272619084067\n",
      "MAE train 1.517607189824948 MAE test 2.351533118201084\n",
      "Epoch 9723 / 10000 loss: 11.833717346191406\n",
      "MSE train 4.904883897961205 MSE test 11.314054685842816\n",
      "MAE train 1.5175909929385223 MAE test 2.3515046961435675\n",
      "Epoch 9724 / 10000 loss: 11.833257913589478\n",
      "MSE train 4.904792270762343 MSE test 11.314042180514937\n",
      "MAE train 1.5175732573791694 MAE test 2.3515082140179353\n",
      "Epoch 9725 / 10000 loss: 11.832918167114258\n",
      "MSE train 4.904688400593776 MSE test 11.313771884778347\n",
      "MAE train 1.5175583727247217 MAE test 2.3514728029618204\n",
      "Epoch 9726 / 10000 loss: 11.832544088363647\n",
      "MSE train 4.904580821957453 MSE test 11.313795123608545\n",
      "MAE train 1.5175356233240396 MAE test 2.351481173563769\n",
      "Epoch 9727 / 10000 loss: 11.83224892616272\n",
      "MSE train 4.90447565693407 MSE test 11.313579583808698\n",
      "MAE train 1.5175193915208862 MAE test 2.351453057799089\n",
      "Epoch 9728 / 10000 loss: 11.831787109375\n",
      "MSE train 4.904383688366244 MSE test 11.313564870921905\n",
      "MAE train 1.5175016164643167 MAE test 2.351456300121981\n",
      "Epoch 9729 / 10000 loss: 11.831444501876831\n",
      "MSE train 4.904279752871365 MSE test 11.313296750313764\n",
      "MAE train 1.517486677082458 MAE test 2.351421169524132\n",
      "Epoch 9730 / 10000 loss: 11.831070184707642\n",
      "MSE train 4.90417290811615 MSE test 11.313319610816295\n",
      "MAE train 1.5174641537757017 MAE test 2.3514294857696894\n",
      "Epoch 9731 / 10000 loss: 11.83077359199524\n",
      "MSE train 4.904067455303833 MSE test 11.313099611685784\n",
      "MAE train 1.5174479310492033 MAE test 2.3514007865931252\n",
      "Epoch 9732 / 10000 loss: 11.830315351486206\n",
      "MSE train 4.903975668499674 MSE test 11.313089787746245\n",
      "MAE train 1.5174301018486138 MAE test 2.351404658221406\n",
      "Epoch 9733 / 10000 loss: 11.829975366592407\n",
      "MSE train 4.903871462318371 MSE test 11.312817612306864\n",
      "MAE train 1.517415175499849 MAE test 2.35136899657962\n",
      "Epoch 9734 / 10000 loss: 11.829598903656006\n",
      "MSE train 4.903762630695739 MSE test 11.31284131589735\n",
      "MAE train 1.5173921038034366 MAE test 2.3513774353207806\n",
      "Epoch 9735 / 10000 loss: 11.82930326461792\n",
      "MSE train 4.903657307817754 MSE test 11.312630285503104\n",
      "MAE train 1.5173757439136089 MAE test 2.351349928698833\n",
      "Epoch 9736 / 10000 loss: 11.828836441040039\n",
      "MSE train 4.903564298062501 MSE test 11.312610343513024\n",
      "MAE train 1.5173578250498265 MAE test 2.3513524452666275\n",
      "Epoch 9737 / 10000 loss: 11.828490495681763\n",
      "MSE train 4.903459926550438 MSE test 11.312348197687806\n",
      "MAE train 1.5173426846171785 MAE test 2.351318108979094\n",
      "Epoch 9738 / 10000 loss: 11.828116655349731\n",
      "MSE train 4.903355121825159 MSE test 11.312369231590859\n",
      "MAE train 1.5173207664036452 MAE test 2.3513261693464473\n",
      "Epoch 9739 / 10000 loss: 11.827812671661377\n",
      "MSE train 4.903249133983655 MSE test 11.312137503393398\n",
      "MAE train 1.5173046675833008 MAE test 2.351295902428719\n",
      "Epoch 9740 / 10000 loss: 11.82736349105835\n",
      "MSE train 4.903156083805619 MSE test 11.312138690949988\n",
      "MAE train 1.5172862592524916 MAE test 2.3513012467769485\n",
      "Epoch 9741 / 10000 loss: 11.827030181884766\n",
      "MSE train 4.903051022363885 MSE test 11.311863856546344\n",
      "MAE train 1.5172711796277358 MAE test 2.3512652199767157\n",
      "Epoch 9742 / 10000 loss: 11.826640605926514\n",
      "MSE train 4.902940752132433 MSE test 11.31188764222819\n",
      "MAE train 1.5172477244070743 MAE test 2.35127368410381\n",
      "Epoch 9743 / 10000 loss: 11.826345205307007\n",
      "MSE train 4.902835044795984 MSE test 11.311681274057396\n",
      "MAE train 1.5172311765717272 MAE test 2.3512467823971686\n",
      "Epoch 9744 / 10000 loss: 11.825872659683228\n",
      "MSE train 4.902740347894485 MSE test 11.311655295112692\n",
      "MAE train 1.5172129627938098 MAE test 2.3512485186795864\n",
      "Epoch 9745 / 10000 loss: 11.82552170753479\n",
      "MSE train 4.902635198565715 MSE test 11.31140113606214\n",
      "MAE train 1.5171974931551744 MAE test 2.351215245359907\n",
      "Epoch 9746 / 10000 loss: 11.82514476776123\n",
      "MSE train 4.902533282539851 MSE test 11.31141919626381\n",
      "MAE train 1.5171764290160792 MAE test 2.3512228925199468\n",
      "Epoch 9747 / 10000 loss: 11.824830532073975\n",
      "MSE train 4.90242682538302 MSE test 11.311171829950379\n",
      "MAE train 1.5171605120843008 MAE test 2.3511905420814543\n",
      "Epoch 9748 / 10000 loss: 11.824395418167114\n",
      "MSE train 4.902328600897088 MSE test 11.31118408366061\n",
      "MAE train 1.517140507102595 MAE test 2.35119739113591\n",
      "Epoch 9749 / 10000 loss: 11.824072360992432\n",
      "MSE train 4.90222218945583 MSE test 11.310922329384319\n",
      "MAE train 1.5171248319427335 MAE test 2.35116312885606\n",
      "Epoch 9750 / 10000 loss: 11.823655128479004\n",
      "MSE train 4.902117738464349 MSE test 11.310941335983898\n",
      "MAE train 1.5171030488164514 MAE test 2.3511708996280754\n",
      "Epoch 9751 / 10000 loss: 11.823342323303223\n",
      "MSE train 4.902010476780309 MSE test 11.310704172259042\n",
      "MAE train 1.5170867463452111 MAE test 2.3511399090397256\n",
      "Epoch 9752 / 10000 loss: 11.822895288467407\n",
      "MSE train 4.901915351661386 MSE test 11.310708973344283\n",
      "MAE train 1.517067710314629 MAE test 2.35114574513047\n",
      "Epoch 9753 / 10000 loss: 11.822561502456665\n",
      "MSE train 4.9018090281835685 MSE test 11.31043626269506\n",
      "MAE train 1.517052259862319 MAE test 2.351110000938041\n",
      "Epoch 9754 / 10000 loss: 11.822161436080933\n",
      "MSE train 4.901699010325354 MSE test 11.31045899355777\n",
      "MAE train 1.517028891119619 MAE test 2.3511183220017573\n",
      "Epoch 9755 / 10000 loss: 11.821859121322632\n",
      "MSE train 4.901591954867337 MSE test 11.310246548641164\n",
      "MAE train 1.517012123778815 MAE test 2.3510906055109873\n",
      "Epoch 9756 / 10000 loss: 11.82138705253601\n",
      "MSE train 4.901497748007481 MSE test 11.310227538704215\n",
      "MAE train 1.5169938516974963 MAE test 2.3510932679835763\n",
      "Epoch 9757 / 10000 loss: 11.821035385131836\n",
      "MSE train 4.901391840952766 MSE test 11.30996387435669\n",
      "MAE train 1.5169783449407377 MAE test 2.3510587279740713\n",
      "Epoch 9758 / 10000 loss: 11.820653915405273\n",
      "MSE train 4.90128524730461 MSE test 11.309985154774557\n",
      "MAE train 1.516955936106687 MAE test 2.3510668344967156\n",
      "Epoch 9759 / 10000 loss: 11.820346117019653\n",
      "MSE train 4.901178072184421 MSE test 11.309755928829329\n",
      "MAE train 1.5169394575683077 MAE test 2.3510368953233938\n",
      "Epoch 9760 / 10000 loss: 11.819889545440674\n",
      "MSE train 4.90108450198653 MSE test 11.309754569480551\n",
      "MAE train 1.5169209413644762 MAE test 2.35104190589872\n",
      "Epoch 9761 / 10000 loss: 11.819549322128296\n",
      "MSE train 4.900978836404557 MSE test 11.309479308700654\n",
      "MAE train 1.5169056752878554 MAE test 2.3510058239079767\n",
      "Epoch 9762 / 10000 loss: 11.819158554077148\n",
      "MSE train 4.900867915584748 MSE test 11.309503190360937\n",
      "MAE train 1.5168819954212622 MAE test 2.351014310141401\n",
      "Epoch 9763 / 10000 loss: 11.818861722946167\n",
      "MSE train 4.900762172124882 MSE test 11.309297894832417\n",
      "MAE train 1.5168653491303097 MAE test 2.350987544743803\n",
      "Epoch 9764 / 10000 loss: 11.818385601043701\n",
      "MSE train 4.900667289273857 MSE test 11.309270503668714\n",
      "MAE train 1.516847047616246 MAE test 2.3509891097643516\n",
      "Epoch 9765 / 10000 loss: 11.818033218383789\n",
      "MSE train 4.900562544454691 MSE test 11.309018474527823\n",
      "MAE train 1.516831581324689 MAE test 2.3509561272869077\n",
      "Epoch 9766 / 10000 loss: 11.81765627861023\n",
      "MSE train 4.900462303380397 MSE test 11.309035454485334\n",
      "MAE train 1.5168108940228817 MAE test 2.350963631542352\n",
      "Epoch 9767 / 10000 loss: 11.817342758178711\n",
      "MSE train 4.900356948549866 MSE test 11.3087844426692\n",
      "MAE train 1.516795247861838 MAE test 2.350930802924809\n",
      "Epoch 9768 / 10000 loss: 11.816914796829224\n",
      "MSE train 4.900258575508675 MSE test 11.308799159171318\n",
      "MAE train 1.516775054924107 MAE test 2.350937999348033\n",
      "Epoch 9769 / 10000 loss: 11.816598415374756\n",
      "MSE train 4.900153612288051 MSE test 11.308543324715275\n",
      "MAE train 1.516759560663942 MAE test 2.3509045154087986\n",
      "Epoch 9770 / 10000 loss: 11.8161780834198\n",
      "MSE train 4.9000537001857705 MSE test 11.308559975672676\n",
      "MAE train 1.5167389039222734 MAE test 2.3509119801472727\n",
      "Epoch 9771 / 10000 loss: 11.81586766242981\n",
      "MSE train 4.899948754015362 MSE test 11.308312203798325\n",
      "MAE train 1.5167232857909265 MAE test 2.3508795849496167\n",
      "Epoch 9772 / 10000 loss: 11.815439939498901\n",
      "MSE train 4.899852470101137 MSE test 11.308324588139289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5167036656058315 MAE test 2.3508864591968357\n",
      "Epoch 9773 / 10000 loss: 11.815123319625854\n",
      "MSE train 4.899748213770757 MSE test 11.308063831336389\n",
      "MAE train 1.516688424059673 MAE test 2.3508523270066695\n",
      "Epoch 9774 / 10000 loss: 11.814711809158325\n",
      "MSE train 4.899646451289072 MSE test 11.30808292880635\n",
      "MAE train 1.5166672253448696 MAE test 2.3508601300459255\n",
      "Epoch 9775 / 10000 loss: 11.81440806388855\n",
      "MSE train 4.899541836347436 MSE test 11.307845004833275\n",
      "MAE train 1.516651484655855 MAE test 2.350829041480466\n",
      "Epoch 9776 / 10000 loss: 11.813971519470215\n",
      "MSE train 4.899449100397675 MSE test 11.307851138106228\n",
      "MAE train 1.5166329172661344 MAE test 2.350835072308687\n",
      "Epoch 9777 / 10000 loss: 11.813647747039795\n",
      "MSE train 4.8993456056892075 MSE test 11.307579861638503\n",
      "MAE train 1.5166180430132998 MAE test 2.350799520402162\n",
      "Epoch 9778 / 10000 loss: 11.813255548477173\n",
      "MSE train 4.899239017767621 MSE test 11.307602984092178\n",
      "MAE train 1.5165954474538044 MAE test 2.350807900660884\n",
      "Epoch 9779 / 10000 loss: 11.812962055206299\n",
      "MSE train 4.8991349277836065 MSE test 11.307388772915656\n",
      "MAE train 1.5165793645951282 MAE test 2.3507799603858692\n",
      "Epoch 9780 / 10000 loss: 11.812503814697266\n",
      "MSE train 4.899044001594481 MSE test 11.30737314478407\n",
      "MAE train 1.5165617757022378 MAE test 2.350783089183684\n",
      "Epoch 9781 / 10000 loss: 11.812165021896362\n",
      "MSE train 4.89894125390665 MSE test 11.30710720587001\n",
      "MAE train 1.5165469937550526 MAE test 2.35074824982535\n",
      "Epoch 9782 / 10000 loss: 11.811795473098755\n",
      "MSE train 4.898836404700376 MSE test 11.307129871027506\n",
      "MAE train 1.5165248814876908 MAE test 2.35075656143048\n",
      "Epoch 9783 / 10000 loss: 11.811501026153564\n",
      "MSE train 4.89873224414448 MSE test 11.306907503238014\n",
      "MAE train 1.5165089418504583 MAE test 2.3507275345812824\n",
      "Epoch 9784 / 10000 loss: 11.811049699783325\n",
      "MSE train 4.898641976179915 MSE test 11.306901144440674\n",
      "MAE train 1.5164913064564804 MAE test 2.350731898649351\n",
      "Epoch 9785 / 10000 loss: 11.81071662902832\n",
      "MSE train 4.898539230175361 MSE test 11.306628180423683\n",
      "MAE train 1.5164766490074073 MAE test 2.350696118717911\n",
      "Epoch 9786 / 10000 loss: 11.810342788696289\n",
      "MSE train 4.898431436308332 MSE test 11.306652458092273\n",
      "MAE train 1.5164536958271506 MAE test 2.350704653474473\n",
      "Epoch 9787 / 10000 loss: 11.810054063796997\n",
      "MSE train 4.898327921460183 MSE test 11.306445614275702\n",
      "MAE train 1.5164376008316087 MAE test 2.350677695631088\n",
      "Epoch 9788 / 10000 loss: 11.809589862823486\n",
      "MSE train 4.898235968210565 MSE test 11.30642211763583\n",
      "MAE train 1.5164199064837223 MAE test 2.350679771098579\n",
      "Epoch 9789 / 10000 loss: 11.809247493743896\n",
      "MSE train 4.898133314090533 MSE test 11.30616640650933\n",
      "MAE train 1.5164049723466666 MAE test 2.3506462973486797\n",
      "Epoch 9790 / 10000 loss: 11.808879137039185\n",
      "MSE train 4.898032976056551 MSE test 11.306185985520633\n",
      "MAE train 1.5163841408877308 MAE test 2.350654167311258\n",
      "Epoch 9791 / 10000 loss: 11.808576822280884\n",
      "MSE train 4.897929092595569 MSE test 11.305943929413722\n",
      "MAE train 1.516368657711178 MAE test 2.350622524493347\n",
      "Epoch 9792 / 10000 loss: 11.808145999908447\n",
      "MSE train 4.8978353214298656 MSE test 11.30595414914405\n",
      "MAE train 1.5163497248184634 MAE test 2.3506291061378692\n",
      "Epoch 9793 / 10000 loss: 11.807828664779663\n",
      "MSE train 4.8977320088277025 MSE test 11.30568780097149\n",
      "MAE train 1.516334798132077 MAE test 2.350594213012564\n",
      "Epoch 9794 / 10000 loss: 11.807429313659668\n",
      "MSE train 4.897627919240557 MSE test 11.30570975971277\n",
      "MAE train 1.5163128891789035 MAE test 2.3506024122703932\n",
      "Epoch 9795 / 10000 loss: 11.807133913040161\n",
      "MSE train 4.897523829385021 MSE test 11.305485630733143\n",
      "MAE train 1.51629698969224 MAE test 2.3505731575820206\n",
      "Epoch 9796 / 10000 loss: 11.80668592453003\n",
      "MSE train 4.897433615835651 MSE test 11.305480777098115\n",
      "MAE train 1.516279333840282 MAE test 2.3505777062932203\n",
      "Epoch 9797 / 10000 loss: 11.80635404586792\n",
      "MSE train 4.897330893684664 MSE test 11.305207434420716\n",
      "MAE train 1.5162646797227353 MAE test 2.3505418656535646\n",
      "Epoch 9798 / 10000 loss: 11.805979490280151\n",
      "MSE train 4.897223059919205 MSE test 11.3052319255611\n",
      "MAE train 1.5162417009483733 MAE test 2.350550434447084\n",
      "Epoch 9799 / 10000 loss: 11.805691003799438\n",
      "MSE train 4.897119723384451 MSE test 11.305026238772628\n",
      "MAE train 1.5162256201729323 MAE test 2.3505236314924924\n",
      "Epoch 9800 / 10000 loss: 11.805227279663086\n",
      "MSE train 4.897027650908568 MSE test 11.305001687918203\n",
      "MAE train 1.5162079095214611 MAE test 2.3505255611728137\n",
      "Epoch 9801 / 10000 loss: 11.804885149002075\n",
      "MSE train 4.896925026898342 MSE test 11.304747826285078\n",
      "MAE train 1.5161929511877705 MAE test 2.350492330284849\n",
      "Epoch 9802 / 10000 loss: 11.804517030715942\n",
      "MSE train 4.896825523231982 MSE test 11.304766811905008\n",
      "MAE train 1.5161723399645872 MAE test 2.3505001103830643\n",
      "Epoch 9803 / 10000 loss: 11.804213047027588\n",
      "MSE train 4.896721832065974 MSE test 11.304522083939842\n",
      "MAE train 1.5161569486515465 MAE test 2.350468110321895\n",
      "Epoch 9804 / 10000 loss: 11.803786039352417\n",
      "MSE train 4.896627082720103 MSE test 11.304534140610707\n",
      "MAE train 1.5161377100590656 MAE test 2.3504749383195036\n",
      "Epoch 9805 / 10000 loss: 11.803471326828003\n",
      "MSE train 4.896523678106439 MSE test 11.304271847786843\n",
      "MAE train 1.5161226879798366 MAE test 2.3504405961921058\n",
      "Epoch 9806 / 10000 loss: 11.803067207336426\n",
      "MSE train 4.896421437544083 MSE test 11.304292553647711\n",
      "MAE train 1.5161012964657965 MAE test 2.350448618885043\n",
      "Epoch 9807 / 10000 loss: 11.802767992019653\n",
      "MSE train 4.896317356461409 MSE test 11.304060475387471\n",
      "MAE train 1.5160855597468392 MAE test 2.3504183110389576\n",
      "Epoch 9808 / 10000 loss: 11.802327394485474\n",
      "MSE train 4.896226347131126 MSE test 11.30406289943802\n",
      "MAE train 1.5160675081288673 MAE test 2.350423826332534\n",
      "Epoch 9809 / 10000 loss: 11.802002668380737\n",
      "MSE train 4.896123433399923 MSE test 11.303789825166332\n",
      "MAE train 1.5160528036072676 MAE test 2.350388035842152\n",
      "Epoch 9810 / 10000 loss: 11.801619529724121\n",
      "MSE train 4.896015916670049 MSE test 11.303814147803044\n",
      "MAE train 1.5160299117489697 MAE test 2.3503965853675366\n",
      "Epoch 9811 / 10000 loss: 11.801331043243408\n",
      "MSE train 4.895912545600001 MSE test 11.303607440866616\n",
      "MAE train 1.5160138319185454 MAE test 2.350369637747437\n",
      "Epoch 9812 / 10000 loss: 11.800868034362793\n",
      "MSE train 4.89582075940315 MSE test 11.303584181052589\n",
      "MAE train 1.5159961639184514 MAE test 2.350371741401155\n",
      "Epoch 9813 / 10000 loss: 11.80052638053894\n",
      "MSE train 4.895718269861393 MSE test 11.303328737549778\n",
      "MAE train 1.5159812515494604 MAE test 2.3503383074934505\n",
      "Epoch 9814 / 10000 loss: 11.800158739089966\n",
      "MSE train 4.895618056684856 MSE test 11.303348629820608\n",
      "MAE train 1.5159604376925762 MAE test 2.350346219567396\n",
      "Epoch 9815 / 10000 loss: 11.799856901168823\n",
      "MSE train 4.895514289653481 MSE test 11.303107031779271\n",
      "MAE train 1.51594497233574 MAE test 2.350314629676938\n",
      "Epoch 9816 / 10000 loss: 11.799426555633545\n",
      "MSE train 4.895420699478817 MSE test 11.303117388065846\n",
      "MAE train 1.5159260668238472 MAE test 2.3503212342194866\n",
      "Epoch 9817 / 10000 loss: 11.79910945892334\n",
      "MSE train 4.895317518622239 MSE test 11.302851545655738\n",
      "MAE train 1.515911156792899 MAE test 2.350286415501733\n",
      "Epoch 9818 / 10000 loss: 11.79871129989624\n",
      "MSE train 4.895213582298522 MSE test 11.302873569704596\n",
      "MAE train 1.5158892692935853 MAE test 2.3502946332655994\n",
      "Epoch 9819 / 10000 loss: 11.798415899276733\n",
      "MSE train 4.895109587443196 MSE test 11.302649796889394\n",
      "MAE train 1.5158733845028074 MAE test 2.350265419349052\n",
      "Epoch 9820 / 10000 loss: 11.79796814918518\n",
      "MSE train 4.895019550783289 MSE test 11.302645209198275\n",
      "MAE train 1.5158557469414884 MAE test 2.350270011583526\n",
      "Epoch 9821 / 10000 loss: 11.797637939453125\n",
      "MSE train 4.894916950994986 MSE test 11.302372406201352\n",
      "MAE train 1.5158411093864774 MAE test 2.350234256525009\n",
      "Epoch 9822 / 10000 loss: 11.797263145446777\n",
      "MSE train 4.894809235137492 MSE test 11.302397169793357\n",
      "MAE train 1.51581814777258 MAE test 2.3502428657143613\n",
      "Epoch 9823 / 10000 loss: 11.796975374221802\n",
      "MSE train 4.894705986697682 MSE test 11.302191438303925\n",
      "MAE train 1.515802082369861 MAE test 2.350216051781968\n",
      "Epoch 9824 / 10000 loss: 11.79651165008545\n",
      "MSE train 4.894614050194242 MSE test 11.302167269797321\n",
      "MAE train 1.5157843894406855 MAE test 2.3502180471544474\n",
      "Epoch 9825 / 10000 loss: 11.796170234680176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.894511585313263 MSE test 11.301913532044503\n",
      "MAE train 1.5157694561244177 MAE test 2.350184834315987\n",
      "Epoch 9826 / 10000 loss: 11.79580283164978\n",
      "MSE train 4.894412096446229 MSE test 11.301932858510852\n",
      "MAE train 1.5157488320747858 MAE test 2.350192664972436\n",
      "Epoch 9827 / 10000 loss: 11.795500040054321\n",
      "MSE train 4.894308451790482 MSE test 11.301688851753925\n",
      "MAE train 1.5157334405321279 MAE test 2.350160765179531\n",
      "Epoch 9828 / 10000 loss: 11.795072555541992\n",
      "MSE train 4.894213993843571 MSE test 11.30170097032109\n",
      "MAE train 1.5157142631260891 MAE test 2.350167610465155\n",
      "Epoch 9829 / 10000 loss: 11.794757843017578\n",
      "MSE train 4.894110679958888 MSE test 11.30143843828238\n",
      "MAE train 1.515699261820287 MAE test 2.3501332320746484\n",
      "Epoch 9830 / 10000 loss: 11.794355154037476\n",
      "MSE train 4.894008393960235 MSE test 11.301459436617174\n",
      "MAE train 1.5156778307498702 MAE test 2.3501413024895457\n",
      "Epoch 9831 / 10000 loss: 11.794057369232178\n",
      "MSE train 4.893904384395976 MSE test 11.301228941687786\n",
      "MAE train 1.5156620827537588 MAE test 2.350111208280612\n",
      "Epoch 9832 / 10000 loss: 11.793616771697998\n",
      "MSE train 4.893813680662866 MSE test 11.301230649968915\n",
      "MAE train 1.5156441119390953 MAE test 2.350116645215547\n",
      "Epoch 9833 / 10000 loss: 11.793291091918945\n",
      "MSE train 4.893710905055689 MSE test 11.300957591859985\n",
      "MAE train 1.515629432363278 MAE test 2.3500808562830344\n",
      "Epoch 9834 / 10000 loss: 11.792909145355225\n",
      "MSE train 4.893603364261115 MSE test 11.30098229173271\n",
      "MAE train 1.515606513064727 MAE test 2.350089460491225\n",
      "Epoch 9835 / 10000 loss: 11.792621850967407\n",
      "MSE train 4.893500139549105 MSE test 11.300776573030998\n",
      "MAE train 1.5155904472237374 MAE test 2.3500626397495887\n",
      "Epoch 9836 / 10000 loss: 11.792158603668213\n",
      "MSE train 4.893408343262308 MSE test 11.300752661716729\n",
      "MAE train 1.5155727750417456 MAE test 2.3500646681850923\n",
      "Epoch 9837 / 10000 loss: 11.79181718826294\n",
      "MSE train 4.893305920372003 MSE test 11.300499003403505\n",
      "MAE train 1.515557848352535 MAE test 2.350031481201393\n",
      "Epoch 9838 / 10000 loss: 11.791450023651123\n",
      "MSE train 4.893206404627847 MSE test 11.300518420187268\n",
      "MAE train 1.5155372098975548 MAE test 2.350039325542603\n",
      "Epoch 9839 / 10000 loss: 11.791147470474243\n",
      "MSE train 4.89310275870584 MSE test 11.30027501795057\n",
      "MAE train 1.5155218069825471 MAE test 2.35000751485232\n",
      "Epoch 9840 / 10000 loss: 11.790720462799072\n",
      "MSE train 4.893008501898931 MSE test 11.300286999391911\n",
      "MAE train 1.515502680373556 MAE test 2.3500143448182973\n",
      "Epoch 9841 / 10000 loss: 11.7904052734375\n",
      "MSE train 4.892905332557149 MSE test 11.30002418416834\n",
      "MAE train 1.5154877106046327 MAE test 2.3499799242645687\n",
      "Epoch 9842 / 10000 loss: 11.790003776550293\n",
      "MSE train 4.892802766737735 MSE test 11.300045536042651\n",
      "MAE train 1.5154662039317366 MAE test 2.3499880661992067\n",
      "Epoch 9843 / 10000 loss: 11.789705991744995\n",
      "MSE train 4.892698830896326 MSE test 11.29981608967275\n",
      "MAE train 1.5154504426258628 MAE test 2.3499581123547264\n",
      "Epoch 9844 / 10000 loss: 11.789264917373657\n",
      "MSE train 4.892608363986861 MSE test 11.299817141879483\n",
      "MAE train 1.5154325513214415 MAE test 2.3499634732224677\n",
      "Epoch 9845 / 10000 loss: 11.788938522338867\n",
      "MSE train 4.8925056787923165 MSE test 11.29954412839265\n",
      "MAE train 1.515417889267953 MAE test 2.349927693758257\n",
      "Epoch 9846 / 10000 loss: 11.788558959960938\n",
      "MSE train 4.892398072009107 MSE test 11.299568965291401\n",
      "MAE train 1.5153949423219701 MAE test 2.349936331870712\n",
      "Epoch 9847 / 10000 loss: 11.78827166557312\n",
      "MSE train 4.892294950521873 MSE test 11.29936400819275\n",
      "MAE train 1.5153788865599793 MAE test 2.3499096288942596\n",
      "Epoch 9848 / 10000 loss: 11.787807941436768\n",
      "MSE train 4.89220305232605 MSE test 11.299339570270378\n",
      "MAE train 1.515361191867985 MAE test 2.3499116032379095\n",
      "Epoch 9849 / 10000 loss: 11.787466526031494\n",
      "MSE train 4.892100639875319 MSE test 11.299087062848347\n",
      "MAE train 1.5153462526164205 MAE test 2.3498785701104516\n",
      "Epoch 9850 / 10000 loss: 11.787099361419678\n",
      "MSE train 4.892001616045427 MSE test 11.299106208377033\n",
      "MAE train 1.5153257419031667 MAE test 2.349886389665739\n",
      "Epoch 9851 / 10000 loss: 11.78679609298706\n",
      "MSE train 4.891898094552801 MSE test 11.298861142370681\n",
      "MAE train 1.5153103905317264 MAE test 2.3498543504481955\n",
      "Epoch 9852 / 10000 loss: 11.78637146949768\n",
      "MSE train 4.891803183920009 MSE test 11.29887425976005\n",
      "MAE train 1.5152910652134628 MAE test 2.349861349432289\n",
      "Epoch 9853 / 10000 loss: 11.78605842590332\n",
      "MSE train 4.891699954685789 MSE test 11.298614142380003\n",
      "MAE train 1.5152760334560142 MAE test 2.3498273129730194\n",
      "Epoch 9854 / 10000 loss: 11.785653114318848\n",
      "MSE train 4.891598660301495 MSE test 11.298634626081245\n",
      "MAE train 1.515254876482823 MAE test 2.349835324612313\n",
      "Epoch 9855 / 10000 loss: 11.785353660583496\n",
      "MSE train 4.89149478364818 MSE test 11.298400316850133\n",
      "MAE train 1.515239232779504 MAE test 2.3498047372069824\n",
      "Epoch 9856 / 10000 loss: 11.784917831420898\n",
      "MSE train 4.89140335084485 MSE test 11.29840558647764\n",
      "MAE train 1.5152209837251747 MAE test 2.349810677891598\n",
      "Epoch 9857 / 10000 loss: 11.784595727920532\n",
      "MSE train 4.891300562950418 MSE test 11.298134734293171\n",
      "MAE train 1.5152062501261578 MAE test 2.349775195270097\n",
      "Epoch 9858 / 10000 loss: 11.784209728240967\n",
      "MSE train 4.891194039477234 MSE test 11.298158964178066\n",
      "MAE train 1.5151835999640864 MAE test 2.349783752237104\n",
      "Epoch 9859 / 10000 loss: 11.783920526504517\n",
      "MSE train 4.891090667550181 MSE test 11.297949161420297\n",
      "MAE train 1.5151675865707155 MAE test 2.3497564175780603\n",
      "Epoch 9860 / 10000 loss: 11.783461093902588\n",
      "MSE train 4.890999865729792 MSE test 11.297930926183467\n",
      "MAE train 1.5151500413412595 MAE test 2.3497592164024597\n",
      "Epoch 9861 / 10000 loss: 11.783123016357422\n",
      "MSE train 4.8908975509427215 MSE test 11.297670398120518\n",
      "MAE train 1.5151352481331612 MAE test 2.349725109917384\n",
      "Epoch 9862 / 10000 loss: 11.782756090164185\n",
      "MSE train 4.8907950503761475 MSE test 11.297692649172332\n",
      "MAE train 1.515113735241176 MAE test 2.34973338326682\n",
      "Epoch 9863 / 10000 loss: 11.782459259033203\n",
      "MSE train 4.890691326637653 MSE test 11.297463141056284\n",
      "MAE train 1.5150980365130169 MAE test 2.349703429647118\n",
      "Epoch 9864 / 10000 loss: 11.782018661499023\n",
      "MSE train 4.890600803837016 MSE test 11.297465359187395\n",
      "MAE train 1.515080092523127 MAE test 2.349708969417773\n",
      "Epoch 9865 / 10000 loss: 11.78169322013855\n",
      "MSE train 4.890498193618626 MSE test 11.297192790157643\n",
      "MAE train 1.5150654380791082 MAE test 2.3496732523055517\n",
      "Epoch 9866 / 10000 loss: 11.781313419342041\n",
      "MSE train 4.8903907417527215 MSE test 11.297217823527344\n",
      "MAE train 1.5150425236988223 MAE test 2.3496819381427785\n",
      "Epoch 9867 / 10000 loss: 11.781026124954224\n",
      "MSE train 4.890287670470299 MSE test 11.297012906893217\n",
      "MAE train 1.5150264770616257 MAE test 2.34965524150265\n",
      "Epoch 9868 / 10000 loss: 11.780563831329346\n",
      "MSE train 4.890195965922348 MSE test 11.296988971078207\n",
      "MAE train 1.5150088144856666 MAE test 2.3496573035057944\n",
      "Epoch 9869 / 10000 loss: 11.780222654342651\n",
      "MSE train 4.890093610769776 MSE test 11.296736262392294\n",
      "MAE train 1.5149938839061552 MAE test 2.349624244597411\n",
      "Epoch 9870 / 10000 loss: 11.779855966567993\n",
      "MSE train 4.889994444709111 MSE test 11.2967558640688\n",
      "MAE train 1.5149733188062184 MAE test 2.349632146448086\n",
      "Epoch 9871 / 10000 loss: 11.779552936553955\n",
      "MSE train 4.889890981295034 MSE test 11.296512175536524\n",
      "MAE train 1.514957952606138 MAE test 2.3496003161209074\n",
      "Epoch 9872 / 10000 loss: 11.779127359390259\n",
      "MSE train 4.8897965530007275 MSE test 11.29652489620381\n",
      "MAE train 1.5149387551842655 MAE test 2.3496072695452295\n",
      "Epoch 9873 / 10000 loss: 11.77881407737732\n",
      "MSE train 4.889693421508481 MSE test 11.296263775025663\n",
      "MAE train 1.514923764549442 MAE test 2.34957309988338\n",
      "Epoch 9874 / 10000 loss: 11.778411626815796\n",
      "MSE train 4.889591574652178 MSE test 11.296284902125995\n",
      "MAE train 1.5149024332893808 MAE test 2.3495812117626484\n",
      "Epoch 9875 / 10000 loss: 11.778112888336182\n",
      "MSE train 4.889487766698618 MSE test 11.296053962018329\n",
      "MAE train 1.514886738609681 MAE test 2.349551084798291\n",
      "Epoch 9876 / 10000 loss: 11.777675151824951\n",
      "MSE train 4.889397042716452 MSE test 11.29605716679703\n",
      "MAE train 1.5148687130379774 MAE test 2.349556764089302\n",
      "Epoch 9877 / 10000 loss: 11.777351140975952\n",
      "MSE train 4.889294365421143 MSE test 11.295785434453116\n",
      "MAE train 1.5148540217724875 MAE test 2.349521174371631\n",
      "Epoch 9878 / 10000 loss: 11.776968479156494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.889187343300051 MSE test 11.295810299540118\n",
      "MAE train 1.5148312137966446 MAE test 2.349529839839685\n",
      "Epoch 9879 / 10000 loss: 11.776681184768677\n",
      "MSE train 4.889084211256447 MSE test 11.295603898449603\n",
      "MAE train 1.5148151796359017 MAE test 2.3495029615244745\n",
      "Epoch 9880 / 10000 loss: 11.776219844818115\n",
      "MSE train 4.888992884904237 MSE test 11.295582133556573\n",
      "MAE train 1.5147975686641983 MAE test 2.3495053198186384\n",
      "Epoch 9881 / 10000 loss: 11.775880336761475\n",
      "MSE train 4.888890623874143 MSE test 11.295326973718293\n",
      "MAE train 1.5147826959355009 MAE test 2.3494719486092364\n",
      "Epoch 9882 / 10000 loss: 11.775513648986816\n",
      "MSE train 4.888790386961012 MSE test 11.295347782459105\n",
      "MAE train 1.514761819993697 MAE test 2.3494800219328273\n",
      "Epoch 9883 / 10000 loss: 11.775213479995728\n",
      "MSE train 4.888686833356763 MSE test 11.295109129537572\n",
      "MAE train 1.5147463384796258 MAE test 2.34944888407478\n",
      "Epoch 9884 / 10000 loss: 11.77478313446045\n",
      "MSE train 4.88859408344178 MSE test 11.29511884140168\n",
      "MAE train 1.5147276472837659 MAE test 2.3494554389153057\n",
      "Epoch 9885 / 10000 loss: 11.774465799331665\n",
      "MSE train 4.888491246973389 MSE test 11.294852539694018\n",
      "MAE train 1.5147128161238341 MAE test 2.349420591425261\n",
      "Epoch 9886 / 10000 loss: 11.774071216583252\n",
      "MSE train 4.888386814818671 MSE test 11.29487592277149\n",
      "MAE train 1.5146907337477147 MAE test 2.3494290548457655\n",
      "Epoch 9887 / 10000 loss: 11.773778438568115\n",
      "MSE train 4.888283155721623 MSE test 11.294657204843046\n",
      "MAE train 1.5146748214088364 MAE test 2.3494005491993484\n",
      "Epoch 9888 / 10000 loss: 11.77332854270935\n",
      "MSE train 4.888193400493576 MSE test 11.294649566375426\n",
      "MAE train 1.5146573149821687 MAE test 2.349404775989153\n",
      "Epoch 9889 / 10000 loss: 11.772996425628662\n",
      "MSE train 4.8880911102552345 MSE test 11.29438006472641\n",
      "MAE train 1.514642674308811 MAE test 2.3493695081420354\n",
      "Epoch 9890 / 10000 loss: 11.772626161575317\n",
      "MSE train 4.887984607675128 MSE test 11.294405051316229\n",
      "MAE train 1.5146200073967455 MAE test 2.3493781960826334\n",
      "Epoch 9891 / 10000 loss: 11.772338390350342\n",
      "MSE train 4.887881396894962 MSE test 11.2941961754506\n",
      "MAE train 1.514604011260247 MAE test 2.349351016757241\n",
      "Epoch 9892 / 10000 loss: 11.771879434585571\n",
      "MSE train 4.88779070261042 MSE test 11.294178274476279\n",
      "MAE train 1.514586481724911 MAE test 2.349353895967638\n",
      "Epoch 9893 / 10000 loss: 11.771541357040405\n",
      "MSE train 4.887688520981139 MSE test 11.293918808549332\n",
      "MAE train 1.5145716989195082 MAE test 2.3493199672193805\n",
      "Epoch 9894 / 10000 loss: 11.771175146102905\n",
      "MSE train 4.8875862716705765 MSE test 11.293941330650194\n",
      "MAE train 1.5145502343318968 MAE test 2.3493283072294844\n",
      "Epoch 9895 / 10000 loss: 11.770878076553345\n",
      "MSE train 4.887482689868838 MSE test 11.293712060514034\n",
      "MAE train 1.5145345600280353 MAE test 2.3492984287535563\n",
      "Epoch 9896 / 10000 loss: 11.77043890953064\n",
      "MSE train 4.887392163241806 MSE test 11.293715129276432\n",
      "MAE train 1.514516600586673 MAE test 2.349304123869706\n",
      "Epoch 9897 / 10000 loss: 11.770114660263062\n",
      "MSE train 4.887289644745472 MSE test 11.293443569862104\n",
      "MAE train 1.5145019404967188 MAE test 2.349268588184811\n",
      "Epoch 9898 / 10000 loss: 11.769733428955078\n",
      "MSE train 4.887182462503676 MSE test 11.293468898100073\n",
      "MAE train 1.514479082665722 MAE test 2.34927734840903\n",
      "Epoch 9899 / 10000 loss: 11.769446849822998\n",
      "MSE train 4.887079487549787 MSE test 11.293264128014842\n",
      "MAE train 1.5144630475431877 MAE test 2.349250718354325\n",
      "Epoch 9900 / 10000 loss: 11.768986225128174\n",
      "MSE train 4.88698800462425 MSE test 11.293241438621902\n",
      "MAE train 1.5144454184392844 MAE test 2.349252991139114\n",
      "Epoch 9901 / 10000 loss: 11.768646001815796\n",
      "MSE train 4.886885817863262 MSE test 11.292988507825322\n",
      "MAE train 1.514430522359831 MAE test 2.3492199483010006\n",
      "Epoch 9902 / 10000 loss: 11.768279075622559\n",
      "MSE train 4.88678638466344 MSE test 11.293008916254285\n",
      "MAE train 1.514409865422534 MAE test 2.3492280096562888\n",
      "Epoch 9903 / 10000 loss: 11.767977952957153\n",
      "MSE train 4.886682980088415 MSE test 11.292767683402843\n",
      "MAE train 1.5143944623054968 MAE test 2.349196559343879\n",
      "Epoch 9904 / 10000 loss: 11.76755142211914\n",
      "MSE train 4.8865892782732665 MSE test 11.292779936704509\n",
      "MAE train 1.514375465927712 MAE test 2.3492034800049093\n",
      "Epoch 9905 / 10000 loss: 11.767236709594727\n",
      "MSE train 4.886486335006743 MSE test 11.292517497911676\n",
      "MAE train 1.5143605352187735 MAE test 2.3491691822764955\n",
      "Epoch 9906 / 10000 loss: 11.766836881637573\n",
      "MSE train 4.886383662371302 MSE test 11.292539946137397\n",
      "MAE train 1.514338953234283 MAE test 2.3491775360788405\n",
      "Epoch 9907 / 10000 loss: 11.766541957855225\n",
      "MSE train 4.886279957298445 MSE test 11.292313862562612\n",
      "MAE train 1.5143231697347095 MAE test 2.3491480947808805\n",
      "Epoch 9908 / 10000 loss: 11.76609992980957\n",
      "MSE train 4.886189954131681 MSE test 11.292314025205602\n",
      "MAE train 1.5143054172464783 MAE test 2.3491534226313755\n",
      "Epoch 9909 / 10000 loss: 11.765772819519043\n",
      "MSE train 4.886087539031152 MSE test 11.292042488415712\n",
      "MAE train 1.5142907779620376 MAE test 2.3491179030677425\n",
      "Epoch 9910 / 10000 loss: 11.765396356582642\n",
      "MSE train 4.885980235006967 MSE test 11.292068293766427\n",
      "MAE train 1.5142678804336458 MAE test 2.349126750842697\n",
      "Epoch 9911 / 10000 loss: 11.765109777450562\n",
      "MSE train 4.885877310838957 MSE test 11.291864759413372\n",
      "MAE train 1.5142518349390335 MAE test 2.349100301320317\n",
      "Epoch 9912 / 10000 loss: 11.7646484375\n",
      "MSE train 4.885785626493197 MSE test 11.29184113209925\n",
      "MAE train 1.5142341744406063 MAE test 2.3491024753158114\n",
      "Epoch 9913 / 10000 loss: 11.764307498931885\n",
      "MSE train 4.885683442543375 MSE test 11.291590274962813\n",
      "MAE train 1.5142192490713502 MAE test 2.349069737835001\n",
      "Epoch 9914 / 10000 loss: 11.763941049575806\n",
      "MSE train 4.885584845532672 MSE test 11.291610216786891\n",
      "MAE train 1.514198820864952 MAE test 2.349077755433331\n",
      "Epoch 9915 / 10000 loss: 11.763638496398926\n",
      "MSE train 4.885481560724906 MSE test 11.291366176581613\n",
      "MAE train 1.514183487866334 MAE test 2.3490459452016657\n",
      "Epoch 9916 / 10000 loss: 11.7632155418396\n",
      "MSE train 4.885386771185009 MSE test 11.29138055644724\n",
      "MAE train 1.514164172060995 MAE test 2.349053208678769\n",
      "Epoch 9917 / 10000 loss: 11.762903928756714\n",
      "MSE train 4.88528369512064 MSE test 11.29112253838039\n",
      "MAE train 1.5141491288690927 MAE test 2.3490195318057925\n",
      "Epoch 9918 / 10000 loss: 11.762499570846558\n",
      "MSE train 4.885183028432823 MSE test 11.291143752865063\n",
      "MAE train 1.5141281104716469 MAE test 2.349027748134804\n",
      "Epoch 9919 / 10000 loss: 11.762199878692627\n",
      "MSE train 4.885079353906801 MSE test 11.290909508654542\n",
      "MAE train 1.5141125004720433 MAE test 2.348997276692363\n",
      "Epoch 9920 / 10000 loss: 11.761767148971558\n",
      "MSE train 4.884987876138579 MSE test 11.290916874798635\n",
      "MAE train 1.5140941984363208 MAE test 2.3490035923374797\n",
      "Epoch 9921 / 10000 loss: 11.761446237564087\n",
      "MSE train 4.8848852099784335 MSE test 11.290648601332222\n",
      "MAE train 1.5140794347040976 MAE test 2.3489685646824454\n",
      "Epoch 9922 / 10000 loss: 11.761059284210205\n",
      "MSE train 4.884779447396731 MSE test 11.290673572419381\n",
      "MAE train 1.5140569716304608 MAE test 2.348977328469774\n",
      "Epoch 9923 / 10000 loss: 11.760769367218018\n",
      "MSE train 4.884676135731564 MSE test 11.29046286522152\n",
      "MAE train 1.5140409896712486 MAE test 2.3489499942419125\n",
      "Epoch 9924 / 10000 loss: 11.760314226150513\n",
      "MSE train 4.884585984916381 MSE test 11.290448411064075\n",
      "MAE train 1.5140235267390811 MAE test 2.3489534264581526\n",
      "Epoch 9925 / 10000 loss: 11.7599778175354\n",
      "MSE train 4.884483820456853 MSE test 11.290186648590803\n",
      "MAE train 1.5140087771799282 MAE test 2.348919284009434\n",
      "Epoch 9926 / 10000 loss: 11.759611129760742\n",
      "MSE train 4.8843803216679325 MSE test 11.290210858386168\n",
      "MAE train 1.5139869488050277 MAE test 2.348927953551956\n",
      "Epoch 9927 / 10000 loss: 11.759318113327026\n",
      "MSE train 4.88427680208837 MSE test 11.289989015824904\n",
      "MAE train 1.5139711369389754 MAE test 2.3488991498057135\n",
      "Epoch 9928 / 10000 loss: 11.758872985839844\n",
      "MSE train 4.8841871327401325 MSE test 11.289986865824389\n",
      "MAE train 1.5139535299597637 MAE test 2.348904235829357\n",
      "Epoch 9929 / 10000 loss: 11.758543729782104\n",
      "MSE train 4.884084912643279 MSE test 11.289716564309513\n",
      "MAE train 1.513938910590869 MAE test 2.348868962235122\n",
      "Epoch 9930 / 10000 loss: 11.758171081542969\n",
      "MSE train 4.883977723737433 MSE test 11.289742798308218\n",
      "MAE train 1.5139160389321176 MAE test 2.3488779290769486\n",
      "Epoch 9931 / 10000 loss: 11.757884740829468\n",
      "MSE train 4.883874864488702 MSE test 11.289539613602518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train 1.5139000016275186 MAE test 2.348851601244222\n",
      "Epoch 9932 / 10000 loss: 11.757423162460327\n",
      "MSE train 4.883783339268567 MSE test 11.289517095978038\n",
      "MAE train 1.5138823752555182 MAE test 2.3488539975157843\n",
      "Epoch 9933 / 10000 loss: 11.757082462310791\n",
      "MSE train 4.8836811995019405 MSE test 11.289266273170808\n",
      "MAE train 1.5138674470010032 MAE test 2.348821340753342\n",
      "Epoch 9934 / 10000 loss: 11.75671648979187\n",
      "MSE train 4.8835823289075835 MSE test 11.289287032777775\n",
      "MAE train 1.5138469478766687 MAE test 2.348829546275604\n",
      "Epoch 9935 / 10000 loss: 11.756415367126465\n",
      "MSE train 4.88347903055766 MSE test 11.289044915756007\n",
      "MAE train 1.5138315749461664 MAE test 2.3487980668697555\n",
      "Epoch 9936 / 10000 loss: 11.755990982055664\n",
      "MSE train 4.883384746289627 MSE test 11.289059133649868\n",
      "MAE train 1.5138124099781827 MAE test 2.3488053714273023\n",
      "Epoch 9937 / 10000 loss: 11.75567889213562\n",
      "MSE train 4.883281788403778 MSE test 11.288800262799338\n",
      "MAE train 1.5137974063297366 MAE test 2.348771654240353\n",
      "Epoch 9938 / 10000 loss: 11.755276203155518\n",
      "MSE train 4.883180333849407 MSE test 11.288822564745912\n",
      "MAE train 1.5137761724468866 MAE test 2.3487800843187703\n",
      "Epoch 9939 / 10000 loss: 11.754979133605957\n",
      "MSE train 4.8830767409298295 MSE test 11.288592495829908\n",
      "MAE train 1.5137604959201028 MAE test 2.3487502309224113\n",
      "Epoch 9940 / 10000 loss: 11.754542589187622\n",
      "MSE train 4.88298606153444 MSE test 11.288597809766994\n",
      "MAE train 1.5137424626483325 MAE test 2.3487563370906597\n",
      "Epoch 9941 / 10000 loss: 11.754219055175781\n",
      "MSE train 4.882883556154945 MSE test 11.288328444902277\n",
      "MAE train 1.5137277578255284 MAE test 2.3487212134022952\n",
      "Epoch 9942 / 10000 loss: 11.753836870193481\n",
      "MSE train 4.8827769553767055 MSE test 11.288354581545857\n",
      "MAE train 1.5137050523864974 MAE test 2.3487302162157384\n",
      "Epoch 9943 / 10000 loss: 11.753549814224243\n",
      "MSE train 4.882673910875289 MSE test 11.288148995656215\n",
      "MAE train 1.513689032719318 MAE test 2.3487036101543635\n",
      "Epoch 9944 / 10000 loss: 11.753090858459473\n",
      "MSE train 4.882583022062322 MSE test 11.288130181382503\n",
      "MAE train 1.513671488954395 MAE test 2.348706534860259\n",
      "Epoch 9945 / 10000 loss: 11.752751350402832\n",
      "MSE train 4.882480915128008 MSE test 11.287875255831707\n",
      "MAE train 1.5136566422394229 MAE test 2.348673356937336\n",
      "Epoch 9946 / 10000 loss: 11.752386569976807\n",
      "MSE train 4.882380129495166 MSE test 11.287898001108045\n",
      "MAE train 1.5136355919825208 MAE test 2.3486818995954235\n",
      "Epoch 9947 / 10000 loss: 11.75208854675293\n",
      "MSE train 4.882276701790359 MSE test 11.287664667291498\n",
      "MAE train 1.5136200399406818 MAE test 2.348651638898221\n",
      "Epoch 9948 / 10000 loss: 11.751655340194702\n",
      "MSE train 4.882185087031253 MSE test 11.287673544560548\n",
      "MAE train 1.5136016860942323 MAE test 2.3486582659558133\n",
      "Epoch 9949 / 10000 loss: 11.751335859298706\n",
      "MSE train 4.882082442894221 MSE test 11.287406709527051\n",
      "MAE train 1.5135869060446767 MAE test 2.348623526904477\n",
      "Epoch 9950 / 10000 loss: 11.750948667526245\n",
      "MSE train 4.881976978962299 MSE test 11.287432482403522\n",
      "MAE train 1.5135645116795173 MAE test 2.3486324958074016\n",
      "Epoch 9951 / 10000 loss: 11.75065803527832\n",
      "MSE train 4.881873701845402 MSE test 11.287221761886633\n",
      "MAE train 1.5135485398775468 MAE test 2.3486052509559063\n",
      "Epoch 9952 / 10000 loss: 11.750203609466553\n",
      "MSE train 4.881783660412563 MSE test 11.287209202571752\n",
      "MAE train 1.5135310887683873 MAE test 2.3486090470685537\n",
      "Epoch 9953 / 10000 loss: 11.749868154525757\n",
      "MSE train 4.881681539810689 MSE test 11.286947528097977\n",
      "MAE train 1.5135163564122747 MAE test 2.348575002708929\n",
      "Epoch 9954 / 10000 loss: 11.749501705169678\n",
      "MSE train 4.881577674247039 MSE test 11.286972818667023\n",
      "MAE train 1.5134944139647102 MAE test 2.3485839114090257\n",
      "Epoch 9955 / 10000 loss: 11.7492094039917\n",
      "MSE train 4.881474181743703 MSE test 11.286754088131556\n",
      "MAE train 1.5134785550918783 MAE test 2.348555624999332\n",
      "Epoch 9956 / 10000 loss: 11.748762130737305\n",
      "MSE train 4.881384631860942 MSE test 11.286750757446498\n",
      "MAE train 1.5134610303691811 MAE test 2.348560661095442\n",
      "Epoch 9957 / 10000 loss: 11.748431921005249\n",
      "MSE train 4.881282443707387 MSE test 11.286482252552174\n",
      "MAE train 1.5134463950588022 MAE test 2.3485257204893073\n",
      "Epoch 9958 / 10000 loss: 11.748061418533325\n",
      "MSE train 4.88117567951041 MSE test 11.286509132256768\n",
      "MAE train 1.5134236350324366 MAE test 2.34853489178324\n",
      "Epoch 9959 / 10000 loss: 11.747774362564087\n",
      "MSE train 4.881072710965807 MSE test 11.286304928616952\n",
      "MAE train 1.513407612604388 MAE test 2.3485085134758377\n",
      "Epoch 9960 / 10000 loss: 11.747314929962158\n",
      "MSE train 4.880981629625885 MSE test 11.28628578323807\n",
      "MAE train 1.5133900440455477 MAE test 2.3485114671732537\n",
      "Epoch 9961 / 10000 loss: 11.746975898742676\n",
      "MSE train 4.880879572587444 MSE test 11.286032534705534\n",
      "MAE train 1.5133751791030952 MAE test 2.348478570382721\n",
      "Epoch 9962 / 10000 loss: 11.746610164642334\n",
      "MSE train 4.880779336451374 MSE test 11.286055330889731\n",
      "MAE train 1.5133542823158697 MAE test 2.3484871565210512\n",
      "Epoch 9963 / 10000 loss: 11.746310472488403\n",
      "MSE train 4.880675917851251 MSE test 11.28582011573899\n",
      "MAE train 1.5133387743723195 MAE test 2.348456684576392\n",
      "Epoch 9964 / 10000 loss: 11.745880603790283\n",
      "MSE train 4.880583657614056 MSE test 11.285831071324802\n",
      "MAE train 1.5133202129215657 MAE test 2.3484636449166048\n",
      "Epoch 9965 / 10000 loss: 11.745562314987183\n",
      "MSE train 4.880480910476732 MSE test 11.285566602540959\n",
      "MAE train 1.5133053708039261 MAE test 2.3484292640289306\n",
      "Epoch 9966 / 10000 loss: 11.745171070098877\n",
      "MSE train 4.880376447547755 MSE test 11.285591982871393\n",
      "MAE train 1.5132832577981783 MAE test 2.348438220353305\n",
      "Epoch 9967 / 10000 loss: 11.744879007339478\n",
      "MSE train 4.880272910966061 MSE test 11.285376938071707\n",
      "MAE train 1.5132673147909377 MAE test 2.3484104294690606\n",
      "Epoch 9968 / 10000 loss: 11.744429349899292\n",
      "MSE train 4.880183312867446 MSE test 11.285369652423734\n",
      "MAE train 1.513249865869548 MAE test 2.348414939855712\n",
      "Epoch 9969 / 10000 loss: 11.744096040725708\n",
      "MSE train 4.8800811156619215 MSE test 11.285103821744647\n",
      "MAE train 1.513235188722846 MAE test 2.3483803686388143\n",
      "Epoch 9970 / 10000 loss: 11.743727445602417\n",
      "MSE train 4.879975347651247 MSE test 11.28513026877536\n",
      "MAE train 1.5132127114289207 MAE test 2.3483894806565364\n",
      "Epoch 9971 / 10000 loss: 11.743438720703125\n",
      "MSE train 4.879872118959237 MSE test 11.284921083693199\n",
      "MAE train 1.5131967322083215 MAE test 2.3483624594367587\n",
      "Epoch 9972 / 10000 loss: 11.742984294891357\n",
      "MSE train 4.879781963116918 MSE test 11.284907928002346\n",
      "MAE train 1.513179275423732 MAE test 2.3483662081504475\n",
      "Epoch 9973 / 10000 loss: 11.742647409439087\n",
      "MSE train 4.879679868527231 MSE test 11.284647532930096\n",
      "MAE train 1.5131645228458157 MAE test 2.3483323576057433\n",
      "Epoch 9974 / 10000 loss: 11.742281198501587\n",
      "MSE train 4.879576369582925 MSE test 11.28467252698154\n",
      "MAE train 1.5131426916269992 MAE test 2.3483412678091056\n",
      "Epoch 9975 / 10000 loss: 11.741987943649292\n",
      "MSE train 4.879472840709 MSE test 11.284451971318617\n",
      "MAE train 1.513126869717185 MAE test 2.348312757697795\n",
      "Epoch 9976 / 10000 loss: 11.741542339324951\n",
      "MSE train 4.8793831151232006 MSE test 11.284450588700997\n",
      "MAE train 1.5131092596482696 MAE test 2.3483180656972844\n",
      "Epoch 9977 / 10000 loss: 11.74121356010437\n",
      "MSE train 4.8792808586304375 MSE test 11.28418141485387\n",
      "MAE train 1.5130946181663516 MAE test 2.3482830365604004\n",
      "Epoch 9978 / 10000 loss: 11.740840196609497\n",
      "MSE train 4.879173770984997 MSE test 11.284208365557454\n",
      "MAE train 1.5130717836320784 MAE test 2.3482922277258282\n",
      "Epoch 9979 / 10000 loss: 11.740553617477417\n",
      "MSE train 4.87907082633254 MSE test 11.284005411520791\n",
      "MAE train 1.5130557330978 MAE test 2.348266026228691\n",
      "Epoch 9980 / 10000 loss: 11.740093231201172\n",
      "MSE train 4.878979374347102 MSE test 11.283984154871309\n",
      "MAE train 1.5130381197074054 MAE test 2.3482686972796794\n",
      "Epoch 9981 / 10000 loss: 11.739752292633057\n",
      "MSE train 4.87887717244636 MSE test 11.28373310813372\n",
      "MAE train 1.5130231898382958 MAE test 2.3482360926514785\n",
      "Epoch 9982 / 10000 loss: 11.739386081695557\n",
      "MSE train 4.878777884895501 MSE test 11.283754434588822\n",
      "MAE train 1.513002574278884 MAE test 2.3482444728711713\n",
      "Epoch 9983 / 10000 loss: 11.739084720611572\n",
      "MSE train 4.878674425208614 MSE test 11.283514688510278\n",
      "MAE train 1.5129871341899168 MAE test 2.3482133818842676\n",
      "Epoch 9984 / 10000 loss: 11.738658666610718\n",
      "MSE train 4.878580686737718 MSE test 11.283527851635244\n",
      "MAE train 1.5129681440787028 MAE test 2.3482206240037975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9985 / 10000 loss: 11.738343477249146\n",
      "MSE train 4.878477672101516 MSE test 11.28326736495263\n",
      "MAE train 1.5129531618421004 MAE test 2.348186758452712\n",
      "Epoch 9986 / 10000 loss: 11.737944602966309\n",
      "MSE train 4.878375169942313 MSE test 11.283290380612925\n",
      "MAE train 1.5129316334640974 MAE test 2.3481953521915258\n",
      "Epoch 9987 / 10000 loss: 11.737648010253906\n",
      "MSE train 4.878271394148735 MSE test 11.283064810244953\n",
      "MAE train 1.5129158369192983 MAE test 2.3481661370388704\n",
      "Epoch 9988 / 10000 loss: 11.73720669746399\n",
      "MSE train 4.878181171711689 MSE test 11.283066132509997\n",
      "MAE train 1.5128980402974785 MAE test 2.348171772460914\n",
      "Epoch 9989 / 10000 loss: 11.736879587173462\n",
      "MSE train 4.878078557577325 MSE test 11.282795931225879\n",
      "MAE train 1.5128833262377341 MAE test 2.348136580040107\n",
      "Epoch 9990 / 10000 loss: 11.736502647399902\n",
      "MSE train 4.877971323587326 MSE test 11.282821815401565\n",
      "MAE train 1.512860465449957 MAE test 2.3481455994295786\n",
      "Epoch 9991 / 10000 loss: 11.736215114593506\n",
      "MSE train 4.877868171196888 MSE test 11.282618245334307\n",
      "MAE train 1.5128443772582925 MAE test 2.3481192575641496\n",
      "Epoch 9992 / 10000 loss: 11.735752582550049\n",
      "MSE train 4.877776464122162 MSE test 11.282595739378898\n",
      "MAE train 1.5128267188453366 MAE test 2.3481217265836056\n",
      "Epoch 9993 / 10000 loss: 11.735411167144775\n",
      "MSE train 4.877673957095614 MSE test 11.282344209600234\n",
      "MAE train 1.5128117268988823 MAE test 2.3480890037212383\n",
      "Epoch 9994 / 10000 loss: 11.735044240951538\n",
      "MSE train 4.877574521832386 MSE test 11.282364404471044\n",
      "MAE train 1.5127911088381152 MAE test 2.348097173722952\n",
      "Epoch 9995 / 10000 loss: 11.7347412109375\n",
      "MSE train 4.877470815175012 MSE test 11.282122750844268\n",
      "MAE train 1.5127756399427283 MAE test 2.348065789742405\n",
      "Epoch 9996 / 10000 loss: 11.734314203262329\n",
      "MSE train 4.877376379360591 MSE test 11.282135283234894\n",
      "MAE train 1.512756493163824 MAE test 2.3480729088322128\n",
      "Epoch 9997 / 10000 loss: 11.733999013900757\n",
      "MSE train 4.877272841073605 MSE test 11.281874661403235\n",
      "MAE train 1.5127413940954335 MAE test 2.348038975786641\n",
      "Epoch 9998 / 10000 loss: 11.733595609664917\n",
      "MSE train 4.8771703820767165 MSE test 11.281896119987612\n",
      "MAE train 1.5127199358698904 MAE test 2.3480473172142573\n",
      "Epoch 9999 / 10000 loss: 11.733296632766724\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "hm_epochs = 10000\n",
    "tot_users = X_train.shape[0]\n",
    "# print(tot_users)\n",
    "\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0    # initializing error as 0\n",
    "    for i in range(int(tot_users/batch_size)):\n",
    "        # print(epoch_x)\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],feed_dict={input_layer: epoch_x, output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer, feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer, feed_dict={input_layer:X_test})\n",
    "    print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))\n",
    "    print('MAE train', MAE(output_train, X_train),'MAE test', MAE(output_test, X_test))\n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a user\n",
    "sample_user = X_test.iloc[99,:]\n",
    "# get the predicted ratings\n",
    "sample_user_pred = sess.run(output_layer, feed_dict={input_layer:[sample_user]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "\n",
    "v1 = sess.run(hidden_1_layer_vals)\n",
    "f = open(\"weights.pkl\",\"wb\")\n",
    "pickle.dump(v1,f)\n",
    "f.close()\n",
    "\n",
    "v2 = sess.run(output_layer_vals)\n",
    "f = open(\"weights-output.pkl\",\"wb\")\n",
    "pickle.dump(v2,f)\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
