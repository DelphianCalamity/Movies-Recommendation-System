{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Computes mae in batches so that we don't have memory issue in big dataset\n",
    "def compute_MAE(sess, train_sparse, output_layer):\n",
    "\n",
    "    loss_mae = 0\n",
    "    bsize=100\n",
    "    tot_users = train_sparse.shape[0]\n",
    "    train_sparse = train_sparse.tocsr()\n",
    "    # print(tot_users)\n",
    "\n",
    "    for i in range(int(tot_users/bsize)+1):\n",
    "\n",
    "        to = (i+1)*bsize\n",
    "        if to > tot_users:\n",
    "            to = tot_users\n",
    "            \n",
    "        epoch_x = train_sparse[ i*bsize : to ]\n",
    "        epoch_x = epoch_x.toarray()\n",
    "\n",
    "        output_train = sess.run(output_layer, feed_dict={input_layer:epoch_x})\n",
    "        loss_mae += np.sum(abs(output_train - epoch_x))\n",
    "\n",
    "    mae = loss_mae / (train_sparse.shape[0]*train_sparse.shape[1])\n",
    "    return mae\n",
    "\n",
    "\n",
    "def compute_RMSE(sess, train_sparse, output_layer):\n",
    "\n",
    "    loss_rmse = 0\n",
    "    bsize=100\n",
    "    tot_users = train_sparse.shape[0]\n",
    "    train_sparse = train_sparse.tocsr()\n",
    "    # print(tot_users)\n",
    "\n",
    "    for i in range(int(tot_users/bsize)+1):\n",
    "\n",
    "        to = (i+1)*bsize\n",
    "        if to > tot_users:\n",
    "            to = tot_users\n",
    "            \n",
    "        epoch_x = train_sparse[ i*bsize : to ]\n",
    "        epoch_x = epoch_x.toarray()\n",
    "\n",
    "        output_train = sess.run(output_layer, feed_dict={input_layer:epoch_x})\n",
    "        loss_rmse += np.sum(np.square(output_train - epoch_x))\n",
    "\n",
    "    rmse = loss_rmse / (train_sparse.shape[0]*train_sparse.shape[1])\n",
    "    return rmse\n",
    "\n",
    "def save_weights(sess, hidden_vals, output_vals):\n",
    "\n",
    "    v1 = sess.run(hidden_vals)\n",
    "    f = open(\"weights-hidden.pkl\",\"wb\")\n",
    "    pickle.dump(v1,f)\n",
    "    f.close()\n",
    "\n",
    "    v2 = sess.run(output_vals)\n",
    "    f = open(\"weights-output.pkl\",\"wb\")\n",
    "    pickle.dump(v2,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ratings data\n",
    "ratings_df = pd.read_csv('../datasets/ml-latest/ratings.csv', sep=\",\")\n",
    "\n",
    "# Making the dataset a little bit smaller due to lack of memory resources\n",
    "ratings_df = ratings_df.head(len(ratings_df))\n",
    "# print(ratings_df)\n",
    "\n",
    "# Preprocessing\n",
    "np_users = ratings_df.userId.values\n",
    "np_items = ratings_df.movieId.values\n",
    "\n",
    "unique_users = np.unique(np_users)\n",
    "unique_items = np.unique(np_items)\n",
    "\n",
    "n_users = unique_users.shape[0]\n",
    "n_items = unique_items.shape[0]\n",
    "\n",
    "# print(n_users)\n",
    "# print(n_items)\n",
    "\n",
    "max_item = unique_items[-1]\n",
    "\n",
    "# Reconstruct the ratings set's user/movie indices\n",
    "np_users = ratings_df.userId.values\n",
    "np_users[:] -= 1 # Make users zero-indexed\n",
    "# print(np_users)\n",
    "\n",
    "# Mapping unique items down to an array 0..n_items-1\n",
    "z = np.zeros(max_item+1, dtype=int)\n",
    "z[unique_items] = np.arange(n_items)\n",
    "movies_map = z[np_items]\n",
    "\n",
    "np_ratings = ratings_df.rating.values\n",
    "# print(np_ratings.shape[0])\n",
    "ratings = np.zeros((np_ratings.shape[0], 3), dtype=object)\n",
    "ratings[:, 0] = np_users\n",
    "ratings[:, 1] = movies_map\n",
    "ratings[:, 2] = np_ratings\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(ratings, train_size=0.8)\n",
    "# print(X_train)\n",
    "\n",
    "# Ignoring timestamp\n",
    "user_train, movie_train, rating_train = zip(*X_train)\n",
    "train_sparse = coo_matrix((rating_train, (user_train, movie_train)), shape=(n_users, n_items))\n",
    "# print(train_sparse.shape)\n",
    "\n",
    "user_test, movie_test, rating_test = zip(*X_test)\n",
    "test_sparse = coo_matrix((rating_test, (user_test, movie_test)), shape=(n_users, n_items))\n",
    "# print(test_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Graph - Autoencoder with one hidden layer\n",
    "\n",
    "![autoencoder with one layer](../Images/autoencoders-1layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/calliope/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Deciding how many nodes each layer should have - Depending on the dataset's size\n",
    "movies_size = 53889 #28267 #9724 #28267 #58099\n",
    "n_nodes_inpl = movies_size\n",
    "n_nodes_hl1  = 256\n",
    "n_nodes_outl = movies_size\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "\n",
    "# first hidden layer has 15159*256 weights and 256 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1, n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1, n_nodes_outl]))}\n",
    "\n",
    "input_layer = tf.placeholder('float', [None, movies_size])\n",
    "\n",
    "input_layer_const = tf.fill([tf.shape(input_layer)[0], 1], 1.0)\n",
    "input_layer_concat = tf.concat([input_layer, input_layer_const], 1)\n",
    "\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat, hidden_1_layer_vals['weights']))\n",
    "\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1], 1.0)\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "\n",
    "output_layer = tf.matmul(layer_concat, output_layer_vals['weights'])\n",
    "\n",
    "output_true = tf.placeholder('float', [None, movies_size])\n",
    "meansq = tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "\n",
    "learn_rate = 0.1   # learning rate\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)\n",
    "\n",
    "# initializing variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "writer.close()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-911f6fe0b302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepoch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sparse\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mepoch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeansq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "hm_epochs = 1\n",
    "tot_users = train_sparse.shape[0]\n",
    "# print(tot_users)\n",
    "\n",
    "train_sparse = train_sparse.tocsr()\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(int(tot_users/batch_size)):\n",
    "        epoch_x = train_sparse[ i*batch_size : (i+1)*batch_size ]\n",
    "        epoch_x = epoch_x.toarray()\n",
    "        _, c = sess.run([optimizer, meansq],feed_dict={input_layer: epoch_x, output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "  \n",
    "    print((epoch+1)%10)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('MAE train', compute_MAE(sess, train_sparse, output_layer))\n",
    "        print('MSE train', np.sqrt(compute_RMSE(sess, train_sparse, output_layer)))\n",
    "\n",
    "print('MAE train', compute_MAE(sess, train_sparse, output_layer))\n",
    "print('MSE train', np.sqrt(compute_RMSE(sess, train_sparse, output_layer)))\n",
    "print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a user\n",
    "sample_user = X_test.iloc[99,:]\n",
    "# get the predicted ratings\n",
    "sample_user_pred = sess.run(output_layer, feed_dict={input_layer:[sample_user]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
