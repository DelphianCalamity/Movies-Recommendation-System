{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# reading the ratings data\n",
    "ratings = pd.read_csv('ml-latest/ratings2.csv', sep=\",\")\n",
    "\n",
    "# Making the dataset a little bit smaller due to lack of memory resources\n",
    "# ratings = ratings.head(len(ratings)//100)\n",
    "# print(ratings)\n",
    "\n",
    "ratings_pivot = pd.pivot_table(ratings[['userId', 'movieId', 'rating']], \n",
    "                               values='rating', index='userId', columns='movieId' ).fillna(0)\n",
    "\n",
    "\n",
    "# creating train and test sets\n",
    "X_train, X_test = train_test_split(ratings_pivot, train_size=0.8)\n",
    "# print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.to_csv(\"ratings2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many nodes each layer should have - Depending on the dataset's size\n",
    "movies_size = 15159 #58099\n",
    "n_nodes_inpl = movies_size\n",
    "n_nodes_hl1  = 256\n",
    "n_nodes_outl = movies_size\n",
    "\n",
    "# first hidden layer has 15159*256 weights and 256 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1, n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1, n_nodes_outl]))}\n",
    "\n",
    "input_layer = tf.placeholder('float', [None, movies_size])\n",
    "\n",
    "input_layer_const = tf.fill([tf.shape(input_layer)[0], 1], 1.0)\n",
    "input_layer_concat = tf.concat([input_layer, input_layer_const], 1)\n",
    "\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat, hidden_1_layer_vals['weights']))\n",
    "\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1], 1.0)\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "\n",
    "output_layer = tf.matmul(layer_concat, output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, movies_size])\n",
    "meansq = tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "\n",
    "learn_rate = 0.1   # learning rate\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)\n",
    "\n",
    "# initializing variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "writer.close()\n",
    "sess.run(init)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with one hidden layer\n",
    "\n",
    "![autoencoder with one layer](Images/autoencoders-1layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 103.61305168161442 MSE test 104.39914391376686\n",
      "Epoch 0 / 10000 loss: 2405.342124938965\n",
      "MSE train 88.75391705831747 MSE test 89.58262378900004\n",
      "Epoch 1 / 10000 loss: 2027.1185836791992\n",
      "MSE train 77.71646725737037 MSE test 78.42167132517308\n",
      "Epoch 2 / 10000 loss: 1756.1263122558594\n",
      "MSE train 69.20817850482163 MSE test 69.84069429708786\n",
      "Epoch 3 / 10000 loss: 1550.3154525756836\n",
      "MSE train 62.39136858247147 MSE test 62.978598688487715\n",
      "Epoch 4 / 10000 loss: 1389.608169555664\n",
      "MSE train 56.89096179580607 MSE test 57.536959658152426\n",
      "Epoch 5 / 10000 loss: 1259.2187118530273\n",
      "MSE train 52.49309155083232 MSE test 53.075452227451635\n",
      "Epoch 6 / 10000 loss: 1155.0602836608887\n",
      "MSE train 48.78740183551802 MSE test 49.393628651979654\n",
      "Epoch 7 / 10000 loss: 1070.0268630981445\n",
      "MSE train 45.614263571740516 MSE test 46.28982381901562\n",
      "Epoch 8 / 10000 loss: 997.1967010498047\n",
      "MSE train 42.9860053302266 MSE test 43.695583102031826\n",
      "Epoch 9 / 10000 loss: 935.8436622619629\n",
      "MSE train 40.70990814533569 MSE test 41.50209986474687\n",
      "Epoch 10 / 10000 loss: 884.1612396240234\n",
      "MSE train 38.74742888083352 MSE test 39.56643779585777\n",
      "Epoch 11 / 10000 loss: 839.2590103149414\n",
      "MSE train 37.04898914643897 MSE test 37.88537420061378\n",
      "Epoch 12 / 10000 loss: 800.361759185791\n",
      "MSE train 35.548640307548425 MSE test 36.42978562668809\n",
      "Epoch 13 / 10000 loss: 766.4652061462402\n",
      "MSE train 34.24144330327829 MSE test 35.15334349511506\n",
      "Epoch 14 / 10000 loss: 736.6649761199951\n",
      "MSE train 33.09507839484577 MSE test 34.027344961575636\n",
      "Epoch 15 / 10000 loss: 710.4128112792969\n",
      "MSE train 32.06815442526047 MSE test 33.02270468821827\n",
      "Epoch 16 / 10000 loss: 687.4333915710449\n",
      "MSE train 31.09270169035429 MSE test 32.084540934464435\n",
      "Epoch 17 / 10000 loss: 666.2726936340332\n",
      "MSE train 30.20041155223941 MSE test 31.237762461093684\n",
      "Epoch 18 / 10000 loss: 646.3899040222168\n",
      "MSE train 29.41107027091494 MSE test 30.467451339655387\n",
      "Epoch 19 / 10000 loss: 628.5202045440674\n",
      "MSE train 28.67611055632684 MSE test 29.75341454624556\n",
      "Epoch 20 / 10000 loss: 612.3000640869141\n",
      "MSE train 27.984947761363504 MSE test 29.094359194015535\n",
      "Epoch 21 / 10000 loss: 597.2652187347412\n",
      "MSE train 27.349641823030034 MSE test 28.493787994701034\n",
      "Epoch 22 / 10000 loss: 583.1324291229248\n",
      "MSE train 26.759038680353843 MSE test 27.93324521049476\n",
      "Epoch 23 / 10000 loss: 570.1415576934814\n",
      "MSE train 26.203366528422254 MSE test 27.397295032958446\n",
      "Epoch 24 / 10000 loss: 557.9945468902588\n",
      "MSE train 25.686432669647356 MSE test 26.893132942232203\n",
      "Epoch 25 / 10000 loss: 546.574857711792\n",
      "MSE train 25.216429766604143 MSE test 26.43870183784525\n",
      "Epoch 26 / 10000 loss: 536.0211734771729\n",
      "MSE train 24.768468794556306 MSE test 26.0147221897612\n",
      "Epoch 27 / 10000 loss: 526.3351745605469\n",
      "MSE train 24.33706281771224 MSE test 25.605346199470198\n",
      "Epoch 28 / 10000 loss: 516.9956741333008\n",
      "MSE train 23.928257286144532 MSE test 25.21712911181922\n",
      "Epoch 29 / 10000 loss: 508.0546226501465\n",
      "MSE train 23.544830117483773 MSE test 24.847899548047074\n",
      "Epoch 30 / 10000 loss: 499.63220405578613\n",
      "MSE train 23.17762877280465 MSE test 24.496955418985234\n",
      "Epoch 31 / 10000 loss: 491.687463760376\n",
      "MSE train 22.82239511854756 MSE test 24.15705629873636\n",
      "Epoch 32 / 10000 loss: 484.00868797302246\n",
      "MSE train 22.47988049537045 MSE test 23.832080711366107\n",
      "Epoch 33 / 10000 loss: 476.60086250305176\n",
      "MSE train 22.15394636630245 MSE test 23.51919914239609\n",
      "Epoch 34 / 10000 loss: 469.4863224029541\n",
      "MSE train 21.83906571918324 MSE test 23.217143724028876\n",
      "Epoch 35 / 10000 loss: 462.69273376464844\n",
      "MSE train 21.54308360581804 MSE test 22.934188538987982\n",
      "Epoch 36 / 10000 loss: 456.1751003265381\n",
      "MSE train 21.258680995078898 MSE test 22.663155669321494\n",
      "Epoch 37 / 10000 loss: 450.0182285308838\n",
      "MSE train 20.988136696267212 MSE test 22.404213845822486\n",
      "Epoch 38 / 10000 loss: 444.0857791900635\n",
      "MSE train 20.729591140268763 MSE test 22.15727092262488\n",
      "Epoch 39 / 10000 loss: 438.4742240905762\n",
      "MSE train 20.482419965012134 MSE test 21.91935853162337\n",
      "Epoch 40 / 10000 loss: 433.09545135498047\n",
      "MSE train 20.24699778156663 MSE test 21.692230846387186\n",
      "Epoch 41 / 10000 loss: 427.9672451019287\n",
      "MSE train 20.01369135124565 MSE test 21.47048960717778\n",
      "Epoch 42 / 10000 loss: 423.0421676635742\n",
      "MSE train 19.790592315747155 MSE test 21.258129893339678\n",
      "Epoch 43 / 10000 loss: 418.1940574645996\n",
      "MSE train 19.574358687064034 MSE test 21.052211382828027\n",
      "Epoch 44 / 10000 loss: 413.5321292877197\n",
      "MSE train 19.36540481714907 MSE test 20.85165670869216\n",
      "Epoch 45 / 10000 loss: 409.02270889282227\n",
      "MSE train 19.161591927173006 MSE test 20.656421298532237\n",
      "Epoch 46 / 10000 loss: 404.6605978012085\n",
      "MSE train 18.961663141328224 MSE test 20.46789881985349\n",
      "Epoch 47 / 10000 loss: 400.39252281188965\n",
      "MSE train 18.77260949490801 MSE test 20.287260615505193\n",
      "Epoch 48 / 10000 loss: 396.22492694854736\n",
      "MSE train 18.587995458414373 MSE test 20.111482793985736\n",
      "Epoch 49 / 10000 loss: 392.26868057250977\n",
      "MSE train 18.408156536439346 MSE test 19.940485687081075\n",
      "Epoch 50 / 10000 loss: 388.41232109069824\n",
      "MSE train 18.23600613101452 MSE test 19.77586569774327\n",
      "Epoch 51 / 10000 loss: 384.6640787124634\n",
      "MSE train 18.068971514529913 MSE test 19.614943123669853\n",
      "Epoch 52 / 10000 loss: 381.06914710998535\n",
      "MSE train 17.907118679725667 MSE test 19.458830725764066\n",
      "Epoch 53 / 10000 loss: 377.5892925262451\n",
      "MSE train 17.74984273225959 MSE test 19.306207799876532\n",
      "Epoch 54 / 10000 loss: 374.2043867111206\n",
      "MSE train 17.598057790850447 MSE test 19.15925473711902\n",
      "Epoch 55 / 10000 loss: 370.9320459365845\n",
      "MSE train 17.449838590392165 MSE test 19.014957307467178\n",
      "Epoch 56 / 10000 loss: 367.76107120513916\n",
      "MSE train 17.30437979743613 MSE test 18.87389831100064\n",
      "Epoch 57 / 10000 loss: 364.6646957397461\n",
      "MSE train 17.161653972305803 MSE test 18.737293515579484\n",
      "Epoch 58 / 10000 loss: 361.6220932006836\n",
      "MSE train 17.023823016388313 MSE test 18.60553145165091\n",
      "Epoch 59 / 10000 loss: 358.64787197113037\n",
      "MSE train 16.890774845376757 MSE test 18.477126520689527\n",
      "Epoch 60 / 10000 loss: 355.77179622650146\n",
      "MSE train 16.761420426261996 MSE test 18.3509533797375\n",
      "Epoch 61 / 10000 loss: 352.98795223236084\n",
      "MSE train 16.636644065000876 MSE test 18.22937760494525\n",
      "Epoch 62 / 10000 loss: 350.2877531051636\n",
      "MSE train 16.514390314965347 MSE test 18.110952151564796\n",
      "Epoch 63 / 10000 loss: 347.68188285827637\n",
      "MSE train 16.394044116998394 MSE test 17.99558839101576\n",
      "Epoch 64 / 10000 loss: 345.1195077896118\n",
      "MSE train 16.27770269182359 MSE test 17.882095404809554\n",
      "Epoch 65 / 10000 loss: 342.6082487106323\n",
      "MSE train 16.163334014898854 MSE test 17.770692974333805\n",
      "Epoch 66 / 10000 loss: 340.17330741882324\n",
      "MSE train 16.05226245067637 MSE test 17.661501851518654\n",
      "Epoch 67 / 10000 loss: 337.7824420928955\n",
      "MSE train 15.94240360844436 MSE test 17.555322221087323\n",
      "Epoch 68 / 10000 loss: 335.4578504562378\n",
      "MSE train 15.835735431922908 MSE test 17.452582516521403\n",
      "Epoch 69 / 10000 loss: 333.1571569442749\n",
      "MSE train 15.73197132302758 MSE test 17.3531432905349\n",
      "Epoch 70 / 10000 loss: 330.9317903518677\n",
      "MSE train 15.628398379749909 MSE test 17.255651848246288\n",
      "Epoch 71 / 10000 loss: 328.75503635406494\n",
      "MSE train 15.527081017099453 MSE test 17.160298858351066\n",
      "Epoch 72 / 10000 loss: 326.58488845825195\n",
      "MSE train 15.427179215126783 MSE test 17.066367178050246\n",
      "Epoch 73 / 10000 loss: 324.4675102233887\n",
      "MSE train 15.328531639550308 MSE test 16.973949603682122\n",
      "Epoch 74 / 10000 loss: 322.37176513671875\n",
      "MSE train 15.23332688209897 MSE test 16.88373697229369\n",
      "Epoch 75 / 10000 loss: 320.30696868896484\n",
      "MSE train 15.139285343888643 MSE test 16.79469913577765\n",
      "Epoch 76 / 10000 loss: 318.3143787384033\n",
      "MSE train 15.045809214405404 MSE test 16.706595534151642\n",
      "Epoch 77 / 10000 loss: 316.3426351547241\n",
      "MSE train 14.953803151438866 MSE test 16.619741723761265\n",
      "Epoch 78 / 10000 loss: 314.380654335022\n",
      "MSE train 14.863103630926933 MSE test 16.534511908064257\n",
      "Epoch 79 / 10000 loss: 312.45092010498047\n",
      "MSE train 14.773829954912328 MSE test 16.450556073312317\n",
      "Epoch 80 / 10000 loss: 310.54918479919434\n",
      "MSE train 14.686176248803834 MSE test 16.367757306071717\n",
      "Epoch 81 / 10000 loss: 308.67548847198486\n",
      "MSE train 14.600841713736946 MSE test 16.28740726239842\n",
      "Epoch 82 / 10000 loss: 306.8396348953247\n",
      "MSE train 14.51729113196439 MSE test 16.20828525839498\n",
      "Epoch 83 / 10000 loss: 305.04666805267334\n",
      "MSE train 14.43317238213873 MSE test 16.13031624264272\n",
      "Epoch 84 / 10000 loss: 303.29033374786377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 14.347830964585178 MSE test 16.05289847703229\n",
      "Epoch 85 / 10000 loss: 301.51487922668457\n",
      "MSE train 14.265031369241884 MSE test 15.977345792768855\n",
      "Epoch 86 / 10000 loss: 299.721887588501\n",
      "MSE train 14.182690514347005 MSE test 15.903104185639183\n",
      "Epoch 87 / 10000 loss: 297.9803466796875\n",
      "MSE train 14.103194935855447 MSE test 15.830429699153134\n",
      "Epoch 88 / 10000 loss: 296.2491798400879\n",
      "MSE train 14.02569952997984 MSE test 15.759507713350379\n",
      "Epoch 89 / 10000 loss: 294.5789852142334\n",
      "MSE train 13.949768790126791 MSE test 15.68988547338055\n",
      "Epoch 90 / 10000 loss: 292.9507713317871\n",
      "MSE train 13.876212159959056 MSE test 15.621266681919566\n",
      "Epoch 91 / 10000 loss: 291.35611724853516\n",
      "MSE train 13.8041779030753 MSE test 15.55430867119352\n",
      "Epoch 92 / 10000 loss: 289.81330013275146\n",
      "MSE train 13.73326700101128 MSE test 15.488722012825066\n",
      "Epoch 93 / 10000 loss: 288.29965019226074\n",
      "MSE train 13.663687713365151 MSE test 15.424808193793277\n",
      "Epoch 94 / 10000 loss: 286.8103675842285\n",
      "MSE train 13.594132095528694 MSE test 15.361771700173266\n",
      "Epoch 95 / 10000 loss: 285.34728717803955\n",
      "MSE train 13.525959211347704 MSE test 15.299749251837408\n",
      "Epoch 96 / 10000 loss: 283.88446521759033\n",
      "MSE train 13.460103791156266 MSE test 15.239324651646589\n",
      "Epoch 97 / 10000 loss: 282.45388412475586\n",
      "MSE train 13.394501995496976 MSE test 15.179631871382117\n",
      "Epoch 98 / 10000 loss: 281.0688600540161\n",
      "MSE train 13.329075879516239 MSE test 15.120234799627282\n",
      "Epoch 99 / 10000 loss: 279.68698024749756\n",
      "MSE train 13.265356225051665 MSE test 15.061770400810488\n",
      "Epoch 100 / 10000 loss: 278.3099670410156\n",
      "MSE train 13.203144076617804 MSE test 15.00418028872479\n",
      "Epoch 101 / 10000 loss: 276.97021675109863\n",
      "MSE train 13.141088306647797 MSE test 14.947307482723557\n",
      "Epoch 102 / 10000 loss: 275.66188049316406\n",
      "MSE train 13.079063834547139 MSE test 14.890310945972576\n",
      "Epoch 103 / 10000 loss: 274.35297298431396\n",
      "MSE train 13.016827273106227 MSE test 14.833555769612099\n",
      "Epoch 104 / 10000 loss: 273.0466299057007\n",
      "MSE train 12.955749599713217 MSE test 14.777504946519498\n",
      "Epoch 105 / 10000 loss: 271.73545837402344\n",
      "MSE train 12.89481696028158 MSE test 14.72263687897989\n",
      "Epoch 106 / 10000 loss: 270.44813537597656\n",
      "MSE train 12.8339170387778 MSE test 14.66823005607289\n",
      "Epoch 107 / 10000 loss: 269.16530323028564\n",
      "MSE train 12.774095007052736 MSE test 14.614097612526395\n",
      "Epoch 108 / 10000 loss: 267.88126277923584\n",
      "MSE train 12.715789646520205 MSE test 14.56120724110671\n",
      "Epoch 109 / 10000 loss: 266.62493228912354\n",
      "MSE train 12.657919174124478 MSE test 14.508981885537658\n",
      "Epoch 110 / 10000 loss: 265.3976049423218\n",
      "MSE train 12.60101928775438 MSE test 14.45735735490154\n",
      "Epoch 111 / 10000 loss: 264.17791175842285\n",
      "MSE train 12.54468022362982 MSE test 14.406752899063028\n",
      "Epoch 112 / 10000 loss: 262.9802436828613\n",
      "MSE train 12.489504584261029 MSE test 14.356984868340836\n",
      "Epoch 113 / 10000 loss: 261.79383182525635\n",
      "MSE train 12.43513539341298 MSE test 14.30801357324744\n",
      "Epoch 114 / 10000 loss: 260.63147354125977\n",
      "MSE train 12.381522187632955 MSE test 14.259938658979758\n",
      "Epoch 115 / 10000 loss: 259.4869546890259\n",
      "MSE train 12.329150930970759 MSE test 14.212869230390346\n",
      "Epoch 116 / 10000 loss: 258.3607482910156\n",
      "MSE train 12.277419718355564 MSE test 14.166385801243077\n",
      "Epoch 117 / 10000 loss: 257.25776863098145\n",
      "MSE train 12.226195227193143 MSE test 14.120677970112203\n",
      "Epoch 118 / 10000 loss: 256.1704168319702\n",
      "MSE train 12.17514437001394 MSE test 14.075302891321083\n",
      "Epoch 119 / 10000 loss: 255.0906276702881\n",
      "MSE train 12.12448859272505 MSE test 14.030479393739641\n",
      "Epoch 120 / 10000 loss: 254.01505184173584\n",
      "MSE train 12.075243084655876 MSE test 13.986440169785599\n",
      "Epoch 121 / 10000 loss: 252.94892978668213\n",
      "MSE train 12.026651142270358 MSE test 13.943048292068298\n",
      "Epoch 122 / 10000 loss: 251.9121217727661\n",
      "MSE train 11.978832851454928 MSE test 13.900306617048884\n",
      "Epoch 123 / 10000 loss: 250.88837814331055\n",
      "MSE train 11.931084527598463 MSE test 13.858035640407676\n",
      "Epoch 124 / 10000 loss: 249.8808183670044\n",
      "MSE train 11.884073527338064 MSE test 13.816062315262984\n",
      "Epoch 125 / 10000 loss: 248.87465381622314\n",
      "MSE train 11.837949259903754 MSE test 13.774721004829168\n",
      "Epoch 126 / 10000 loss: 247.8846197128296\n",
      "MSE train 11.791955117508232 MSE test 13.73361756856641\n",
      "Epoch 127 / 10000 loss: 246.9132080078125\n",
      "MSE train 11.747256203894759 MSE test 13.693286584787876\n",
      "Epoch 128 / 10000 loss: 245.94448566436768\n",
      "MSE train 11.702695071779749 MSE test 13.653342357287851\n",
      "Epoch 129 / 10000 loss: 245.0000705718994\n",
      "MSE train 11.658661913259733 MSE test 13.614176320209928\n",
      "Epoch 130 / 10000 loss: 244.06469631195068\n",
      "MSE train 11.614945370697173 MSE test 13.575579014957194\n",
      "Epoch 131 / 10000 loss: 243.1363697052002\n",
      "MSE train 11.572348419624559 MSE test 13.537760916021119\n",
      "Epoch 132 / 10000 loss: 242.21652030944824\n",
      "MSE train 11.529794479830667 MSE test 13.500353840991151\n",
      "Epoch 133 / 10000 loss: 241.31932735443115\n",
      "MSE train 11.48768654061893 MSE test 13.463286097722003\n",
      "Epoch 134 / 10000 loss: 240.4216947555542\n",
      "MSE train 11.446059850202627 MSE test 13.426756765508324\n",
      "Epoch 135 / 10000 loss: 239.53456592559814\n",
      "MSE train 11.40531924762091 MSE test 13.390592896466364\n",
      "Epoch 136 / 10000 loss: 238.65638160705566\n",
      "MSE train 11.365426194942506 MSE test 13.354713014473612\n",
      "Epoch 137 / 10000 loss: 237.7981948852539\n",
      "MSE train 11.325709148067563 MSE test 13.319379413593873\n",
      "Epoch 138 / 10000 loss: 236.9582061767578\n",
      "MSE train 11.286728661737758 MSE test 13.28445169033442\n",
      "Epoch 139 / 10000 loss: 236.12138843536377\n",
      "MSE train 11.247880737303408 MSE test 13.249962873704252\n",
      "Epoch 140 / 10000 loss: 235.29980659484863\n",
      "MSE train 11.208981029933124 MSE test 13.215596093396696\n",
      "Epoch 141 / 10000 loss: 234.48014068603516\n",
      "MSE train 11.170529835969647 MSE test 13.181654817997899\n",
      "Epoch 142 / 10000 loss: 233.65978813171387\n",
      "MSE train 11.132075096815056 MSE test 13.147919940052676\n",
      "Epoch 143 / 10000 loss: 232.848464012146\n",
      "MSE train 11.0936645548852 MSE test 13.114413625323788\n",
      "Epoch 144 / 10000 loss: 232.03712844848633\n",
      "MSE train 11.056185389069714 MSE test 13.08140526718916\n",
      "Epoch 145 / 10000 loss: 231.22718715667725\n",
      "MSE train 11.01923358636369 MSE test 13.048844528827056\n",
      "Epoch 146 / 10000 loss: 230.43669605255127\n",
      "MSE train 10.982597896143059 MSE test 13.016702459810515\n",
      "Epoch 147 / 10000 loss: 229.65701961517334\n",
      "MSE train 10.94591244189826 MSE test 12.984743665991388\n",
      "Epoch 148 / 10000 loss: 228.88332653045654\n",
      "MSE train 10.909744146503412 MSE test 12.953067872142055\n",
      "Epoch 149 / 10000 loss: 228.1090908050537\n",
      "MSE train 10.87351453494994 MSE test 12.92161420216281\n",
      "Epoch 150 / 10000 loss: 227.34550094604492\n",
      "MSE train 10.837725622259166 MSE test 12.890323302241411\n",
      "Epoch 151 / 10000 loss: 226.58004665374756\n",
      "MSE train 10.802779611838693 MSE test 12.859457592050429\n",
      "Epoch 152 / 10000 loss: 225.8256959915161\n",
      "MSE train 10.767866478370307 MSE test 12.828926653955701\n",
      "Epoch 153 / 10000 loss: 225.08799934387207\n",
      "MSE train 10.733261737033208 MSE test 12.798979181314293\n",
      "Epoch 154 / 10000 loss: 224.35046291351318\n",
      "MSE train 10.699144859404797 MSE test 12.769510347320537\n",
      "Epoch 155 / 10000 loss: 223.6199369430542\n",
      "MSE train 10.665868963432763 MSE test 12.74052948512027\n",
      "Epoch 156 / 10000 loss: 222.90044689178467\n",
      "MSE train 10.633021308272742 MSE test 12.71204954281417\n",
      "Epoch 157 / 10000 loss: 222.19811725616455\n",
      "MSE train 10.600188013335552 MSE test 12.683844017269692\n",
      "Epoch 158 / 10000 loss: 221.50373649597168\n",
      "MSE train 10.568344078946069 MSE test 12.656254323451718\n",
      "Epoch 159 / 10000 loss: 220.81112003326416\n",
      "MSE train 10.537112550855712 MSE test 12.62910457958675\n",
      "Epoch 160 / 10000 loss: 220.13905715942383\n",
      "MSE train 10.506759076232198 MSE test 12.602357984000738\n",
      "Epoch 161 / 10000 loss: 219.48069381713867\n",
      "MSE train 10.477172079736668 MSE test 12.576030735751575\n",
      "Epoch 162 / 10000 loss: 218.84079933166504\n",
      "MSE train 10.447948588351515 MSE test 12.549998715251807\n",
      "Epoch 163 / 10000 loss: 218.21684741973877\n",
      "MSE train 10.418933837760731 MSE test 12.524208062669574\n",
      "Epoch 164 / 10000 loss: 217.60023832321167\n",
      "MSE train 10.390245508075914 MSE test 12.498571017916573\n",
      "Epoch 165 / 10000 loss: 216.98799800872803\n",
      "MSE train 10.361484090211464 MSE test 12.473187115371763\n",
      "Epoch 166 / 10000 loss: 216.38253545761108\n",
      "MSE train 10.332453652384936 MSE test 12.44780970872645\n",
      "Epoch 167 / 10000 loss: 215.77433681488037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 10.303424151204766 MSE test 12.422860461485197\n",
      "Epoch 168 / 10000 loss: 215.16175270080566\n",
      "MSE train 10.274456829495092 MSE test 12.39801155732604\n",
      "Epoch 169 / 10000 loss: 214.54729557037354\n",
      "MSE train 10.246223828653138 MSE test 12.373480334156046\n",
      "Epoch 170 / 10000 loss: 213.93572807312012\n",
      "MSE train 10.218542548247218 MSE test 12.349216087012598\n",
      "Epoch 171 / 10000 loss: 213.3395791053772\n",
      "MSE train 10.190970989421691 MSE test 12.32499634076911\n",
      "Epoch 172 / 10000 loss: 212.75478315353394\n",
      "MSE train 10.16350022989562 MSE test 12.300967821043695\n",
      "Epoch 173 / 10000 loss: 212.1729712486267\n",
      "MSE train 10.13607721179628 MSE test 12.27710465097494\n",
      "Epoch 174 / 10000 loss: 211.59249687194824\n",
      "MSE train 10.109396232875913 MSE test 12.253633783280327\n",
      "Epoch 175 / 10000 loss: 211.0140085220337\n",
      "MSE train 10.082666469501996 MSE test 12.230290411063944\n",
      "Epoch 176 / 10000 loss: 210.45083618164062\n",
      "MSE train 10.055843533837466 MSE test 12.206974141248162\n",
      "Epoch 177 / 10000 loss: 209.8862180709839\n",
      "MSE train 10.02946339209043 MSE test 12.183805441637556\n",
      "Epoch 178 / 10000 loss: 209.32007694244385\n",
      "MSE train 10.003537402030341 MSE test 12.160938274905275\n",
      "Epoch 179 / 10000 loss: 208.7635416984558\n",
      "MSE train 9.977709448920901 MSE test 12.138215257320914\n",
      "Epoch 180 / 10000 loss: 208.21637773513794\n",
      "MSE train 9.952018579281393 MSE test 12.115594959789282\n",
      "Epoch 181 / 10000 loss: 207.67158126831055\n",
      "MSE train 9.9268046884103 MSE test 12.093167290433845\n",
      "Epoch 182 / 10000 loss: 207.1296706199646\n",
      "MSE train 9.901021654892718 MSE test 12.070763640582783\n",
      "Epoch 183 / 10000 loss: 206.59710884094238\n",
      "MSE train 9.875418019405894 MSE test 12.048480659140964\n",
      "Epoch 184 / 10000 loss: 206.05265140533447\n",
      "MSE train 9.849959245683193 MSE test 12.026342013821694\n",
      "Epoch 185 / 10000 loss: 205.51252222061157\n",
      "MSE train 9.824265365906394 MSE test 12.00423108164621\n",
      "Epoch 186 / 10000 loss: 204.97489261627197\n",
      "MSE train 9.79903927740852 MSE test 11.982400108154984\n",
      "Epoch 187 / 10000 loss: 204.43232917785645\n",
      "MSE train 9.773949499709765 MSE test 11.960758722728924\n",
      "Epoch 188 / 10000 loss: 203.89971256256104\n",
      "MSE train 9.748649712770147 MSE test 11.939239280118782\n",
      "Epoch 189 / 10000 loss: 203.36979913711548\n",
      "MSE train 9.724044869031205 MSE test 11.917871440277343\n",
      "Epoch 190 / 10000 loss: 202.83528518676758\n",
      "MSE train 9.699124414781508 MSE test 11.89677590466169\n",
      "Epoch 191 / 10000 loss: 202.31581211090088\n",
      "MSE train 9.67496587487562 MSE test 11.875918009488185\n",
      "Epoch 192 / 10000 loss: 201.78972244262695\n",
      "MSE train 9.651053307125263 MSE test 11.855197790651696\n",
      "Epoch 193 / 10000 loss: 201.27993202209473\n",
      "MSE train 9.627109954586647 MSE test 11.834597620169854\n",
      "Epoch 194 / 10000 loss: 200.77546644210815\n",
      "MSE train 9.603839826154966 MSE test 11.814169762706209\n",
      "Epoch 195 / 10000 loss: 200.2706708908081\n",
      "MSE train 9.580814749723439 MSE test 11.793748416185247\n",
      "Epoch 196 / 10000 loss: 199.77987480163574\n",
      "MSE train 9.55796194685108 MSE test 11.773558110645023\n",
      "Epoch 197 / 10000 loss: 199.29456043243408\n",
      "MSE train 9.53478467572222 MSE test 11.753379810798604\n",
      "Epoch 198 / 10000 loss: 198.81241464614868\n",
      "MSE train 9.511651857214845 MSE test 11.733230129121283\n",
      "Epoch 199 / 10000 loss: 198.32305240631104\n",
      "MSE train 9.488147713861787 MSE test 11.713069072216824\n",
      "Epoch 200 / 10000 loss: 197.8343186378479\n",
      "MSE train 9.464266101295767 MSE test 11.69284767422444\n",
      "Epoch 201 / 10000 loss: 197.33744382858276\n",
      "MSE train 9.440677140507296 MSE test 11.672720598985478\n",
      "Epoch 202 / 10000 loss: 196.8329701423645\n",
      "MSE train 9.417349181233767 MSE test 11.652757703815135\n",
      "Epoch 203 / 10000 loss: 196.33492136001587\n",
      "MSE train 9.394206312678335 MSE test 11.632847832617674\n",
      "Epoch 204 / 10000 loss: 195.842453956604\n",
      "MSE train 9.371085510168426 MSE test 11.612935753021429\n",
      "Epoch 205 / 10000 loss: 195.35388565063477\n",
      "MSE train 9.347748448727044 MSE test 11.592970447578471\n",
      "Epoch 206 / 10000 loss: 194.86549282073975\n",
      "MSE train 9.324702888792443 MSE test 11.573199046616786\n",
      "Epoch 207 / 10000 loss: 194.37285995483398\n",
      "MSE train 9.30198442453104 MSE test 11.553589346226847\n",
      "Epoch 208 / 10000 loss: 193.88649129867554\n",
      "MSE train 9.279371959973457 MSE test 11.534159930372978\n",
      "Epoch 209 / 10000 loss: 193.4070019721985\n",
      "MSE train 9.25708571497374 MSE test 11.51496309803654\n",
      "Epoch 210 / 10000 loss: 192.92962217330933\n",
      "MSE train 9.23514935529002 MSE test 11.496073874066312\n",
      "Epoch 211 / 10000 loss: 192.45941305160522\n",
      "MSE train 9.213221666208897 MSE test 11.47738686610728\n",
      "Epoch 212 / 10000 loss: 191.99638843536377\n",
      "MSE train 9.191312018156541 MSE test 11.458805190512235\n",
      "Epoch 213 / 10000 loss: 191.53337478637695\n",
      "MSE train 9.169121270981192 MSE test 11.440185151949597\n",
      "Epoch 214 / 10000 loss: 191.0709991455078\n",
      "MSE train 9.146987082441841 MSE test 11.421837049616489\n",
      "Epoch 215 / 10000 loss: 190.60223197937012\n",
      "MSE train 9.125718870065093 MSE test 11.403782192705561\n",
      "Epoch 216 / 10000 loss: 190.13528060913086\n",
      "MSE train 9.105214315395008 MSE test 11.385968386806345\n",
      "Epoch 217 / 10000 loss: 189.6873002052307\n",
      "MSE train 9.08480344158444 MSE test 11.368307857737992\n",
      "Epoch 218 / 10000 loss: 189.25546836853027\n",
      "MSE train 9.06373966173389 MSE test 11.350639229169081\n",
      "Epoch 219 / 10000 loss: 188.82488250732422\n",
      "MSE train 9.042655687426452 MSE test 11.333030345096299\n",
      "Epoch 220 / 10000 loss: 188.37994956970215\n",
      "MSE train 9.02197655533119 MSE test 11.315563029029521\n",
      "Epoch 221 / 10000 loss: 187.93473720550537\n",
      "MSE train 9.001747974775952 MSE test 11.298331887393418\n",
      "Epoch 222 / 10000 loss: 187.4990291595459\n",
      "MSE train 8.981307433228501 MSE test 11.281139285225372\n",
      "Epoch 223 / 10000 loss: 187.0719223022461\n",
      "MSE train 8.960831362133558 MSE test 11.263965740480625\n",
      "Epoch 224 / 10000 loss: 186.64017295837402\n",
      "MSE train 8.940457322285157 MSE test 11.24689711715926\n",
      "Epoch 225 / 10000 loss: 186.2078537940979\n",
      "MSE train 8.920271040442803 MSE test 11.229890648435331\n",
      "Epoch 226 / 10000 loss: 185.7777886390686\n",
      "MSE train 8.90042879495323 MSE test 11.212959732993204\n",
      "Epoch 227 / 10000 loss: 185.3520917892456\n",
      "MSE train 8.880822045619604 MSE test 11.196105152554212\n",
      "Epoch 228 / 10000 loss: 184.93360471725464\n",
      "MSE train 8.86098288534745 MSE test 11.179268462525958\n",
      "Epoch 229 / 10000 loss: 184.52005529403687\n",
      "MSE train 8.840998049135303 MSE test 11.162406323315576\n",
      "Epoch 230 / 10000 loss: 184.1012454032898\n",
      "MSE train 8.821291447350564 MSE test 11.145544695510514\n",
      "Epoch 231 / 10000 loss: 183.67948722839355\n",
      "MSE train 8.801652314266232 MSE test 11.128487447388508\n",
      "Epoch 232 / 10000 loss: 183.26370668411255\n",
      "MSE train 8.782567096360172 MSE test 11.11198884967163\n",
      "Epoch 233 / 10000 loss: 182.84989309310913\n",
      "MSE train 8.764132981612956 MSE test 11.09591506003656\n",
      "Epoch 234 / 10000 loss: 182.44779586791992\n",
      "MSE train 8.746139584370018 MSE test 11.080113198373118\n",
      "Epoch 235 / 10000 loss: 182.05948877334595\n",
      "MSE train 8.728327007583061 MSE test 11.064493752871064\n",
      "Epoch 236 / 10000 loss: 181.6802659034729\n",
      "MSE train 8.710781107870142 MSE test 11.049060982242601\n",
      "Epoch 237 / 10000 loss: 181.30531692504883\n",
      "MSE train 8.693558240440797 MSE test 11.033626960116127\n",
      "Epoch 238 / 10000 loss: 180.9355583190918\n",
      "MSE train 8.676606119100034 MSE test 11.018453756761236\n",
      "Epoch 239 / 10000 loss: 180.57323265075684\n",
      "MSE train 8.659720132587829 MSE test 11.00336726907897\n",
      "Epoch 240 / 10000 loss: 180.21630573272705\n",
      "MSE train 8.642711693678278 MSE test 10.988273092353676\n",
      "Epoch 241 / 10000 loss: 179.8605079650879\n",
      "MSE train 8.62565856710462 MSE test 10.973159279813109\n",
      "Epoch 242 / 10000 loss: 179.5019187927246\n",
      "MSE train 8.608117741841287 MSE test 10.957820452280473\n",
      "Epoch 243 / 10000 loss: 179.14208698272705\n",
      "MSE train 8.59099520025967 MSE test 10.942829566229564\n",
      "Epoch 244 / 10000 loss: 178.77190732955933\n",
      "MSE train 8.573726651226602 MSE test 10.927927859813673\n",
      "Epoch 245 / 10000 loss: 178.41081142425537\n",
      "MSE train 8.556156450549834 MSE test 10.912975076634266\n",
      "Epoch 246 / 10000 loss: 178.0465030670166\n",
      "MSE train 8.53861560669131 MSE test 10.898093144331767\n",
      "Epoch 247 / 10000 loss: 177.67590475082397\n",
      "MSE train 8.52089481780421 MSE test 10.883216666900966\n",
      "Epoch 248 / 10000 loss: 177.3061499595642\n",
      "MSE train 8.502976996110272 MSE test 10.868311262347216\n",
      "Epoch 249 / 10000 loss: 176.932466506958\n",
      "MSE train 8.485904457554561 MSE test 10.853652766342295\n",
      "Epoch 250 / 10000 loss: 176.55478954315186\n",
      "MSE train 8.469149834873704 MSE test 10.839204726738343\n",
      "Epoch 251 / 10000 loss: 176.19516515731812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 8.452699313274556 MSE test 10.824940638733462\n",
      "Epoch 252 / 10000 loss: 175.84223318099976\n",
      "MSE train 8.436372634872994 MSE test 10.81083649781613\n",
      "Epoch 253 / 10000 loss: 175.49571990966797\n",
      "MSE train 8.420148189403914 MSE test 10.796839345236375\n",
      "Epoch 254 / 10000 loss: 175.151602268219\n",
      "MSE train 8.40419677311923 MSE test 10.782988702903669\n",
      "Epoch 255 / 10000 loss: 174.80966186523438\n",
      "MSE train 8.388514320470172 MSE test 10.769282343771964\n",
      "Epoch 256 / 10000 loss: 174.47372102737427\n",
      "MSE train 8.372998602224776 MSE test 10.755713517598004\n",
      "Epoch 257 / 10000 loss: 174.14361429214478\n",
      "MSE train 8.357333725256398 MSE test 10.742268414522444\n",
      "Epoch 258 / 10000 loss: 173.81700468063354\n",
      "MSE train 8.341625872558163 MSE test 10.728921676089962\n",
      "Epoch 259 / 10000 loss: 173.48702907562256\n",
      "MSE train 8.325869500337639 MSE test 10.715684307175955\n",
      "Epoch 260 / 10000 loss: 173.1560254096985\n",
      "MSE train 8.310636010627801 MSE test 10.702628932210851\n",
      "Epoch 261 / 10000 loss: 172.82423877716064\n",
      "MSE train 8.29551583443841 MSE test 10.689704849982157\n",
      "Epoch 262 / 10000 loss: 172.50360870361328\n",
      "MSE train 8.280433179556628 MSE test 10.676887954422385\n",
      "Epoch 263 / 10000 loss: 172.18516159057617\n",
      "MSE train 8.265742203415925 MSE test 10.664198588228679\n",
      "Epoch 264 / 10000 loss: 171.8675332069397\n",
      "MSE train 8.251271626819499 MSE test 10.65166370474719\n",
      "Epoch 265 / 10000 loss: 171.55824375152588\n",
      "MSE train 8.236831943981802 MSE test 10.639200283555372\n",
      "Epoch 266 / 10000 loss: 171.25353145599365\n",
      "MSE train 8.22230787851789 MSE test 10.626784208893794\n",
      "Epoch 267 / 10000 loss: 170.94941186904907\n",
      "MSE train 8.207539257440102 MSE test 10.614383998396999\n",
      "Epoch 268 / 10000 loss: 170.6434383392334\n",
      "MSE train 8.192436414231047 MSE test 10.60197546856204\n",
      "Epoch 269 / 10000 loss: 170.33224773406982\n",
      "MSE train 8.177512455634899 MSE test 10.589589049651106\n",
      "Epoch 270 / 10000 loss: 170.01396465301514\n",
      "MSE train 8.16256095866598 MSE test 10.577284781639287\n",
      "Epoch 271 / 10000 loss: 169.69952630996704\n",
      "MSE train 8.147807525812206 MSE test 10.564972300144685\n",
      "Epoch 272 / 10000 loss: 169.3843674659729\n",
      "MSE train 8.133501762433138 MSE test 10.552851463418909\n",
      "Epoch 273 / 10000 loss: 169.07377243041992\n",
      "MSE train 8.119130358893267 MSE test 10.540821894312629\n",
      "Epoch 274 / 10000 loss: 168.77260065078735\n",
      "MSE train 8.104388121625053 MSE test 10.528822474413078\n",
      "Epoch 275 / 10000 loss: 168.46979475021362\n",
      "MSE train 8.08893399922829 MSE test 10.516770204953481\n",
      "Epoch 276 / 10000 loss: 168.1588397026062\n",
      "MSE train 8.074080540388396 MSE test 10.50479269452139\n",
      "Epoch 277 / 10000 loss: 167.83290147781372\n",
      "MSE train 8.059350187585636 MSE test 10.492869719324444\n",
      "Epoch 278 / 10000 loss: 167.51973867416382\n",
      "MSE train 8.04437515017471 MSE test 10.480878460538785\n",
      "Epoch 279 / 10000 loss: 167.2090139389038\n",
      "MSE train 8.029921666978069 MSE test 10.469148785789008\n",
      "Epoch 280 / 10000 loss: 166.89357614517212\n",
      "MSE train 8.015738411797837 MSE test 10.457529127436246\n",
      "Epoch 281 / 10000 loss: 166.589204788208\n",
      "MSE train 8.001518569578195 MSE test 10.445959170731706\n",
      "Epoch 282 / 10000 loss: 166.29031944274902\n",
      "MSE train 7.9875316078513485 MSE test 10.434495737499036\n",
      "Epoch 283 / 10000 loss: 165.99079132080078\n",
      "MSE train 7.97360034966873 MSE test 10.423118162842057\n",
      "Epoch 284 / 10000 loss: 165.6962924003601\n",
      "MSE train 7.959572997331334 MSE test 10.411781980524543\n",
      "Epoch 285 / 10000 loss: 165.4025902748108\n",
      "MSE train 7.945833968543182 MSE test 10.400614533020947\n",
      "Epoch 286 / 10000 loss: 165.1075005531311\n",
      "MSE train 7.932126015208858 MSE test 10.389532516987224\n",
      "Epoch 287 / 10000 loss: 164.81810092926025\n",
      "MSE train 7.918816994402025 MSE test 10.3786132462494\n",
      "Epoch 288 / 10000 loss: 164.52999258041382\n",
      "MSE train 7.9053966377275415 MSE test 10.36776817927709\n",
      "Epoch 289 / 10000 loss: 164.24983406066895\n",
      "MSE train 7.89222889560258 MSE test 10.357047206101702\n",
      "Epoch 290 / 10000 loss: 163.96727895736694\n",
      "MSE train 7.879376279868134 MSE test 10.346524619789765\n",
      "Epoch 291 / 10000 loss: 163.6902780532837\n",
      "MSE train 7.866407872299123 MSE test 10.336106552966026\n",
      "Epoch 292 / 10000 loss: 163.41966915130615\n",
      "MSE train 7.853513059818195 MSE test 10.325776669861384\n",
      "Epoch 293 / 10000 loss: 163.14642000198364\n",
      "MSE train 7.841104033615506 MSE test 10.315565740951232\n",
      "Epoch 294 / 10000 loss: 162.87510633468628\n",
      "MSE train 7.828867001993086 MSE test 10.305431764206073\n",
      "Epoch 295 / 10000 loss: 162.6138916015625\n",
      "MSE train 7.816694926854098 MSE test 10.295359174535538\n",
      "Epoch 296 / 10000 loss: 162.35622596740723\n",
      "MSE train 7.804443136948022 MSE test 10.285316889000486\n",
      "Epoch 297 / 10000 loss: 162.0997438430786\n",
      "MSE train 7.792102387668005 MSE test 10.275266320584672\n",
      "Epoch 298 / 10000 loss: 161.84136486053467\n",
      "MSE train 7.779524884715617 MSE test 10.265169945268235\n",
      "Epoch 299 / 10000 loss: 161.58089780807495\n",
      "MSE train 7.767175530605471 MSE test 10.255106501480494\n",
      "Epoch 300 / 10000 loss: 161.31535482406616\n",
      "MSE train 7.754892592371672 MSE test 10.245174112989652\n",
      "Epoch 301 / 10000 loss: 161.05484247207642\n",
      "MSE train 7.742517469595122 MSE test 10.235319957469816\n",
      "Epoch 302 / 10000 loss: 160.7956166267395\n",
      "MSE train 7.729977402718795 MSE test 10.225490649599543\n",
      "Epoch 303 / 10000 loss: 160.53442764282227\n",
      "MSE train 7.717749547633339 MSE test 10.21572526124502\n",
      "Epoch 304 / 10000 loss: 160.26979303359985\n",
      "MSE train 7.705476981969355 MSE test 10.205967617684625\n",
      "Epoch 305 / 10000 loss: 160.0117506980896\n",
      "MSE train 7.693312525654563 MSE test 10.196200717540224\n",
      "Epoch 306 / 10000 loss: 159.75258111953735\n",
      "MSE train 7.681368485295629 MSE test 10.186416998945408\n",
      "Epoch 307 / 10000 loss: 159.4956111907959\n",
      "MSE train 7.669623482656459 MSE test 10.176847713262907\n",
      "Epoch 308 / 10000 loss: 159.24356412887573\n",
      "MSE train 7.657984005505355 MSE test 10.16729678659071\n",
      "Epoch 309 / 10000 loss: 158.9954981803894\n",
      "MSE train 7.646473050346952 MSE test 10.157797404274463\n",
      "Epoch 310 / 10000 loss: 158.74966192245483\n",
      "MSE train 7.634790517798527 MSE test 10.148304775689168\n",
      "Epoch 311 / 10000 loss: 158.50652503967285\n",
      "MSE train 7.622810160313197 MSE test 10.138810780822572\n",
      "Epoch 312 / 10000 loss: 158.25966882705688\n",
      "MSE train 7.610967210162967 MSE test 10.129410328823074\n",
      "Epoch 313 / 10000 loss: 158.0065097808838\n",
      "MSE train 7.599372307241848 MSE test 10.12016708870003\n",
      "Epoch 314 / 10000 loss: 157.75642013549805\n",
      "MSE train 7.587945243825131 MSE test 10.110987106564043\n",
      "Epoch 315 / 10000 loss: 157.51162433624268\n",
      "MSE train 7.576711287589906 MSE test 10.10184653584263\n",
      "Epoch 316 / 10000 loss: 157.27042770385742\n",
      "MSE train 7.565582465642507 MSE test 10.092741746792514\n",
      "Epoch 317 / 10000 loss: 157.0334358215332\n",
      "MSE train 7.554003722964614 MSE test 10.08357056719085\n",
      "Epoch 318 / 10000 loss: 156.79862356185913\n",
      "MSE train 7.542810552729821 MSE test 10.074350365735112\n",
      "Epoch 319 / 10000 loss: 156.55405521392822\n",
      "MSE train 7.531667251462214 MSE test 10.065302185024462\n",
      "Epoch 320 / 10000 loss: 156.3179841041565\n",
      "MSE train 7.520373758582153 MSE test 10.056243855611255\n",
      "Epoch 321 / 10000 loss: 156.08280181884766\n",
      "MSE train 7.508737754233677 MSE test 10.047178864698985\n",
      "Epoch 322 / 10000 loss: 155.84421062469482\n",
      "MSE train 7.4970275614669095 MSE test 10.03807398107879\n",
      "Epoch 323 / 10000 loss: 155.5983395576477\n",
      "MSE train 7.485424441576215 MSE test 10.029007630490275\n",
      "Epoch 324 / 10000 loss: 155.35109758377075\n",
      "MSE train 7.474201263293653 MSE test 10.020018568183277\n",
      "Epoch 325 / 10000 loss: 155.10602521896362\n",
      "MSE train 7.462948732448236 MSE test 10.011080936873906\n",
      "Epoch 326 / 10000 loss: 154.8690948486328\n",
      "MSE train 7.4520030867195155 MSE test 10.002210427041694\n",
      "Epoch 327 / 10000 loss: 154.63149452209473\n",
      "MSE train 7.441094798084013 MSE test 9.993373946180592\n",
      "Epoch 328 / 10000 loss: 154.40045356750488\n",
      "MSE train 7.430046037929897 MSE test 9.984517878888944\n",
      "Epoch 329 / 10000 loss: 154.17016410827637\n",
      "MSE train 7.418836700928124 MSE test 9.9756195408749\n",
      "Epoch 330 / 10000 loss: 153.936842918396\n",
      "MSE train 7.4077154740969275 MSE test 9.966702876930492\n",
      "Epoch 331 / 10000 loss: 153.70012617111206\n",
      "MSE train 7.396767085488228 MSE test 9.957857778977509\n",
      "Epoch 332 / 10000 loss: 153.46543264389038\n",
      "MSE train 7.385837747660838 MSE test 9.94901412131543\n",
      "Epoch 333 / 10000 loss: 153.2342586517334\n",
      "MSE train 7.374978014307954 MSE test 9.940187294241774\n",
      "Epoch 334 / 10000 loss: 153.00334548950195\n",
      "MSE train 7.364104720705723 MSE test 9.931405595796456\n",
      "Epoch 335 / 10000 loss: 152.77383184432983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 7.353162112660694 MSE test 9.922647157950166\n",
      "Epoch 336 / 10000 loss: 152.54390287399292\n",
      "MSE train 7.342384302224616 MSE test 9.913915504700702\n",
      "Epoch 337 / 10000 loss: 152.312518119812\n",
      "MSE train 7.331777237154438 MSE test 9.905204854162468\n",
      "Epoch 338 / 10000 loss: 152.08468532562256\n",
      "MSE train 7.321285502812657 MSE test 9.896541614654893\n",
      "Epoch 339 / 10000 loss: 151.86043071746826\n",
      "MSE train 7.311001307662432 MSE test 9.888011635682075\n",
      "Epoch 340 / 10000 loss: 151.63869047164917\n",
      "MSE train 7.3009053511422 MSE test 9.87959907702634\n",
      "Epoch 341 / 10000 loss: 151.42144918441772\n",
      "MSE train 7.290843924803988 MSE test 9.871268086278782\n",
      "Epoch 342 / 10000 loss: 151.2081823348999\n",
      "MSE train 7.280945297441915 MSE test 9.863023473627132\n",
      "Epoch 343 / 10000 loss: 150.99561500549316\n",
      "MSE train 7.27107332675544 MSE test 9.854872343758599\n",
      "Epoch 344 / 10000 loss: 150.7865228652954\n",
      "MSE train 7.261175860812706 MSE test 9.846767132262546\n",
      "Epoch 345 / 10000 loss: 150.57784366607666\n",
      "MSE train 7.251319999952886 MSE test 9.838707233555246\n",
      "Epoch 346 / 10000 loss: 150.36856651306152\n",
      "MSE train 7.241598282164501 MSE test 9.830701138174387\n",
      "Epoch 347 / 10000 loss: 150.16018390655518\n",
      "MSE train 7.2319405856103245 MSE test 9.822756228635786\n",
      "Epoch 348 / 10000 loss: 149.9546947479248\n",
      "MSE train 7.222342247013833 MSE test 9.814854181972471\n",
      "Epoch 349 / 10000 loss: 149.75054264068604\n",
      "MSE train 7.212849862847585 MSE test 9.80698431789821\n",
      "Epoch 350 / 10000 loss: 149.54765224456787\n",
      "MSE train 7.203302070938259 MSE test 9.799123692594417\n",
      "Epoch 351 / 10000 loss: 149.34700775146484\n",
      "MSE train 7.193730866134189 MSE test 9.791273413218924\n",
      "Epoch 352 / 10000 loss: 149.14513969421387\n",
      "MSE train 7.184138042785007 MSE test 9.783439719334094\n",
      "Epoch 353 / 10000 loss: 148.94273567199707\n",
      "MSE train 7.174465064096506 MSE test 9.775614722594034\n",
      "Epoch 354 / 10000 loss: 148.73983335494995\n",
      "MSE train 7.164729659119333 MSE test 9.767786772657303\n",
      "Epoch 355 / 10000 loss: 148.53519439697266\n",
      "MSE train 7.154937598658669 MSE test 9.759951630606787\n",
      "Epoch 356 / 10000 loss: 148.32923793792725\n",
      "MSE train 7.145151632697911 MSE test 9.752119127227559\n",
      "Epoch 357 / 10000 loss: 148.1221022605896\n",
      "MSE train 7.1352892303247675 MSE test 9.744289994287348\n",
      "Epoch 358 / 10000 loss: 147.9150996208191\n",
      "MSE train 7.125436530774536 MSE test 9.736457154557497\n",
      "Epoch 359 / 10000 loss: 147.70636987686157\n",
      "MSE train 7.115737001523879 MSE test 9.728677310751321\n",
      "Epoch 360 / 10000 loss: 147.49782609939575\n",
      "MSE train 7.106172453198517 MSE test 9.720964152367923\n",
      "Epoch 361 / 10000 loss: 147.29259490966797\n",
      "MSE train 7.096667816680982 MSE test 9.713316361344328\n",
      "Epoch 362 / 10000 loss: 147.09030532836914\n",
      "MSE train 7.087139990863843 MSE test 9.705706886521497\n",
      "Epoch 363 / 10000 loss: 146.88928031921387\n",
      "MSE train 7.077677705897225 MSE test 9.698119274510063\n",
      "Epoch 364 / 10000 loss: 146.6877179145813\n",
      "MSE train 7.068270647162382 MSE test 9.690543328582791\n",
      "Epoch 365 / 10000 loss: 146.48755741119385\n",
      "MSE train 7.058825772885743 MSE test 9.682961368479948\n",
      "Epoch 366 / 10000 loss: 146.28855991363525\n",
      "MSE train 7.049206624848779 MSE test 9.675351643061742\n",
      "Epoch 367 / 10000 loss: 146.08871507644653\n",
      "MSE train 7.03981992599784 MSE test 9.667722528230566\n",
      "Epoch 368 / 10000 loss: 145.8851079940796\n",
      "MSE train 7.030512688541299 MSE test 9.660177370737614\n",
      "Epoch 369 / 10000 loss: 145.6866021156311\n",
      "MSE train 7.021038615018467 MSE test 9.652607520688278\n",
      "Epoch 370 / 10000 loss: 145.48964548110962\n",
      "MSE train 7.0115842022171515 MSE test 9.645032696742174\n",
      "Epoch 371 / 10000 loss: 145.2891092300415\n",
      "MSE train 7.002189779021527 MSE test 9.637475845505536\n",
      "Epoch 372 / 10000 loss: 145.08899307250977\n",
      "MSE train 6.992808800201754 MSE test 9.629946209011624\n",
      "Epoch 373 / 10000 loss: 144.89009428024292\n",
      "MSE train 6.982999594305549 MSE test 9.622395237481763\n",
      "Epoch 374 / 10000 loss: 144.69132137298584\n",
      "MSE train 6.973765907350713 MSE test 9.614946058450478\n",
      "Epoch 375 / 10000 loss: 144.48342847824097\n",
      "MSE train 6.964811058077635 MSE test 9.607573758712832\n",
      "Epoch 376 / 10000 loss: 144.28793859481812\n",
      "MSE train 6.95595369859128 MSE test 9.600291382190115\n",
      "Epoch 377 / 10000 loss: 144.09846544265747\n",
      "MSE train 6.9469049268938035 MSE test 9.593051326919264\n",
      "Epoch 378 / 10000 loss: 143.91095972061157\n",
      "MSE train 6.937664742791622 MSE test 9.585811925932097\n",
      "Epoch 379 / 10000 loss: 143.71909093856812\n",
      "MSE train 6.928939104468939 MSE test 9.578652794508576\n",
      "Epoch 380 / 10000 loss: 143.52371263504028\n",
      "MSE train 6.920171814863853 MSE test 9.57151643348894\n",
      "Epoch 381 / 10000 loss: 143.33896446228027\n",
      "MSE train 6.911262515429731 MSE test 9.56440249632038\n",
      "Epoch 382 / 10000 loss: 143.15324354171753\n",
      "MSE train 6.902370827156771 MSE test 9.557332822223154\n",
      "Epoch 383 / 10000 loss: 142.96442079544067\n",
      "MSE train 6.893850152937134 MSE test 9.550368501160621\n",
      "Epoch 384 / 10000 loss: 142.77602529525757\n",
      "MSE train 6.885587037748036 MSE test 9.543513087334746\n",
      "Epoch 385 / 10000 loss: 142.59567308425903\n",
      "MSE train 6.877481220477451 MSE test 9.536725935077373\n",
      "Epoch 386 / 10000 loss: 142.4208550453186\n",
      "MSE train 6.869485559442831 MSE test 9.5299866910493\n",
      "Epoch 387 / 10000 loss: 142.24941205978394\n",
      "MSE train 6.861469324693502 MSE test 9.523273830557633\n",
      "Epoch 388 / 10000 loss: 142.08032894134521\n",
      "MSE train 6.8533367786768515 MSE test 9.51656333859436\n",
      "Epoch 389 / 10000 loss: 141.91076946258545\n",
      "MSE train 6.845350793450376 MSE test 9.509887206902668\n",
      "Epoch 390 / 10000 loss: 141.73866748809814\n",
      "MSE train 6.83729573083572 MSE test 9.503226938069224\n",
      "Epoch 391 / 10000 loss: 141.56972217559814\n",
      "MSE train 6.829197472011777 MSE test 9.496552572135437\n",
      "Epoch 392 / 10000 loss: 141.3993067741394\n",
      "MSE train 6.821123120735631 MSE test 9.489867727442611\n",
      "Epoch 393 / 10000 loss: 141.22795820236206\n",
      "MSE train 6.81316239638895 MSE test 9.4831780529324\n",
      "Epoch 394 / 10000 loss: 141.0571117401123\n",
      "MSE train 6.8051502092188825 MSE test 9.476440049773432\n",
      "Epoch 395 / 10000 loss: 140.88872528076172\n",
      "MSE train 6.796992059951689 MSE test 9.469588536701137\n",
      "Epoch 396 / 10000 loss: 140.71919870376587\n",
      "MSE train 6.789132882423014 MSE test 9.462957114993172\n",
      "Epoch 397 / 10000 loss: 140.54645586013794\n",
      "MSE train 6.781672135227414 MSE test 9.456589645946057\n",
      "Epoch 398 / 10000 loss: 140.38032245635986\n",
      "MSE train 6.774341276795992 MSE test 9.45032087563677\n",
      "Epoch 399 / 10000 loss: 140.22277164459229\n",
      "MSE train 6.766974010887423 MSE test 9.444103338930438\n",
      "Epoch 400 / 10000 loss: 140.06797647476196\n",
      "MSE train 6.759453484496309 MSE test 9.437895289803631\n",
      "Epoch 401 / 10000 loss: 139.91235160827637\n",
      "MSE train 6.751682431451247 MSE test 9.4316690933488\n",
      "Epoch 402 / 10000 loss: 139.7533860206604\n",
      "MSE train 6.743598199208876 MSE test 9.425410311856991\n",
      "Epoch 403 / 10000 loss: 139.5889744758606\n",
      "MSE train 6.735372164367411 MSE test 9.419130605248103\n",
      "Epoch 404 / 10000 loss: 139.41777801513672\n",
      "MSE train 6.72696779885725 MSE test 9.412837757403102\n",
      "Epoch 405 / 10000 loss: 139.2434482574463\n",
      "MSE train 6.718899934172469 MSE test 9.406518302696089\n",
      "Epoch 406 / 10000 loss: 139.06526708602905\n",
      "MSE train 6.711112372472392 MSE test 9.400299296418096\n",
      "Epoch 407 / 10000 loss: 138.894700050354\n",
      "MSE train 6.70318957677418 MSE test 9.394063786073131\n",
      "Epoch 408 / 10000 loss: 138.72992372512817\n",
      "MSE train 6.6953227155937896 MSE test 9.387818104828877\n",
      "Epoch 409 / 10000 loss: 138.56216669082642\n",
      "MSE train 6.687689971765517 MSE test 9.38161511604588\n",
      "Epoch 410 / 10000 loss: 138.395583152771\n",
      "MSE train 6.680092699531638 MSE test 9.375436517084\n",
      "Epoch 411 / 10000 loss: 138.23403453826904\n",
      "MSE train 6.672500429479397 MSE test 9.369296685151367\n",
      "Epoch 412 / 10000 loss: 138.0732445716858\n",
      "MSE train 6.664890443815703 MSE test 9.363195151515137\n",
      "Epoch 413 / 10000 loss: 137.91258764266968\n",
      "MSE train 6.657181546848662 MSE test 9.357094758133666\n",
      "Epoch 414 / 10000 loss: 137.751531124115\n",
      "MSE train 6.649208748285478 MSE test 9.350931840149267\n",
      "Epoch 415 / 10000 loss: 137.58825254440308\n",
      "MSE train 6.641367609689073 MSE test 9.344832825794217\n",
      "Epoch 416 / 10000 loss: 137.41921615600586\n",
      "MSE train 6.633614952268376 MSE test 9.338846454024717\n",
      "Epoch 417 / 10000 loss: 137.25300979614258\n",
      "MSE train 6.626025254259113 MSE test 9.332912556231749\n",
      "Epoch 418 / 10000 loss: 137.08868885040283\n",
      "MSE train 6.618429477519309 MSE test 9.327029636545277\n",
      "Epoch 419 / 10000 loss: 136.92779111862183\n",
      "MSE train 6.611099927341849 MSE test 9.32120890941806\n",
      "Epoch 420 / 10000 loss: 136.76686763763428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.603904686678722 MSE test 9.315460263145662\n",
      "Epoch 421 / 10000 loss: 136.61182641983032\n",
      "MSE train 6.596746573725926 MSE test 9.30976298976512\n",
      "Epoch 422 / 10000 loss: 136.45938920974731\n",
      "MSE train 6.589649490176942 MSE test 9.30411138267807\n",
      "Epoch 423 / 10000 loss: 136.30773067474365\n",
      "MSE train 6.582686622960894 MSE test 9.29850368573119\n",
      "Epoch 424 / 10000 loss: 136.15739965438843\n",
      "MSE train 6.575733425860407 MSE test 9.292926354226433\n",
      "Epoch 425 / 10000 loss: 136.00998878479004\n",
      "MSE train 6.568512336153931 MSE test 9.287356070859293\n",
      "Epoch 426 / 10000 loss: 135.86276721954346\n",
      "MSE train 6.561080606555804 MSE test 9.281771118732358\n",
      "Epoch 427 / 10000 loss: 135.70974445343018\n",
      "MSE train 6.553940258841568 MSE test 9.276215189852028\n",
      "Epoch 428 / 10000 loss: 135.55257511138916\n",
      "MSE train 6.546973066246526 MSE test 9.270724931299716\n",
      "Epoch 429 / 10000 loss: 135.40154552459717\n",
      "MSE train 6.539781734221978 MSE test 9.265225761851113\n",
      "Epoch 430 / 10000 loss: 135.25408124923706\n",
      "MSE train 6.532868346600196 MSE test 9.259809293157126\n",
      "Epoch 431 / 10000 loss: 135.1017198562622\n",
      "MSE train 6.5259178230578785 MSE test 9.254401789742687\n",
      "Epoch 432 / 10000 loss: 134.9553279876709\n",
      "MSE train 6.519164730323092 MSE test 9.249062399158998\n",
      "Epoch 433 / 10000 loss: 134.8081979751587\n",
      "MSE train 6.512437851860562 MSE test 9.243764123240828\n",
      "Epoch 434 / 10000 loss: 134.66523551940918\n",
      "MSE train 6.505696522763532 MSE test 9.2385217790294\n",
      "Epoch 435 / 10000 loss: 134.52281856536865\n",
      "MSE train 6.498930820785912 MSE test 9.233299239009419\n",
      "Epoch 436 / 10000 loss: 134.38011074066162\n",
      "MSE train 6.492271153525479 MSE test 9.228093960572878\n",
      "Epoch 437 / 10000 loss: 134.23696327209473\n",
      "MSE train 6.485690926714361 MSE test 9.222902458011463\n",
      "Epoch 438 / 10000 loss: 134.09615325927734\n",
      "MSE train 6.478947525956609 MSE test 9.217697516825341\n",
      "Epoch 439 / 10000 loss: 133.95699644088745\n",
      "MSE train 6.472092344591379 MSE test 9.212469408317535\n",
      "Epoch 440 / 10000 loss: 133.8142809867859\n",
      "MSE train 6.465515697272542 MSE test 9.207306054925516\n",
      "Epoch 441 / 10000 loss: 133.66928672790527\n",
      "MSE train 6.458841177262314 MSE test 9.202139123883311\n",
      "Epoch 442 / 10000 loss: 133.53014659881592\n",
      "MSE train 6.452283700777632 MSE test 9.196985676412607\n",
      "Epoch 443 / 10000 loss: 133.38890266418457\n",
      "MSE train 6.445709992135238 MSE test 9.19184973842237\n",
      "Epoch 444 / 10000 loss: 133.2502088546753\n",
      "MSE train 6.438726271518943 MSE test 9.186686237082398\n",
      "Epoch 445 / 10000 loss: 133.11108684539795\n",
      "MSE train 6.431947178452942 MSE test 9.181539537189817\n",
      "Epoch 446 / 10000 loss: 132.9632749557495\n",
      "MSE train 6.425097775168733 MSE test 9.176389093641799\n",
      "Epoch 447 / 10000 loss: 132.81976556777954\n",
      "MSE train 6.418312489213695 MSE test 9.171234202177164\n",
      "Epoch 448 / 10000 loss: 132.67479991912842\n",
      "MSE train 6.411484126231774 MSE test 9.166065221631893\n",
      "Epoch 449 / 10000 loss: 132.53115558624268\n",
      "MSE train 6.404880128679496 MSE test 9.160913508662343\n",
      "Epoch 450 / 10000 loss: 132.3866319656372\n",
      "MSE train 6.3982635805552945 MSE test 9.155763315909846\n",
      "Epoch 451 / 10000 loss: 132.2469425201416\n",
      "MSE train 6.39164787612755 MSE test 9.150560201875939\n",
      "Epoch 452 / 10000 loss: 132.10689449310303\n",
      "MSE train 6.38515129514459 MSE test 9.145340171032094\n",
      "Epoch 453 / 10000 loss: 131.96697330474854\n",
      "MSE train 6.378698522756325 MSE test 9.140177172776315\n",
      "Epoch 454 / 10000 loss: 131.82956790924072\n",
      "MSE train 6.372150009183493 MSE test 9.135090103611402\n",
      "Epoch 455 / 10000 loss: 131.69309520721436\n",
      "MSE train 6.365367366020492 MSE test 9.130004463436622\n",
      "Epoch 456 / 10000 loss: 131.5544981956482\n",
      "MSE train 6.359059687620954 MSE test 9.125026841860223\n",
      "Epoch 457 / 10000 loss: 131.41094970703125\n",
      "MSE train 6.352948341439739 MSE test 9.120154202624624\n",
      "Epoch 458 / 10000 loss: 131.27770948410034\n",
      "MSE train 6.346850455143662 MSE test 9.11531627388109\n",
      "Epoch 459 / 10000 loss: 131.14854860305786\n",
      "MSE train 6.340689789983591 MSE test 9.110496569941418\n",
      "Epoch 460 / 10000 loss: 131.01958799362183\n",
      "MSE train 6.33456120203593 MSE test 9.105685206341374\n",
      "Epoch 461 / 10000 loss: 130.8892879486084\n",
      "MSE train 6.328575007508526 MSE test 9.100888361277535\n",
      "Epoch 462 / 10000 loss: 130.75973224639893\n",
      "MSE train 6.322619793800595 MSE test 9.096096783340773\n",
      "Epoch 463 / 10000 loss: 130.63320064544678\n",
      "MSE train 6.316644294181295 MSE test 9.091298672054641\n",
      "Epoch 464 / 10000 loss: 130.5073127746582\n",
      "MSE train 6.310587404276284 MSE test 9.086487741945895\n",
      "Epoch 465 / 10000 loss: 130.3809733390808\n",
      "MSE train 6.30432583823889 MSE test 9.081660604017863\n",
      "Epoch 466 / 10000 loss: 130.25286483764648\n",
      "MSE train 6.297922442622193 MSE test 9.076807216981326\n",
      "Epoch 467 / 10000 loss: 130.12032890319824\n",
      "MSE train 6.291645625250768 MSE test 9.072020928022733\n",
      "Epoch 468 / 10000 loss: 129.9846568107605\n",
      "MSE train 6.285572503936203 MSE test 9.067262577948236\n",
      "Epoch 469 / 10000 loss: 129.8517723083496\n",
      "MSE train 6.279684400056681 MSE test 9.06255258271891\n",
      "Epoch 470 / 10000 loss: 129.72330331802368\n",
      "MSE train 6.273745442232902 MSE test 9.057858957036338\n",
      "Epoch 471 / 10000 loss: 129.5988211631775\n",
      "MSE train 6.2679252308421125 MSE test 9.053182652091197\n",
      "Epoch 472 / 10000 loss: 129.4732141494751\n",
      "MSE train 6.262285591231874 MSE test 9.048585604586258\n",
      "Epoch 473 / 10000 loss: 129.35014629364014\n",
      "MSE train 6.256759199144027 MSE test 9.04402853940005\n",
      "Epoch 474 / 10000 loss: 129.230966091156\n",
      "MSE train 6.25132985566705 MSE test 9.039514097704274\n",
      "Epoch 475 / 10000 loss: 129.11423206329346\n",
      "MSE train 6.245955463531417 MSE test 9.035036568475267\n",
      "Epoch 476 / 10000 loss: 128.99957847595215\n",
      "MSE train 6.240608805221391 MSE test 9.03058972041158\n",
      "Epoch 477 / 10000 loss: 128.88609838485718\n",
      "MSE train 6.235268674006052 MSE test 9.026170168985368\n",
      "Epoch 478 / 10000 loss: 128.773202419281\n",
      "MSE train 6.22988850489166 MSE test 9.02177328315818\n",
      "Epoch 479 / 10000 loss: 128.66043090820312\n",
      "MSE train 6.224541651014369 MSE test 9.017396729948812\n",
      "Epoch 480 / 10000 loss: 128.54677438735962\n",
      "MSE train 6.2193051548731555 MSE test 9.013048253569755\n",
      "Epoch 481 / 10000 loss: 128.43383359909058\n",
      "MSE train 6.214077681013449 MSE test 9.008713401941874\n",
      "Epoch 482 / 10000 loss: 128.3232765197754\n",
      "MSE train 6.208806145329776 MSE test 9.004382635489952\n",
      "Epoch 483 / 10000 loss: 128.21291065216064\n",
      "MSE train 6.203523269935868 MSE test 9.000057724777706\n",
      "Epoch 484 / 10000 loss: 128.10161876678467\n",
      "MSE train 6.198349143281328 MSE test 8.995761014355411\n",
      "Epoch 485 / 10000 loss: 127.99011468887329\n",
      "MSE train 6.193239915862883 MSE test 8.991491616241925\n",
      "Epoch 486 / 10000 loss: 127.88094997406006\n",
      "MSE train 6.188143594951239 MSE test 8.987236736385627\n",
      "Epoch 487 / 10000 loss: 127.7731728553772\n",
      "MSE train 6.1830499505924035 MSE test 8.982987803554082\n",
      "Epoch 488 / 10000 loss: 127.66566371917725\n",
      "MSE train 6.177966912562148 MSE test 8.978738086989434\n",
      "Epoch 489 / 10000 loss: 127.55821561813354\n",
      "MSE train 6.172869171662704 MSE test 8.974480600888574\n",
      "Epoch 490 / 10000 loss: 127.4509949684143\n",
      "MSE train 6.16769836012875 MSE test 8.970203709855546\n",
      "Epoch 491 / 10000 loss: 127.34345197677612\n",
      "MSE train 6.162413336813123 MSE test 8.965895849082582\n",
      "Epoch 492 / 10000 loss: 127.2343258857727\n",
      "MSE train 6.157073560280133 MSE test 8.961570116200134\n",
      "Epoch 493 / 10000 loss: 127.12275457382202\n",
      "MSE train 6.151781115803098 MSE test 8.957268047379088\n",
      "Epoch 494 / 10000 loss: 127.01003217697144\n",
      "MSE train 6.146614101623414 MSE test 8.953015902919208\n",
      "Epoch 495 / 10000 loss: 126.89837551116943\n",
      "MSE train 6.141463390375648 MSE test 8.948799514387805\n",
      "Epoch 496 / 10000 loss: 126.78938055038452\n",
      "MSE train 6.136165409687841 MSE test 8.94458299131235\n",
      "Epoch 497 / 10000 loss: 126.68068170547485\n",
      "MSE train 6.13116922355875 MSE test 8.940399320702788\n",
      "Epoch 498 / 10000 loss: 126.56876611709595\n",
      "MSE train 6.126236715962507 MSE test 8.936264133887688\n",
      "Epoch 499 / 10000 loss: 126.46334743499756\n",
      "MSE train 6.121280070611956 MSE test 8.932130865070429\n",
      "Epoch 500 / 10000 loss: 126.35929775238037\n",
      "MSE train 6.116265066158672 MSE test 8.927990794878944\n",
      "Epoch 501 / 10000 loss: 126.25471353530884\n",
      "MSE train 6.111153835716608 MSE test 8.923838187761309\n",
      "Epoch 502 / 10000 loss: 126.14886665344238\n",
      "MSE train 6.105936336936192 MSE test 8.91967371899073\n",
      "Epoch 503 / 10000 loss: 126.04093647003174\n",
      "MSE train 6.100686177944639 MSE test 8.915509106772435\n",
      "Epoch 504 / 10000 loss: 125.93071508407593\n",
      "MSE train 6.095443254104371 MSE test 8.9113582466063\n",
      "Epoch 505 / 10000 loss: 125.81978368759155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 6.090151673484162 MSE test 8.907218413533954\n",
      "Epoch 506 / 10000 loss: 125.70901298522949\n",
      "MSE train 6.084838194641301 MSE test 8.903085470809037\n",
      "Epoch 507 / 10000 loss: 125.59719800949097\n",
      "MSE train 6.07950839140204 MSE test 8.898961165812647\n",
      "Epoch 508 / 10000 loss: 125.48492431640625\n",
      "MSE train 6.074184520976894 MSE test 8.894860462318299\n",
      "Epoch 509 / 10000 loss: 125.372323513031\n",
      "MSE train 6.069144971018727 MSE test 8.890819956669413\n",
      "Epoch 510 / 10000 loss: 125.25988721847534\n",
      "MSE train 6.064221070139794 MSE test 8.886833835505907\n",
      "Epoch 511 / 10000 loss: 125.15359878540039\n",
      "MSE train 6.059329597366928 MSE test 8.882875975735846\n",
      "Epoch 512 / 10000 loss: 125.04980611801147\n",
      "MSE train 6.054423102522193 MSE test 8.878932734122401\n",
      "Epoch 513 / 10000 loss: 124.94673109054565\n",
      "MSE train 6.049461832572591 MSE test 8.874994325345451\n",
      "Epoch 514 / 10000 loss: 124.84333181381226\n",
      "MSE train 6.044288619841526 MSE test 8.871046980872066\n",
      "Epoch 515 / 10000 loss: 124.73875999450684\n",
      "MSE train 6.039146824673756 MSE test 8.86707597932963\n",
      "Epoch 516 / 10000 loss: 124.62961721420288\n",
      "MSE train 6.033883438085329 MSE test 8.863130318209125\n",
      "Epoch 517 / 10000 loss: 124.52119588851929\n",
      "MSE train 6.028873523578158 MSE test 8.859200020358523\n",
      "Epoch 518 / 10000 loss: 124.41001510620117\n",
      "MSE train 6.023879629207516 MSE test 8.855254588425677\n",
      "Epoch 519 / 10000 loss: 124.30430364608765\n",
      "MSE train 6.018852151812524 MSE test 8.851282483268495\n",
      "Epoch 520 / 10000 loss: 124.1988844871521\n",
      "MSE train 6.013599077651506 MSE test 8.847260292098179\n",
      "Epoch 521 / 10000 loss: 124.09267950057983\n",
      "MSE train 6.0082815445147295 MSE test 8.843193024037625\n",
      "Epoch 522 / 10000 loss: 123.9816689491272\n",
      "MSE train 6.00296482528461 MSE test 8.839186814331667\n",
      "Epoch 523 / 10000 loss: 123.86951446533203\n",
      "MSE train 5.997829443998007 MSE test 8.835206697278974\n",
      "Epoch 524 / 10000 loss: 123.757155418396\n",
      "MSE train 5.992802870516081 MSE test 8.831227724613987\n",
      "Epoch 525 / 10000 loss: 123.64858293533325\n",
      "MSE train 5.987701666821128 MSE test 8.827231557246595\n",
      "Epoch 526 / 10000 loss: 123.5424656867981\n",
      "MSE train 5.982558859007921 MSE test 8.823203586460236\n",
      "Epoch 527 / 10000 loss: 123.43474960327148\n",
      "MSE train 5.977669746948774 MSE test 8.819220360862936\n",
      "Epoch 528 / 10000 loss: 123.3261947631836\n",
      "MSE train 5.972800754959473 MSE test 8.815249240720494\n",
      "Epoch 529 / 10000 loss: 123.22287464141846\n",
      "MSE train 5.9678347556955 MSE test 8.811277108341592\n",
      "Epoch 530 / 10000 loss: 123.11999082565308\n",
      "MSE train 5.96276067360652 MSE test 8.807283221899237\n",
      "Epoch 531 / 10000 loss: 123.01498126983643\n",
      "MSE train 5.957771012295048 MSE test 8.803296155100766\n",
      "Epoch 532 / 10000 loss: 122.90766954421997\n",
      "MSE train 5.952735120406661 MSE test 8.799287275617948\n",
      "Epoch 533 / 10000 loss: 122.8021388053894\n",
      "MSE train 5.947864018861839 MSE test 8.795326715989328\n",
      "Epoch 534 / 10000 loss: 122.69561576843262\n",
      "MSE train 5.942953592249246 MSE test 8.791394234174977\n",
      "Epoch 535 / 10000 loss: 122.5926513671875\n",
      "MSE train 5.93807154162022 MSE test 8.787462001154822\n",
      "Epoch 536 / 10000 loss: 122.48882579803467\n",
      "MSE train 5.933271229068245 MSE test 8.783524844385656\n",
      "Epoch 537 / 10000 loss: 122.38562870025635\n",
      "MSE train 5.928437519298893 MSE test 8.77957028433621\n",
      "Epoch 538 / 10000 loss: 122.28420162200928\n",
      "MSE train 5.923343925531854 MSE test 8.775554353076952\n",
      "Epoch 539 / 10000 loss: 122.18205404281616\n",
      "MSE train 5.918590783161476 MSE test 8.771602789056336\n",
      "Epoch 540 / 10000 loss: 122.07430934906006\n",
      "MSE train 5.91384582855198 MSE test 8.767649719983607\n",
      "Epoch 541 / 10000 loss: 121.97392559051514\n",
      "MSE train 5.90909961786226 MSE test 8.763691063864533\n",
      "Epoch 542 / 10000 loss: 121.87371397018433\n",
      "MSE train 5.904346712240352 MSE test 8.759726506578618\n",
      "Epoch 543 / 10000 loss: 121.77347803115845\n",
      "MSE train 5.899594121105624 MSE test 8.755760315054351\n",
      "Epoch 544 / 10000 loss: 121.67311239242554\n",
      "MSE train 5.8948581803171605 MSE test 8.751801374846123\n",
      "Epoch 545 / 10000 loss: 121.57275390625\n",
      "MSE train 5.890127411901328 MSE test 8.74785547225969\n",
      "Epoch 546 / 10000 loss: 121.47275257110596\n",
      "MSE train 5.885365757448364 MSE test 8.743921225666028\n",
      "Epoch 547 / 10000 loss: 121.37284994125366\n",
      "MSE train 5.880489505379884 MSE test 8.7399927600831\n",
      "Epoch 548 / 10000 loss: 121.27225303649902\n",
      "MSE train 5.875531865649408 MSE test 8.73606505413122\n",
      "Epoch 549 / 10000 loss: 121.16916990280151\n",
      "MSE train 5.870758257317356 MSE test 8.732190464208376\n",
      "Epoch 550 / 10000 loss: 121.0644850730896\n",
      "MSE train 5.8660392426012935 MSE test 8.728350148940102\n",
      "Epoch 551 / 10000 loss: 120.96369886398315\n",
      "MSE train 5.861220945065933 MSE test 8.724525083547778\n",
      "Epoch 552 / 10000 loss: 120.86408853530884\n",
      "MSE train 5.856415420815766 MSE test 8.720706173403963\n",
      "Epoch 553 / 10000 loss: 120.76235103607178\n",
      "MSE train 5.851755328268486 MSE test 8.716935659051657\n",
      "Epoch 554 / 10000 loss: 120.6609058380127\n",
      "MSE train 5.84705061890247 MSE test 8.71318747528728\n",
      "Epoch 555 / 10000 loss: 120.56251239776611\n",
      "MSE train 5.842195677383556 MSE test 8.709449555956725\n",
      "Epoch 556 / 10000 loss: 120.4631290435791\n",
      "MSE train 5.837609900181774 MSE test 8.705760691911477\n",
      "Epoch 557 / 10000 loss: 120.36046886444092\n",
      "MSE train 5.833176558341514 MSE test 8.702108136129894\n",
      "Epoch 558 / 10000 loss: 120.26362133026123\n",
      "MSE train 5.828837980276069 MSE test 8.698490112561313\n",
      "Epoch 559 / 10000 loss: 120.1700496673584\n",
      "MSE train 5.824567492252341 MSE test 8.694896794699677\n",
      "Epoch 560 / 10000 loss: 120.07850694656372\n",
      "MSE train 5.8203628446400595 MSE test 8.691321892733425\n",
      "Epoch 561 / 10000 loss: 119.9884295463562\n",
      "MSE train 5.816176586041607 MSE test 8.687755866620236\n",
      "Epoch 562 / 10000 loss: 119.8997573852539\n",
      "MSE train 5.811974803792806 MSE test 8.684189045107106\n",
      "Epoch 563 / 10000 loss: 119.8114686012268\n",
      "MSE train 5.807733792992007 MSE test 8.680613938637807\n",
      "Epoch 564 / 10000 loss: 119.7228422164917\n",
      "MSE train 5.803430865342394 MSE test 8.677024981865047\n",
      "Epoch 565 / 10000 loss: 119.63336372375488\n",
      "MSE train 5.799035432748984 MSE test 8.673417879625342\n",
      "Epoch 566 / 10000 loss: 119.54256868362427\n",
      "MSE train 5.7945534247792665 MSE test 8.669793318710266\n",
      "Epoch 567 / 10000 loss: 119.4498119354248\n",
      "MSE train 5.790152100518127 MSE test 8.666176581263475\n",
      "Epoch 568 / 10000 loss: 119.35525703430176\n",
      "MSE train 5.785885981143179 MSE test 8.662602350078364\n",
      "Epoch 569 / 10000 loss: 119.26247119903564\n",
      "MSE train 5.7816594402522234 MSE test 8.659055375882867\n",
      "Epoch 570 / 10000 loss: 119.17257118225098\n",
      "MSE train 5.77743661816827 MSE test 8.655519284180825\n",
      "Epoch 571 / 10000 loss: 119.08348083496094\n",
      "MSE train 5.773193292090803 MSE test 8.651984528572763\n",
      "Epoch 572 / 10000 loss: 118.99443817138672\n",
      "MSE train 5.768892099589708 MSE test 8.648443164349137\n",
      "Epoch 573 / 10000 loss: 118.90491771697998\n",
      "MSE train 5.764488628374992 MSE test 8.644887575188704\n",
      "Epoch 574 / 10000 loss: 118.81411838531494\n",
      "MSE train 5.75999558032663 MSE test 8.641315736913578\n",
      "Epoch 575 / 10000 loss: 118.72110652923584\n",
      "MSE train 5.755578454885433 MSE test 8.637747307135962\n",
      "Epoch 576 / 10000 loss: 118.62622690200806\n",
      "MSE train 5.751257926220271 MSE test 8.634199939692907\n",
      "Epoch 577 / 10000 loss: 118.53302478790283\n",
      "MSE train 5.7469274527805885 MSE test 8.630655930811555\n",
      "Epoch 578 / 10000 loss: 118.44185209274292\n",
      "MSE train 5.742479594894226 MSE test 8.627102287956825\n",
      "Epoch 579 / 10000 loss: 118.35042190551758\n",
      "MSE train 5.737923824652984 MSE test 8.62352980746782\n",
      "Epoch 580 / 10000 loss: 118.25642967224121\n",
      "MSE train 5.733418884521457 MSE test 8.619943382836984\n",
      "Epoch 581 / 10000 loss: 118.16007089614868\n",
      "MSE train 5.728871718927405 MSE test 8.61633823320699\n",
      "Epoch 582 / 10000 loss: 118.06479454040527\n",
      "MSE train 5.724335196400664 MSE test 8.612718546232282\n",
      "Epoch 583 / 10000 loss: 117.96859455108643\n",
      "MSE train 5.7198103468583 MSE test 8.609083978724499\n",
      "Epoch 584 / 10000 loss: 117.87262201309204\n",
      "MSE train 5.715282880229169 MSE test 8.605435321036591\n",
      "Epoch 585 / 10000 loss: 117.77690410614014\n",
      "MSE train 5.7107603999741965 MSE test 8.601781168693023\n",
      "Epoch 586 / 10000 loss: 117.68113470077515\n",
      "MSE train 5.706254014378824 MSE test 8.598133493466884\n",
      "Epoch 587 / 10000 loss: 117.5854697227478\n",
      "MSE train 5.701755426911821 MSE test 8.594493875362007\n",
      "Epoch 588 / 10000 loss: 117.49014043807983\n",
      "MSE train 5.697299934399112 MSE test 8.59085660327479\n",
      "Epoch 589 / 10000 loss: 117.39497709274292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.69292814551564 MSE test 8.587217868678346\n",
      "Epoch 590 / 10000 loss: 117.30073595046997\n",
      "MSE train 5.688598774627195 MSE test 8.58357536199026\n",
      "Epoch 591 / 10000 loss: 117.20829391479492\n",
      "MSE train 5.684256822763315 MSE test 8.579936512303851\n",
      "Epoch 592 / 10000 loss: 117.11675024032593\n",
      "MSE train 5.6798746082768465 MSE test 8.576318039721864\n",
      "Epoch 593 / 10000 loss: 117.02491521835327\n",
      "MSE train 5.675455077907383 MSE test 8.572725917640243\n",
      "Epoch 594 / 10000 loss: 116.93220090866089\n",
      "MSE train 5.670965075614774 MSE test 8.569133834389833\n",
      "Epoch 595 / 10000 loss: 116.83867025375366\n",
      "MSE train 5.666595975955608 MSE test 8.565522339359166\n",
      "Epoch 596 / 10000 loss: 116.74362993240356\n",
      "MSE train 5.662152853685486 MSE test 8.561817290974957\n",
      "Epoch 597 / 10000 loss: 116.65121698379517\n",
      "MSE train 5.657858345089224 MSE test 8.558062780839006\n",
      "Epoch 598 / 10000 loss: 116.55727100372314\n",
      "MSE train 5.6537150094343405 MSE test 8.554701682071011\n",
      "Epoch 599 / 10000 loss: 116.46651935577393\n",
      "MSE train 5.649644261881146 MSE test 8.551371582080849\n",
      "Epoch 600 / 10000 loss: 116.37902975082397\n",
      "MSE train 5.645623661830447 MSE test 8.548060281134168\n",
      "Epoch 601 / 10000 loss: 116.2930679321289\n",
      "MSE train 5.641657595522004 MSE test 8.544763980870345\n",
      "Epoch 602 / 10000 loss: 116.20815515518188\n",
      "MSE train 5.637739686798416 MSE test 8.541483168059228\n",
      "Epoch 603 / 10000 loss: 116.1244044303894\n",
      "MSE train 5.633850821244661 MSE test 8.538216301692815\n",
      "Epoch 604 / 10000 loss: 116.04167604446411\n",
      "MSE train 5.629940909359828 MSE test 8.534957628995375\n",
      "Epoch 605 / 10000 loss: 115.95956563949585\n",
      "MSE train 5.6259562450953275 MSE test 8.531698691319493\n",
      "Epoch 606 / 10000 loss: 115.8769793510437\n",
      "MSE train 5.621925637833217 MSE test 8.5284334901316\n",
      "Epoch 607 / 10000 loss: 115.79277467727661\n",
      "MSE train 5.617911487048854 MSE test 8.525165747849687\n",
      "Epoch 608 / 10000 loss: 115.707594871521\n",
      "MSE train 5.613894560000687 MSE test 8.521912236727507\n",
      "Epoch 609 / 10000 loss: 115.62277221679688\n",
      "MSE train 5.609878154826689 MSE test 8.518697264339846\n",
      "Epoch 610 / 10000 loss: 115.53790330886841\n",
      "MSE train 5.605855205526664 MSE test 8.515510951925863\n",
      "Epoch 611 / 10000 loss: 115.45304203033447\n",
      "MSE train 5.601744063957701 MSE test 8.512331808065545\n",
      "Epoch 612 / 10000 loss: 115.36802768707275\n",
      "MSE train 5.597526163957063 MSE test 8.509139159849706\n",
      "Epoch 613 / 10000 loss: 115.28109645843506\n",
      "MSE train 5.593592209815818 MSE test 8.505994507405125\n",
      "Epoch 614 / 10000 loss: 115.19188165664673\n",
      "MSE train 5.58972063838667 MSE test 8.502896633910119\n",
      "Epoch 615 / 10000 loss: 115.10882616043091\n",
      "MSE train 5.585829156696309 MSE test 8.49981037315351\n",
      "Epoch 616 / 10000 loss: 115.02708625793457\n",
      "MSE train 5.581844984681754 MSE test 8.496727304952833\n",
      "Epoch 617 / 10000 loss: 114.94491052627563\n",
      "MSE train 5.577695110447171 MSE test 8.49363960789686\n",
      "Epoch 618 / 10000 loss: 114.86070203781128\n",
      "MSE train 5.573617046649166 MSE test 8.490557013597455\n",
      "Epoch 619 / 10000 loss: 114.7729721069336\n",
      "MSE train 5.569708069409427 MSE test 8.487490687291414\n",
      "Epoch 620 / 10000 loss: 114.68677043914795\n",
      "MSE train 5.565938328495532 MSE test 8.484456168901701\n",
      "Epoch 621 / 10000 loss: 114.6042366027832\n",
      "MSE train 5.562109497815734 MSE test 8.481426733565021\n",
      "Epoch 622 / 10000 loss: 114.52469730377197\n",
      "MSE train 5.558090761250899 MSE test 8.47838025637822\n",
      "Epoch 623 / 10000 loss: 114.44386863708496\n",
      "MSE train 5.553936197705502 MSE test 8.475302604911485\n",
      "Epoch 624 / 10000 loss: 114.35891628265381\n",
      "MSE train 5.55000341595544 MSE test 8.472251388221945\n",
      "Epoch 625 / 10000 loss: 114.27107810974121\n",
      "MSE train 5.5460323624111965 MSE test 8.469221623780975\n",
      "Epoch 626 / 10000 loss: 114.18805074691772\n",
      "MSE train 5.541934583129866 MSE test 8.466167534211648\n",
      "Epoch 627 / 10000 loss: 114.10413455963135\n",
      "MSE train 5.5379702720748964 MSE test 8.463123038421783\n",
      "Epoch 628 / 10000 loss: 114.01745700836182\n",
      "MSE train 5.534078775207531 MSE test 8.460100980463922\n",
      "Epoch 629 / 10000 loss: 113.9336485862732\n",
      "MSE train 5.530228249243712 MSE test 8.457103516033637\n",
      "Epoch 630 / 10000 loss: 113.8514175415039\n",
      "MSE train 5.526557373025634 MSE test 8.454147239562646\n",
      "Epoch 631 / 10000 loss: 113.77013492584229\n",
      "MSE train 5.522969528571984 MSE test 8.451231213792827\n",
      "Epoch 632 / 10000 loss: 113.69279456138611\n",
      "MSE train 5.5193286430320745 MSE test 8.448323404626978\n",
      "Epoch 633 / 10000 loss: 113.61721801757812\n",
      "MSE train 5.515537627812074 MSE test 8.445401157180084\n",
      "Epoch 634 / 10000 loss: 113.5404760837555\n",
      "MSE train 5.51169280061824 MSE test 8.442472273449072\n",
      "Epoch 635 / 10000 loss: 113.46048784255981\n",
      "MSE train 5.507971593113839 MSE test 8.439576253415822\n",
      "Epoch 636 / 10000 loss: 113.37935376167297\n",
      "MSE train 5.504275995224905 MSE test 8.436705138985047\n",
      "Epoch 637 / 10000 loss: 113.30086970329285\n",
      "MSE train 5.5005662186001905 MSE test 8.433857400221058\n",
      "Epoch 638 / 10000 loss: 113.22293496131897\n",
      "MSE train 5.496874488867983 MSE test 8.431028991336634\n",
      "Epoch 639 / 10000 loss: 113.14470529556274\n",
      "MSE train 5.493222153289497 MSE test 8.42821643347227\n",
      "Epoch 640 / 10000 loss: 113.06686902046204\n",
      "MSE train 5.4895835914523206 MSE test 8.425417989236152\n",
      "Epoch 641 / 10000 loss: 112.98989415168762\n",
      "MSE train 5.485937026360859 MSE test 8.422631981517867\n",
      "Epoch 642 / 10000 loss: 112.91323113441467\n",
      "MSE train 5.482265595801747 MSE test 8.419856405808119\n",
      "Epoch 643 / 10000 loss: 112.8363995552063\n",
      "MSE train 5.478547101662461 MSE test 8.417088267004427\n",
      "Epoch 644 / 10000 loss: 112.75903534889221\n",
      "MSE train 5.474743667784786 MSE test 8.414324395469814\n",
      "Epoch 645 / 10000 loss: 112.68065190315247\n",
      "MSE train 5.47092071386927 MSE test 8.411564681819284\n",
      "Epoch 646 / 10000 loss: 112.60042977333069\n",
      "MSE train 5.467253657164213 MSE test 8.408819348637062\n",
      "Epoch 647 / 10000 loss: 112.51979422569275\n",
      "MSE train 5.463623548624434 MSE test 8.406084948551412\n",
      "Epoch 648 / 10000 loss: 112.44249176979065\n",
      "MSE train 5.460007224411393 MSE test 8.403355011723603\n",
      "Epoch 649 / 10000 loss: 112.3659656047821\n",
      "MSE train 5.456440960375055 MSE test 8.400625911444738\n",
      "Epoch 650 / 10000 loss: 112.28974223136902\n",
      "MSE train 5.45291939824001 MSE test 8.397894420433113\n",
      "Epoch 651 / 10000 loss: 112.21460270881653\n",
      "MSE train 5.449415959195872 MSE test 8.395157989458708\n",
      "Epoch 652 / 10000 loss: 112.14044141769409\n",
      "MSE train 5.445892850534186 MSE test 8.392416458078761\n",
      "Epoch 653 / 10000 loss: 112.06667304039001\n",
      "MSE train 5.4423154356451 MSE test 8.389666513746599\n",
      "Epoch 654 / 10000 loss: 111.99247312545776\n",
      "MSE train 5.438888566557124 MSE test 8.38693553067031\n",
      "Epoch 655 / 10000 loss: 111.91713356971741\n",
      "MSE train 5.435473766645869 MSE test 8.384215751418989\n",
      "Epoch 656 / 10000 loss: 111.84505772590637\n",
      "MSE train 5.431997336349092 MSE test 8.381491747108054\n",
      "Epoch 657 / 10000 loss: 111.7732367515564\n",
      "MSE train 5.428400231264487 MSE test 8.378758459899249\n",
      "Epoch 658 / 10000 loss: 111.70008683204651\n",
      "MSE train 5.424863122918567 MSE test 8.376011335266218\n",
      "Epoch 659 / 10000 loss: 111.6243245601654\n",
      "MSE train 5.421274406210897 MSE test 8.373238155405005\n",
      "Epoch 660 / 10000 loss: 111.54985427856445\n",
      "MSE train 5.417742051743695 MSE test 8.370453784969689\n",
      "Epoch 661 / 10000 loss: 111.47424936294556\n",
      "MSE train 5.414197559154488 MSE test 8.36769170851628\n",
      "Epoch 662 / 10000 loss: 111.39986157417297\n",
      "MSE train 5.4104849147683405 MSE test 8.364900721346844\n",
      "Epoch 663 / 10000 loss: 111.32516694068909\n",
      "MSE train 5.406894331958579 MSE test 8.36209581216388\n",
      "Epoch 664 / 10000 loss: 111.24682474136353\n",
      "MSE train 5.4033098098434245 MSE test 8.359302877697335\n",
      "Epoch 665 / 10000 loss: 111.17113375663757\n",
      "MSE train 5.3996331403784446 MSE test 8.356476388575803\n",
      "Epoch 666 / 10000 loss: 111.09552597999573\n",
      "MSE train 5.395902871083974 MSE test 8.353622804719546\n",
      "Epoch 667 / 10000 loss: 111.01790809631348\n",
      "MSE train 5.392402156894769 MSE test 8.35082280593533\n",
      "Epoch 668 / 10000 loss: 110.93916058540344\n",
      "MSE train 5.389070487749557 MSE test 8.348111596268199\n",
      "Epoch 669 / 10000 loss: 110.86536121368408\n",
      "MSE train 5.385765058705888 MSE test 8.345432731905317\n",
      "Epoch 670 / 10000 loss: 110.79515433311462\n",
      "MSE train 5.382435814140068 MSE test 8.34276511003035\n",
      "Epoch 671 / 10000 loss: 110.7254786491394\n",
      "MSE train 5.379047840302437 MSE test 8.340098845548143\n",
      "Epoch 672 / 10000 loss: 110.6552517414093\n",
      "MSE train 5.375535363116437 MSE test 8.337427856870233\n",
      "Epoch 673 / 10000 loss: 110.58372139930725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.371878951335234 MSE test 8.334745413283535\n",
      "Epoch 674 / 10000 loss: 110.50945091247559\n",
      "MSE train 5.368355487285076 MSE test 8.332066293678247\n",
      "Epoch 675 / 10000 loss: 110.43212509155273\n",
      "MSE train 5.364749169912885 MSE test 8.329373771199\n",
      "Epoch 676 / 10000 loss: 110.3576066493988\n",
      "MSE train 5.361179224967244 MSE test 8.326686398726217\n",
      "Epoch 677 / 10000 loss: 110.28127813339233\n",
      "MSE train 5.357637169216253 MSE test 8.324015276483077\n",
      "Epoch 678 / 10000 loss: 110.2057363986969\n",
      "MSE train 5.354214761333205 MSE test 8.321358613320566\n",
      "Epoch 679 / 10000 loss: 110.1307942867279\n",
      "MSE train 5.350897728207892 MSE test 8.318725158664682\n",
      "Epoch 680 / 10000 loss: 110.05843567848206\n",
      "MSE train 5.3475919090649935 MSE test 8.316090465625182\n",
      "Epoch 681 / 10000 loss: 109.98834252357483\n",
      "MSE train 5.344297930607389 MSE test 8.313453376086061\n",
      "Epoch 682 / 10000 loss: 109.91847252845764\n",
      "MSE train 5.340920168319232 MSE test 8.310807637964482\n",
      "Epoch 683 / 10000 loss: 109.84885096549988\n",
      "MSE train 5.337291460742654 MSE test 8.308137488358083\n",
      "Epoch 684 / 10000 loss: 109.77739691734314\n",
      "MSE train 5.333978748308623 MSE test 8.305506417704908\n",
      "Epoch 685 / 10000 loss: 109.70050144195557\n",
      "MSE train 5.330629196847345 MSE test 8.302879233085367\n",
      "Epoch 686 / 10000 loss: 109.63044214248657\n",
      "MSE train 5.327008201187957 MSE test 8.300246294504914\n",
      "Epoch 687 / 10000 loss: 109.55958890914917\n",
      "MSE train 5.323689160957596 MSE test 8.297615594197767\n",
      "Epoch 688 / 10000 loss: 109.48282980918884\n",
      "MSE train 5.3203345766734085 MSE test 8.294981212977207\n",
      "Epoch 689 / 10000 loss: 109.41261839866638\n",
      "MSE train 5.316942543715019 MSE test 8.292340752367195\n",
      "Epoch 690 / 10000 loss: 109.34162998199463\n",
      "MSE train 5.31358075713445 MSE test 8.289696193323095\n",
      "Epoch 691 / 10000 loss: 109.26982879638672\n",
      "MSE train 5.310270426891754 MSE test 8.2870509859495\n",
      "Epoch 692 / 10000 loss: 109.1986768245697\n",
      "MSE train 5.3069416608622255 MSE test 8.284398139057899\n",
      "Epoch 693 / 10000 loss: 109.12863874435425\n",
      "MSE train 5.3035712516159474 MSE test 8.28173164627875\n",
      "Epoch 694 / 10000 loss: 109.05820226669312\n",
      "MSE train 5.300250175839801 MSE test 8.279070372727414\n",
      "Epoch 695 / 10000 loss: 108.98686027526855\n",
      "MSE train 5.2969888433469015 MSE test 8.27642988267049\n",
      "Epoch 696 / 10000 loss: 108.91659235954285\n",
      "MSE train 5.293779275796811 MSE test 8.273808898071469\n",
      "Epoch 697 / 10000 loss: 108.84763240814209\n",
      "MSE train 5.290575689474862 MSE test 8.27120226678275\n",
      "Epoch 698 / 10000 loss: 108.77978563308716\n",
      "MSE train 5.2873321158521485 MSE test 8.26860176477317\n",
      "Epoch 699 / 10000 loss: 108.71205401420593\n",
      "MSE train 5.284004201016611 MSE test 8.266000957370672\n",
      "Epoch 700 / 10000 loss: 108.64344954490662\n",
      "MSE train 5.2806007112087885 MSE test 8.263397490991746\n",
      "Epoch 701 / 10000 loss: 108.57300806045532\n",
      "MSE train 5.277255688212679 MSE test 8.260811422359668\n",
      "Epoch 702 / 10000 loss: 108.50093483924866\n",
      "MSE train 5.2739646460247185 MSE test 8.258247430914071\n",
      "Epoch 703 / 10000 loss: 108.4301335811615\n",
      "MSE train 5.270665109381397 MSE test 8.255688193305806\n",
      "Epoch 704 / 10000 loss: 108.36048150062561\n",
      "MSE train 5.267337759952473 MSE test 8.253126226032903\n",
      "Epoch 705 / 10000 loss: 108.29063272476196\n",
      "MSE train 5.263979238372322 MSE test 8.250557295240991\n",
      "Epoch 706 / 10000 loss: 108.2201759815216\n",
      "MSE train 5.2605704076005155 MSE test 8.247977557820393\n",
      "Epoch 707 / 10000 loss: 108.1490306854248\n",
      "MSE train 5.2570774480527165 MSE test 8.245383228945817\n",
      "Epoch 708 / 10000 loss: 108.07679343223572\n",
      "MSE train 5.253483034110048 MSE test 8.242775677532592\n",
      "Epoch 709 / 10000 loss: 108.00271964073181\n",
      "MSE train 5.24979410853171 MSE test 8.240164270663078\n",
      "Epoch 710 / 10000 loss: 107.92642951011658\n",
      "MSE train 5.24619424591366 MSE test 8.237559175247887\n",
      "Epoch 711 / 10000 loss: 107.8481068611145\n",
      "MSE train 5.242736290403153 MSE test 8.234987010011935\n",
      "Epoch 712 / 10000 loss: 107.77180457115173\n",
      "MSE train 5.239259724370963 MSE test 8.232422300996475\n",
      "Epoch 713 / 10000 loss: 107.69851851463318\n",
      "MSE train 5.235779928304365 MSE test 8.229857789752199\n",
      "Epoch 714 / 10000 loss: 107.62484335899353\n",
      "MSE train 5.232303774658797 MSE test 8.227289715198424\n",
      "Epoch 715 / 10000 loss: 107.55114793777466\n",
      "MSE train 5.228784757419876 MSE test 8.224712581466349\n",
      "Epoch 716 / 10000 loss: 107.47756814956665\n",
      "MSE train 5.225198119217805 MSE test 8.22212148850516\n",
      "Epoch 717 / 10000 loss: 107.40306282043457\n",
      "MSE train 5.22161222748044 MSE test 8.219520801973946\n",
      "Epoch 718 / 10000 loss: 107.32708144187927\n",
      "MSE train 5.218043300222081 MSE test 8.21692014404142\n",
      "Epoch 719 / 10000 loss: 107.25108170509338\n",
      "MSE train 5.214439198220128 MSE test 8.214319779863864\n",
      "Epoch 720 / 10000 loss: 107.17542290687561\n",
      "MSE train 5.210760101859306 MSE test 8.21173228574286\n",
      "Epoch 721 / 10000 loss: 107.09898710250854\n",
      "MSE train 5.207150876370551 MSE test 8.20915078435509\n",
      "Epoch 722 / 10000 loss: 107.0209093093872\n",
      "MSE train 5.2037038532463145 MSE test 8.206583385870072\n",
      "Epoch 723 / 10000 loss: 106.9443907737732\n",
      "MSE train 5.2002892240396275 MSE test 8.204027108406606\n",
      "Epoch 724 / 10000 loss: 106.8713366985321\n",
      "MSE train 5.196897604907933 MSE test 8.201480518981443\n",
      "Epoch 725 / 10000 loss: 106.79897475242615\n",
      "MSE train 5.193554934487833 MSE test 8.198949155570821\n",
      "Epoch 726 / 10000 loss: 106.7271089553833\n",
      "MSE train 5.19024865317832 MSE test 8.19643637069582\n",
      "Epoch 727 / 10000 loss: 106.65630292892456\n",
      "MSE train 5.186920013787791 MSE test 8.193935268956853\n",
      "Epoch 728 / 10000 loss: 106.58627200126648\n",
      "MSE train 5.183493330245669 MSE test 8.191434540229357\n",
      "Epoch 729 / 10000 loss: 106.5157458782196\n",
      "MSE train 5.180112856979094 MSE test 8.18894029557502\n",
      "Epoch 730 / 10000 loss: 106.44309449195862\n",
      "MSE train 5.176907126075941 MSE test 8.186497445710708\n",
      "Epoch 731 / 10000 loss: 106.37145066261292\n",
      "MSE train 5.1737292304805464 MSE test 8.184075381247942\n",
      "Epoch 732 / 10000 loss: 106.30356884002686\n",
      "MSE train 5.17052759972102 MSE test 8.181663673559605\n",
      "Epoch 733 / 10000 loss: 106.23628902435303\n",
      "MSE train 5.167326132577873 MSE test 8.179260763208582\n",
      "Epoch 734 / 10000 loss: 106.16849684715271\n",
      "MSE train 5.16424992391532 MSE test 8.176882788998604\n",
      "Epoch 735 / 10000 loss: 106.10069108009338\n",
      "MSE train 5.161261752438979 MSE test 8.174531834684823\n",
      "Epoch 736 / 10000 loss: 106.0355658531189\n",
      "MSE train 5.15831350696031 MSE test 8.172195881115762\n",
      "Epoch 737 / 10000 loss: 105.97233653068542\n",
      "MSE train 5.15538168015149 MSE test 8.1698683326037\n",
      "Epoch 738 / 10000 loss: 105.90995788574219\n",
      "MSE train 5.1524328509326995 MSE test 8.167543577054133\n",
      "Epoch 739 / 10000 loss: 105.84793400764465\n",
      "MSE train 5.149416160149144 MSE test 8.165215454637794\n",
      "Epoch 740 / 10000 loss: 105.78553104400635\n",
      "MSE train 5.146294775891001 MSE test 8.162878974485551\n",
      "Epoch 741 / 10000 loss: 105.72166514396667\n",
      "MSE train 5.1431322618922195 MSE test 8.16053635077276\n",
      "Epoch 742 / 10000 loss: 105.65555620193481\n",
      "MSE train 5.139922383991228 MSE test 8.158188708738368\n",
      "Epoch 743 / 10000 loss: 105.58858013153076\n",
      "MSE train 5.136430609831008 MSE test 8.155817781500982\n",
      "Epoch 744 / 10000 loss: 105.52056884765625\n",
      "MSE train 5.132920121749068 MSE test 8.153438490590581\n",
      "Epoch 745 / 10000 loss: 105.44643664360046\n",
      "MSE train 5.1293982119771355 MSE test 8.151093789575834\n",
      "Epoch 746 / 10000 loss: 105.37195158004761\n",
      "MSE train 5.1261601208843075 MSE test 8.148785128934966\n",
      "Epoch 747 / 10000 loss: 105.29713654518127\n",
      "MSE train 5.1231816710428015 MSE test 8.146493217688933\n",
      "Epoch 748 / 10000 loss: 105.22849082946777\n",
      "MSE train 5.120311846238288 MSE test 8.144230798803767\n",
      "Epoch 749 / 10000 loss: 105.16556143760681\n",
      "MSE train 5.117373996344017 MSE test 8.141967292109536\n",
      "Epoch 750 / 10000 loss: 105.10492420196533\n",
      "MSE train 5.114371400454431 MSE test 8.139695979410225\n",
      "Epoch 751 / 10000 loss: 105.04281997680664\n",
      "MSE train 5.111372272225881 MSE test 8.137416677454052\n",
      "Epoch 752 / 10000 loss: 104.979318857193\n",
      "MSE train 5.108402831629611 MSE test 8.135131902220841\n",
      "Epoch 753 / 10000 loss: 104.91590809822083\n",
      "MSE train 5.105427982358677 MSE test 8.132840779781054\n",
      "Epoch 754 / 10000 loss: 104.85313963890076\n",
      "MSE train 5.102403011350321 MSE test 8.130539745131014\n",
      "Epoch 755 / 10000 loss: 104.79025387763977\n",
      "MSE train 5.099337980051002 MSE test 8.128224657837738\n",
      "Epoch 756 / 10000 loss: 104.72629976272583\n",
      "MSE train 5.096313642015117 MSE test 8.125903105281418\n",
      "Epoch 757 / 10000 loss: 104.66148734092712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 5.093348279129765 MSE test 8.123594234796405\n",
      "Epoch 758 / 10000 loss: 104.59753561019897\n",
      "MSE train 5.09033660730563 MSE test 8.12129106245532\n",
      "Epoch 759 / 10000 loss: 104.53484535217285\n",
      "MSE train 5.0871972248411135 MSE test 8.118976003313083\n",
      "Epoch 760 / 10000 loss: 104.47115921974182\n",
      "MSE train 5.083995900723454 MSE test 8.116650966466874\n",
      "Epoch 761 / 10000 loss: 104.40470719337463\n",
      "MSE train 5.080870730794013 MSE test 8.114333553293731\n",
      "Epoch 762 / 10000 loss: 104.33692407608032\n",
      "MSE train 5.077762719757086 MSE test 8.11202203330731\n",
      "Epoch 763 / 10000 loss: 104.27078580856323\n",
      "MSE train 5.0747839428399795 MSE test 8.109728921800267\n",
      "Epoch 764 / 10000 loss: 104.20503330230713\n",
      "MSE train 5.071931012958365 MSE test 8.107471538496846\n",
      "Epoch 765 / 10000 loss: 104.1421287059784\n",
      "MSE train 5.0691023257790375 MSE test 8.1052304717953\n",
      "Epoch 766 / 10000 loss: 104.08191657066345\n",
      "MSE train 5.066284744516099 MSE test 8.102998779365873\n",
      "Epoch 767 / 10000 loss: 104.02223324775696\n",
      "MSE train 5.063481203112386 MSE test 8.100774355815563\n",
      "Epoch 768 / 10000 loss: 103.96280002593994\n",
      "MSE train 5.060712245412664 MSE test 8.098557464807293\n",
      "Epoch 769 / 10000 loss: 103.9036774635315\n",
      "MSE train 5.057981995240246 MSE test 8.096348346382918\n",
      "Epoch 770 / 10000 loss: 103.84531283378601\n",
      "MSE train 5.055256596307681 MSE test 8.094142455482592\n",
      "Epoch 771 / 10000 loss: 103.78778195381165\n",
      "MSE train 5.05254243609873 MSE test 8.091938134769915\n",
      "Epoch 772 / 10000 loss: 103.7303581237793\n",
      "MSE train 5.049885200973013 MSE test 8.089747226916103\n",
      "Epoch 773 / 10000 loss: 103.67317605018616\n",
      "MSE train 5.047258490056327 MSE test 8.087570083640523\n",
      "Epoch 774 / 10000 loss: 103.61722469329834\n",
      "MSE train 5.044651072116326 MSE test 8.085401540069071\n",
      "Epoch 775 / 10000 loss: 103.56191635131836\n",
      "MSE train 5.042075432192254 MSE test 8.083244079674738\n",
      "Epoch 776 / 10000 loss: 103.50701808929443\n",
      "MSE train 5.039538188015277 MSE test 8.081101089946648\n",
      "Epoch 777 / 10000 loss: 103.4527940750122\n",
      "MSE train 5.03703287919468 MSE test 8.078972018602057\n",
      "Epoch 778 / 10000 loss: 103.39936995506287\n",
      "MSE train 5.034549588328397 MSE test 8.076853967817682\n",
      "Epoch 779 / 10000 loss: 103.34661602973938\n",
      "MSE train 5.032079520045998 MSE test 8.07474445113676\n",
      "Epoch 780 / 10000 loss: 103.29430961608887\n",
      "MSE train 5.0296150390501015 MSE test 8.072641797486954\n",
      "Epoch 781 / 10000 loss: 103.24227261543274\n",
      "MSE train 5.027148578529609 MSE test 8.070545198413708\n",
      "Epoch 782 / 10000 loss: 103.19033479690552\n",
      "MSE train 5.024670858707496 MSE test 8.068453980884195\n",
      "Epoch 783 / 10000 loss: 103.13833475112915\n",
      "MSE train 5.022167757124993 MSE test 8.066367566041539\n",
      "Epoch 784 / 10000 loss: 103.08607196807861\n",
      "MSE train 5.019614380253202 MSE test 8.064284370295356\n",
      "Epoch 785 / 10000 loss: 103.03323793411255\n",
      "MSE train 5.016971121971575 MSE test 8.062201784506271\n",
      "Epoch 786 / 10000 loss: 102.97929406166077\n",
      "MSE train 5.014289128899868 MSE test 8.060119385777671\n",
      "Epoch 787 / 10000 loss: 102.92338299751282\n",
      "MSE train 5.011684889550382 MSE test 8.058045542253486\n",
      "Epoch 788 / 10000 loss: 102.86663174629211\n",
      "MSE train 5.009058439250328 MSE test 8.055977690392796\n",
      "Epoch 789 / 10000 loss: 102.81154751777649\n",
      "MSE train 5.006399593519703 MSE test 8.053912711885944\n",
      "Epoch 790 / 10000 loss: 102.75596642494202\n",
      "MSE train 5.003800426179121 MSE test 8.05184507668434\n",
      "Epoch 791 / 10000 loss: 102.69967579841614\n",
      "MSE train 5.001053749760231 MSE test 8.04975243907364\n",
      "Epoch 792 / 10000 loss: 102.64468908309937\n",
      "MSE train 4.998482806355807 MSE test 8.047656251234068\n",
      "Epoch 793 / 10000 loss: 102.58649802207947\n",
      "MSE train 4.996082431529079 MSE test 8.045647489708388\n",
      "Epoch 794 / 10000 loss: 102.53208231925964\n",
      "MSE train 4.993690488660589 MSE test 8.043646639736998\n",
      "Epoch 795 / 10000 loss: 102.48136281967163\n",
      "MSE train 4.991277746559714 MSE test 8.041643056296056\n",
      "Epoch 796 / 10000 loss: 102.43081474304199\n",
      "MSE train 4.988814370643286 MSE test 8.039630806198511\n",
      "Epoch 797 / 10000 loss: 102.37982225418091\n",
      "MSE train 4.986262398779846 MSE test 8.037605393171054\n",
      "Epoch 798 / 10000 loss: 102.3277268409729\n",
      "MSE train 4.983614963170843 MSE test 8.035562237435686\n",
      "Epoch 799 / 10000 loss: 102.27369546890259\n",
      "MSE train 4.98116705421002 MSE test 8.033541234479646\n",
      "Epoch 800 / 10000 loss: 102.21762347221375\n",
      "MSE train 4.978682454976799 MSE test 8.031519300303568\n",
      "Epoch 801 / 10000 loss: 102.16585421562195\n",
      "MSE train 4.976126349293618 MSE test 8.029488845597253\n",
      "Epoch 802 / 10000 loss: 102.11327242851257\n",
      "MSE train 4.973616874817558 MSE test 8.027454095100278\n",
      "Epoch 803 / 10000 loss: 102.0591630935669\n",
      "MSE train 4.971162804358005 MSE test 8.025421666123947\n",
      "Epoch 804 / 10000 loss: 102.00608325004578\n",
      "MSE train 4.968672029077356 MSE test 8.02338017854\n",
      "Epoch 805 / 10000 loss: 101.95414853096008\n",
      "MSE train 4.966069169162024 MSE test 8.021318184641668\n",
      "Epoch 806 / 10000 loss: 101.90140557289124\n",
      "MSE train 4.963464795744859 MSE test 8.019238688119794\n",
      "Epoch 807 / 10000 loss: 101.84622573852539\n",
      "MSE train 4.960946683886016 MSE test 8.017186108503129\n",
      "Epoch 808 / 10000 loss: 101.79100012779236\n",
      "MSE train 4.958438380016527 MSE test 8.015135826706404\n",
      "Epoch 809 / 10000 loss: 101.73765659332275\n",
      "MSE train 4.955927449925902 MSE test 8.01308510453593\n",
      "Epoch 810 / 10000 loss: 101.6845211982727\n",
      "MSE train 4.95343823233714 MSE test 8.011031903784817\n",
      "Epoch 811 / 10000 loss: 101.63132071495056\n",
      "MSE train 4.950943550145778 MSE test 8.00897128619986\n",
      "Epoch 812 / 10000 loss: 101.57857847213745\n",
      "MSE train 4.9483666961462855 MSE test 8.006885739293795\n",
      "Epoch 813 / 10000 loss: 101.52570867538452\n",
      "MSE train 4.945835817808049 MSE test 8.004804278440773\n",
      "Epoch 814 / 10000 loss: 101.4710853099823\n",
      "MSE train 4.943153189420327 MSE test 8.002729995593873\n",
      "Epoch 815 / 10000 loss: 101.41747999191284\n",
      "MSE train 4.94064403789421 MSE test 8.000664912266151\n",
      "Epoch 816 / 10000 loss: 101.36056804656982\n",
      "MSE train 4.938156015076568 MSE test 7.998637220567096\n",
      "Epoch 817 / 10000 loss: 101.30740451812744\n",
      "MSE train 4.935628881025331 MSE test 7.996609294855145\n",
      "Epoch 818 / 10000 loss: 101.25469636917114\n",
      "MSE train 4.933053343292228 MSE test 7.994580856925391\n",
      "Epoch 819 / 10000 loss: 101.20114040374756\n",
      "MSE train 4.930424240864032 MSE test 7.992551519448522\n",
      "Epoch 820 / 10000 loss: 101.14653587341309\n",
      "MSE train 4.927749959338512 MSE test 7.990520231126323\n",
      "Epoch 821 / 10000 loss: 101.09077620506287\n",
      "MSE train 4.925044222922852 MSE test 7.9884862475499485\n",
      "Epoch 822 / 10000 loss: 101.03404355049133\n",
      "MSE train 4.922337588229915 MSE test 7.986453239624386\n",
      "Epoch 823 / 10000 loss: 100.97662472724915\n",
      "MSE train 4.919536855793452 MSE test 7.984418492224073\n",
      "Epoch 824 / 10000 loss: 100.91918802261353\n",
      "MSE train 4.916784598576295 MSE test 7.9823765068114385\n",
      "Epoch 825 / 10000 loss: 100.85971140861511\n",
      "MSE train 4.91399201576039 MSE test 7.980350600486897\n",
      "Epoch 826 / 10000 loss: 100.8012764453888\n",
      "MSE train 4.911274653429331 MSE test 7.978318686426949\n",
      "Epoch 827 / 10000 loss: 100.74200391769409\n",
      "MSE train 4.90859616337588 MSE test 7.9762990218792025\n",
      "Epoch 828 / 10000 loss: 100.68438506126404\n",
      "MSE train 4.905863303412947 MSE test 7.974286264618927\n",
      "Epoch 829 / 10000 loss: 100.62759327888489\n",
      "MSE train 4.903016141509628 MSE test 7.972274988091411\n",
      "Epoch 830 / 10000 loss: 100.56963229179382\n",
      "MSE train 4.900373133628289 MSE test 7.970295864170399\n",
      "Epoch 831 / 10000 loss: 100.50919318199158\n",
      "MSE train 4.897811332897917 MSE test 7.968354174456279\n",
      "Epoch 832 / 10000 loss: 100.45318341255188\n",
      "MSE train 4.895274080427192 MSE test 7.966427670502177\n",
      "Epoch 833 / 10000 loss: 100.39892578125\n",
      "MSE train 4.89272791176101 MSE test 7.9645112794993445\n",
      "Epoch 834 / 10000 loss: 100.34520816802979\n",
      "MSE train 4.890235051220829 MSE test 7.962608483291585\n",
      "Epoch 835 / 10000 loss: 100.29130244255066\n",
      "MSE train 4.887835856904409 MSE test 7.960728782132929\n",
      "Epoch 836 / 10000 loss: 100.23855805397034\n",
      "MSE train 4.885485757797847 MSE test 7.958865803524798\n",
      "Epoch 837 / 10000 loss: 100.18784856796265\n",
      "MSE train 4.883154040909724 MSE test 7.9570126449451335\n",
      "Epoch 838 / 10000 loss: 100.13820242881775\n",
      "MSE train 4.8808097601364535 MSE test 7.9551626558938064\n",
      "Epoch 839 / 10000 loss: 100.08895611763\n",
      "MSE train 4.878426593212576 MSE test 7.953309555411134\n",
      "Epoch 840 / 10000 loss: 100.0394344329834\n",
      "MSE train 4.876021965579743 MSE test 7.951454478163872\n",
      "Epoch 841 / 10000 loss: 99.98907828330994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.873638144933356 MSE test 7.949611366215284\n",
      "Epoch 842 / 10000 loss: 99.93825817108154\n",
      "MSE train 4.871239423241471 MSE test 7.9477787271079565\n",
      "Epoch 843 / 10000 loss: 99.88789415359497\n",
      "MSE train 4.868764272620105 MSE test 7.945947266262033\n",
      "Epoch 844 / 10000 loss: 99.83721494674683\n",
      "MSE train 4.866413317534912 MSE test 7.944113649769476\n",
      "Epoch 845 / 10000 loss: 99.78488516807556\n",
      "MSE train 4.8640943777411385 MSE test 7.942278313689871\n",
      "Epoch 846 / 10000 loss: 99.73524761199951\n",
      "MSE train 4.861778352818374 MSE test 7.940439899811587\n",
      "Epoch 847 / 10000 loss: 99.68629193305969\n",
      "MSE train 4.859473289643085 MSE test 7.938599589196526\n",
      "Epoch 848 / 10000 loss: 99.63740706443787\n",
      "MSE train 4.857176515408552 MSE test 7.936758281425425\n",
      "Epoch 849 / 10000 loss: 99.58875441551208\n",
      "MSE train 4.8548613972586 MSE test 7.934914127901236\n",
      "Epoch 850 / 10000 loss: 99.54028367996216\n",
      "MSE train 4.852469539913706 MSE test 7.9330622383787155\n",
      "Epoch 851 / 10000 loss: 99.49140453338623\n",
      "MSE train 4.84995278011767 MSE test 7.931196135650279\n",
      "Epoch 852 / 10000 loss: 99.44085502624512\n",
      "MSE train 4.8474979830887515 MSE test 7.929322354285832\n",
      "Epoch 853 / 10000 loss: 99.38766527175903\n",
      "MSE train 4.844987576169188 MSE test 7.927437706967907\n",
      "Epoch 854 / 10000 loss: 99.33580541610718\n",
      "MSE train 4.842357838250739 MSE test 7.925530255390675\n",
      "Epoch 855 / 10000 loss: 99.28267526626587\n",
      "MSE train 4.8398136992514775 MSE test 7.923600952254031\n",
      "Epoch 856 / 10000 loss: 99.22699451446533\n",
      "MSE train 4.837212181380321 MSE test 7.921652921436142\n",
      "Epoch 857 / 10000 loss: 99.17322278022766\n",
      "MSE train 4.834501528359598 MSE test 7.919654630479938\n",
      "Epoch 858 / 10000 loss: 99.11814832687378\n",
      "MSE train 4.831963341831525 MSE test 7.917724967077082\n",
      "Epoch 859 / 10000 loss: 99.06071209907532\n",
      "MSE train 4.829564624751538 MSE test 7.915817783244646\n",
      "Epoch 860 / 10000 loss: 99.00699543952942\n",
      "MSE train 4.827191992863948 MSE test 7.913926876089122\n",
      "Epoch 861 / 10000 loss: 98.95629620552063\n",
      "MSE train 4.824818202695593 MSE test 7.912046352136729\n",
      "Epoch 862 / 10000 loss: 98.90615367889404\n",
      "MSE train 4.8224455131282395 MSE test 7.910171605664082\n",
      "Epoch 863 / 10000 loss: 98.85598635673523\n",
      "MSE train 4.820091293857779 MSE test 7.9082988228022755\n",
      "Epoch 864 / 10000 loss: 98.80583620071411\n",
      "MSE train 4.817739274325234 MSE test 7.906422075268681\n",
      "Epoch 865 / 10000 loss: 98.75607180595398\n",
      "MSE train 4.815352436982379 MSE test 7.90453396998003\n",
      "Epoch 866 / 10000 loss: 98.70633244514465\n",
      "MSE train 4.812948165304309 MSE test 7.902635168703658\n",
      "Epoch 867 / 10000 loss: 98.65582966804504\n",
      "MSE train 4.810581267390133 MSE test 7.900742266002948\n",
      "Epoch 868 / 10000 loss: 98.60493326187134\n",
      "MSE train 4.808239948005379 MSE test 7.898857350324252\n",
      "Epoch 869 / 10000 loss: 98.55483555793762\n",
      "MSE train 4.8059209251031385 MSE test 7.896978977154287\n",
      "Epoch 870 / 10000 loss: 98.50528645515442\n",
      "MSE train 4.803590365950949 MSE test 7.895103854162386\n",
      "Epoch 871 / 10000 loss: 98.45621705055237\n",
      "MSE train 4.801206661337347 MSE test 7.893226008427696\n",
      "Epoch 872 / 10000 loss: 98.40689063072205\n",
      "MSE train 4.798777547769076 MSE test 7.891343140839417\n",
      "Epoch 873 / 10000 loss: 98.35641360282898\n",
      "MSE train 4.796334005841152 MSE test 7.889458042194041\n",
      "Epoch 874 / 10000 loss: 98.30495071411133\n",
      "MSE train 4.793862071485203 MSE test 7.88757117738835\n",
      "Epoch 875 / 10000 loss: 98.25317883491516\n",
      "MSE train 4.791358318098121 MSE test 7.885682070783496\n",
      "Epoch 876 / 10000 loss: 98.20079231262207\n",
      "MSE train 4.788728970092024 MSE test 7.883790364536032\n",
      "Epoch 877 / 10000 loss: 98.14771866798401\n",
      "MSE train 4.786188900425737 MSE test 7.881894631007169\n",
      "Epoch 878 / 10000 loss: 98.09193229675293\n",
      "MSE train 4.783610373229087 MSE test 7.880010208494159\n",
      "Epoch 879 / 10000 loss: 98.0381326675415\n",
      "MSE train 4.78096053763362 MSE test 7.878111205732238\n",
      "Epoch 880 / 10000 loss: 97.98346781730652\n",
      "MSE train 4.7783318486459825 MSE test 7.876251227146029\n",
      "Epoch 881 / 10000 loss: 97.92730808258057\n",
      "MSE train 4.77578256654687 MSE test 7.87439398597859\n",
      "Epoch 882 / 10000 loss: 97.87159395217896\n",
      "MSE train 4.773448627763393 MSE test 7.87257656199989\n",
      "Epoch 883 / 10000 loss: 97.81756067276001\n",
      "MSE train 4.771232123656964 MSE test 7.870782252546783\n",
      "Epoch 884 / 10000 loss: 97.76822328567505\n",
      "MSE train 4.769105229713313 MSE test 7.8690102840126315\n",
      "Epoch 885 / 10000 loss: 97.72143197059631\n",
      "MSE train 4.767005996737218 MSE test 7.8672534179363796\n",
      "Epoch 886 / 10000 loss: 97.67658543586731\n",
      "MSE train 4.764898953107517 MSE test 7.865503686986541\n",
      "Epoch 887 / 10000 loss: 97.63234305381775\n",
      "MSE train 4.762776105120206 MSE test 7.863756793408955\n",
      "Epoch 888 / 10000 loss: 97.58793663978577\n",
      "MSE train 4.760640388636163 MSE test 7.8620104168737415\n",
      "Epoch 889 / 10000 loss: 97.54319071769714\n",
      "MSE train 4.758487160694809 MSE test 7.860262899071741\n",
      "Epoch 890 / 10000 loss: 97.49816370010376\n",
      "MSE train 4.756303159606785 MSE test 7.858512289474892\n",
      "Epoch 891 / 10000 loss: 97.45275139808655\n",
      "MSE train 4.754075787757938 MSE test 7.856756742951216\n",
      "Epoch 892 / 10000 loss: 97.40667605400085\n",
      "MSE train 4.75179067825088 MSE test 7.854994621132704\n",
      "Epoch 893 / 10000 loss: 97.35965538024902\n",
      "MSE train 4.749436703579288 MSE test 7.853225511633261\n",
      "Epoch 894 / 10000 loss: 97.31138920783997\n",
      "MSE train 4.7470700371374575 MSE test 7.851458113531936\n",
      "Epoch 895 / 10000 loss: 97.2616376876831\n",
      "MSE train 4.7447797720941285 MSE test 7.849707679335867\n",
      "Epoch 896 / 10000 loss: 97.21161770820618\n",
      "MSE train 4.7425614095679665 MSE test 7.847974187006525\n",
      "Epoch 897 / 10000 loss: 97.16323614120483\n",
      "MSE train 4.740387182332521 MSE test 7.84625557185815\n",
      "Epoch 898 / 10000 loss: 97.1163763999939\n",
      "MSE train 4.738234275911733 MSE test 7.844550349038399\n",
      "Epoch 899 / 10000 loss: 97.07044124603271\n",
      "MSE train 4.736092935393418 MSE test 7.842855578640728\n",
      "Epoch 900 / 10000 loss: 97.02496981620789\n",
      "MSE train 4.733977088158491 MSE test 7.841169912014242\n",
      "Epoch 901 / 10000 loss: 96.97976446151733\n",
      "MSE train 4.731878805394646 MSE test 7.839491582181531\n",
      "Epoch 902 / 10000 loss: 96.93511915206909\n",
      "MSE train 4.729776162456596 MSE test 7.837817083975618\n",
      "Epoch 903 / 10000 loss: 96.89084219932556\n",
      "MSE train 4.727650382854851 MSE test 7.836142770324767\n",
      "Epoch 904 / 10000 loss: 96.84645462036133\n",
      "MSE train 4.725483103987328 MSE test 7.834465363880639\n",
      "Epoch 905 / 10000 loss: 96.80156254768372\n",
      "MSE train 4.723274915361094 MSE test 7.832782521356938\n",
      "Epoch 906 / 10000 loss: 96.75577068328857\n",
      "MSE train 4.721046610826528 MSE test 7.831093974456459\n",
      "Epoch 907 / 10000 loss: 96.7091019153595\n",
      "MSE train 4.718768086400426 MSE test 7.82940031920724\n",
      "Epoch 908 / 10000 loss: 96.66199159622192\n",
      "MSE train 4.716320508477116 MSE test 7.827699205072815\n",
      "Epoch 909 / 10000 loss: 96.61381125450134\n",
      "MSE train 4.713873881069094 MSE test 7.825996412104988\n",
      "Epoch 910 / 10000 loss: 96.5619707107544\n",
      "MSE train 4.711519666033208 MSE test 7.824300740585076\n",
      "Epoch 911 / 10000 loss: 96.51025319099426\n",
      "MSE train 4.709132151342413 MSE test 7.822603740977773\n",
      "Epoch 912 / 10000 loss: 96.46050930023193\n",
      "MSE train 4.706983801892462 MSE test 7.820949627837101\n",
      "Epoch 913 / 10000 loss: 96.40997171401978\n",
      "MSE train 4.704958010432278 MSE test 7.819344460698855\n",
      "Epoch 914 / 10000 loss: 96.36460876464844\n",
      "MSE train 4.702949393301232 MSE test 7.81775291012886\n",
      "Epoch 915 / 10000 loss: 96.32189631462097\n",
      "MSE train 4.700942168986841 MSE test 7.816166844687587\n",
      "Epoch 916 / 10000 loss: 96.27955460548401\n",
      "MSE train 4.698928929820755 MSE test 7.81458248662543\n",
      "Epoch 917 / 10000 loss: 96.2372465133667\n",
      "MSE train 4.696902767385548 MSE test 7.8129966751685265\n",
      "Epoch 918 / 10000 loss: 96.19481372833252\n",
      "MSE train 4.694858326578701 MSE test 7.811406735771135\n",
      "Epoch 919 / 10000 loss: 96.15211033821106\n",
      "MSE train 4.692792610388492 MSE test 7.809810127582575\n",
      "Epoch 920 / 10000 loss: 96.10901594161987\n",
      "MSE train 4.690700990774192 MSE test 7.808204337722199\n",
      "Epoch 921 / 10000 loss: 96.06547570228577\n",
      "MSE train 4.688571419844828 MSE test 7.806586105993879\n",
      "Epoch 922 / 10000 loss: 96.02138829231262\n",
      "MSE train 4.6863814620564215 MSE test 7.804951537963812\n",
      "Epoch 923 / 10000 loss: 95.9765100479126\n",
      "MSE train 4.684100392966456 MSE test 7.80329677591907\n",
      "Epoch 924 / 10000 loss: 95.93035221099854\n",
      "MSE train 4.681691215607722 MSE test 7.801621872432823\n",
      "Epoch 925 / 10000 loss: 95.8822374343872\n",
      "MSE train 4.679363762846003 MSE test 7.799943664344453\n",
      "Epoch 926 / 10000 loss: 95.83137154579163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.677204289164078 MSE test 7.798294135102799\n",
      "Epoch 927 / 10000 loss: 95.78233695030212\n",
      "MSE train 4.675073636918985 MSE test 7.796648412010333\n",
      "Epoch 928 / 10000 loss: 95.73676180839539\n",
      "MSE train 4.67295156470806 MSE test 7.795002077405336\n",
      "Epoch 929 / 10000 loss: 95.6917667388916\n",
      "MSE train 4.670837490505223 MSE test 7.793354939273354\n",
      "Epoch 930 / 10000 loss: 95.64692878723145\n",
      "MSE train 4.668745934155722 MSE test 7.791710950904533\n",
      "Epoch 931 / 10000 loss: 95.60224747657776\n",
      "MSE train 4.6666891358945835 MSE test 7.790075059185831\n",
      "Epoch 932 / 10000 loss: 95.5580358505249\n",
      "MSE train 4.664663907267209 MSE test 7.788448816281468\n",
      "Epoch 933 / 10000 loss: 95.51456928253174\n",
      "MSE train 4.662658854555288 MSE test 7.786829591318523\n",
      "Epoch 934 / 10000 loss: 95.4717788696289\n",
      "MSE train 4.660653879960876 MSE test 7.785212692998804\n",
      "Epoch 935 / 10000 loss: 95.42941689491272\n",
      "MSE train 4.658599236843836 MSE test 7.783591031007214\n",
      "Epoch 936 / 10000 loss: 95.387047290802\n",
      "MSE train 4.656437201627077 MSE test 7.7819512206778425\n",
      "Epoch 937 / 10000 loss: 95.34360194206238\n",
      "MSE train 4.6544621920037805 MSE test 7.780318467436871\n",
      "Epoch 938 / 10000 loss: 95.29782438278198\n",
      "MSE train 4.65255971816073 MSE test 7.778719352779457\n",
      "Epoch 939 / 10000 loss: 95.25608038902283\n",
      "MSE train 4.650666560626395 MSE test 7.777119037671077\n",
      "Epoch 940 / 10000 loss: 95.21589159965515\n",
      "MSE train 4.6487803719241665 MSE test 7.775516693753652\n",
      "Epoch 941 / 10000 loss: 95.17589974403381\n",
      "MSE train 4.646892552184775 MSE test 7.7739111931089635\n",
      "Epoch 942 / 10000 loss: 95.13605785369873\n",
      "MSE train 4.644985026156372 MSE test 7.772300699555406\n",
      "Epoch 943 / 10000 loss: 95.09617400169373\n",
      "MSE train 4.643033379224783 MSE test 7.77068305042314\n",
      "Epoch 944 / 10000 loss: 95.05586314201355\n",
      "MSE train 4.641030154445342 MSE test 7.769057082186483\n",
      "Epoch 945 / 10000 loss: 95.01459836959839\n",
      "MSE train 4.639014747432614 MSE test 7.767424419911081\n",
      "Epoch 946 / 10000 loss: 94.97220826148987\n",
      "MSE train 4.636976183417104 MSE test 7.765787240470115\n",
      "Epoch 947 / 10000 loss: 94.92954349517822\n",
      "MSE train 4.634876673018711 MSE test 7.76414611597291\n",
      "Epoch 948 / 10000 loss: 94.88636779785156\n",
      "MSE train 4.632737808754652 MSE test 7.7625041676499595\n",
      "Epoch 949 / 10000 loss: 94.84187698364258\n",
      "MSE train 4.6306242002871905 MSE test 7.760867488097312\n",
      "Epoch 950 / 10000 loss: 94.79653120040894\n",
      "MSE train 4.62856813408337 MSE test 7.759241144815428\n",
      "Epoch 951 / 10000 loss: 94.7517409324646\n",
      "MSE train 4.626539894325532 MSE test 7.757623788938561\n",
      "Epoch 952 / 10000 loss: 94.70818901062012\n",
      "MSE train 4.624511090831875 MSE test 7.756011497431012\n",
      "Epoch 953 / 10000 loss: 94.6652340888977\n",
      "MSE train 4.622461270889937 MSE test 7.754400849870643\n",
      "Epoch 954 / 10000 loss: 94.6222653388977\n",
      "MSE train 4.6203784232450875 MSE test 7.752789002726576\n",
      "Epoch 955 / 10000 loss: 94.57883882522583\n",
      "MSE train 4.618384783983422 MSE test 7.751181247987802\n",
      "Epoch 956 / 10000 loss: 94.53468656539917\n",
      "MSE train 4.6164455341631125 MSE test 7.749585251555767\n",
      "Epoch 957 / 10000 loss: 94.49246883392334\n",
      "MSE train 4.614517741628615 MSE test 7.748000968026696\n",
      "Epoch 958 / 10000 loss: 94.45143103599548\n",
      "MSE train 4.612573215380655 MSE test 7.7464225385323475\n",
      "Epoch 959 / 10000 loss: 94.41064810752869\n",
      "MSE train 4.610598576555783 MSE test 7.744845272972294\n",
      "Epoch 960 / 10000 loss: 94.36950254440308\n",
      "MSE train 4.6086196787057485 MSE test 7.743268879442291\n",
      "Epoch 961 / 10000 loss: 94.32771635055542\n",
      "MSE train 4.606680860647776 MSE test 7.741698702284115\n",
      "Epoch 962 / 10000 loss: 94.2858452796936\n",
      "MSE train 4.604768267436675 MSE test 7.740134629208787\n",
      "Epoch 963 / 10000 loss: 94.24485230445862\n",
      "MSE train 4.602858727837598 MSE test 7.7385722574625415\n",
      "Epoch 964 / 10000 loss: 94.20443439483643\n",
      "MSE train 4.60092749273259 MSE test 7.737006429835745\n",
      "Epoch 965 / 10000 loss: 94.1640932559967\n",
      "MSE train 4.5989190890303 MSE test 7.735430488501645\n",
      "Epoch 966 / 10000 loss: 94.12329316139221\n",
      "MSE train 4.5967647126462925 MSE test 7.733835093108094\n",
      "Epoch 967 / 10000 loss: 94.08083033561707\n",
      "MSE train 4.594589882634536 MSE test 7.732240608849713\n",
      "Epoch 968 / 10000 loss: 94.0352156162262\n",
      "MSE train 4.592441530252956 MSE test 7.730662110451709\n",
      "Epoch 969 / 10000 loss: 93.98917412757874\n",
      "MSE train 4.590412272463058 MSE test 7.729106906991428\n",
      "Epoch 970 / 10000 loss: 93.94372320175171\n",
      "MSE train 4.588497597200656 MSE test 7.727563316178\n",
      "Epoch 971 / 10000 loss: 93.90087223052979\n",
      "MSE train 4.586626228601582 MSE test 7.726027452493315\n",
      "Epoch 972 / 10000 loss: 93.86047887802124\n",
      "MSE train 4.5847537076470335 MSE test 7.7244956273484755\n",
      "Epoch 973 / 10000 loss: 93.8209912776947\n",
      "MSE train 4.582861975032517 MSE test 7.722964613229828\n",
      "Epoch 974 / 10000 loss: 93.78147339820862\n",
      "MSE train 4.580939287228484 MSE test 7.721431323025182\n",
      "Epoch 975 / 10000 loss: 93.74154281616211\n",
      "MSE train 4.578976883407311 MSE test 7.719892740620566\n",
      "Epoch 976 / 10000 loss: 93.70094108581543\n",
      "MSE train 4.5769663098374105 MSE test 7.7183463367788665\n",
      "Epoch 977 / 10000 loss: 93.65948271751404\n",
      "MSE train 4.574893849797035 MSE test 7.7167895769301635\n",
      "Epoch 978 / 10000 loss: 93.61698603630066\n",
      "MSE train 4.572715698639512 MSE test 7.71521971214316\n",
      "Epoch 979 / 10000 loss: 93.57315397262573\n",
      "MSE train 4.570466956845089 MSE test 7.713633112457216\n",
      "Epoch 980 / 10000 loss: 93.52703475952148\n",
      "MSE train 4.568404545346463 MSE test 7.712072199201334\n",
      "Epoch 981 / 10000 loss: 93.47937417030334\n",
      "MSE train 4.566312784657963 MSE test 7.710506398714896\n",
      "Epoch 982 / 10000 loss: 93.43576097488403\n",
      "MSE train 4.564160997483679 MSE test 7.708921272477855\n",
      "Epoch 983 / 10000 loss: 93.39151310920715\n",
      "MSE train 4.561963570852182 MSE test 7.707303098116933\n",
      "Epoch 984 / 10000 loss: 93.34596991539001\n",
      "MSE train 4.559935387127363 MSE test 7.705724042109621\n",
      "Epoch 985 / 10000 loss: 93.29943704605103\n",
      "MSE train 4.557945933723832 MSE test 7.704171164831699\n",
      "Epoch 986 / 10000 loss: 93.2565667629242\n",
      "MSE train 4.555953089866541 MSE test 7.702617354562986\n",
      "Epoch 987 / 10000 loss: 93.21451377868652\n",
      "MSE train 4.553942704109117 MSE test 7.701056628863024\n",
      "Epoch 988 / 10000 loss: 93.1723747253418\n",
      "MSE train 4.551911236221193 MSE test 7.699486396002372\n",
      "Epoch 989 / 10000 loss: 93.12984013557434\n",
      "MSE train 4.549872687618785 MSE test 7.6979090820180325\n",
      "Epoch 990 / 10000 loss: 93.08684515953064\n",
      "MSE train 4.547845428569058 MSE test 7.696331084447609\n",
      "Epoch 991 / 10000 loss: 93.04369902610779\n",
      "MSE train 4.5458253724709 MSE test 7.694754780221243\n",
      "Epoch 992 / 10000 loss: 93.00079917907715\n",
      "MSE train 4.543788559538527 MSE test 7.693176056667188\n",
      "Epoch 993 / 10000 loss: 92.95805096626282\n",
      "MSE train 4.541689655443252 MSE test 7.691586678905604\n",
      "Epoch 994 / 10000 loss: 92.91493725776672\n",
      "MSE train 4.5395047893361244 MSE test 7.689976184425895\n",
      "Epoch 995 / 10000 loss: 92.87048077583313\n",
      "MSE train 4.5373899631754355 MSE test 7.688382470820124\n",
      "Epoch 996 / 10000 loss: 92.82415413856506\n",
      "MSE train 4.5352519057438245 MSE test 7.686803045146658\n",
      "Epoch 997 / 10000 loss: 92.7793562412262\n",
      "MSE train 4.533121802704971 MSE test 7.685222952650151\n",
      "Epoch 998 / 10000 loss: 92.73407101631165\n",
      "MSE train 4.531055644548635 MSE test 7.683647238581108\n",
      "Epoch 999 / 10000 loss: 92.68896079063416\n",
      "MSE train 4.528979112853714 MSE test 7.68206789254746\n",
      "Epoch 1000 / 10000 loss: 92.6452407836914\n",
      "MSE train 4.5269155651365525 MSE test 7.680491257266384\n",
      "Epoch 1001 / 10000 loss: 92.60129451751709\n",
      "MSE train 4.524920658307286 MSE test 7.678956567111337\n",
      "Epoch 1002 / 10000 loss: 92.55763745307922\n",
      "MSE train 4.522876664024481 MSE test 7.677434130292556\n",
      "Epoch 1003 / 10000 loss: 92.51547455787659\n",
      "MSE train 4.520659427955738 MSE test 7.675898726627267\n",
      "Epoch 1004 / 10000 loss: 92.47227597236633\n",
      "MSE train 4.518615456140398 MSE test 7.674386846307134\n",
      "Epoch 1005 / 10000 loss: 92.42544031143188\n",
      "MSE train 4.516582770842754 MSE test 7.672887379900441\n",
      "Epoch 1006 / 10000 loss: 92.38224124908447\n",
      "MSE train 4.514612991929107 MSE test 7.671404283597562\n",
      "Epoch 1007 / 10000 loss: 92.33925414085388\n",
      "MSE train 4.512649109648381 MSE test 7.66993268203253\n",
      "Epoch 1008 / 10000 loss: 92.2976405620575\n",
      "MSE train 4.510713077777982 MSE test 7.66847185040124\n",
      "Epoch 1009 / 10000 loss: 92.25616335868835\n",
      "MSE train 4.508806086438119 MSE test 7.667024222420228\n",
      "Epoch 1010 / 10000 loss: 92.21528673171997\n",
      "MSE train 4.506889255670006 MSE test 7.6655844517004885\n",
      "Epoch 1011 / 10000 loss: 92.17501378059387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.504967526153588 MSE test 7.664152832590046\n",
      "Epoch 1012 / 10000 loss: 92.1345226764679\n",
      "MSE train 4.50298505556274 MSE test 7.662729690511883\n",
      "Epoch 1013 / 10000 loss: 92.0939347743988\n",
      "MSE train 4.501213783751341 MSE test 7.661329439483678\n",
      "Epoch 1014 / 10000 loss: 92.05206179618835\n",
      "MSE train 4.499451244404352 MSE test 7.659939065357219\n",
      "Epoch 1015 / 10000 loss: 92.01471757888794\n",
      "MSE train 4.497676775914887 MSE test 7.658550461332385\n",
      "Epoch 1016 / 10000 loss: 91.97754573822021\n",
      "MSE train 4.495885882669585 MSE test 7.657161147048166\n",
      "Epoch 1017 / 10000 loss: 91.94011521339417\n",
      "MSE train 4.494076916500205 MSE test 7.655770105604565\n",
      "Epoch 1018 / 10000 loss: 91.90232181549072\n",
      "MSE train 4.492249338028569 MSE test 7.654377719906819\n",
      "Epoch 1019 / 10000 loss: 91.86413288116455\n",
      "MSE train 4.490399583901771 MSE test 7.652984960392109\n",
      "Epoch 1020 / 10000 loss: 91.82553935050964\n",
      "MSE train 4.488519691183758 MSE test 7.651591873019582\n",
      "Epoch 1021 / 10000 loss: 91.7864637374878\n",
      "MSE train 4.486607682581348 MSE test 7.650197450576459\n",
      "Epoch 1022 / 10000 loss: 91.74672889709473\n",
      "MSE train 4.484679962464957 MSE test 7.648801610282243\n",
      "Epoch 1023 / 10000 loss: 91.70629811286926\n",
      "MSE train 4.482758600909211 MSE test 7.647405939873184\n",
      "Epoch 1024 / 10000 loss: 91.66552686691284\n",
      "MSE train 4.480836950615139 MSE test 7.646011977972137\n",
      "Epoch 1025 / 10000 loss: 91.62489247322083\n",
      "MSE train 4.478871227603343 MSE test 7.644618223151687\n",
      "Epoch 1026 / 10000 loss: 91.58424711227417\n",
      "MSE train 4.476986087559639 MSE test 7.643231919234104\n",
      "Epoch 1027 / 10000 loss: 91.54265213012695\n",
      "MSE train 4.475194276448079 MSE test 7.641870478314486\n",
      "Epoch 1028 / 10000 loss: 91.50280618667603\n",
      "MSE train 4.473392351084554 MSE test 7.640517206792796\n",
      "Epoch 1029 / 10000 loss: 91.4649703502655\n",
      "MSE train 4.471560761400588 MSE test 7.639167269623968\n",
      "Epoch 1030 / 10000 loss: 91.42690443992615\n",
      "MSE train 4.469769037584456 MSE test 7.637822868849044\n",
      "Epoch 1031 / 10000 loss: 91.38819909095764\n",
      "MSE train 4.4680324516148655 MSE test 7.636489198155576\n",
      "Epoch 1032 / 10000 loss: 91.35035800933838\n",
      "MSE train 4.466299193125821 MSE test 7.63516027052388\n",
      "Epoch 1033 / 10000 loss: 91.3136944770813\n",
      "MSE train 4.464557906368891 MSE test 7.633832546120206\n",
      "Epoch 1034 / 10000 loss: 91.27709555625916\n",
      "MSE train 4.462808589876392 MSE test 7.632504391672658\n",
      "Epoch 1035 / 10000 loss: 91.24031615257263\n",
      "MSE train 4.461049068000947 MSE test 7.63117448091452\n",
      "Epoch 1036 / 10000 loss: 91.20335650444031\n",
      "MSE train 4.459287059150654 MSE test 7.629842440932146\n",
      "Epoch 1037 / 10000 loss: 91.16618323326111\n",
      "MSE train 4.4575588865728415 MSE test 7.628509292959098\n",
      "Epoch 1038 / 10000 loss: 91.12896251678467\n",
      "MSE train 4.45587152527045 MSE test 7.627175729914676\n",
      "Epoch 1039 / 10000 loss: 91.09247875213623\n",
      "MSE train 4.454203022577605 MSE test 7.625839555775875\n",
      "Epoch 1040 / 10000 loss: 91.05687808990479\n",
      "MSE train 4.452539648382865 MSE test 7.624498095440879\n",
      "Epoch 1041 / 10000 loss: 91.02167820930481\n",
      "MSE train 4.450872639891041 MSE test 7.623149469368926\n",
      "Epoch 1042 / 10000 loss: 90.9865825176239\n",
      "MSE train 4.449193945509769 MSE test 7.621791533614404\n",
      "Epoch 1043 / 10000 loss: 90.95140433311462\n",
      "MSE train 4.447493092278763 MSE test 7.6204217734784185\n",
      "Epoch 1044 / 10000 loss: 90.91596412658691\n",
      "MSE train 4.445748937247656 MSE test 7.6190364249893685\n",
      "Epoch 1045 / 10000 loss: 90.88003873825073\n",
      "MSE train 4.443912255192798 MSE test 7.617628311228382\n",
      "Epoch 1046 / 10000 loss: 90.84317374229431\n",
      "MSE train 4.442034468355801 MSE test 7.616197155579414\n",
      "Epoch 1047 / 10000 loss: 90.8043007850647\n",
      "MSE train 4.440298732281959 MSE test 7.614804376699829\n",
      "Epoch 1048 / 10000 loss: 90.76450824737549\n",
      "MSE train 4.438595990077714 MSE test 7.613431302586417\n",
      "Epoch 1049 / 10000 loss: 90.727792263031\n",
      "MSE train 4.4368999433700145 MSE test 7.612068738088369\n",
      "Epoch 1050 / 10000 loss: 90.69178748130798\n",
      "MSE train 4.435194481085859 MSE test 7.6107146068278375\n",
      "Epoch 1051 / 10000 loss: 90.6559226512909\n",
      "MSE train 4.433472956564983 MSE test 7.609367828583545\n",
      "Epoch 1052 / 10000 loss: 90.61985397338867\n",
      "MSE train 4.431727937397321 MSE test 7.608028578637769\n",
      "Epoch 1053 / 10000 loss: 90.5834310054779\n",
      "MSE train 4.429905378203342 MSE test 7.60669599997898\n",
      "Epoch 1054 / 10000 loss: 90.54649639129639\n",
      "MSE train 4.427930768591128 MSE test 7.605366352671289\n",
      "Epoch 1055 / 10000 loss: 90.50787806510925\n",
      "MSE train 4.426144469871255 MSE test 7.604049603971606\n",
      "Epoch 1056 / 10000 loss: 90.46597456932068\n",
      "MSE train 4.424337522770853 MSE test 7.602740161156814\n",
      "Epoch 1057 / 10000 loss: 90.42815089225769\n",
      "MSE train 4.422489291337514 MSE test 7.601435389909574\n",
      "Epoch 1058 / 10000 loss: 90.38987493515015\n",
      "MSE train 4.4206188926592676 MSE test 7.600138013016441\n",
      "Epoch 1059 / 10000 loss: 90.35071420669556\n",
      "MSE train 4.4187464786110064 MSE test 7.598851287783238\n",
      "Epoch 1060 / 10000 loss: 90.31107306480408\n",
      "MSE train 4.4169457371202965 MSE test 7.59757524156258\n",
      "Epoch 1061 / 10000 loss: 90.27139663696289\n",
      "MSE train 4.4152676965662705 MSE test 7.59631009378385\n",
      "Epoch 1062 / 10000 loss: 90.23326969146729\n",
      "MSE train 4.4136511647002346 MSE test 7.595053651215587\n",
      "Epoch 1063 / 10000 loss: 90.19778275489807\n",
      "MSE train 4.412065775884049 MSE test 7.593803544007939\n",
      "Epoch 1064 / 10000 loss: 90.16361379623413\n",
      "MSE train 4.410499521446707 MSE test 7.592558058172447\n",
      "Epoch 1065 / 10000 loss: 90.13011026382446\n",
      "MSE train 4.408944518265149 MSE test 7.591315402474424\n",
      "Epoch 1066 / 10000 loss: 90.09701681137085\n",
      "MSE train 4.407394990022662 MSE test 7.590073673986207\n",
      "Epoch 1067 / 10000 loss: 90.06416130065918\n",
      "MSE train 4.4058461765671035 MSE test 7.588830932628219\n",
      "Epoch 1068 / 10000 loss: 90.03142356872559\n",
      "MSE train 4.404293463856132 MSE test 7.587585298177511\n",
      "Epoch 1069 / 10000 loss: 89.99870014190674\n",
      "MSE train 4.402732342301739 MSE test 7.586335493137499\n",
      "Epoch 1070 / 10000 loss: 89.96589207649231\n",
      "MSE train 4.401158650750141 MSE test 7.5850802982507055\n",
      "Epoch 1071 / 10000 loss: 89.93290281295776\n",
      "MSE train 4.399568066688658 MSE test 7.58381855906201\n",
      "Epoch 1072 / 10000 loss: 89.89964294433594\n",
      "MSE train 4.397954593101034 MSE test 7.582550012153676\n",
      "Epoch 1073 / 10000 loss: 89.86602210998535\n",
      "MSE train 4.396307836360588 MSE test 7.58127423819971\n",
      "Epoch 1074 / 10000 loss: 89.83190584182739\n",
      "MSE train 4.3945950375697755 MSE test 7.579991324170667\n",
      "Epoch 1075 / 10000 loss: 89.79707169532776\n",
      "MSE train 4.392641164156707 MSE test 7.578700626046317\n",
      "Epoch 1076 / 10000 loss: 89.76080632209778\n",
      "MSE train 4.390951417903944 MSE test 7.577415036475398\n",
      "Epoch 1077 / 10000 loss: 89.71933054924011\n",
      "MSE train 4.38928859271022 MSE test 7.576137213708807\n",
      "Epoch 1078 / 10000 loss: 89.68359637260437\n",
      "MSE train 4.387615909924543 MSE test 7.5748593782231675\n",
      "Epoch 1079 / 10000 loss: 89.64844107627869\n",
      "MSE train 4.3859128912342005 MSE test 7.573575946956226\n",
      "Epoch 1080 / 10000 loss: 89.61307740211487\n",
      "MSE train 4.384141406632426 MSE test 7.572277868728693\n",
      "Epoch 1081 / 10000 loss: 89.57705926895142\n",
      "MSE train 4.382216319392433 MSE test 7.570948842137242\n",
      "Epoch 1082 / 10000 loss: 89.53955388069153\n",
      "MSE train 4.380162305445801 MSE test 7.569565692057508\n",
      "Epoch 1083 / 10000 loss: 89.49869799613953\n",
      "MSE train 4.3784252435163475 MSE test 7.568260276955826\n",
      "Epoch 1084 / 10000 loss: 89.45515584945679\n",
      "MSE train 4.376732617019883 MSE test 7.566978897353654\n",
      "Epoch 1085 / 10000 loss: 89.41844725608826\n",
      "MSE train 4.3750678022685845 MSE test 7.565701625520557\n",
      "Epoch 1086 / 10000 loss: 89.38268494606018\n",
      "MSE train 4.373421894423137 MSE test 7.564426160902945\n",
      "Epoch 1087 / 10000 loss: 89.34751009941101\n",
      "MSE train 4.371781145286405 MSE test 7.563150635228151\n",
      "Epoch 1088 / 10000 loss: 89.31274223327637\n",
      "MSE train 4.370135043519729 MSE test 7.561872585056393\n",
      "Epoch 1089 / 10000 loss: 89.27807259559631\n",
      "MSE train 4.368477083678751 MSE test 7.560590056504698\n",
      "Epoch 1090 / 10000 loss: 89.24328303337097\n",
      "MSE train 4.366803151932045 MSE test 7.559301478577299\n",
      "Epoch 1091 / 10000 loss: 89.20822834968567\n",
      "MSE train 4.365113967216572 MSE test 7.558005654045265\n",
      "Epoch 1092 / 10000 loss: 89.1728241443634\n",
      "MSE train 4.363412488358768 MSE test 7.55670201041729\n",
      "Epoch 1093 / 10000 loss: 89.13708662986755\n",
      "MSE train 4.36169513589499 MSE test 7.555390559542835\n",
      "Epoch 1094 / 10000 loss: 89.101083278656\n",
      "MSE train 4.359957164851332 MSE test 7.554071255669674\n",
      "Epoch 1095 / 10000 loss: 89.06473922729492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.358201631630835 MSE test 7.55274569617128\n",
      "Epoch 1096 / 10000 loss: 89.0279495716095\n",
      "MSE train 4.356435195086142 MSE test 7.551416168248778\n",
      "Epoch 1097 / 10000 loss: 88.99078154563904\n",
      "MSE train 4.354664605982705 MSE test 7.550087138958955\n",
      "Epoch 1098 / 10000 loss: 88.95337581634521\n",
      "MSE train 4.352901295045407 MSE test 7.548764214177089\n",
      "Epoch 1099 / 10000 loss: 88.91587805747986\n",
      "MSE train 4.351154378578063 MSE test 7.547453413156235\n",
      "Epoch 1100 / 10000 loss: 88.8785309791565\n",
      "MSE train 4.349416569954526 MSE test 7.546157077093518\n",
      "Epoch 1101 / 10000 loss: 88.84153985977173\n",
      "MSE train 4.3476728811585845 MSE test 7.5448736233480975\n",
      "Epoch 1102 / 10000 loss: 88.8047366142273\n",
      "MSE train 4.345934991411799 MSE test 7.543600480076487\n",
      "Epoch 1103 / 10000 loss: 88.76780295372009\n",
      "MSE train 4.344202169914483 MSE test 7.542335185955072\n",
      "Epoch 1104 / 10000 loss: 88.73098945617676\n",
      "MSE train 4.342462165094506 MSE test 7.541074522680356\n",
      "Epoch 1105 / 10000 loss: 88.69428491592407\n",
      "MSE train 4.340793076285304 MSE test 7.539829100284567\n",
      "Epoch 1106 / 10000 loss: 88.65741991996765\n",
      "MSE train 4.339162882408684 MSE test 7.538601402990264\n",
      "Epoch 1107 / 10000 loss: 88.6220862865448\n",
      "MSE train 4.337537364568204 MSE test 7.537381825427364\n",
      "Epoch 1108 / 10000 loss: 88.58759498596191\n",
      "MSE train 4.335911332000838 MSE test 7.536167149857294\n",
      "Epoch 1109 / 10000 loss: 88.55319857597351\n",
      "MSE train 4.334285994457349 MSE test 7.534956020308932\n",
      "Epoch 1110 / 10000 loss: 88.51878762245178\n",
      "MSE train 4.332663545657815 MSE test 7.533747461831889\n",
      "Epoch 1111 / 10000 loss: 88.48438930511475\n",
      "MSE train 4.331044169617477 MSE test 7.532541178378537\n",
      "Epoch 1112 / 10000 loss: 88.4500482082367\n",
      "MSE train 4.329427860022564 MSE test 7.531336607498147\n",
      "Epoch 1113 / 10000 loss: 88.4157783985138\n",
      "MSE train 4.327816052293362 MSE test 7.530133241643587\n",
      "Epoch 1114 / 10000 loss: 88.38156867027283\n",
      "MSE train 4.32620921276573 MSE test 7.528930375534665\n",
      "Epoch 1115 / 10000 loss: 88.34745621681213\n",
      "MSE train 4.324613852674338 MSE test 7.527728966648339\n",
      "Epoch 1116 / 10000 loss: 88.31344699859619\n",
      "MSE train 4.323049876227311 MSE test 7.526532656537963\n",
      "Epoch 1117 / 10000 loss: 88.2796859741211\n",
      "MSE train 4.321526527728403 MSE test 7.525345431965861\n",
      "Epoch 1118 / 10000 loss: 88.24660181999207\n",
      "MSE train 4.320032814380172 MSE test 7.524166978421523\n",
      "Epoch 1119 / 10000 loss: 88.2143976688385\n",
      "MSE train 4.318552506085823 MSE test 7.522994951848415\n",
      "Epoch 1120 / 10000 loss: 88.1828305721283\n",
      "MSE train 4.3170662945503855 MSE test 7.52182589488877\n",
      "Epoch 1121 / 10000 loss: 88.15155410766602\n",
      "MSE train 4.315538145923565 MSE test 7.5206556886863565\n",
      "Epoch 1122 / 10000 loss: 88.12014627456665\n",
      "MSE train 4.313888276339836 MSE test 7.519478774121161\n",
      "Epoch 1123 / 10000 loss: 88.08782434463501\n",
      "MSE train 4.312214623367016 MSE test 7.5182952858208525\n",
      "Epoch 1124 / 10000 loss: 88.05286145210266\n",
      "MSE train 4.310702783752758 MSE test 7.517131412743552\n",
      "Epoch 1125 / 10000 loss: 88.0173830986023\n",
      "MSE train 4.3092474592165875 MSE test 7.515973032917185\n",
      "Epoch 1126 / 10000 loss: 87.98539662361145\n",
      "MSE train 4.307797016714214 MSE test 7.514815792281797\n",
      "Epoch 1127 / 10000 loss: 87.9546308517456\n",
      "MSE train 4.306331415425829 MSE test 7.513657140225897\n",
      "Epoch 1128 / 10000 loss: 87.92396569252014\n",
      "MSE train 4.304839071095158 MSE test 7.512495002434816\n",
      "Epoch 1129 / 10000 loss: 87.89297246932983\n",
      "MSE train 4.303310609393175 MSE test 7.511327786006347\n",
      "Epoch 1130 / 10000 loss: 87.86139392852783\n",
      "MSE train 4.30173662339829 MSE test 7.510153966918435\n",
      "Epoch 1131 / 10000 loss: 87.82903146743774\n",
      "MSE train 4.300105443647332 MSE test 7.508972002711651\n",
      "Epoch 1132 / 10000 loss: 87.79568243026733\n",
      "MSE train 4.298404627271431 MSE test 7.507779612445789\n",
      "Epoch 1133 / 10000 loss: 87.76109480857849\n",
      "MSE train 4.296625590644583 MSE test 7.506573916071833\n",
      "Epoch 1134 / 10000 loss: 87.72499442100525\n",
      "MSE train 4.294855824793792 MSE test 7.505357715645285\n",
      "Epoch 1135 / 10000 loss: 87.6872010231018\n",
      "MSE train 4.29313386761807 MSE test 7.504145280790011\n",
      "Epoch 1136 / 10000 loss: 87.64961290359497\n",
      "MSE train 4.291248065851464 MSE test 7.502911334119887\n",
      "Epoch 1137 / 10000 loss: 87.61306309700012\n",
      "MSE train 4.289328100912473 MSE test 7.501642170892156\n",
      "Epoch 1138 / 10000 loss: 87.57297539710999\n",
      "MSE train 4.287514318872663 MSE test 7.500440938093553\n",
      "Epoch 1139 / 10000 loss: 87.53215622901917\n",
      "MSE train 4.2857832207914655 MSE test 7.499238879843541\n",
      "Epoch 1140 / 10000 loss: 87.49360632896423\n",
      "MSE train 4.284087211232762 MSE test 7.4980358268898035\n",
      "Epoch 1141 / 10000 loss: 87.45685076713562\n",
      "MSE train 4.282366293173815 MSE test 7.496823802942562\n",
      "Epoch 1142 / 10000 loss: 87.4208471775055\n",
      "MSE train 4.280674771869931 MSE test 7.4956117110546625\n",
      "Epoch 1143 / 10000 loss: 87.38431477546692\n",
      "MSE train 4.279015562676206 MSE test 7.49441151005561\n",
      "Epoch 1144 / 10000 loss: 87.34842681884766\n",
      "MSE train 4.2773576990557665 MSE test 7.49321490591709\n",
      "Epoch 1145 / 10000 loss: 87.31323480606079\n",
      "MSE train 4.275735206149775 MSE test 7.492028471742915\n",
      "Epoch 1146 / 10000 loss: 87.27806782722473\n",
      "MSE train 4.274158609608734 MSE test 7.490861552872372\n",
      "Epoch 1147 / 10000 loss: 87.2436637878418\n",
      "MSE train 4.272603464676521 MSE test 7.489708696059379\n",
      "Epoch 1148 / 10000 loss: 87.2102563381195\n",
      "MSE train 4.2710542615029246 MSE test 7.488563520561973\n",
      "Epoch 1149 / 10000 loss: 87.17730641365051\n",
      "MSE train 4.269501964628466 MSE test 7.487422847304398\n",
      "Epoch 1150 / 10000 loss: 87.14448404312134\n",
      "MSE train 4.267940549762308 MSE test 7.486284766898164\n",
      "Epoch 1151 / 10000 loss: 87.11159372329712\n",
      "MSE train 4.266367496919168 MSE test 7.4851482281474135\n",
      "Epoch 1152 / 10000 loss: 87.07850575447083\n",
      "MSE train 4.264785233393329 MSE test 7.484013072593371\n",
      "Epoch 1153 / 10000 loss: 87.04516267776489\n",
      "MSE train 4.2632017503733755 MSE test 7.482879522775319\n",
      "Epoch 1154 / 10000 loss: 87.01162147521973\n",
      "MSE train 4.2616277967535385 MSE test 7.481748241880832\n",
      "Epoch 1155 / 10000 loss: 86.97805452346802\n",
      "MSE train 4.260069884921692 MSE test 7.48061948658514\n",
      "Epoch 1156 / 10000 loss: 86.94469594955444\n",
      "MSE train 4.258524607306441 MSE test 7.479492714503015\n",
      "Epoch 1157 / 10000 loss: 86.91168594360352\n",
      "MSE train 4.256980800194874 MSE test 7.47836635162277\n",
      "Epoch 1158 / 10000 loss: 86.87894606590271\n",
      "MSE train 4.255429793213278 MSE test 7.477238297376692\n",
      "Epoch 1159 / 10000 loss: 86.8462462425232\n",
      "MSE train 4.253877602303134 MSE test 7.476106641737963\n",
      "Epoch 1160 / 10000 loss: 86.81339478492737\n",
      "MSE train 4.252325760688692 MSE test 7.474969773448394\n",
      "Epoch 1161 / 10000 loss: 86.78052616119385\n",
      "MSE train 4.2507343945366065 MSE test 7.473824404344749\n",
      "Epoch 1162 / 10000 loss: 86.74766039848328\n",
      "MSE train 4.249040747561844 MSE test 7.472666406534638\n",
      "Epoch 1163 / 10000 loss: 86.71394467353821\n",
      "MSE train 4.247281998517964 MSE test 7.471496230444771\n",
      "Epoch 1164 / 10000 loss: 86.67804312705994\n",
      "MSE train 4.24560001861476 MSE test 7.470329393700177\n",
      "Epoch 1165 / 10000 loss: 86.64078450202942\n",
      "MSE train 4.244035160499233 MSE test 7.46918042597161\n",
      "Epoch 1166 / 10000 loss: 86.60515832901001\n",
      "MSE train 4.242544197910106 MSE test 7.468046536858536\n",
      "Epoch 1167 / 10000 loss: 86.57203698158264\n",
      "MSE train 4.241073962530545 MSE test 7.466921545076164\n",
      "Epoch 1168 / 10000 loss: 86.5405023097992\n",
      "MSE train 4.239609350148153 MSE test 7.465801697122293\n",
      "Epoch 1169 / 10000 loss: 86.50941181182861\n",
      "MSE train 4.238149753726091 MSE test 7.464686078654669\n",
      "Epoch 1170 / 10000 loss: 86.47844529151917\n",
      "MSE train 4.236697084361257 MSE test 7.463574548640813\n",
      "Epoch 1171 / 10000 loss: 86.44758892059326\n",
      "MSE train 4.235252624545746 MSE test 7.462467324906662\n",
      "Epoch 1172 / 10000 loss: 86.41688513755798\n",
      "MSE train 4.233816182928829 MSE test 7.461364284932608\n",
      "Epoch 1173 / 10000 loss: 86.38636231422424\n",
      "MSE train 4.232385957259544 MSE test 7.460265299380292\n",
      "Epoch 1174 / 10000 loss: 86.35601115226746\n",
      "MSE train 4.2309592910533285 MSE test 7.459169967622935\n",
      "Epoch 1175 / 10000 loss: 86.32579803466797\n",
      "MSE train 4.229533784942129 MSE test 7.458077578210163\n",
      "Epoch 1176 / 10000 loss: 86.29566216468811\n",
      "MSE train 4.2281075613019965 MSE test 7.45698792625538\n",
      "Epoch 1177 / 10000 loss: 86.26555228233337\n",
      "MSE train 4.226678446111443 MSE test 7.455900525625503\n",
      "Epoch 1178 / 10000 loss: 86.23542213439941\n",
      "MSE train 4.22524349764441 MSE test 7.454815257859872\n",
      "Epoch 1179 / 10000 loss: 86.20522904396057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.22379901712405 MSE test 7.453732087290794\n",
      "Epoch 1180 / 10000 loss: 86.1749017238617\n",
      "MSE train 4.222340534466096 MSE test 7.452651392710859\n",
      "Epoch 1181 / 10000 loss: 86.14436507225037\n",
      "MSE train 4.220861072443354 MSE test 7.451573202741672\n",
      "Epoch 1182 / 10000 loss: 86.11353015899658\n",
      "MSE train 4.219354900964762 MSE test 7.450497301597211\n",
      "Epoch 1183 / 10000 loss: 86.08224654197693\n",
      "MSE train 4.2178742731266015 MSE test 7.449424679350956\n",
      "Epoch 1184 / 10000 loss: 86.05040955543518\n",
      "MSE train 4.216476778181207 MSE test 7.448358857425164\n",
      "Epoch 1185 / 10000 loss: 86.01912808418274\n",
      "MSE train 4.215118002573372 MSE test 7.4472987172420675\n",
      "Epoch 1186 / 10000 loss: 85.98961019515991\n",
      "MSE train 4.213775872374312 MSE test 7.446242435769777\n",
      "Epoch 1187 / 10000 loss: 85.96090149879456\n",
      "MSE train 4.212442033156897 MSE test 7.445188761658696\n",
      "Epoch 1188 / 10000 loss: 85.93254470825195\n",
      "MSE train 4.2111106385060975 MSE test 7.444136864541693\n",
      "Epoch 1189 / 10000 loss: 85.90435814857483\n",
      "MSE train 4.209776800268388 MSE test 7.443086031834856\n",
      "Epoch 1190 / 10000 loss: 85.87621879577637\n",
      "MSE train 4.208435486643122 MSE test 7.442035393599093\n",
      "Epoch 1191 / 10000 loss: 85.84802603721619\n",
      "MSE train 4.207080265707545 MSE test 7.44098361332599\n",
      "Epoch 1192 / 10000 loss: 85.81967067718506\n",
      "MSE train 4.205702395533437 MSE test 7.439929551749459\n",
      "Epoch 1193 / 10000 loss: 85.79101014137268\n",
      "MSE train 4.204292945303844 MSE test 7.438872347025273\n",
      "Epoch 1194 / 10000 loss: 85.76186037063599\n",
      "MSE train 4.202856353903215 MSE test 7.4378138906110065\n",
      "Epoch 1195 / 10000 loss: 85.73202729225159\n",
      "MSE train 4.201431445181832 MSE test 7.436760752611003\n",
      "Epoch 1196 / 10000 loss: 85.70160913467407\n",
      "MSE train 4.200066166653745 MSE test 7.435719692536173\n",
      "Epoch 1197 / 10000 loss: 85.6714460849762\n",
      "MSE train 4.1987578746336185 MSE test 7.434691300575626\n",
      "Epoch 1198 / 10000 loss: 85.64257383346558\n",
      "MSE train 4.197481224585344 MSE test 7.433673141601817\n",
      "Epoch 1199 / 10000 loss: 85.61493802070618\n",
      "MSE train 4.19621834505482 MSE test 7.432663529135506\n",
      "Epoch 1200 / 10000 loss: 85.58798480033875\n",
      "MSE train 4.1949619295388265 MSE test 7.4316615720621115\n",
      "Epoch 1201 / 10000 loss: 85.56133460998535\n",
      "MSE train 4.193737688680023 MSE test 7.43066681294233\n",
      "Epoch 1202 / 10000 loss: 85.53482174873352\n",
      "MSE train 4.192572737068238 MSE test 7.429678906245511\n",
      "Epoch 1203 / 10000 loss: 85.50901055335999\n",
      "MSE train 4.191447257210066 MSE test 7.428697005032567\n",
      "Epoch 1204 / 10000 loss: 85.4844856262207\n",
      "MSE train 4.190344143047121 MSE test 7.427720095395137\n",
      "Epoch 1205 / 10000 loss: 85.4608166217804\n",
      "MSE train 4.189255281092098 MSE test 7.426747064493043\n",
      "Epoch 1206 / 10000 loss: 85.43763470649719\n",
      "MSE train 4.1881747067325605 MSE test 7.4257765475930375\n",
      "Epoch 1207 / 10000 loss: 85.41476345062256\n",
      "MSE train 4.187097110207654 MSE test 7.424807050771163\n",
      "Epoch 1208 / 10000 loss: 85.39207601547241\n",
      "MSE train 4.18601781467475 MSE test 7.423837270834087\n",
      "Epoch 1209 / 10000 loss: 85.36945390701294\n",
      "MSE train 4.18493312489654 MSE test 7.422865227876631\n",
      "Epoch 1210 / 10000 loss: 85.34680080413818\n",
      "MSE train 4.183840577431136 MSE test 7.421889464742536\n",
      "Epoch 1211 / 10000 loss: 85.3240385055542\n",
      "MSE train 4.182738585297269 MSE test 7.4209079406433\n",
      "Epoch 1212 / 10000 loss: 85.301100730896\n",
      "MSE train 4.1816254822488945 MSE test 7.419918691655884\n",
      "Epoch 1213 / 10000 loss: 85.27796483039856\n",
      "MSE train 4.180498870649602 MSE test 7.418920093627514\n",
      "Epoch 1214 / 10000 loss: 85.25458860397339\n",
      "MSE train 4.17935568829489 MSE test 7.417910672524738\n",
      "Epoch 1215 / 10000 loss: 85.23092269897461\n",
      "MSE train 4.178191798803086 MSE test 7.416890419233324\n",
      "Epoch 1216 / 10000 loss: 85.20689654350281\n",
      "MSE train 4.176995808634089 MSE test 7.415860305690965\n",
      "Epoch 1217 / 10000 loss: 85.1824312210083\n",
      "MSE train 4.175713934981626 MSE test 7.414820294762124\n",
      "Epoch 1218 / 10000 loss: 85.15727639198303\n",
      "MSE train 4.17397006504267 MSE test 7.413752457746084\n",
      "Epoch 1219 / 10000 loss: 85.13013935089111\n",
      "MSE train 4.172737633622403 MSE test 7.412719214633153\n",
      "Epoch 1220 / 10000 loss: 85.09364819526672\n",
      "MSE train 4.171524414297047 MSE test 7.411693688138975\n",
      "Epoch 1221 / 10000 loss: 85.06771445274353\n",
      "MSE train 4.170296967051167 MSE test 7.410669469307591\n",
      "Epoch 1222 / 10000 loss: 85.04214334487915\n",
      "MSE train 4.169053668149217 MSE test 7.409645452124477\n",
      "Epoch 1223 / 10000 loss: 85.01625895500183\n",
      "MSE train 4.167794721108972 MSE test 7.408621280808803\n",
      "Epoch 1224 / 10000 loss: 84.9900324344635\n",
      "MSE train 4.166520418800507 MSE test 7.4075966631139805\n",
      "Epoch 1225 / 10000 loss: 84.96346807479858\n",
      "MSE train 4.16523057729806 MSE test 7.406571762085278\n",
      "Epoch 1226 / 10000 loss: 84.93657350540161\n",
      "MSE train 4.163924324670563 MSE test 7.405546572134058\n",
      "Epoch 1227 / 10000 loss: 84.909343957901\n",
      "MSE train 4.1626003118984904 MSE test 7.404521027940624\n",
      "Epoch 1228 / 10000 loss: 84.88175773620605\n",
      "MSE train 4.16125736640124 MSE test 7.40349533571283\n",
      "Epoch 1229 / 10000 loss: 84.8537917137146\n",
      "MSE train 4.159895815211755 MSE test 7.402469695875272\n",
      "Epoch 1230 / 10000 loss: 84.82541751861572\n",
      "MSE train 4.158518052954628 MSE test 7.401444312302152\n",
      "Epoch 1231 / 10000 loss: 84.79663872718811\n",
      "MSE train 4.157126171841695 MSE test 7.400419241074209\n",
      "Epoch 1232 / 10000 loss: 84.76750874519348\n",
      "MSE train 4.1557162399217065 MSE test 7.399394387216867\n",
      "Epoch 1233 / 10000 loss: 84.73806381225586\n",
      "MSE train 4.154272374846335 MSE test 7.3983690590953\n",
      "Epoch 1234 / 10000 loss: 84.70823121070862\n",
      "MSE train 4.152759322351494 MSE test 7.397342067753254\n",
      "Epoch 1235 / 10000 loss: 84.67767405509949\n",
      "MSE train 4.151240921203969 MSE test 7.396312814517681\n",
      "Epoch 1236 / 10000 loss: 84.64563918113708\n",
      "MSE train 4.1498329696880925 MSE test 7.395288480526544\n",
      "Epoch 1237 / 10000 loss: 84.61349153518677\n",
      "MSE train 4.148398543629528 MSE test 7.394261057527053\n",
      "Epoch 1238 / 10000 loss: 84.5837254524231\n",
      "MSE train 4.146837814845877 MSE test 7.393221419152174\n",
      "Epoch 1239 / 10000 loss: 84.55336594581604\n",
      "MSE train 4.145194587339221 MSE test 7.392156934020629\n",
      "Epoch 1240 / 10000 loss: 84.52024817466736\n",
      "MSE train 4.143814333883338 MSE test 7.391140078467283\n",
      "Epoch 1241 / 10000 loss: 84.4853904247284\n",
      "MSE train 4.14245583456193 MSE test 7.390128446724435\n",
      "Epoch 1242 / 10000 loss: 84.4561915397644\n",
      "MSE train 4.141107368923695 MSE test 7.389118505424005\n",
      "Epoch 1243 / 10000 loss: 84.42745995521545\n",
      "MSE train 4.139765088391314 MSE test 7.3881093720028534\n",
      "Epoch 1244 / 10000 loss: 84.39894485473633\n",
      "MSE train 4.138409667558763 MSE test 7.387100188961377\n",
      "Epoch 1245 / 10000 loss: 84.37056374549866\n",
      "MSE train 4.136952638219949 MSE test 7.386088580734464\n",
      "Epoch 1246 / 10000 loss: 84.34190249443054\n",
      "MSE train 4.1354691566703865 MSE test 7.385071493243553\n",
      "Epoch 1247 / 10000 loss: 84.31105852127075\n",
      "MSE train 4.1341754184675725 MSE test 7.384065559632062\n",
      "Epoch 1248 / 10000 loss: 84.27966380119324\n",
      "MSE train 4.132887174970934 MSE test 7.38305878668248\n",
      "Epoch 1249 / 10000 loss: 84.25232481956482\n",
      "MSE train 4.131603757141915 MSE test 7.3820506607696625\n",
      "Epoch 1250 / 10000 loss: 84.22510099411011\n",
      "MSE train 4.1303248977015645 MSE test 7.381041141012895\n",
      "Epoch 1251 / 10000 loss: 84.19798135757446\n",
      "MSE train 4.129050637462565 MSE test 7.380030645373766\n",
      "Epoch 1252 / 10000 loss: 84.17096138000488\n",
      "MSE train 4.127781308184072 MSE test 7.379019716111181\n",
      "Epoch 1253 / 10000 loss: 84.14404225349426\n",
      "MSE train 4.1265166279381384 MSE test 7.378009151348213\n",
      "Epoch 1254 / 10000 loss: 84.11723232269287\n",
      "MSE train 4.1252545731014765 MSE test 7.376999355890072\n",
      "Epoch 1255 / 10000 loss: 84.09052801132202\n",
      "MSE train 4.123990618345661 MSE test 7.375990104809998\n",
      "Epoch 1256 / 10000 loss: 84.06387662887573\n",
      "MSE train 4.122717628782037 MSE test 7.374980588496946\n",
      "Epoch 1257 / 10000 loss: 84.03718090057373\n",
      "MSE train 4.121425624052136 MSE test 7.373969342881652\n",
      "Epoch 1258 / 10000 loss: 84.01029181480408\n",
      "MSE train 4.120103656715618 MSE test 7.372954611810276\n",
      "Epoch 1259 / 10000 loss: 83.98298811912537\n",
      "MSE train 4.118757005744685 MSE test 7.371936394770708\n",
      "Epoch 1260 / 10000 loss: 83.95503330230713\n",
      "MSE train 4.117430033827115 MSE test 7.370921203641454\n",
      "Epoch 1261 / 10000 loss: 83.92654752731323\n",
      "MSE train 4.116142576291579 MSE test 7.369916273891947\n",
      "Epoch 1262 / 10000 loss: 83.89849901199341\n",
      "MSE train 4.114872898093073 MSE test 7.368918271051785\n",
      "Epoch 1263 / 10000 loss: 83.87130117416382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.113605197730016 MSE test 7.367922678838396\n",
      "Epoch 1264 / 10000 loss: 83.84448528289795\n",
      "MSE train 4.112326665924192 MSE test 7.366926464617299\n",
      "Epoch 1265 / 10000 loss: 83.81771087646484\n",
      "MSE train 4.111023409860572 MSE test 7.365927324800276\n",
      "Epoch 1266 / 10000 loss: 83.79069948196411\n",
      "MSE train 4.1096572276570855 MSE test 7.364923503674505\n",
      "Epoch 1267 / 10000 loss: 83.76315450668335\n",
      "MSE train 4.108003463691645 MSE test 7.363906519881315\n",
      "Epoch 1268 / 10000 loss: 83.73424482345581\n",
      "MSE train 4.1066486040542305 MSE test 7.362903458722938\n",
      "Epoch 1269 / 10000 loss: 83.69915652275085\n",
      "MSE train 4.105188660922139 MSE test 7.361897197897852\n",
      "Epoch 1270 / 10000 loss: 83.67051076889038\n",
      "MSE train 4.103737145888243 MSE test 7.36088933510374\n",
      "Epoch 1271 / 10000 loss: 83.6396210193634\n",
      "MSE train 4.102277665976959 MSE test 7.35988160899861\n",
      "Epoch 1272 / 10000 loss: 83.60889840126038\n",
      "MSE train 4.100988300539673 MSE test 7.3588751687623315\n",
      "Epoch 1273 / 10000 loss: 83.57794785499573\n",
      "MSE train 4.099669877599629 MSE test 7.357865295406772\n",
      "Epoch 1274 / 10000 loss: 83.55066633224487\n",
      "MSE train 4.098321637338772 MSE test 7.35685158137408\n",
      "Epoch 1275 / 10000 loss: 83.52275514602661\n",
      "MSE train 4.097017200500083 MSE test 7.3558421737721895\n",
      "Epoch 1276 / 10000 loss: 83.49419164657593\n",
      "MSE train 4.095771847515343 MSE test 7.354846154171418\n",
      "Epoch 1277 / 10000 loss: 83.4665744304657\n",
      "MSE train 4.094545017187397 MSE test 7.353856963783712\n",
      "Epoch 1278 / 10000 loss: 83.44022989273071\n",
      "MSE train 4.09332286588044 MSE test 7.352869992849885\n",
      "Epoch 1279 / 10000 loss: 83.41428327560425\n",
      "MSE train 4.0920988231354 MSE test 7.351882876051548\n",
      "Epoch 1280 / 10000 loss: 83.38843011856079\n",
      "MSE train 4.090867490426449 MSE test 7.35089406014989\n",
      "Epoch 1281 / 10000 loss: 83.3625328540802\n",
      "MSE train 4.089619652212246 MSE test 7.349901542626785\n",
      "Epoch 1282 / 10000 loss: 83.3364782333374\n",
      "MSE train 4.088335134976887 MSE test 7.348902873979663\n",
      "Epoch 1283 / 10000 loss: 83.31005859375\n",
      "MSE train 4.086975062667481 MSE test 7.347894123012569\n",
      "Epoch 1284 / 10000 loss: 83.28284478187561\n",
      "MSE train 4.085498429727449 MSE test 7.34687105417792\n",
      "Epoch 1285 / 10000 loss: 83.25398397445679\n",
      "MSE train 4.083976794581287 MSE test 7.34584117009683\n",
      "Epoch 1286 / 10000 loss: 83.22260308265686\n",
      "MSE train 4.082504196866056 MSE test 7.34482434900515\n",
      "Epoch 1287 / 10000 loss: 83.19031047821045\n",
      "MSE train 4.0811707108947815 MSE test 7.343820533188394\n",
      "Epoch 1288 / 10000 loss: 83.15908479690552\n",
      "MSE train 4.079903461546499 MSE test 7.342825840992692\n",
      "Epoch 1289 / 10000 loss: 83.13084554672241\n",
      "MSE train 4.0786541327520975 MSE test 7.341833362319567\n",
      "Epoch 1290 / 10000 loss: 83.10402345657349\n",
      "MSE train 4.077429140969497 MSE test 7.3408425751569455\n",
      "Epoch 1291 / 10000 loss: 83.07758378982544\n",
      "MSE train 4.076228066240054 MSE test 7.339854665493753\n",
      "Epoch 1292 / 10000 loss: 83.05167055130005\n",
      "MSE train 4.07504417270843 MSE test 7.338870648318874\n",
      "Epoch 1293 / 10000 loss: 83.02627491950989\n",
      "MSE train 4.073871585536217 MSE test 7.337890141922821\n",
      "Epoch 1294 / 10000 loss: 83.00125193595886\n",
      "MSE train 4.072706679376909 MSE test 7.336912018989034\n",
      "Epoch 1295 / 10000 loss: 82.97646951675415\n",
      "MSE train 4.071545535406624 MSE test 7.335934902941699\n",
      "Epoch 1296 / 10000 loss: 82.9518506526947\n",
      "MSE train 4.070380540946266 MSE test 7.334956909447685\n",
      "Epoch 1297 / 10000 loss: 82.92731380462646\n",
      "MSE train 4.069200166121857 MSE test 7.333975769444079\n",
      "Epoch 1298 / 10000 loss: 82.90269446372986\n",
      "MSE train 4.067990874868531 MSE test 7.33298888927707\n",
      "Epoch 1299 / 10000 loss: 82.8777425289154\n",
      "MSE train 4.066741932289386 MSE test 7.331994408830346\n",
      "Epoch 1300 / 10000 loss: 82.8521716594696\n",
      "MSE train 4.065458608948928 MSE test 7.330993779859842\n",
      "Epoch 1301 / 10000 loss: 82.82574987411499\n",
      "MSE train 4.064171057556463 MSE test 7.329993554032126\n",
      "Epoch 1302 / 10000 loss: 82.79859137535095\n",
      "MSE train 4.062905727893763 MSE test 7.328999773330523\n",
      "Epoch 1303 / 10000 loss: 82.7713508605957\n",
      "MSE train 4.0616599258131645 MSE test 7.32801145655521\n",
      "Epoch 1304 / 10000 loss: 82.7445878982544\n",
      "MSE train 4.060418171946187 MSE test 7.3270252470210515\n",
      "Epoch 1305 / 10000 loss: 82.71824765205383\n",
      "MSE train 4.059170421013766 MSE test 7.3260389026799295\n",
      "Epoch 1306 / 10000 loss: 82.6919937133789\n",
      "MSE train 4.05791310210335 MSE test 7.325051724674634\n",
      "Epoch 1307 / 10000 loss: 82.6656129360199\n",
      "MSE train 4.0566446760745825 MSE test 7.3240639792084865\n",
      "Epoch 1308 / 10000 loss: 82.6390221118927\n",
      "MSE train 4.055360336982647 MSE test 7.32307604879486\n",
      "Epoch 1309 / 10000 loss: 82.61219429969788\n",
      "MSE train 4.054049035643345 MSE test 7.322087793702345\n",
      "Epoch 1310 / 10000 loss: 82.58502125740051\n",
      "MSE train 4.052688667259736 MSE test 7.321098158796791\n",
      "Epoch 1311 / 10000 loss: 82.5572657585144\n",
      "MSE train 4.051200962478389 MSE test 7.320105546600092\n",
      "Epoch 1312 / 10000 loss: 82.52844524383545\n",
      "MSE train 4.049769196952404 MSE test 7.319110657070761\n",
      "Epoch 1313 / 10000 loss: 82.49687027931213\n",
      "MSE train 4.048485496486253 MSE test 7.318125230639025\n",
      "Epoch 1314 / 10000 loss: 82.4665310382843\n",
      "MSE train 4.047227366272948 MSE test 7.317146315879768\n",
      "Epoch 1315 / 10000 loss: 82.43938040733337\n",
      "MSE train 4.045982551875779 MSE test 7.316173385646277\n",
      "Epoch 1316 / 10000 loss: 82.4127790927887\n",
      "MSE train 4.044742194339619 MSE test 7.315205001730756\n",
      "Epoch 1317 / 10000 loss: 82.38645887374878\n",
      "MSE train 4.043500279886706 MSE test 7.3142401016013245\n",
      "Epoch 1318 / 10000 loss: 82.36022782325745\n",
      "MSE train 4.04224856137996 MSE test 7.313278351382756\n",
      "Epoch 1319 / 10000 loss: 82.33395743370056\n",
      "MSE train 4.040975318025357 MSE test 7.312319642032242\n",
      "Epoch 1320 / 10000 loss: 82.30747604370117\n",
      "MSE train 4.039696309864397 MSE test 7.311365026286852\n",
      "Epoch 1321 / 10000 loss: 82.28053450584412\n",
      "MSE train 4.038471571667901 MSE test 7.3104181262639445\n",
      "Epoch 1322 / 10000 loss: 82.25348377227783\n",
      "MSE train 4.037279377803678 MSE test 7.309479414320988\n",
      "Epoch 1323 / 10000 loss: 82.22762203216553\n",
      "MSE train 4.036091375829787 MSE test 7.3085461247715156\n",
      "Epoch 1324 / 10000 loss: 82.20246982574463\n",
      "MSE train 4.03489882452704 MSE test 7.307616828717145\n",
      "Epoch 1325 / 10000 loss: 82.17741250991821\n",
      "MSE train 4.033688614217944 MSE test 7.306690482936073\n",
      "Epoch 1326 / 10000 loss: 82.15224719047546\n",
      "MSE train 4.032450403715525 MSE test 7.305765932012105\n",
      "Epoch 1327 / 10000 loss: 82.12669491767883\n",
      "MSE train 4.031241151524166 MSE test 7.304843037303532\n",
      "Epoch 1328 / 10000 loss: 82.10052967071533\n",
      "MSE train 4.030082650342983 MSE test 7.303922587369415\n",
      "Epoch 1329 / 10000 loss: 82.07499408721924\n",
      "MSE train 4.028925977235547 MSE test 7.303001818746027\n",
      "Epoch 1330 / 10000 loss: 82.05054354667664\n",
      "MSE train 4.027750228375176 MSE test 7.302078625084265\n",
      "Epoch 1331 / 10000 loss: 82.0261287689209\n",
      "MSE train 4.026539158115853 MSE test 7.301150707026637\n",
      "Epoch 1332 / 10000 loss: 82.00129580497742\n",
      "MSE train 4.025277477914017 MSE test 7.300216222572987\n",
      "Epoch 1333 / 10000 loss: 81.97570371627808\n",
      "MSE train 4.023969529887332 MSE test 7.299273996643595\n",
      "Epoch 1334 / 10000 loss: 81.94902181625366\n",
      "MSE train 4.022655211407273 MSE test 7.298325048945864\n",
      "Epoch 1335 / 10000 loss: 81.92133784294128\n",
      "MSE train 4.021355917449623 MSE test 7.297369546052019\n",
      "Epoch 1336 / 10000 loss: 81.89351892471313\n",
      "MSE train 4.020059498275533 MSE test 7.296401691965915\n",
      "Epoch 1337 / 10000 loss: 81.86602663993835\n",
      "MSE train 4.018702855523784 MSE test 7.295402581497533\n",
      "Epoch 1338 / 10000 loss: 81.83860802650452\n",
      "MSE train 4.017229757602634 MSE test 7.294315253478985\n",
      "Epoch 1339 / 10000 loss: 81.80992794036865\n",
      "MSE train 4.016000325825687 MSE test 7.293371044857716\n",
      "Epoch 1340 / 10000 loss: 81.77880883216858\n",
      "MSE train 4.014801246659236 MSE test 7.292439228233126\n",
      "Epoch 1341 / 10000 loss: 81.75281047821045\n",
      "MSE train 4.013623210377633 MSE test 7.291515412365471\n",
      "Epoch 1342 / 10000 loss: 81.72745871543884\n",
      "MSE train 4.012436486684591 MSE test 7.290598055244674\n",
      "Epoch 1343 / 10000 loss: 81.70256686210632\n",
      "MSE train 4.011222545821116 MSE test 7.289685404127622\n",
      "Epoch 1344 / 10000 loss: 81.67748665809631\n",
      "MSE train 4.010068664647559 MSE test 7.288777846467857\n",
      "Epoch 1345 / 10000 loss: 81.65181756019592\n",
      "MSE train 4.008957158733604 MSE test 7.287876053020963\n",
      "Epoch 1346 / 10000 loss: 81.62745761871338\n",
      "MSE train 4.007858015021817 MSE test 7.286978464747084\n",
      "Epoch 1347 / 10000 loss: 81.6040244102478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 4.006778036910252 MSE test 7.286084881200512\n",
      "Epoch 1348 / 10000 loss: 81.58085942268372\n",
      "MSE train 4.005717152465421 MSE test 7.285194867240839\n",
      "Epoch 1349 / 10000 loss: 81.55811405181885\n",
      "MSE train 4.004667326033089 MSE test 7.2843069387154555\n",
      "Epoch 1350 / 10000 loss: 81.53577327728271\n",
      "MSE train 4.003617230697592 MSE test 7.283419710198534\n",
      "Epoch 1351 / 10000 loss: 81.51366329193115\n",
      "MSE train 4.002554061973489 MSE test 7.282531567293382\n",
      "Epoch 1352 / 10000 loss: 81.4915382862091\n",
      "MSE train 4.001469682489841 MSE test 7.2816413599035394\n",
      "Epoch 1353 / 10000 loss: 81.46911859512329\n",
      "MSE train 4.000380217097656 MSE test 7.280748214426947\n",
      "Epoch 1354 / 10000 loss: 81.44623517990112\n",
      "MSE train 3.999306267443601 MSE test 7.279852212456241\n",
      "Epoch 1355 / 10000 loss: 81.42323660850525\n",
      "MSE train 3.998227180874727 MSE test 7.278952058432666\n",
      "Epoch 1356 / 10000 loss: 81.40057349205017\n",
      "MSE train 3.9971206782095843 MSE test 7.27804609121978\n",
      "Epoch 1357 / 10000 loss: 81.37779974937439\n",
      "MSE train 3.9959918043955134 MSE test 7.277133450207875\n",
      "Epoch 1358 / 10000 loss: 81.35443091392517\n",
      "MSE train 3.994871661287904 MSE test 7.276214649786164\n",
      "Epoch 1359 / 10000 loss: 81.3305811882019\n",
      "MSE train 3.993758804343065 MSE test 7.275289820731323\n",
      "Epoch 1360 / 10000 loss: 81.30692076683044\n",
      "MSE train 3.9926274592073314 MSE test 7.274356769166191\n",
      "Epoch 1361 / 10000 loss: 81.28342199325562\n",
      "MSE train 3.9914598225832316 MSE test 7.273412962148581\n",
      "Epoch 1362 / 10000 loss: 81.2595283985138\n",
      "MSE train 3.99025126545764 MSE test 7.272455428641007\n",
      "Epoch 1363 / 10000 loss: 81.2348518371582\n",
      "MSE train 3.9890144067510773 MSE test 7.271480242612341\n",
      "Epoch 1364 / 10000 loss: 81.20929455757141\n",
      "MSE train 3.987746910627833 MSE test 7.270481180383152\n",
      "Epoch 1365 / 10000 loss: 81.18312644958496\n",
      "MSE train 3.986408789502268 MSE test 7.269448427566915\n",
      "Epoch 1366 / 10000 loss: 81.15629982948303\n",
      "MSE train 3.9849974776735624 MSE test 7.268378606194614\n",
      "Epoch 1367 / 10000 loss: 81.12795066833496\n",
      "MSE train 3.9836392612019673 MSE test 7.267330111169664\n",
      "Epoch 1368 / 10000 loss: 81.09802961349487\n",
      "MSE train 3.98232151119583 MSE test 7.266325194324252\n",
      "Epoch 1369 / 10000 loss: 81.06925988197327\n",
      "MSE train 3.98104919845723 MSE test 7.265336738086705\n",
      "Epoch 1370 / 10000 loss: 81.04135704040527\n",
      "MSE train 3.9798132363501506 MSE test 7.264359211229968\n",
      "Epoch 1371 / 10000 loss: 81.01443910598755\n",
      "MSE train 3.9785924410523625 MSE test 7.263388902386379\n",
      "Epoch 1372 / 10000 loss: 80.98830986022949\n",
      "MSE train 3.9773801976074763 MSE test 7.262423541225175\n",
      "Epoch 1373 / 10000 loss: 80.96251273155212\n",
      "MSE train 3.976174800731824 MSE test 7.2614619973409\n",
      "Epoch 1374 / 10000 loss: 80.93690514564514\n",
      "MSE train 3.974975527642368 MSE test 7.260503207767732\n",
      "Epoch 1375 / 10000 loss: 80.91144943237305\n",
      "MSE train 3.973781205072837 MSE test 7.259546256772476\n",
      "Epoch 1376 / 10000 loss: 80.88612771034241\n",
      "MSE train 3.972589907761103 MSE test 7.258590305550206\n",
      "Epoch 1377 / 10000 loss: 80.86091899871826\n",
      "MSE train 3.971399177849332 MSE test 7.257634793372804\n",
      "Epoch 1378 / 10000 loss: 80.835777759552\n",
      "MSE train 3.970206242830849 MSE test 7.256679440712552\n",
      "Epoch 1379 / 10000 loss: 80.8106472492218\n",
      "MSE train 3.969008223421919 MSE test 7.255723978366244\n",
      "Epoch 1380 / 10000 loss: 80.785475730896\n",
      "MSE train 3.967802516802355 MSE test 7.254768638888452\n",
      "Epoch 1381 / 10000 loss: 80.76019215583801\n",
      "MSE train 3.966587097338651 MSE test 7.253813439200391\n",
      "Epoch 1382 / 10000 loss: 80.73474740982056\n",
      "MSE train 3.965361847694537 MSE test 7.252858630121289\n",
      "Epoch 1383 / 10000 loss: 80.70909023284912\n",
      "MSE train 3.96413074838101 MSE test 7.2519042953638\n",
      "Epoch 1384 / 10000 loss: 80.68322968482971\n",
      "MSE train 3.962898412688524 MSE test 7.250949673784619\n",
      "Epoch 1385 / 10000 loss: 80.65725302696228\n",
      "MSE train 3.96166073438562 MSE test 7.249992773885605\n",
      "Epoch 1386 / 10000 loss: 80.63125658035278\n",
      "MSE train 3.960396184574499 MSE test 7.249029081000295\n",
      "Epoch 1387 / 10000 loss: 80.60513925552368\n",
      "MSE train 3.959099500490171 MSE test 7.248053361635936\n",
      "Epoch 1388 / 10000 loss: 80.57842564582825\n",
      "MSE train 3.9579552846183566 MSE test 7.247100712076611\n",
      "Epoch 1389 / 10000 loss: 80.55102777481079\n",
      "MSE train 3.956866504202655 MSE test 7.246174092823106\n",
      "Epoch 1390 / 10000 loss: 80.52693200111389\n",
      "MSE train 3.955776116288587 MSE test 7.245251927377803\n",
      "Epoch 1391 / 10000 loss: 80.50401616096497\n",
      "MSE train 3.954651368411567 MSE test 7.244329188053902\n",
      "Epoch 1392 / 10000 loss: 80.48105430603027\n",
      "MSE train 3.953431753774838 MSE test 7.243401404444746\n",
      "Epoch 1393 / 10000 loss: 80.4573450088501\n",
      "MSE train 3.9522077390617683 MSE test 7.24246804697896\n",
      "Epoch 1394 / 10000 loss: 80.43157649040222\n",
      "MSE train 3.951078368899104 MSE test 7.2415429585404905\n",
      "Epoch 1395 / 10000 loss: 80.40571713447571\n",
      "MSE train 3.9499376054971753 MSE test 7.240615784133447\n",
      "Epoch 1396 / 10000 loss: 80.38189649581909\n",
      "MSE train 3.9487783833147097 MSE test 7.239684694054775\n",
      "Epoch 1397 / 10000 loss: 80.3578290939331\n",
      "MSE train 3.9475975259269016 MSE test 7.238749105341822\n",
      "Epoch 1398 / 10000 loss: 80.33335781097412\n",
      "MSE train 3.9463955413466407 MSE test 7.237809685863885\n",
      "Epoch 1399 / 10000 loss: 80.30841851234436\n",
      "MSE train 3.9451816037387375 MSE test 7.23686891358159\n",
      "Epoch 1400 / 10000 loss: 80.28302121162415\n",
      "MSE train 3.943970316973078 MSE test 7.235931175074642\n",
      "Epoch 1401 / 10000 loss: 80.25736689567566\n",
      "MSE train 3.9427684467880875 MSE test 7.2349994390115535\n",
      "Epoch 1402 / 10000 loss: 80.23177289962769\n",
      "MSE train 3.9415701126002416 MSE test 7.234073338508459\n",
      "Epoch 1403 / 10000 loss: 80.20638155937195\n",
      "MSE train 3.94036644537479 MSE test 7.233151038903093\n",
      "Epoch 1404 / 10000 loss: 80.18106508255005\n",
      "MSE train 3.939166259204479 MSE test 7.232231264996046\n",
      "Epoch 1405 / 10000 loss: 80.1556351184845\n",
      "MSE train 3.9380000477806503 MSE test 7.231314579526666\n",
      "Epoch 1406 / 10000 loss: 80.13027930259705\n",
      "MSE train 3.9368726544886883 MSE test 7.2304014453785515\n",
      "Epoch 1407 / 10000 loss: 80.10565519332886\n",
      "MSE train 3.935766878335395 MSE test 7.229490782049121\n",
      "Epoch 1408 / 10000 loss: 80.0818657875061\n",
      "MSE train 3.934671524913496 MSE test 7.22858158519509\n",
      "Epoch 1409 / 10000 loss: 80.05854058265686\n",
      "MSE train 3.93358201585165 MSE test 7.227673258379385\n",
      "Epoch 1410 / 10000 loss: 80.03542971611023\n",
      "MSE train 3.9324986273154625 MSE test 7.226765794838482\n",
      "Epoch 1411 / 10000 loss: 80.01243352890015\n",
      "MSE train 3.931423895586035 MSE test 7.225859511596825\n",
      "Epoch 1412 / 10000 loss: 79.98955726623535\n",
      "MSE train 3.930358663851905 MSE test 7.224954905925132\n",
      "Epoch 1413 / 10000 loss: 79.96686053276062\n",
      "MSE train 3.9293006686257193 MSE test 7.224051997114002\n",
      "Epoch 1414 / 10000 loss: 79.94435596466064\n",
      "MSE train 3.928246598518527 MSE test 7.22315060150357\n",
      "Epoch 1415 / 10000 loss: 79.92200136184692\n",
      "MSE train 3.927194338733096 MSE test 7.222250676673898\n",
      "Epoch 1416 / 10000 loss: 79.8997254371643\n",
      "MSE train 3.926144803181697 MSE test 7.2213527113553475\n",
      "Epoch 1417 / 10000 loss: 79.87748098373413\n",
      "MSE train 3.9251027142199795 MSE test 7.2204577480990295\n",
      "Epoch 1418 / 10000 loss: 79.85528922080994\n",
      "MSE train 3.9240741177026806 MSE test 7.219566807351971\n",
      "Epoch 1419 / 10000 loss: 79.8332507610321\n",
      "MSE train 3.9230611829805357 MSE test 7.218680494000682\n",
      "Epoch 1420 / 10000 loss: 79.81150221824646\n",
      "MSE train 3.922060784919589 MSE test 7.2177988917433185\n",
      "Epoch 1421 / 10000 loss: 79.79008269309998\n",
      "MSE train 3.921067488892162 MSE test 7.2169211649313025\n",
      "Epoch 1422 / 10000 loss: 79.76893281936646\n",
      "MSE train 3.9200759602476762 MSE test 7.216046384829072\n",
      "Epoch 1423 / 10000 loss: 79.74793219566345\n",
      "MSE train 3.919081545621162 MSE test 7.215173539196151\n",
      "Epoch 1424 / 10000 loss: 79.72696900367737\n",
      "MSE train 3.918080036684774 MSE test 7.214301587322573\n",
      "Epoch 1425 / 10000 loss: 79.7059383392334\n",
      "MSE train 3.917067490679617 MSE test 7.213429654262426\n",
      "Epoch 1426 / 10000 loss: 79.68475246429443\n",
      "MSE train 3.916040040190239 MSE test 7.212557146771859\n",
      "Epoch 1427 / 10000 loss: 79.663321018219\n",
      "MSE train 3.914993766359896 MSE test 7.21168339183647\n",
      "Epoch 1428 / 10000 loss: 79.64155888557434\n",
      "MSE train 3.913924276194346 MSE test 7.210808052981077\n",
      "Epoch 1429 / 10000 loss: 79.61938619613647\n",
      "MSE train 3.9128260140498905 MSE test 7.209930621176595\n",
      "Epoch 1430 / 10000 loss: 79.59670209884644\n",
      "MSE train 3.91169136192936 MSE test 7.209051033199503\n",
      "Epoch 1431 / 10000 loss: 79.57337379455566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.91051161070581 MSE test 7.208168705778406\n",
      "Epoch 1432 / 10000 loss: 79.54923605918884\n",
      "MSE train 3.9092854576037723 MSE test 7.2072831804249695\n",
      "Epoch 1433 / 10000 loss: 79.52410459518433\n",
      "MSE train 3.9080329510802767 MSE test 7.206394050031229\n",
      "Epoch 1434 / 10000 loss: 79.49800109863281\n",
      "MSE train 3.9067834979177882 MSE test 7.205501205104197\n",
      "Epoch 1435 / 10000 loss: 79.47141671180725\n",
      "MSE train 3.9055567534348024 MSE test 7.204605372815308\n",
      "Epoch 1436 / 10000 loss: 79.44495129585266\n",
      "MSE train 3.9043612413491555 MSE test 7.203707029183977\n",
      "Epoch 1437 / 10000 loss: 79.41896224021912\n",
      "MSE train 3.9031859610613506 MSE test 7.202805695242482\n",
      "Epoch 1438 / 10000 loss: 79.39362382888794\n",
      "MSE train 3.9020119405753513 MSE test 7.201899646466532\n",
      "Epoch 1439 / 10000 loss: 79.36870336532593\n",
      "MSE train 3.9008359964098855 MSE test 7.200988916565525\n",
      "Epoch 1440 / 10000 loss: 79.34379839897156\n",
      "MSE train 3.8996911153270455 MSE test 7.200079258790368\n",
      "Epoch 1441 / 10000 loss: 79.31884336471558\n",
      "MSE train 3.898588391885068 MSE test 7.199177291876464\n",
      "Epoch 1442 / 10000 loss: 79.29455423355103\n",
      "MSE train 3.897503285971552 MSE test 7.198280030195872\n",
      "Epoch 1443 / 10000 loss: 79.27117967605591\n",
      "MSE train 3.8964186135608165 MSE test 7.197383278314948\n",
      "Epoch 1444 / 10000 loss: 79.2481906414032\n",
      "MSE train 3.8953161585262994 MSE test 7.19648405184556\n",
      "Epoch 1445 / 10000 loss: 79.22521448135376\n",
      "MSE train 3.8941428261402584 MSE test 7.1955780543558605\n",
      "Epoch 1446 / 10000 loss: 79.20185804367065\n",
      "MSE train 3.8928445841009425 MSE test 7.194657279406389\n",
      "Epoch 1447 / 10000 loss: 79.1769688129425\n",
      "MSE train 3.891679531961827 MSE test 7.193749682011669\n",
      "Epoch 1448 / 10000 loss: 79.14937329292297\n",
      "MSE train 3.890464464195682 MSE test 7.192843008099804\n",
      "Epoch 1449 / 10000 loss: 79.12468194961548\n",
      "MSE train 3.88922553191867 MSE test 7.191932050721719\n",
      "Epoch 1450 / 10000 loss: 79.09891200065613\n",
      "MSE train 3.888022044469332 MSE test 7.19102176759145\n",
      "Epoch 1451 / 10000 loss: 79.0726330280304\n",
      "MSE train 3.8868454654102593 MSE test 7.190113534176736\n",
      "Epoch 1452 / 10000 loss: 79.04713010787964\n",
      "MSE train 3.8856963803958395 MSE test 7.1892090943063955\n",
      "Epoch 1453 / 10000 loss: 79.02220916748047\n",
      "MSE train 3.8845690546747873 MSE test 7.188309372564505\n",
      "Epoch 1454 / 10000 loss: 78.9978756904602\n",
      "MSE train 3.8834536062626532 MSE test 7.187413196033115\n",
      "Epoch 1455 / 10000 loss: 78.97400665283203\n",
      "MSE train 3.882347471800019 MSE test 7.186519520533026\n",
      "Epoch 1456 / 10000 loss: 78.9503824710846\n",
      "MSE train 3.881253711944649 MSE test 7.185627943187509\n",
      "Epoch 1457 / 10000 loss: 78.9269540309906\n",
      "MSE train 3.8801749585302594 MSE test 7.184738131546615\n",
      "Epoch 1458 / 10000 loss: 78.90378665924072\n",
      "MSE train 3.879110212760372 MSE test 7.183849448375557\n",
      "Epoch 1459 / 10000 loss: 78.88094139099121\n",
      "MSE train 3.8780571505448265 MSE test 7.1829610794056595\n",
      "Epoch 1460 / 10000 loss: 78.85839486122131\n",
      "MSE train 3.877013774165338 MSE test 7.18207225419473\n",
      "Epoch 1461 / 10000 loss: 78.836097240448\n",
      "MSE train 3.8759778452230087 MSE test 7.181182151300688\n",
      "Epoch 1462 / 10000 loss: 78.8140058517456\n",
      "MSE train 3.874945900910102 MSE test 7.180289993323292\n",
      "Epoch 1463 / 10000 loss: 78.79207634925842\n",
      "MSE train 3.873912254731088 MSE test 7.179394494278922\n",
      "Epoch 1464 / 10000 loss: 78.77022647857666\n",
      "MSE train 3.872868301556594 MSE test 7.178494488776014\n",
      "Epoch 1465 / 10000 loss: 78.74834275245667\n",
      "MSE train 3.8718035851638204 MSE test 7.17758827338697\n",
      "Epoch 1466 / 10000 loss: 78.72623300552368\n",
      "MSE train 3.8707142759800965 MSE test 7.176675743970365\n",
      "Epoch 1467 / 10000 loss: 78.70367860794067\n",
      "MSE train 3.8696126866222222 MSE test 7.175760774917235\n",
      "Epoch 1468 / 10000 loss: 78.68058705329895\n",
      "MSE train 3.868502604330746 MSE test 7.174849252552174\n",
      "Epoch 1469 / 10000 loss: 78.65723037719727\n",
      "MSE train 3.8673705639031772 MSE test 7.173940697473653\n",
      "Epoch 1470 / 10000 loss: 78.63368916511536\n",
      "MSE train 3.8662357775205205 MSE test 7.173031976027093\n",
      "Epoch 1471 / 10000 loss: 78.60967016220093\n",
      "MSE train 3.865108128993888 MSE test 7.172120819488386\n",
      "Epoch 1472 / 10000 loss: 78.5855975151062\n",
      "MSE train 3.863958728811717 MSE test 7.171204311730139\n",
      "Epoch 1473 / 10000 loss: 78.5616807937622\n",
      "MSE train 3.862790585154195 MSE test 7.1702817869655675\n",
      "Epoch 1474 / 10000 loss: 78.53730726242065\n",
      "MSE train 3.8616158101917324 MSE test 7.169355613284241\n",
      "Epoch 1475 / 10000 loss: 78.51254057884216\n",
      "MSE train 3.8604884322630415 MSE test 7.1684412699003435\n",
      "Epoch 1476 / 10000 loss: 78.48762798309326\n",
      "MSE train 3.8593837772214443 MSE test 7.167541723824941\n",
      "Epoch 1477 / 10000 loss: 78.46372938156128\n",
      "MSE train 3.8582989218378447 MSE test 7.166646639597559\n",
      "Epoch 1478 / 10000 loss: 78.4403121471405\n",
      "MSE train 3.8572229548118044 MSE test 7.165752991081499\n",
      "Epoch 1479 / 10000 loss: 78.417320728302\n",
      "MSE train 3.8561377692744006 MSE test 7.164858121907622\n",
      "Epoch 1480 / 10000 loss: 78.3945164680481\n",
      "MSE train 3.8550333064097946 MSE test 7.163959249870123\n",
      "Epoch 1481 / 10000 loss: 78.37151622772217\n",
      "MSE train 3.853905488177413 MSE test 7.163054638463436\n",
      "Epoch 1482 / 10000 loss: 78.34809637069702\n",
      "MSE train 3.852785052819757 MSE test 7.1621473947377305\n",
      "Epoch 1483 / 10000 loss: 78.32417273521423\n",
      "MSE train 3.851706744161985 MSE test 7.161247831286842\n",
      "Epoch 1484 / 10000 loss: 78.30040717124939\n",
      "MSE train 3.8506463721474176 MSE test 7.160356037366335\n",
      "Epoch 1485 / 10000 loss: 78.27755808830261\n",
      "MSE train 3.849586504937004 MSE test 7.159467667163679\n",
      "Epoch 1486 / 10000 loss: 78.25509834289551\n",
      "MSE train 3.848521870006841 MSE test 7.158580970739287\n",
      "Epoch 1487 / 10000 loss: 78.23265600204468\n",
      "MSE train 3.8474501584862186 MSE test 7.15769540732874\n",
      "Epoch 1488 / 10000 loss: 78.21011424064636\n",
      "MSE train 3.8463702914252935 MSE test 7.1568108381570195\n",
      "Epoch 1489 / 10000 loss: 78.18742418289185\n",
      "MSE train 3.8452838997804606 MSE test 7.155927104546577\n",
      "Epoch 1490 / 10000 loss: 78.164559841156\n",
      "MSE train 3.844195982725535 MSE test 7.155043572241287\n",
      "Epoch 1491 / 10000 loss: 78.1415638923645\n",
      "MSE train 3.843108230363924 MSE test 7.154158879604602\n",
      "Epoch 1492 / 10000 loss: 78.11854457855225\n",
      "MSE train 3.842009276644081 MSE test 7.153270454080321\n",
      "Epoch 1493 / 10000 loss: 78.09553718566895\n",
      "MSE train 3.8408665110158573 MSE test 7.15237271817527\n",
      "Epoch 1494 / 10000 loss: 78.07230472564697\n",
      "MSE train 3.8395886346830177 MSE test 7.15145552598343\n",
      "Epoch 1495 / 10000 loss: 78.04814410209656\n",
      "MSE train 3.8382777342382073 MSE test 7.15051083149518\n",
      "Epoch 1496 / 10000 loss: 78.02107810974121\n",
      "MSE train 3.837117813842176 MSE test 7.149616718552727\n",
      "Epoch 1497 / 10000 loss: 77.99331402778625\n",
      "MSE train 3.836000758123661 MSE test 7.148739555526444\n",
      "Epoch 1498 / 10000 loss: 77.96882128715515\n",
      "MSE train 3.834911208167228 MSE test 7.147882271968815\n",
      "Epoch 1499 / 10000 loss: 77.94522857666016\n",
      "MSE train 3.8338326347647156 MSE test 7.14703754410022\n",
      "Epoch 1500 / 10000 loss: 77.9221887588501\n",
      "MSE train 3.832781823032621 MSE test 7.146200937620344\n",
      "Epoch 1501 / 10000 loss: 77.8993604183197\n",
      "MSE train 3.831776518631515 MSE test 7.14537151144544\n",
      "Epoch 1502 / 10000 loss: 77.87711977958679\n",
      "MSE train 3.8308032799819975 MSE test 7.144547717956055\n",
      "Epoch 1503 / 10000 loss: 77.85585403442383\n",
      "MSE train 3.829851412427745 MSE test 7.143728688396038\n",
      "Epoch 1504 / 10000 loss: 77.83527851104736\n",
      "MSE train 3.828923786580163 MSE test 7.142915210988278\n",
      "Epoch 1505 / 10000 loss: 77.81515717506409\n",
      "MSE train 3.8280145476810508 MSE test 7.142107932847278\n",
      "Epoch 1506 / 10000 loss: 77.79556012153625\n",
      "MSE train 3.8271081628246484 MSE test 7.141305439402233\n",
      "Epoch 1507 / 10000 loss: 77.77634978294373\n",
      "MSE train 3.826196411353968 MSE test 7.140505944671811\n",
      "Epoch 1508 / 10000 loss: 77.75720167160034\n",
      "MSE train 3.825286975624938 MSE test 7.139708950269633\n",
      "Epoch 1509 / 10000 loss: 77.73793053627014\n",
      "MSE train 3.824393413580735 MSE test 7.138914771988157\n",
      "Epoch 1510 / 10000 loss: 77.71871399879456\n",
      "MSE train 3.8235162932629327 MSE test 7.138123687919826\n",
      "Epoch 1511 / 10000 loss: 77.69983243942261\n",
      "MSE train 3.822648821246064 MSE test 7.137335247889233\n",
      "Epoch 1512 / 10000 loss: 77.68131184577942\n",
      "MSE train 3.821787003628915 MSE test 7.136548668535239\n",
      "Epoch 1513 / 10000 loss: 77.66299867630005\n",
      "MSE train 3.8209302432321355 MSE test 7.13576367015872\n",
      "Epoch 1514 / 10000 loss: 77.64480781555176\n",
      "MSE train 3.820079705807933 MSE test 7.134980306957033\n",
      "Epoch 1515 / 10000 loss: 77.62672424316406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.819237145610095 MSE test 7.134198720811147\n",
      "Epoch 1516 / 10000 loss: 77.60877513885498\n",
      "MSE train 3.818404140227351 MSE test 7.133418987685389\n",
      "Epoch 1517 / 10000 loss: 77.59099650382996\n",
      "MSE train 3.817581971205751 MSE test 7.132641386607574\n",
      "Epoch 1518 / 10000 loss: 77.57342219352722\n",
      "MSE train 3.816772027211876 MSE test 7.131865916275101\n",
      "Epoch 1519 / 10000 loss: 77.55607914924622\n",
      "MSE train 3.815975555557648 MSE test 7.131092682327096\n",
      "Epoch 1520 / 10000 loss: 77.53899550437927\n",
      "MSE train 3.815192534114472 MSE test 7.130321430454595\n",
      "Epoch 1521 / 10000 loss: 77.52220344543457\n",
      "MSE train 3.814420665873421 MSE test 7.129551539418538\n",
      "Epoch 1522 / 10000 loss: 77.50569987297058\n",
      "MSE train 3.8136559445818174 MSE test 7.128782144633205\n",
      "Epoch 1523 / 10000 loss: 77.48943161964417\n",
      "MSE train 3.812893695654458 MSE test 7.128011771030349\n",
      "Epoch 1524 / 10000 loss: 77.47332167625427\n",
      "MSE train 3.812129092688124 MSE test 7.127239005141762\n",
      "Epoch 1525 / 10000 loss: 77.45726275444031\n",
      "MSE train 3.8113568099562 MSE test 7.1264622684009264\n",
      "Epoch 1526 / 10000 loss: 77.44115328788757\n",
      "MSE train 3.810570272952461 MSE test 7.125679697973245\n",
      "Epoch 1527 / 10000 loss: 77.42487716674805\n",
      "MSE train 3.8097601618279415 MSE test 7.124889172406108\n",
      "Epoch 1528 / 10000 loss: 77.40829491615295\n",
      "MSE train 3.808911888342307 MSE test 7.1240880192087435\n",
      "Epoch 1529 / 10000 loss: 77.39120626449585\n",
      "MSE train 3.808001764524741 MSE test 7.123272967074451\n",
      "Epoch 1530 / 10000 loss: 77.37329173088074\n",
      "MSE train 3.8070002473310147 MSE test 7.12244011607123\n",
      "Epoch 1531 / 10000 loss: 77.35404300689697\n",
      "MSE train 3.80593471364717 MSE test 7.121589940365876\n",
      "Epoch 1532 / 10000 loss: 77.33283019065857\n",
      "MSE train 3.8049243908194184 MSE test 7.120737564741388\n",
      "Epoch 1533 / 10000 loss: 77.31028294563293\n",
      "MSE train 3.803959515160338 MSE test 7.119889360375457\n",
      "Epoch 1534 / 10000 loss: 77.28892827033997\n",
      "MSE train 3.8029917168237857 MSE test 7.119037246889924\n",
      "Epoch 1535 / 10000 loss: 77.26851201057434\n",
      "MSE train 3.8019893603153183 MSE test 7.118174706054437\n",
      "Epoch 1536 / 10000 loss: 77.24801468849182\n",
      "MSE train 3.800972493218997 MSE test 7.117302310504547\n",
      "Epoch 1537 / 10000 loss: 77.22675442695618\n",
      "MSE train 3.8000051546284617 MSE test 7.116434470291414\n",
      "Epoch 1538 / 10000 loss: 77.20516920089722\n",
      "MSE train 3.7990712458851803 MSE test 7.11557792535415\n",
      "Epoch 1539 / 10000 loss: 77.18465542793274\n",
      "MSE train 3.7981330098882924 MSE test 7.114726300673226\n",
      "Epoch 1540 / 10000 loss: 77.16487789154053\n",
      "MSE train 3.79717234190803 MSE test 7.113874236133899\n",
      "Epoch 1541 / 10000 loss: 77.14500689506531\n",
      "MSE train 3.796185673632783 MSE test 7.113020228304267\n",
      "Epoch 1542 / 10000 loss: 77.12465333938599\n",
      "MSE train 3.7951789928416755 MSE test 7.1121652440094705\n",
      "Epoch 1543 / 10000 loss: 77.10373783111572\n",
      "MSE train 3.794158520793549 MSE test 7.111311280164069\n",
      "Epoch 1544 / 10000 loss: 77.08239102363586\n",
      "MSE train 3.79312528886159 MSE test 7.110459045662475\n",
      "Epoch 1545 / 10000 loss: 77.06074523925781\n",
      "MSE train 3.7920896297754028 MSE test 7.109607784210836\n",
      "Epoch 1546 / 10000 loss: 77.03882932662964\n",
      "MSE train 3.7910461925523045 MSE test 7.108755402683375\n",
      "Epoch 1547 / 10000 loss: 77.01686096191406\n",
      "MSE train 3.789973491355126 MSE test 7.107899040171003\n",
      "Epoch 1548 / 10000 loss: 76.99472904205322\n",
      "MSE train 3.7889747626193797 MSE test 7.107051517824964\n",
      "Epoch 1549 / 10000 loss: 76.97197127342224\n",
      "MSE train 3.7880411712786852 MSE test 7.106223564029395\n",
      "Epoch 1550 / 10000 loss: 76.95081758499146\n",
      "MSE train 3.7871198637873 MSE test 7.105402226856153\n",
      "Epoch 1551 / 10000 loss: 76.93106389045715\n",
      "MSE train 3.786201491386918 MSE test 7.104583340003424\n",
      "Epoch 1552 / 10000 loss: 76.91157674789429\n",
      "MSE train 3.7852825563188017 MSE test 7.103764942793816\n",
      "Epoch 1553 / 10000 loss: 76.89215040206909\n",
      "MSE train 3.784360833846469 MSE test 7.102945565308912\n",
      "Epoch 1554 / 10000 loss: 76.8727126121521\n",
      "MSE train 3.7834342759648187 MSE test 7.102124005343995\n",
      "Epoch 1555 / 10000 loss: 76.85321879386902\n",
      "MSE train 3.782500466878782 MSE test 7.101299146641897\n",
      "Epoch 1556 / 10000 loss: 76.83362150192261\n",
      "MSE train 3.7815567605597216 MSE test 7.1004697068925555\n",
      "Epoch 1557 / 10000 loss: 76.81387138366699\n",
      "MSE train 3.7806007604545653 MSE test 7.099634499207874\n",
      "Epoch 1558 / 10000 loss: 76.7939100265503\n",
      "MSE train 3.779629530767844 MSE test 7.098792353042348\n",
      "Epoch 1559 / 10000 loss: 76.77368187904358\n",
      "MSE train 3.7786329374665515 MSE test 7.097941162799295\n",
      "Epoch 1560 / 10000 loss: 76.75312757492065\n",
      "MSE train 3.777575410006172 MSE test 7.097075877067122\n",
      "Epoch 1561 / 10000 loss: 76.73202466964722\n",
      "MSE train 3.7763888212681773 MSE test 7.096186829960742\n",
      "Epoch 1562 / 10000 loss: 76.70959734916687\n",
      "MSE train 3.7752090428578433 MSE test 7.095279949145834\n",
      "Epoch 1563 / 10000 loss: 76.68437004089355\n",
      "MSE train 3.7742772250844183 MSE test 7.094460625782665\n",
      "Epoch 1564 / 10000 loss: 76.65926575660706\n",
      "MSE train 3.773401119409936 MSE test 7.093655346468702\n",
      "Epoch 1565 / 10000 loss: 76.6395525932312\n",
      "MSE train 3.772546382655391 MSE test 7.0928577464947296\n",
      "Epoch 1566 / 10000 loss: 76.62104797363281\n",
      "MSE train 3.7716981988900735 MSE test 7.092064710791996\n",
      "Epoch 1567 / 10000 loss: 76.60300517082214\n",
      "MSE train 3.770849638298039 MSE test 7.091273872136741\n",
      "Epoch 1568 / 10000 loss: 76.58509945869446\n",
      "MSE train 3.7699966706813575 MSE test 7.090483437623364\n",
      "Epoch 1569 / 10000 loss: 76.56718707084656\n",
      "MSE train 3.7691370993939337 MSE test 7.08969202794204\n",
      "Epoch 1570 / 10000 loss: 76.54917883872986\n",
      "MSE train 3.7682698762170523 MSE test 7.088898631014072\n",
      "Epoch 1571 / 10000 loss: 76.53102540969849\n",
      "MSE train 3.7673945781791693 MSE test 7.088102883103965\n",
      "Epoch 1572 / 10000 loss: 76.51270484924316\n",
      "MSE train 3.766511449929596 MSE test 7.087304710090264\n",
      "Epoch 1573 / 10000 loss: 76.49420928955078\n",
      "MSE train 3.765621020159624 MSE test 7.086504583678467\n",
      "Epoch 1574 / 10000 loss: 76.47554469108582\n",
      "MSE train 3.7647227221257986 MSE test 7.085702935046109\n",
      "Epoch 1575 / 10000 loss: 76.45672106742859\n",
      "MSE train 3.763813525414413 MSE test 7.084899714501353\n",
      "Epoch 1576 / 10000 loss: 76.43772792816162\n",
      "MSE train 3.762887459558424 MSE test 7.084094390970299\n",
      "Epoch 1577 / 10000 loss: 76.41850185394287\n",
      "MSE train 3.7619363775102164 MSE test 7.083285934390382\n",
      "Epoch 1578 / 10000 loss: 76.3989109992981\n",
      "MSE train 3.7609549026604783 MSE test 7.082473904623707\n",
      "Epoch 1579 / 10000 loss: 76.3787841796875\n",
      "MSE train 3.75995406843798 MSE test 7.081660257704171\n",
      "Epoch 1580 / 10000 loss: 76.3580002784729\n",
      "MSE train 3.758957334891815 MSE test 7.08085031129782\n",
      "Epoch 1581 / 10000 loss: 76.33680558204651\n",
      "MSE train 3.757962595986336 MSE test 7.080047364217798\n",
      "Epoch 1582 / 10000 loss: 76.31570267677307\n",
      "MSE train 3.7569498491688376 MSE test 7.079250290384128\n",
      "Epoch 1583 / 10000 loss: 76.29465126991272\n",
      "MSE train 3.7559170697305784 MSE test 7.078457639310593\n",
      "Epoch 1584 / 10000 loss: 76.27321457862854\n",
      "MSE train 3.7549042985829115 MSE test 7.0776691557151095\n",
      "Epoch 1585 / 10000 loss: 76.2513518333435\n",
      "MSE train 3.753931160036234 MSE test 7.076884835898459\n",
      "Epoch 1586 / 10000 loss: 76.22993016242981\n",
      "MSE train 3.752975332492549 MSE test 7.076103171302599\n",
      "Epoch 1587 / 10000 loss: 76.20938086509705\n",
      "MSE train 3.752020761052115 MSE test 7.075321687027301\n",
      "Epoch 1588 / 10000 loss: 76.18922066688538\n",
      "MSE train 3.7510487059719817 MSE test 7.074535964644938\n",
      "Epoch 1589 / 10000 loss: 76.16910195350647\n",
      "MSE train 3.750009478975536 MSE test 7.073737294903395\n",
      "Epoch 1590 / 10000 loss: 76.14861512184143\n",
      "MSE train 3.748860159820207 MSE test 7.072912053506671\n",
      "Epoch 1591 / 10000 loss: 76.1266839504242\n",
      "MSE train 3.7478318838242535 MSE test 7.072112758786764\n",
      "Epoch 1592 / 10000 loss: 76.10236716270447\n",
      "MSE train 3.746822001423214 MSE test 7.071347535198422\n",
      "Epoch 1593 / 10000 loss: 76.08067870140076\n",
      "MSE train 3.7457917325016323 MSE test 7.070587559691641\n",
      "Epoch 1594 / 10000 loss: 76.05939149856567\n",
      "MSE train 3.7447642886717563 MSE test 7.069832018389677\n",
      "Epoch 1595 / 10000 loss: 76.03766775131226\n",
      "MSE train 3.7437775013436823 MSE test 7.06908356787399\n",
      "Epoch 1596 / 10000 loss: 76.01600790023804\n",
      "MSE train 3.7428423893192706 MSE test 7.068344168779597\n",
      "Epoch 1597 / 10000 loss: 75.9952244758606\n",
      "MSE train 3.7419408607743434 MSE test 7.0676127628177845\n",
      "Epoch 1598 / 10000 loss: 75.97554516792297\n",
      "MSE train 3.7410562492276647 MSE test 7.0668874068587835\n",
      "Epoch 1599 / 10000 loss: 75.95657110214233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.740178903779355 MSE test 7.066166359218141\n",
      "Epoch 1600 / 10000 loss: 75.93794345855713\n",
      "MSE train 3.7393020187588597 MSE test 7.06544862381737\n",
      "Epoch 1601 / 10000 loss: 75.91946220397949\n",
      "MSE train 3.7384186217124173 MSE test 7.06473286244379\n",
      "Epoch 1602 / 10000 loss: 75.90097498893738\n",
      "MSE train 3.7375202678578447 MSE test 7.064018170410808\n",
      "Epoch 1603 / 10000 loss: 75.88233613967896\n",
      "MSE train 3.7366014378100543 MSE test 7.063303245953735\n",
      "Epoch 1604 / 10000 loss: 75.86336207389832\n",
      "MSE train 3.7356675225292397 MSE test 7.062587689541575\n",
      "Epoch 1605 / 10000 loss: 75.8439359664917\n",
      "MSE train 3.7347121199998576 MSE test 7.061871264072504\n",
      "Epoch 1606 / 10000 loss: 75.82417297363281\n",
      "MSE train 3.733703985424858 MSE test 7.061152643057583\n",
      "Epoch 1607 / 10000 loss: 75.80393481254578\n",
      "MSE train 3.732648754556547 MSE test 7.060434600311752\n",
      "Epoch 1608 / 10000 loss: 75.78255820274353\n",
      "MSE train 3.73157119362971 MSE test 7.059723537173707\n",
      "Epoch 1609 / 10000 loss: 75.76016283035278\n",
      "MSE train 3.730554493815136 MSE test 7.059018421151713\n",
      "Epoch 1610 / 10000 loss: 75.7372739315033\n",
      "MSE train 3.7296217579574766 MSE test 7.0583189242633635\n",
      "Epoch 1611 / 10000 loss: 75.71569395065308\n",
      "MSE train 3.7287271187008857 MSE test 7.057623553453599\n",
      "Epoch 1612 / 10000 loss: 75.69593334197998\n",
      "MSE train 3.7278537669455756 MSE test 7.056931637322463\n",
      "Epoch 1613 / 10000 loss: 75.676992893219\n",
      "MSE train 3.726995897244939 MSE test 7.056242640418113\n",
      "Epoch 1614 / 10000 loss: 75.65851640701294\n",
      "MSE train 3.7261485618675834 MSE test 7.055555788300712\n",
      "Epoch 1615 / 10000 loss: 75.6403706073761\n",
      "MSE train 3.7253048627213556 MSE test 7.054870028929716\n",
      "Epoch 1616 / 10000 loss: 75.62245392799377\n",
      "MSE train 3.724457749939693 MSE test 7.054183839849917\n",
      "Epoch 1617 / 10000 loss: 75.60461616516113\n",
      "MSE train 3.723601828946669 MSE test 7.053496113300001\n",
      "Epoch 1618 / 10000 loss: 75.58669877052307\n",
      "MSE train 3.7227348228274875 MSE test 7.052806038083581\n",
      "Epoch 1619 / 10000 loss: 75.568594455719\n",
      "MSE train 3.7218567188515417 MSE test 7.052113358057232\n",
      "Epoch 1620 / 10000 loss: 75.55024766921997\n",
      "MSE train 3.7209625669317017 MSE test 7.051417874284569\n",
      "Epoch 1621 / 10000 loss: 75.53165864944458\n",
      "MSE train 3.720032670757913 MSE test 7.05071898628033\n",
      "Epoch 1622 / 10000 loss: 75.51271843910217\n",
      "MSE train 3.719025953049321 MSE test 7.0500159694601\n",
      "Epoch 1623 / 10000 loss: 75.49300384521484\n",
      "MSE train 3.7180034462868203 MSE test 7.049311414879867\n",
      "Epoch 1624 / 10000 loss: 75.47162055969238\n",
      "MSE train 3.71711367463121 MSE test 7.048620430250782\n",
      "Epoch 1625 / 10000 loss: 75.44989800453186\n",
      "MSE train 3.716261546883178 MSE test 7.047940185776868\n",
      "Epoch 1626 / 10000 loss: 75.43105363845825\n",
      "MSE train 3.7154251970865166 MSE test 7.0472677498097225\n",
      "Epoch 1627 / 10000 loss: 75.41302633285522\n",
      "MSE train 3.7145946778271415 MSE test 7.046601237977351\n",
      "Epoch 1628 / 10000 loss: 75.39534068107605\n",
      "MSE train 3.713763927548705 MSE test 7.04593906583926\n",
      "Epoch 1629 / 10000 loss: 75.37777853012085\n",
      "MSE train 3.71293058197456 MSE test 7.0452801274906385\n",
      "Epoch 1630 / 10000 loss: 75.36021518707275\n",
      "MSE train 3.7120952409431793 MSE test 7.044623500980166\n",
      "Epoch 1631 / 10000 loss: 75.34259510040283\n",
      "MSE train 3.71126051719837 MSE test 7.043968749543296\n",
      "Epoch 1632 / 10000 loss: 75.3249306678772\n",
      "MSE train 3.710429592177661 MSE test 7.043315447021544\n",
      "Epoch 1633 / 10000 loss: 75.30728125572205\n",
      "MSE train 3.709604490836183 MSE test 7.0426628334715184\n",
      "Epoch 1634 / 10000 loss: 75.28971743583679\n",
      "MSE train 3.7087850228863215 MSE test 7.0420103052860625\n",
      "Epoch 1635 / 10000 loss: 75.27227973937988\n",
      "MSE train 3.707968536191335 MSE test 7.041356785483037\n",
      "Epoch 1636 / 10000 loss: 75.25496339797974\n",
      "MSE train 3.7071493356394156 MSE test 7.040701156921805\n",
      "Epoch 1637 / 10000 loss: 75.23771667480469\n",
      "MSE train 3.7063167463398208 MSE test 7.040041607174739\n",
      "Epoch 1638 / 10000 loss: 75.22041320800781\n",
      "MSE train 3.7054547273021985 MSE test 7.039376250147534\n",
      "Epoch 1639 / 10000 loss: 75.20281934738159\n",
      "MSE train 3.704568546688707 MSE test 7.0387044380315045\n",
      "Epoch 1640 / 10000 loss: 75.18459177017212\n",
      "MSE train 3.7037210445090643 MSE test 7.038032174634591\n",
      "Epoch 1641 / 10000 loss: 75.16584467887878\n",
      "MSE train 3.7029160305081583 MSE test 7.037363650310995\n",
      "Epoch 1642 / 10000 loss: 75.1479332447052\n",
      "MSE train 3.702119765265773 MSE test 7.0366938526864224\n",
      "Epoch 1643 / 10000 loss: 75.13095021247864\n",
      "MSE train 3.7013182371382425 MSE test 7.036018777832461\n",
      "Epoch 1644 / 10000 loss: 75.11416101455688\n",
      "MSE train 3.700500861888625 MSE test 7.03533520642543\n",
      "Epoch 1645 / 10000 loss: 75.09726095199585\n",
      "MSE train 3.6996572501376943 MSE test 7.03464009482297\n",
      "Epoch 1646 / 10000 loss: 75.08002185821533\n",
      "MSE train 3.6987875991849304 MSE test 7.033932286921611\n",
      "Epoch 1647 / 10000 loss: 75.06221723556519\n",
      "MSE train 3.697930757832302 MSE test 7.0332200480978\n",
      "Epoch 1648 / 10000 loss: 75.04385709762573\n",
      "MSE train 3.697138672742828 MSE test 7.032523571261622\n",
      "Epoch 1649 / 10000 loss: 75.02577590942383\n",
      "MSE train 3.6963823705305763 MSE test 7.031843467383159\n",
      "Epoch 1650 / 10000 loss: 75.00908899307251\n",
      "MSE train 3.695630321003265 MSE test 7.031167716064957\n",
      "Epoch 1651 / 10000 loss: 74.99316763877869\n",
      "MSE train 3.6948692219233843 MSE test 7.0304898383649395\n",
      "Epoch 1652 / 10000 loss: 74.97732973098755\n",
      "MSE train 3.6940906289874302 MSE test 7.029805615491861\n",
      "Epoch 1653 / 10000 loss: 74.96129298210144\n",
      "MSE train 3.693287090162002 MSE test 7.029111227160721\n",
      "Epoch 1654 / 10000 loss: 74.94487309455872\n",
      "MSE train 3.692450533771908 MSE test 7.028402228612283\n",
      "Epoch 1655 / 10000 loss: 74.9279100894928\n",
      "MSE train 3.6915726658466044 MSE test 7.027673065979599\n",
      "Epoch 1656 / 10000 loss: 74.9102292060852\n",
      "MSE train 3.6906522687580114 MSE test 7.026919311125379\n",
      "Epoch 1657 / 10000 loss: 74.89164900779724\n",
      "MSE train 3.6897216846105856 MSE test 7.0261501840960205\n",
      "Epoch 1658 / 10000 loss: 74.87214732170105\n",
      "MSE train 3.6888313505260033 MSE test 7.025402286826329\n",
      "Epoch 1659 / 10000 loss: 74.85241985321045\n",
      "MSE train 3.6879679699556798 MSE test 7.02468772125245\n",
      "Epoch 1660 / 10000 loss: 74.83355593681335\n",
      "MSE train 3.68710964635009 MSE test 7.023990867104169\n",
      "Epoch 1661 / 10000 loss: 74.81527423858643\n",
      "MSE train 3.686259603454577 MSE test 7.0233029431812675\n",
      "Epoch 1662 / 10000 loss: 74.79709434509277\n",
      "MSE train 3.685432372398756 MSE test 7.0226210326018315\n",
      "Epoch 1663 / 10000 loss: 74.77908682823181\n",
      "MSE train 3.6846208207273747 MSE test 7.021943263113982\n",
      "Epoch 1664 / 10000 loss: 74.76157331466675\n",
      "MSE train 3.6838054462743197 MSE test 7.021266789201524\n",
      "Epoch 1665 / 10000 loss: 74.74439668655396\n",
      "MSE train 3.682973263816069 MSE test 7.020589269053893\n",
      "Epoch 1666 / 10000 loss: 74.7271375656128\n",
      "MSE train 3.6821213941026354 MSE test 7.019909890868855\n",
      "Epoch 1667 / 10000 loss: 74.70951056480408\n",
      "MSE train 3.6812618432232496 MSE test 7.019229593390321\n",
      "Epoch 1668 / 10000 loss: 74.69145703315735\n",
      "MSE train 3.680412445380056 MSE test 7.018551336712078\n",
      "Epoch 1669 / 10000 loss: 74.67323422431946\n",
      "MSE train 3.6795762827455487 MSE test 7.017876720495597\n",
      "Epoch 1670 / 10000 loss: 74.65523076057434\n",
      "MSE train 3.6787463155226723 MSE test 7.017205474629569\n",
      "Epoch 1671 / 10000 loss: 74.6375162601471\n",
      "MSE train 3.677916168974341 MSE test 7.016536630667144\n",
      "Epoch 1672 / 10000 loss: 74.61993503570557\n",
      "MSE train 3.677081275541646 MSE test 7.015869617432142\n",
      "Epoch 1673 / 10000 loss: 74.6023519039154\n",
      "MSE train 3.6762378975011476 MSE test 7.015204007575381\n",
      "Epoch 1674 / 10000 loss: 74.5846643447876\n",
      "MSE train 3.6753840547133367 MSE test 7.01453976257973\n",
      "Epoch 1675 / 10000 loss: 74.56679391860962\n",
      "MSE train 3.6745263943511053 MSE test 7.013877742561875\n",
      "Epoch 1676 / 10000 loss: 74.54869532585144\n",
      "MSE train 3.6736865623134816 MSE test 7.013221267961665\n",
      "Epoch 1677 / 10000 loss: 74.53051543235779\n",
      "MSE train 3.6728791110021097 MSE test 7.012573950005301\n",
      "Epoch 1678 / 10000 loss: 74.51271629333496\n",
      "MSE train 3.672099812307531 MSE test 7.0119359484359745\n",
      "Epoch 1679 / 10000 loss: 74.49561524391174\n",
      "MSE train 3.6713441596545744 MSE test 7.011305951542675\n",
      "Epoch 1680 / 10000 loss: 74.47912430763245\n",
      "MSE train 3.6706101228676586 MSE test 7.010682565247321\n",
      "Epoch 1681 / 10000 loss: 74.46314287185669\n",
      "MSE train 3.6698953799990037 MSE test 7.010065081381625\n",
      "Epoch 1682 / 10000 loss: 74.44762921333313\n",
      "MSE train 3.6691970845190647 MSE test 7.009452854907228\n",
      "Epoch 1683 / 10000 loss: 74.432532787323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.6685125357430888 MSE test 7.008845206613265\n",
      "Epoch 1684 / 10000 loss: 74.41779017448425\n",
      "MSE train 3.6678393892609473 MSE test 7.00824176596959\n",
      "Epoch 1685 / 10000 loss: 74.40334415435791\n",
      "MSE train 3.6671755588711683 MSE test 7.00764201862938\n",
      "Epoch 1686 / 10000 loss: 74.38914489746094\n",
      "MSE train 3.666519017216964 MSE test 7.007045581624268\n",
      "Epoch 1687 / 10000 loss: 74.37514781951904\n",
      "MSE train 3.6658677715651575 MSE test 7.006451829490783\n",
      "Epoch 1688 / 10000 loss: 74.36130619049072\n",
      "MSE train 3.6652199463598105 MSE test 7.005860424680196\n",
      "Epoch 1689 / 10000 loss: 74.34757971763611\n",
      "MSE train 3.6645738914647197 MSE test 7.00527088710339\n",
      "Epoch 1690 / 10000 loss: 74.33392477035522\n",
      "MSE train 3.663928330843396 MSE test 7.0046827445171775\n",
      "Epoch 1691 / 10000 loss: 74.32031059265137\n",
      "MSE train 3.6632823740197797 MSE test 7.004095491801794\n",
      "Epoch 1692 / 10000 loss: 74.30670380592346\n",
      "MSE train 3.6626355324558446 MSE test 7.003508765607444\n",
      "Epoch 1693 / 10000 loss: 74.29309034347534\n",
      "MSE train 3.661987641812796 MSE test 7.002922042999503\n",
      "Epoch 1694 / 10000 loss: 74.27945733070374\n",
      "MSE train 3.6613387277134946 MSE test 7.002334950975226\n",
      "Epoch 1695 / 10000 loss: 74.2657995223999\n",
      "MSE train 3.660688716745503 MSE test 7.001747104691386\n",
      "Epoch 1696 / 10000 loss: 74.252121925354\n",
      "MSE train 3.6600371130627445 MSE test 7.001158028198878\n",
      "Epoch 1697 / 10000 loss: 74.23841714859009\n",
      "MSE train 3.6593826620822085 MSE test 7.000567304274518\n",
      "Epoch 1698 / 10000 loss: 74.2246835231781\n",
      "MSE train 3.6587230591660607 MSE test 6.999974343139636\n",
      "Epoch 1699 / 10000 loss: 74.21088480949402\n",
      "MSE train 3.658054693825613 MSE test 6.9993785275055505\n",
      "Epoch 1700 / 10000 loss: 74.19697523117065\n",
      "MSE train 3.657372594329407 MSE test 6.998779368142504\n",
      "Epoch 1701 / 10000 loss: 74.18287777900696\n",
      "MSE train 3.6566713996735873 MSE test 6.998176253606122\n",
      "Epoch 1702 / 10000 loss: 74.16848158836365\n",
      "MSE train 3.655949410040479 MSE test 6.997568717979091\n",
      "Epoch 1703 / 10000 loss: 74.15367460250854\n",
      "MSE train 3.655215212289858 MSE test 6.996956718908586\n",
      "Epoch 1704 / 10000 loss: 74.13841652870178\n",
      "MSE train 3.6544824663884032 MSE test 6.996340800389581\n",
      "Epoch 1705 / 10000 loss: 74.1228973865509\n",
      "MSE train 3.653752579459242 MSE test 6.99572119800984\n",
      "Epoch 1706 / 10000 loss: 74.10740900039673\n",
      "MSE train 3.6530172817916537 MSE test 6.9950976523707045\n",
      "Epoch 1707 / 10000 loss: 74.09198474884033\n",
      "MSE train 3.6522674148061087 MSE test 6.994470229505906\n",
      "Epoch 1708 / 10000 loss: 74.07644891738892\n",
      "MSE train 3.651484646978833 MSE test 6.993838729195413\n",
      "Epoch 1709 / 10000 loss: 74.0605947971344\n",
      "MSE train 3.650623144994657 MSE test 6.9932022543942685\n",
      "Epoch 1710 / 10000 loss: 74.04403495788574\n",
      "MSE train 3.649767239889338 MSE test 6.99256208498474\n",
      "Epoch 1711 / 10000 loss: 74.02577543258667\n",
      "MSE train 3.6490321354930915 MSE test 6.991930461492583\n",
      "Epoch 1712 / 10000 loss: 74.00763988494873\n",
      "MSE train 3.648314586000307 MSE test 6.991300698126835\n",
      "Epoch 1713 / 10000 loss: 73.99211311340332\n",
      "MSE train 3.647604650996703 MSE test 6.990671098594304\n",
      "Epoch 1714 / 10000 loss: 73.976970911026\n",
      "MSE train 3.646895111573438 MSE test 6.990040691516095\n",
      "Epoch 1715 / 10000 loss: 73.96199297904968\n",
      "MSE train 3.646178926613287 MSE test 6.989408262358641\n",
      "Epoch 1716 / 10000 loss: 73.94703364372253\n",
      "MSE train 3.645450479991018 MSE test 6.988772947260262\n",
      "Epoch 1717 / 10000 loss: 73.93193221092224\n",
      "MSE train 3.644705888760456 MSE test 6.98813396902088\n",
      "Epoch 1718 / 10000 loss: 73.91657018661499\n",
      "MSE train 3.6439422292601535 MSE test 6.987490704373882\n",
      "Epoch 1719 / 10000 loss: 73.90086460113525\n",
      "MSE train 3.6431546400148913 MSE test 6.986842611003843\n",
      "Epoch 1720 / 10000 loss: 73.88474702835083\n",
      "MSE train 3.6423311246196253 MSE test 6.9861886223758844\n",
      "Epoch 1721 / 10000 loss: 73.86811304092407\n",
      "MSE train 3.6414475767745 MSE test 6.985527086354652\n",
      "Epoch 1722 / 10000 loss: 73.85070371627808\n",
      "MSE train 3.640508467073998 MSE test 6.984856806074741\n",
      "Epoch 1723 / 10000 loss: 73.83199524879456\n",
      "MSE train 3.6395972846947506 MSE test 6.984181315058715\n",
      "Epoch 1724 / 10000 loss: 73.81207823753357\n",
      "MSE train 3.638675858016743 MSE test 6.983501513191538\n",
      "Epoch 1725 / 10000 loss: 73.79276990890503\n",
      "MSE train 3.63773788555682 MSE test 6.982816084156235\n",
      "Epoch 1726 / 10000 loss: 73.7732412815094\n",
      "MSE train 3.636830779470772 MSE test 6.982128970430551\n",
      "Epoch 1727 / 10000 loss: 73.75335383415222\n",
      "MSE train 3.6359621980040893 MSE test 6.9814434340936105\n",
      "Epoch 1728 / 10000 loss: 73.73413801193237\n",
      "MSE train 3.6351129711006527 MSE test 6.9807586874967935\n",
      "Epoch 1729 / 10000 loss: 73.7157552242279\n",
      "MSE train 3.634275244225494 MSE test 6.980074076081205\n",
      "Epoch 1730 / 10000 loss: 73.69779586791992\n",
      "MSE train 3.63344605122043 MSE test 6.979389423514674\n",
      "Epoch 1731 / 10000 loss: 73.68008399009705\n",
      "MSE train 3.6326224158309235 MSE test 6.978704488931603\n",
      "Epoch 1732 / 10000 loss: 73.66255140304565\n",
      "MSE train 3.631800070006543 MSE test 6.978019165782531\n",
      "Epoch 1733 / 10000 loss: 73.64513540267944\n",
      "MSE train 3.6309741443424586 MSE test 6.977332749901566\n",
      "Epoch 1734 / 10000 loss: 73.62774300575256\n",
      "MSE train 3.63014142944705 MSE test 6.976644795772475\n",
      "Epoch 1735 / 10000 loss: 73.61026668548584\n",
      "MSE train 3.6293032307793966 MSE test 6.975954942008074\n",
      "Epoch 1736 / 10000 loss: 73.59263801574707\n",
      "MSE train 3.628465149715686 MSE test 6.975263164348\n",
      "Epoch 1737 / 10000 loss: 73.57488965988159\n",
      "MSE train 3.6276314264967158 MSE test 6.974569610219599\n",
      "Epoch 1738 / 10000 loss: 73.55714178085327\n",
      "MSE train 3.62680152231 MSE test 6.973874285101579\n",
      "Epoch 1739 / 10000 loss: 73.53948092460632\n",
      "MSE train 3.6259728014130923 MSE test 6.973177315344598\n",
      "Epoch 1740 / 10000 loss: 73.5219042301178\n",
      "MSE train 3.6251429372789135 MSE test 6.972478897189734\n",
      "Epoch 1741 / 10000 loss: 73.50435161590576\n",
      "MSE train 3.624310286582076 MSE test 6.971779378749642\n",
      "Epoch 1742 / 10000 loss: 73.48677253723145\n",
      "MSE train 3.6234739623729357 MSE test 6.97107926438222\n",
      "Epoch 1743 / 10000 loss: 73.46913480758667\n",
      "MSE train 3.622634303481009 MSE test 6.970379042308721\n",
      "Epoch 1744 / 10000 loss: 73.45141530036926\n",
      "MSE train 3.621793058626278 MSE test 6.969679370258184\n",
      "Epoch 1745 / 10000 loss: 73.43362498283386\n",
      "MSE train 3.6209529734503394 MSE test 6.968980990733791\n",
      "Epoch 1746 / 10000 loss: 73.41579604148865\n",
      "MSE train 3.620116677071974 MSE test 6.968284233754496\n",
      "Epoch 1747 / 10000 loss: 73.39799213409424\n",
      "MSE train 3.619285273149537 MSE test 6.967589191554275\n",
      "Epoch 1748 / 10000 loss: 73.38026928901672\n",
      "MSE train 3.6184558163380363 MSE test 6.966895340526919\n",
      "Epoch 1749 / 10000 loss: 73.36264657974243\n",
      "MSE train 3.617619363976732 MSE test 6.966202101714468\n",
      "Epoch 1750 / 10000 loss: 73.34506368637085\n",
      "MSE train 3.616762012562798 MSE test 6.965509044987013\n",
      "Epoch 1751 / 10000 loss: 73.32732558250427\n",
      "MSE train 3.615837837056161 MSE test 6.964817019054211\n",
      "Epoch 1752 / 10000 loss: 73.3091299533844\n",
      "MSE train 3.6149755095135276 MSE test 6.964128387757643\n",
      "Epoch 1753 / 10000 loss: 73.28948211669922\n",
      "MSE train 3.614249986711034 MSE test 6.963463153609887\n",
      "Epoch 1754 / 10000 loss: 73.27117681503296\n",
      "MSE train 3.6135307935475764 MSE test 6.962803281108277\n",
      "Epoch 1755 / 10000 loss: 73.25583624839783\n",
      "MSE train 3.6128113418305743 MSE test 6.9621468233616675\n",
      "Epoch 1756 / 10000 loss: 73.24063467979431\n",
      "MSE train 3.61208808476391 MSE test 6.961492432970361\n",
      "Epoch 1757 / 10000 loss: 73.22542524337769\n",
      "MSE train 3.611358694345007 MSE test 6.960839335521253\n",
      "Epoch 1758 / 10000 loss: 73.2101321220398\n",
      "MSE train 3.610621400766307 MSE test 6.960186752233037\n",
      "Epoch 1759 / 10000 loss: 73.19470596313477\n",
      "MSE train 3.6098750085933045 MSE test 6.959534168014433\n",
      "Epoch 1760 / 10000 loss: 73.17910838127136\n",
      "MSE train 3.609119619138178 MSE test 6.958881091900828\n",
      "Epoch 1761 / 10000 loss: 73.16331434249878\n",
      "MSE train 3.608357875630073 MSE test 6.95822722401459\n",
      "Epoch 1762 / 10000 loss: 73.1473240852356\n",
      "MSE train 3.607595403282861 MSE test 6.957572539618976\n",
      "Epoch 1763 / 10000 loss: 73.13119626045227\n",
      "MSE train 3.606838615431119 MSE test 6.956916986120776\n",
      "Epoch 1764 / 10000 loss: 73.1150574684143\n",
      "MSE train 3.6060916104914345 MSE test 6.956260640538644\n",
      "Epoch 1765 / 10000 loss: 73.09904170036316\n",
      "MSE train 3.6053548951860037 MSE test 6.95560339454546\n",
      "Epoch 1766 / 10000 loss: 73.08323645591736\n",
      "MSE train 3.6046258464443426 MSE test 6.954944838782808\n",
      "Epoch 1767 / 10000 loss: 73.06765675544739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.6038996921123228 MSE test 6.954284267039432\n",
      "Epoch 1768 / 10000 loss: 73.05224370956421\n",
      "MSE train 3.6031708383530074 MSE test 6.953620708480384\n",
      "Epoch 1769 / 10000 loss: 73.03689479827881\n",
      "MSE train 3.602433727543097 MSE test 6.9529532295468925\n",
      "Epoch 1770 / 10000 loss: 73.021488904953\n",
      "MSE train 3.6016833557478205 MSE test 6.952280555156946\n",
      "Epoch 1771 / 10000 loss: 73.00590634346008\n",
      "MSE train 3.6009153463069143 MSE test 6.951601648139893\n",
      "Epoch 1772 / 10000 loss: 72.99003911018372\n",
      "MSE train 3.600124782976715 MSE test 6.950915160769158\n",
      "Epoch 1773 / 10000 loss: 72.97379446029663\n",
      "MSE train 3.599299135565064 MSE test 6.950218742648909\n",
      "Epoch 1774 / 10000 loss: 72.95706820487976\n",
      "MSE train 3.5984034120991795 MSE test 6.949507535034999\n",
      "Epoch 1775 / 10000 loss: 72.93958234786987\n",
      "MSE train 3.5974989703667415 MSE test 6.948782882712532\n",
      "Epoch 1776 / 10000 loss: 72.9205870628357\n",
      "MSE train 3.596694206374792 MSE test 6.948085935449935\n",
      "Epoch 1777 / 10000 loss: 72.90139389038086\n",
      "MSE train 3.5958944507506723 MSE test 6.947394407843575\n",
      "Epoch 1778 / 10000 loss: 72.88437056541443\n",
      "MSE train 3.5950861540529946 MSE test 6.946700185877572\n",
      "Epoch 1779 / 10000 loss: 72.86745715141296\n",
      "MSE train 3.5942515420709835 MSE test 6.945998439253606\n",
      "Epoch 1780 / 10000 loss: 72.8503623008728\n",
      "MSE train 3.5933546372510516 MSE test 6.94528394359664\n",
      "Epoch 1781 / 10000 loss: 72.8326964378357\n",
      "MSE train 3.5924489540187725 MSE test 6.944565701214797\n",
      "Epoch 1782 / 10000 loss: 72.8136830329895\n",
      "MSE train 3.591623648928189 MSE test 6.943883714456951\n",
      "Epoch 1783 / 10000 loss: 72.79447889328003\n",
      "MSE train 3.5907549948538797 MSE test 6.943214880948133\n",
      "Epoch 1784 / 10000 loss: 72.77701354026794\n",
      "MSE train 3.5897920008815634 MSE test 6.942545198817638\n",
      "Epoch 1785 / 10000 loss: 72.75860929489136\n",
      "MSE train 3.5889656406845014 MSE test 6.941886391272382\n",
      "Epoch 1786 / 10000 loss: 72.73816323280334\n",
      "MSE train 3.5881634336434662 MSE test 6.9412379342932\n",
      "Epoch 1787 / 10000 loss: 72.7206768989563\n",
      "MSE train 3.587339890010029 MSE test 6.940592053746552\n",
      "Epoch 1788 / 10000 loss: 72.70370936393738\n",
      "MSE train 3.586503286690919 MSE test 6.939947950562326\n",
      "Epoch 1789 / 10000 loss: 72.68628072738647\n",
      "MSE train 3.5856905751672015 MSE test 6.939306813981457\n",
      "Epoch 1790 / 10000 loss: 72.66856551170349\n",
      "MSE train 3.584908000935521 MSE test 6.938669558373178\n",
      "Epoch 1791 / 10000 loss: 72.65136289596558\n",
      "MSE train 3.584138740795467 MSE test 6.938035322053925\n",
      "Epoch 1792 / 10000 loss: 72.6348123550415\n",
      "MSE train 3.5833768192952604 MSE test 6.93740340184743\n",
      "Epoch 1793 / 10000 loss: 72.61854481697083\n",
      "MSE train 3.5826211133840187 MSE test 6.936773296125702\n",
      "Epoch 1794 / 10000 loss: 72.60243678092957\n",
      "MSE train 3.5818703679039454 MSE test 6.936144842323569\n",
      "Epoch 1795 / 10000 loss: 72.5864610671997\n",
      "MSE train 3.581122482365952 MSE test 6.9355179035104815\n",
      "Epoch 1796 / 10000 loss: 72.57059216499329\n",
      "MSE train 3.580374481133121 MSE test 6.934892031445014\n",
      "Epoch 1797 / 10000 loss: 72.5547878742218\n",
      "MSE train 3.579621653013869 MSE test 6.934266887693521\n",
      "Epoch 1798 / 10000 loss: 72.53898024559021\n",
      "MSE train 3.578856730186315 MSE test 6.933641647367788\n",
      "Epoch 1799 / 10000 loss: 72.52306509017944\n",
      "MSE train 3.5780746352504704 MSE test 6.93301560474355\n",
      "Epoch 1800 / 10000 loss: 72.50689339637756\n",
      "MSE train 3.577290492516434 MSE test 6.932389414905337\n",
      "Epoch 1801 / 10000 loss: 72.49034833908081\n",
      "MSE train 3.5765345312348584 MSE test 6.931766098748172\n",
      "Epoch 1802 / 10000 loss: 72.47375845909119\n",
      "MSE train 3.5758053061987156 MSE test 6.931146919419594\n",
      "Epoch 1803 / 10000 loss: 72.45777368545532\n",
      "MSE train 3.5750883599401124 MSE test 6.930530111935212\n",
      "Epoch 1804 / 10000 loss: 72.44237279891968\n",
      "MSE train 3.5743773783443773 MSE test 6.929914249299574\n",
      "Epoch 1805 / 10000 loss: 72.42723655700684\n",
      "MSE train 3.573669477253343 MSE test 6.929298527400776\n",
      "Epoch 1806 / 10000 loss: 72.41222882270813\n",
      "MSE train 3.5729607433943937 MSE test 6.928682254390569\n",
      "Epoch 1807 / 10000 loss: 72.39728569984436\n",
      "MSE train 3.5722451495888223 MSE test 6.928065135781495\n",
      "Epoch 1808 / 10000 loss: 72.38232421875\n",
      "MSE train 3.5715164448622585 MSE test 6.927447465597178\n",
      "Epoch 1809 / 10000 loss: 72.3672125339508\n",
      "MSE train 3.5707723842880212 MSE test 6.926830589624688\n",
      "Epoch 1810 / 10000 loss: 72.35181450843811\n",
      "MSE train 3.5700245999388898 MSE test 6.926216645095248\n",
      "Epoch 1811 / 10000 loss: 72.3360824584961\n",
      "MSE train 3.569300932990754 MSE test 6.92560724230016\n",
      "Epoch 1812 / 10000 loss: 72.32027125358582\n",
      "MSE train 3.5686060929430963 MSE test 6.925002213957569\n",
      "Epoch 1813 / 10000 loss: 72.30497908592224\n",
      "MSE train 3.5679197300007357 MSE test 6.924400054660445\n",
      "Epoch 1814 / 10000 loss: 72.29030585289001\n",
      "MSE train 3.567219064418885 MSE test 6.92379849985719\n",
      "Epoch 1815 / 10000 loss: 72.27581691741943\n",
      "MSE train 3.5664502924588515 MSE test 6.9231941318813455\n",
      "Epoch 1816 / 10000 loss: 72.26101422309875\n",
      "MSE train 3.5654412559483895 MSE test 6.922578328999197\n",
      "Epoch 1817 / 10000 loss: 72.24474716186523\n",
      "MSE train 3.564576637783627 MSE test 6.9219459990764225\n",
      "Epoch 1818 / 10000 loss: 72.22328066825867\n",
      "MSE train 3.5639079298465624 MSE test 6.92135629846953\n",
      "Epoch 1819 / 10000 loss: 72.20486283302307\n",
      "MSE train 3.5632381308286933 MSE test 6.920767428431602\n",
      "Epoch 1820 / 10000 loss: 72.19074320793152\n",
      "MSE train 3.5625683846048406 MSE test 6.920179275047844\n",
      "Epoch 1821 / 10000 loss: 72.17660140991211\n",
      "MSE train 3.561900172400496 MSE test 6.919592054713043\n",
      "Epoch 1822 / 10000 loss: 72.16246175765991\n",
      "MSE train 3.5612342869230584 MSE test 6.919005904900808\n",
      "Epoch 1823 / 10000 loss: 72.14835453033447\n",
      "MSE train 3.5605705153824254 MSE test 6.9184207997790965\n",
      "Epoch 1824 / 10000 loss: 72.13429641723633\n",
      "MSE train 3.5599076805751064 MSE test 6.917836725614672\n",
      "Epoch 1825 / 10000 loss: 72.12029004096985\n",
      "MSE train 3.5592438080994917 MSE test 6.9172534589665915\n",
      "Epoch 1826 / 10000 loss: 72.10630369186401\n",
      "MSE train 3.5585763698204604 MSE test 6.916670705806393\n",
      "Epoch 1827 / 10000 loss: 72.09229612350464\n",
      "MSE train 3.5579025164596745 MSE test 6.916088072629134\n",
      "Epoch 1828 / 10000 loss: 72.0782163143158\n",
      "MSE train 3.557219365454207 MSE test 6.9155050165179635\n",
      "Epoch 1829 / 10000 loss: 72.06399893760681\n",
      "MSE train 3.5565243272283946 MSE test 6.914921136411715\n",
      "Epoch 1830 / 10000 loss: 72.04958438873291\n",
      "MSE train 3.555815488760977 MSE test 6.914335842912395\n",
      "Epoch 1831 / 10000 loss: 72.03491759300232\n",
      "MSE train 3.5550918304497143 MSE test 6.913748594910294\n",
      "Epoch 1832 / 10000 loss: 72.01995635032654\n",
      "MSE train 3.554352946411228 MSE test 6.913158982196778\n",
      "Epoch 1833 / 10000 loss: 72.00467896461487\n",
      "MSE train 3.5535989536072012 MSE test 6.912566740289543\n",
      "Epoch 1834 / 10000 loss: 71.9890775680542\n",
      "MSE train 3.5528327458390407 MSE test 6.911971933919475\n",
      "Epoch 1835 / 10000 loss: 71.97315812110901\n",
      "MSE train 3.552061790638255 MSE test 6.911375717304767\n",
      "Epoch 1836 / 10000 loss: 71.95697832107544\n",
      "MSE train 3.551290592635316 MSE test 6.9107792787366815\n",
      "Epoch 1837 / 10000 loss: 71.94070386886597\n",
      "MSE train 3.550514171999172 MSE test 6.9101834141730105\n",
      "Epoch 1838 / 10000 loss: 71.92443251609802\n",
      "MSE train 3.549728878199338 MSE test 6.909588111709928\n",
      "Epoch 1839 / 10000 loss: 71.90804886817932\n",
      "MSE train 3.548949433778591 MSE test 6.9089943361114985\n",
      "Epoch 1840 / 10000 loss: 71.8914749622345\n",
      "MSE train 3.5481981919093655 MSE test 6.908403329706986\n",
      "Epoch 1841 / 10000 loss: 71.87502074241638\n",
      "MSE train 3.5474716129842334 MSE test 6.907815723227055\n",
      "Epoch 1842 / 10000 loss: 71.85917043685913\n",
      "MSE train 3.546755929742497 MSE test 6.907230633149001\n",
      "Epoch 1843 / 10000 loss: 71.84384560585022\n",
      "MSE train 3.546043661402956 MSE test 6.9066473932186385\n",
      "Epoch 1844 / 10000 loss: 71.82875061035156\n",
      "MSE train 3.545332179818607 MSE test 6.906065424154761\n",
      "Epoch 1845 / 10000 loss: 71.81372451782227\n",
      "MSE train 3.5446215583008645 MSE test 6.905484318982278\n",
      "Epoch 1846 / 10000 loss: 71.79871010780334\n",
      "MSE train 3.543913389050485 MSE test 6.904903868396372\n",
      "Epoch 1847 / 10000 loss: 71.78371739387512\n",
      "MSE train 3.543209464667229 MSE test 6.904323901541294\n",
      "Epoch 1848 / 10000 loss: 71.76877093315125\n",
      "MSE train 3.5425105248247997 MSE test 6.9037441854582715\n",
      "Epoch 1849 / 10000 loss: 71.75391936302185\n",
      "MSE train 3.541815703736398 MSE test 6.9031644947705315\n",
      "Epoch 1850 / 10000 loss: 71.73917698860168\n",
      "MSE train 3.5411228286590513 MSE test 6.9025846007612195\n",
      "Epoch 1851 / 10000 loss: 71.7245237827301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.5404292437939873 MSE test 6.902004097530104\n",
      "Epoch 1852 / 10000 loss: 71.70991492271423\n",
      "MSE train 3.539732433928753 MSE test 6.901422756800453\n",
      "Epoch 1853 / 10000 loss: 71.6952919960022\n",
      "MSE train 3.5390304418315233 MSE test 6.900840387991435\n",
      "Epoch 1854 / 10000 loss: 71.68059945106506\n",
      "MSE train 3.538322096514006 MSE test 6.900256830867758\n",
      "Epoch 1855 / 10000 loss: 71.66580009460449\n",
      "MSE train 3.5376070382538507 MSE test 6.899671849457866\n",
      "Epoch 1856 / 10000 loss: 71.65086340904236\n",
      "MSE train 3.5368857200692068 MSE test 6.899085447593257\n",
      "Epoch 1857 / 10000 loss: 71.63578200340271\n",
      "MSE train 3.536159203986084 MSE test 6.89849763672081\n",
      "Epoch 1858 / 10000 loss: 71.62056469917297\n",
      "MSE train 3.5354288437059616 MSE test 6.8979084343673644\n",
      "Epoch 1859 / 10000 loss: 71.60523819923401\n",
      "MSE train 3.534695822904357 MSE test 6.8973177565492065\n",
      "Epoch 1860 / 10000 loss: 71.58982563018799\n",
      "MSE train 3.533960994713828 MSE test 6.896725694398473\n",
      "Epoch 1861 / 10000 loss: 71.57435584068298\n",
      "MSE train 3.5332249795092676 MSE test 6.896132277013204\n",
      "Epoch 1862 / 10000 loss: 71.55884599685669\n",
      "MSE train 3.532488517062558 MSE test 6.895537669537709\n",
      "Epoch 1863 / 10000 loss: 71.54330658912659\n",
      "MSE train 3.531752587879821 MSE test 6.894941930434276\n",
      "Epoch 1864 / 10000 loss: 71.52775287628174\n",
      "MSE train 3.5310181878062212 MSE test 6.894345287374577\n",
      "Epoch 1865 / 10000 loss: 71.51221323013306\n",
      "MSE train 3.5302856815903376 MSE test 6.893747871110242\n",
      "Epoch 1866 / 10000 loss: 71.49669933319092\n",
      "MSE train 3.5295543218231193 MSE test 6.8931496002500605\n",
      "Epoch 1867 / 10000 loss: 71.48122882843018\n",
      "MSE train 3.5288218339729975 MSE test 6.892550231830975\n",
      "Epoch 1868 / 10000 loss: 71.46578073501587\n",
      "MSE train 3.528084340870375 MSE test 6.891949489628556\n",
      "Epoch 1869 / 10000 loss: 71.4503071308136\n",
      "MSE train 3.5273359971827807 MSE test 6.891346755839331\n",
      "Epoch 1870 / 10000 loss: 71.43472576141357\n",
      "MSE train 3.5265678082659697 MSE test 6.89074134129135\n",
      "Epoch 1871 / 10000 loss: 71.41890954971313\n",
      "MSE train 3.525764882201556 MSE test 6.8901318460555085\n",
      "Epoch 1872 / 10000 loss: 71.40266704559326\n",
      "MSE train 3.5249133175560647 MSE test 6.889517137081122\n",
      "Epoch 1873 / 10000 loss: 71.38568043708801\n",
      "MSE train 3.524062015223086 MSE test 6.888900305066621\n",
      "Epoch 1874 / 10000 loss: 71.3676438331604\n",
      "MSE train 3.5232684356122856 MSE test 6.8882912000458525\n",
      "Epoch 1875 / 10000 loss: 71.34961462020874\n",
      "MSE train 3.5224816547386126 MSE test 6.887687532105753\n",
      "Epoch 1876 / 10000 loss: 71.33282113075256\n",
      "MSE train 3.5216635887949295 MSE test 6.887084487961456\n",
      "Epoch 1877 / 10000 loss: 71.31616234779358\n",
      "MSE train 3.5207906757674583 MSE test 6.886479812088813\n",
      "Epoch 1878 / 10000 loss: 71.29882454872131\n",
      "MSE train 3.519842737142955 MSE test 6.885871382203479\n",
      "Epoch 1879 / 10000 loss: 71.28029441833496\n",
      "MSE train 3.519015896899741 MSE test 6.885263339983816\n",
      "Epoch 1880 / 10000 loss: 71.26014757156372\n",
      "MSE train 3.518215139932545 MSE test 6.884659934190084\n",
      "Epoch 1881 / 10000 loss: 71.24261927604675\n",
      "MSE train 3.5173253752430425 MSE test 6.88404240157977\n",
      "Epoch 1882 / 10000 loss: 71.22564172744751\n",
      "MSE train 3.5163901721531112 MSE test 6.883406778068845\n",
      "Epoch 1883 / 10000 loss: 71.20674633979797\n",
      "MSE train 3.5156063692108055 MSE test 6.882808460139665\n",
      "Epoch 1884 / 10000 loss: 71.1869523525238\n",
      "MSE train 3.5148600900714224 MSE test 6.882223745988749\n",
      "Epoch 1885 / 10000 loss: 71.17038917541504\n",
      "MSE train 3.514119282660762 MSE test 6.881642778847754\n",
      "Epoch 1886 / 10000 loss: 71.15462470054626\n",
      "MSE train 3.5133713843928813 MSE test 6.881062939283984\n",
      "Epoch 1887 / 10000 loss: 71.13898301124573\n",
      "MSE train 3.5126236384310827 MSE test 6.880483585469354\n",
      "Epoch 1888 / 10000 loss: 71.12319159507751\n",
      "MSE train 3.5118820409888474 MSE test 6.879904871936296\n",
      "Epoch 1889 / 10000 loss: 71.10740089416504\n",
      "MSE train 3.5111320991809833 MSE test 6.879325817165695\n",
      "Epoch 1890 / 10000 loss: 71.09174394607544\n",
      "MSE train 3.5103520028727027 MSE test 6.878744175992547\n",
      "Epoch 1891 / 10000 loss: 71.07590317726135\n",
      "MSE train 3.509504902992847 MSE test 6.878156202140551\n",
      "Epoch 1892 / 10000 loss: 71.05940961837769\n",
      "MSE train 3.5086011730919497 MSE test 6.877555834482179\n",
      "Epoch 1893 / 10000 loss: 71.04147028923035\n",
      "MSE train 3.5078867752603315 MSE test 6.876979179195918\n",
      "Epoch 1894 / 10000 loss: 71.02230310440063\n",
      "MSE train 3.5071952285064567 MSE test 6.876410800709396\n",
      "Epoch 1895 / 10000 loss: 71.00723242759705\n",
      "MSE train 3.5065086315706866 MSE test 6.875846442516048\n",
      "Epoch 1896 / 10000 loss: 70.99265241622925\n",
      "MSE train 3.50581688792985 MSE test 6.875285164960829\n",
      "Epoch 1897 / 10000 loss: 70.97817778587341\n",
      "MSE train 3.505122745186397 MSE test 6.874726090132338\n",
      "Epoch 1898 / 10000 loss: 70.96359014511108\n",
      "MSE train 3.5044435275226773 MSE test 6.874169073861859\n",
      "Epoch 1899 / 10000 loss: 70.94894289970398\n",
      "MSE train 3.5037732533238 MSE test 6.873613700225248\n",
      "Epoch 1900 / 10000 loss: 70.93461847305298\n",
      "MSE train 3.503086931255034 MSE test 6.8730587673578505\n",
      "Epoch 1901 / 10000 loss: 70.92048358917236\n",
      "MSE train 3.50237528894412 MSE test 6.872503280559796\n",
      "Epoch 1902 / 10000 loss: 70.906001329422\n",
      "MSE train 3.5016840524634834 MSE test 6.871948240929405\n",
      "Epoch 1903 / 10000 loss: 70.89096808433533\n",
      "MSE train 3.501031280288308 MSE test 6.87139603150348\n",
      "Epoch 1904 / 10000 loss: 70.8763747215271\n",
      "MSE train 3.5003838030761045 MSE test 6.870845415662223\n",
      "Epoch 1905 / 10000 loss: 70.86261248588562\n",
      "MSE train 3.4997254182543798 MSE test 6.8702951311897165\n",
      "Epoch 1906 / 10000 loss: 70.84896731376648\n",
      "MSE train 3.499039461776669 MSE test 6.869744562862406\n",
      "Epoch 1907 / 10000 loss: 70.83508014678955\n",
      "MSE train 3.4982992289814048 MSE test 6.869192851257807\n",
      "Epoch 1908 / 10000 loss: 70.82059979438782\n",
      "MSE train 3.4974912801933726 MSE test 6.868639459442729\n",
      "Epoch 1909 / 10000 loss: 70.80494046211243\n",
      "MSE train 3.4967296825286662 MSE test 6.868085942786435\n",
      "Epoch 1910 / 10000 loss: 70.78781580924988\n",
      "MSE train 3.4960466226493265 MSE test 6.867535837156942\n",
      "Epoch 1911 / 10000 loss: 70.7716896533966\n",
      "MSE train 3.49538986633779 MSE test 6.866988691112151\n",
      "Epoch 1912 / 10000 loss: 70.75726699829102\n",
      "MSE train 3.494760594118663 MSE test 6.866445669414102\n",
      "Epoch 1913 / 10000 loss: 70.74341130256653\n",
      "MSE train 3.4941561546077584 MSE test 6.86590734059452\n",
      "Epoch 1914 / 10000 loss: 70.73014998435974\n",
      "MSE train 3.4935673173703465 MSE test 6.865373274108491\n",
      "Epoch 1915 / 10000 loss: 70.71742677688599\n",
      "MSE train 3.4929867849201934 MSE test 6.86484251516109\n",
      "Epoch 1916 / 10000 loss: 70.70504260063171\n",
      "MSE train 3.492410318233041 MSE test 6.864314353932588\n",
      "Epoch 1917 / 10000 loss: 70.69283819198608\n",
      "MSE train 3.4918355855361956 MSE test 6.8637883338959\n",
      "Epoch 1918 / 10000 loss: 70.68072390556335\n",
      "MSE train 3.4912613805640924 MSE test 6.863263986526865\n",
      "Epoch 1919 / 10000 loss: 70.66865253448486\n",
      "MSE train 3.490687069645603 MSE test 6.862741088773261\n",
      "Epoch 1920 / 10000 loss: 70.65659356117249\n",
      "MSE train 3.4901119162728533 MSE test 6.862219295223781\n",
      "Epoch 1921 / 10000 loss: 70.64453506469727\n",
      "MSE train 3.4895345617069173 MSE test 6.861698381736441\n",
      "Epoch 1922 / 10000 loss: 70.63246369361877\n",
      "MSE train 3.4889528993474594 MSE test 6.8611780129793845\n",
      "Epoch 1923 / 10000 loss: 70.62034869194031\n",
      "MSE train 3.48836446928224 MSE test 6.860657797453048\n",
      "Epoch 1924 / 10000 loss: 70.60814452171326\n",
      "MSE train 3.487767075665989 MSE test 6.860137380042962\n",
      "Epoch 1925 / 10000 loss: 70.59580135345459\n",
      "MSE train 3.4871594150911687 MSE test 6.859616426532473\n",
      "Epoch 1926 / 10000 loss: 70.58326435089111\n",
      "MSE train 3.486541400183396 MSE test 6.8590948074358655\n",
      "Epoch 1927 / 10000 loss: 70.57051277160645\n",
      "MSE train 3.485914315384263 MSE test 6.858572383844567\n",
      "Epoch 1928 / 10000 loss: 70.55754113197327\n",
      "MSE train 3.4852804162539828 MSE test 6.858049299489354\n",
      "Epoch 1929 / 10000 loss: 70.54437375068665\n",
      "MSE train 3.4846423334690035 MSE test 6.857526020117953\n",
      "Epoch 1930 / 10000 loss: 70.5310652256012\n",
      "MSE train 3.484002484065376 MSE test 6.857003017331623\n",
      "Epoch 1931 / 10000 loss: 70.51767206192017\n",
      "MSE train 3.4833628865109305 MSE test 6.856480713278584\n",
      "Epoch 1932 / 10000 loss: 70.50424313545227\n",
      "MSE train 3.482725073714224 MSE test 6.855959670570953\n",
      "Epoch 1933 / 10000 loss: 70.49082612991333\n",
      "MSE train 3.482089236464025 MSE test 6.855440007957072\n",
      "Epoch 1934 / 10000 loss: 70.4774477481842\n",
      "MSE train 3.481452462455674 MSE test 6.854921307014134\n",
      "Epoch 1935 / 10000 loss: 70.4641125202179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.480803870094021 MSE test 6.854402370242024\n",
      "Epoch 1936 / 10000 loss: 70.45074558258057\n",
      "MSE train 3.480106403017708 MSE test 6.853880522063954\n",
      "Epoch 1937 / 10000 loss: 70.4371166229248\n",
      "MSE train 3.4792988214517617 MSE test 6.853350490760903\n",
      "Epoch 1938 / 10000 loss: 70.42242002487183\n",
      "MSE train 3.4786020510730213 MSE test 6.852823377111746\n",
      "Epoch 1939 / 10000 loss: 70.40532302856445\n",
      "MSE train 3.4779433493056517 MSE test 6.852307925515758\n",
      "Epoch 1940 / 10000 loss: 70.39062666893005\n",
      "MSE train 3.4772276495895458 MSE test 6.851788749620321\n",
      "Epoch 1941 / 10000 loss: 70.37675642967224\n",
      "MSE train 3.4763380211067676 MSE test 6.851258593199141\n",
      "Epoch 1942 / 10000 loss: 70.3616533279419\n",
      "MSE train 3.4754286514663084 MSE test 6.850714433908702\n",
      "Epoch 1943 / 10000 loss: 70.3427963256836\n",
      "MSE train 3.4745892728350283 MSE test 6.85018689220426\n",
      "Epoch 1944 / 10000 loss: 70.32355260848999\n",
      "MSE train 3.473888378001399 MSE test 6.849672407720819\n",
      "Epoch 1945 / 10000 loss: 70.30577349662781\n",
      "MSE train 3.4732004206994054 MSE test 6.849165345724585\n",
      "Epoch 1946 / 10000 loss: 70.2909746170044\n",
      "MSE train 3.4725020127159816 MSE test 6.8486595676199435\n",
      "Epoch 1947 / 10000 loss: 70.2764482498169\n",
      "MSE train 3.471805082397932 MSE test 6.848154594601792\n",
      "Epoch 1948 / 10000 loss: 70.26169490814209\n",
      "MSE train 3.471131090971352 MSE test 6.847651653455488\n",
      "Epoch 1949 / 10000 loss: 70.24697256088257\n",
      "MSE train 3.470489566355958 MSE test 6.847152267545093\n",
      "Epoch 1950 / 10000 loss: 70.232750415802\n",
      "MSE train 3.4698747853224683 MSE test 6.846656771344943\n",
      "Epoch 1951 / 10000 loss: 70.21923112869263\n",
      "MSE train 3.469277306382069 MSE test 6.846164001473043\n",
      "Epoch 1952 / 10000 loss: 70.20628952980042\n",
      "MSE train 3.4686891697508626 MSE test 6.845672708223143\n",
      "Epoch 1953 / 10000 loss: 70.1937243938446\n",
      "MSE train 3.4681027836338583 MSE test 6.845181663852724\n",
      "Epoch 1954 / 10000 loss: 70.18136072158813\n",
      "MSE train 3.4675108611624674 MSE test 6.8446899772369\n",
      "Epoch 1955 / 10000 loss: 70.16903448104858\n",
      "MSE train 3.4669076358399407 MSE test 6.844196670629431\n",
      "Epoch 1956 / 10000 loss: 70.15658760070801\n",
      "MSE train 3.4662908729000055 MSE test 6.84370161902613\n",
      "Epoch 1957 / 10000 loss: 70.14389514923096\n",
      "MSE train 3.465664101896579 MSE test 6.84320522526464\n",
      "Epoch 1958 / 10000 loss: 70.13091158866882\n",
      "MSE train 3.465035136274241 MSE test 6.842708799532987\n",
      "Epoch 1959 / 10000 loss: 70.1177110671997\n",
      "MSE train 3.464409758011019 MSE test 6.84221355051305\n",
      "Epoch 1960 / 10000 loss: 70.10446500778198\n",
      "MSE train 3.4637892928289786 MSE test 6.841720095061989\n",
      "Epoch 1961 / 10000 loss: 70.09129881858826\n",
      "MSE train 3.463173524101687 MSE test 6.841228382068301\n",
      "Epoch 1962 / 10000 loss: 70.07824683189392\n",
      "MSE train 3.4625616589949644 MSE test 6.840738421717315\n",
      "Epoch 1963 / 10000 loss: 70.0652985572815\n",
      "MSE train 3.4619527603869185 MSE test 6.840250218291841\n",
      "Epoch 1964 / 10000 loss: 70.05243968963623\n",
      "MSE train 3.461348702855571 MSE test 6.839763926975197\n",
      "Epoch 1965 / 10000 loss: 70.0396511554718\n",
      "MSE train 3.4607552716703003 MSE test 6.839280071857042\n",
      "Epoch 1966 / 10000 loss: 70.02697086334229\n",
      "MSE train 3.460175981072969 MSE test 6.838799082811877\n",
      "Epoch 1967 / 10000 loss: 70.0145251750946\n",
      "MSE train 3.4596080713555573 MSE test 6.838320960384877\n",
      "Epoch 1968 / 10000 loss: 70.00238990783691\n",
      "MSE train 3.459048322499411 MSE test 6.837845306480649\n",
      "Epoch 1969 / 10000 loss: 69.99050521850586\n",
      "MSE train 3.458498261061316 MSE test 6.837371816644953\n",
      "Epoch 1970 / 10000 loss: 69.97880101203918\n",
      "MSE train 3.457961269155265 MSE test 6.836900399204293\n",
      "Epoch 1971 / 10000 loss: 69.96731114387512\n",
      "MSE train 3.4574369947034804 MSE test 6.8364310262486505\n",
      "Epoch 1972 / 10000 loss: 69.95610356330872\n",
      "MSE train 3.4569216347843708 MSE test 6.835963379966961\n",
      "Epoch 1973 / 10000 loss: 69.94517731666565\n",
      "MSE train 3.45641134247103 MSE test 6.835497128152495\n",
      "Epoch 1974 / 10000 loss: 69.93443989753723\n",
      "MSE train 3.4559036266214953 MSE test 6.83503198233838\n",
      "Epoch 1975 / 10000 loss: 69.92381405830383\n",
      "MSE train 3.45539714143386 MSE test 6.834567782798227\n",
      "Epoch 1976 / 10000 loss: 69.91323637962341\n",
      "MSE train 3.454891322475772 MSE test 6.83410432691286\n",
      "Epoch 1977 / 10000 loss: 69.90268564224243\n",
      "MSE train 3.4543859214961374 MSE test 6.833641473853788\n",
      "Epoch 1978 / 10000 loss: 69.89214086532593\n",
      "MSE train 3.4538805986489436 MSE test 6.833179004162911\n",
      "Epoch 1979 / 10000 loss: 69.88160037994385\n",
      "MSE train 3.453374344162207 MSE test 6.832716643628253\n",
      "Epoch 1980 / 10000 loss: 69.87105941772461\n",
      "MSE train 3.452864279296867 MSE test 6.832253843353131\n",
      "Epoch 1981 / 10000 loss: 69.86049151420593\n",
      "MSE train 3.452342972951517 MSE test 6.831789937198093\n",
      "Epoch 1982 / 10000 loss: 69.84983468055725\n",
      "MSE train 3.4517934448097116 MSE test 6.8313238464055885\n",
      "Epoch 1983 / 10000 loss: 69.83893251419067\n",
      "MSE train 3.4512078943920526 MSE test 6.830854421245395\n",
      "Epoch 1984 / 10000 loss: 69.82741498947144\n",
      "MSE train 3.450664968264159 MSE test 6.830385487906245\n",
      "Epoch 1985 / 10000 loss: 69.81511282920837\n",
      "MSE train 3.450163326038428 MSE test 6.82992146680329\n",
      "Epoch 1986 / 10000 loss: 69.80373430252075\n",
      "MSE train 3.4496632061088786 MSE test 6.829458052194379\n",
      "Epoch 1987 / 10000 loss: 69.79324865341187\n",
      "MSE train 3.4491586318909477 MSE test 6.828993941496901\n",
      "Epoch 1988 / 10000 loss: 69.78279542922974\n",
      "MSE train 3.4486471363534954 MSE test 6.828528640778507\n",
      "Epoch 1989 / 10000 loss: 69.77224540710449\n",
      "MSE train 3.4481266708578473 MSE test 6.828061662612747\n",
      "Epoch 1990 / 10000 loss: 69.76154828071594\n",
      "MSE train 3.4475952665389125 MSE test 6.827592775454384\n",
      "Epoch 1991 / 10000 loss: 69.75065493583679\n",
      "MSE train 3.4470508530611834 MSE test 6.827121639229491\n",
      "Epoch 1992 / 10000 loss: 69.73953080177307\n",
      "MSE train 3.4464912522306697 MSE test 6.8266481474466945\n",
      "Epoch 1993 / 10000 loss: 69.72812342643738\n",
      "MSE train 3.445914231829842 MSE test 6.826172048606777\n",
      "Epoch 1994 / 10000 loss: 69.71639561653137\n",
      "MSE train 3.4453175766128887 MSE test 6.825693119869769\n",
      "Epoch 1995 / 10000 loss: 69.7042932510376\n",
      "MSE train 3.4446991618643943 MSE test 6.825211138030678\n",
      "Epoch 1996 / 10000 loss: 69.69176840782166\n",
      "MSE train 3.4440569515902193 MSE test 6.824726016238018\n",
      "Epoch 1997 / 10000 loss: 69.67877840995789\n",
      "MSE train 3.443389051022538 MSE test 6.82423753708228\n",
      "Epoch 1998 / 10000 loss: 69.6652729511261\n",
      "MSE train 3.442694742223146 MSE test 6.823745792786893\n",
      "Epoch 1999 / 10000 loss: 69.65121626853943\n",
      "MSE train 3.4419793769005875 MSE test 6.823250895891976\n",
      "Epoch 2000 / 10000 loss: 69.63658571243286\n",
      "MSE train 3.441260294221133 MSE test 6.822753317943729\n",
      "Epoch 2001 / 10000 loss: 69.62149715423584\n",
      "MSE train 3.4405565230876376 MSE test 6.822253770157988\n",
      "Epoch 2002 / 10000 loss: 69.60631847381592\n",
      "MSE train 3.439871415768235 MSE test 6.8217526713821615\n",
      "Epoch 2003 / 10000 loss: 69.59146690368652\n",
      "MSE train 3.4391996843603416 MSE test 6.82125001480436\n",
      "Epoch 2004 / 10000 loss: 69.57701253890991\n",
      "MSE train 3.4385369348118315 MSE test 6.820745611476987\n",
      "Epoch 2005 / 10000 loss: 69.56283926963806\n",
      "MSE train 3.437880598265079 MSE test 6.820239300039763\n",
      "Epoch 2006 / 10000 loss: 69.54885745048523\n",
      "MSE train 3.437229003558532 MSE test 6.819730770821659\n",
      "Epoch 2007 / 10000 loss: 69.53500580787659\n",
      "MSE train 3.4365808080601563 MSE test 6.819219571664519\n",
      "Epoch 2008 / 10000 loss: 69.52125120162964\n",
      "MSE train 3.4359345044559935 MSE test 6.818704950630833\n",
      "Epoch 2009 / 10000 loss: 69.50756859779358\n",
      "MSE train 3.4352866195828926 MSE test 6.818185729624522\n",
      "Epoch 2010 / 10000 loss: 69.49391841888428\n",
      "MSE train 3.4346289497744085 MSE test 6.817660367684118\n",
      "Epoch 2011 / 10000 loss: 69.48023557662964\n",
      "MSE train 3.433947407383241 MSE test 6.817126684450651\n",
      "Epoch 2012 / 10000 loss: 69.46633982658386\n",
      "MSE train 3.4332337504610835 MSE test 6.816584224014026\n",
      "Epoch 2013 / 10000 loss: 69.45192360877991\n",
      "MSE train 3.4325222347202646 MSE test 6.816040235926925\n",
      "Epoch 2014 / 10000 loss: 69.43681120872498\n",
      "MSE train 3.4318441622212807 MSE test 6.815508450935829\n",
      "Epoch 2015 / 10000 loss: 69.42174100875854\n",
      "MSE train 3.431175933311736 MSE test 6.814987427128455\n",
      "Epoch 2016 / 10000 loss: 69.40739297866821\n",
      "MSE train 3.4305046714380474 MSE test 6.814472026326605\n",
      "Epoch 2017 / 10000 loss: 69.39325881004333\n",
      "MSE train 3.4298305750056644 MSE test 6.8139603702334215\n",
      "Epoch 2018 / 10000 loss: 69.37905740737915\n",
      "MSE train 3.4291566452219544 MSE test 6.813452020578821\n",
      "Epoch 2019 / 10000 loss: 69.36479425430298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.4284844077956262 MSE test 6.812946673553258\n",
      "Epoch 2020 / 10000 loss: 69.35053610801697\n",
      "MSE train 3.427817028722767 MSE test 6.812443835882553\n",
      "Epoch 2021 / 10000 loss: 69.33631372451782\n",
      "MSE train 3.427162191492007 MSE test 6.811942942529858\n",
      "Epoch 2022 / 10000 loss: 69.32219862937927\n",
      "MSE train 3.426524548895067 MSE test 6.811443532619381\n",
      "Epoch 2023 / 10000 loss: 69.30835723876953\n",
      "MSE train 3.4259004761040726 MSE test 6.8109449625023\n",
      "Epoch 2024 / 10000 loss: 69.2948911190033\n",
      "MSE train 3.425283716594009 MSE test 6.810446556275255\n",
      "Epoch 2025 / 10000 loss: 69.28171992301941\n",
      "MSE train 3.4246693307532894 MSE test 6.80994777714034\n",
      "Epoch 2026 / 10000 loss: 69.26870799064636\n",
      "MSE train 3.424053374660582 MSE test 6.809448109391782\n",
      "Epoch 2027 / 10000 loss: 69.25574803352356\n",
      "MSE train 3.423431617747142 MSE test 6.8089471108712125\n",
      "Epoch 2028 / 10000 loss: 69.24275970458984\n",
      "MSE train 3.4227987125958412 MSE test 6.808444226193553\n",
      "Epoch 2029 / 10000 loss: 69.22964668273926\n",
      "MSE train 3.4221480819714714 MSE test 6.807938859790314\n",
      "Epoch 2030 / 10000 loss: 69.21629595756531\n",
      "MSE train 3.4214731516109858 MSE test 6.807430478488972\n",
      "Epoch 2031 / 10000 loss: 69.2025694847107\n",
      "MSE train 3.4207718004905434 MSE test 6.806919019454573\n",
      "Epoch 2032 / 10000 loss: 69.18832206726074\n",
      "MSE train 3.4200529291214035 MSE test 6.806405165439142\n",
      "Epoch 2033 / 10000 loss: 69.17351269721985\n",
      "MSE train 3.419334177292504 MSE test 6.805890406894803\n",
      "Epoch 2034 / 10000 loss: 69.15833353996277\n",
      "MSE train 3.4186263047273564 MSE test 6.805375921692972\n",
      "Epoch 2035 / 10000 loss: 69.14316391944885\n",
      "MSE train 3.417921422467618 MSE test 6.804861766319287\n",
      "Epoch 2036 / 10000 loss: 69.12823128700256\n",
      "MSE train 3.417204430179283 MSE test 6.804347636577677\n",
      "Epoch 2037 / 10000 loss: 69.11335945129395\n",
      "MSE train 3.4164794938267447 MSE test 6.8038329802772575\n",
      "Epoch 2038 / 10000 loss: 69.098224401474\n",
      "MSE train 3.4157698175728917 MSE test 6.803317766362045\n",
      "Epoch 2039 / 10000 loss: 69.08292007446289\n",
      "MSE train 3.4150729342075183 MSE test 6.802801899024837\n",
      "Epoch 2040 / 10000 loss: 69.06794285774231\n",
      "MSE train 3.4143776573312787 MSE test 6.802285048105569\n",
      "Epoch 2041 / 10000 loss: 69.05323433876038\n",
      "MSE train 3.413689964280565 MSE test 6.801766687427887\n",
      "Epoch 2042 / 10000 loss: 69.03855848312378\n",
      "MSE train 3.4130108644720885 MSE test 6.801245979285225\n",
      "Epoch 2043 / 10000 loss: 69.02405118942261\n",
      "MSE train 3.4123128713871913 MSE test 6.800720791238853\n",
      "Epoch 2044 / 10000 loss: 69.00972843170166\n",
      "MSE train 3.411498607778088 MSE test 6.800185143864548\n",
      "Epoch 2045 / 10000 loss: 68.99500918388367\n",
      "MSE train 3.410717262899413 MSE test 6.799636593375771\n",
      "Epoch 2046 / 10000 loss: 68.97779107093811\n",
      "MSE train 3.4100483827809436 MSE test 6.799118965959677\n",
      "Epoch 2047 / 10000 loss: 68.96126890182495\n",
      "MSE train 3.409370383065947 MSE test 6.798600391833982\n",
      "Epoch 2048 / 10000 loss: 68.94715476036072\n",
      "MSE train 3.4086835023131314 MSE test 6.79808114425132\n",
      "Epoch 2049 / 10000 loss: 68.9328441619873\n",
      "MSE train 3.407989247943618 MSE test 6.797561821643355\n",
      "Epoch 2050 / 10000 loss: 68.91834235191345\n",
      "MSE train 3.407289556153925 MSE test 6.797042944434412\n",
      "Epoch 2051 / 10000 loss: 68.90368127822876\n",
      "MSE train 3.4065863179555955 MSE test 6.7965249840736\n",
      "Epoch 2052 / 10000 loss: 68.88890290260315\n",
      "MSE train 3.405881662806175 MSE test 6.796008066931922\n",
      "Epoch 2053 / 10000 loss: 68.87404799461365\n",
      "MSE train 3.4051782130400343 MSE test 6.79549213469587\n",
      "Epoch 2054 / 10000 loss: 68.8591570854187\n",
      "MSE train 3.4044786602047297 MSE test 6.794977142794332\n",
      "Epoch 2055 / 10000 loss: 68.84429264068604\n",
      "MSE train 3.403784839175774 MSE test 6.794463020426091\n",
      "Epoch 2056 / 10000 loss: 68.82950687408447\n",
      "MSE train 3.4030973668248974 MSE test 6.793949442655645\n",
      "Epoch 2057 / 10000 loss: 68.8148443698883\n",
      "MSE train 3.4024160680627737 MSE test 6.793436243673754\n",
      "Epoch 2058 / 10000 loss: 68.8003146648407\n",
      "MSE train 3.401740483196061 MSE test 6.792923158881786\n",
      "Epoch 2059 / 10000 loss: 68.78591704368591\n",
      "MSE train 3.401070100317815 MSE test 6.792409933541932\n",
      "Epoch 2060 / 10000 loss: 68.77163982391357\n",
      "MSE train 3.400404424074988 MSE test 6.79189651248414\n",
      "Epoch 2061 / 10000 loss: 68.75747394561768\n",
      "MSE train 3.399742846622996 MSE test 6.791382887507932\n",
      "Epoch 2062 / 10000 loss: 68.74340724945068\n",
      "MSE train 3.399084586227515 MSE test 6.790869163399409\n",
      "Epoch 2063 / 10000 loss: 68.72942805290222\n",
      "MSE train 3.3984284961147977 MSE test 6.790355469952016\n",
      "Epoch 2064 / 10000 loss: 68.71552205085754\n",
      "MSE train 3.3977730084665523 MSE test 6.789841951355333\n",
      "Epoch 2065 / 10000 loss: 68.70166397094727\n",
      "MSE train 3.3971165717626746 MSE test 6.78932888517432\n",
      "Epoch 2066 / 10000 loss: 68.68781805038452\n",
      "MSE train 3.396458790419588 MSE test 6.788816293535179\n",
      "Epoch 2067 / 10000 loss: 68.67395496368408\n",
      "MSE train 3.395801686479288 MSE test 6.788304582517747\n",
      "Epoch 2068 / 10000 loss: 68.6600615978241\n",
      "MSE train 3.3951487781932856 MSE test 6.7877938848392\n",
      "Epoch 2069 / 10000 loss: 68.64618444442749\n",
      "MSE train 3.3945019057521977 MSE test 6.7872844053562815\n",
      "Epoch 2070 / 10000 loss: 68.63239789009094\n",
      "MSE train 3.393859435198787 MSE test 6.786776271278455\n",
      "Epoch 2071 / 10000 loss: 68.61873507499695\n",
      "MSE train 3.3932180162546164 MSE test 6.786269195009637\n",
      "Epoch 2072 / 10000 loss: 68.60516119003296\n",
      "MSE train 3.39257423170549 MSE test 6.7857631326115335\n",
      "Epoch 2073 / 10000 loss: 68.59160494804382\n",
      "MSE train 3.3919248986939614 MSE test 6.7852580308296675\n",
      "Epoch 2074 / 10000 loss: 68.57799530029297\n",
      "MSE train 3.3912671916824735 MSE test 6.784753664400102\n",
      "Epoch 2075 / 10000 loss: 68.5642638206482\n",
      "MSE train 3.390599534330401 MSE test 6.7842497348642965\n",
      "Epoch 2076 / 10000 loss: 68.55034613609314\n",
      "MSE train 3.3899230713929107 MSE test 6.783746113922344\n",
      "Epoch 2077 / 10000 loss: 68.53621435165405\n",
      "MSE train 3.3892406923883738 MSE test 6.783242464091321\n",
      "Epoch 2078 / 10000 loss: 68.5218870639801\n",
      "MSE train 3.3885515742501555 MSE test 6.782738260271531\n",
      "Epoch 2079 / 10000 loss: 68.50742745399475\n",
      "MSE train 3.387846877944172 MSE test 6.782232873010029\n",
      "Epoch 2080 / 10000 loss: 68.49282169342041\n",
      "MSE train 3.387113429548092 MSE test 6.781725686138402\n",
      "Epoch 2081 / 10000 loss: 68.47787499427795\n",
      "MSE train 3.386347831055087 MSE test 6.781216631177592\n",
      "Epoch 2082 / 10000 loss: 68.4623007774353\n",
      "MSE train 3.3855826223196717 MSE test 6.78070790257999\n",
      "Epoch 2083 / 10000 loss: 68.44602918624878\n",
      "MSE train 3.384869105868998 MSE test 6.78020388867142\n",
      "Epoch 2084 / 10000 loss: 68.42976546287537\n",
      "MSE train 3.384203136062867 MSE test 6.7797060430283365\n",
      "Epoch 2085 / 10000 loss: 68.41462850570679\n",
      "MSE train 3.3835614684321427 MSE test 6.779212147204127\n",
      "Epoch 2086 / 10000 loss: 68.40052604675293\n",
      "MSE train 3.3829296875194985 MSE test 6.7787205021500805\n",
      "Epoch 2087 / 10000 loss: 68.38695240020752\n",
      "MSE train 3.382296951439598 MSE test 6.778229902198895\n",
      "Epoch 2088 / 10000 loss: 68.37359142303467\n",
      "MSE train 3.3816535443527704 MSE test 6.777739454278929\n",
      "Epoch 2089 / 10000 loss: 68.36021113395691\n",
      "MSE train 3.3809922431225727 MSE test 6.777248480508572\n",
      "Epoch 2090 / 10000 loss: 68.34660005569458\n",
      "MSE train 3.3803192091784187 MSE test 6.776756555916531\n",
      "Epoch 2091 / 10000 loss: 68.33260321617126\n",
      "MSE train 3.3796573807586765 MSE test 6.776263294741241\n",
      "Epoch 2092 / 10000 loss: 68.31834959983826\n",
      "MSE train 3.379012035486281 MSE test 6.775768482918963\n",
      "Epoch 2093 / 10000 loss: 68.30434155464172\n",
      "MSE train 3.3783704063370865 MSE test 6.775272095604677\n",
      "Epoch 2094 / 10000 loss: 68.29069304466248\n",
      "MSE train 3.377725085298629 MSE test 6.774774075553829\n",
      "Epoch 2095 / 10000 loss: 68.27712774276733\n",
      "MSE train 3.3770745952706 MSE test 6.774274575062887\n",
      "Epoch 2096 / 10000 loss: 68.26348423957825\n",
      "MSE train 3.3764207131786597 MSE test 6.773774076141213\n",
      "Epoch 2097 / 10000 loss: 68.24973273277283\n",
      "MSE train 3.3757667627953976 MSE test 6.773273076038502\n",
      "Epoch 2098 / 10000 loss: 68.23590970039368\n",
      "MSE train 3.375115968377646 MSE test 6.772772063287774\n",
      "Epoch 2099 / 10000 loss: 68.22208642959595\n",
      "MSE train 3.374469999717048 MSE test 6.772271324325271\n",
      "Epoch 2100 / 10000 loss: 68.20833015441895\n",
      "MSE train 3.3738280891488426 MSE test 6.7717706782357645\n",
      "Epoch 2101 / 10000 loss: 68.19467782974243\n",
      "MSE train 3.3731867063555283 MSE test 6.771269926813528\n",
      "Epoch 2102 / 10000 loss: 68.18111157417297\n",
      "MSE train 3.372541983377061 MSE test 6.7707686454519465\n",
      "Epoch 2103 / 10000 loss: 68.16755604743958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.371901118984133 MSE test 6.770267375097035\n",
      "Epoch 2104 / 10000 loss: 68.15392827987671\n",
      "MSE train 3.3712872013399813 MSE test 6.769768037548722\n",
      "Epoch 2105 / 10000 loss: 68.1403865814209\n",
      "MSE train 3.3707067823935755 MSE test 6.769272365205915\n",
      "Epoch 2106 / 10000 loss: 68.12743067741394\n",
      "MSE train 3.370146593289524 MSE test 6.768779567939345\n",
      "Epoch 2107 / 10000 loss: 68.1152036190033\n",
      "MSE train 3.3695967304037375 MSE test 6.768288290412574\n",
      "Epoch 2108 / 10000 loss: 68.10341262817383\n",
      "MSE train 3.369052271225642 MSE test 6.767797706146685\n",
      "Epoch 2109 / 10000 loss: 68.09184432029724\n",
      "MSE train 3.368510405828184 MSE test 6.767307212521628\n",
      "Epoch 2110 / 10000 loss: 68.08039736747742\n",
      "MSE train 3.3679691801264986 MSE test 6.76681648088036\n",
      "Epoch 2111 / 10000 loss: 68.0690085887909\n",
      "MSE train 3.36742682305993 MSE test 6.7663250966075505\n",
      "Epoch 2112 / 10000 loss: 68.05763268470764\n",
      "MSE train 3.3668814370496194 MSE test 6.7658328500217735\n",
      "Epoch 2113 / 10000 loss: 68.04623651504517\n",
      "MSE train 3.3663308234407703 MSE test 6.765339298252931\n",
      "Epoch 2114 / 10000 loss: 68.03477430343628\n",
      "MSE train 3.365772545618415 MSE test 6.7648442324250535\n",
      "Epoch 2115 / 10000 loss: 68.02320432662964\n",
      "MSE train 3.3652040470414737 MSE test 6.764347091118029\n",
      "Epoch 2116 / 10000 loss: 68.01146864891052\n",
      "MSE train 3.36462263030813 MSE test 6.7638475573523715\n",
      "Epoch 2117 / 10000 loss: 67.99951481819153\n",
      "MSE train 3.364025647059514 MSE test 6.763345532271951\n",
      "Epoch 2118 / 10000 loss: 67.98728513717651\n",
      "MSE train 3.363412936190876 MSE test 6.762840976698133\n",
      "Epoch 2119 / 10000 loss: 67.9747200012207\n",
      "MSE train 3.3627927580827515 MSE test 6.762334517430778\n",
      "Epoch 2120 / 10000 loss: 67.96182298660278\n",
      "MSE train 3.362180176897897 MSE test 6.761827578746248\n",
      "Epoch 2121 / 10000 loss: 67.94876146316528\n",
      "MSE train 3.361580894325783 MSE test 6.761321493892988\n",
      "Epoch 2122 / 10000 loss: 67.93587136268616\n",
      "MSE train 3.360990417201605 MSE test 6.760817132285139\n",
      "Epoch 2123 / 10000 loss: 67.92326402664185\n",
      "MSE train 3.3604051722964803 MSE test 6.760315250017905\n",
      "Epoch 2124 / 10000 loss: 67.91085004806519\n",
      "MSE train 3.359824955013022 MSE test 6.759816272079336\n",
      "Epoch 2125 / 10000 loss: 67.8985505104065\n",
      "MSE train 3.359251117517391 MSE test 6.759320567913263\n",
      "Epoch 2126 / 10000 loss: 67.88636326789856\n",
      "MSE train 3.358685035850277 MSE test 6.758828323409697\n",
      "Epoch 2127 / 10000 loss: 67.87431454658508\n",
      "MSE train 3.358127168081353 MSE test 6.7583395610897306\n",
      "Epoch 2128 / 10000 loss: 67.86243462562561\n",
      "MSE train 3.3575768939009976 MSE test 6.757854090368856\n",
      "Epoch 2129 / 10000 loss: 67.85073709487915\n",
      "MSE train 3.357032729243007 MSE test 6.757371492655393\n",
      "Epoch 2130 / 10000 loss: 67.83920788764954\n",
      "MSE train 3.356492659545379 MSE test 6.756891218831628\n",
      "Epoch 2131 / 10000 loss: 67.82781291007996\n",
      "MSE train 3.3559544752301043 MSE test 6.756412631841515\n",
      "Epoch 2132 / 10000 loss: 67.81651544570923\n",
      "MSE train 3.3554159254556017 MSE test 6.755935181607146\n",
      "Epoch 2133 / 10000 loss: 67.80526161193848\n",
      "MSE train 3.354874787279986 MSE test 6.755458143849909\n",
      "Epoch 2134 / 10000 loss: 67.7940080165863\n",
      "MSE train 3.3543288444512385 MSE test 6.754980813582724\n",
      "Epoch 2135 / 10000 loss: 67.782705783844\n",
      "MSE train 3.3537758776134936 MSE test 6.754502522612589\n",
      "Epoch 2136 / 10000 loss: 67.77130341529846\n",
      "MSE train 3.3532136163930244 MSE test 6.754022499541219\n",
      "Epoch 2137 / 10000 loss: 67.759756565094\n",
      "MSE train 3.3526397784896136 MSE test 6.753540140003931\n",
      "Epoch 2138 / 10000 loss: 67.74801468849182\n",
      "MSE train 3.3520523966606977 MSE test 6.753054910313886\n",
      "Epoch 2139 / 10000 loss: 67.73602318763733\n",
      "MSE train 3.3514509995514623 MSE test 6.752566705193897\n",
      "Epoch 2140 / 10000 loss: 67.7237377166748\n",
      "MSE train 3.3508388505799536 MSE test 6.752076212904418\n",
      "Epoch 2141 / 10000 loss: 67.71114659309387\n",
      "MSE train 3.3502241775364534 MSE test 6.751585387070213\n",
      "Epoch 2142 / 10000 loss: 67.69831395149231\n",
      "MSE train 3.3496168576491807 MSE test 6.751096670629646\n",
      "Epoch 2143 / 10000 loss: 67.6854236125946\n",
      "MSE train 3.3490233018568016 MSE test 6.750611909046136\n",
      "Epoch 2144 / 10000 loss: 67.672682762146\n",
      "MSE train 3.3484454193197566 MSE test 6.750131498915866\n",
      "Epoch 2145 / 10000 loss: 67.6602303981781\n",
      "MSE train 3.347881373170726 MSE test 6.749654980145632\n",
      "Epoch 2146 / 10000 loss: 67.64811658859253\n",
      "MSE train 3.347327184658429 MSE test 6.749181762637449\n",
      "Epoch 2147 / 10000 loss: 67.63629198074341\n",
      "MSE train 3.3467786894802365 MSE test 6.748711009790497\n",
      "Epoch 2148 / 10000 loss: 67.62467813491821\n",
      "MSE train 3.3462326009197954 MSE test 6.7482420309249544\n",
      "Epoch 2149 / 10000 loss: 67.6131865978241\n",
      "MSE train 3.3456866154609863 MSE test 6.747774328016422\n",
      "Epoch 2150 / 10000 loss: 67.60174512863159\n",
      "MSE train 3.3451392695902475 MSE test 6.747307620684031\n",
      "Epoch 2151 / 10000 loss: 67.5903046131134\n",
      "MSE train 3.3445897806953035 MSE test 6.746841480752776\n",
      "Epoch 2152 / 10000 loss: 67.57883358001709\n",
      "MSE train 3.3440379710191652 MSE test 6.746375753881779\n",
      "Epoch 2153 / 10000 loss: 67.56731486320496\n",
      "MSE train 3.343484103322862 MSE test 6.745910458336925\n",
      "Epoch 2154 / 10000 loss: 67.5557472705841\n",
      "MSE train 3.342928731807595 MSE test 6.745445369973394\n",
      "Epoch 2155 / 10000 loss: 67.5441324710846\n",
      "MSE train 3.342372496052171 MSE test 6.744980561114671\n",
      "Epoch 2156 / 10000 loss: 67.53248500823975\n",
      "MSE train 3.3418159313094593 MSE test 6.744516114463355\n",
      "Epoch 2157 / 10000 loss: 67.52081537246704\n",
      "MSE train 3.341259316705747 MSE test 6.744052004503833\n",
      "Epoch 2158 / 10000 loss: 67.50913715362549\n",
      "MSE train 3.3407027866204086 MSE test 6.743588218951899\n",
      "Epoch 2159 / 10000 loss: 67.49745035171509\n",
      "MSE train 3.34014655066022 MSE test 6.743124631552943\n",
      "Epoch 2160 / 10000 loss: 67.4857656955719\n",
      "MSE train 3.339590923067497 MSE test 6.742661031055403\n",
      "Epoch 2161 / 10000 loss: 67.47408175468445\n",
      "MSE train 3.339035911748736 MSE test 6.742197098775073\n",
      "Epoch 2162 / 10000 loss: 67.46240973472595\n",
      "MSE train 3.3384800984068392 MSE test 6.741732160280551\n",
      "Epoch 2163 / 10000 loss: 67.45074796676636\n",
      "MSE train 3.3379191634922054 MSE test 6.741265092281553\n",
      "Epoch 2164 / 10000 loss: 67.43906784057617\n",
      "MSE train 3.337346492914145 MSE test 6.740794223818858\n",
      "Epoch 2165 / 10000 loss: 67.4272735118866\n",
      "MSE train 3.3367608175864483 MSE test 6.740317247281428\n",
      "Epoch 2166 / 10000 loss: 67.41522598266602\n",
      "MSE train 3.336153016147364 MSE test 6.739829314051255\n",
      "Epoch 2167 / 10000 loss: 67.4028890132904\n",
      "MSE train 3.3354140728921498 MSE test 6.739307711857336\n",
      "Epoch 2168 / 10000 loss: 67.39007377624512\n",
      "MSE train 3.3348813877837213 MSE test 6.738815296144848\n",
      "Epoch 2169 / 10000 loss: 67.37440466880798\n",
      "MSE train 3.3343898266152387 MSE test 6.738376702833717\n",
      "Epoch 2170 / 10000 loss: 67.363201379776\n",
      "MSE train 3.3339058853476047 MSE test 6.737940731149003\n",
      "Epoch 2171 / 10000 loss: 67.35288977622986\n",
      "MSE train 3.3334289010210396 MSE test 6.737506643886555\n",
      "Epoch 2172 / 10000 loss: 67.34274578094482\n",
      "MSE train 3.33295788797724 MSE test 6.737073918820206\n",
      "Epoch 2173 / 10000 loss: 67.33275175094604\n",
      "MSE train 3.3324911897324743 MSE test 6.736642145423624\n",
      "Epoch 2174 / 10000 loss: 67.32288813591003\n",
      "MSE train 3.332026533073353 MSE test 6.736210775287862\n",
      "Epoch 2175 / 10000 loss: 67.31311202049255\n",
      "MSE train 3.331561132430978 MSE test 6.735779489318192\n",
      "Epoch 2176 / 10000 loss: 67.30338644981384\n",
      "MSE train 3.3310918046117903 MSE test 6.735347786058584\n",
      "Epoch 2177 / 10000 loss: 67.2936429977417\n",
      "MSE train 3.330614827834076 MSE test 6.734915214219847\n",
      "Epoch 2178 / 10000 loss: 67.28381323814392\n",
      "MSE train 3.330125929159775 MSE test 6.7344812142401755\n",
      "Epoch 2179 / 10000 loss: 67.27382183074951\n",
      "MSE train 3.3296202377620427 MSE test 6.734045314001002\n",
      "Epoch 2180 / 10000 loss: 67.2635726928711\n",
      "MSE train 3.3290924483173674 MSE test 6.73360705741814\n",
      "Epoch 2181 / 10000 loss: 67.25296020507812\n",
      "MSE train 3.328536758213054 MSE test 6.733166160415137\n",
      "Epoch 2182 / 10000 loss: 67.24187111854553\n",
      "MSE train 3.327948809024725 MSE test 6.732722394909155\n",
      "Epoch 2183 / 10000 loss: 67.23017883300781\n",
      "MSE train 3.327345041248754 MSE test 6.732276129084011\n",
      "Epoch 2184 / 10000 loss: 67.21778917312622\n",
      "MSE train 3.3267692832721316 MSE test 6.731828775717483\n",
      "Epoch 2185 / 10000 loss: 67.20505809783936\n",
      "MSE train 3.326216469930155 MSE test 6.73138132294047\n",
      "Epoch 2186 / 10000 loss: 67.19293689727783\n",
      "MSE train 3.325666956218085 MSE test 6.730933484527378\n",
      "Epoch 2187 / 10000 loss: 67.18131256103516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.325116347358674 MSE test 6.730485482692799\n",
      "Epoch 2188 / 10000 loss: 67.16976070404053\n",
      "MSE train 3.3245650109286893 MSE test 6.730037600613283\n",
      "Epoch 2189 / 10000 loss: 67.15818619728088\n",
      "MSE train 3.3240146080911153 MSE test 6.729590429282998\n",
      "Epoch 2190 / 10000 loss: 67.14659237861633\n",
      "MSE train 3.323466678597197 MSE test 6.729144272142242\n",
      "Epoch 2191 / 10000 loss: 67.13502192497253\n",
      "MSE train 3.3229215562109236 MSE test 6.728699323052005\n",
      "Epoch 2192 / 10000 loss: 67.12350249290466\n",
      "MSE train 3.322377822135957 MSE test 6.728255492438318\n",
      "Epoch 2193 / 10000 loss: 67.11204314231873\n",
      "MSE train 3.32183222825057 MSE test 6.7278124951207445\n",
      "Epoch 2194 / 10000 loss: 67.10061120986938\n",
      "MSE train 3.321279881191209 MSE test 6.727369729735478\n",
      "Epoch 2195 / 10000 loss: 67.08913969993591\n",
      "MSE train 3.3207145049386995 MSE test 6.726926473329121\n",
      "Epoch 2196 / 10000 loss: 67.07751798629761\n",
      "MSE train 3.3201294249228432 MSE test 6.726482237205072\n",
      "Epoch 2197 / 10000 loss: 67.06561422348022\n",
      "MSE train 3.3195222810330023 MSE test 6.7260363809663035\n",
      "Epoch 2198 / 10000 loss: 67.05328249931335\n",
      "MSE train 3.3189058247433745 MSE test 6.7255892611677375\n",
      "Epoch 2199 / 10000 loss: 67.0404703617096\n",
      "MSE train 3.3183075959536303 MSE test 6.725142360788665\n",
      "Epoch 2200 / 10000 loss: 67.02745270729065\n",
      "MSE train 3.317739000253631 MSE test 6.724697071119273\n",
      "Epoch 2201 / 10000 loss: 67.01482391357422\n",
      "MSE train 3.317191061385555 MSE test 6.724253522780324\n",
      "Epoch 2202 / 10000 loss: 67.00283670425415\n",
      "MSE train 3.3166554809649598 MSE test 6.723811189232177\n",
      "Epoch 2203 / 10000 loss: 66.99129271507263\n",
      "MSE train 3.3161276141760974 MSE test 6.723369756539739\n",
      "Epoch 2204 / 10000 loss: 66.98001837730408\n",
      "MSE train 3.3156024996157463 MSE test 6.722928888238172\n",
      "Epoch 2205 / 10000 loss: 66.96890783309937\n",
      "MSE train 3.3150731307408323 MSE test 6.722488156367519\n",
      "Epoch 2206 / 10000 loss: 66.95786118507385\n",
      "MSE train 3.314532128051561 MSE test 6.722046925036142\n",
      "Epoch 2207 / 10000 loss: 66.94672346115112\n",
      "MSE train 3.313977314240138 MSE test 6.721604775695707\n",
      "Epoch 2208 / 10000 loss: 66.93533682823181\n",
      "MSE train 3.3134164214042015 MSE test 6.721161982985859\n",
      "Epoch 2209 / 10000 loss: 66.92365074157715\n",
      "MSE train 3.312862549507139 MSE test 6.720719475996298\n",
      "Epoch 2210 / 10000 loss: 66.9118299484253\n",
      "MSE train 3.3123303037337806 MSE test 6.72027918800911\n",
      "Epoch 2211 / 10000 loss: 66.90015459060669\n",
      "MSE train 3.311821441154211 MSE test 6.719842373231482\n",
      "Epoch 2212 / 10000 loss: 66.88893485069275\n",
      "MSE train 3.3113239606005673 MSE test 6.719408239806634\n",
      "Epoch 2213 / 10000 loss: 66.87821984291077\n",
      "MSE train 3.310829028856354 MSE test 6.718975432940299\n",
      "Epoch 2214 / 10000 loss: 66.86774682998657\n",
      "MSE train 3.3103327520764005 MSE test 6.718542918183038\n",
      "Epoch 2215 / 10000 loss: 66.85732340812683\n",
      "MSE train 3.3098334607840725 MSE test 6.718110179663229\n",
      "Epoch 2216 / 10000 loss: 66.84686803817749\n",
      "MSE train 3.3093303455456162 MSE test 6.717676721558001\n",
      "Epoch 2217 / 10000 loss: 66.83634805679321\n",
      "MSE train 3.308822669913955 MSE test 6.717242378445297\n",
      "Epoch 2218 / 10000 loss: 66.82574200630188\n",
      "MSE train 3.308309242118344 MSE test 6.716806769440804\n",
      "Epoch 2219 / 10000 loss: 66.81503462791443\n",
      "MSE train 3.307788057759552 MSE test 6.716369582385135\n",
      "Epoch 2220 / 10000 loss: 66.80420303344727\n",
      "MSE train 3.307256434144199 MSE test 6.715930476907978\n",
      "Epoch 2221 / 10000 loss: 66.79319834709167\n",
      "MSE train 3.3067125503743715 MSE test 6.715489243385001\n",
      "Epoch 2222 / 10000 loss: 66.78196883201599\n",
      "MSE train 3.3061594039249917 MSE test 6.7150457709163\n",
      "Epoch 2223 / 10000 loss: 66.77047157287598\n",
      "MSE train 3.3056067966790597 MSE test 6.714600476346399\n",
      "Epoch 2224 / 10000 loss: 66.75877332687378\n",
      "MSE train 3.30506294402261 MSE test 6.714153823577206\n",
      "Epoch 2225 / 10000 loss: 66.74708437919617\n",
      "MSE train 3.3045262446853885 MSE test 6.713705683662803\n",
      "Epoch 2226 / 10000 loss: 66.73558473587036\n",
      "MSE train 3.3039902826025194 MSE test 6.713255841767451\n",
      "Epoch 2227 / 10000 loss: 66.72423934936523\n",
      "MSE train 3.303448899165421 MSE test 6.712803664153184\n",
      "Epoch 2228 / 10000 loss: 66.71290922164917\n",
      "MSE train 3.302896419675208 MSE test 6.712348605503319\n",
      "Epoch 2229 / 10000 loss: 66.70146155357361\n",
      "MSE train 3.3023264830546 MSE test 6.711890268803776\n",
      "Epoch 2230 / 10000 loss: 66.68977427482605\n",
      "MSE train 3.3017320965592205 MSE test 6.711428200726792\n",
      "Epoch 2231 / 10000 loss: 66.67771315574646\n",
      "MSE train 3.3011159109211965 MSE test 6.710962491676011\n",
      "Epoch 2232 / 10000 loss: 66.66512084007263\n",
      "MSE train 3.300510497192017 MSE test 6.710495962133657\n",
      "Epoch 2233 / 10000 loss: 66.65205574035645\n",
      "MSE train 3.299937453291184 MSE test 6.710032312099569\n",
      "Epoch 2234 / 10000 loss: 66.63923120498657\n",
      "MSE train 3.299362323155801 MSE test 6.709568668018199\n",
      "Epoch 2235 / 10000 loss: 66.6271026134491\n",
      "MSE train 3.2986479099552635 MSE test 6.7090945287021055\n",
      "Epoch 2236 / 10000 loss: 66.61492967605591\n",
      "MSE train 3.2979953374598607 MSE test 6.708607423981815\n",
      "Epoch 2237 / 10000 loss: 66.5997359752655\n",
      "MSE train 3.297494271919402 MSE test 6.708169300324125\n",
      "Epoch 2238 / 10000 loss: 66.58588790893555\n",
      "MSE train 3.2969981771369943 MSE test 6.707732912813631\n",
      "Epoch 2239 / 10000 loss: 66.57532095909119\n",
      "MSE train 3.2965034660867567 MSE test 6.707297235796353\n",
      "Epoch 2240 / 10000 loss: 66.56486654281616\n",
      "MSE train 3.2960056408661207 MSE test 6.7068613628174605\n",
      "Epoch 2241 / 10000 loss: 66.55444097518921\n",
      "MSE train 3.29549886153575 MSE test 6.706424053167677\n",
      "Epoch 2242 / 10000 loss: 66.54395246505737\n",
      "MSE train 3.2949751143210873 MSE test 6.705984102525428\n",
      "Epoch 2243 / 10000 loss: 66.53327512741089\n",
      "MSE train 3.294422942337358 MSE test 6.705539947741951\n",
      "Epoch 2244 / 10000 loss: 66.5222396850586\n",
      "MSE train 3.2938295763907197 MSE test 6.70509034683538\n",
      "Epoch 2245 / 10000 loss: 66.51059341430664\n",
      "MSE train 3.293200430841998 MSE test 6.704635407346311\n",
      "Epoch 2246 / 10000 loss: 66.49806761741638\n",
      "MSE train 3.2925746391931896 MSE test 6.704179246909151\n",
      "Epoch 2247 / 10000 loss: 66.48477458953857\n",
      "MSE train 3.2919663868727547 MSE test 6.703725965360837\n",
      "Epoch 2248 / 10000 loss: 66.4715485572815\n",
      "MSE train 3.291371102639539 MSE test 6.703276029628983\n",
      "Epoch 2249 / 10000 loss: 66.45868682861328\n",
      "MSE train 3.290795231163785 MSE test 6.702830809955853\n",
      "Epoch 2250 / 10000 loss: 66.44609522819519\n",
      "MSE train 3.2902414256216446 MSE test 6.702390888849939\n",
      "Epoch 2251 / 10000 loss: 66.43391704559326\n",
      "MSE train 3.2897067986504593 MSE test 6.701955889917059\n",
      "Epoch 2252 / 10000 loss: 66.42221403121948\n",
      "MSE train 3.289187211688093 MSE test 6.701524863888856\n",
      "Epoch 2253 / 10000 loss: 66.41092371940613\n",
      "MSE train 3.2886789212988745 MSE test 6.701097207927382\n",
      "Epoch 2254 / 10000 loss: 66.39996027946472\n",
      "MSE train 3.2881787730581373 MSE test 6.70067226309454\n",
      "Epoch 2255 / 10000 loss: 66.38924026489258\n",
      "MSE train 3.287684205996135 MSE test 6.700249387862932\n",
      "Epoch 2256 / 10000 loss: 66.37869787216187\n",
      "MSE train 3.2871932402167 MSE test 6.6998280586956565\n",
      "Epoch 2257 / 10000 loss: 66.36827683448792\n",
      "MSE train 3.2867042853140256 MSE test 6.699407729326616\n",
      "Epoch 2258 / 10000 loss: 66.35793566703796\n",
      "MSE train 3.2862159387058796 MSE test 6.698987852020041\n",
      "Epoch 2259 / 10000 loss: 66.34763669967651\n",
      "MSE train 3.2857266086378405 MSE test 6.698567882846772\n",
      "Epoch 2260 / 10000 loss: 66.33735489845276\n",
      "MSE train 3.2852342442589033 MSE test 6.698147354184602\n",
      "Epoch 2261 / 10000 loss: 66.3270492553711\n",
      "MSE train 3.2847358856572626 MSE test 6.697725683867406\n",
      "Epoch 2262 / 10000 loss: 66.31668090820312\n",
      "MSE train 3.2842268998852453 MSE test 6.6973023055326175\n",
      "Epoch 2263 / 10000 loss: 66.30618381500244\n",
      "MSE train 3.28369862449253 MSE test 6.696876400489588\n",
      "Epoch 2264 / 10000 loss: 66.29545378684998\n",
      "MSE train 3.2831326492794846 MSE test 6.696446998533856\n",
      "Epoch 2265 / 10000 loss: 66.28430414199829\n",
      "MSE train 3.2825010689052023 MSE test 6.696012945871083\n",
      "Epoch 2266 / 10000 loss: 66.27233171463013\n",
      "MSE train 3.2818612577768573 MSE test 6.6955760406354505\n",
      "Epoch 2267 / 10000 loss: 66.2589499950409\n",
      "MSE train 3.281305211432374 MSE test 6.695145331526934\n",
      "Epoch 2268 / 10000 loss: 66.2454297542572\n",
      "MSE train 3.28077923159361 MSE test 6.694719543716635\n",
      "Epoch 2269 / 10000 loss: 66.23371744155884\n",
      "MSE train 3.2802721754846296 MSE test 6.694297624144126\n",
      "Epoch 2270 / 10000 loss: 66.22264385223389\n",
      "MSE train 3.2797813372102516 MSE test 6.693879283505228\n",
      "Epoch 2271 / 10000 loss: 66.21198153495789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.279302532114937 MSE test 6.693463869054298\n",
      "Epoch 2272 / 10000 loss: 66.20167350769043\n",
      "MSE train 3.278832153455177 MSE test 6.6930505784446375\n",
      "Epoch 2273 / 10000 loss: 66.19162511825562\n",
      "MSE train 3.2783677892225143 MSE test 6.69263886957989\n",
      "Epoch 2274 / 10000 loss: 66.18176603317261\n",
      "MSE train 3.2779072840514933 MSE test 6.692228122500022\n",
      "Epoch 2275 / 10000 loss: 66.17203879356384\n",
      "MSE train 3.2774480331076417 MSE test 6.691817917908214\n",
      "Epoch 2276 / 10000 loss: 66.16239881515503\n",
      "MSE train 3.276986911858625 MSE test 6.6914076132638325\n",
      "Epoch 2277 / 10000 loss: 66.1527910232544\n",
      "MSE train 3.2765206236210918 MSE test 6.690996799739492\n",
      "Epoch 2278 / 10000 loss: 66.1431450843811\n",
      "MSE train 3.2760462612855337 MSE test 6.6905850896581756\n",
      "Epoch 2279 / 10000 loss: 66.13339519500732\n",
      "MSE train 3.27556198388604 MSE test 6.690172371086911\n",
      "Epoch 2280 / 10000 loss: 66.12347078323364\n",
      "MSE train 3.275067768441745 MSE test 6.689759082570248\n",
      "Epoch 2281 / 10000 loss: 66.11333680152893\n",
      "MSE train 3.2745662267753954 MSE test 6.68934580474396\n",
      "Epoch 2282 / 10000 loss: 66.1029884815216\n",
      "MSE train 3.2740624543969283 MSE test 6.688933680710606\n",
      "Epoch 2283 / 10000 loss: 66.09247851371765\n",
      "MSE train 3.2735621705358064 MSE test 6.688523642802584\n",
      "Epoch 2284 / 10000 loss: 66.08191633224487\n",
      "MSE train 3.2730688045475556 MSE test 6.688116452184494\n",
      "Epoch 2285 / 10000 loss: 66.0714282989502\n",
      "MSE train 3.272582161032162 MSE test 6.6877123936605045\n",
      "Epoch 2286 / 10000 loss: 66.0610785484314\n",
      "MSE train 3.272099677441825 MSE test 6.687311064212798\n",
      "Epoch 2287 / 10000 loss: 66.05087184906006\n",
      "MSE train 3.2716183061266535 MSE test 6.686911828215037\n",
      "Epoch 2288 / 10000 loss: 66.04075026512146\n",
      "MSE train 3.271135601325892 MSE test 6.686513992722276\n",
      "Epoch 2289 / 10000 loss: 66.03064727783203\n",
      "MSE train 3.270649793683353 MSE test 6.686116831789354\n",
      "Epoch 2290 / 10000 loss: 66.02051329612732\n",
      "MSE train 3.270159436064305 MSE test 6.685719789494403\n",
      "Epoch 2291 / 10000 loss: 66.01031064987183\n",
      "MSE train 3.269662902943262 MSE test 6.685322204940157\n",
      "Epoch 2292 / 10000 loss: 66.00000619888306\n",
      "MSE train 3.269157803933953 MSE test 6.6849235145717865\n",
      "Epoch 2293 / 10000 loss: 65.98956775665283\n",
      "MSE train 3.2686406767666427 MSE test 6.684523117135808\n",
      "Epoch 2294 / 10000 loss: 65.97894310951233\n",
      "MSE train 3.2681079410835707 MSE test 6.6841206762296705\n",
      "Epoch 2295 / 10000 loss: 65.96805930137634\n",
      "MSE train 3.2675603008139973 MSE test 6.683716184569065\n",
      "Epoch 2296 / 10000 loss: 65.95683407783508\n",
      "MSE train 3.2670084116396776 MSE test 6.68331048121157\n",
      "Epoch 2297 / 10000 loss: 65.94529128074646\n",
      "MSE train 3.266465676483983 MSE test 6.682905114148515\n",
      "Epoch 2298 / 10000 loss: 65.93365287780762\n",
      "MSE train 3.2659333509703083 MSE test 6.682500768685356\n",
      "Epoch 2299 / 10000 loss: 65.92221522331238\n",
      "MSE train 3.265404975123641 MSE test 6.682097034503334\n",
      "Epoch 2300 / 10000 loss: 65.91100478172302\n",
      "MSE train 3.264874598855805 MSE test 6.681693428330777\n",
      "Epoch 2301 / 10000 loss: 65.89987969398499\n",
      "MSE train 3.264337789520128 MSE test 6.68128904824401\n",
      "Epoch 2302 / 10000 loss: 65.88871884346008\n",
      "MSE train 3.2637918089303395 MSE test 6.680883561757366\n",
      "Epoch 2303 / 10000 loss: 65.87742161750793\n",
      "MSE train 3.2632358571355606 MSE test 6.680476734761149\n",
      "Epoch 2304 / 10000 loss: 65.8659303188324\n",
      "MSE train 3.2626698887849557 MSE test 6.68006843339886\n",
      "Epoch 2305 / 10000 loss: 65.85422873497009\n",
      "MSE train 3.2620940237241682 MSE test 6.679658554876423\n",
      "Epoch 2306 / 10000 loss: 65.84231781959534\n",
      "MSE train 3.261514434037242 MSE test 6.6792471772904625\n",
      "Epoch 2307 / 10000 loss: 65.83019781112671\n",
      "MSE train 3.260945307497048 MSE test 6.678834272407261\n",
      "Epoch 2308 / 10000 loss: 65.81801319122314\n",
      "MSE train 3.26039397126154 MSE test 6.678420239257191\n",
      "Epoch 2309 / 10000 loss: 65.8060576915741\n",
      "MSE train 3.2598579520176645 MSE test 6.678005573699313\n",
      "Epoch 2310 / 10000 loss: 65.79449009895325\n",
      "MSE train 3.25933491806852 MSE test 6.677590909349812\n",
      "Epoch 2311 / 10000 loss: 65.78324961662292\n",
      "MSE train 3.258823403887299 MSE test 6.677176948768291\n",
      "Epoch 2312 / 10000 loss: 65.7722864151001\n",
      "MSE train 3.258320960842762 MSE test 6.676763746666941\n",
      "Epoch 2313 / 10000 loss: 65.76155972480774\n",
      "MSE train 3.2578242463739575 MSE test 6.676351201189586\n",
      "Epoch 2314 / 10000 loss: 65.75102066993713\n",
      "MSE train 3.257329709114242 MSE test 6.6759387043618155\n",
      "Epoch 2315 / 10000 loss: 65.74059891700745\n",
      "MSE train 3.256834057157202 MSE test 6.675525723273918\n",
      "Epoch 2316 / 10000 loss: 65.73021340370178\n",
      "MSE train 3.2563347892391836 MSE test 6.6751117560788416\n",
      "Epoch 2317 / 10000 loss: 65.71979808807373\n",
      "MSE train 3.2558311920788205 MSE test 6.6746964486055065\n",
      "Epoch 2318 / 10000 loss: 65.70929455757141\n",
      "MSE train 3.2553252284729886 MSE test 6.674279627018313\n",
      "Epoch 2319 / 10000 loss: 65.6986939907074\n",
      "MSE train 3.254820621402526 MSE test 6.6738612994610085\n",
      "Epoch 2320 / 10000 loss: 65.68803644180298\n",
      "MSE train 3.2543196728849235 MSE test 6.673441719290015\n",
      "Epoch 2321 / 10000 loss: 65.67740511894226\n",
      "MSE train 3.2538215949517353 MSE test 6.673020843884539\n",
      "Epoch 2322 / 10000 loss: 65.66684627532959\n",
      "MSE train 3.2533243274223573 MSE test 6.672598454403109\n",
      "Epoch 2323 / 10000 loss: 65.65635085105896\n",
      "MSE train 3.2528265990043774 MSE test 6.672174515788801\n",
      "Epoch 2324 / 10000 loss: 65.64586472511292\n",
      "MSE train 3.2523285736869285 MSE test 6.671749160077628\n",
      "Epoch 2325 / 10000 loss: 65.63536834716797\n",
      "MSE train 3.251831403529769 MSE test 6.671322840267339\n",
      "Epoch 2326 / 10000 loss: 65.62485909461975\n",
      "MSE train 3.251336279194975 MSE test 6.670895992345094\n",
      "Epoch 2327 / 10000 loss: 65.61436986923218\n",
      "MSE train 3.250843367258898 MSE test 6.670469104477526\n",
      "Epoch 2328 / 10000 loss: 65.60391855239868\n",
      "MSE train 3.250351462963787 MSE test 6.670042208419287\n",
      "Epoch 2329 / 10000 loss: 65.59351420402527\n",
      "MSE train 3.249858554000676 MSE test 6.669615195484001\n",
      "Epoch 2330 / 10000 loss: 65.58313298225403\n",
      "MSE train 3.2493626052007825 MSE test 6.669187698823881\n",
      "Epoch 2331 / 10000 loss: 65.57272338867188\n",
      "MSE train 3.24886203671568 MSE test 6.668759342718545\n",
      "Epoch 2332 / 10000 loss: 65.56224727630615\n",
      "MSE train 3.2483560467526824 MSE test 6.6683299841601915\n",
      "Epoch 2333 / 10000 loss: 65.55167055130005\n",
      "MSE train 3.247844702461112 MSE test 6.667899439767427\n",
      "Epoch 2334 / 10000 loss: 65.54097533226013\n",
      "MSE train 3.2473289223540873 MSE test 6.66746791730457\n",
      "Epoch 2335 / 10000 loss: 65.53016138076782\n",
      "MSE train 3.2468103270010893 MSE test 6.667035512787934\n",
      "Epoch 2336 / 10000 loss: 65.5192518234253\n",
      "MSE train 3.246291078199235 MSE test 6.666602428748782\n",
      "Epoch 2337 / 10000 loss: 65.50828313827515\n",
      "MSE train 3.2457735577299363 MSE test 6.666168858140213\n",
      "Epoch 2338 / 10000 loss: 65.49729537963867\n",
      "MSE train 3.245260000552669 MSE test 6.665734957151319\n",
      "Epoch 2339 / 10000 loss: 65.48634386062622\n",
      "MSE train 3.244752090633254 MSE test 6.665300811006418\n",
      "Epoch 2340 / 10000 loss: 65.47548389434814\n",
      "MSE train 3.244250863899939 MSE test 6.664866525585505\n",
      "Epoch 2341 / 10000 loss: 65.46474051475525\n",
      "MSE train 3.243756738725729 MSE test 6.664432239481303\n",
      "Epoch 2342 / 10000 loss: 65.4541425704956\n",
      "MSE train 3.243269371939721 MSE test 6.663997972062085\n",
      "Epoch 2343 / 10000 loss: 65.44369840621948\n",
      "MSE train 3.2427873401659455 MSE test 6.663563721812371\n",
      "Epoch 2344 / 10000 loss: 65.43339920043945\n",
      "MSE train 3.242307838212462 MSE test 6.6631294305880955\n",
      "Epoch 2345 / 10000 loss: 65.42321610450745\n",
      "MSE train 3.2418268005750424 MSE test 6.662695022902573\n",
      "Epoch 2346 / 10000 loss: 65.41308617591858\n",
      "MSE train 3.2413393497012204 MSE test 6.662260223583671\n",
      "Epoch 2347 / 10000 loss: 65.40292358398438\n",
      "MSE train 3.2408413890979975 MSE test 6.661824868473403\n",
      "Epoch 2348 / 10000 loss: 65.39262533187866\n",
      "MSE train 3.2403338014420573 MSE test 6.66138890121998\n",
      "Epoch 2349 / 10000 loss: 65.3820948600769\n",
      "MSE train 3.239827935931884 MSE test 6.660952394797064\n",
      "Epoch 2350 / 10000 loss: 65.37135815620422\n",
      "MSE train 3.2393390020591273 MSE test 6.660515587284692\n",
      "Epoch 2351 / 10000 loss: 65.36065769195557\n",
      "MSE train 3.2388696240900807 MSE test 6.660078710010469\n",
      "Epoch 2352 / 10000 loss: 65.35032176971436\n",
      "MSE train 3.2384129229766434 MSE test 6.659642029710274\n",
      "Epoch 2353 / 10000 loss: 65.34041118621826\n",
      "MSE train 3.237963078298674 MSE test 6.659205653668818\n",
      "Epoch 2354 / 10000 loss: 65.33077502250671\n",
      "MSE train 3.237517215976666 MSE test 6.65877009299103\n",
      "Epoch 2355 / 10000 loss: 65.32128620147705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.237073898243747 MSE test 6.658335939173353\n",
      "Epoch 2356 / 10000 loss: 65.3118851184845\n",
      "MSE train 3.236631420843854 MSE test 6.657903535355579\n",
      "Epoch 2357 / 10000 loss: 65.30253911018372\n",
      "MSE train 3.236186371719457 MSE test 6.6574731915875445\n",
      "Epoch 2358 / 10000 loss: 65.29321360588074\n",
      "MSE train 3.2357325459865156 MSE test 6.657044636101081\n",
      "Epoch 2359 / 10000 loss: 65.28383231163025\n",
      "MSE train 3.2352610815481686 MSE test 6.65661714755156\n",
      "Epoch 2360 / 10000 loss: 65.27426099777222\n",
      "MSE train 3.234766342170261 MSE test 6.656189818927826\n",
      "Epoch 2361 / 10000 loss: 65.26431107521057\n",
      "MSE train 3.23425838080296 MSE test 6.655762016927609\n",
      "Epoch 2362 / 10000 loss: 65.25385761260986\n",
      "MSE train 3.233747170903021 MSE test 6.655333057923463\n",
      "Epoch 2363 / 10000 loss: 65.24311923980713\n",
      "MSE train 3.233214156396013 MSE test 6.65490095160796\n",
      "Epoch 2364 / 10000 loss: 65.23231387138367\n",
      "MSE train 3.2326691439564086 MSE test 6.654464241821238\n",
      "Epoch 2365 / 10000 loss: 65.22104215621948\n",
      "MSE train 3.232143195149206 MSE test 6.654025357503014\n",
      "Epoch 2366 / 10000 loss: 65.20951080322266\n",
      "MSE train 3.2316355537433066 MSE test 6.653587770380405\n",
      "Epoch 2367 / 10000 loss: 65.198397397995\n",
      "MSE train 3.2311634470019914 MSE test 6.653162188311789\n",
      "Epoch 2368 / 10000 loss: 65.18767809867859\n",
      "MSE train 3.230708319712087 MSE test 6.652749380714481\n",
      "Epoch 2369 / 10000 loss: 65.177729845047\n",
      "MSE train 3.230256302224548 MSE test 6.652343627039516\n",
      "Epoch 2370 / 10000 loss: 65.1681489944458\n",
      "MSE train 3.229804362129474 MSE test 6.6519422060245335\n",
      "Epoch 2371 / 10000 loss: 65.15864086151123\n",
      "MSE train 3.229352056220472 MSE test 6.651543557028538\n",
      "Epoch 2372 / 10000 loss: 65.14913249015808\n",
      "MSE train 3.228899337700532 MSE test 6.651147090068878\n",
      "Epoch 2373 / 10000 loss: 65.13961839675903\n",
      "MSE train 3.2284460195059177 MSE test 6.650752202281499\n",
      "Epoch 2374 / 10000 loss: 65.13009667396545\n",
      "MSE train 3.227991781116092 MSE test 6.650358639876596\n",
      "Epoch 2375 / 10000 loss: 65.12055993080139\n",
      "MSE train 3.227536041454531 MSE test 6.649966053362559\n",
      "Epoch 2376 / 10000 loss: 65.11100029945374\n",
      "MSE train 3.2270779325959404 MSE test 6.649573888997441\n",
      "Epoch 2377 / 10000 loss: 65.10140705108643\n",
      "MSE train 3.226616389110062 MSE test 6.649181781815443\n",
      "Epoch 2378 / 10000 loss: 65.09175539016724\n",
      "MSE train 3.2261502181713633 MSE test 6.648789311695655\n",
      "Epoch 2379 / 10000 loss: 65.08202981948853\n",
      "MSE train 3.225678652210837 MSE test 6.648396110589385\n",
      "Epoch 2380 / 10000 loss: 65.07220005989075\n",
      "MSE train 3.2252021223164165 MSE test 6.6480022121693\n",
      "Epoch 2381 / 10000 loss: 65.06225275993347\n",
      "MSE train 3.2247232561194346 MSE test 6.647607666052194\n",
      "Epoch 2382 / 10000 loss: 65.05219340324402\n",
      "MSE train 3.2242468710815624 MSE test 6.647212866868419\n",
      "Epoch 2383 / 10000 loss: 65.04208278656006\n",
      "MSE train 3.2237784283406636 MSE test 6.646818439718538\n",
      "Epoch 2384 / 10000 loss: 65.03202605247498\n",
      "MSE train 3.2233215002605204 MSE test 6.646424970502453\n",
      "Epoch 2385 / 10000 loss: 65.02213978767395\n",
      "MSE train 3.222876500501872 MSE test 6.646032858442334\n",
      "Epoch 2386 / 10000 loss: 65.01250147819519\n",
      "MSE train 3.222441476316023 MSE test 6.6456422908810815\n",
      "Epoch 2387 / 10000 loss: 65.00312209129333\n",
      "MSE train 3.2220137559433364 MSE test 6.645253054740963\n",
      "Epoch 2388 / 10000 loss: 64.9939591884613\n",
      "MSE train 3.2215911076850037 MSE test 6.644864999516762\n",
      "Epoch 2389 / 10000 loss: 64.98495507240295\n",
      "MSE train 3.221172430192605 MSE test 6.644477741833838\n",
      "Epoch 2390 / 10000 loss: 64.97606039047241\n",
      "MSE train 3.2207577979604363 MSE test 6.644090898330572\n",
      "Epoch 2391 / 10000 loss: 64.96725010871887\n",
      "MSE train 3.2203473010156376 MSE test 6.6437040340618365\n",
      "Epoch 2392 / 10000 loss: 64.95852875709534\n",
      "MSE train 3.2199394693946193 MSE test 6.6433163709933805\n",
      "Epoch 2393 / 10000 loss: 64.94989657402039\n",
      "MSE train 3.219530167949397 MSE test 6.642927015714935\n",
      "Epoch 2394 / 10000 loss: 64.941321849823\n",
      "MSE train 3.21911137607743 MSE test 6.642534280796666\n",
      "Epoch 2395 / 10000 loss: 64.93271732330322\n",
      "MSE train 3.2186647945942473 MSE test 6.642135226871377\n",
      "Epoch 2396 / 10000 loss: 64.9239068031311\n",
      "MSE train 3.2181259680050616 MSE test 6.641723792526255\n",
      "Epoch 2397 / 10000 loss: 64.91449809074402\n",
      "MSE train 3.2173033589383357 MSE test 6.641284631682324\n",
      "Epoch 2398 / 10000 loss: 64.90309000015259\n",
      "MSE train 3.2165787586290553 MSE test 6.640820134628509\n",
      "Epoch 2399 / 10000 loss: 64.88554286956787\n",
      "MSE train 3.2161356858805874 MSE test 6.640396098961045\n",
      "Epoch 2400 / 10000 loss: 64.87011790275574\n",
      "MSE train 3.215731331246259 MSE test 6.640006896069476\n",
      "Epoch 2401 / 10000 loss: 64.86079478263855\n",
      "MSE train 3.2153283930351635 MSE test 6.6396203906440405\n",
      "Epoch 2402 / 10000 loss: 64.85230135917664\n",
      "MSE train 3.2149240077771855 MSE test 6.639234416640118\n",
      "Epoch 2403 / 10000 loss: 64.8438413143158\n",
      "MSE train 3.2145158884291125 MSE test 6.638847866923821\n",
      "Epoch 2404 / 10000 loss: 64.83535051345825\n",
      "MSE train 3.2141019864844482 MSE test 6.638459881923644\n",
      "Epoch 2405 / 10000 loss: 64.82677912712097\n",
      "MSE train 3.2136802687537394 MSE test 6.6380697736345935\n",
      "Epoch 2406 / 10000 loss: 64.81808423995972\n",
      "MSE train 3.2132485286658317 MSE test 6.637677012707806\n",
      "Epoch 2407 / 10000 loss: 64.80922269821167\n",
      "MSE train 3.2128040925705794 MSE test 6.637281162324524\n",
      "Epoch 2408 / 10000 loss: 64.80014443397522\n",
      "MSE train 3.2123439689465467 MSE test 6.636881801665733\n",
      "Epoch 2409 / 10000 loss: 64.79079699516296\n",
      "MSE train 3.2118665330978198 MSE test 6.63647881796158\n",
      "Epoch 2410 / 10000 loss: 64.78111100196838\n",
      "MSE train 3.211375876173872 MSE test 6.636072238282523\n",
      "Epoch 2411 / 10000 loss: 64.77105140686035\n",
      "MSE train 3.2108838670191435 MSE test 6.635662747353041\n",
      "Epoch 2412 / 10000 loss: 64.76071095466614\n",
      "MSE train 3.2103998938663 MSE test 6.63525145633561\n",
      "Epoch 2413 / 10000 loss: 64.75034356117249\n",
      "MSE train 3.2099219825991008 MSE test 6.634838852754463\n",
      "Epoch 2414 / 10000 loss: 64.74015641212463\n",
      "MSE train 3.2094436611925263 MSE test 6.634424930845478\n",
      "Epoch 2415 / 10000 loss: 64.7301025390625\n",
      "MSE train 3.2089600871835984 MSE test 6.634009740452483\n",
      "Epoch 2416 / 10000 loss: 64.72004294395447\n",
      "MSE train 3.2084689618732454 MSE test 6.633593365875239\n",
      "Epoch 2417 / 10000 loss: 64.70987439155579\n",
      "MSE train 3.2079713503711096 MSE test 6.6331760348730855\n",
      "Epoch 2418 / 10000 loss: 64.69954991340637\n",
      "MSE train 3.207473058301216 MSE test 6.632758237613583\n",
      "Epoch 2419 / 10000 loss: 64.68908500671387\n",
      "MSE train 3.206982555396016 MSE test 6.632340483975208\n",
      "Epoch 2420 / 10000 loss: 64.67860984802246\n",
      "MSE train 3.2065047527856096 MSE test 6.631923444655959\n",
      "Epoch 2421 / 10000 loss: 64.6682996749878\n",
      "MSE train 3.2060388197847045 MSE test 6.631507357920981\n",
      "Epoch 2422 / 10000 loss: 64.65826201438904\n",
      "MSE train 3.2055814530381803 MSE test 6.631092124639374\n",
      "Epoch 2423 / 10000 loss: 64.64847731590271\n",
      "MSE train 3.205129358889457 MSE test 6.6306776547924\n",
      "Epoch 2424 / 10000 loss: 64.63887095451355\n",
      "MSE train 3.2046796294690187 MSE test 6.630263736587862\n",
      "Epoch 2425 / 10000 loss: 64.62938165664673\n",
      "MSE train 3.204229492707075 MSE test 6.629849928988427\n",
      "Epoch 2426 / 10000 loss: 64.6199369430542\n",
      "MSE train 3.2037762317225416 MSE test 6.629436087738031\n",
      "Epoch 2427 / 10000 loss: 64.61048316955566\n",
      "MSE train 3.203317535883738 MSE test 6.6290219944275925\n",
      "Epoch 2428 / 10000 loss: 64.60095882415771\n",
      "MSE train 3.202853459193166 MSE test 6.628608144489546\n",
      "Epoch 2429 / 10000 loss: 64.5913200378418\n",
      "MSE train 3.202389713512981 MSE test 6.628195456802441\n",
      "Epoch 2430 / 10000 loss: 64.58156251907349\n",
      "MSE train 3.201936607722968 MSE test 6.627785803346858\n",
      "Epoch 2431 / 10000 loss: 64.57180976867676\n",
      "MSE train 3.201499418324397 MSE test 6.627380879517104\n",
      "Epoch 2432 / 10000 loss: 64.56228375434875\n",
      "MSE train 3.201074637170519 MSE test 6.626980852926856\n",
      "Epoch 2433 / 10000 loss: 64.55310249328613\n",
      "MSE train 3.2006564776860613 MSE test 6.626585003957343\n",
      "Epoch 2434 / 10000 loss: 64.54418587684631\n",
      "MSE train 3.200241050764771 MSE test 6.626192515434347\n",
      "Epoch 2435 / 10000 loss: 64.53540849685669\n",
      "MSE train 3.199826664062686 MSE test 6.625802611162823\n",
      "Epoch 2436 / 10000 loss: 64.52669143676758\n",
      "MSE train 3.199413223178962 MSE test 6.625414949587395\n",
      "Epoch 2437 / 10000 loss: 64.5179934501648\n",
      "MSE train 3.19900151734026 MSE test 6.625029197788474\n",
      "Epoch 2438 / 10000 loss: 64.5093162059784\n",
      "MSE train 3.198592372467332 MSE test 6.6246453330408315\n",
      "Epoch 2439 / 10000 loss: 64.50067567825317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.19818596806559 MSE test 6.6242629988612345\n",
      "Epoch 2440 / 10000 loss: 64.49208641052246\n",
      "MSE train 3.197781620203121 MSE test 6.623882030610734\n",
      "Epoch 2441 / 10000 loss: 64.48355793952942\n",
      "MSE train 3.1973779618622067 MSE test 6.623502132561879\n",
      "Epoch 2442 / 10000 loss: 64.47507333755493\n",
      "MSE train 3.196973318203551 MSE test 6.623122893510749\n",
      "Epoch 2443 / 10000 loss: 64.4666006565094\n",
      "MSE train 3.1965658688996506 MSE test 6.622743974462967\n",
      "Epoch 2444 / 10000 loss: 64.4581081867218\n",
      "MSE train 3.1961538741887647 MSE test 6.622364952973986\n",
      "Epoch 2445 / 10000 loss: 64.44955158233643\n",
      "MSE train 3.195735811496707 MSE test 6.621985516203616\n",
      "Epoch 2446 / 10000 loss: 64.44089770317078\n",
      "MSE train 3.1953106333798336 MSE test 6.621605535231112\n",
      "Epoch 2447 / 10000 loss: 64.43211245536804\n",
      "MSE train 3.1948781530369597 MSE test 6.621224723601583\n",
      "Epoch 2448 / 10000 loss: 64.4231743812561\n",
      "MSE train 3.1944394055439687 MSE test 6.6208430192364895\n",
      "Epoch 2449 / 10000 loss: 64.41407942771912\n",
      "MSE train 3.1939965905439496 MSE test 6.620460388520225\n",
      "Epoch 2450 / 10000 loss: 64.40484642982483\n",
      "MSE train 3.193552235406378 MSE test 6.620076884127175\n",
      "Epoch 2451 / 10000 loss: 64.39552998542786\n",
      "MSE train 3.193107724120079 MSE test 6.619692574787578\n",
      "Epoch 2452 / 10000 loss: 64.38617849349976\n",
      "MSE train 3.192662242971928 MSE test 6.619307281542477\n",
      "Epoch 2453 / 10000 loss: 64.37682747840881\n",
      "MSE train 3.1922129256949145 MSE test 6.618920925515823\n",
      "Epoch 2454 / 10000 loss: 64.36745691299438\n",
      "MSE train 3.191756664685755 MSE test 6.6185332413502405\n",
      "Epoch 2455 / 10000 loss: 64.35800290107727\n",
      "MSE train 3.1912941742251384 MSE test 6.618144589636214\n",
      "Epoch 2456 / 10000 loss: 64.34840393066406\n",
      "MSE train 3.1908341202169503 MSE test 6.617755959406995\n",
      "Epoch 2457 / 10000 loss: 64.33867383003235\n",
      "MSE train 3.190387770998539 MSE test 6.617368894462755\n",
      "Epoch 2458 / 10000 loss: 64.32899236679077\n",
      "MSE train 3.189957483796866 MSE test 6.6169842664226595\n",
      "Epoch 2459 / 10000 loss: 64.31960535049438\n",
      "MSE train 3.1895383561093498 MSE test 6.61660184003698\n",
      "Epoch 2460 / 10000 loss: 64.31055736541748\n",
      "MSE train 3.189125633272194 MSE test 6.616220927476561\n",
      "Epoch 2461 / 10000 loss: 64.30174684524536\n",
      "MSE train 3.1887164019101033 MSE test 6.615841011711668\n",
      "Epoch 2462 / 10000 loss: 64.29306674003601\n",
      "MSE train 3.188308861909685 MSE test 6.615461515438836\n",
      "Epoch 2463 / 10000 loss: 64.28446054458618\n",
      "MSE train 3.187901699843461 MSE test 6.615082072142328\n",
      "Epoch 2464 / 10000 loss: 64.27588820457458\n",
      "MSE train 3.1874936639123694 MSE test 6.614702393639111\n",
      "Epoch 2465 / 10000 loss: 64.26732349395752\n",
      "MSE train 3.187083539069078 MSE test 6.614322106958459\n",
      "Epoch 2466 / 10000 loss: 64.25873947143555\n",
      "MSE train 3.186670102603861 MSE test 6.613941056168893\n",
      "Epoch 2467 / 10000 loss: 64.2501106262207\n",
      "MSE train 3.1862523099919566 MSE test 6.613558977552663\n",
      "Epoch 2468 / 10000 loss: 64.2414083480835\n",
      "MSE train 3.1858294066140833 MSE test 6.613175736490018\n",
      "Epoch 2469 / 10000 loss: 64.2326123714447\n",
      "MSE train 3.185401051630392 MSE test 6.612791170326176\n",
      "Epoch 2470 / 10000 loss: 64.2237057685852\n",
      "MSE train 3.1849673407418306 MSE test 6.612405459674995\n",
      "Epoch 2471 / 10000 loss: 64.2146852016449\n",
      "MSE train 3.1845287225331034 MSE test 6.612018709136916\n",
      "Epoch 2472 / 10000 loss: 64.20554709434509\n",
      "MSE train 3.184085848624886 MSE test 6.611631117784549\n",
      "Epoch 2473 / 10000 loss: 64.19630432128906\n",
      "MSE train 3.1836394526187104 MSE test 6.6112429902417835\n",
      "Epoch 2474 / 10000 loss: 64.18697309494019\n",
      "MSE train 3.1831903722989465 MSE test 6.610854649024234\n",
      "Epoch 2475 / 10000 loss: 64.17756462097168\n",
      "MSE train 3.1827397013408953 MSE test 6.610466240462667\n",
      "Epoch 2476 / 10000 loss: 64.16810059547424\n",
      "MSE train 3.1822889067258284 MSE test 6.610078157388847\n",
      "Epoch 2477 / 10000 loss: 64.15860199928284\n",
      "MSE train 3.1818396342702973 MSE test 6.609690570176396\n",
      "Epoch 2478 / 10000 loss: 64.14910411834717\n",
      "MSE train 3.181393123505105 MSE test 6.609303587603593\n",
      "Epoch 2479 / 10000 loss: 64.139639377594\n",
      "MSE train 3.1809495094511377 MSE test 6.608917287041048\n",
      "Epoch 2480 / 10000 loss: 64.13023209571838\n",
      "MSE train 3.1805074070185504 MSE test 6.608531451449135\n",
      "Epoch 2481 / 10000 loss: 64.12089276313782\n",
      "MSE train 3.1800640673622147 MSE test 6.608145828552818\n",
      "Epoch 2482 / 10000 loss: 64.11158156394958\n",
      "MSE train 3.1796156349319875 MSE test 6.607759961175899\n",
      "Epoch 2483 / 10000 loss: 64.10224199295044\n",
      "MSE train 3.179157319816604 MSE test 6.607373308856433\n",
      "Epoch 2484 / 10000 loss: 64.09279584884644\n",
      "MSE train 3.178683154807966 MSE test 6.606985417832154\n",
      "Epoch 2485 / 10000 loss: 64.08313536643982\n",
      "MSE train 3.178185504033562 MSE test 6.606595572369981\n",
      "Epoch 2486 / 10000 loss: 64.07313418388367\n",
      "MSE train 3.177655254418805 MSE test 6.6062031463675615\n",
      "Epoch 2487 / 10000 loss: 64.06262254714966\n",
      "MSE train 3.177088457601636 MSE test 6.605807736730959\n",
      "Epoch 2488 / 10000 loss: 64.0514075756073\n",
      "MSE train 3.1765098451492535 MSE test 6.605410106979121\n",
      "Epoch 2489 / 10000 loss: 64.03940200805664\n",
      "MSE train 3.17596588644117 MSE test 6.60501300368989\n",
      "Epoch 2490 / 10000 loss: 64.02713632583618\n",
      "MSE train 3.1754661944685822 MSE test 6.6046188231483764\n",
      "Epoch 2491 / 10000 loss: 64.01561856269836\n",
      "MSE train 3.175000299888969 MSE test 6.6042278786090804\n",
      "Epoch 2492 / 10000 loss: 64.00506258010864\n",
      "MSE train 3.1745538618837648 MSE test 6.60383979869098\n",
      "Epoch 2493 / 10000 loss: 63.995232820510864\n",
      "MSE train 3.174112934157865 MSE test 6.6034533823800485\n",
      "Epoch 2494 / 10000 loss: 63.98582196235657\n",
      "MSE train 3.173667009703689 MSE test 6.6030676940298925\n",
      "Epoch 2495 / 10000 loss: 63.97652888298035\n",
      "MSE train 3.173212007207677 MSE test 6.6026822941620065\n",
      "Epoch 2496 / 10000 loss: 63.967122316360474\n",
      "MSE train 3.1727577431597624 MSE test 6.602297700351111\n",
      "Epoch 2497 / 10000 loss: 63.95751690864563\n",
      "MSE train 3.172322291533087 MSE test 6.601915196305517\n",
      "Epoch 2498 / 10000 loss: 63.94792628288269\n",
      "MSE train 3.1719084335526917 MSE test 6.601535453684271\n",
      "Epoch 2499 / 10000 loss: 63.93873953819275\n",
      "MSE train 3.1715077624418226 MSE test 6.601157963476666\n",
      "Epoch 2500 / 10000 loss: 63.93001890182495\n",
      "MSE train 3.1711143146775957 MSE test 6.600781680969861\n",
      "Epoch 2501 / 10000 loss: 63.92158317565918\n",
      "MSE train 3.1707254047129774 MSE test 6.6004059637866845\n",
      "Epoch 2502 / 10000 loss: 63.91329908370972\n",
      "MSE train 3.1703397192012566 MSE test 6.600030234396507\n",
      "Epoch 2503 / 10000 loss: 63.905112504959106\n",
      "MSE train 3.1699563185211317 MSE test 6.599653815388855\n",
      "Epoch 2504 / 10000 loss: 63.89699578285217\n",
      "MSE train 3.169574011684495 MSE test 6.599276132531443\n",
      "Epoch 2505 / 10000 loss: 63.88892698287964\n",
      "MSE train 3.1691909465859207 MSE test 6.598896415406936\n",
      "Epoch 2506 / 10000 loss: 63.88087821006775\n",
      "MSE train 3.1688040831364646 MSE test 6.598513787906431\n",
      "Epoch 2507 / 10000 loss: 63.87281346321106\n",
      "MSE train 3.1684082295066824 MSE test 6.598127032204886\n",
      "Epoch 2508 / 10000 loss: 63.86466717720032\n",
      "MSE train 3.1679943299032103 MSE test 6.597734426478607\n",
      "Epoch 2509 / 10000 loss: 63.85632658004761\n",
      "MSE train 3.1675497667840453 MSE test 6.597333896225507\n",
      "Epoch 2510 / 10000 loss: 63.84759283065796\n",
      "MSE train 3.1670783195232888 MSE test 6.596925503469722\n",
      "Epoch 2511 / 10000 loss: 63.838199615478516\n",
      "MSE train 3.166628180966868 MSE test 6.59651787855147\n",
      "Epoch 2512 / 10000 loss: 63.828224897384644\n",
      "MSE train 3.166212336897478 MSE test 6.596119628940174\n",
      "Epoch 2513 / 10000 loss: 63.818713426589966\n",
      "MSE train 3.16580781463578 MSE test 6.595726221426137\n",
      "Epoch 2514 / 10000 loss: 63.809938192367554\n",
      "MSE train 3.1654074596314556 MSE test 6.595333593768876\n",
      "Epoch 2515 / 10000 loss: 63.80140566825867\n",
      "MSE train 3.165009440831586 MSE test 6.594940088788094\n",
      "Epoch 2516 / 10000 loss: 63.79296398162842\n",
      "MSE train 3.1646113128385625 MSE test 6.59454447411625\n",
      "Epoch 2517 / 10000 loss: 63.784570932388306\n",
      "MSE train 3.164209995200323 MSE test 6.594146059410494\n",
      "Epoch 2518 / 10000 loss: 63.77617406845093\n",
      "MSE train 3.1638029090507005 MSE test 6.593744277240085\n",
      "Epoch 2519 / 10000 loss: 63.767711877822876\n",
      "MSE train 3.1633887765139304 MSE test 6.593338853682204\n",
      "Epoch 2520 / 10000 loss: 63.759122371673584\n",
      "MSE train 3.1629677364219044 MSE test 6.592929943634754\n",
      "Epoch 2521 / 10000 loss: 63.750383615493774\n",
      "MSE train 3.16254107320342 MSE test 6.592518066861845\n",
      "Epoch 2522 / 10000 loss: 63.74149441719055\n",
      "MSE train 3.1621103172953315 MSE test 6.592104189772119\n",
      "Epoch 2523 / 10000 loss: 63.73248624801636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.161676267969141 MSE test 6.591689166371675\n",
      "Epoch 2524 / 10000 loss: 63.72339153289795\n",
      "MSE train 3.1612383285061667 MSE test 6.5912737520739455\n",
      "Epoch 2525 / 10000 loss: 63.714224100112915\n",
      "MSE train 3.160794735143058 MSE test 6.590858249515782\n",
      "Epoch 2526 / 10000 loss: 63.70497751235962\n",
      "MSE train 3.16034308069482 MSE test 6.590442705305645\n",
      "Epoch 2527 / 10000 loss: 63.69560694694519\n",
      "MSE train 3.159880712264086 MSE test 6.590026949959802\n",
      "Epoch 2528 / 10000 loss: 63.68606424331665\n",
      "MSE train 3.1594041457874775 MSE test 6.5896107299315645\n",
      "Epoch 2529 / 10000 loss: 63.67629361152649\n",
      "MSE train 3.1589071776733957 MSE test 6.589193493791844\n",
      "Epoch 2530 / 10000 loss: 63.666220903396606\n",
      "MSE train 3.1583767832692344 MSE test 6.588773573421353\n",
      "Epoch 2531 / 10000 loss: 63.65571403503418\n",
      "MSE train 3.1577864521275503 MSE test 6.588348095539331\n",
      "Epoch 2532 / 10000 loss: 63.644492626190186\n",
      "MSE train 3.15713923260311 MSE test 6.587915064601268\n",
      "Epoch 2533 / 10000 loss: 63.63198924064636\n",
      "MSE train 3.1565703234588334 MSE test 6.587490384959738\n",
      "Epoch 2534 / 10000 loss: 63.61825633049011\n",
      "MSE train 3.1560592102042317 MSE test 6.587080865203137\n",
      "Epoch 2535 / 10000 loss: 63.606197357177734\n",
      "MSE train 3.1555603200152675 MSE test 6.586675077585551\n",
      "Epoch 2536 / 10000 loss: 63.595377683639526\n",
      "MSE train 3.1550616761101713 MSE test 6.586269930491744\n",
      "Epoch 2537 / 10000 loss: 63.58482313156128\n",
      "MSE train 3.1545589275502053 MSE test 6.585864283867883\n",
      "Epoch 2538 / 10000 loss: 63.57427358627319\n",
      "MSE train 3.154055595965344 MSE test 6.585458272945766\n",
      "Epoch 2539 / 10000 loss: 63.56363296508789\n",
      "MSE train 3.1535567947423373 MSE test 6.585052515256556\n",
      "Epoch 2540 / 10000 loss: 63.55298113822937\n",
      "MSE train 3.153058233258175 MSE test 6.5846472168264745\n",
      "Epoch 2541 / 10000 loss: 63.54242825508118\n",
      "MSE train 3.1525441709997613 MSE test 6.5842412602986675\n",
      "Epoch 2542 / 10000 loss: 63.531882762908936\n",
      "MSE train 3.151999468830179 MSE test 6.583833112281318\n",
      "Epoch 2543 / 10000 loss: 63.521000385284424\n",
      "MSE train 3.1514617974108567 MSE test 6.5834240478672665\n",
      "Epoch 2544 / 10000 loss: 63.50945711135864\n",
      "MSE train 3.1509840135608798 MSE test 6.583019337510397\n",
      "Epoch 2545 / 10000 loss: 63.49806523323059\n",
      "MSE train 3.150534929854781 MSE test 6.582618070670155\n",
      "Epoch 2546 / 10000 loss: 63.48796606063843\n",
      "MSE train 3.1500941257155652 MSE test 6.582216908173449\n",
      "Epoch 2547 / 10000 loss: 63.47848606109619\n",
      "MSE train 3.149653389465101 MSE test 6.581813938591938\n",
      "Epoch 2548 / 10000 loss: 63.46918249130249\n",
      "MSE train 3.1492053935268864 MSE test 6.581407588843434\n",
      "Epoch 2549 / 10000 loss: 63.45987796783447\n",
      "MSE train 3.148743072844114 MSE test 6.580996337559575\n",
      "Epoch 2550 / 10000 loss: 63.45041847229004\n",
      "MSE train 3.1482667571024376 MSE test 6.580579952234562\n",
      "Epoch 2551 / 10000 loss: 63.44064521789551\n",
      "MSE train 3.147794137761135 MSE test 6.580162282011746\n",
      "Epoch 2552 / 10000 loss: 63.43056869506836\n",
      "MSE train 3.1473410275493783 MSE test 6.579749770907176\n",
      "Epoch 2553 / 10000 loss: 63.420574426651\n",
      "MSE train 3.146900717038654 MSE test 6.579343451404437\n",
      "Epoch 2554 / 10000 loss: 63.41100335121155\n",
      "MSE train 3.146462982304683 MSE test 6.578940391191906\n",
      "Epoch 2555 / 10000 loss: 63.40170931816101\n",
      "MSE train 3.146021922964344 MSE test 6.578537998160833\n",
      "Epoch 2556 / 10000 loss: 63.39247155189514\n",
      "MSE train 3.1455728829986382 MSE test 6.578134341265856\n",
      "Epoch 2557 / 10000 loss: 63.38316226005554\n",
      "MSE train 3.14511050577254 MSE test 6.577727454409393\n",
      "Epoch 2558 / 10000 loss: 63.37368202209473\n",
      "MSE train 3.1446292393552167 MSE test 6.577315921555371\n",
      "Epoch 2559 / 10000 loss: 63.363913774490356\n",
      "MSE train 3.1441273650594894 MSE test 6.576898425135607\n",
      "Epoch 2560 / 10000 loss: 63.353737592697144\n",
      "MSE train 3.1436096729261 MSE test 6.576474758405915\n",
      "Epoch 2561 / 10000 loss: 63.343114137649536\n",
      "MSE train 3.143078297799811 MSE test 6.5760450589786315\n",
      "Epoch 2562 / 10000 loss: 63.33214783668518\n",
      "MSE train 3.142564226618155 MSE test 6.575613218952986\n",
      "Epoch 2563 / 10000 loss: 63.32088255882263\n",
      "MSE train 3.142099888443656 MSE test 6.575194778371015\n",
      "Epoch 2564 / 10000 loss: 63.30999445915222\n",
      "MSE train 3.141642945445839 MSE test 6.574783105977251\n",
      "Epoch 2565 / 10000 loss: 63.30018353462219\n",
      "MSE train 3.1411778001174095 MSE test 6.574369480449294\n",
      "Epoch 2566 / 10000 loss: 63.290534019470215\n",
      "MSE train 3.140714891590073 MSE test 6.573954425141294\n",
      "Epoch 2567 / 10000 loss: 63.28070569038391\n",
      "MSE train 3.1402840421116767 MSE test 6.573547204546368\n",
      "Epoch 2568 / 10000 loss: 63.27092409133911\n",
      "MSE train 3.1398849703151765 MSE test 6.573153739134854\n",
      "Epoch 2569 / 10000 loss: 63.26183843612671\n",
      "MSE train 3.1395002299602774 MSE test 6.572769596729598\n",
      "Epoch 2570 / 10000 loss: 63.253438234329224\n",
      "MSE train 3.1391207893800397 MSE test 6.572390654563169\n",
      "Epoch 2571 / 10000 loss: 63.24535298347473\n",
      "MSE train 3.1387422131557856 MSE test 6.572014617110238\n",
      "Epoch 2572 / 10000 loss: 63.23737978935242\n",
      "MSE train 3.138361308410274 MSE test 6.571640281278955\n",
      "Epoch 2573 / 10000 loss: 63.22942614555359\n",
      "MSE train 3.1379751683055295 MSE test 6.571267022242823\n",
      "Epoch 2574 / 10000 loss: 63.22142171859741\n",
      "MSE train 3.1375815143725223 MSE test 6.5708943804922155\n",
      "Epoch 2575 / 10000 loss: 63.21330165863037\n",
      "MSE train 3.137180702900989 MSE test 6.570521914635944\n",
      "Epoch 2576 / 10000 loss: 63.2050244808197\n",
      "MSE train 3.13677838277959 MSE test 6.5701495680156565\n",
      "Epoch 2577 / 10000 loss: 63.19658827781677\n",
      "MSE train 3.1363834204062138 MSE test 6.569777141610718\n",
      "Epoch 2578 / 10000 loss: 63.188119649887085\n",
      "MSE train 3.1360001578662735 MSE test 6.569404567130151\n",
      "Epoch 2579 / 10000 loss: 63.17981028556824\n",
      "MSE train 3.1356263941317364 MSE test 6.569031601669198\n",
      "Epoch 2580 / 10000 loss: 63.171754360198975\n",
      "MSE train 3.135258334782576 MSE test 6.568658223450932\n",
      "Epoch 2581 / 10000 loss: 63.16390562057495\n",
      "MSE train 3.134893501116973 MSE test 6.568284311769701\n",
      "Epoch 2582 / 10000 loss: 63.156182527542114\n",
      "MSE train 3.1345307471696624 MSE test 6.5679097934518165\n",
      "Epoch 2583 / 10000 loss: 63.14852833747864\n",
      "MSE train 3.1341697053678406 MSE test 6.567534669732768\n",
      "Epoch 2584 / 10000 loss: 63.140918254852295\n",
      "MSE train 3.1338102368526544 MSE test 6.567158748222868\n",
      "Epoch 2585 / 10000 loss: 63.133349657058716\n",
      "MSE train 3.133452017539091 MSE test 6.566781867521466\n",
      "Epoch 2586 / 10000 loss: 63.125813722610474\n",
      "MSE train 3.1330942972890226 MSE test 6.566403825962796\n",
      "Epoch 2587 / 10000 loss: 63.11830425262451\n",
      "MSE train 3.132735839464233 MSE test 6.566024233795598\n",
      "Epoch 2588 / 10000 loss: 63.11080884933472\n",
      "MSE train 3.132374938563242 MSE test 6.565642767914568\n",
      "Epoch 2589 / 10000 loss: 63.103296518325806\n",
      "MSE train 3.1320095596678907 MSE test 6.565258930115439\n",
      "Epoch 2590 / 10000 loss: 63.095731019973755\n",
      "MSE train 3.131637692307417 MSE test 6.564872384815782\n",
      "Epoch 2591 / 10000 loss: 63.088069438934326\n",
      "MSE train 3.1312581816034335 MSE test 6.564482877716536\n",
      "Epoch 2592 / 10000 loss: 63.080268144607544\n",
      "MSE train 3.1308723112317787 MSE test 6.56409113640304\n",
      "Epoch 2593 / 10000 loss: 63.07230091094971\n",
      "MSE train 3.1304847791706645 MSE test 6.563698620588561\n",
      "Epoch 2594 / 10000 loss: 63.064194679260254\n",
      "MSE train 3.1301016164955815 MSE test 6.563307670930675\n",
      "Epoch 2595 / 10000 loss: 63.05605506896973\n",
      "MSE train 3.1297259398496946 MSE test 6.562919967831056\n",
      "Epoch 2596 / 10000 loss: 63.04801058769226\n",
      "MSE train 3.129357110693449 MSE test 6.562535906128838\n",
      "Epoch 2597 / 10000 loss: 63.040127992630005\n",
      "MSE train 3.1289931061994687 MSE test 6.562154736704355\n",
      "Epoch 2598 / 10000 loss: 63.03239130973816\n",
      "MSE train 3.128632032152037 MSE test 6.561775506033882\n",
      "Epoch 2599 / 10000 loss: 63.02475690841675\n",
      "MSE train 3.128272156947644 MSE test 6.561397247344899\n",
      "Epoch 2600 / 10000 loss: 63.01718521118164\n",
      "MSE train 3.1279114268033363 MSE test 6.561019107681596\n",
      "Epoch 2601 / 10000 loss: 63.009636640548706\n",
      "MSE train 3.127547045024904 MSE test 6.560640275758708\n",
      "Epoch 2602 / 10000 loss: 63.002068281173706\n",
      "MSE train 3.1271753537748377 MSE test 6.560260171275653\n",
      "Epoch 2603 / 10000 loss: 62.99441742897034\n",
      "MSE train 3.126792077476844 MSE test 6.559877985819251\n",
      "Epoch 2604 / 10000 loss: 62.98660922050476\n",
      "MSE train 3.1263940475267034 MSE test 6.559493319708695\n",
      "Epoch 2605 / 10000 loss: 62.97854709625244\n",
      "MSE train 3.1259837904322914 MSE test 6.559106242916061\n",
      "Epoch 2606 / 10000 loss: 62.97016263008118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.1255727555904533 MSE test 6.558717807961473\n",
      "Epoch 2607 / 10000 loss: 62.96151256561279\n",
      "MSE train 3.125171975814416 MSE test 6.5583296376547775\n",
      "Epoch 2608 / 10000 loss: 62.95284581184387\n",
      "MSE train 3.124781455311225 MSE test 6.557942314522252\n",
      "Epoch 2609 / 10000 loss: 62.944398403167725\n",
      "MSE train 3.1243961013849453 MSE test 6.5575553282975125\n",
      "Epoch 2610 / 10000 loss: 62.93617391586304\n",
      "MSE train 3.1240121347646777 MSE test 6.557167948289147\n",
      "Epoch 2611 / 10000 loss: 62.92805814743042\n",
      "MSE train 3.1236274512675286 MSE test 6.556779571939071\n",
      "Epoch 2612 / 10000 loss: 62.91997504234314\n",
      "MSE train 3.12324068275826 MSE test 6.55638981646267\n",
      "Epoch 2613 / 10000 loss: 62.9118754863739\n",
      "MSE train 3.122850911861555 MSE test 6.555998253129943\n",
      "Epoch 2614 / 10000 loss: 62.903727293014526\n",
      "MSE train 3.1224574843484207 MSE test 6.555604746123753\n",
      "Epoch 2615 / 10000 loss: 62.8955180644989\n",
      "MSE train 3.122059883387289 MSE test 6.5552089654705705\n",
      "Epoch 2616 / 10000 loss: 62.8872287273407\n",
      "MSE train 3.121657620327061 MSE test 6.554810673208011\n",
      "Epoch 2617 / 10000 loss: 62.878849267959595\n",
      "MSE train 3.121249983824035 MSE test 6.554409777351003\n",
      "Epoch 2618 / 10000 loss: 62.870368242263794\n",
      "MSE train 3.1208357305751853 MSE test 6.554005914999173\n",
      "Epoch 2619 / 10000 loss: 62.86176943778992\n",
      "MSE train 3.120412895584732 MSE test 6.553599024328841\n",
      "Epoch 2620 / 10000 loss: 62.853028774261475\n",
      "MSE train 3.1199782381179295 MSE test 6.553188703911634\n",
      "Epoch 2621 / 10000 loss: 62.844101428985596\n",
      "MSE train 3.119526412374725 MSE test 6.552774878644763\n",
      "Epoch 2622 / 10000 loss: 62.834922075271606\n",
      "MSE train 3.1190485374562718 MSE test 6.552357105263735\n",
      "Epoch 2623 / 10000 loss: 62.82537055015564\n",
      "MSE train 3.1185333667872506 MSE test 6.551935036696375\n",
      "Epoch 2624 / 10000 loss: 62.81525373458862\n",
      "MSE train 3.1179849951636838 MSE test 6.5515083634183435\n",
      "Epoch 2625 / 10000 loss: 62.80433225631714\n",
      "MSE train 3.117439722596133 MSE test 6.551076670484574\n",
      "Epoch 2626 / 10000 loss: 62.792691469192505\n",
      "MSE train 3.116904741644911 MSE test 6.550639950233619\n",
      "Epoch 2627 / 10000 loss: 62.78112173080444\n",
      "MSE train 3.116374469692258 MSE test 6.5501993662163684\n",
      "Epoch 2628 / 10000 loss: 62.769779205322266\n",
      "MSE train 3.1158712749394515 MSE test 6.549758982693213\n",
      "Epoch 2629 / 10000 loss: 62.75854015350342\n",
      "MSE train 3.1153865608138656 MSE test 6.549320861796484\n",
      "Epoch 2630 / 10000 loss: 62.74788475036621\n",
      "MSE train 3.114897732520679 MSE test 6.548883562694477\n",
      "Epoch 2631 / 10000 loss: 62.737624168395996\n",
      "MSE train 3.114408370779905 MSE test 6.548447070360863\n",
      "Epoch 2632 / 10000 loss: 62.72727417945862\n",
      "MSE train 3.1139499670293347 MSE test 6.548015160761674\n",
      "Epoch 2633 / 10000 loss: 62.716907262802124\n",
      "MSE train 3.1135273571572792 MSE test 6.547591057507297\n",
      "Epoch 2634 / 10000 loss: 62.70721173286438\n",
      "MSE train 3.113122993249777 MSE test 6.547173239733516\n",
      "Epoch 2635 / 10000 loss: 62.698288679122925\n",
      "MSE train 3.112727109319293 MSE test 6.546759774991116\n",
      "Epoch 2636 / 10000 loss: 62.68976402282715\n",
      "MSE train 3.112334971708888 MSE test 6.546349337344793\n",
      "Epoch 2637 / 10000 loss: 62.681418895721436\n",
      "MSE train 3.1119428049356217 MSE test 6.545940914923413\n",
      "Epoch 2638 / 10000 loss: 62.673157691955566\n",
      "MSE train 3.1115455429126535 MSE test 6.545533071291558\n",
      "Epoch 2639 / 10000 loss: 62.66489315032959\n",
      "MSE train 3.111133653265356 MSE test 6.545124131026001\n",
      "Epoch 2640 / 10000 loss: 62.6565215587616\n",
      "MSE train 3.110687750212186 MSE test 6.5447119300160095\n",
      "Epoch 2641 / 10000 loss: 62.64783477783203\n",
      "MSE train 3.110194366183169 MSE test 6.544295616667669\n",
      "Epoch 2642 / 10000 loss: 62.638416051864624\n",
      "MSE train 3.109732040899455 MSE test 6.54388506662021\n",
      "Epoch 2643 / 10000 loss: 62.62797284126282\n",
      "MSE train 3.1093284817128604 MSE test 6.543491734215354\n",
      "Epoch 2644 / 10000 loss: 62.61820149421692\n",
      "MSE train 3.10893432970517 MSE test 6.54310588537303\n",
      "Epoch 2645 / 10000 loss: 62.60969090461731\n",
      "MSE train 3.108538744147173 MSE test 6.5427233604849055\n",
      "Epoch 2646 / 10000 loss: 62.60138010978699\n",
      "MSE train 3.1081390048734963 MSE test 6.542342786065773\n",
      "Epoch 2647 / 10000 loss: 62.59303689002991\n",
      "MSE train 3.107734069340958 MSE test 6.541963498535333\n",
      "Epoch 2648 / 10000 loss: 62.5846004486084\n",
      "MSE train 3.107323694157782 MSE test 6.541585088485406\n",
      "Epoch 2649 / 10000 loss: 62.57605338096619\n",
      "MSE train 3.106908171114772 MSE test 6.541207294186216\n",
      "Epoch 2650 / 10000 loss: 62.567384243011475\n",
      "MSE train 3.106488235333288 MSE test 6.540829941310227\n",
      "Epoch 2651 / 10000 loss: 62.55860733985901\n",
      "MSE train 3.106064856759225 MSE test 6.540452821009253\n",
      "Epoch 2652 / 10000 loss: 62.54973244667053\n",
      "MSE train 3.1056390227461774 MSE test 6.540075781350099\n",
      "Epoch 2653 / 10000 loss: 62.540780544281006\n",
      "MSE train 3.1052115287415476 MSE test 6.5396986007897455\n",
      "Epoch 2654 / 10000 loss: 62.53177833557129\n",
      "MSE train 3.104782974571149 MSE test 6.539321073984981\n",
      "Epoch 2655 / 10000 loss: 62.52273988723755\n",
      "MSE train 3.104353716078007 MSE test 6.538943034415911\n",
      "Epoch 2656 / 10000 loss: 62.51367807388306\n",
      "MSE train 3.103923785049738 MSE test 6.5385642842381\n",
      "Epoch 2657 / 10000 loss: 62.504600048065186\n",
      "MSE train 3.1034927866337054 MSE test 6.538184616063943\n",
      "Epoch 2658 / 10000 loss: 62.495505571365356\n",
      "MSE train 3.103059992725822 MSE test 6.537803757699646\n",
      "Epoch 2659 / 10000 loss: 62.486390590667725\n",
      "MSE train 3.1026246235490182 MSE test 6.537421401509058\n",
      "Epoch 2660 / 10000 loss: 62.47723460197449\n",
      "MSE train 3.102185885983675 MSE test 6.537037114278175\n",
      "Epoch 2661 / 10000 loss: 62.46802735328674\n",
      "MSE train 3.101742219027293 MSE test 6.536650221858801\n",
      "Epoch 2662 / 10000 loss: 62.45874261856079\n",
      "MSE train 3.1012899398432574 MSE test 6.536259590179384\n",
      "Epoch 2663 / 10000 loss: 62.44935607910156\n",
      "MSE train 3.100825387291839 MSE test 6.535864592598478\n",
      "Epoch 2664 / 10000 loss: 62.439780950546265\n",
      "MSE train 3.1003555918993984 MSE test 6.535466458806773\n",
      "Epoch 2665 / 10000 loss: 62.42994141578674\n",
      "MSE train 3.099894155330821 MSE test 6.535069784011537\n",
      "Epoch 2666 / 10000 loss: 62.419995069503784\n",
      "MSE train 3.0994290031605054 MSE test 6.534676771140514\n",
      "Epoch 2667 / 10000 loss: 62.41023373603821\n",
      "MSE train 3.098937033906273 MSE test 6.534284134100651\n",
      "Epoch 2668 / 10000 loss: 62.40039396286011\n",
      "MSE train 3.098419882948239 MSE test 6.5338900515476395\n",
      "Epoch 2669 / 10000 loss: 62.3899781703949\n",
      "MSE train 3.09792312237208 MSE test 6.533497476501875\n",
      "Epoch 2670 / 10000 loss: 62.37901759147644\n",
      "MSE train 3.097477763691708 MSE test 6.533111236727667\n",
      "Epoch 2671 / 10000 loss: 62.368496894836426\n",
      "MSE train 3.0970653090429012 MSE test 6.532731086433997\n",
      "Epoch 2672 / 10000 loss: 62.359087228775024\n",
      "MSE train 3.0966654999697862 MSE test 6.532354064538963\n",
      "Epoch 2673 / 10000 loss: 62.35038352012634\n",
      "MSE train 3.0962689713819973 MSE test 6.531978028013219\n",
      "Epoch 2674 / 10000 loss: 62.341954469680786\n",
      "MSE train 3.0958714363748276 MSE test 6.531601705143646\n",
      "Epoch 2675 / 10000 loss: 62.33359432220459\n",
      "MSE train 3.095470526773368 MSE test 6.531224186953511\n",
      "Epoch 2676 / 10000 loss: 62.32521033287048\n",
      "MSE train 3.095064772568096 MSE test 6.530845071140305\n",
      "Epoch 2677 / 10000 loss: 62.31675362586975\n",
      "MSE train 3.0946533773811358 MSE test 6.530463978683498\n",
      "Epoch 2678 / 10000 loss: 62.30819511413574\n",
      "MSE train 3.0942361488900776 MSE test 6.530080883011584\n",
      "Epoch 2679 / 10000 loss: 62.299514055252075\n",
      "MSE train 3.0938138051936654 MSE test 6.529695822824907\n",
      "Epoch 2680 / 10000 loss: 62.290706157684326\n",
      "MSE train 3.0933881455296475 MSE test 6.529309462901664\n",
      "Epoch 2681 / 10000 loss: 62.28179144859314\n",
      "MSE train 3.092961812668985 MSE test 6.52892251368269\n",
      "Epoch 2682 / 10000 loss: 62.272804260253906\n",
      "MSE train 3.0925371289378942 MSE test 6.5285357472917855\n",
      "Epoch 2683 / 10000 loss: 62.2638041973114\n",
      "MSE train 3.092114782855536 MSE test 6.528149795891364\n",
      "Epoch 2684 / 10000 loss: 62.254841327667236\n",
      "MSE train 3.0916935766960507 MSE test 6.52776491492901\n",
      "Epoch 2685 / 10000 loss: 62.24592876434326\n",
      "MSE train 3.091271416187968 MSE test 6.527380969059392\n",
      "Epoch 2686 / 10000 loss: 62.237038373947144\n",
      "MSE train 3.090846223373551 MSE test 6.5269977268084425\n",
      "Epoch 2687 / 10000 loss: 62.22813010215759\n",
      "MSE train 3.090416537308303 MSE test 6.526614855934917\n",
      "Epoch 2688 / 10000 loss: 62.219155073165894\n",
      "MSE train 3.089981762048552 MSE test 6.526232173626491\n",
      "Epoch 2689 / 10000 loss: 62.210084438323975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.089542166194926 MSE test 6.525849435957298\n",
      "Epoch 2690 / 10000 loss: 62.200905323028564\n",
      "MSE train 3.089098577899346 MSE test 6.525466711390439\n",
      "Epoch 2691 / 10000 loss: 62.191622257232666\n",
      "MSE train 3.0886519620504305 MSE test 6.525083872517823\n",
      "Epoch 2692 / 10000 loss: 62.18225312232971\n",
      "MSE train 3.08820310684385 MSE test 6.524700912677341\n",
      "Epoch 2693 / 10000 loss: 62.17281937599182\n",
      "MSE train 3.0877526898934664 MSE test 6.5243177754288295\n",
      "Epoch 2694 / 10000 loss: 62.16334056854248\n",
      "MSE train 3.0873013247936933 MSE test 6.523934381960183\n",
      "Epoch 2695 / 10000 loss: 62.15382957458496\n",
      "MSE train 3.0868494089489555 MSE test 6.523550570166667\n",
      "Epoch 2696 / 10000 loss: 62.14430212974548\n",
      "MSE train 3.0863966878191103 MSE test 6.523166275123072\n",
      "Epoch 2697 / 10000 loss: 62.13476276397705\n",
      "MSE train 3.085942672396629 MSE test 6.522781392540089\n",
      "Epoch 2698 / 10000 loss: 62.125208616256714\n",
      "MSE train 3.085488998300124 MSE test 6.522395972625378\n",
      "Epoch 2699 / 10000 loss: 62.11563062667847\n",
      "MSE train 3.0850416688432207 MSE test 6.522010431846704\n",
      "Epoch 2700 / 10000 loss: 62.106061935424805\n",
      "MSE train 3.084607107620489 MSE test 6.521625490154035\n",
      "Epoch 2701 / 10000 loss: 62.09663128852844\n",
      "MSE train 3.0841852193479937 MSE test 6.5212413998490995\n",
      "Epoch 2702 / 10000 loss: 62.08748149871826\n",
      "MSE train 3.083770360718833 MSE test 6.520857556055559\n",
      "Epoch 2703 / 10000 loss: 62.078606605529785\n",
      "MSE train 3.0833559026803172 MSE test 6.520473515725947\n",
      "Epoch 2704 / 10000 loss: 62.06988501548767\n",
      "MSE train 3.0829350632361123 MSE test 6.520088392218933\n",
      "Epoch 2705 / 10000 loss: 62.06117558479309\n",
      "MSE train 3.082499139323626 MSE test 6.519701691976059\n",
      "Epoch 2706 / 10000 loss: 62.05233025550842\n",
      "MSE train 3.0820368432759326 MSE test 6.519312934170191\n",
      "Epoch 2707 / 10000 loss: 62.04315948486328\n",
      "MSE train 3.0815499235914436 MSE test 6.518922089797815\n",
      "Epoch 2708 / 10000 loss: 62.033421993255615\n",
      "MSE train 3.0810824846398273 MSE test 6.518530604947765\n",
      "Epoch 2709 / 10000 loss: 62.02314901351929\n",
      "MSE train 3.0806527014147056 MSE test 6.518140515937629\n",
      "Epoch 2710 / 10000 loss: 62.01330280303955\n",
      "MSE train 3.0802366832124153 MSE test 6.517751461334468\n",
      "Epoch 2711 / 10000 loss: 62.00426983833313\n",
      "MSE train 3.079823384756172 MSE test 6.517362879777927\n",
      "Epoch 2712 / 10000 loss: 61.9955313205719\n",
      "MSE train 3.079408539783375 MSE test 6.516974728425482\n",
      "Epoch 2713 / 10000 loss: 61.98685359954834\n",
      "MSE train 3.078989358614532 MSE test 6.516586825646705\n",
      "Epoch 2714 / 10000 loss: 61.9781391620636\n",
      "MSE train 3.0785638078602298 MSE test 6.516199164859607\n",
      "Epoch 2715 / 10000 loss: 61.969330072402954\n",
      "MSE train 3.0781309649227504 MSE test 6.515811832062554\n",
      "Epoch 2716 / 10000 loss: 61.960384368896484\n",
      "MSE train 3.077691764678986 MSE test 6.515425053643342\n",
      "Epoch 2717 / 10000 loss: 61.95127773284912\n",
      "MSE train 3.0772493680303357 MSE test 6.515039136125691\n",
      "Epoch 2718 / 10000 loss: 61.94203543663025\n",
      "MSE train 3.0768081616153045 MSE test 6.514654366188538\n",
      "Epoch 2719 / 10000 loss: 61.93272256851196\n",
      "MSE train 3.0763716952492457 MSE test 6.51427103761091\n",
      "Epoch 2720 / 10000 loss: 61.92344069480896\n",
      "MSE train 3.075941334746015 MSE test 6.513889353349163\n",
      "Epoch 2721 / 10000 loss: 61.914260149002075\n",
      "MSE train 3.0755164714426044 MSE test 6.513509155843435\n",
      "Epoch 2722 / 10000 loss: 61.905213832855225\n",
      "MSE train 3.0750949846225435 MSE test 6.5131300933660405\n",
      "Epoch 2723 / 10000 loss: 61.89628887176514\n",
      "MSE train 3.074672389629941 MSE test 6.512751479731004\n",
      "Epoch 2724 / 10000 loss: 61.88744020462036\n",
      "MSE train 3.074233559846191 MSE test 6.5123719893873835\n",
      "Epoch 2725 / 10000 loss: 61.87857007980347\n",
      "MSE train 3.073666334110297 MSE test 6.5119869220526105\n",
      "Epoch 2726 / 10000 loss: 61.86934995651245\n",
      "MSE train 3.0730931092712135 MSE test 6.511583231585068\n",
      "Epoch 2727 / 10000 loss: 61.8573477268219\n",
      "MSE train 3.072682341103686 MSE test 6.511212070665825\n",
      "Epoch 2728 / 10000 loss: 61.845240116119385\n",
      "MSE train 3.072269608624037 MSE test 6.510841627640563\n",
      "Epoch 2729 / 10000 loss: 61.83663988113403\n",
      "MSE train 3.0718517070531894 MSE test 6.5104717465027955\n",
      "Epoch 2730 / 10000 loss: 61.82799553871155\n",
      "MSE train 3.071424478332053 MSE test 6.510102457856062\n",
      "Epoch 2731 / 10000 loss: 61.81924104690552\n",
      "MSE train 3.0709858368577443 MSE test 6.509733598230194\n",
      "Epoch 2732 / 10000 loss: 61.81028461456299\n",
      "MSE train 3.070542395339777 MSE test 6.509365157365357\n",
      "Epoch 2733 / 10000 loss: 61.80107760429382\n",
      "MSE train 3.070108544330659 MSE test 6.508996872486076\n",
      "Epoch 2734 / 10000 loss: 61.79176425933838\n",
      "MSE train 3.069689175507044 MSE test 6.508628679119421\n",
      "Epoch 2735 / 10000 loss: 61.7826566696167\n",
      "MSE train 3.0692774224940935 MSE test 6.508260258906018\n",
      "Epoch 2736 / 10000 loss: 61.7738561630249\n",
      "MSE train 3.0688664307926334 MSE test 6.507890933481716\n",
      "Epoch 2737 / 10000 loss: 61.76521635055542\n",
      "MSE train 3.0684516132756334 MSE test 6.507519950320219\n",
      "Epoch 2738 / 10000 loss: 61.75659203529358\n",
      "MSE train 3.0680279549995904 MSE test 6.507146048735333\n",
      "Epoch 2739 / 10000 loss: 61.74787616729736\n",
      "MSE train 3.067585547675162 MSE test 6.50676722950219\n",
      "Epoch 2740 / 10000 loss: 61.73896908760071\n",
      "MSE train 3.0671017935198894 MSE test 6.506379920149982\n",
      "Epoch 2741 / 10000 loss: 61.72965145111084\n",
      "MSE train 3.0665631161932225 MSE test 6.50598080255891\n",
      "Epoch 2742 / 10000 loss: 61.719433069229126\n",
      "MSE train 3.0660741453378866 MSE test 6.505585111807214\n",
      "Epoch 2743 / 10000 loss: 61.70801877975464\n",
      "MSE train 3.0656435403096376 MSE test 6.5052108314962735\n",
      "Epoch 2744 / 10000 loss: 61.6976797580719\n",
      "MSE train 3.0652232512258166 MSE test 6.504844038984111\n",
      "Epoch 2745 / 10000 loss: 61.68860101699829\n",
      "MSE train 3.064813040268537 MSE test 6.504480929766765\n",
      "Epoch 2746 / 10000 loss: 61.67974066734314\n",
      "MSE train 3.0644191604673647 MSE test 6.504120924045813\n",
      "Epoch 2747 / 10000 loss: 61.67109489440918\n",
      "MSE train 3.0640440675966123 MSE test 6.503763841566643\n",
      "Epoch 2748 / 10000 loss: 61.6628053188324\n",
      "MSE train 3.063685139866463 MSE test 6.503409471641439\n",
      "Epoch 2749 / 10000 loss: 61.65491819381714\n",
      "MSE train 3.0633383150689655 MSE test 6.50305746866757\n",
      "Epoch 2750 / 10000 loss: 61.647380113601685\n",
      "MSE train 3.063000198685689 MSE test 6.502707408139048\n",
      "Epoch 2751 / 10000 loss: 61.64010739326477\n",
      "MSE train 3.0626682804744503 MSE test 6.502358909361691\n",
      "Epoch 2752 / 10000 loss: 61.633021116256714\n",
      "MSE train 3.062340717997403 MSE test 6.502011728514401\n",
      "Epoch 2753 / 10000 loss: 61.62606716156006\n",
      "MSE train 3.0620160688365434 MSE test 6.501665500055755\n",
      "Epoch 2754 / 10000 loss: 61.61920976638794\n",
      "MSE train 3.061693201611153 MSE test 6.501320047870621\n",
      "Epoch 2755 / 10000 loss: 61.61241316795349\n",
      "MSE train 3.0613711379927335 MSE test 6.500975104046723\n",
      "Epoch 2756 / 10000 loss: 61.60565805435181\n",
      "MSE train 3.06104906021224 MSE test 6.500630549934968\n",
      "Epoch 2757 / 10000 loss: 61.59891939163208\n",
      "MSE train 3.0607261407100816 MSE test 6.500286210189923\n",
      "Epoch 2758 / 10000 loss: 61.59218096733093\n",
      "MSE train 3.060401582481165 MSE test 6.499941969163381\n",
      "Epoch 2759 / 10000 loss: 61.585424184799194\n",
      "MSE train 3.060074533367601 MSE test 6.4995976327958696\n",
      "Epoch 2760 / 10000 loss: 61.57863450050354\n",
      "MSE train 3.0597440950644463 MSE test 6.4992530785204385\n",
      "Epoch 2761 / 10000 loss: 61.57178974151611\n",
      "MSE train 3.0594093452832194 MSE test 6.498908211063777\n",
      "Epoch 2762 / 10000 loss: 61.5648729801178\n",
      "MSE train 3.0590693533597735 MSE test 6.498562862081179\n",
      "Epoch 2763 / 10000 loss: 61.557865619659424\n",
      "MSE train 3.0587232876962056 MSE test 6.498216952980382\n",
      "Epoch 2764 / 10000 loss: 61.55074620246887\n",
      "MSE train 3.0583706207625827 MSE test 6.497870561507181\n",
      "Epoch 2765 / 10000 loss: 61.5434992313385\n",
      "MSE train 3.058011447988213 MSE test 6.4975237756424145\n",
      "Epoch 2766 / 10000 loss: 61.53610920906067\n",
      "MSE train 3.057646884098712 MSE test 6.49717692664699\n",
      "Epoch 2767 / 10000 loss: 61.52858209609985\n",
      "MSE train 3.0572792830807 MSE test 6.49683059230141\n",
      "Epoch 2768 / 10000 loss: 61.52093982696533\n",
      "MSE train 3.056911600148536 MSE test 6.496485313317939\n",
      "Epoch 2769 / 10000 loss: 61.51323366165161\n",
      "MSE train 3.05654571881525 MSE test 6.496141773515296\n",
      "Epoch 2770 / 10000 loss: 61.50552845001221\n",
      "MSE train 3.0561803849474374 MSE test 6.49580004088618\n",
      "Epoch 2771 / 10000 loss: 61.49786138534546\n",
      "MSE train 3.0558061927311266 MSE test 6.495459767668375\n",
      "Epoch 2772 / 10000 loss: 61.49020576477051\n",
      "MSE train 3.0553741420009195 MSE test 6.495119723191403\n",
      "Epoch 2773 / 10000 loss: 61.48236083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.054795264505402 MSE test 6.494776464012449\n",
      "Epoch 2774 / 10000 loss: 61.47326588630676\n",
      "MSE train 3.0544358274656296 MSE test 6.494438774708969\n",
      "Epoch 2775 / 10000 loss: 61.4609911441803\n",
      "MSE train 3.0540806230794324 MSE test 6.49410281180339\n",
      "Epoch 2776 / 10000 loss: 61.453457832336426\n",
      "MSE train 3.0537197318837324 MSE test 6.493767228377233\n",
      "Epoch 2777 / 10000 loss: 61.44601559638977\n",
      "MSE train 3.0533503952894763 MSE test 6.493431490799659\n",
      "Epoch 2778 / 10000 loss: 61.43844795227051\n",
      "MSE train 3.052970625782185 MSE test 6.4930954072827305\n",
      "Epoch 2779 / 10000 loss: 61.43069505691528\n",
      "MSE train 3.0525798469734498 MSE test 6.492758921162577\n",
      "Epoch 2780 / 10000 loss: 61.42272114753723\n",
      "MSE train 3.052179312567114 MSE test 6.492422457836511\n",
      "Epoch 2781 / 10000 loss: 61.4145085811615\n",
      "MSE train 3.051771317404157 MSE test 6.4920864675326255\n",
      "Epoch 2782 / 10000 loss: 61.40608501434326\n",
      "MSE train 3.0513578692740033 MSE test 6.49175145971009\n",
      "Epoch 2783 / 10000 loss: 61.39750289916992\n",
      "MSE train 3.0509411761185454 MSE test 6.491417569389915\n",
      "Epoch 2784 / 10000 loss: 61.38880205154419\n",
      "MSE train 3.0505250258796326 MSE test 6.491084720100081\n",
      "Epoch 2785 / 10000 loss: 61.38003706932068\n",
      "MSE train 3.050114037717189 MSE test 6.490752780163306\n",
      "Epoch 2786 / 10000 loss: 61.371283531188965\n",
      "MSE train 3.0497111826161714 MSE test 6.490421636266459\n",
      "Epoch 2787 / 10000 loss: 61.36264455318451\n",
      "MSE train 3.049317184904379 MSE test 6.490091233806173\n",
      "Epoch 2788 / 10000 loss: 61.35418224334717\n",
      "MSE train 3.04893157291626 MSE test 6.489761663486047\n",
      "Epoch 2789 / 10000 loss: 61.34591317176819\n",
      "MSE train 3.048553411828057 MSE test 6.489432901758603\n",
      "Epoch 2790 / 10000 loss: 61.33782684803009\n",
      "MSE train 3.048181561220514 MSE test 6.489104820363989\n",
      "Epoch 2791 / 10000 loss: 61.329901456832886\n",
      "MSE train 3.0478146975165905 MSE test 6.48877738934643\n",
      "Epoch 2792 / 10000 loss: 61.32211434841156\n",
      "MSE train 3.0474513570872706 MSE test 6.488450422100751\n",
      "Epoch 2793 / 10000 loss: 61.314433574676514\n",
      "MSE train 3.0470899977739405 MSE test 6.488123771652702\n",
      "Epoch 2794 / 10000 loss: 61.30682837963104\n",
      "MSE train 3.0467290627925383 MSE test 6.487797212640754\n",
      "Epoch 2795 / 10000 loss: 61.29926574230194\n",
      "MSE train 3.046366966919661 MSE test 6.487470540190366\n",
      "Epoch 2796 / 10000 loss: 61.291711926460266\n",
      "MSE train 3.046002124415479 MSE test 6.487143653614318\n",
      "Epoch 2797 / 10000 loss: 61.28413450717926\n",
      "MSE train 3.0456330244686347 MSE test 6.486816406264277\n",
      "Epoch 2798 / 10000 loss: 61.27649545669556\n",
      "MSE train 3.045258599123197 MSE test 6.486488852536913\n",
      "Epoch 2799 / 10000 loss: 61.2687691450119\n",
      "MSE train 3.0448784681238275 MSE test 6.486161244973972\n",
      "Epoch 2800 / 10000 loss: 61.26092290878296\n",
      "MSE train 3.044493164557695 MSE test 6.485833864182931\n",
      "Epoch 2801 / 10000 loss: 61.25295555591583\n",
      "MSE train 3.0441038900706943 MSE test 6.485507171473352\n",
      "Epoch 2802 / 10000 loss: 61.244871973991394\n",
      "MSE train 3.0437127925166876 MSE test 6.48518164560807\n",
      "Epoch 2803 / 10000 loss: 61.23670053482056\n",
      "MSE train 3.0433243195565427 MSE test 6.484857571759303\n",
      "Epoch 2804 / 10000 loss: 61.22848558425903\n",
      "MSE train 3.0429452971750472 MSE test 6.4845350975183464\n",
      "Epoch 2805 / 10000 loss: 61.22032368183136\n",
      "MSE train 3.0425804326590837 MSE test 6.484214182641924\n",
      "Epoch 2806 / 10000 loss: 61.21236169338226\n",
      "MSE train 3.0422285944953007 MSE test 6.483894736661188\n",
      "Epoch 2807 / 10000 loss: 61.20470118522644\n",
      "MSE train 3.0418850234828545 MSE test 6.483576424837592\n",
      "Epoch 2808 / 10000 loss: 61.19732177257538\n",
      "MSE train 3.041544278624397 MSE test 6.483258985095458\n",
      "Epoch 2809 / 10000 loss: 61.190117955207825\n",
      "MSE train 3.0412005670578615 MSE test 6.482942192203655\n",
      "Epoch 2810 / 10000 loss: 61.182974338531494\n",
      "MSE train 3.0408459483434327 MSE test 6.482625522752449\n",
      "Epoch 2811 / 10000 loss: 61.175761580467224\n",
      "MSE train 3.0404673388758674 MSE test 6.48230879200176\n",
      "Epoch 2812 / 10000 loss: 61.16831421852112\n",
      "MSE train 3.0400524909144955 MSE test 6.481991739897417\n",
      "Epoch 2813 / 10000 loss: 61.1603422164917\n",
      "MSE train 3.0396397700756594 MSE test 6.48167457081628\n",
      "Epoch 2814 / 10000 loss: 61.15158700942993\n",
      "MSE train 3.0392727482110824 MSE test 6.481358762389233\n",
      "Epoch 2815 / 10000 loss: 61.14287090301514\n",
      "MSE train 3.038912350922192 MSE test 6.4810438059620425\n",
      "Epoch 2816 / 10000 loss: 61.135149240493774\n",
      "MSE train 3.0385208532792283 MSE test 6.480728776064397\n",
      "Epoch 2817 / 10000 loss: 61.127572536468506\n",
      "MSE train 3.038035624820001 MSE test 6.480412267076838\n",
      "Epoch 2818 / 10000 loss: 61.11932289600372\n",
      "MSE train 3.037632022845145 MSE test 6.480095766724733\n",
      "Epoch 2819 / 10000 loss: 61.10904002189636\n",
      "MSE train 3.0373084926112144 MSE test 6.479784471266059\n",
      "Epoch 2820 / 10000 loss: 61.100504636764526\n",
      "MSE train 3.0369892028251853 MSE test 6.479474054793649\n",
      "Epoch 2821 / 10000 loss: 61.09372055530548\n",
      "MSE train 3.036672823742113 MSE test 6.479164071243217\n",
      "Epoch 2822 / 10000 loss: 61.08703100681305\n",
      "MSE train 3.0363585431397704 MSE test 6.478854324186218\n",
      "Epoch 2823 / 10000 loss: 61.080403327941895\n",
      "MSE train 3.0360457853339953 MSE test 6.478544514745193\n",
      "Epoch 2824 / 10000 loss: 61.073821663856506\n",
      "MSE train 3.0357340769369183 MSE test 6.478234471993024\n",
      "Epoch 2825 / 10000 loss: 61.067272663116455\n",
      "MSE train 3.035422957721237 MSE test 6.4779239648177525\n",
      "Epoch 2826 / 10000 loss: 61.06074380874634\n",
      "MSE train 3.035111797336759 MSE test 6.4776128444160195\n",
      "Epoch 2827 / 10000 loss: 61.05423104763031\n",
      "MSE train 3.0347998235862677 MSE test 6.477300986740856\n",
      "Epoch 2828 / 10000 loss: 61.047714829444885\n",
      "MSE train 3.0344860918721936 MSE test 6.476988128237472\n",
      "Epoch 2829 / 10000 loss: 61.041181802749634\n",
      "MSE train 3.034169589885695 MSE test 6.476674258541962\n",
      "Epoch 2830 / 10000 loss: 61.03461134433746\n",
      "MSE train 3.033849212917056 MSE test 6.4763591521890715\n",
      "Epoch 2831 / 10000 loss: 61.02797985076904\n",
      "MSE train 3.0335238391411616 MSE test 6.476042886614997\n",
      "Epoch 2832 / 10000 loss: 61.02126336097717\n",
      "MSE train 3.0331922289378817 MSE test 6.475725438360085\n",
      "Epoch 2833 / 10000 loss: 61.01443791389465\n",
      "MSE train 3.0328530071923696 MSE test 6.475406904954485\n",
      "Epoch 2834 / 10000 loss: 61.007476687431335\n",
      "MSE train 3.0325046723773967 MSE test 6.475087337740381\n",
      "Epoch 2835 / 10000 loss: 61.00035071372986\n",
      "MSE train 3.0321459744007897 MSE test 6.474766845108508\n",
      "Epoch 2836 / 10000 loss: 60.99302661418915\n",
      "MSE train 3.0317771646667238 MSE test 6.474445673201152\n",
      "Epoch 2837 / 10000 loss: 60.98547697067261\n",
      "MSE train 3.0314017046954507 MSE test 6.474124107583749\n",
      "Epoch 2838 / 10000 loss: 60.977707505226135\n",
      "MSE train 3.031026140099161 MSE test 6.473802584085439\n",
      "Epoch 2839 / 10000 loss: 60.96979320049286\n",
      "MSE train 3.030655878385041 MSE test 6.473481345164801\n",
      "Epoch 2840 / 10000 loss: 60.96187663078308\n",
      "MSE train 3.0302919569611317 MSE test 6.473160601450266\n",
      "Epoch 2841 / 10000 loss: 60.954073548316956\n",
      "MSE train 3.0299329271580384 MSE test 6.4728404457413005\n",
      "Epoch 2842 / 10000 loss: 60.94640803337097\n",
      "MSE train 3.0295774363707113 MSE test 6.472520572362094\n",
      "Epoch 2843 / 10000 loss: 60.938849329948425\n",
      "MSE train 3.0292246790019157 MSE test 6.472200888845969\n",
      "Epoch 2844 / 10000 loss: 60.9313679933548\n",
      "MSE train 3.028873949502453 MSE test 6.471881347545207\n",
      "Epoch 2845 / 10000 loss: 60.923943877220154\n",
      "MSE train 3.0285243898610053 MSE test 6.4715615877689485\n",
      "Epoch 2846 / 10000 loss: 60.91656720638275\n",
      "MSE train 3.0281750775107645 MSE test 6.471241397973317\n",
      "Epoch 2847 / 10000 loss: 60.90921449661255\n",
      "MSE train 3.027825092210665 MSE test 6.470920572435764\n",
      "Epoch 2848 / 10000 loss: 60.90186965465546\n",
      "MSE train 3.0274734963991716 MSE test 6.470598874865071\n",
      "Epoch 2849 / 10000 loss: 60.89451014995575\n",
      "MSE train 3.0271192612816846 MSE test 6.470275968793863\n",
      "Epoch 2850 / 10000 loss: 60.887115359306335\n",
      "MSE train 3.026760970936455 MSE test 6.469951579611669\n",
      "Epoch 2851 / 10000 loss: 60.87967073917389\n",
      "MSE train 3.0263963667629055 MSE test 6.4696253392637235\n",
      "Epoch 2852 / 10000 loss: 60.87213385105133\n",
      "MSE train 3.026021319449547 MSE test 6.469296690900581\n",
      "Epoch 2853 / 10000 loss: 60.86446475982666\n",
      "MSE train 3.0256273822104336 MSE test 6.468964851689069\n",
      "Epoch 2854 / 10000 loss: 60.856571435928345\n",
      "MSE train 3.025197912965079 MSE test 6.468628948791285\n",
      "Epoch 2855 / 10000 loss: 60.84827268123627\n",
      "MSE train 3.024721778740187 MSE test 6.468288021949574\n",
      "Epoch 2856 / 10000 loss: 60.839213609695435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 3.0242558805045556 MSE test 6.467943600775208\n",
      "Epoch 2857 / 10000 loss: 60.829139709472656\n",
      "MSE train 3.023815823989584 MSE test 6.467598969395676\n",
      "Epoch 2858 / 10000 loss: 60.81928777694702\n",
      "MSE train 3.023363258996027 MSE test 6.467252159991328\n",
      "Epoch 2859 / 10000 loss: 60.80999457836151\n",
      "MSE train 3.0229324246038236 MSE test 6.466904705427725\n",
      "Epoch 2860 / 10000 loss: 60.800427317619324\n",
      "MSE train 3.02254147314488 MSE test 6.466559983027007\n",
      "Epoch 2861 / 10000 loss: 60.791332483291626\n",
      "MSE train 3.0221666969820413 MSE test 6.466217086304359\n",
      "Epoch 2862 / 10000 loss: 60.78309905529022\n",
      "MSE train 3.0217982827881356 MSE test 6.4658749748654945\n",
      "Epoch 2863 / 10000 loss: 60.775219082832336\n",
      "MSE train 3.021433813709786 MSE test 6.465533645503911\n",
      "Epoch 2864 / 10000 loss: 60.767470479011536\n",
      "MSE train 3.021072300904005 MSE test 6.465193213189095\n",
      "Epoch 2865 / 10000 loss: 60.75980520248413\n",
      "MSE train 3.020712913270686 MSE test 6.464853952796486\n",
      "Epoch 2866 / 10000 loss: 60.752201557159424\n",
      "MSE train 3.020354695957415 MSE test 6.464516101719901\n",
      "Epoch 2867 / 10000 loss: 60.744637846946716\n",
      "MSE train 3.0199966292784355 MSE test 6.464179945895604\n",
      "Epoch 2868 / 10000 loss: 60.737098932266235\n",
      "MSE train 3.0196378366316914 MSE test 6.463845544516221\n",
      "Epoch 2869 / 10000 loss: 60.72955787181854\n",
      "MSE train 3.0192777070201045 MSE test 6.46351295328445\n",
      "Epoch 2870 / 10000 loss: 60.721999406814575\n",
      "MSE train 3.0189159372843095 MSE test 6.463182058308229\n",
      "Epoch 2871 / 10000 loss: 60.71440804004669\n",
      "MSE train 3.0185524747922443 MSE test 6.4628526229827115\n",
      "Epoch 2872 / 10000 loss: 60.70678126811981\n",
      "MSE train 3.0181872472732323 MSE test 6.462524458302242\n",
      "Epoch 2873 / 10000 loss: 60.69911539554596\n",
      "MSE train 3.017819917122311 MSE test 6.462197150400899\n",
      "Epoch 2874 / 10000 loss: 60.6914085149765\n",
      "MSE train 3.0174498343337053 MSE test 6.461870324160397\n",
      "Epoch 2875 / 10000 loss: 60.68365514278412\n",
      "MSE train 3.0170761169525644 MSE test 6.461543456279155\n",
      "Epoch 2876 / 10000 loss: 60.6758428812027\n",
      "MSE train 3.0166982534766844 MSE test 6.4612163113094745\n",
      "Epoch 2877 / 10000 loss: 60.667949080467224\n",
      "MSE train 3.016317354159837 MSE test 6.460888915476429\n",
      "Epoch 2878 / 10000 loss: 60.65996563434601\n",
      "MSE train 3.015937146381709 MSE test 6.460562156668139\n",
      "Epoch 2879 / 10000 loss: 60.65191650390625\n",
      "MSE train 3.0155623761034818 MSE test 6.460237245225547\n",
      "Epoch 2880 / 10000 loss: 60.64388072490692\n",
      "MSE train 3.01519497941219 MSE test 6.459915171543365\n",
      "Epoch 2881 / 10000 loss: 60.635961294174194\n",
      "MSE train 3.0148334371424883 MSE test 6.459596327117999\n",
      "Epoch 2882 / 10000 loss: 60.628204584121704\n",
      "MSE train 3.0144757904414115 MSE test 6.459280097786456\n",
      "Epoch 2883 / 10000 loss: 60.62057268619537\n",
      "MSE train 3.0141217494561627 MSE test 6.458966060689171\n",
      "Epoch 2884 / 10000 loss: 60.61302828788757\n",
      "MSE train 3.01377249630053 MSE test 6.458653703017686\n",
      "Epoch 2885 / 10000 loss: 60.60555624961853\n",
      "MSE train 3.013428968102824 MSE test 6.458342578947064\n",
      "Epoch 2886 / 10000 loss: 60.59819424152374\n",
      "MSE train 3.0130908041285966 MSE test 6.458032482106887\n",
      "Epoch 2887 / 10000 loss: 60.59095251560211\n",
      "MSE train 3.0127565033964645 MSE test 6.457722918791035\n",
      "Epoch 2888 / 10000 loss: 60.58382761478424\n",
      "MSE train 3.0124239478041446 MSE test 6.457413773366512\n",
      "Epoch 2889 / 10000 loss: 60.57678818702698\n",
      "MSE train 3.0120907540711968 MSE test 6.4571046772152005\n",
      "Epoch 2890 / 10000 loss: 60.56978511810303\n",
      "MSE train 3.011754370598194 MSE test 6.456795297201314\n",
      "Epoch 2891 / 10000 loss: 60.56277275085449\n",
      "MSE train 3.011412324741559 MSE test 6.456485357725632\n",
      "Epoch 2892 / 10000 loss: 60.55568861961365\n",
      "MSE train 3.0110629921907752 MSE test 6.456174543507705\n",
      "Epoch 2893 / 10000 loss: 60.54848086833954\n",
      "MSE train 3.010706774906064 MSE test 6.455862518135481\n",
      "Epoch 2894 / 10000 loss: 60.54111659526825\n",
      "MSE train 3.0103466763812925 MSE test 6.455549149970313\n",
      "Epoch 2895 / 10000 loss: 60.53360664844513\n",
      "MSE train 3.009986491513476 MSE test 6.45523437543675\n",
      "Epoch 2896 / 10000 loss: 60.52601206302643\n",
      "MSE train 3.0096277915372642 MSE test 6.454917968794043\n",
      "Epoch 2897 / 10000 loss: 60.518412709236145\n",
      "MSE train 3.0092695529199167 MSE test 6.454599966387082\n",
      "Epoch 2898 / 10000 loss: 60.51085114479065\n",
      "MSE train 3.0089099123265965 MSE test 6.454280320582509\n",
      "Epoch 2899 / 10000 loss: 60.50329804420471\n",
      "MSE train 3.0085472080245466 MSE test 6.453959016301525\n",
      "Epoch 2900 / 10000 loss: 60.49571418762207\n",
      "MSE train 3.0081800345030945 MSE test 6.453636017915638\n",
      "Epoch 2901 / 10000 loss: 60.48806703090668\n",
      "MSE train 3.0078071337614967 MSE test 6.453311329995161\n",
      "Epoch 2902 / 10000 loss: 60.48032331466675\n",
      "MSE train 3.0074277262448685 MSE test 6.452984980803516\n",
      "Epoch 2903 / 10000 loss: 60.47245728969574\n",
      "MSE train 3.007041982291062 MSE test 6.45265692948955\n",
      "Epoch 2904 / 10000 loss: 60.4644478559494\n",
      "MSE train 3.006651155284254 MSE test 6.452327526154797\n",
      "Epoch 2905 / 10000 loss: 60.456308484077454\n",
      "MSE train 3.0062571029917486 MSE test 6.451997016166262\n",
      "Epoch 2906 / 10000 loss: 60.448057889938354\n",
      "MSE train 3.0058616888582277 MSE test 6.451665899089976\n",
      "Epoch 2907 / 10000 loss: 60.43973636627197\n",
      "MSE train 3.005466736036197 MSE test 6.4513347166996065\n",
      "Epoch 2908 / 10000 loss: 60.431390166282654\n",
      "MSE train 3.005074263376227 MSE test 6.4510041801895355\n",
      "Epoch 2909 / 10000 loss: 60.423051953315735\n",
      "MSE train 3.0046865477543725 MSE test 6.45067499737592\n",
      "Epoch 2910 / 10000 loss: 60.414772391319275\n",
      "MSE train 3.00430582528084 MSE test 6.450347802119569\n",
      "Epoch 2911 / 10000 loss: 60.40659463405609\n",
      "MSE train 3.003933921408371 MSE test 6.4500230205850055\n",
      "Epoch 2912 / 10000 loss: 60.39857244491577\n",
      "MSE train 3.0035718466418118 MSE test 6.449700963042852\n",
      "Epoch 2913 / 10000 loss: 60.39074122905731\n",
      "MSE train 3.0032196432838987 MSE test 6.44938157896303\n",
      "Epoch 2914 / 10000 loss: 60.38312268257141\n",
      "MSE train 3.0028763130557516 MSE test 6.44906480167202\n",
      "Epoch 2915 / 10000 loss: 60.37571823596954\n",
      "MSE train 3.0025398408472963 MSE test 6.448750329099797\n",
      "Epoch 2916 / 10000 loss: 60.36850357055664\n",
      "MSE train 3.0022069440294734 MSE test 6.448437740575438\n",
      "Epoch 2917 / 10000 loss: 60.36143958568573\n",
      "MSE train 3.001871285085075 MSE test 6.448126670565439\n",
      "Epoch 2918 / 10000 loss: 60.354453325271606\n",
      "MSE train 3.001513854396412 MSE test 6.4478166432637405\n",
      "Epoch 2919 / 10000 loss: 60.34740626811981\n",
      "MSE train 3.00106533668558 MSE test 6.447506751463187\n",
      "Epoch 2920 / 10000 loss: 60.33988583087921\n",
      "MSE train 3.000655830962458 MSE test 6.4471962215454655\n",
      "Epoch 2921 / 10000 loss: 60.330392479896545\n",
      "MSE train 3.00033613215221 MSE test 6.446886831412256\n",
      "Epoch 2922 / 10000 loss: 60.32174301147461\n",
      "MSE train 3.0000135860548394 MSE test 6.446578604664105\n",
      "Epoch 2923 / 10000 loss: 60.31504225730896\n",
      "MSE train 2.9996859102567073 MSE test 6.446270627105511\n",
      "Epoch 2924 / 10000 loss: 60.30828309059143\n",
      "MSE train 2.99934919157499 MSE test 6.445962685739708\n",
      "Epoch 2925 / 10000 loss: 60.30141031742096\n",
      "MSE train 2.9989949049555293 MSE test 6.44565431444792\n",
      "Epoch 2926 / 10000 loss: 60.29434275627136\n",
      "MSE train 2.998605005096749 MSE test 6.445345069459456\n",
      "Epoch 2927 / 10000 loss: 60.2868994474411\n",
      "MSE train 2.9981710238303854 MSE test 6.445034687480289\n",
      "Epoch 2928 / 10000 loss: 60.27868068218231\n",
      "MSE train 2.9977725041637977 MSE test 6.444724825736737\n",
      "Epoch 2929 / 10000 loss: 60.269503474235535\n",
      "MSE train 2.9974279303119857 MSE test 6.444417711760766\n",
      "Epoch 2930 / 10000 loss: 60.261096239089966\n",
      "MSE train 2.997092201466283 MSE test 6.444112066753908\n",
      "Epoch 2931 / 10000 loss: 60.253864884376526\n",
      "MSE train 2.996754964471771 MSE test 6.443807089038937\n",
      "Epoch 2932 / 10000 loss: 60.24682128429413\n",
      "MSE train 2.9964127950463486 MSE test 6.443502526368125\n",
      "Epoch 2933 / 10000 loss: 60.23974919319153\n",
      "MSE train 2.9960629576192632 MSE test 6.44319813912886\n",
      "Epoch 2934 / 10000 loss: 60.2325713634491\n",
      "MSE train 2.9956993298895895 MSE test 6.442893521802061\n",
      "Epoch 2935 / 10000 loss: 60.2252299785614\n",
      "MSE train 2.9952994636207504 MSE test 6.44258770777562\n",
      "Epoch 2936 / 10000 loss: 60.21758961677551\n",
      "MSE train 2.994823397575494 MSE test 6.442279234145035\n",
      "Epoch 2937 / 10000 loss: 60.20916736125946\n",
      "MSE train 2.9944180439520798 MSE test 6.441972162426597\n",
      "Epoch 2938 / 10000 loss: 60.19909179210663\n",
      "MSE train 2.994096544957937 MSE test 6.441674198124309\n",
      "Epoch 2939 / 10000 loss: 60.190547823905945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.9937854425607315 MSE test 6.441378662719196\n",
      "Epoch 2940 / 10000 loss: 60.18382370471954\n",
      "MSE train 2.9934801354818292 MSE test 6.44108469656325\n",
      "Epoch 2941 / 10000 loss: 60.177329778671265\n",
      "MSE train 2.9931786256769928 MSE test 6.44079186753292\n",
      "Epoch 2942 / 10000 loss: 60.170960426330566\n",
      "MSE train 2.9928795257796073 MSE test 6.440499933301213\n",
      "Epoch 2943 / 10000 loss: 60.164679169654846\n",
      "MSE train 2.992581710166948 MSE test 6.4402085837479595\n",
      "Epoch 2944 / 10000 loss: 60.15844976902008\n",
      "MSE train 2.9922843170394415 MSE test 6.439917549103941\n",
      "Epoch 2945 / 10000 loss: 60.1522501707077\n",
      "MSE train 2.991986630630809 MSE test 6.439626629970295\n",
      "Epoch 2946 / 10000 loss: 60.146064043045044\n",
      "MSE train 2.9916879508039 MSE test 6.43933552404653\n",
      "Epoch 2947 / 10000 loss: 60.13987338542938\n",
      "MSE train 2.991387479831484 MSE test 6.439043878363413\n",
      "Epoch 2948 / 10000 loss: 60.13366389274597\n",
      "MSE train 2.9910841026005928 MSE test 6.438751338079667\n",
      "Epoch 2949 / 10000 loss: 60.12741804122925\n",
      "MSE train 2.990776039762472 MSE test 6.438457321148478\n",
      "Epoch 2950 / 10000 loss: 60.12111783027649\n",
      "MSE train 2.9904597807289712 MSE test 6.438160873941419\n",
      "Epoch 2951 / 10000 loss: 60.11471772193909\n",
      "MSE train 2.9901262536187327 MSE test 6.437860238576037\n",
      "Epoch 2952 / 10000 loss: 60.10815107822418\n",
      "MSE train 2.9897472537341145 MSE test 6.4375519208572545\n",
      "Epoch 2953 / 10000 loss: 60.10121726989746\n",
      "MSE train 2.9892741805197844 MSE test 6.4372297269224115\n",
      "Epoch 2954 / 10000 loss: 60.0933198928833\n",
      "MSE train 2.9888733165417727 MSE test 6.436907213406529\n",
      "Epoch 2955 / 10000 loss: 60.08340799808502\n",
      "MSE train 2.9885532022758765 MSE test 6.436610121947694\n",
      "Epoch 2956 / 10000 loss: 60.0750538110733\n",
      "MSE train 2.988235070281444 MSE test 6.436315784343851\n",
      "Epoch 2957 / 10000 loss: 60.0684027671814\n",
      "MSE train 2.9879152964436737 MSE test 6.43602185866453\n",
      "Epoch 2958 / 10000 loss: 60.061787128448486\n",
      "MSE train 2.9875928164644106 MSE test 6.435727797063385\n",
      "Epoch 2959 / 10000 loss: 60.05513536930084\n",
      "MSE train 2.987267128784375 MSE test 6.435433220043188\n",
      "Epoch 2960 / 10000 loss: 60.048421025276184\n",
      "MSE train 2.986937970961367 MSE test 6.435138018186324\n",
      "Epoch 2961 / 10000 loss: 60.04163610935211\n",
      "MSE train 2.9866051929886797 MSE test 6.434842177049995\n",
      "Epoch 2962 / 10000 loss: 60.03477370738983\n",
      "MSE train 2.9862685716362862 MSE test 6.434545618636064\n",
      "Epoch 2963 / 10000 loss: 60.02783143520355\n",
      "MSE train 2.9859276040265263 MSE test 6.434248392170384\n",
      "Epoch 2964 / 10000 loss: 60.020803570747375\n",
      "MSE train 2.985581139494471 MSE test 6.433950397859768\n",
      "Epoch 2965 / 10000 loss: 60.01367902755737\n",
      "MSE train 2.9852270331507564 MSE test 6.433651646439333\n",
      "Epoch 2966 / 10000 loss: 60.006436586380005\n",
      "MSE train 2.984861857552486 MSE test 6.433351946949605\n",
      "Epoch 2967 / 10000 loss: 59.999025106430054\n",
      "MSE train 2.9844818178317105 MSE test 6.433051282746307\n",
      "Epoch 2968 / 10000 loss: 59.991371870040894\n",
      "MSE train 2.9840880711736197 MSE test 6.4327495951432025\n",
      "Epoch 2969 / 10000 loss: 59.98339760303497\n",
      "MSE train 2.9836949355536166 MSE test 6.432447137343933\n",
      "Epoch 2970 / 10000 loss: 59.97512745857239\n",
      "MSE train 2.9833201081987193 MSE test 6.432144433133696\n",
      "Epoch 2971 / 10000 loss: 59.966867327690125\n",
      "MSE train 2.9829639246532342 MSE test 6.431841785163991\n",
      "Epoch 2972 / 10000 loss: 59.95900630950928\n",
      "MSE train 2.982618394204525 MSE test 6.431538930555183\n",
      "Epoch 2973 / 10000 loss: 59.95154881477356\n",
      "MSE train 2.9822787401529407 MSE test 6.431235660804451\n",
      "Epoch 2974 / 10000 loss: 59.94431960582733\n",
      "MSE train 2.9819430994467218 MSE test 6.4309317451577295\n",
      "Epoch 2975 / 10000 loss: 59.93721795082092\n",
      "MSE train 2.9816106574159282 MSE test 6.430627155527738\n",
      "Epoch 2976 / 10000 loss: 59.93020498752594\n",
      "MSE train 2.981280491902664 MSE test 6.430321668053509\n",
      "Epoch 2977 / 10000 loss: 59.923259019851685\n",
      "MSE train 2.9809512921495065 MSE test 6.430015192145979\n",
      "Epoch 2978 / 10000 loss: 59.91636502742767\n",
      "MSE train 2.980621367045879 MSE test 6.4297075763903875\n",
      "Epoch 2979 / 10000 loss: 59.909491300582886\n",
      "MSE train 2.9802887538193943 MSE test 6.429398607902445\n",
      "Epoch 2980 / 10000 loss: 59.902600169181824\n",
      "MSE train 2.9799512190553132 MSE test 6.429088064376253\n",
      "Epoch 2981 / 10000 loss: 59.89565408229828\n",
      "MSE train 2.9796060172583423 MSE test 6.428775779536535\n",
      "Epoch 2982 / 10000 loss: 59.88859796524048\n",
      "MSE train 2.979249588748164 MSE test 6.428461479771984\n",
      "Epoch 2983 / 10000 loss: 59.88137745857239\n",
      "MSE train 2.97887744900506 MSE test 6.428144981777166\n",
      "Epoch 2984 / 10000 loss: 59.87391531467438\n",
      "MSE train 2.9784858973393153 MSE test 6.427826031254415\n",
      "Epoch 2985 / 10000 loss: 59.866111755371094\n",
      "MSE train 2.9780788206407784 MSE test 6.42750475026213\n",
      "Epoch 2986 / 10000 loss: 59.85788702964783\n",
      "MSE train 2.9776733375246502 MSE test 6.42718155491226\n",
      "Epoch 2987 / 10000 loss: 59.84932553768158\n",
      "MSE train 2.9772814001445496 MSE test 6.42685696992325\n",
      "Epoch 2988 / 10000 loss: 59.840800285339355\n",
      "MSE train 2.976894238298302 MSE test 6.426530977863628\n",
      "Epoch 2989 / 10000 loss: 59.83256387710571\n",
      "MSE train 2.976496827965765 MSE test 6.426202877401575\n",
      "Epoch 2990 / 10000 loss: 59.824432611465454\n",
      "MSE train 2.9760853974227586 MSE test 6.425872413140033\n",
      "Epoch 2991 / 10000 loss: 59.81608009338379\n",
      "MSE train 2.9756886039822312 MSE test 6.425540693195965\n",
      "Epoch 2992 / 10000 loss: 59.807422399520874\n",
      "MSE train 2.975320878481236 MSE test 6.4252097620842346\n",
      "Epoch 2993 / 10000 loss: 59.799083948135376\n",
      "MSE train 2.9749619321850775 MSE test 6.424878882232351\n",
      "Epoch 2994 / 10000 loss: 59.791367173194885\n",
      "MSE train 2.9746026056320347 MSE test 6.4245469265201995\n",
      "Epoch 2995 / 10000 loss: 59.78383207321167\n",
      "MSE train 2.974241040679482 MSE test 6.424213548324486\n",
      "Epoch 2996 / 10000 loss: 59.77628743648529\n",
      "MSE train 2.973877002970765 MSE test 6.423878627896134\n",
      "Epoch 2997 / 10000 loss: 59.76869010925293\n",
      "MSE train 2.9735101602682854 MSE test 6.4235420995165455\n",
      "Epoch 2998 / 10000 loss: 59.76103973388672\n",
      "MSE train 2.9731397013071037 MSE test 6.423204025660657\n",
      "Epoch 2999 / 10000 loss: 59.753326773643494\n",
      "MSE train 2.972764747714095 MSE test 6.4228643066428415\n",
      "Epoch 3000 / 10000 loss: 59.74553680419922\n",
      "MSE train 2.9723848247470905 MSE test 6.4225230874269235\n",
      "Epoch 3001 / 10000 loss: 59.737650752067566\n",
      "MSE train 2.9720000459769933 MSE test 6.422180752313766\n",
      "Epoch 3002 / 10000 loss: 59.729655623435974\n",
      "MSE train 2.971610786419572 MSE test 6.421837729619995\n",
      "Epoch 3003 / 10000 loss: 59.72155570983887\n",
      "MSE train 2.971217210694401 MSE test 6.421494605651072\n",
      "Epoch 3004 / 10000 loss: 59.71336281299591\n",
      "MSE train 2.97081903569503 MSE test 6.421151820287996\n",
      "Epoch 3005 / 10000 loss: 59.705076456069946\n",
      "MSE train 2.970415754204096 MSE test 6.420809641446916\n",
      "Epoch 3006 / 10000 loss: 59.6966917514801\n",
      "MSE train 2.9700076202263412 MSE test 6.420468363626945\n",
      "Epoch 3007 / 10000 loss: 59.68819832801819\n",
      "MSE train 2.969596873026044 MSE test 6.42012831277\n",
      "Epoch 3008 / 10000 loss: 59.67960166931152\n",
      "MSE train 2.9691887738865073 MSE test 6.419789949271355\n",
      "Epoch 3009 / 10000 loss: 59.6709486246109\n",
      "MSE train 2.9687903716598454 MSE test 6.41945384576861\n",
      "Epoch 3010 / 10000 loss: 59.662355065345764\n",
      "MSE train 2.968406663350476 MSE test 6.419120817939791\n",
      "Epoch 3011 / 10000 loss: 59.65396559238434\n",
      "MSE train 2.9680382606228117 MSE test 6.418791376619408\n",
      "Epoch 3012 / 10000 loss: 59.64589047431946\n",
      "MSE train 2.9676826191452523 MSE test 6.418465522121121\n",
      "Epoch 3013 / 10000 loss: 59.63813924789429\n",
      "MSE train 2.967336110744166 MSE test 6.418143185214921\n",
      "Epoch 3014 / 10000 loss: 59.63065695762634\n",
      "MSE train 2.9669951297487485 MSE test 6.417823802750491\n",
      "Epoch 3015 / 10000 loss: 59.6233696937561\n",
      "MSE train 2.966656472798263 MSE test 6.417506912299814\n",
      "Epoch 3016 / 10000 loss: 59.6161949634552\n",
      "MSE train 2.9663173106151057 MSE test 6.4171918567354735\n",
      "Epoch 3017 / 10000 loss: 59.609068274497986\n",
      "MSE train 2.9659750594333576 MSE test 6.416878134767373\n",
      "Epoch 3018 / 10000 loss: 59.601927518844604\n",
      "MSE train 2.9656269117400393 MSE test 6.416565287482765\n",
      "Epoch 3019 / 10000 loss: 59.59471607208252\n",
      "MSE train 2.9652693706541813 MSE test 6.416252939775312\n",
      "Epoch 3020 / 10000 loss: 59.587376952171326\n",
      "MSE train 2.964897148717368 MSE test 6.415940867692533\n",
      "Epoch 3021 / 10000 loss: 59.5798305273056\n",
      "MSE train 2.964503094346347 MSE test 6.4156287842922906\n",
      "Epoch 3022 / 10000 loss: 59.571964263916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.9640869756157366 MSE test 6.415316595774074\n",
      "Epoch 3023 / 10000 loss: 59.56362545490265\n",
      "MSE train 2.963677156193349 MSE test 6.415004387766251\n",
      "Epoch 3024 / 10000 loss: 59.55480706691742\n",
      "MSE train 2.9632985523040167 MSE test 6.414692701114283\n",
      "Epoch 3025 / 10000 loss: 59.5461231470108\n",
      "MSE train 2.9629368078443563 MSE test 6.414381592065538\n",
      "Epoch 3026 / 10000 loss: 59.5381144285202\n",
      "MSE train 2.962580042276203 MSE test 6.414071008318239\n",
      "Epoch 3027 / 10000 loss: 59.53047072887421\n",
      "MSE train 2.9622236857359936 MSE test 6.413760721150798\n",
      "Epoch 3028 / 10000 loss: 59.522937059402466\n",
      "MSE train 2.9618651059296464 MSE test 6.41345065989901\n",
      "Epoch 3029 / 10000 loss: 59.51540768146515\n",
      "MSE train 2.9615027042572244 MSE test 6.413140688744608\n",
      "Epoch 3030 / 10000 loss: 59.50783312320709\n",
      "MSE train 2.9611366901045515 MSE test 6.412830817028378\n",
      "Epoch 3031 / 10000 loss: 59.500173687934875\n",
      "MSE train 2.9607701288416948 MSE test 6.412521580110106\n",
      "Epoch 3032 / 10000 loss: 59.49243664741516\n",
      "MSE train 2.9604079638713996 MSE test 6.412213794037831\n",
      "Epoch 3033 / 10000 loss: 59.48468577861786\n",
      "MSE train 2.960053867665688 MSE test 6.411908011992559\n",
      "Epoch 3034 / 10000 loss: 59.47702968120575\n",
      "MSE train 2.9597083423905484 MSE test 6.411604540714743\n",
      "Epoch 3035 / 10000 loss: 59.46954798698425\n",
      "MSE train 2.9593699680266607 MSE test 6.411303028891819\n",
      "Epoch 3036 / 10000 loss: 59.46225106716156\n",
      "MSE train 2.9590370822062804 MSE test 6.411003062318453\n",
      "Epoch 3037 / 10000 loss: 59.45510768890381\n",
      "MSE train 2.958708384745238 MSE test 6.410704256607006\n",
      "Epoch 3038 / 10000 loss: 59.448081731796265\n",
      "MSE train 2.958382859679002 MSE test 6.410406195294515\n",
      "Epoch 3039 / 10000 loss: 59.44114685058594\n",
      "MSE train 2.9580596224718874 MSE test 6.410108524667122\n",
      "Epoch 3040 / 10000 loss: 59.434279799461365\n",
      "MSE train 2.957737808917161 MSE test 6.409811054466269\n",
      "Epoch 3041 / 10000 loss: 59.42746138572693\n",
      "MSE train 2.9574166406825153 MSE test 6.409513519350169\n",
      "Epoch 3042 / 10000 loss: 59.420671820640564\n",
      "MSE train 2.9570954726411145 MSE test 6.409215795413515\n",
      "Epoch 3043 / 10000 loss: 59.41389763355255\n",
      "MSE train 2.9567739135123734 MSE test 6.408917696618385\n",
      "Epoch 3044 / 10000 loss: 59.40712320804596\n",
      "MSE train 2.956451983934741 MSE test 6.408619212128632\n",
      "Epoch 3045 / 10000 loss: 59.400339007377625\n",
      "MSE train 2.956130070668635 MSE test 6.408320385681781\n",
      "Epoch 3046 / 10000 loss: 59.39354872703552\n",
      "MSE train 2.9558089604445863 MSE test 6.408021255519636\n",
      "Epoch 3047 / 10000 loss: 59.38675856590271\n",
      "MSE train 2.9554896803379247 MSE test 6.407722007812018\n",
      "Epoch 3048 / 10000 loss: 59.37998425960541\n",
      "MSE train 2.955173375372661 MSE test 6.407422771752304\n",
      "Epoch 3049 / 10000 loss: 59.373250007629395\n",
      "MSE train 2.954861112862322 MSE test 6.407123665405684\n",
      "Epoch 3050 / 10000 loss: 59.36658012866974\n",
      "MSE train 2.9545536505762957 MSE test 6.406824938047371\n",
      "Epoch 3051 / 10000 loss: 59.3599967956543\n",
      "MSE train 2.9542513071806185 MSE test 6.40652663000169\n",
      "Epoch 3052 / 10000 loss: 59.35352003574371\n",
      "MSE train 2.9539539664328007 MSE test 6.406228820931539\n",
      "Epoch 3053 / 10000 loss: 59.3471542596817\n",
      "MSE train 2.9536611782718034 MSE test 6.405931490082824\n",
      "Epoch 3054 / 10000 loss: 59.34089505672455\n",
      "MSE train 2.95337226924552 MSE test 6.405634519075863\n",
      "Epoch 3055 / 10000 loss: 59.334736585617065\n",
      "MSE train 2.9530865325072226 MSE test 6.40533783944088\n",
      "Epoch 3056 / 10000 loss: 59.32866406440735\n",
      "MSE train 2.9528032240282083 MSE test 6.405041190556562\n",
      "Epoch 3057 / 10000 loss: 59.32265877723694\n",
      "MSE train 2.952521600481056 MSE test 6.404744462350083\n",
      "Epoch 3058 / 10000 loss: 59.31670701503754\n",
      "MSE train 2.9522408410560206 MSE test 6.404447306810342\n",
      "Epoch 3059 / 10000 loss: 59.310792446136475\n",
      "MSE train 2.951959943868675 MSE test 6.404149541349394\n",
      "Epoch 3060 / 10000 loss: 59.30489909648895\n",
      "MSE train 2.951677671737237 MSE test 6.403850872933467\n",
      "Epoch 3061 / 10000 loss: 59.299002170562744\n",
      "MSE train 2.9513924221598957 MSE test 6.4035509424198525\n",
      "Epoch 3062 / 10000 loss: 59.29307746887207\n",
      "MSE train 2.9511022110755443 MSE test 6.403249498249946\n",
      "Epoch 3063 / 10000 loss: 59.28709101676941\n",
      "MSE train 2.9508045531418943 MSE test 6.402946151900557\n",
      "Epoch 3064 / 10000 loss: 59.28099834918976\n",
      "MSE train 2.9504966344132217 MSE test 6.402640630489891\n",
      "Epoch 3065 / 10000 loss: 59.274741768836975\n",
      "MSE train 2.9501758934970184 MSE test 6.402332646673664\n",
      "Epoch 3066 / 10000 loss: 59.26826870441437\n",
      "MSE train 2.9498420748106056 MSE test 6.402022132090108\n",
      "Epoch 3067 / 10000 loss: 59.2615180015564\n",
      "MSE train 2.9495005386467965 MSE test 6.401709341541976\n",
      "Epoch 3068 / 10000 loss: 59.254485726356506\n",
      "MSE train 2.9491615823120045 MSE test 6.401394976022371\n",
      "Epoch 3069 / 10000 loss: 59.247286558151245\n",
      "MSE train 2.9488317458379387 MSE test 6.4010795216628305\n",
      "Epoch 3070 / 10000 loss: 59.240145325660706\n",
      "MSE train 2.9485092975750904 MSE test 6.400763175525503\n",
      "Epoch 3071 / 10000 loss: 59.233203411102295\n",
      "MSE train 2.948189526574992 MSE test 6.400445696534812\n",
      "Epoch 3072 / 10000 loss: 59.226420879364014\n",
      "MSE train 2.947868745396713 MSE test 6.400126704610553\n",
      "Epoch 3073 / 10000 loss: 59.219698905944824\n",
      "MSE train 2.9475448151584285 MSE test 6.399806005491449\n",
      "Epoch 3074 / 10000 loss: 59.21295487880707\n",
      "MSE train 2.9472167443489052 MSE test 6.399483554855535\n",
      "Epoch 3075 / 10000 loss: 59.20614218711853\n",
      "MSE train 2.9468841608231564 MSE test 6.399159449673736\n",
      "Epoch 3076 / 10000 loss: 59.19924080371857\n",
      "MSE train 2.94654668187618 MSE test 6.398833716863314\n",
      "Epoch 3077 / 10000 loss: 59.19224405288696\n",
      "MSE train 2.9462032721841314 MSE test 6.398506290463776\n",
      "Epoch 3078 / 10000 loss: 59.18513882160187\n",
      "MSE train 2.9458517296346813 MSE test 6.398176755519551\n",
      "Epoch 3079 / 10000 loss: 59.177905917167664\n",
      "MSE train 2.9454880094676317 MSE test 6.397844378285604\n",
      "Epoch 3080 / 10000 loss: 59.1704968214035\n",
      "MSE train 2.9451054312678813 MSE test 6.397507975044406\n",
      "Epoch 3081 / 10000 loss: 59.16282260417938\n",
      "MSE train 2.9446953636638176 MSE test 6.397166308765492\n",
      "Epoch 3082 / 10000 loss: 59.15474247932434\n",
      "MSE train 2.9442588013662703 MSE test 6.3968194596987615\n",
      "Epoch 3083 / 10000 loss: 59.1460657119751\n",
      "MSE train 2.943827057319491 MSE test 6.396472795363175\n",
      "Epoch 3084 / 10000 loss: 59.13681602478027\n",
      "MSE train 2.943422440283336 MSE test 6.396134152132397\n",
      "Epoch 3085 / 10000 loss: 59.127670645713806\n",
      "MSE train 2.9430308458798096 MSE test 6.395802893796038\n",
      "Epoch 3086 / 10000 loss: 59.11910629272461\n",
      "MSE train 2.9426428451250977 MSE test 6.395475738553872\n",
      "Epoch 3087 / 10000 loss: 59.11082720756531\n",
      "MSE train 2.942256984320757 MSE test 6.395151023073056\n",
      "Epoch 3088 / 10000 loss: 59.10262310504913\n",
      "MSE train 2.9418740681410016 MSE test 6.394828057937351\n",
      "Epoch 3089 / 10000 loss: 59.09446144104004\n",
      "MSE train 2.9414951065189747 MSE test 6.394506552234017\n",
      "Epoch 3090 / 10000 loss: 59.08636724948883\n",
      "MSE train 2.941120974279705 MSE test 6.394186312824302\n",
      "Epoch 3091 / 10000 loss: 59.07835805416107\n",
      "MSE train 2.940752514466984 MSE test 6.393867256222996\n",
      "Epoch 3092 / 10000 loss: 59.07045340538025\n",
      "MSE train 2.9403905599410476 MSE test 6.393549304804697\n",
      "Epoch 3093 / 10000 loss: 59.06267166137695\n",
      "MSE train 2.940035484521265 MSE test 6.393232424181124\n",
      "Epoch 3094 / 10000 loss: 59.0550320148468\n",
      "MSE train 2.9396868207677085 MSE test 6.392916451716899\n",
      "Epoch 3095 / 10000 loss: 59.04754042625427\n",
      "MSE train 2.9393431656117044 MSE test 6.392601254992183\n",
      "Epoch 3096 / 10000 loss: 59.04018759727478\n",
      "MSE train 2.9390024495539517 MSE test 6.392286538392913\n",
      "Epoch 3097 / 10000 loss: 59.032946825027466\n",
      "MSE train 2.9386621104129045 MSE test 6.391972142460768\n",
      "Epoch 3098 / 10000 loss: 59.02576756477356\n",
      "MSE train 2.9383190261403334 MSE test 6.39165778727618\n",
      "Epoch 3099 / 10000 loss: 59.018598556518555\n",
      "MSE train 2.9379690419001734 MSE test 6.391343162866389\n",
      "Epoch 3100 / 10000 loss: 59.01137018203735\n",
      "MSE train 2.9376060861662596 MSE test 6.391027995312864\n",
      "Epoch 3101 / 10000 loss: 59.00399196147919\n",
      "MSE train 2.937221064566333 MSE test 6.390711923081091\n",
      "Epoch 3102 / 10000 loss: 58.996333718299866\n",
      "MSE train 2.9368035256786738 MSE test 6.390394649286468\n",
      "Epoch 3103 / 10000 loss: 58.98819875717163\n",
      "MSE train 2.936353874302846 MSE test 6.390075913034271\n",
      "Epoch 3104 / 10000 loss: 58.97935891151428\n",
      "MSE train 2.9359029661778724 MSE test 6.389756367568399\n",
      "Epoch 3105 / 10000 loss: 58.969820737838745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.935495045963852 MSE test 6.389437940163737\n",
      "Epoch 3106 / 10000 loss: 58.96025550365448\n",
      "MSE train 2.935131919817839 MSE test 6.389122279132881\n",
      "Epoch 3107 / 10000 loss: 58.95162081718445\n",
      "MSE train 2.934791941119446 MSE test 6.388808660153561\n",
      "Epoch 3108 / 10000 loss: 58.94395697116852\n",
      "MSE train 2.9344642738553164 MSE test 6.388496309290281\n",
      "Epoch 3109 / 10000 loss: 58.93679583072662\n",
      "MSE train 2.9341435904008852 MSE test 6.388184614299234\n",
      "Epoch 3110 / 10000 loss: 58.929901480674744\n",
      "MSE train 2.933825941318916 MSE test 6.3878731819709476\n",
      "Epoch 3111 / 10000 loss: 58.92315852642059\n",
      "MSE train 2.933507973410967 MSE test 6.387561443087267\n",
      "Epoch 3112 / 10000 loss: 58.916481733322144\n",
      "MSE train 2.9331862250604583 MSE test 6.3872488069391435\n",
      "Epoch 3113 / 10000 loss: 58.90979826450348\n",
      "MSE train 2.9328553482510897 MSE test 6.386934270249959\n",
      "Epoch 3114 / 10000 loss: 58.90303301811218\n",
      "MSE train 2.9325024516663754 MSE test 6.386615977851199\n",
      "Epoch 3115 / 10000 loss: 58.8960679769516\n",
      "MSE train 2.9320897529350214 MSE test 6.386290239330502\n",
      "Epoch 3116 / 10000 loss: 58.88862490653992\n",
      "MSE train 2.9315907492572766 MSE test 6.385952311315016\n",
      "Epoch 3117 / 10000 loss: 58.87988483905792\n",
      "MSE train 2.9311901028700285 MSE test 6.385624259767426\n",
      "Epoch 3118 / 10000 loss: 58.8692809343338\n",
      "MSE train 2.9308126641853436 MSE test 6.385311138273892\n",
      "Epoch 3119 / 10000 loss: 58.86081099510193\n",
      "MSE train 2.9304276531496467 MSE test 6.385000148057976\n",
      "Epoch 3120 / 10000 loss: 58.85284245014191\n",
      "MSE train 2.9300636838605976 MSE test 6.384691710829233\n",
      "Epoch 3121 / 10000 loss: 58.84470784664154\n",
      "MSE train 2.9297255526488217 MSE test 6.38438685402039\n",
      "Epoch 3122 / 10000 loss: 58.837031960487366\n",
      "MSE train 2.9294003460078 MSE test 6.38408494298713\n",
      "Epoch 3123 / 10000 loss: 58.82991576194763\n",
      "MSE train 2.929083174304513 MSE test 6.383785431442404\n",
      "Epoch 3124 / 10000 loss: 58.823076605796814\n",
      "MSE train 2.928774227377477 MSE test 6.383488123135367\n",
      "Epoch 3125 / 10000 loss: 58.81641483306885\n",
      "MSE train 2.928474572557995 MSE test 6.383192953318248\n",
      "Epoch 3126 / 10000 loss: 58.80992889404297\n",
      "MSE train 2.9281845124588135 MSE test 6.382899782981611\n",
      "Epoch 3127 / 10000 loss: 58.80364441871643\n",
      "MSE train 2.927903021073777 MSE test 6.38260845665411\n",
      "Epoch 3128 / 10000 loss: 58.79756784439087\n",
      "MSE train 2.927628112850655 MSE test 6.382318540385879\n",
      "Epoch 3129 / 10000 loss: 58.79167675971985\n",
      "MSE train 2.927357432476017 MSE test 6.382029662582936\n",
      "Epoch 3130 / 10000 loss: 58.785929799079895\n",
      "MSE train 2.9270887801333445 MSE test 6.381741298081562\n",
      "Epoch 3131 / 10000 loss: 58.78027057647705\n",
      "MSE train 2.926820216550878 MSE test 6.381453065358128\n",
      "Epoch 3132 / 10000 loss: 58.774656772613525\n",
      "MSE train 2.9265499648276196 MSE test 6.38116443313438\n",
      "Epoch 3133 / 10000 loss: 58.76904332637787\n",
      "MSE train 2.926276145423089 MSE test 6.380874986111072\n",
      "Epoch 3134 / 10000 loss: 58.76339113712311\n",
      "MSE train 2.9259964912282577 MSE test 6.380584333713726\n",
      "Epoch 3135 / 10000 loss: 58.7576584815979\n",
      "MSE train 2.925708105894005 MSE test 6.380292002354989\n",
      "Epoch 3136 / 10000 loss: 58.75179934501648\n",
      "MSE train 2.9254070732720394 MSE test 6.379997564266389\n",
      "Epoch 3137 / 10000 loss: 58.745747208595276\n",
      "MSE train 2.925087675992238 MSE test 6.379700630161588\n",
      "Epoch 3138 / 10000 loss: 58.739418148994446\n",
      "MSE train 2.9247399394008076 MSE test 6.379400795522082\n",
      "Epoch 3139 / 10000 loss: 58.73268938064575\n",
      "MSE train 2.9243434694690884 MSE test 6.379097696566987\n",
      "Epoch 3140 / 10000 loss: 58.72534430027008\n",
      "MSE train 2.923882608873422 MSE test 6.378791041869571\n",
      "Epoch 3141 / 10000 loss: 58.71694016456604\n",
      "MSE train 2.923458733663936 MSE test 6.378483250376043\n",
      "Epoch 3142 / 10000 loss: 58.707138538360596\n",
      "MSE train 2.9231083803216764 MSE test 6.37817804583246\n",
      "Epoch 3143 / 10000 loss: 58.698140382766724\n",
      "MSE train 2.922761499060821 MSE test 6.377872366811643\n",
      "Epoch 3144 / 10000 loss: 58.69073307514191\n",
      "MSE train 2.9223538648088425 MSE test 6.377562163466695\n",
      "Epoch 3145 / 10000 loss: 58.683396220207214\n",
      "MSE train 2.9219342659953873 MSE test 6.377242985514169\n",
      "Epoch 3146 / 10000 loss: 58.67474389076233\n",
      "MSE train 2.9216374008333155 MSE test 6.376945205739743\n",
      "Epoch 3147 / 10000 loss: 58.665825843811035\n",
      "MSE train 2.921343328652035 MSE test 6.376649294453535\n",
      "Epoch 3148 / 10000 loss: 58.6595733165741\n",
      "MSE train 2.921057702527715 MSE test 6.376355742785193\n",
      "Epoch 3149 / 10000 loss: 58.65337896347046\n",
      "MSE train 2.920785826700321 MSE test 6.376065822183807\n",
      "Epoch 3150 / 10000 loss: 58.64736711978912\n",
      "MSE train 2.9205265541472354 MSE test 6.375779968996737\n",
      "Epoch 3151 / 10000 loss: 58.641650319099426\n",
      "MSE train 2.9202751139161593 MSE test 6.375497502923842\n",
      "Epoch 3152 / 10000 loss: 58.63620960712433\n",
      "MSE train 2.920027248147493 MSE test 6.375217448115915\n",
      "Epoch 3153 / 10000 loss: 58.63093674182892\n",
      "MSE train 2.9197801009671327 MSE test 6.374938918551169\n",
      "Epoch 3154 / 10000 loss: 58.62574112415314\n",
      "MSE train 2.919531805510894 MSE test 6.374661168615824\n",
      "Epoch 3155 / 10000 loss: 58.620561838150024\n",
      "MSE train 2.919281072571387 MSE test 6.374383820181211\n",
      "Epoch 3156 / 10000 loss: 58.615357518196106\n",
      "MSE train 2.9190269180009976 MSE test 6.374106375746699\n",
      "Epoch 3157 / 10000 loss: 58.61010181903839\n",
      "MSE train 2.918768513466845 MSE test 6.373828495195959\n",
      "Epoch 3158 / 10000 loss: 58.60476994514465\n",
      "MSE train 2.9185051355014715 MSE test 6.373550045488331\n",
      "Epoch 3159 / 10000 loss: 58.59934914112091\n",
      "MSE train 2.9182361893423994 MSE test 6.373270656897258\n",
      "Epoch 3160 / 10000 loss: 58.59382224082947\n",
      "MSE train 2.917961280560981 MSE test 6.372990286961137\n",
      "Epoch 3161 / 10000 loss: 58.58817100524902\n",
      "MSE train 2.9176804933611993 MSE test 6.372708707794413\n",
      "Epoch 3162 / 10000 loss: 58.582395792007446\n",
      "MSE train 2.91739461507924 MSE test 6.372426047558215\n",
      "Epoch 3163 / 10000 loss: 58.576491951942444\n",
      "MSE train 2.917105226318037 MSE test 6.372142256082152\n",
      "Epoch 3164 / 10000 loss: 58.57048141956329\n",
      "MSE train 2.916814408323817 MSE test 6.371857587618367\n",
      "Epoch 3165 / 10000 loss: 58.564393758773804\n",
      "MSE train 2.9165240716309624 MSE test 6.371572054886949\n",
      "Epoch 3166 / 10000 loss: 58.55827844142914\n",
      "MSE train 2.9162354242927626 MSE test 6.371285831228081\n",
      "Epoch 3167 / 10000 loss: 58.55217361450195\n",
      "MSE train 2.9159488192190968 MSE test 6.370999067829258\n",
      "Epoch 3168 / 10000 loss: 58.546106696128845\n",
      "MSE train 2.91566400929641 MSE test 6.370711710979754\n",
      "Epoch 3169 / 10000 loss: 58.54008483886719\n",
      "MSE train 2.915380372293856 MSE test 6.3704239048976685\n",
      "Epoch 3170 / 10000 loss: 58.534101247787476\n",
      "MSE train 2.915097166118473 MSE test 6.370135660437166\n",
      "Epoch 3171 / 10000 loss: 58.52814829349518\n",
      "MSE train 2.9148136820172317 MSE test 6.369847061023278\n",
      "Epoch 3172 / 10000 loss: 58.52220320701599\n",
      "MSE train 2.9145292610142155 MSE test 6.369558244495669\n",
      "Epoch 3173 / 10000 loss: 58.516252756118774\n",
      "MSE train 2.914243313838947 MSE test 6.3692693339743816\n",
      "Epoch 3174 / 10000 loss: 58.510281682014465\n",
      "MSE train 2.9139551402512582 MSE test 6.368980510053851\n",
      "Epoch 3175 / 10000 loss: 58.50428092479706\n",
      "MSE train 2.913663925577212 MSE test 6.368691774308242\n",
      "Epoch 3176 / 10000 loss: 58.49823224544525\n",
      "MSE train 2.913368712020754 MSE test 6.368403145588621\n",
      "Epoch 3177 / 10000 loss: 58.49212169647217\n",
      "MSE train 2.9130684956979187 MSE test 6.368114470791185\n",
      "Epoch 3178 / 10000 loss: 58.48592293262482\n",
      "MSE train 2.9127624649900983 MSE test 6.367825644686745\n",
      "Epoch 3179 / 10000 loss: 58.47961902618408\n",
      "MSE train 2.912450165233457 MSE test 6.367536559212126\n",
      "Epoch 3180 / 10000 loss: 58.4731924533844\n",
      "MSE train 2.9121317325083522 MSE test 6.367247136500539\n",
      "Epoch 3181 / 10000 loss: 58.46663200855255\n",
      "MSE train 2.911807906562125 MSE test 6.366957463474519\n",
      "Epoch 3182 / 10000 loss: 58.45994210243225\n",
      "MSE train 2.9114799026475944 MSE test 6.366667610974795\n",
      "Epoch 3183 / 10000 loss: 58.45313501358032\n",
      "MSE train 2.9111491959986076 MSE test 6.366377764946947\n",
      "Epoch 3184 / 10000 loss: 58.44624149799347\n",
      "MSE train 2.910817394554438 MSE test 6.366088155840697\n",
      "Epoch 3185 / 10000 loss: 58.439290165901184\n",
      "MSE train 2.9104861882416233 MSE test 6.3657990700249325\n",
      "Epoch 3186 / 10000 loss: 58.43231642246246\n",
      "MSE train 2.910157406316305 MSE test 6.365510733364394\n",
      "Epoch 3187 / 10000 loss: 58.425355434417725\n",
      "MSE train 2.9098329211456333 MSE test 6.365223402276942\n",
      "Epoch 3188 / 10000 loss: 58.41844820976257\n",
      "MSE train 2.909514396417635 MSE test 6.364937333219365\n",
      "Epoch 3189 / 10000 loss: 58.41162967681885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.9092030611440363 MSE test 6.364652739576887\n",
      "Epoch 3190 / 10000 loss: 58.40493953227997\n",
      "MSE train 2.908899551540521 MSE test 6.364369614377936\n",
      "Epoch 3191 / 10000 loss: 58.3984032869339\n",
      "MSE train 2.9086039848450698 MSE test 6.364087958487661\n",
      "Epoch 3192 / 10000 loss: 58.392030000686646\n",
      "MSE train 2.908316014790363 MSE test 6.363807614172942\n",
      "Epoch 3193 / 10000 loss: 58.38582718372345\n",
      "MSE train 2.9080349463009942 MSE test 6.363528453889733\n",
      "Epoch 3194 / 10000 loss: 58.37978267669678\n",
      "MSE train 2.9077598069345694 MSE test 6.363250213970378\n",
      "Epoch 3195 / 10000 loss: 58.37388777732849\n",
      "MSE train 2.907489428528841 MSE test 6.362972598240088\n",
      "Epoch 3196 / 10000 loss: 58.36811637878418\n",
      "MSE train 2.907222497781063 MSE test 6.362695397397167\n",
      "Epoch 3197 / 10000 loss: 58.362446784973145\n",
      "MSE train 2.9069576345351877 MSE test 6.362418195226809\n",
      "Epoch 3198 / 10000 loss: 58.356849193573\n",
      "MSE train 2.9066934186307765 MSE test 6.362140689038839\n",
      "Epoch 3199 / 10000 loss: 58.35129487514496\n",
      "MSE train 2.9064285170264297 MSE test 6.361862525627842\n",
      "Epoch 3200 / 10000 loss: 58.34575366973877\n",
      "MSE train 2.906161741200828 MSE test 6.361583351215193\n",
      "Epoch 3201 / 10000 loss: 58.340195417404175\n",
      "MSE train 2.905892198098827 MSE test 6.361302850426384\n",
      "Epoch 3202 / 10000 loss: 58.33459782600403\n",
      "MSE train 2.9056194386874314 MSE test 6.361020882032917\n",
      "Epoch 3203 / 10000 loss: 58.328941106796265\n",
      "MSE train 2.9053435327984865 MSE test 6.360737281014252\n",
      "Epoch 3204 / 10000 loss: 58.323214530944824\n",
      "MSE train 2.9050648817606572 MSE test 6.360451995231723\n",
      "Epoch 3205 / 10000 loss: 58.31741690635681\n",
      "MSE train 2.9047839056839426 MSE test 6.360165209299713\n",
      "Epoch 3206 / 10000 loss: 58.31156134605408\n",
      "MSE train 2.904500814436998 MSE test 6.359876937919753\n",
      "Epoch 3207 / 10000 loss: 58.305655002593994\n",
      "MSE train 2.9042158624788286 MSE test 6.359587451661201\n",
      "Epoch 3208 / 10000 loss: 58.29970395565033\n",
      "MSE train 2.903930021140455 MSE test 6.359297233653195\n",
      "Epoch 3209 / 10000 loss: 58.29371452331543\n",
      "MSE train 2.9036453050136166 MSE test 6.359007204462847\n",
      "Epoch 3210 / 10000 loss: 58.28770112991333\n",
      "MSE train 2.90336398538721 MSE test 6.358718469179649\n",
      "Epoch 3211 / 10000 loss: 58.28171527385712\n",
      "MSE train 2.9030872256102085 MSE test 6.358432061817236\n",
      "Epoch 3212 / 10000 loss: 58.27580523490906\n",
      "MSE train 2.9028144384760624 MSE test 6.358148358569593\n",
      "Epoch 3213 / 10000 loss: 58.269991517066956\n",
      "MSE train 2.902543949681755 MSE test 6.357867235053696\n",
      "Epoch 3214 / 10000 loss: 58.26426613330841\n",
      "MSE train 2.9022738844021907 MSE test 6.357588277326666\n",
      "Epoch 3215 / 10000 loss: 58.25859010219574\n",
      "MSE train 2.9020026276482507 MSE test 6.357310916321529\n",
      "Epoch 3216 / 10000 loss: 58.252922892570496\n",
      "MSE train 2.901728973095186 MSE test 6.357034725559015\n",
      "Epoch 3217 / 10000 loss: 58.24722909927368\n",
      "MSE train 2.901451999939272 MSE test 6.356759323471662\n",
      "Epoch 3218 / 10000 loss: 58.2414870262146\n",
      "MSE train 2.901171005115867 MSE test 6.356484439337452\n",
      "Epoch 3219 / 10000 loss: 58.23567092418671\n",
      "MSE train 2.9008853151910228 MSE test 6.356209854678875\n",
      "Epoch 3220 / 10000 loss: 58.229767203330994\n",
      "MSE train 2.900594189224453 MSE test 6.355935434126898\n",
      "Epoch 3221 / 10000 loss: 58.223763942718506\n",
      "MSE train 2.9002968166695515 MSE test 6.355661037957006\n",
      "Epoch 3222 / 10000 loss: 58.217644691467285\n",
      "MSE train 2.8999925347386926 MSE test 6.355386525174527\n",
      "Epoch 3223 / 10000 loss: 58.21138823032379\n",
      "MSE train 2.8996814623957157 MSE test 6.355111679564916\n",
      "Epoch 3224 / 10000 loss: 58.2049857378006\n",
      "MSE train 2.899365276390476 MSE test 6.3548365629383445\n",
      "Epoch 3225 / 10000 loss: 58.198431849479675\n",
      "MSE train 2.899047143402443 MSE test 6.354561074982882\n",
      "Epoch 3226 / 10000 loss: 58.191771030426025\n",
      "MSE train 2.898730130056572 MSE test 6.354285251674761\n",
      "Epoch 3227 / 10000 loss: 58.18506681919098\n",
      "MSE train 2.8984155990822464 MSE test 6.3540091339074225\n",
      "Epoch 3228 / 10000 loss: 58.17838680744171\n",
      "MSE train 2.8981033649881818 MSE test 6.353732592391438\n",
      "Epoch 3229 / 10000 loss: 58.17175912857056\n",
      "MSE train 2.8977928886126287 MSE test 6.353455706836462\n",
      "Epoch 3230 / 10000 loss: 58.16518235206604\n",
      "MSE train 2.8974838376203764 MSE test 6.3531784617962\n",
      "Epoch 3231 / 10000 loss: 58.15864646434784\n",
      "MSE train 2.897175809933868 MSE test 6.35290084613928\n",
      "Epoch 3232 / 10000 loss: 58.15213692188263\n",
      "MSE train 2.896867777117684 MSE test 6.352622677787717\n",
      "Epoch 3233 / 10000 loss: 58.145649671554565\n",
      "MSE train 2.8965576048606616 MSE test 6.352343569509434\n",
      "Epoch 3234 / 10000 loss: 58.13916265964508\n",
      "MSE train 2.8962415250111375 MSE test 6.352062716482842\n",
      "Epoch 3235 / 10000 loss: 58.132627964019775\n",
      "MSE train 2.895913069059293 MSE test 6.351778824588056\n",
      "Epoch 3236 / 10000 loss: 58.1259640455246\n",
      "MSE train 2.8955596939061916 MSE test 6.351489798642274\n",
      "Epoch 3237 / 10000 loss: 58.1190322637558\n",
      "MSE train 2.8951546923135867 MSE test 6.351192230862269\n",
      "Epoch 3238 / 10000 loss: 58.11155903339386\n",
      "MSE train 2.8946751595133042 MSE test 6.350881636072184\n",
      "Epoch 3239 / 10000 loss: 58.10296380519867\n",
      "MSE train 2.89422850452906 MSE test 6.3505607694811586\n",
      "Epoch 3240 / 10000 loss: 58.09275233745575\n",
      "MSE train 2.8938281208152747 MSE test 6.350234153334066\n",
      "Epoch 3241 / 10000 loss: 58.08325445652008\n",
      "MSE train 2.893439437015014 MSE test 6.349897086791398\n",
      "Epoch 3242 / 10000 loss: 58.0747594833374\n",
      "MSE train 2.893079199516652 MSE test 6.349563914644469\n",
      "Epoch 3243 / 10000 loss: 58.06651723384857\n",
      "MSE train 2.8927489677861287 MSE test 6.349246292772214\n",
      "Epoch 3244 / 10000 loss: 58.05889415740967\n",
      "MSE train 2.892443824972892 MSE test 6.3489433240604445\n",
      "Epoch 3245 / 10000 loss: 58.05191957950592\n",
      "MSE train 2.8921583917644837 MSE test 6.348651156239959\n",
      "Epoch 3246 / 10000 loss: 58.04548978805542\n",
      "MSE train 2.8918867311838157 MSE test 6.348366796923779\n",
      "Epoch 3247 / 10000 loss: 58.03948521614075\n",
      "MSE train 2.8916236998043514 MSE test 6.348088060512277\n",
      "Epoch 3248 / 10000 loss: 58.03377878665924\n",
      "MSE train 2.8913654972923633 MSE test 6.3478134279426595\n",
      "Epoch 3249 / 10000 loss: 58.02826166152954\n",
      "MSE train 2.891109455399575 MSE test 6.347541823283449\n",
      "Epoch 3250 / 10000 loss: 58.022849798202515\n",
      "MSE train 2.8908535306781222 MSE test 6.347272328884375\n",
      "Epoch 3251 / 10000 loss: 58.01748335361481\n",
      "MSE train 2.890596064267932 MSE test 6.347004282414031\n",
      "Epoch 3252 / 10000 loss: 58.012117981910706\n",
      "MSE train 2.8903355499627783 MSE test 6.346737096653384\n",
      "Epoch 3253 / 10000 loss: 58.00672471523285\n",
      "MSE train 2.8900705277664565 MSE test 6.346470515521314\n",
      "Epoch 3254 / 10000 loss: 58.00126230716705\n",
      "MSE train 2.889799562054864 MSE test 6.346203878609828\n",
      "Epoch 3255 / 10000 loss: 57.99570322036743\n",
      "MSE train 2.8895213535428232 MSE test 6.345936994912962\n",
      "Epoch 3256 / 10000 loss: 57.99001657962799\n",
      "MSE train 2.889234687028632 MSE test 6.345669480292077\n",
      "Epoch 3257 / 10000 loss: 57.98417329788208\n",
      "MSE train 2.888937853280089 MSE test 6.345400895159337\n",
      "Epoch 3258 / 10000 loss: 57.978142738342285\n",
      "MSE train 2.8886280446649035 MSE test 6.345131011377128\n",
      "Epoch 3259 / 10000 loss: 57.971896171569824\n",
      "MSE train 2.888306208642005 MSE test 6.3448597506307935\n",
      "Epoch 3260 / 10000 loss: 57.965365171432495\n",
      "MSE train 2.8879913341530448 MSE test 6.344588139014639\n",
      "Epoch 3261 / 10000 loss: 57.95857357978821\n",
      "MSE train 2.887707531386061 MSE test 6.34431843656908\n",
      "Epoch 3262 / 10000 loss: 57.951934814453125\n",
      "MSE train 2.887450106024111 MSE test 6.344051420627574\n",
      "Epoch 3263 / 10000 loss: 57.94596588611603\n",
      "MSE train 2.8872056316157515 MSE test 6.3437862134164495\n",
      "Epoch 3264 / 10000 loss: 57.940571784973145\n",
      "MSE train 2.8869671721750736 MSE test 6.343522057320225\n",
      "Epoch 3265 / 10000 loss: 57.93545687198639\n",
      "MSE train 2.8867316272937775 MSE test 6.343258566642218\n",
      "Epoch 3266 / 10000 loss: 57.93047285079956\n",
      "MSE train 2.886497514225106 MSE test 6.342995633722256\n",
      "Epoch 3267 / 10000 loss: 57.92555093765259\n",
      "MSE train 2.8862640407417683 MSE test 6.342733211640339\n",
      "Epoch 3268 / 10000 loss: 57.92065989971161\n",
      "MSE train 2.8860307854691714 MSE test 6.342471358909664\n",
      "Epoch 3269 / 10000 loss: 57.915786147117615\n",
      "MSE train 2.88579747025857 MSE test 6.342210069555071\n",
      "Epoch 3270 / 10000 loss: 57.91091203689575\n",
      "MSE train 2.885563921264621 MSE test 6.341949385390263\n",
      "Epoch 3271 / 10000 loss: 57.906036615371704\n",
      "MSE train 2.8853299864277306 MSE test 6.341689211297567\n",
      "Epoch 3272 / 10000 loss: 57.90115487575531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.8850954785945975 MSE test 6.341429512170341\n",
      "Epoch 3273 / 10000 loss: 57.89626598358154\n",
      "MSE train 2.8848602011308198 MSE test 6.341170062218266\n",
      "Epoch 3274 / 10000 loss: 57.891361117362976\n",
      "MSE train 2.884623883391536 MSE test 6.340910619407432\n",
      "Epoch 3275 / 10000 loss: 57.88643991947174\n",
      "MSE train 2.8843861775222903 MSE test 6.340650927990945\n",
      "Epoch 3276 / 10000 loss: 57.881494641304016\n",
      "MSE train 2.8841465094088417 MSE test 6.340390582267496\n",
      "Epoch 3277 / 10000 loss: 57.876518964767456\n",
      "MSE train 2.8839037496080966 MSE test 6.340129098548385\n",
      "Epoch 3278 / 10000 loss: 57.871498823165894\n",
      "MSE train 2.883655344507286 MSE test 6.339865808086906\n",
      "Epoch 3279 / 10000 loss: 57.86641311645508\n",
      "MSE train 2.883394996755789 MSE test 6.339599724210508\n",
      "Epoch 3280 / 10000 loss: 57.86120367050171\n",
      "MSE train 2.8831066251676476 MSE test 6.339328889404579\n",
      "Epoch 3281 / 10000 loss: 57.85573363304138\n",
      "MSE train 2.882761696451404 MSE test 6.339050465303293\n",
      "Epoch 3282 / 10000 loss: 57.849658131599426\n",
      "MSE train 2.882409969251972 MSE test 6.338766507960929\n",
      "Epoch 3283 / 10000 loss: 57.84235644340515\n",
      "MSE train 2.88214178019266 MSE test 6.338494160758577\n",
      "Epoch 3284 / 10000 loss: 57.83490216732025\n",
      "MSE train 2.8818926884470937 MSE test 6.338228390668642\n",
      "Epoch 3285 / 10000 loss: 57.82925736904144\n",
      "MSE train 2.881644554776623 MSE test 6.337964065461825\n",
      "Epoch 3286 / 10000 loss: 57.82402980327606\n",
      "MSE train 2.881394125514137 MSE test 6.337699853882458\n",
      "Epoch 3287 / 10000 loss: 57.81882405281067\n",
      "MSE train 2.881140208010192 MSE test 6.337435385126254\n",
      "Epoch 3288 / 10000 loss: 57.81356716156006\n",
      "MSE train 2.880882291978065 MSE test 6.337170410807803\n",
      "Epoch 3289 / 10000 loss: 57.80823624134064\n",
      "MSE train 2.8806202903402105 MSE test 6.3369048527749365\n",
      "Epoch 3290 / 10000 loss: 57.80281710624695\n",
      "MSE train 2.880354401871807 MSE test 6.336638655975797\n",
      "Epoch 3291 / 10000 loss: 57.79730927944183\n",
      "MSE train 2.8800850084970517 MSE test 6.33637188577601\n",
      "Epoch 3292 / 10000 loss: 57.79171943664551\n",
      "MSE train 2.879812455353629 MSE test 6.336104572620447\n",
      "Epoch 3293 / 10000 loss: 57.78605270385742\n",
      "MSE train 2.8795368884232952 MSE test 6.335836824801676\n",
      "Epoch 3294 / 10000 loss: 57.78031837940216\n",
      "MSE train 2.879258184424361 MSE test 6.335568577110023\n",
      "Epoch 3295 / 10000 loss: 57.77451956272125\n",
      "MSE train 2.8789759977232463 MSE test 6.335299888094895\n",
      "Epoch 3296 / 10000 loss: 57.76865327358246\n",
      "MSE train 2.878689917850488 MSE test 6.3350306471326014\n",
      "Epoch 3297 / 10000 loss: 57.762712597846985\n",
      "MSE train 2.8783995798471453 MSE test 6.334760778785079\n",
      "Epoch 3298 / 10000 loss: 57.756686091423035\n",
      "MSE train 2.8781047934561985 MSE test 6.334490217254389\n",
      "Epoch 3299 / 10000 loss: 57.75056743621826\n",
      "MSE train 2.8778056536015977 MSE test 6.334218990748573\n",
      "Epoch 3300 / 10000 loss: 57.74435496330261\n",
      "MSE train 2.8775029241135806 MSE test 6.333946986077755\n",
      "Epoch 3301 / 10000 loss: 57.738046646118164\n",
      "MSE train 2.8771984555101726 MSE test 6.333674540742154\n",
      "Epoch 3302 / 10000 loss: 57.73166215419769\n",
      "MSE train 2.8768951843998387 MSE test 6.333401970016865\n",
      "Epoch 3303 / 10000 loss: 57.725242137908936\n",
      "MSE train 2.8765959788160615 MSE test 6.333129455873359\n",
      "Epoch 3304 / 10000 loss: 57.71884548664093\n",
      "MSE train 2.876301938053868 MSE test 6.332857321932669\n",
      "Epoch 3305 / 10000 loss: 57.71253943443298\n",
      "MSE train 2.876011932778621 MSE test 6.332585395495423\n",
      "Epoch 3306 / 10000 loss: 57.70634603500366\n",
      "MSE train 2.875723177071837 MSE test 6.332313467458279\n",
      "Epoch 3307 / 10000 loss: 57.70024132728577\n",
      "MSE train 2.875431691329033 MSE test 6.3320410843539605\n",
      "Epoch 3308 / 10000 loss: 57.694164872169495\n",
      "MSE train 2.8751311709788814 MSE test 6.331767703183618\n",
      "Epoch 3309 / 10000 loss: 57.68803071975708\n",
      "MSE train 2.8748093552726695 MSE test 6.331492410908325\n",
      "Epoch 3310 / 10000 loss: 57.68169987201691\n",
      "MSE train 2.874447495479564 MSE test 6.331213999784135\n",
      "Epoch 3311 / 10000 loss: 57.67490911483765\n",
      "MSE train 2.874071934801624 MSE test 6.330933249731664\n",
      "Epoch 3312 / 10000 loss: 57.66725492477417\n",
      "MSE train 2.8737627380805666 MSE test 6.330657888217218\n",
      "Epoch 3313 / 10000 loss: 57.65930378437042\n",
      "MSE train 2.8734886054362887 MSE test 6.330388604762233\n",
      "Epoch 3314 / 10000 loss: 57.652788400650024\n",
      "MSE train 2.873226126361133 MSE test 6.330122019424568\n",
      "Epoch 3315 / 10000 loss: 57.647029876708984\n",
      "MSE train 2.872970872369853 MSE test 6.329857090043147\n",
      "Epoch 3316 / 10000 loss: 57.64152431488037\n",
      "MSE train 2.87272094734641 MSE test 6.329593464863659\n",
      "Epoch 3317 / 10000 loss: 57.63617551326752\n",
      "MSE train 2.87247481466795 MSE test 6.329330755818891\n",
      "Epoch 3318 / 10000 loss: 57.63094115257263\n",
      "MSE train 2.872231058713792 MSE test 6.329068779610297\n",
      "Epoch 3319 / 10000 loss: 57.625789642333984\n",
      "MSE train 2.8719884151724155 MSE test 6.328807345672021\n",
      "Epoch 3320 / 10000 loss: 57.620688915252686\n",
      "MSE train 2.8717457735019973 MSE test 6.328546241820417\n",
      "Epoch 3321 / 10000 loss: 57.615612864494324\n",
      "MSE train 2.8715022013978335 MSE test 6.328285321391015\n",
      "Epoch 3322 / 10000 loss: 57.610538363456726\n",
      "MSE train 2.8712569935241827 MSE test 6.3280244008530335\n",
      "Epoch 3323 / 10000 loss: 57.605440855026245\n",
      "MSE train 2.8710096629785675 MSE test 6.3277633554035875\n",
      "Epoch 3324 / 10000 loss: 57.60031056404114\n",
      "MSE train 2.8707600523666446 MSE test 6.327501983897136\n",
      "Epoch 3325 / 10000 loss: 57.59513545036316\n",
      "MSE train 2.8705082581281878 MSE test 6.32724024260473\n",
      "Epoch 3326 / 10000 loss: 57.58990800380707\n",
      "MSE train 2.870254638694345 MSE test 6.326977904607692\n",
      "Epoch 3327 / 10000 loss: 57.584636092185974\n",
      "MSE train 2.8699997837877955 MSE test 6.326714969323812\n",
      "Epoch 3328 / 10000 loss: 57.579325675964355\n",
      "MSE train 2.8697444173761006 MSE test 6.326451320058098\n",
      "Epoch 3329 / 10000 loss: 57.573986291885376\n",
      "MSE train 2.8694892331764117 MSE test 6.326186852838132\n",
      "Epoch 3330 / 10000 loss: 57.56863570213318\n",
      "MSE train 2.869234763312173 MSE test 6.32592141646166\n",
      "Epoch 3331 / 10000 loss: 57.563292145729065\n",
      "MSE train 2.8689812113091455 MSE test 6.325654990420072\n",
      "Epoch 3332 / 10000 loss: 57.55796468257904\n",
      "MSE train 2.8687283773964563 MSE test 6.3253874006318975\n",
      "Epoch 3333 / 10000 loss: 57.55265665054321\n",
      "MSE train 2.868475752723177 MSE test 6.32511856073686\n",
      "Epoch 3334 / 10000 loss: 57.547364592552185\n",
      "MSE train 2.868222610376488 MSE test 6.324848396851813\n",
      "Epoch 3335 / 10000 loss: 57.542078375816345\n",
      "MSE train 2.8679682012880177 MSE test 6.324576762122135\n",
      "Epoch 3336 / 10000 loss: 57.5367830991745\n",
      "MSE train 2.867711722072392 MSE test 6.324303623632652\n",
      "Epoch 3337 / 10000 loss: 57.53145921230316\n",
      "MSE train 2.8674524398719123 MSE test 6.324028843728364\n",
      "Epoch 3338 / 10000 loss: 57.5260910987854\n",
      "MSE train 2.8671896056194695 MSE test 6.323752456623408\n",
      "Epoch 3339 / 10000 loss: 57.52066421508789\n",
      "MSE train 2.8669224427587987 MSE test 6.323474400045247\n",
      "Epoch 3340 / 10000 loss: 57.5151606798172\n",
      "MSE train 2.866650115049487 MSE test 6.3231947070088435\n",
      "Epoch 3341 / 10000 loss: 57.50956463813782\n",
      "MSE train 2.866371684847959 MSE test 6.32291348681864\n",
      "Epoch 3342 / 10000 loss: 57.50385642051697\n",
      "MSE train 2.8660860988921697 MSE test 6.3226308354859\n",
      "Epoch 3343 / 10000 loss: 57.49801802635193\n",
      "MSE train 2.865792155931581 MSE test 6.322346914986737\n",
      "Epoch 3344 / 10000 loss: 57.49202263355255\n",
      "MSE train 2.865488633779673 MSE test 6.322061886619667\n",
      "Epoch 3345 / 10000 loss: 57.485849380493164\n",
      "MSE train 2.8651745661944696 MSE test 6.321776066185208\n",
      "Epoch 3346 / 10000 loss: 57.47946763038635\n",
      "MSE train 2.8648499830430487 MSE test 6.321489724216056\n",
      "Epoch 3347 / 10000 loss: 57.47285807132721\n",
      "MSE train 2.8645170891860934 MSE test 6.321203261779639\n",
      "Epoch 3348 / 10000 loss: 57.46602118015289\n",
      "MSE train 2.8641807001223554 MSE test 6.3209171940425115\n",
      "Epoch 3349 / 10000 loss: 57.4590026140213\n",
      "MSE train 2.8638463975740356 MSE test 6.320632067174147\n",
      "Epoch 3350 / 10000 loss: 57.451910853385925\n",
      "MSE train 2.8635177437195485 MSE test 6.3203482686145165\n",
      "Epoch 3351 / 10000 loss: 57.444862842559814\n",
      "MSE train 2.8631961980307423 MSE test 6.320065960520917\n",
      "Epoch 3352 / 10000 loss: 57.43793594837189\n",
      "MSE train 2.8628825937750157 MSE test 6.319785079504046\n",
      "Epoch 3353 / 10000 loss: 57.43116354942322\n",
      "MSE train 2.86257761600561 MSE test 6.319505625390396\n",
      "Epoch 3354 / 10000 loss: 57.42456018924713\n",
      "MSE train 2.86228135045597 MSE test 6.319227383244417\n",
      "Epoch 3355 / 10000 loss: 57.41814613342285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.8619931816484265 MSE test 6.3189502915657325\n",
      "Epoch 3356 / 10000 loss: 57.411916613578796\n",
      "MSE train 2.8617119867045995 MSE test 6.318674004425195\n",
      "Epoch 3357 / 10000 loss: 57.40586233139038\n",
      "MSE train 2.8614364222381465 MSE test 6.318398378757659\n",
      "Epoch 3358 / 10000 loss: 57.399959325790405\n",
      "MSE train 2.8611651906130375 MSE test 6.318123119882279\n",
      "Epoch 3359 / 10000 loss: 57.394177317619324\n",
      "MSE train 2.860897113560195 MSE test 6.317848147282165\n",
      "Epoch 3360 / 10000 loss: 57.38849174976349\n",
      "MSE train 2.860631159666548 MSE test 6.317573082233577\n",
      "Epoch 3361 / 10000 loss: 57.38287329673767\n",
      "MSE train 2.860366449350026 MSE test 6.31729792693439\n",
      "Epoch 3362 / 10000 loss: 57.37730133533478\n",
      "MSE train 2.8601022794623203 MSE test 6.317022423726995\n",
      "Epoch 3363 / 10000 loss: 57.37175631523132\n",
      "MSE train 2.859838048353779 MSE test 6.3167465914539145\n",
      "Epoch 3364 / 10000 loss: 57.366222620010376\n",
      "MSE train 2.8595733725764454 MSE test 6.316470235459447\n",
      "Epoch 3365 / 10000 loss: 57.360690236091614\n",
      "MSE train 2.8593080483532214 MSE test 6.316193246022307\n",
      "Epoch 3366 / 10000 loss: 57.3551470041275\n",
      "MSE train 2.8590420493066264 MSE test 6.315915618692481\n",
      "Epoch 3367 / 10000 loss: 57.34959268569946\n",
      "MSE train 2.8587754472185654 MSE test 6.315637261384059\n",
      "Epoch 3368 / 10000 loss: 57.34402406215668\n",
      "MSE train 2.8585082437435627 MSE test 6.315358105122815\n",
      "Epoch 3369 / 10000 loss: 57.33844435214996\n",
      "MSE train 2.858240246883595 MSE test 6.315078058625351\n",
      "Epoch 3370 / 10000 loss: 57.33285319805145\n",
      "MSE train 2.8579709931030073 MSE test 6.31479679709967\n",
      "Epoch 3371 / 10000 loss: 57.327245593070984\n",
      "MSE train 2.8576996956077467 MSE test 6.314514328377732\n",
      "Epoch 3372 / 10000 loss: 57.32161343097687\n",
      "MSE train 2.857425171187419 MSE test 6.314230225558519\n",
      "Epoch 3373 / 10000 loss: 57.315937519073486\n",
      "MSE train 2.857145680651276 MSE test 6.313944046473535\n",
      "Epoch 3374 / 10000 loss: 57.31019341945648\n",
      "MSE train 2.856858158040733 MSE test 6.31365506141732\n",
      "Epoch 3375 / 10000 loss: 57.30434262752533\n",
      "MSE train 2.8565546937725705 MSE test 6.313361994528507\n",
      "Epoch 3376 / 10000 loss: 57.29832136631012\n",
      "MSE train 2.856202861641156 MSE test 6.313061528475075\n",
      "Epoch 3377 / 10000 loss: 57.29195785522461\n",
      "MSE train 2.855694189417812 MSE test 6.3127444395223415\n",
      "Epoch 3378 / 10000 loss: 57.28455376625061\n",
      "MSE train 2.8553255979260554 MSE test 6.312426621645371\n",
      "Epoch 3379 / 10000 loss: 57.27375018596649\n",
      "MSE train 2.855019093059363 MSE test 6.3121348819689755\n",
      "Epoch 3380 / 10000 loss: 57.26596748828888\n",
      "MSE train 2.8547075508766815 MSE test 6.311842211297318\n",
      "Epoch 3381 / 10000 loss: 57.25953769683838\n",
      "MSE train 2.854391345176936 MSE test 6.311548399128137\n",
      "Epoch 3382 / 10000 loss: 57.25300145149231\n",
      "MSE train 2.854071044653549 MSE test 6.311253481729808\n",
      "Epoch 3383 / 10000 loss: 57.24636173248291\n",
      "MSE train 2.85374728200152 MSE test 6.310957340038255\n",
      "Epoch 3384 / 10000 loss: 57.239635705947876\n",
      "MSE train 2.8534204805604286 MSE test 6.310659908058137\n",
      "Epoch 3385 / 10000 loss: 57.23283398151398\n",
      "MSE train 2.853090355879569 MSE test 6.310361091539255\n",
      "Epoch 3386 / 10000 loss: 57.22596502304077\n",
      "MSE train 2.852754700353509 MSE test 6.3100602684209575\n",
      "Epoch 3387 / 10000 loss: 57.2190226316452\n",
      "MSE train 2.852405155809303 MSE test 6.309756547019932\n",
      "Epoch 3388 / 10000 loss: 57.21195864677429\n",
      "MSE train 2.8520094897661177 MSE test 6.309447446898752\n",
      "Epoch 3389 / 10000 loss: 57.20459270477295\n",
      "MSE train 2.851520811211631 MSE test 6.309127937389513\n",
      "Epoch 3390 / 10000 loss: 57.19622731208801\n",
      "MSE train 2.851159297034987 MSE test 6.308817105298587\n",
      "Epoch 3391 / 10000 loss: 57.18584167957306\n",
      "MSE train 2.8508442100213327 MSE test 6.308523437411018\n",
      "Epoch 3392 / 10000 loss: 57.17821133136749\n",
      "MSE train 2.850535100391751 MSE test 6.308232890353507\n",
      "Epoch 3393 / 10000 loss: 57.1715874671936\n",
      "MSE train 2.8502311555798356 MSE test 6.307945111119234\n",
      "Epoch 3394 / 10000 loss: 57.16509199142456\n",
      "MSE train 2.8499311355537524 MSE test 6.307659882819819\n",
      "Epoch 3395 / 10000 loss: 57.15870749950409\n",
      "MSE train 2.8496332794666817 MSE test 6.30737696774456\n",
      "Epoch 3396 / 10000 loss: 57.15240728855133\n",
      "MSE train 2.849335692256755 MSE test 6.3070960052734115\n",
      "Epoch 3397 / 10000 loss: 57.14614999294281\n",
      "MSE train 2.849036535091838 MSE test 6.306816564275925\n",
      "Epoch 3398 / 10000 loss: 57.13990092277527\n",
      "MSE train 2.8487342382396914 MSE test 6.306538201697767\n",
      "Epoch 3399 / 10000 loss: 57.13361477851868\n",
      "MSE train 2.848427604159379 MSE test 6.306260639700603\n",
      "Epoch 3400 / 10000 loss: 57.12725806236267\n",
      "MSE train 2.848116076531284 MSE test 6.305983659692194\n",
      "Epoch 3401 / 10000 loss: 57.12080907821655\n",
      "MSE train 2.8478000608383987 MSE test 6.30570710773771\n",
      "Epoch 3402 / 10000 loss: 57.114253282547\n",
      "MSE train 2.8474810818480747 MSE test 6.305430928802224\n",
      "Epoch 3403 / 10000 loss: 57.10759925842285\n",
      "MSE train 2.8471613138020873 MSE test 6.305155319296484\n",
      "Epoch 3404 / 10000 loss: 57.10088074207306\n",
      "MSE train 2.846842450747763 MSE test 6.304880454518737\n",
      "Epoch 3405 / 10000 loss: 57.09414494037628\n",
      "MSE train 2.846524864216931 MSE test 6.3046063799503465\n",
      "Epoch 3406 / 10000 loss: 57.087427854537964\n",
      "MSE train 2.8462078023434247 MSE test 6.30433317284584\n",
      "Epoch 3407 / 10000 loss: 57.080740094184875\n",
      "MSE train 2.845890303644512 MSE test 6.30406077382114\n",
      "Epoch 3408 / 10000 loss: 57.07406270503998\n",
      "MSE train 2.845572192767497 MSE test 6.303789078413918\n",
      "Epoch 3409 / 10000 loss: 57.067373514175415\n",
      "MSE train 2.8452546911501737 MSE test 6.3035180802658255\n",
      "Epoch 3410 / 10000 loss: 57.0606734752655\n",
      "MSE train 2.844940177009265 MSE test 6.303247778526531\n",
      "Epoch 3411 / 10000 loss: 57.053983211517334\n",
      "MSE train 2.8446311408322376 MSE test 6.302978081888155\n",
      "Epoch 3412 / 10000 loss: 57.047356963157654\n",
      "MSE train 2.8443289888611853 MSE test 6.302708982020763\n",
      "Epoch 3413 / 10000 loss: 57.04084801673889\n",
      "MSE train 2.8440337353105565 MSE test 6.302440399525885\n",
      "Epoch 3414 / 10000 loss: 57.03448975086212\n",
      "MSE train 2.8437443987305455 MSE test 6.302172182096102\n",
      "Epoch 3415 / 10000 loss: 57.028276324272156\n",
      "MSE train 2.8434596625251602 MSE test 6.3019041956647275\n",
      "Epoch 3416 / 10000 loss: 57.02219295501709\n",
      "MSE train 2.8431782404666373 MSE test 6.301636259942159\n",
      "Epoch 3417 / 10000 loss: 57.01620638370514\n",
      "MSE train 2.84289895505126 MSE test 6.301368222141464\n",
      "Epoch 3418 / 10000 loss: 57.0102915763855\n",
      "MSE train 2.8426208222310834 MSE test 6.301100046513081\n",
      "Epoch 3419 / 10000 loss: 57.00442087650299\n",
      "MSE train 2.842343008119219 MSE test 6.300831570551488\n",
      "Epoch 3420 / 10000 loss: 56.998576521873474\n",
      "MSE train 2.8420649158756843 MSE test 6.300562719097428\n",
      "Epoch 3421 / 10000 loss: 56.99273717403412\n",
      "MSE train 2.8417863262230973 MSE test 6.300293587025464\n",
      "Epoch 3422 / 10000 loss: 56.98689067363739\n",
      "MSE train 2.8415074491222607 MSE test 6.300024203722533\n",
      "Epoch 3423 / 10000 loss: 56.98103415966034\n",
      "MSE train 2.841228914802099 MSE test 6.299754720969582\n",
      "Epoch 3424 / 10000 loss: 56.975170493125916\n",
      "MSE train 2.840951571711899 MSE test 6.299485304500994\n",
      "Epoch 3425 / 10000 loss: 56.96931481361389\n",
      "MSE train 2.840676151951817 MSE test 6.299216184873725\n",
      "Epoch 3426 / 10000 loss: 56.96348166465759\n",
      "MSE train 2.8404029822505494 MSE test 6.298947575642256\n",
      "Epoch 3427 / 10000 loss: 56.957690834999084\n",
      "MSE train 2.8401318473253916 MSE test 6.298679568903169\n",
      "Epoch 3428 / 10000 loss: 56.951947927474976\n",
      "MSE train 2.8398620315410708 MSE test 6.298412045458577\n",
      "Epoch 3429 / 10000 loss: 56.94624853134155\n",
      "MSE train 2.8395925155099695 MSE test 6.298145054067038\n",
      "Epoch 3430 / 10000 loss: 56.94057643413544\n",
      "MSE train 2.839322092519494 MSE test 6.297878496469911\n",
      "Epoch 3431 / 10000 loss: 56.93491053581238\n",
      "MSE train 2.839049510309579 MSE test 6.297612076398614\n",
      "Epoch 3432 / 10000 loss: 56.92922282218933\n",
      "MSE train 2.8387736344445123 MSE test 6.297345809317869\n",
      "Epoch 3433 / 10000 loss: 56.92349112033844\n",
      "MSE train 2.838493540348559 MSE test 6.297079470429553\n",
      "Epoch 3434 / 10000 loss: 56.91768789291382\n",
      "MSE train 2.8382087295457823 MSE test 6.296812888216835\n",
      "Epoch 3435 / 10000 loss: 56.91179156303406\n",
      "MSE train 2.837919301820655 MSE test 6.29654599370027\n",
      "Epoch 3436 / 10000 loss: 56.905792474746704\n",
      "MSE train 2.83762614253371 MSE test 6.296278880523549\n",
      "Epoch 3437 / 10000 loss: 56.899696826934814\n",
      "MSE train 2.8373310498085385 MSE test 6.296011606921107\n",
      "Epoch 3438 / 10000 loss: 56.89351665973663\n",
      "MSE train 2.837036453788318 MSE test 6.295744239220424\n",
      "Epoch 3439 / 10000 loss: 56.887298464775085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.8367445742776964 MSE test 6.295476990314316\n",
      "Epoch 3440 / 10000 loss: 56.88108837604523\n",
      "MSE train 2.836456383212935 MSE test 6.295209912788894\n",
      "Epoch 3441 / 10000 loss: 56.874937415122986\n",
      "MSE train 2.8361714549949095 MSE test 6.294942932022298\n",
      "Epoch 3442 / 10000 loss: 56.8688668012619\n",
      "MSE train 2.8358887275618305 MSE test 6.2946759880840215\n",
      "Epoch 3443 / 10000 loss: 56.86286675930023\n",
      "MSE train 2.835607413117733 MSE test 6.294409056111407\n",
      "Epoch 3444 / 10000 loss: 56.856914043426514\n",
      "MSE train 2.8353274105423676 MSE test 6.294141845277208\n",
      "Epoch 3445 / 10000 loss: 56.85099482536316\n",
      "MSE train 2.835049008179576 MSE test 6.293874556040161\n",
      "Epoch 3446 / 10000 loss: 56.845102310180664\n",
      "MSE train 2.8347723212469083 MSE test 6.293607121247372\n",
      "Epoch 3447 / 10000 loss: 56.83924436569214\n",
      "MSE train 2.8344968840225033 MSE test 6.293339530236211\n",
      "Epoch 3448 / 10000 loss: 56.83342516422272\n",
      "MSE train 2.834221836213604 MSE test 6.293071725168871\n",
      "Epoch 3449 / 10000 loss: 56.82763457298279\n",
      "MSE train 2.8339463524810884 MSE test 6.292803696056615\n",
      "Epoch 3450 / 10000 loss: 56.821852684020996\n",
      "MSE train 2.8336700675970548 MSE test 6.292535457284184\n",
      "Epoch 3451 / 10000 loss: 56.81606459617615\n",
      "MSE train 2.833393238690848 MSE test 6.292267153884736\n",
      "Epoch 3452 / 10000 loss: 56.8102570772171\n",
      "MSE train 2.8331165672454914 MSE test 6.291999070923736\n",
      "Epoch 3453 / 10000 loss: 56.80444145202637\n",
      "MSE train 2.832840687572719 MSE test 6.291731381191914\n",
      "Epoch 3454 / 10000 loss: 56.79863119125366\n",
      "MSE train 2.8325654984519075 MSE test 6.291464301230932\n",
      "Epoch 3455 / 10000 loss: 56.79283797740936\n",
      "MSE train 2.832289815886883 MSE test 6.291197730276186\n",
      "Epoch 3456 / 10000 loss: 56.78706204891205\n",
      "MSE train 2.832010980747723 MSE test 6.290931453282177\n",
      "Epoch 3457 / 10000 loss: 56.781280636787415\n",
      "MSE train 2.8317240324300337 MSE test 6.290665177162092\n",
      "Epoch 3458 / 10000 loss: 56.77543115615845\n",
      "MSE train 2.831420000965179 MSE test 6.290398231883123\n",
      "Epoch 3459 / 10000 loss: 56.76941514015198\n",
      "MSE train 2.8310859359810223 MSE test 6.290130036669828\n",
      "Epoch 3460 / 10000 loss: 56.7630352973938\n",
      "MSE train 2.830726484263629 MSE test 6.2898603081844495\n",
      "Epoch 3461 / 10000 loss: 56.75601518154144\n",
      "MSE train 2.830392640604737 MSE test 6.289590650439176\n",
      "Epoch 3462 / 10000 loss: 56.74845778942108\n",
      "MSE train 2.830091908625115 MSE test 6.289322350852594\n",
      "Epoch 3463 / 10000 loss: 56.74145519733429\n",
      "MSE train 2.8297962857037073 MSE test 6.289054249520357\n",
      "Epoch 3464 / 10000 loss: 56.73515605926514\n",
      "MSE train 2.8294972028656105 MSE test 6.288785765438532\n",
      "Epoch 3465 / 10000 loss: 56.728965640068054\n",
      "MSE train 2.829196984758359 MSE test 6.288517211361639\n",
      "Epoch 3466 / 10000 loss: 56.72270202636719\n",
      "MSE train 2.8289023719227724 MSE test 6.288249499682912\n",
      "Epoch 3467 / 10000 loss: 56.71641290187836\n",
      "MSE train 2.8286177867622997 MSE test 6.287983758535768\n",
      "Epoch 3468 / 10000 loss: 56.71024739742279\n",
      "MSE train 2.8283427489156066 MSE test 6.287720236919377\n",
      "Epoch 3469 / 10000 loss: 56.70429170131683\n",
      "MSE train 2.8280748425250994 MSE test 6.287458719382045\n",
      "Epoch 3470 / 10000 loss: 56.69853615760803\n",
      "MSE train 2.8278121758378005 MSE test 6.287198758826469\n",
      "Epoch 3471 / 10000 loss: 56.692925214767456\n",
      "MSE train 2.8275535819466064 MSE test 6.286940004817887\n",
      "Epoch 3472 / 10000 loss: 56.68742263317108\n",
      "MSE train 2.827298216454674 MSE test 6.286682171263655\n",
      "Epoch 3473 / 10000 loss: 56.68200469017029\n",
      "MSE train 2.8270452505406483 MSE test 6.286425083341952\n",
      "Epoch 3474 / 10000 loss: 56.67665195465088\n",
      "MSE train 2.826793786486174 MSE test 6.286168534638498\n",
      "Epoch 3475 / 10000 loss: 56.67134714126587\n",
      "MSE train 2.8265429228939842 MSE test 6.285912352063042\n",
      "Epoch 3476 / 10000 loss: 56.66607463359833\n",
      "MSE train 2.82629183222876 MSE test 6.285656531112666\n",
      "Epoch 3477 / 10000 loss: 56.66081082820892\n",
      "MSE train 2.8260398624719607 MSE test 6.285400831996883\n",
      "Epoch 3478 / 10000 loss: 56.65554082393646\n",
      "MSE train 2.825786581759641 MSE test 6.285145446777414\n",
      "Epoch 3479 / 10000 loss: 56.650254011154175\n",
      "MSE train 2.8255318089695076 MSE test 6.284890198414391\n",
      "Epoch 3480 / 10000 loss: 56.64493465423584\n",
      "MSE train 2.8252756351497976 MSE test 6.284635244720469\n",
      "Epoch 3481 / 10000 loss: 56.639580965042114\n",
      "MSE train 2.825018416972804 MSE test 6.284380657010227\n",
      "Epoch 3482 / 10000 loss: 56.63419830799103\n",
      "MSE train 2.8247607769203205 MSE test 6.284126447666854\n",
      "Epoch 3483 / 10000 loss: 56.628791093826294\n",
      "MSE train 2.8245034833072915 MSE test 6.283872830899022\n",
      "Epoch 3484 / 10000 loss: 56.623374223709106\n",
      "MSE train 2.8242474085979947 MSE test 6.28361995486395\n",
      "Epoch 3485 / 10000 loss: 56.61796772480011\n",
      "MSE train 2.823993343684597 MSE test 6.28336788041465\n",
      "Epoch 3486 / 10000 loss: 56.61258375644684\n",
      "MSE train 2.8237419701385593 MSE test 6.283116631825451\n",
      "Epoch 3487 / 10000 loss: 56.60724401473999\n",
      "MSE train 2.8234937212007303 MSE test 6.282866294791788\n",
      "Epoch 3488 / 10000 loss: 56.60196340084076\n",
      "MSE train 2.823248712473638 MSE test 6.282616834729293\n",
      "Epoch 3489 / 10000 loss: 56.596749901771545\n",
      "MSE train 2.8230066966557286 MSE test 6.282368191162787\n",
      "Epoch 3490 / 10000 loss: 56.5916051864624\n",
      "MSE train 2.8227670471809256 MSE test 6.282120204939526\n",
      "Epoch 3491 / 10000 loss: 56.58652675151825\n",
      "MSE train 2.8225287704872644 MSE test 6.281872651914637\n",
      "Epoch 3492 / 10000 loss: 56.58149719238281\n",
      "MSE train 2.8222906201090203 MSE test 6.281625302888106\n",
      "Epoch 3493 / 10000 loss: 56.57649898529053\n",
      "MSE train 2.8220511363507232 MSE test 6.281377990217841\n",
      "Epoch 3494 / 10000 loss: 56.5715047121048\n",
      "MSE train 2.8218088459960344 MSE test 6.281130377414136\n",
      "Epoch 3495 / 10000 loss: 56.56647872924805\n",
      "MSE train 2.8215624405899806 MSE test 6.280882245520588\n",
      "Epoch 3496 / 10000 loss: 56.56139147281647\n",
      "MSE train 2.8213110187399213 MSE test 6.280633312027013\n",
      "Epoch 3497 / 10000 loss: 56.556215047836304\n",
      "MSE train 2.8210540849563253 MSE test 6.280383458681113\n",
      "Epoch 3498 / 10000 loss: 56.55093038082123\n",
      "MSE train 2.8207910907327043 MSE test 6.2801325369089565\n",
      "Epoch 3499 / 10000 loss: 56.545525670051575\n",
      "MSE train 2.8205203415673905 MSE test 6.279880226886992\n",
      "Epoch 3500 / 10000 loss: 56.5399888753891\n",
      "MSE train 2.8202377077962177 MSE test 6.279626051585209\n",
      "Epoch 3501 / 10000 loss: 56.5342857837677\n",
      "MSE train 2.8199356049827067 MSE test 6.279369204539389\n",
      "Epoch 3502 / 10000 loss: 56.52832269668579\n",
      "MSE train 2.819603424073348 MSE test 6.279108796958892\n",
      "Epoch 3503 / 10000 loss: 56.52193629741669\n",
      "MSE train 2.8192351223030534 MSE test 6.278844421732302\n",
      "Epoch 3504 / 10000 loss: 56.51490020751953\n",
      "MSE train 2.8188507586799756 MSE test 6.27857830500914\n",
      "Epoch 3505 / 10000 loss: 56.507081151008606\n",
      "MSE train 2.8184932616632654 MSE test 6.278316014406278\n",
      "Epoch 3506 / 10000 loss: 56.49890649318695\n",
      "MSE train 2.818171503643971 MSE test 6.278060619051282\n",
      "Epoch 3507 / 10000 loss: 56.491315960884094\n",
      "MSE train 2.817867010268103 MSE test 6.277810440228277\n",
      "Epoch 3508 / 10000 loss: 56.484498262405396\n",
      "MSE train 2.8175687306246973 MSE test 6.2775634644438805\n",
      "Epoch 3509 / 10000 loss: 56.478058218955994\n",
      "MSE train 2.8172729090302706 MSE test 6.277318430318886\n",
      "Epoch 3510 / 10000 loss: 56.47175180912018\n",
      "MSE train 2.8169780963296938 MSE test 6.277074747790661\n",
      "Epoch 3511 / 10000 loss: 56.46549999713898\n",
      "MSE train 2.8166845233122872 MSE test 6.276832013047422\n",
      "Epoch 3512 / 10000 loss: 56.45926868915558\n",
      "MSE train 2.8163965682006755 MSE test 6.276590299544646\n",
      "Epoch 3513 / 10000 loss: 56.45306646823883\n",
      "MSE train 2.8161225821624143 MSE test 6.276350154157239\n",
      "Epoch 3514 / 10000 loss: 56.446988105773926\n",
      "MSE train 2.815867238024083 MSE test 6.276111923537901\n",
      "Epoch 3515 / 10000 loss: 56.44121062755585\n",
      "MSE train 2.81562752117156 MSE test 6.275875620145729\n",
      "Epoch 3516 / 10000 loss: 56.43583941459656\n",
      "MSE train 2.8153976969294106 MSE test 6.275640860796648\n",
      "Epoch 3517 / 10000 loss: 56.430806398391724\n",
      "MSE train 2.815173114677624 MSE test 6.275407180915509\n",
      "Epoch 3518 / 10000 loss: 56.425989270210266\n",
      "MSE train 2.8149505508782178 MSE test 6.275174180213091\n",
      "Epoch 3519 / 10000 loss: 56.42128503322601\n",
      "MSE train 2.8147277532492807 MSE test 6.274941591135548\n",
      "Epoch 3520 / 10000 loss: 56.41662776470184\n",
      "MSE train 2.814503086119062 MSE test 6.274709058963175\n",
      "Epoch 3521 / 10000 loss: 56.41196155548096\n",
      "MSE train 2.8142754947914264 MSE test 6.274476401251555\n",
      "Epoch 3522 / 10000 loss: 56.40725755691528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.814044590686275 MSE test 6.274243452254464\n",
      "Epoch 3523 / 10000 loss: 56.40249419212341\n",
      "MSE train 2.813810717798179 MSE test 6.274010102906206\n",
      "Epoch 3524 / 10000 loss: 56.397653102874756\n",
      "MSE train 2.813574838833008 MSE test 6.273776188883676\n",
      "Epoch 3525 / 10000 loss: 56.39275312423706\n",
      "MSE train 2.813337991760073 MSE test 6.273541649775872\n",
      "Epoch 3526 / 10000 loss: 56.38780879974365\n",
      "MSE train 2.8131007831711368 MSE test 6.273306443130884\n",
      "Epoch 3527 / 10000 loss: 56.382845997810364\n",
      "MSE train 2.812862967073415 MSE test 6.273070356994121\n",
      "Epoch 3528 / 10000 loss: 56.377872824668884\n",
      "MSE train 2.8126236801264883 MSE test 6.272833142575422\n",
      "Epoch 3529 / 10000 loss: 56.37289023399353\n",
      "MSE train 2.812381780778192 MSE test 6.272594697209404\n",
      "Epoch 3530 / 10000 loss: 56.36787545681\n",
      "MSE train 2.812136040662948 MSE test 6.272354617617771\n",
      "Epoch 3531 / 10000 loss: 56.36280632019043\n",
      "MSE train 2.8118849977542726 MSE test 6.272112531724864\n",
      "Epoch 3532 / 10000 loss: 56.35765278339386\n",
      "MSE train 2.8116260132546724 MSE test 6.271867622579961\n",
      "Epoch 3533 / 10000 loss: 56.352386713027954\n",
      "MSE train 2.811350531601638 MSE test 6.271618398797147\n",
      "Epoch 3534 / 10000 loss: 56.34694993495941\n",
      "MSE train 2.811013589358594 MSE test 6.271360322776387\n",
      "Epoch 3535 / 10000 loss: 56.34116005897522\n",
      "MSE train 2.810513295428521 MSE test 6.2710790430901815\n",
      "Epoch 3536 / 10000 loss: 56.3340460062027\n",
      "MSE train 2.8102341949197536 MSE test 6.270824080425096\n",
      "Epoch 3537 / 10000 loss: 56.32339382171631\n",
      "MSE train 2.809963200315785 MSE test 6.270578351142293\n",
      "Epoch 3538 / 10000 loss: 56.3175253868103\n",
      "MSE train 2.8096885136337497 MSE test 6.27033255043917\n",
      "Epoch 3539 / 10000 loss: 56.311830282211304\n",
      "MSE train 2.809409444458195 MSE test 6.270086297640397\n",
      "Epoch 3540 / 10000 loss: 56.306055545806885\n",
      "MSE train 2.8091252976361734 MSE test 6.269839391127149\n",
      "Epoch 3541 / 10000 loss: 56.30018615722656\n",
      "MSE train 2.808835419463467 MSE test 6.269591625775767\n",
      "Epoch 3542 / 10000 loss: 56.294209241867065\n",
      "MSE train 2.8085394003584705 MSE test 6.269342880775258\n",
      "Epoch 3543 / 10000 loss: 56.288108825683594\n",
      "MSE train 2.808237367442514 MSE test 6.269093031778606\n",
      "Epoch 3544 / 10000 loss: 56.281874775886536\n",
      "MSE train 2.8079299548352634 MSE test 6.268842133112137\n",
      "Epoch 3545 / 10000 loss: 56.27551305294037\n",
      "MSE train 2.807618238864281 MSE test 6.268590184586898\n",
      "Epoch 3546 / 10000 loss: 56.26903450489044\n",
      "MSE train 2.807303623917873 MSE test 6.268337405074967\n",
      "Epoch 3547 / 10000 loss: 56.26246440410614\n",
      "MSE train 2.8069878821590324 MSE test 6.268084072844529\n",
      "Epoch 3548 / 10000 loss: 56.25583326816559\n",
      "MSE train 2.806673070496596 MSE test 6.267830685249399\n",
      "Epoch 3549 / 10000 loss: 56.249178767204285\n",
      "MSE train 2.806361064334407 MSE test 6.26757764007596\n",
      "Epoch 3550 / 10000 loss: 56.2425457239151\n",
      "MSE train 2.806053063345107 MSE test 6.267325212278691\n",
      "Epoch 3551 / 10000 loss: 56.23597550392151\n",
      "MSE train 2.8057492789092793 MSE test 6.267073745914942\n",
      "Epoch 3552 / 10000 loss: 56.22949421405792\n",
      "MSE train 2.8054490228844067 MSE test 6.266823089108101\n",
      "Epoch 3553 / 10000 loss: 56.22310554981232\n",
      "MSE train 2.805150991646079 MSE test 6.266573251851878\n",
      "Epoch 3554 / 10000 loss: 56.21679437160492\n",
      "MSE train 2.804853537766523 MSE test 6.266323996597345\n",
      "Epoch 3555 / 10000 loss: 56.21053636074066\n",
      "MSE train 2.804554828059424 MSE test 6.266075107630862\n",
      "Epoch 3556 / 10000 loss: 56.20429170131683\n",
      "MSE train 2.804252917823654 MSE test 6.265826293131254\n",
      "Epoch 3557 / 10000 loss: 56.19802463054657\n",
      "MSE train 2.8039460810037395 MSE test 6.265577446836493\n",
      "Epoch 3558 / 10000 loss: 56.19169044494629\n",
      "MSE train 2.8036340305999654 MSE test 6.265328449998489\n",
      "Epoch 3559 / 10000 loss: 56.18525218963623\n",
      "MSE train 2.803320651214141 MSE test 6.265079589485772\n",
      "Epoch 3560 / 10000 loss: 56.1787074804306\n",
      "MSE train 2.803015117757651 MSE test 6.26483152761632\n",
      "Epoch 3561 / 10000 loss: 56.17213463783264\n",
      "MSE train 2.8027255074477253 MSE test 6.264585126075544\n",
      "Epoch 3562 / 10000 loss: 56.16573190689087\n",
      "MSE train 2.802452070509332 MSE test 6.2643407262567505\n",
      "Epoch 3563 / 10000 loss: 56.15967130661011\n",
      "MSE train 2.8021904911641338 MSE test 6.264098109396555\n",
      "Epoch 3564 / 10000 loss: 56.15395724773407\n",
      "MSE train 2.801936771565168 MSE test 6.263856862468267\n",
      "Epoch 3565 / 10000 loss: 56.14849650859833\n",
      "MSE train 2.801688226196904 MSE test 6.263616697385736\n",
      "Epoch 3566 / 10000 loss: 56.143202900886536\n",
      "MSE train 2.801443125047049 MSE test 6.263377276444856\n",
      "Epoch 3567 / 10000 loss: 56.138020277023315\n",
      "MSE train 2.8012003094063873 MSE test 6.263138519286759\n",
      "Epoch 3568 / 10000 loss: 56.132909178733826\n",
      "MSE train 2.800958968556131 MSE test 6.262900169389952\n",
      "Epoch 3569 / 10000 loss: 56.12784969806671\n",
      "MSE train 2.800718567948682 MSE test 6.262662237739076\n",
      "Epoch 3570 / 10000 loss: 56.12282073497772\n",
      "MSE train 2.8004788187630005 MSE test 6.262424504892256\n",
      "Epoch 3571 / 10000 loss: 56.117812275886536\n",
      "MSE train 2.8002396249778787 MSE test 6.262186937658397\n",
      "Epoch 3572 / 10000 loss: 56.112817883491516\n",
      "MSE train 2.8000010593621196 MSE test 6.261949488228029\n",
      "Epoch 3573 / 10000 loss: 56.10783529281616\n",
      "MSE train 2.799763344890592 MSE test 6.2617121729970355\n",
      "Epoch 3574 / 10000 loss: 56.102866411209106\n",
      "MSE train 2.799526771469522 MSE test 6.261474916754732\n",
      "Epoch 3575 / 10000 loss: 56.097917675971985\n",
      "MSE train 2.7992916413582853 MSE test 6.261237749220898\n",
      "Epoch 3576 / 10000 loss: 56.09299349784851\n",
      "MSE train 2.799058193264406 MSE test 6.261000639704634\n",
      "Epoch 3577 / 10000 loss: 56.08809947967529\n",
      "MSE train 2.7988265457422754 MSE test 6.260763631161176\n",
      "Epoch 3578 / 10000 loss: 56.08324575424194\n",
      "MSE train 2.798596680516132 MSE test 6.260526664158737\n",
      "Epoch 3579 / 10000 loss: 56.078428506851196\n",
      "MSE train 2.798368392572444 MSE test 6.260289757162216\n",
      "Epoch 3580 / 10000 loss: 56.07365393638611\n",
      "MSE train 2.798141309307756 MSE test 6.260052858634999\n",
      "Epoch 3581 / 10000 loss: 56.06891357898712\n",
      "MSE train 2.797914903018753 MSE test 6.259815824875746\n",
      "Epoch 3582 / 10000 loss: 56.064199924468994\n",
      "MSE train 2.797688513567426 MSE test 6.259578579096254\n",
      "Epoch 3583 / 10000 loss: 56.05950331687927\n",
      "MSE train 2.797461377630277 MSE test 6.259341134399009\n",
      "Epoch 3584 / 10000 loss: 56.05480885505676\n",
      "MSE train 2.7972326763254127 MSE test 6.25910322371808\n",
      "Epoch 3585 / 10000 loss: 56.05009889602661\n",
      "MSE train 2.797001619370652 MSE test 6.258864742019543\n",
      "Epoch 3586 / 10000 loss: 56.045358777046204\n",
      "MSE train 2.796767553653086 MSE test 6.258625660603115\n",
      "Epoch 3587 / 10000 loss: 56.040568113327026\n",
      "MSE train 2.7965300499354306 MSE test 6.258385845156892\n",
      "Epoch 3588 / 10000 loss: 56.035715222358704\n",
      "MSE train 2.7962891421328147 MSE test 6.258145199723522\n",
      "Epoch 3589 / 10000 loss: 56.03079044818878\n",
      "MSE train 2.7960453819128688 MSE test 6.257903759946993\n",
      "Epoch 3590 / 10000 loss: 56.025794506073\n",
      "MSE train 2.795799874482525 MSE test 6.2576616582683675\n",
      "Epoch 3591 / 10000 loss: 56.02073931694031\n",
      "MSE train 2.795554027419399 MSE test 6.257418984206361\n",
      "Epoch 3592 / 10000 loss: 56.015647172927856\n",
      "MSE train 2.79530917956884 MSE test 6.25717598219638\n",
      "Epoch 3593 / 10000 loss: 56.01055204868317\n",
      "MSE train 2.795066218791443 MSE test 6.256932816829621\n",
      "Epoch 3594 / 10000 loss: 56.00547897815704\n",
      "MSE train 2.794825322562948 MSE test 6.256689544062241\n",
      "Epoch 3595 / 10000 loss: 56.00044858455658\n",
      "MSE train 2.794586097689617 MSE test 6.256446300105755\n",
      "Epoch 3596 / 10000 loss: 55.99546551704407\n",
      "MSE train 2.7943478279915888 MSE test 6.256203046320566\n",
      "Epoch 3597 / 10000 loss: 55.990519523620605\n",
      "MSE train 2.794109913469315 MSE test 6.25595982738137\n",
      "Epoch 3598 / 10000 loss: 55.985594511032104\n",
      "MSE train 2.7938722176822495 MSE test 6.2557165833743404\n",
      "Epoch 3599 / 10000 loss: 55.98067855834961\n",
      "MSE train 2.7936350811944193 MSE test 6.255473503776258\n",
      "Epoch 3600 / 10000 loss: 55.97576868534088\n",
      "MSE train 2.7933991857345832 MSE test 6.2552305810723166\n",
      "Epoch 3601 / 10000 loss: 55.97087490558624\n",
      "MSE train 2.7931651039394465 MSE test 6.25498807496951\n",
      "Epoch 3602 / 10000 loss: 55.96601045131683\n",
      "MSE train 2.792933048924929 MSE test 6.25474598540402\n",
      "Epoch 3603 / 10000 loss: 55.96118712425232\n",
      "MSE train 2.792702899328456 MSE test 6.254504432611927\n",
      "Epoch 3604 / 10000 loss: 55.9564071893692\n",
      "MSE train 2.7924743719243335 MSE test 6.254263275136199\n",
      "Epoch 3605 / 10000 loss: 55.95167517662048\n",
      "MSE train 2.792247237347347 MSE test 6.254022564884581\n",
      "Epoch 3606 / 10000 loss: 55.94697678089142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.7920214790753217 MSE test 6.25378232043642\n",
      "Epoch 3607 / 10000 loss: 55.942314863204956\n",
      "MSE train 2.791797196015038 MSE test 6.253542296431966\n",
      "Epoch 3608 / 10000 loss: 55.93768525123596\n",
      "MSE train 2.7915745046828038 MSE test 6.253302556154491\n",
      "Epoch 3609 / 10000 loss: 55.93308675289154\n",
      "MSE train 2.7913533190431763 MSE test 6.253062961672396\n",
      "Epoch 3610 / 10000 loss: 55.928529381752014\n",
      "MSE train 2.791133313010734 MSE test 6.252823431963559\n",
      "Epoch 3611 / 10000 loss: 55.92400848865509\n",
      "MSE train 2.7909138479456477 MSE test 6.252583801777087\n",
      "Epoch 3612 / 10000 loss: 55.91951656341553\n",
      "MSE train 2.7906941215538716 MSE test 6.252343979024262\n",
      "Epoch 3613 / 10000 loss: 55.91504085063934\n",
      "MSE train 2.7904732060980595 MSE test 6.252103747731083\n",
      "Epoch 3614 / 10000 loss: 55.91056680679321\n",
      "MSE train 2.7902502130725244 MSE test 6.251862935405687\n",
      "Epoch 3615 / 10000 loss: 55.906068444252014\n",
      "MSE train 2.790024288245625 MSE test 6.251621366106543\n",
      "Epoch 3616 / 10000 loss: 55.90153515338898\n",
      "MSE train 2.789794721936137 MSE test 6.251378854216396\n",
      "Epoch 3617 / 10000 loss: 55.89694261550903\n",
      "MSE train 2.789560915792216 MSE test 6.251135246572494\n",
      "Epoch 3618 / 10000 loss: 55.89227545261383\n",
      "MSE train 2.789322525466167 MSE test 6.2508902949331695\n",
      "Epoch 3619 / 10000 loss: 55.88752222061157\n",
      "MSE train 2.7890793462552015 MSE test 6.250644009314753\n",
      "Epoch 3620 / 10000 loss: 55.88267374038696\n",
      "MSE train 2.788831342612605 MSE test 6.250396111735698\n",
      "Epoch 3621 / 10000 loss: 55.87772274017334\n",
      "MSE train 2.788578486562916 MSE test 6.250146510212775\n",
      "Epoch 3622 / 10000 loss: 55.87266802787781\n",
      "MSE train 2.7883206798793756 MSE test 6.249895107437303\n",
      "Epoch 3623 / 10000 loss: 55.86750781536102\n",
      "MSE train 2.7880576649516002 MSE test 6.249641823959311\n",
      "Epoch 3624 / 10000 loss: 55.862237095832825\n",
      "MSE train 2.787789098743822 MSE test 6.249386524034623\n",
      "Epoch 3625 / 10000 loss: 55.856850147247314\n",
      "MSE train 2.787514760183924 MSE test 6.249129270294006\n",
      "Epoch 3626 / 10000 loss: 55.851338267326355\n",
      "MSE train 2.787234784640475 MSE test 6.248870246481004\n",
      "Epoch 3627 / 10000 loss: 55.84569585323334\n",
      "MSE train 2.7869496581011113 MSE test 6.248609659936527\n",
      "Epoch 3628 / 10000 loss: 55.8399316072464\n",
      "MSE train 2.7866597957502366 MSE test 6.248347969824109\n",
      "Epoch 3629 / 10000 loss: 55.834049582481384\n",
      "MSE train 2.7863647120460993 MSE test 6.248085460775962\n",
      "Epoch 3630 / 10000 loss: 55.828065514564514\n",
      "MSE train 2.786062245040463 MSE test 6.247822329541607\n",
      "Epoch 3631 / 10000 loss: 55.82196247577667\n",
      "MSE train 2.7857485407479423 MSE test 6.247558711678118\n",
      "Epoch 3632 / 10000 loss: 55.81570315361023\n",
      "MSE train 2.7854196863519474 MSE test 6.247294479767881\n",
      "Epoch 3633 / 10000 loss: 55.80919659137726\n",
      "MSE train 2.7850743686714474 MSE test 6.247029622147456\n",
      "Epoch 3634 / 10000 loss: 55.802364349365234\n",
      "MSE train 2.784711725172173 MSE test 6.246764107036406\n",
      "Epoch 3635 / 10000 loss: 55.79517590999603\n",
      "MSE train 2.7843259609890922 MSE test 6.24649759547752\n",
      "Epoch 3636 / 10000 loss: 55.787607192993164\n",
      "MSE train 2.7839305002081307 MSE test 6.246230539922786\n",
      "Epoch 3637 / 10000 loss: 55.779534459114075\n",
      "MSE train 2.7835809722340774 MSE test 6.245965576119528\n",
      "Epoch 3638 / 10000 loss: 55.77124798297882\n",
      "MSE train 2.7832824170140475 MSE test 6.2457046706258295\n",
      "Epoch 3639 / 10000 loss: 55.76395571231842\n",
      "MSE train 2.783000836608428 MSE test 6.245446141897726\n",
      "Epoch 3640 / 10000 loss: 55.75776815414429\n",
      "MSE train 2.782718916167779 MSE test 6.245188085968622\n",
      "Epoch 3641 / 10000 loss: 55.75195491313934\n",
      "MSE train 2.7824257497033313 MSE test 6.244929016543637\n",
      "Epoch 3642 / 10000 loss: 55.74613869190216\n",
      "MSE train 2.782105598279299 MSE test 6.244667258246384\n",
      "Epoch 3643 / 10000 loss: 55.740089654922485\n",
      "MSE train 2.781733407041569 MSE test 6.24440058123711\n",
      "Epoch 3644 / 10000 loss: 55.733468413352966\n",
      "MSE train 2.7813382652903282 MSE test 6.2441294193886225\n",
      "Epoch 3645 / 10000 loss: 55.725743532180786\n",
      "MSE train 2.780990916806362 MSE test 6.243863610389992\n",
      "Epoch 3646 / 10000 loss: 55.717552065849304\n",
      "MSE train 2.78059798699097 MSE test 6.243600216128705\n",
      "Epoch 3647 / 10000 loss: 55.710445404052734\n",
      "MSE train 2.780116874314351 MSE test 6.243333047664339\n",
      "Epoch 3648 / 10000 loss: 55.70245003700256\n",
      "MSE train 2.779790536366469 MSE test 6.243071599112833\n",
      "Epoch 3649 / 10000 loss: 55.692710518836975\n",
      "MSE train 2.7795002497348404 MSE test 6.242814212645044\n",
      "Epoch 3650 / 10000 loss: 55.686097741127014\n",
      "MSE train 2.7792111331508393 MSE test 6.242556634621538\n",
      "Epoch 3651 / 10000 loss: 55.680103182792664\n",
      "MSE train 2.7789207353950554 MSE test 6.242298208848384\n",
      "Epoch 3652 / 10000 loss: 55.674108147621155\n",
      "MSE train 2.778628274160165 MSE test 6.242038762754702\n",
      "Epoch 3653 / 10000 loss: 55.66807472705841\n",
      "MSE train 2.77833372254852 MSE test 6.241778211195733\n",
      "Epoch 3654 / 10000 loss: 55.66198968887329\n",
      "MSE train 2.778037642442666 MSE test 6.241516562110393\n",
      "Epoch 3655 / 10000 loss: 55.655855774879456\n",
      "MSE train 2.777741107539387 MSE test 6.241254254776062\n",
      "Epoch 3656 / 10000 loss: 55.64968657493591\n",
      "MSE train 2.777445328943692 MSE test 6.240991567189539\n",
      "Epoch 3657 / 10000 loss: 55.64350724220276\n",
      "MSE train 2.777151092287877 MSE test 6.2407289230863165\n",
      "Epoch 3658 / 10000 loss: 55.637343406677246\n",
      "MSE train 2.7768584046437903 MSE test 6.240466474812687\n",
      "Epoch 3659 / 10000 loss: 55.63121318817139\n",
      "MSE train 2.776566688020084 MSE test 6.240204224226979\n",
      "Epoch 3660 / 10000 loss: 55.62511849403381\n",
      "MSE train 2.7762752806440383 MSE test 6.239942116017647\n",
      "Epoch 3661 / 10000 loss: 55.619046449661255\n",
      "MSE train 2.7759838926585743 MSE test 6.2396798798030115\n",
      "Epoch 3662 / 10000 loss: 55.61298060417175\n",
      "MSE train 2.7756927536919154 MSE test 6.2394172557304755\n",
      "Epoch 3663 / 10000 loss: 55.60691738128662\n",
      "MSE train 2.7754024058211253 MSE test 6.239154076609961\n",
      "Epoch 3664 / 10000 loss: 55.600855350494385\n",
      "MSE train 2.7751134053038373 MSE test 6.238890245280064\n",
      "Epoch 3665 / 10000 loss: 55.59480702877045\n",
      "MSE train 2.774826325055074 MSE test 6.23862575598182\n",
      "Epoch 3666 / 10000 loss: 55.58878529071808\n",
      "MSE train 2.7745418624120552 MSE test 6.238360751457141\n",
      "Epoch 3667 / 10000 loss: 55.582797169685364\n",
      "MSE train 2.774260907141593 MSE test 6.238095425335722\n",
      "Epoch 3668 / 10000 loss: 55.57686173915863\n",
      "MSE train 2.773984194587233 MSE test 6.237830147481008\n",
      "Epoch 3669 / 10000 loss: 55.5709947347641\n",
      "MSE train 2.7737120197380296 MSE test 6.237565177507208\n",
      "Epoch 3670 / 10000 loss: 55.565213322639465\n",
      "MSE train 2.7734443108776583 MSE test 6.2373007770542115\n",
      "Epoch 3671 / 10000 loss: 55.55952560901642\n",
      "MSE train 2.7731809210416922 MSE test 6.237037102818409\n",
      "Epoch 3672 / 10000 loss: 55.55392837524414\n",
      "MSE train 2.7729219125524955 MSE test 6.236774421194935\n",
      "Epoch 3673 / 10000 loss: 55.54842162132263\n",
      "MSE train 2.772667470483222 MSE test 6.236512935271546\n",
      "Epoch 3674 / 10000 loss: 55.5430052280426\n",
      "MSE train 2.7724175808715406 MSE test 6.236252704424736\n",
      "Epoch 3675 / 10000 loss: 55.53768515586853\n",
      "MSE train 2.7721717542751785 MSE test 6.235993743479387\n",
      "Epoch 3676 / 10000 loss: 55.53245794773102\n",
      "MSE train 2.771928942330362 MSE test 6.235736001929042\n",
      "Epoch 3677 / 10000 loss: 55.52731716632843\n",
      "MSE train 2.771687633291744 MSE test 6.235479014557926\n",
      "Epoch 3678 / 10000 loss: 55.522239208221436\n",
      "MSE train 2.7714460156024017 MSE test 6.235222478046176\n",
      "Epoch 3679 / 10000 loss: 55.5171936750412\n",
      "MSE train 2.771202054536521 MSE test 6.234965745111063\n",
      "Epoch 3680 / 10000 loss: 55.51213800907135\n",
      "MSE train 2.7709536038279183 MSE test 6.234708410348335\n",
      "Epoch 3681 / 10000 loss: 55.50703251361847\n",
      "MSE train 2.7706985701543836 MSE test 6.234449943615367\n",
      "Epoch 3682 / 10000 loss: 55.50182497501373\n",
      "MSE train 2.7704353862503965 MSE test 6.234189935824633\n",
      "Epoch 3683 / 10000 loss: 55.496477127075195\n",
      "MSE train 2.77016383783247 MSE test 6.23392842014073\n",
      "Epoch 3684 / 10000 loss: 55.49094891548157\n",
      "MSE train 2.769885819165436 MSE test 6.233665803780359\n",
      "Epoch 3685 / 10000 loss: 55.48523950576782\n",
      "MSE train 2.7696045207624196 MSE test 6.233402994959237\n",
      "Epoch 3686 / 10000 loss: 55.4793883562088\n",
      "MSE train 2.7693221190991903 MSE test 6.233140866085149\n",
      "Epoch 3687 / 10000 loss: 55.47346472740173\n",
      "MSE train 2.76903855599626 MSE test 6.2328799708823786\n",
      "Epoch 3688 / 10000 loss: 55.46751821041107\n",
      "MSE train 2.7687529820942176 MSE test 6.2326203787692185\n",
      "Epoch 3689 / 10000 loss: 55.461546301841736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.7684655789288057 MSE test 6.232362037792555\n",
      "Epoch 3690 / 10000 loss: 55.45552861690521\n",
      "MSE train 2.768178081370589 MSE test 6.23210492867738\n",
      "Epoch 3691 / 10000 loss: 55.44947302341461\n",
      "MSE train 2.767892964814485 MSE test 6.231849137308131\n",
      "Epoch 3692 / 10000 loss: 55.44341313838959\n",
      "MSE train 2.7676123079972568 MSE test 6.231594961867096\n",
      "Epoch 3693 / 10000 loss: 55.43740725517273\n",
      "MSE train 2.7673372184513045 MSE test 6.231342501181448\n",
      "Epoch 3694 / 10000 loss: 55.43149471282959\n",
      "MSE train 2.767067839892525 MSE test 6.231091841336131\n",
      "Epoch 3695 / 10000 loss: 55.42570734024048\n",
      "MSE train 2.7668034557543617 MSE test 6.2308428758888725\n",
      "Epoch 3696 / 10000 loss: 55.42003870010376\n",
      "MSE train 2.7665426785933054 MSE test 6.2305955151354215\n",
      "Epoch 3697 / 10000 loss: 55.41448223590851\n",
      "MSE train 2.7662838297711145 MSE test 6.230349415313747\n",
      "Epoch 3698 / 10000 loss: 55.40900123119354\n",
      "MSE train 2.766025413201166 MSE test 6.230104271287232\n",
      "Epoch 3699 / 10000 loss: 55.40356361865997\n",
      "MSE train 2.7657663240486494 MSE test 6.229859794830419\n",
      "Epoch 3700 / 10000 loss: 55.39813590049744\n",
      "MSE train 2.7655058732862368 MSE test 6.229615653953475\n",
      "Epoch 3701 / 10000 loss: 55.39269137382507\n",
      "MSE train 2.7652435910413886 MSE test 6.229371520393605\n",
      "Epoch 3702 / 10000 loss: 55.38721811771393\n",
      "MSE train 2.7649791873544936 MSE test 6.229127248590856\n",
      "Epoch 3703 / 10000 loss: 55.38170683383942\n",
      "MSE train 2.7647125317406123 MSE test 6.228882638449167\n",
      "Epoch 3704 / 10000 loss: 55.376147747039795\n",
      "MSE train 2.7644436185717245 MSE test 6.228637377447161\n",
      "Epoch 3705 / 10000 loss: 55.37053978443146\n",
      "MSE train 2.764172473784685 MSE test 6.228391409101072\n",
      "Epoch 3706 / 10000 loss: 55.364885210990906\n",
      "MSE train 2.763898998913898 MSE test 6.228144570293375\n",
      "Epoch 3707 / 10000 loss: 55.35918128490448\n",
      "MSE train 2.763622920815819 MSE test 6.227896776170926\n",
      "Epoch 3708 / 10000 loss: 55.35342490673065\n",
      "MSE train 2.7633438448119554 MSE test 6.227647821346028\n",
      "Epoch 3709 / 10000 loss: 55.34761583805084\n",
      "MSE train 2.7630613662190986 MSE test 6.227397739544753\n",
      "Epoch 3710 / 10000 loss: 55.34173893928528\n",
      "MSE train 2.762775171206867 MSE test 6.227146439436287\n",
      "Epoch 3711 / 10000 loss: 55.335793018341064\n",
      "MSE train 2.762484971597838 MSE test 6.226893909971201\n",
      "Epoch 3712 / 10000 loss: 55.32976448535919\n",
      "MSE train 2.762190446284568 MSE test 6.226640048261472\n",
      "Epoch 3713 / 10000 loss: 55.32365131378174\n",
      "MSE train 2.761891042957536 MSE test 6.226384786133151\n",
      "Epoch 3714 / 10000 loss: 55.31744194030762\n",
      "MSE train 2.761585891844196 MSE test 6.226127955774514\n",
      "Epoch 3715 / 10000 loss: 55.31113123893738\n",
      "MSE train 2.76127383710559 MSE test 6.225869619085503\n",
      "Epoch 3716 / 10000 loss: 55.30469477176666\n",
      "MSE train 2.7609537787161584 MSE test 6.225609489114507\n",
      "Epoch 3717 / 10000 loss: 55.29811227321625\n",
      "MSE train 2.760625644422021 MSE test 6.225347821334558\n",
      "Epoch 3718 / 10000 loss: 55.291351556777954\n",
      "MSE train 2.7602916264940704 MSE test 6.225084934370868\n",
      "Epoch 3719 / 10000 loss: 55.2844203710556\n",
      "MSE train 2.75995623639964 MSE test 6.22482161516574\n",
      "Epoch 3720 / 10000 loss: 55.277361035346985\n",
      "MSE train 2.7596236964891956 MSE test 6.2245587658279184\n",
      "Epoch 3721 / 10000 loss: 55.27027189731598\n",
      "MSE train 2.759295274550827 MSE test 6.224297021698834\n",
      "Epoch 3722 / 10000 loss: 55.263246297836304\n",
      "MSE train 2.758969889753855 MSE test 6.224036327322693\n",
      "Epoch 3723 / 10000 loss: 55.256308913230896\n",
      "MSE train 2.758646167458934 MSE test 6.223776562744316\n",
      "Epoch 3724 / 10000 loss: 55.24943709373474\n",
      "MSE train 2.7583235183859296 MSE test 6.22351734888457\n",
      "Epoch 3725 / 10000 loss: 55.24260210990906\n",
      "MSE train 2.7580021501952485 MSE test 6.223258571223938\n",
      "Epoch 3726 / 10000 loss: 55.23578703403473\n",
      "MSE train 2.7576827203074443 MSE test 6.223000029920442\n",
      "Epoch 3727 / 10000 loss: 55.22900354862213\n",
      "MSE train 2.7573660009739074 MSE test 6.222741731243093\n",
      "Epoch 3728 / 10000 loss: 55.22225725650787\n",
      "MSE train 2.7570525565751725 MSE test 6.222483588701062\n",
      "Epoch 3729 / 10000 loss: 55.215569734573364\n",
      "MSE train 2.7567426864245186 MSE test 6.222225647524098\n",
      "Epoch 3730 / 10000 loss: 55.20895338058472\n",
      "MSE train 2.7564365139777176 MSE test 6.221967940409527\n",
      "Epoch 3731 / 10000 loss: 55.202415227890015\n",
      "MSE train 2.7561342054363807 MSE test 6.221710354135427\n",
      "Epoch 3732 / 10000 loss: 55.19595396518707\n",
      "MSE train 2.755836086470192 MSE test 6.221452840891678\n",
      "Epoch 3733 / 10000 loss: 55.189574241638184\n",
      "MSE train 2.7555428461872653 MSE test 6.221195268366261\n",
      "Epoch 3734 / 10000 loss: 55.18328905105591\n",
      "MSE train 2.7552555405970103 MSE test 6.220937485872055\n",
      "Epoch 3735 / 10000 loss: 55.177106738090515\n",
      "MSE train 2.7549752691558207 MSE test 6.220679177285672\n",
      "Epoch 3736 / 10000 loss: 55.17105579376221\n",
      "MSE train 2.754702389480476 MSE test 6.220420154730887\n",
      "Epoch 3737 / 10000 loss: 55.16515624523163\n",
      "MSE train 2.75443571642174 MSE test 6.22015976045035\n",
      "Epoch 3738 / 10000 loss: 55.15941822528839\n",
      "MSE train 2.75417209377154 MSE test 6.219897217169337\n",
      "Epoch 3739 / 10000 loss: 55.153817653656006\n",
      "MSE train 2.7539051441902767 MSE test 6.219631196812581\n",
      "Epoch 3740 / 10000 loss: 55.14828658103943\n",
      "MSE train 2.7536193424022612 MSE test 6.219359404843437\n",
      "Epoch 3741 / 10000 loss: 55.14268636703491\n",
      "MSE train 2.753267345451059 MSE test 6.219076901426576\n",
      "Epoch 3742 / 10000 loss: 55.13669180870056\n",
      "MSE train 2.7528337448151325 MSE test 6.218777877630991\n",
      "Epoch 3743 / 10000 loss: 55.12927746772766\n",
      "MSE train 2.752549020116381 MSE test 6.2184960009439125\n",
      "Epoch 3744 / 10000 loss: 55.120128870010376\n",
      "MSE train 2.7522931204087753 MSE test 6.21822527724504\n",
      "Epoch 3745 / 10000 loss: 55.114165902137756\n",
      "MSE train 2.752035555709241 MSE test 6.217953946138835\n",
      "Epoch 3746 / 10000 loss: 55.10879981517792\n",
      "MSE train 2.751773501599953 MSE test 6.2176805627401075\n",
      "Epoch 3747 / 10000 loss: 55.10339438915253\n",
      "MSE train 2.7515065465728723 MSE test 6.217404974406163\n",
      "Epoch 3748 / 10000 loss: 55.09788477420807\n",
      "MSE train 2.751236400206731 MSE test 6.217127791211186\n",
      "Epoch 3749 / 10000 loss: 55.092270612716675\n",
      "MSE train 2.750966473072827 MSE test 6.2168504941901706\n",
      "Epoch 3750 / 10000 loss: 55.086586594581604\n",
      "MSE train 2.7506999760178172 MSE test 6.216574868727262\n",
      "Epoch 3751 / 10000 loss: 55.08090579509735\n",
      "MSE train 2.750437953885637 MSE test 6.2163021597207955\n",
      "Epoch 3752 / 10000 loss: 55.07529938220978\n",
      "MSE train 2.750179366788297 MSE test 6.216032656127653\n",
      "Epoch 3753 / 10000 loss: 55.06978976726532\n",
      "MSE train 2.7499223922350744 MSE test 6.215766048378838\n",
      "Epoch 3754 / 10000 loss: 55.064353585243225\n",
      "MSE train 2.7496654059699375 MSE test 6.215501611488106\n",
      "Epoch 3755 / 10000 loss: 55.05895221233368\n",
      "MSE train 2.7494072391619935 MSE test 6.215238720899122\n",
      "Epoch 3756 / 10000 loss: 55.05355131626129\n",
      "MSE train 2.7491470946946173 MSE test 6.214976749111596\n",
      "Epoch 3757 / 10000 loss: 55.048123478889465\n",
      "MSE train 2.7488843429347565 MSE test 6.214715213460149\n",
      "Epoch 3758 / 10000 loss: 55.04265236854553\n",
      "MSE train 2.7486182175222647 MSE test 6.2144535353418275\n",
      "Epoch 3759 / 10000 loss: 55.03712606430054\n",
      "MSE train 2.748347560299618 MSE test 6.214191287053281\n",
      "Epoch 3760 / 10000 loss: 55.03152680397034\n",
      "MSE train 2.748070655807756 MSE test 6.213928034605698\n",
      "Epoch 3761 / 10000 loss: 55.025827527046204\n",
      "MSE train 2.747785315546568 MSE test 6.213663146977071\n",
      "Epoch 3762 / 10000 loss: 55.01999521255493\n",
      "MSE train 2.7474892217572537 MSE test 6.213396101517307\n",
      "Epoch 3763 / 10000 loss: 55.013978362083435\n",
      "MSE train 2.7471805349680363 MSE test 6.213126157164471\n",
      "Epoch 3764 / 10000 loss: 55.00772941112518\n",
      "MSE train 2.7468585791653646 MSE test 6.212852406240051\n",
      "Epoch 3765 / 10000 loss: 55.00120675563812\n",
      "MSE train 2.7465237174368986 MSE test 6.212573368765031\n",
      "Epoch 3766 / 10000 loss: 54.994394063949585\n",
      "MSE train 2.7461733060983526 MSE test 6.2122860956811445\n",
      "Epoch 3767 / 10000 loss: 54.987292528152466\n",
      "MSE train 2.745780716316835 MSE test 6.211983404957816\n",
      "Epoch 3768 / 10000 loss: 54.979825377464294\n",
      "MSE train 2.7452286672840676 MSE test 6.211645823278134\n",
      "Epoch 3769 / 10000 loss: 54.97130846977234\n",
      "MSE train 2.7446041960527308 MSE test 6.21126747063934\n",
      "Epoch 3770 / 10000 loss: 54.95913338661194\n",
      "MSE train 2.7442778734807995 MSE test 6.2109617592662385\n",
      "Epoch 3771 / 10000 loss: 54.94638967514038\n",
      "MSE train 2.7439890116357786 MSE test 6.210697853922647\n",
      "Epoch 3772 / 10000 loss: 54.939547419548035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.743700894020219 MSE test 6.210437871725512\n",
      "Epoch 3773 / 10000 loss: 54.93346190452576\n",
      "MSE train 2.7434089680821123 MSE test 6.210179559564983\n",
      "Epoch 3774 / 10000 loss: 54.927390336990356\n",
      "MSE train 2.743106809488726 MSE test 6.20992119141338\n",
      "Epoch 3775 / 10000 loss: 54.9212361574173\n",
      "MSE train 2.742779687693385 MSE test 6.2096610424222245\n",
      "Epoch 3776 / 10000 loss: 54.91485953330994\n",
      "MSE train 2.742392063462473 MSE test 6.209396293882799\n",
      "Epoch 3777 / 10000 loss: 54.9079452753067\n",
      "MSE train 2.7419545984406364 MSE test 6.20912536601939\n",
      "Epoch 3778 / 10000 loss: 54.89971745014191\n",
      "MSE train 2.741610347034193 MSE test 6.20886200101849\n",
      "Epoch 3779 / 10000 loss: 54.890408515930176\n",
      "MSE train 2.741262100370382 MSE test 6.2086034867187685\n",
      "Epoch 3780 / 10000 loss: 54.8831182718277\n",
      "MSE train 2.7407919115697745 MSE test 6.208338231301572\n",
      "Epoch 3781 / 10000 loss: 54.875747203826904\n",
      "MSE train 2.740422994186322 MSE test 6.208071946039235\n",
      "Epoch 3782 / 10000 loss: 54.86573541164398\n",
      "MSE train 2.740127580036785 MSE test 6.2078270482307785\n",
      "Epoch 3783 / 10000 loss: 54.857922077178955\n",
      "MSE train 2.739828921213872 MSE test 6.207582690942927\n",
      "Epoch 3784 / 10000 loss: 54.85169768333435\n",
      "MSE train 2.7395294567450117 MSE test 6.207338586625732\n",
      "Epoch 3785 / 10000 loss: 54.84540319442749\n",
      "MSE train 2.7392339108547 MSE test 6.207094721384023\n",
      "Epoch 3786 / 10000 loss: 54.83909273147583\n",
      "MSE train 2.7389458968888545 MSE test 6.206850928901755\n",
      "Epoch 3787 / 10000 loss: 54.83286714553833\n",
      "MSE train 2.738664381375407 MSE test 6.206606866367848\n",
      "Epoch 3788 / 10000 loss: 54.826807260513306\n",
      "MSE train 2.7383840036975853 MSE test 6.206361924604914\n",
      "Epoch 3789 / 10000 loss: 54.82088923454285\n",
      "MSE train 2.738094711224529 MSE test 6.20611477923187\n",
      "Epoch 3790 / 10000 loss: 54.81499683856964\n",
      "MSE train 2.7377731311597127 MSE test 6.2058631291343955\n",
      "Epoch 3791 / 10000 loss: 54.80891454219818\n",
      "MSE train 2.7373708569306134 MSE test 6.205602936418247\n",
      "Epoch 3792 / 10000 loss: 54.80213713645935\n",
      "MSE train 2.736990258550719 MSE test 6.205338166674646\n",
      "Epoch 3793 / 10000 loss: 54.79361021518707\n",
      "MSE train 2.736707042618066 MSE test 6.2050926565440925\n",
      "Epoch 3794 / 10000 loss: 54.785544753074646\n",
      "MSE train 2.7364288325174733 MSE test 6.204850430520802\n",
      "Epoch 3795 / 10000 loss: 54.779601097106934\n",
      "MSE train 2.7361509659602206 MSE test 6.204609044740198\n",
      "Epoch 3796 / 10000 loss: 54.7737672328949\n",
      "MSE train 2.735873237906497 MSE test 6.204367906495246\n",
      "Epoch 3797 / 10000 loss: 54.76794362068176\n",
      "MSE train 2.7355958768376576 MSE test 6.204126790471945\n",
      "Epoch 3798 / 10000 loss: 54.762126207351685\n",
      "MSE train 2.7353193578260266 MSE test 6.203885566901179\n",
      "Epoch 3799 / 10000 loss: 54.75631761550903\n",
      "MSE train 2.735044598504242 MSE test 6.203644160852661\n",
      "Epoch 3800 / 10000 loss: 54.75052833557129\n",
      "MSE train 2.7347727887709463 MSE test 6.203402550700236\n",
      "Epoch 3801 / 10000 loss: 54.74477934837341\n",
      "MSE train 2.7345048583297333 MSE test 6.203160808382409\n",
      "Epoch 3802 / 10000 loss: 54.73909318447113\n",
      "MSE train 2.7342410138838247 MSE test 6.202918898115203\n",
      "Epoch 3803 / 10000 loss: 54.73349368572235\n",
      "MSE train 2.7339805560721566 MSE test 6.2026767378097585\n",
      "Epoch 3804 / 10000 loss: 54.72798001766205\n",
      "MSE train 2.733722005619665 MSE test 6.2024341559409235\n",
      "Epoch 3805 / 10000 loss: 54.72254431247711\n",
      "MSE train 2.7334631484671332 MSE test 6.202190959414154\n",
      "Epoch 3806 / 10000 loss: 54.71714532375336\n",
      "MSE train 2.7332009810130447 MSE test 6.201946820224302\n",
      "Epoch 3807 / 10000 loss: 54.711745381355286\n",
      "MSE train 2.7329315557132294 MSE test 6.201701345737418\n",
      "Epoch 3808 / 10000 loss: 54.70627200603485\n",
      "MSE train 2.7326501147250957 MSE test 6.201454114680977\n",
      "Epoch 3809 / 10000 loss: 54.7006459236145\n",
      "MSE train 2.732352509345668 MSE test 6.20120453825692\n",
      "Epoch 3810 / 10000 loss: 54.69476068019867\n",
      "MSE train 2.732038699356484 MSE test 6.20095197773884\n",
      "Epoch 3811 / 10000 loss: 54.68852961063385\n",
      "MSE train 2.731713266323233 MSE test 6.200695677805356\n",
      "Epoch 3812 / 10000 loss: 54.68195164203644\n",
      "MSE train 2.7313767458538507 MSE test 6.200434817216618\n",
      "Epoch 3813 / 10000 loss: 54.675127029418945\n",
      "MSE train 2.731032061289565 MSE test 6.200169753220696\n",
      "Epoch 3814 / 10000 loss: 54.668068170547485\n",
      "MSE train 2.730709228621144 MSE test 6.199905464821767\n",
      "Epoch 3815 / 10000 loss: 54.66083884239197\n",
      "MSE train 2.730420661183134 MSE test 6.199648242771553\n",
      "Epoch 3816 / 10000 loss: 54.65408205986023\n",
      "MSE train 2.73014767876706 MSE test 6.199396442596356\n",
      "Epoch 3817 / 10000 loss: 54.6480610370636\n",
      "MSE train 2.7298799852831124 MSE test 6.199147088474709\n",
      "Epoch 3818 / 10000 loss: 54.64237296581268\n",
      "MSE train 2.729613894210397 MSE test 6.198898733955127\n",
      "Epoch 3819 / 10000 loss: 54.636791825294495\n",
      "MSE train 2.72934757803315 MSE test 6.198650624919788\n",
      "Epoch 3820 / 10000 loss: 54.63124239444733\n",
      "MSE train 2.729079830212264 MSE test 6.198402329967279\n",
      "Epoch 3821 / 10000 loss: 54.625682950019836\n",
      "MSE train 2.728809794604032 MSE test 6.198153721104437\n",
      "Epoch 3822 / 10000 loss: 54.62009048461914\n",
      "MSE train 2.7285367939111844 MSE test 6.197904604397206\n",
      "Epoch 3823 / 10000 loss: 54.614441990852356\n",
      "MSE train 2.7282602519777375 MSE test 6.197654891069995\n",
      "Epoch 3824 / 10000 loss: 54.60873067378998\n",
      "MSE train 2.7279796198573583 MSE test 6.197404716275889\n",
      "Epoch 3825 / 10000 loss: 54.60293662548065\n",
      "MSE train 2.7276943782774232 MSE test 6.19715404673026\n",
      "Epoch 3826 / 10000 loss: 54.59705436229706\n",
      "MSE train 2.72740416952784 MSE test 6.196903026817081\n",
      "Epoch 3827 / 10000 loss: 54.59107208251953\n",
      "MSE train 2.727108998875596 MSE test 6.196651708553425\n",
      "Epoch 3828 / 10000 loss: 54.584981083869934\n",
      "MSE train 2.726809433214552 MSE test 6.196400314957038\n",
      "Epoch 3829 / 10000 loss: 54.578781843185425\n",
      "MSE train 2.726506683716664 MSE test 6.1961491019706765\n",
      "Epoch 3830 / 10000 loss: 54.57248616218567\n",
      "MSE train 2.7262025265493746 MSE test 6.195898245382868\n",
      "Epoch 3831 / 10000 loss: 54.56612169742584\n",
      "MSE train 2.725898969123595 MSE test 6.1956480229764255\n",
      "Epoch 3832 / 10000 loss: 54.5597277879715\n",
      "MSE train 2.7255978188469405 MSE test 6.195398699261165\n",
      "Epoch 3833 / 10000 loss: 54.55334508419037\n",
      "MSE train 2.7253003619724074 MSE test 6.195150323677797\n",
      "Epoch 3834 / 10000 loss: 54.54701602458954\n",
      "MSE train 2.7250072356801662 MSE test 6.194902970831926\n",
      "Epoch 3835 / 10000 loss: 54.540767550468445\n",
      "MSE train 2.724718429451275 MSE test 6.194656606647539\n",
      "Epoch 3836 / 10000 loss: 54.53461134433746\n",
      "MSE train 2.7244334298599515 MSE test 6.194411146884512\n",
      "Epoch 3837 / 10000 loss: 54.52854931354523\n",
      "MSE train 2.7241512787780704 MSE test 6.194166353127817\n",
      "Epoch 3838 / 10000 loss: 54.52256917953491\n",
      "MSE train 2.7238707721013085 MSE test 6.193921967698793\n",
      "Epoch 3839 / 10000 loss: 54.51664865016937\n",
      "MSE train 2.7235905504563274 MSE test 6.193677887911897\n",
      "Epoch 3840 / 10000 loss: 54.51076698303223\n",
      "MSE train 2.7233092423215397 MSE test 6.193433866420564\n",
      "Epoch 3841 / 10000 loss: 54.5048850774765\n",
      "MSE train 2.7230255772364145 MSE test 6.193189674291453\n",
      "Epoch 3842 / 10000 loss: 54.49898326396942\n",
      "MSE train 2.7227385183623065 MSE test 6.192945128011085\n",
      "Epoch 3843 / 10000 loss: 54.49302864074707\n",
      "MSE train 2.7224474107124714 MSE test 6.19270030727532\n",
      "Epoch 3844 / 10000 loss: 54.48700296878815\n",
      "MSE train 2.722152189165139 MSE test 6.192455160068034\n",
      "Epoch 3845 / 10000 loss: 54.48088896274567\n",
      "MSE train 2.721853492258746 MSE test 6.192209924070411\n",
      "Epoch 3846 / 10000 loss: 54.47468400001526\n",
      "MSE train 2.721552507859874 MSE test 6.191964778662508\n",
      "Epoch 3847 / 10000 loss: 54.46840572357178\n",
      "MSE train 2.7212505252381516 MSE test 6.19171992233162\n",
      "Epoch 3848 / 10000 loss: 54.46207785606384\n",
      "MSE train 2.7209485948814636 MSE test 6.19147562008591\n",
      "Epoch 3849 / 10000 loss: 54.455729365348816\n",
      "MSE train 2.72064732193528 MSE test 6.191232170131755\n",
      "Epoch 3850 / 10000 loss: 54.449384331703186\n",
      "MSE train 2.720346698240554 MSE test 6.190989561445469\n",
      "Epoch 3851 / 10000 loss: 54.44305467605591\n",
      "MSE train 2.7200462310097966 MSE test 6.190747863851141\n",
      "Epoch 3852 / 10000 loss: 54.436739444732666\n",
      "MSE train 2.7197455036222493 MSE test 6.190507166423508\n",
      "Epoch 3853 / 10000 loss: 54.43043029308319\n",
      "MSE train 2.7194448271663174 MSE test 6.190267514992993\n",
      "Epoch 3854 / 10000 loss: 54.42411971092224\n",
      "MSE train 2.719145505281216 MSE test 6.190029080455816\n",
      "Epoch 3855 / 10000 loss: 54.417811155319214\n",
      "MSE train 2.7188495692103514 MSE test 6.189792127128574\n",
      "Epoch 3856 / 10000 loss: 54.411532521247864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.71855927221718 MSE test 6.1895567511948\n",
      "Epoch 3857 / 10000 loss: 54.4053316116333\n",
      "MSE train 2.7182763564903865 MSE test 6.189323135650445\n",
      "Epoch 3858 / 10000 loss: 54.39925134181976\n",
      "MSE train 2.7180015562545066 MSE test 6.189091183239898\n",
      "Epoch 3859 / 10000 loss: 54.39333236217499\n",
      "MSE train 2.717734533389485 MSE test 6.1888608595102275\n",
      "Epoch 3860 / 10000 loss: 54.387590289115906\n",
      "MSE train 2.71747432684062 MSE test 6.18863192996603\n",
      "Epoch 3861 / 10000 loss: 54.382014989852905\n",
      "MSE train 2.717219805451928 MSE test 6.188404374597584\n",
      "Epoch 3862 / 10000 loss: 54.376585245132446\n",
      "MSE train 2.7169698992964073 MSE test 6.188177991412846\n",
      "Epoch 3863 / 10000 loss: 54.37127947807312\n",
      "MSE train 2.716723620233665 MSE test 6.187952623790507\n",
      "Epoch 3864 / 10000 loss: 54.366068840026855\n",
      "MSE train 2.7164801768219826 MSE test 6.187728292560597\n",
      "Epoch 3865 / 10000 loss: 54.36093533039093\n",
      "MSE train 2.7162390223782515 MSE test 6.187504850159722\n",
      "Epoch 3866 / 10000 loss: 54.35586166381836\n",
      "MSE train 2.715999939118847 MSE test 6.187282355993284\n",
      "Epoch 3867 / 10000 loss: 54.35083603858948\n",
      "MSE train 2.7157630936418187 MSE test 6.187060680981729\n",
      "Epoch 3868 / 10000 loss: 54.345850467681885\n",
      "MSE train 2.7155288874589916 MSE test 6.186839954537247\n",
      "Epoch 3869 / 10000 loss: 54.34091401100159\n",
      "MSE train 2.715297754905637 MSE test 6.186620211389657\n",
      "Epoch 3870 / 10000 loss: 54.336028933525085\n",
      "MSE train 2.7150699702831487 MSE test 6.186401337704298\n",
      "Epoch 3871 / 10000 loss: 54.331209659576416\n",
      "MSE train 2.7148455250924624 MSE test 6.186183351112331\n",
      "Epoch 3872 / 10000 loss: 54.32646059989929\n",
      "MSE train 2.7146241401764137 MSE test 6.185966137085108\n",
      "Epoch 3873 / 10000 loss: 54.32178020477295\n",
      "MSE train 2.7144053505234056 MSE test 6.185749670242713\n",
      "Epoch 3874 / 10000 loss: 54.3171660900116\n",
      "MSE train 2.7141886763121095 MSE test 6.1855337668542925\n",
      "Epoch 3875 / 10000 loss: 54.312604784965515\n",
      "MSE train 2.7139736371106866 MSE test 6.185318366717609\n",
      "Epoch 3876 / 10000 loss: 54.3080860376358\n",
      "MSE train 2.7137598426493303 MSE test 6.185103340884045\n",
      "Epoch 3877 / 10000 loss: 54.30360233783722\n",
      "MSE train 2.7135469214372225 MSE test 6.184888569791742\n",
      "Epoch 3878 / 10000 loss: 54.299142837524414\n",
      "MSE train 2.713334511353274 MSE test 6.184674023839553\n",
      "Epoch 3879 / 10000 loss: 54.294700622558594\n",
      "MSE train 2.7131221990011674 MSE test 6.1844595710642905\n",
      "Epoch 3880 / 10000 loss: 54.2902694940567\n",
      "MSE train 2.7129095043451263 MSE test 6.184245083780655\n",
      "Epoch 3881 / 10000 loss: 54.28583776950836\n",
      "MSE train 2.7126959041276586 MSE test 6.184030490371052\n",
      "Epoch 3882 / 10000 loss: 54.28139889240265\n",
      "MSE train 2.7124808316617384 MSE test 6.183815652564437\n",
      "Epoch 3883 / 10000 loss: 54.276938796043396\n",
      "MSE train 2.712263720181642 MSE test 6.183600540118898\n",
      "Epoch 3884 / 10000 loss: 54.272443890571594\n",
      "MSE train 2.7120440268596697 MSE test 6.183385001962013\n",
      "Epoch 3885 / 10000 loss: 54.267908453941345\n",
      "MSE train 2.7118212358358247 MSE test 6.18316906206509\n",
      "Epoch 3886 / 10000 loss: 54.26331293582916\n",
      "MSE train 2.711594873707314 MSE test 6.182952563140732\n",
      "Epoch 3887 / 10000 loss: 54.25865030288696\n",
      "MSE train 2.711364534733565 MSE test 6.182735536909454\n",
      "Epoch 3888 / 10000 loss: 54.25391173362732\n",
      "MSE train 2.7111298079418047 MSE test 6.182517862637751\n",
      "Epoch 3889 / 10000 loss: 54.24908471107483\n",
      "MSE train 2.710890331483388 MSE test 6.1822994978272625\n",
      "Epoch 3890 / 10000 loss: 54.24416387081146\n",
      "MSE train 2.7106457918247404 MSE test 6.182080476267597\n",
      "Epoch 3891 / 10000 loss: 54.239139795303345\n",
      "MSE train 2.7103959887125373 MSE test 6.181860679107288\n",
      "Epoch 3892 / 10000 loss: 54.23400521278381\n",
      "MSE train 2.710141099586859 MSE test 6.181640186268309\n",
      "Epoch 3893 / 10000 loss: 54.22875690460205\n",
      "MSE train 2.7098822245924774 MSE test 6.181419118787231\n",
      "Epoch 3894 / 10000 loss: 54.22339677810669\n",
      "MSE train 2.7096220012573355 MSE test 6.181197615335462\n",
      "Epoch 3895 / 10000 loss: 54.21795296669006\n",
      "MSE train 2.7093645416642564 MSE test 6.180975943903133\n",
      "Epoch 3896 / 10000 loss: 54.212478160858154\n",
      "MSE train 2.709113668568371 MSE test 6.180754502792416\n",
      "Epoch 3897 / 10000 loss: 54.20706343650818\n",
      "MSE train 2.7088708922967886 MSE test 6.18053348971386\n",
      "Epoch 3898 / 10000 loss: 54.201791405677795\n",
      "MSE train 2.7086352493157233 MSE test 6.180312906859008\n",
      "Epoch 3899 / 10000 loss: 54.19669497013092\n",
      "MSE train 2.7084046007405447 MSE test 6.180092683772751\n",
      "Epoch 3900 / 10000 loss: 54.191754937171936\n",
      "MSE train 2.708176587446705 MSE test 6.179872546221926\n",
      "Epoch 3901 / 10000 loss: 54.18692469596863\n",
      "MSE train 2.7079489430939128 MSE test 6.179652450070395\n",
      "Epoch 3902 / 10000 loss: 54.18215489387512\n",
      "MSE train 2.707719372045847 MSE test 6.179432016018981\n",
      "Epoch 3903 / 10000 loss: 54.177393436431885\n",
      "MSE train 2.707485548574443 MSE test 6.179211141449314\n",
      "Epoch 3904 / 10000 loss: 54.1725937128067\n",
      "MSE train 2.707245358634757 MSE test 6.178989606113194\n",
      "Epoch 3905 / 10000 loss: 54.16770565509796\n",
      "MSE train 2.706998070606419 MSE test 6.178767340190248\n",
      "Epoch 3906 / 10000 loss: 54.16268336772919\n",
      "MSE train 2.7067463816890958 MSE test 6.178544588690568\n",
      "Epoch 3907 / 10000 loss: 54.157514572143555\n",
      "MSE train 2.7064972602846065 MSE test 6.17832188398087\n",
      "Epoch 3908 / 10000 loss: 54.15225005149841\n",
      "MSE train 2.7062579936163234 MSE test 6.17809990354472\n",
      "Epoch 3909 / 10000 loss: 54.147042989730835\n",
      "MSE train 2.706030865025061 MSE test 6.177879095673516\n",
      "Epoch 3910 / 10000 loss: 54.142043113708496\n",
      "MSE train 2.7058138637436753 MSE test 6.17765948071535\n",
      "Epoch 3911 / 10000 loss: 54.13729989528656\n",
      "MSE train 2.70560407276011 MSE test 6.177440845408073\n",
      "Epoch 3912 / 10000 loss: 54.132771015167236\n",
      "MSE train 2.705399053912437 MSE test 6.177222961184966\n",
      "Epoch 3913 / 10000 loss: 54.12839210033417\n",
      "MSE train 2.705196856585078 MSE test 6.177005499191718\n",
      "Epoch 3914 / 10000 loss: 54.1241135597229\n",
      "MSE train 2.7049957613257076 MSE test 6.1767883397115355\n",
      "Epoch 3915 / 10000 loss: 54.11989223957062\n",
      "MSE train 2.7047939934038525 MSE test 6.17657115414684\n",
      "Epoch 3916 / 10000 loss: 54.11569571495056\n",
      "MSE train 2.7045893997113324 MSE test 6.176353740210564\n",
      "Epoch 3917 / 10000 loss: 54.111480951309204\n",
      "MSE train 2.7043788139309317 MSE test 6.176135774574953\n",
      "Epoch 3918 / 10000 loss: 54.10720479488373\n",
      "MSE train 2.7041570572879348 MSE test 6.175916861813449\n",
      "Epoch 3919 / 10000 loss: 54.10279977321625\n",
      "MSE train 2.7039157648267302 MSE test 6.175696505337576\n",
      "Epoch 3920 / 10000 loss: 54.09815180301666\n",
      "MSE train 2.7036468299523584 MSE test 6.17547428335655\n",
      "Epoch 3921 / 10000 loss: 54.09308135509491\n",
      "MSE train 2.703363441112927 MSE test 6.175250837324458\n",
      "Epoch 3922 / 10000 loss: 54.08741307258606\n",
      "MSE train 2.7031036623542204 MSE test 6.175028700386387\n",
      "Epoch 3923 / 10000 loss: 54.08143162727356\n",
      "MSE train 2.7028682981431196 MSE test 6.174809275054523\n",
      "Epoch 3924 / 10000 loss: 54.07596158981323\n",
      "MSE train 2.7026403483155006 MSE test 6.174591425161148\n",
      "Epoch 3925 / 10000 loss: 54.071014761924744\n",
      "MSE train 2.702415341918157 MSE test 6.174374508514437\n",
      "Epoch 3926 / 10000 loss: 54.06623029708862\n",
      "MSE train 2.7021948483796434 MSE test 6.174158259397665\n",
      "Epoch 3927 / 10000 loss: 54.06150782108307\n",
      "MSE train 2.701980130224986 MSE test 6.173942690407342\n",
      "Epoch 3928 / 10000 loss: 54.05688452720642\n",
      "MSE train 2.7017701728796943 MSE test 6.173727711456578\n",
      "Epoch 3929 / 10000 loss: 54.052383065223694\n",
      "MSE train 2.701562684878877 MSE test 6.173513115624107\n",
      "Epoch 3930 / 10000 loss: 54.04798626899719\n",
      "MSE train 2.701355476914672 MSE test 6.1732986401029875\n",
      "Epoch 3931 / 10000 loss: 54.043641090393066\n",
      "MSE train 2.701146916041005 MSE test 6.1730840507392655\n",
      "Epoch 3932 / 10000 loss: 54.039302706718445\n",
      "MSE train 2.700935942348816 MSE test 6.172869228829408\n",
      "Epoch 3933 / 10000 loss: 54.034934282302856\n",
      "MSE train 2.7007221024200283 MSE test 6.1726540180784815\n",
      "Epoch 3934 / 10000 loss: 54.03051257133484\n",
      "MSE train 2.7005056084021497 MSE test 6.172438411870878\n",
      "Epoch 3935 / 10000 loss: 54.026028513908386\n",
      "MSE train 2.7002874046153065 MSE test 6.17222239077683\n",
      "Epoch 3936 / 10000 loss: 54.02148723602295\n",
      "MSE train 2.7000688976354525 MSE test 6.172006191251945\n",
      "Epoch 3937 / 10000 loss: 54.01690757274628\n",
      "MSE train 2.699851543783261 MSE test 6.171789803774398\n",
      "Epoch 3938 / 10000 loss: 54.01232039928436\n",
      "MSE train 2.6996362515267447 MSE test 6.171573362600955\n",
      "Epoch 3939 / 10000 loss: 54.00775730609894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.699423227977067 MSE test 6.171356951950888\n",
      "Epoch 3940 / 10000 loss: 54.00324070453644\n",
      "MSE train 2.699212121372652 MSE test 6.171140404533751\n",
      "Epoch 3941 / 10000 loss: 53.99877107143402\n",
      "MSE train 2.699002286520496 MSE test 6.1709236840393595\n",
      "Epoch 3942 / 10000 loss: 53.99434185028076\n",
      "MSE train 2.6987930904848065 MSE test 6.170706607977018\n",
      "Epoch 3943 / 10000 loss: 53.98994052410126\n",
      "MSE train 2.698583943207626 MSE test 6.170489044798338\n",
      "Epoch 3944 / 10000 loss: 53.9855535030365\n",
      "MSE train 2.698374364132602 MSE test 6.170270840785883\n",
      "Epoch 3945 / 10000 loss: 53.98116672039032\n",
      "MSE train 2.6981638896141606 MSE test 6.170051898766563\n",
      "Epoch 3946 / 10000 loss: 53.976768255233765\n",
      "MSE train 2.6979520599007722 MSE test 6.169832010289316\n",
      "Epoch 3947 / 10000 loss: 53.972352504730225\n",
      "MSE train 2.6977383479532926 MSE test 6.1696110680050165\n",
      "Epoch 3948 / 10000 loss: 53.967905163764954\n",
      "MSE train 2.6975221508600886 MSE test 6.169388968900656\n",
      "Epoch 3949 / 10000 loss: 53.96341872215271\n",
      "MSE train 2.6973027973521906 MSE test 6.169165533404805\n",
      "Epoch 3950 / 10000 loss: 53.95887899398804\n",
      "MSE train 2.6970795984180804 MSE test 6.168940640106504\n",
      "Epoch 3951 / 10000 loss: 53.954267740249634\n",
      "MSE train 2.6968518985713623 MSE test 6.168714157917209\n",
      "Epoch 3952 / 10000 loss: 53.949575781822205\n",
      "MSE train 2.696619169889082 MSE test 6.168486191628145\n",
      "Epoch 3953 / 10000 loss: 53.944785833358765\n",
      "MSE train 2.6963810766382195 MSE test 6.168256657009013\n",
      "Epoch 3954 / 10000 loss: 53.939884662628174\n",
      "MSE train 2.696137564832816 MSE test 6.168025705341456\n",
      "Epoch 3955 / 10000 loss: 53.93487012386322\n",
      "MSE train 2.695888841596715 MSE test 6.167793519874098\n",
      "Epoch 3956 / 10000 loss: 53.929736971855164\n",
      "MSE train 2.69563520423744 MSE test 6.167560373112217\n",
      "Epoch 3957 / 10000 loss: 53.92449176311493\n",
      "MSE train 2.69537680880369 MSE test 6.167326488279204\n",
      "Epoch 3958 / 10000 loss: 53.919140577316284\n",
      "MSE train 2.6951132496784576 MSE test 6.167092113425777\n",
      "Epoch 3959 / 10000 loss: 53.9136860370636\n",
      "MSE train 2.6948429148356405 MSE test 6.1668573924984065\n",
      "Epoch 3960 / 10000 loss: 53.90812027454376\n",
      "MSE train 2.6945625448817703 MSE test 6.166622329302342\n",
      "Epoch 3961 / 10000 loss: 53.90240514278412\n",
      "MSE train 2.694268262893095 MSE test 6.166386831877567\n",
      "Epoch 3962 / 10000 loss: 53.896474838256836\n",
      "MSE train 2.6939628569120817 MSE test 6.166150990263413\n",
      "Epoch 3963 / 10000 loss: 53.89024341106415\n",
      "MSE train 2.6936660978728253 MSE test 6.165915659418775\n",
      "Epoch 3964 / 10000 loss: 53.88376986980438\n",
      "MSE train 2.6933965089059146 MSE test 6.165682252958686\n",
      "Epoch 3965 / 10000 loss: 53.877482175827026\n",
      "MSE train 2.693149140398267 MSE test 6.165451136010779\n",
      "Epoch 3966 / 10000 loss: 53.87178182601929\n",
      "MSE train 2.692914331923449 MSE test 6.165221645009646\n",
      "Epoch 3967 / 10000 loss: 53.86656153202057\n",
      "MSE train 2.6926869369046615 MSE test 6.164993088856798\n",
      "Epoch 3968 / 10000 loss: 53.861616253852844\n",
      "MSE train 2.6924641620031413 MSE test 6.164764954668936\n",
      "Epoch 3969 / 10000 loss: 53.8568297624588\n",
      "MSE train 2.6922440732869934 MSE test 6.164536967855338\n",
      "Epoch 3970 / 10000 loss: 53.85214281082153\n",
      "MSE train 2.6920250886450656 MSE test 6.164308653148543\n",
      "Epoch 3971 / 10000 loss: 53.847514271736145\n",
      "MSE train 2.691805788641019 MSE test 6.1640797527225\n",
      "Epoch 3972 / 10000 loss: 53.84290957450867\n",
      "MSE train 2.691584910455801 MSE test 6.1638499884805755\n",
      "Epoch 3973 / 10000 loss: 53.8382967710495\n",
      "MSE train 2.6913613678347597 MSE test 6.163619104551241\n",
      "Epoch 3974 / 10000 loss: 53.833651065826416\n",
      "MSE train 2.691134284416688 MSE test 6.163386979849473\n",
      "Epoch 3975 / 10000 loss: 53.828946113586426\n",
      "MSE train 2.6909031686305895 MSE test 6.16315355262926\n",
      "Epoch 3976 / 10000 loss: 53.824167013168335\n",
      "MSE train 2.6906680729985224 MSE test 6.162918991823634\n",
      "Epoch 3977 / 10000 loss: 53.819297075271606\n",
      "MSE train 2.6904296211582794 MSE test 6.16268350478363\n",
      "Epoch 3978 / 10000 loss: 53.81434464454651\n",
      "MSE train 2.6901888277700134 MSE test 6.162447376204072\n",
      "Epoch 3979 / 10000 loss: 53.80931735038757\n",
      "MSE train 2.689946527395634 MSE test 6.16221099390179\n",
      "Epoch 3980 / 10000 loss: 53.804240584373474\n",
      "MSE train 2.6897029380451833 MSE test 6.161974481765268\n",
      "Epoch 3981 / 10000 loss: 53.79913091659546\n",
      "MSE train 2.6894575560779646 MSE test 6.1617379154614165\n",
      "Epoch 3982 / 10000 loss: 53.7939932346344\n",
      "MSE train 2.689209423686806 MSE test 6.161501063552678\n",
      "Epoch 3983 / 10000 loss: 53.78881895542145\n",
      "MSE train 2.688957487949608 MSE test 6.16126380597509\n",
      "Epoch 3984 / 10000 loss: 53.7835830450058\n",
      "MSE train 2.6887008783800845 MSE test 6.161025914806333\n",
      "Epoch 3985 / 10000 loss: 53.77826762199402\n",
      "MSE train 2.6884389573728584 MSE test 6.160787255561776\n",
      "Epoch 3986 / 10000 loss: 53.77285063266754\n",
      "MSE train 2.6881713200626036 MSE test 6.1605476530187495\n",
      "Epoch 3987 / 10000 loss: 53.767317056655884\n",
      "MSE train 2.6878977391816905 MSE test 6.160307049244377\n",
      "Epoch 3988 / 10000 loss: 53.761662006378174\n",
      "MSE train 2.68761804124635 MSE test 6.1600653142412485\n",
      "Epoch 3989 / 10000 loss: 53.7558776140213\n",
      "MSE train 2.687332060372583 MSE test 6.159822483795141\n",
      "Epoch 3990 / 10000 loss: 53.74996018409729\n",
      "MSE train 2.6870396023878715 MSE test 6.159578447027662\n",
      "Epoch 3991 / 10000 loss: 53.74390733242035\n",
      "MSE train 2.686740478381711 MSE test 6.159333231549219\n",
      "Epoch 3992 / 10000 loss: 53.73771584033966\n",
      "MSE train 2.6864346321886425 MSE test 6.159086832395289\n",
      "Epoch 3993 / 10000 loss: 53.73137819766998\n",
      "MSE train 2.68612241570574 MSE test 6.158839300437736\n",
      "Epoch 3994 / 10000 loss: 53.72489595413208\n",
      "MSE train 2.685805014010783 MSE test 6.158590729218085\n",
      "Epoch 3995 / 10000 loss: 53.71827805042267\n",
      "MSE train 2.685484920370953 MSE test 6.1583414652535895\n",
      "Epoch 3996 / 10000 loss: 53.71154463291168\n",
      "MSE train 2.685166048933142 MSE test 6.158091968981601\n",
      "Epoch 3997 / 10000 loss: 53.70475482940674\n",
      "MSE train 2.6848529997456296 MSE test 6.157842729145173\n",
      "Epoch 3998 / 10000 loss: 53.69799339771271\n",
      "MSE train 2.684549628567544 MSE test 6.157594143198466\n",
      "Epoch 3999 / 10000 loss: 53.69135558605194\n",
      "MSE train 2.6842577940969337 MSE test 6.157346485168808\n",
      "Epoch 4000 / 10000 loss: 53.68492949008942\n",
      "MSE train 2.6839771655985007 MSE test 6.157099754876634\n",
      "Epoch 4001 / 10000 loss: 53.678752303123474\n",
      "MSE train 2.6837060466198 MSE test 6.156853713179013\n",
      "Epoch 4002 / 10000 loss: 53.67282032966614\n",
      "MSE train 2.683442251103165 MSE test 6.156607970099717\n",
      "Epoch 4003 / 10000 loss: 53.6670925617218\n",
      "MSE train 2.6831835941252495 MSE test 6.156362168475406\n",
      "Epoch 4004 / 10000 loss: 53.661526799201965\n",
      "MSE train 2.682928146679852 MSE test 6.156115818179792\n",
      "Epoch 4005 / 10000 loss: 53.65607190132141\n",
      "MSE train 2.6826742985031884 MSE test 6.155868621267074\n",
      "Epoch 4006 / 10000 loss: 53.65068554878235\n",
      "MSE train 2.6824207949239747 MSE test 6.155620308453513\n",
      "Epoch 4007 / 10000 loss: 53.64533615112305\n",
      "MSE train 2.6821667800470466 MSE test 6.155370720299312\n",
      "Epoch 4008 / 10000 loss: 53.639994382858276\n",
      "MSE train 2.681911741454785 MSE test 6.155119661173302\n",
      "Epoch 4009 / 10000 loss: 53.63464152812958\n",
      "MSE train 2.681655419556599 MSE test 6.15486704991972\n",
      "Epoch 4010 / 10000 loss: 53.62926542758942\n",
      "MSE train 2.6813974821307163 MSE test 6.154612618196447\n",
      "Epoch 4011 / 10000 loss: 53.62386405467987\n",
      "MSE train 2.6811372588841076 MSE test 6.154355879216257\n",
      "Epoch 4012 / 10000 loss: 53.61842691898346\n",
      "MSE train 2.6808731608244685 MSE test 6.1540957520022515\n",
      "Epoch 4013 / 10000 loss: 53.61294341087341\n",
      "MSE train 2.680601608407809 MSE test 6.153830294236564\n",
      "Epoch 4014 / 10000 loss: 53.60737371444702\n",
      "MSE train 2.680314356838455 MSE test 6.153555879049161\n",
      "Epoch 4015 / 10000 loss: 53.60164499282837\n",
      "MSE train 2.679993613634154 MSE test 6.153266164296344\n",
      "Epoch 4016 / 10000 loss: 53.59557366371155\n",
      "MSE train 2.679627540651743 MSE test 6.152954745870153\n",
      "Epoch 4017 / 10000 loss: 53.58877921104431\n",
      "MSE train 2.6792909262075746 MSE test 6.152642247243852\n",
      "Epoch 4018 / 10000 loss: 53.58100342750549\n",
      "MSE train 2.6790090181091535 MSE test 6.152367004240058\n",
      "Epoch 4019 / 10000 loss: 53.57386529445648\n",
      "MSE train 2.6787356831836844 MSE test 6.152108333836126\n",
      "Epoch 4020 / 10000 loss: 53.56791698932648\n",
      "MSE train 2.6784616359281506 MSE test 6.151855808921008\n",
      "Epoch 4021 / 10000 loss: 53.56215453147888\n",
      "MSE train 2.6781851869553477 MSE test 6.151606135487327\n",
      "Epoch 4022 / 10000 loss: 53.55637717247009\n",
      "MSE train 2.677905811199369 MSE test 6.151357928867255\n",
      "Epoch 4023 / 10000 loss: 53.55055296421051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.6776231631886165 MSE test 6.151110631206372\n",
      "Epoch 4024 / 10000 loss: 53.54466652870178\n",
      "MSE train 2.6773373454770084 MSE test 6.1508640027698585\n",
      "Epoch 4025 / 10000 loss: 53.538713693618774\n",
      "MSE train 2.677049404811288 MSE test 6.150618205890602\n",
      "Epoch 4026 / 10000 loss: 53.53269624710083\n",
      "MSE train 2.6767612574246615 MSE test 6.150373640568064\n",
      "Epoch 4027 / 10000 loss: 53.526636838912964\n",
      "MSE train 2.676474493128886 MSE test 6.150130745763739\n",
      "Epoch 4028 / 10000 loss: 53.52057731151581\n",
      "MSE train 2.676188862580227 MSE test 6.149889958810136\n",
      "Epoch 4029 / 10000 loss: 53.514556527137756\n",
      "MSE train 2.6759022264422274 MSE test 6.149651705167704\n",
      "Epoch 4030 / 10000 loss: 53.508567333221436\n",
      "MSE train 2.675613134891249 MSE test 6.149415805541817\n",
      "Epoch 4031 / 10000 loss: 53.502564907073975\n",
      "MSE train 2.6753244740641033 MSE test 6.149182321868959\n",
      "Epoch 4032 / 10000 loss: 53.49651741981506\n",
      "MSE train 2.675042389124623 MSE test 6.148950936508067\n",
      "Epoch 4033 / 10000 loss: 53.49048364162445\n",
      "MSE train 2.67476866702057 MSE test 6.148721500126453\n",
      "Epoch 4034 / 10000 loss: 53.48458707332611\n",
      "MSE train 2.674498740812843 MSE test 6.1484937007006915\n",
      "Epoch 4035 / 10000 loss: 53.47885751724243\n",
      "MSE train 2.6742280523430835 MSE test 6.148267238676449\n",
      "Epoch 4036 / 10000 loss: 53.473198652267456\n",
      "MSE train 2.6739581774273797 MSE test 6.1480420517658105\n",
      "Epoch 4037 / 10000 loss: 53.46751415729523\n",
      "MSE train 2.6736974354307472 MSE test 6.147818482392852\n",
      "Epoch 4038 / 10000 loss: 53.46183967590332\n",
      "MSE train 2.6734522647212513 MSE test 6.147596933975267\n",
      "Epoch 4039 / 10000 loss: 53.456355810165405\n",
      "MSE train 2.673220904035683 MSE test 6.14737737307958\n",
      "Epoch 4040 / 10000 loss: 53.451205253601074\n",
      "MSE train 2.6729981278887642 MSE test 6.147159562048014\n",
      "Epoch 4041 / 10000 loss: 53.44635033607483\n",
      "MSE train 2.6727795687667286 MSE test 6.14694308581393\n",
      "Epoch 4042 / 10000 loss: 53.44168162345886\n",
      "MSE train 2.6725620897364335 MSE test 6.146727578291852\n",
      "Epoch 4043 / 10000 loss: 53.43709897994995\n",
      "MSE train 2.672343257005701 MSE test 6.146512636152651\n",
      "Epoch 4044 / 10000 loss: 53.43254208564758\n",
      "MSE train 2.6721210061172527 MSE test 6.14629795447803\n",
      "Epoch 4045 / 10000 loss: 53.427950978279114\n",
      "MSE train 2.671893630853742 MSE test 6.1460832749640435\n",
      "Epoch 4046 / 10000 loss: 53.42328977584839\n",
      "MSE train 2.6716602272269014 MSE test 6.14586838210364\n",
      "Epoch 4047 / 10000 loss: 53.418514132499695\n",
      "MSE train 2.6714215793548854 MSE test 6.145653236262307\n",
      "Epoch 4048 / 10000 loss: 53.413607597351074\n",
      "MSE train 2.6711813976544247 MSE test 6.145438067511316\n",
      "Epoch 4049 / 10000 loss: 53.40858602523804\n",
      "MSE train 2.6709459783834073 MSE test 6.145223494802813\n",
      "Epoch 4050 / 10000 loss: 53.40353190898895\n",
      "MSE train 2.670720709848751 MSE test 6.145010144672533\n",
      "Epoch 4051 / 10000 loss: 53.39858102798462\n",
      "MSE train 2.6705065544380497 MSE test 6.144798595914997\n",
      "Epoch 4052 / 10000 loss: 53.39384853839874\n",
      "MSE train 2.6703009165169522 MSE test 6.144588544614595\n",
      "Epoch 4053 / 10000 loss: 53.38935828208923\n",
      "MSE train 2.6701004182950574 MSE test 6.144379812290088\n",
      "Epoch 4054 / 10000 loss: 53.38505423069\n",
      "MSE train 2.669902196282755 MSE test 6.144172040036471\n",
      "Epoch 4055 / 10000 loss: 53.38086152076721\n",
      "MSE train 2.669704121372967 MSE test 6.1439649037011375\n",
      "Epoch 4056 / 10000 loss: 53.37671971321106\n",
      "MSE train 2.669504688514477 MSE test 6.143758153738156\n",
      "Epoch 4057 / 10000 loss: 53.372581362724304\n",
      "MSE train 2.6693029159367536 MSE test 6.14355160756941\n",
      "Epoch 4058 / 10000 loss: 53.36841344833374\n",
      "MSE train 2.669098372290341 MSE test 6.14334514416361\n",
      "Epoch 4059 / 10000 loss: 53.36419689655304\n",
      "MSE train 2.66889123532825 MSE test 6.14313867364282\n",
      "Epoch 4060 / 10000 loss: 53.35992085933685\n",
      "MSE train 2.668682358977757 MSE test 6.1429321176285505\n",
      "Epoch 4061 / 10000 loss: 53.35558772087097\n",
      "MSE train 2.6684733184680227 MSE test 6.142725531588807\n",
      "Epoch 4062 / 10000 loss: 53.35121738910675\n",
      "MSE train 2.668266279672781 MSE test 6.142518975252515\n",
      "Epoch 4063 / 10000 loss: 53.34684407711029\n",
      "MSE train 2.6680633602098154 MSE test 6.142312490047609\n",
      "Epoch 4064 / 10000 loss: 53.34251534938812\n",
      "MSE train 2.667865872789074 MSE test 6.142106158352959\n",
      "Epoch 4065 / 10000 loss: 53.338271260261536\n",
      "MSE train 2.667673906877921 MSE test 6.1418999087909345\n",
      "Epoch 4066 / 10000 loss: 53.33414602279663\n",
      "MSE train 2.6674865692159333 MSE test 6.141693682460132\n",
      "Epoch 4067 / 10000 loss: 53.330137848854065\n",
      "MSE train 2.667302562005809 MSE test 6.141487399558275\n",
      "Epoch 4068 / 10000 loss: 53.32622957229614\n",
      "MSE train 2.667120589447454 MSE test 6.1412808407787995\n",
      "Epoch 4069 / 10000 loss: 53.32239508628845\n",
      "MSE train 2.6669395138043424 MSE test 6.141073953598971\n",
      "Epoch 4070 / 10000 loss: 53.3186012506485\n",
      "MSE train 2.6667584262594763 MSE test 6.140866547084989\n",
      "Epoch 4071 / 10000 loss: 53.31482696533203\n",
      "MSE train 2.6665765682157687 MSE test 6.140658556390088\n",
      "Epoch 4072 / 10000 loss: 53.31105387210846\n",
      "MSE train 2.6663933514652878 MSE test 6.140449817116561\n",
      "Epoch 4073 / 10000 loss: 53.307262778282166\n",
      "MSE train 2.6662082818881085 MSE test 6.140240278802052\n",
      "Epoch 4074 / 10000 loss: 53.303441286087036\n",
      "MSE train 2.666020984736302 MSE test 6.140029808382526\n",
      "Epoch 4075 / 10000 loss: 53.299580812454224\n",
      "MSE train 2.6658312065686642 MSE test 6.139818388626519\n",
      "Epoch 4076 / 10000 loss: 53.29567062854767\n",
      "MSE train 2.6656387970745627 MSE test 6.1396060220714155\n",
      "Epoch 4077 / 10000 loss: 53.291707277297974\n",
      "MSE train 2.6654437684337973 MSE test 6.1393926834473636\n",
      "Epoch 4078 / 10000 loss: 53.28768742084503\n",
      "MSE train 2.665246248054866 MSE test 6.139178380794455\n",
      "Epoch 4079 / 10000 loss: 53.28360974788666\n",
      "MSE train 2.6650464789715196 MSE test 6.138963199152901\n",
      "Epoch 4080 / 10000 loss: 53.279478788375854\n",
      "MSE train 2.664844792594087 MSE test 6.138747180530562\n",
      "Epoch 4081 / 10000 loss: 53.2752982378006\n",
      "MSE train 2.6646415229577274 MSE test 6.1385303533685045\n",
      "Epoch 4082 / 10000 loss: 53.271077275276184\n",
      "MSE train 2.6644369549823956 MSE test 6.138312876827275\n",
      "Epoch 4083 / 10000 loss: 53.266823291778564\n",
      "MSE train 2.664231288437303 MSE test 6.138094740298894\n",
      "Epoch 4084 / 10000 loss: 53.26254057884216\n",
      "MSE train 2.664024609303963 MSE test 6.137875991830733\n",
      "Epoch 4085 / 10000 loss: 53.25823390483856\n",
      "MSE train 2.6638169145975734 MSE test 6.137656606019089\n",
      "Epoch 4086 / 10000 loss: 53.25390422344208\n",
      "MSE train 2.6636081253192803 MSE test 6.1374365316213355\n",
      "Epoch 4087 / 10000 loss: 53.24955487251282\n",
      "MSE train 2.6633981618242757 MSE test 6.137215698542361\n",
      "Epoch 4088 / 10000 loss: 53.24517750740051\n",
      "MSE train 2.663186898963622 MSE test 6.136994027852563\n",
      "Epoch 4089 / 10000 loss: 53.24078130722046\n",
      "MSE train 2.662974227219966 MSE test 6.136771389391059\n",
      "Epoch 4090 / 10000 loss: 53.23635375499725\n",
      "MSE train 2.6627600103204307 MSE test 6.1365476591457115\n",
      "Epoch 4091 / 10000 loss: 53.231895446777344\n",
      "MSE train 2.6625440883995375 MSE test 6.136322682231178\n",
      "Epoch 4092 / 10000 loss: 53.2274055480957\n",
      "MSE train 2.6623261909208984 MSE test 6.1360962836609625\n",
      "Epoch 4093 / 10000 loss: 53.22287690639496\n",
      "MSE train 2.662105921221053 MSE test 6.135868225443509\n",
      "Epoch 4094 / 10000 loss: 53.218307971954346\n",
      "MSE train 2.661882682024423 MSE test 6.135638205884511\n",
      "Epoch 4095 / 10000 loss: 53.21368658542633\n",
      "MSE train 2.6616556882908275 MSE test 6.13540602004058\n",
      "Epoch 4096 / 10000 loss: 53.2090003490448\n",
      "MSE train 2.6614239548119496 MSE test 6.1351713391388705\n",
      "Epoch 4097 / 10000 loss: 53.2042350769043\n",
      "MSE train 2.6611864482499588 MSE test 6.134933954427976\n",
      "Epoch 4098 / 10000 loss: 53.199365973472595\n",
      "MSE train 2.660942368777908 MSE test 6.134693820175399\n",
      "Epoch 4099 / 10000 loss: 53.19437217712402\n",
      "MSE train 2.6606914838361897 MSE test 6.134451398209957\n",
      "Epoch 4100 / 10000 loss: 53.189237117767334\n",
      "MSE train 2.6604342573965347 MSE test 6.134207497206375\n",
      "Epoch 4101 / 10000 loss: 53.18395459651947\n",
      "MSE train 2.660171205286249 MSE test 6.133963642688999\n",
      "Epoch 4102 / 10000 loss: 53.17853558063507\n",
      "MSE train 2.6599013728791547 MSE test 6.133721187837773\n",
      "Epoch 4103 / 10000 loss: 53.17299127578735\n",
      "MSE train 2.659621591400209 MSE test 6.133481023492923\n",
      "Epoch 4104 / 10000 loss: 53.16730237007141\n",
      "MSE train 2.6593291806013593 MSE test 6.133243503298995\n",
      "Epoch 4105 / 10000 loss: 53.161396622657776\n",
      "MSE train 2.6590304246428267 MSE test 6.133008607878104\n",
      "Epoch 4106 / 10000 loss: 53.15521812438965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.658742911166783 MSE test 6.132776566778491\n",
      "Epoch 4107 / 10000 loss: 53.14889883995056\n",
      "MSE train 2.6584749395303398 MSE test 6.132547625591384\n",
      "Epoch 4108 / 10000 loss: 53.142826199531555\n",
      "MSE train 2.658219926274915 MSE test 6.132321336902877\n",
      "Epoch 4109 / 10000 loss: 53.137176752090454\n",
      "MSE train 2.6579710619596044 MSE test 6.132096929066138\n",
      "Epoch 4110 / 10000 loss: 53.13180720806122\n",
      "MSE train 2.6577249169280517 MSE test 6.131873821393743\n",
      "Epoch 4111 / 10000 loss: 53.12657606601715\n",
      "MSE train 2.6574797612640064 MSE test 6.131651760190943\n",
      "Epoch 4112 / 10000 loss: 53.121399998664856\n",
      "MSE train 2.6572345740929015 MSE test 6.131430476251774\n",
      "Epoch 4113 / 10000 loss: 53.11625158786774\n",
      "MSE train 2.6569885703883465 MSE test 6.131209879123665\n",
      "Epoch 4114 / 10000 loss: 53.111101269721985\n",
      "MSE train 2.6567409760131366 MSE test 6.130989877734251\n",
      "Epoch 4115 / 10000 loss: 53.105934858322144\n",
      "MSE train 2.6564908267652054 MSE test 6.130770471537617\n",
      "Epoch 4116 / 10000 loss: 53.10073280334473\n",
      "MSE train 2.6562369134069836 MSE test 6.1305514984420535\n",
      "Epoch 4117 / 10000 loss: 53.09547805786133\n",
      "MSE train 2.6559779335533658 MSE test 6.130332894529603\n",
      "Epoch 4118 / 10000 loss: 53.09014439582825\n",
      "MSE train 2.655713049309018 MSE test 6.130114555816049\n",
      "Epoch 4119 / 10000 loss: 53.0847008228302\n",
      "MSE train 2.6554428116319837 MSE test 6.129896655090063\n",
      "Epoch 4120 / 10000 loss: 53.07913136482239\n",
      "MSE train 2.6551697444278455 MSE test 6.129679389206115\n",
      "Epoch 4121 / 10000 loss: 53.07344460487366\n",
      "MSE train 2.654897415410796 MSE test 6.12946318251964\n",
      "Epoch 4122 / 10000 loss: 53.06769847869873\n",
      "MSE train 2.6546285841504593 MSE test 6.129248388981808\n",
      "Epoch 4123 / 10000 loss: 53.06196904182434\n",
      "MSE train 2.6543645349129448 MSE test 6.1290351476822424\n",
      "Epoch 4124 / 10000 loss: 53.056315541267395\n",
      "MSE train 2.6541060432619994 MSE test 6.1288233785678585\n",
      "Epoch 4125 / 10000 loss: 53.05076587200165\n",
      "MSE train 2.653853824917513 MSE test 6.12861286791907\n",
      "Epoch 4126 / 10000 loss: 53.04533767700195\n",
      "MSE train 2.6536080853589987 MSE test 6.128403373466692\n",
      "Epoch 4127 / 10000 loss: 53.040045857429504\n",
      "MSE train 2.653367971543345 MSE test 6.1281947614855\n",
      "Epoch 4128 / 10000 loss: 53.03489410877228\n",
      "MSE train 2.6531317375763077 MSE test 6.127986697785855\n",
      "Epoch 4129 / 10000 loss: 53.02986478805542\n",
      "MSE train 2.652897206794769 MSE test 6.127779044008991\n",
      "Epoch 4130 / 10000 loss: 53.02492022514343\n",
      "MSE train 2.6526622700813314 MSE test 6.127571513410033\n",
      "Epoch 4131 / 10000 loss: 53.02001190185547\n",
      "MSE train 2.652425280268914 MSE test 6.127363992076097\n",
      "Epoch 4132 / 10000 loss: 53.01509511470795\n",
      "MSE train 2.6521857137528566 MSE test 6.127156398936146\n",
      "Epoch 4133 / 10000 loss: 53.010133147239685\n",
      "MSE train 2.6519448347342323 MSE test 6.126948710220453\n",
      "Epoch 4134 / 10000 loss: 53.005115151405334\n",
      "MSE train 2.6517057153761434 MSE test 6.126741152863058\n",
      "Epoch 4135 / 10000 loss: 53.00006854534149\n",
      "MSE train 2.6514714580359726 MSE test 6.126533985159929\n",
      "Epoch 4136 / 10000 loss: 52.99505805969238\n",
      "MSE train 2.651243027766499 MSE test 6.126327404363165\n",
      "Epoch 4137 / 10000 loss: 52.99015438556671\n",
      "MSE train 2.651019101310047 MSE test 6.126121296059612\n",
      "Epoch 4138 / 10000 loss: 52.98537290096283\n",
      "MSE train 2.65079753284362 MSE test 6.1259155686157625\n",
      "Epoch 4139 / 10000 loss: 52.98069190979004\n",
      "MSE train 2.6505763858304383 MSE test 6.1257100051606965\n",
      "Epoch 4140 / 10000 loss: 52.97606015205383\n",
      "MSE train 2.6503543168725927 MSE test 6.125504346512323\n",
      "Epoch 4141 / 10000 loss: 52.971439838409424\n",
      "MSE train 2.6501306630917894 MSE test 6.125298432116512\n",
      "Epoch 4142 / 10000 loss: 52.96679949760437\n",
      "MSE train 2.6499054325430964 MSE test 6.12509211307562\n",
      "Epoch 4143 / 10000 loss: 52.96212697029114\n",
      "MSE train 2.6496792636347957 MSE test 6.124885356577406\n",
      "Epoch 4144 / 10000 loss: 52.95741641521454\n",
      "MSE train 2.649453282702714 MSE test 6.12467816882438\n",
      "Epoch 4145 / 10000 loss: 52.95268929004669\n",
      "MSE train 2.6492287963560344 MSE test 6.12447053739991\n",
      "Epoch 4146 / 10000 loss: 52.947964549064636\n",
      "MSE train 2.649006926566363 MSE test 6.124262394764593\n",
      "Epoch 4147 / 10000 loss: 52.9432715177536\n",
      "MSE train 2.648788299738296 MSE test 6.1240537123073935\n",
      "Epoch 4148 / 10000 loss: 52.93863916397095\n",
      "MSE train 2.648572939070885 MSE test 6.123844353002305\n",
      "Epoch 4149 / 10000 loss: 52.93407499790192\n",
      "MSE train 2.6483600860199874 MSE test 6.123634019797398\n",
      "Epoch 4150 / 10000 loss: 52.92958092689514\n",
      "MSE train 2.6481481974110967 MSE test 6.123422236694363\n",
      "Epoch 4151 / 10000 loss: 52.925142765045166\n",
      "MSE train 2.647934420061058 MSE test 6.1232082813344\n",
      "Epoch 4152 / 10000 loss: 52.92072653770447\n",
      "MSE train 2.647713313272731 MSE test 6.122990976853571\n",
      "Epoch 4153 / 10000 loss: 52.91627085208893\n",
      "MSE train 2.6474748292703967 MSE test 6.122768489234767\n",
      "Epoch 4154 / 10000 loss: 52.91165637969971\n",
      "MSE train 2.6472129362359222 MSE test 6.122539414141379\n",
      "Epoch 4155 / 10000 loss: 52.90666878223419\n",
      "MSE train 2.646967369889376 MSE test 6.122310069626365\n",
      "Epoch 4156 / 10000 loss: 52.9011766910553\n",
      "MSE train 2.6467582296585843 MSE test 6.122093793529017\n",
      "Epoch 4157 / 10000 loss: 52.89603900909424\n",
      "MSE train 2.6465553574351146 MSE test 6.121884008201315\n",
      "Epoch 4158 / 10000 loss: 52.89168620109558\n",
      "MSE train 2.646351089752904 MSE test 6.121675674270334\n",
      "Epoch 4159 / 10000 loss: 52.88747262954712\n",
      "MSE train 2.6461435622466603 MSE test 6.121467316057287\n",
      "Epoch 4160 / 10000 loss: 52.88322997093201\n",
      "MSE train 2.645931730797222 MSE test 6.121258335661163\n",
      "Epoch 4161 / 10000 loss: 52.87891721725464\n",
      "MSE train 2.645714856603458 MSE test 6.12104839269941\n",
      "Epoch 4162 / 10000 loss: 52.874515414237976\n",
      "MSE train 2.645492428619485 MSE test 6.120837258528274\n",
      "Epoch 4163 / 10000 loss: 52.87000632286072\n",
      "MSE train 2.645264265518406 MSE test 6.120624835733699\n",
      "Epoch 4164 / 10000 loss: 52.86538124084473\n",
      "MSE train 2.6450304891198697 MSE test 6.120411123754939\n",
      "Epoch 4165 / 10000 loss: 52.860631585121155\n",
      "MSE train 2.6447915421728343 MSE test 6.120196246689772\n",
      "Epoch 4166 / 10000 loss: 52.855767130851746\n",
      "MSE train 2.644548082665643 MSE test 6.119980227945593\n",
      "Epoch 4167 / 10000 loss: 52.850791454315186\n",
      "MSE train 2.644300922403299 MSE test 6.1197631797189675\n",
      "Epoch 4168 / 10000 loss: 52.845720291137695\n",
      "MSE train 2.6440509292522063 MSE test 6.1195452540546835\n",
      "Epoch 4169 / 10000 loss: 52.84057116508484\n",
      "MSE train 2.6437989954658327 MSE test 6.11932648539554\n",
      "Epoch 4170 / 10000 loss: 52.835362672805786\n",
      "MSE train 2.6435458165896604 MSE test 6.119107004027842\n",
      "Epoch 4171 / 10000 loss: 52.830111622810364\n",
      "MSE train 2.643291730831904 MSE test 6.118886781021228\n",
      "Epoch 4172 / 10000 loss: 52.824835658073425\n",
      "MSE train 2.643036709619191 MSE test 6.118665901073504\n",
      "Epoch 4173 / 10000 loss: 52.81953585147858\n",
      "MSE train 2.6427804951024476 MSE test 6.118444274314204\n",
      "Epoch 4174 / 10000 loss: 52.81421482563019\n",
      "MSE train 2.642522826395494 MSE test 6.118222018423428\n",
      "Epoch 4175 / 10000 loss: 52.80886614322662\n",
      "MSE train 2.642263718243709 MSE test 6.11799930492087\n",
      "Epoch 4176 / 10000 loss: 52.8034827709198\n",
      "MSE train 2.642003410855463 MSE test 6.11777639860022\n",
      "Epoch 4177 / 10000 loss: 52.7980660200119\n",
      "MSE train 2.6417422645680726 MSE test 6.117553480369601\n",
      "Epoch 4178 / 10000 loss: 52.79261898994446\n",
      "MSE train 2.641480498047585 MSE test 6.117330752008113\n",
      "Epoch 4179 / 10000 loss: 52.78715431690216\n",
      "MSE train 2.6412180656550013 MSE test 6.117108453108493\n",
      "Epoch 4180 / 10000 loss: 52.78167283535004\n",
      "MSE train 2.640954861745951 MSE test 6.116886597666845\n",
      "Epoch 4181 / 10000 loss: 52.77617573738098\n",
      "MSE train 2.640690880282849 MSE test 6.116665231087934\n",
      "Epoch 4182 / 10000 loss: 52.770660281181335\n",
      "MSE train 2.640426410408701 MSE test 6.116444485875641\n",
      "Epoch 4183 / 10000 loss: 52.765127062797546\n",
      "MSE train 2.640162009974803 MSE test 6.116224435948728\n",
      "Epoch 4184 / 10000 loss: 52.759583592414856\n",
      "MSE train 2.639898299954213 MSE test 6.116005164522363\n",
      "Epoch 4185 / 10000 loss: 52.754040122032166\n",
      "MSE train 2.6396356891823927 MSE test 6.115786830064648\n",
      "Epoch 4186 / 10000 loss: 52.74851155281067\n",
      "MSE train 2.6393740454040886 MSE test 6.115569555235694\n",
      "Epoch 4187 / 10000 loss: 52.74300754070282\n",
      "MSE train 2.6391125303798413 MSE test 6.115353299887726\n",
      "Epoch 4188 / 10000 loss: 52.73752474784851\n",
      "MSE train 2.6388494731072396 MSE test 6.115137945689181\n",
      "Epoch 4189 / 10000 loss: 52.7320454120636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train 2.6385824682245502 MSE test 6.114923257740101\n",
      "Epoch 4190 / 10000 loss: 52.72653114795685\n",
      "MSE train 2.6383088327821023 MSE test 6.114709031222573\n",
      "Epoch 4191 / 10000 loss: 52.720935583114624\n",
      "MSE train 2.6380268086078975 MSE test 6.114495034631783\n",
      "Epoch 4192 / 10000 loss: 52.715195536613464\n",
      "MSE train 2.6377377658631893 MSE test 6.1142812944078\n",
      "Epoch 4193 / 10000 loss: 52.70927679538727\n",
      "MSE train 2.637447649767771 MSE test 6.114068217438216\n",
      "Epoch 4194 / 10000 loss: 52.703205823898315\n",
      "MSE train 2.637163724674694 MSE test 6.11385628022909\n",
      "Epoch 4195 / 10000 loss: 52.69711422920227\n",
      "MSE train 2.6368893753592926 MSE test 6.113645759833497\n",
      "Epoch 4196 / 10000 loss: 52.69115960597992\n",
      "MSE train 2.636624168883225 MSE test 6.113436447943559\n",
      "Epoch 4197 / 10000 loss: 52.68541145324707\n",
      "MSE train 2.6363664316263273 MSE test 6.113228155419297\n",
      "Epoch 4198 / 10000 loss: 52.679866313934326\n",
      "MSE train 2.636114236845357 MSE test 6.113020426439531\n",
      "Epoch 4199 / 10000 loss: 52.674485206604004\n",
      "MSE train 2.6358654837496083 MSE test 6.112813012186664\n",
      "Epoch 4200 / 10000 loss: 52.66922390460968\n",
      "MSE train 2.6356182333914724 MSE test 6.112605700865312\n",
      "Epoch 4201 / 10000 loss: 52.664042353630066\n",
      "MSE train 2.635370828107122 MSE test 6.112398280733425\n",
      "Epoch 4202 / 10000 loss: 52.65889132022858\n",
      "MSE train 2.635122022311113 MSE test 6.1121907531326585\n",
      "Epoch 4203 / 10000 loss: 52.65373623371124\n",
      "MSE train 2.6348709275307556 MSE test 6.111982968370762\n",
      "Epoch 4204 / 10000 loss: 52.64855670928955\n",
      "MSE train 2.634616949048366 MSE test 6.111774963134249\n",
      "Epoch 4205 / 10000 loss: 52.64332187175751\n",
      "MSE train 2.634359774243319 MSE test 6.1115667039482044\n",
      "Epoch 4206 / 10000 loss: 52.63802778720856\n",
      "MSE train 2.6340992557366403 MSE test 6.111358240029805\n",
      "Epoch 4207 / 10000 loss: 52.63266217708588\n",
      "MSE train 2.6338352762638393 MSE test 6.111149675099556\n",
      "Epoch 4208 / 10000 loss: 52.62722063064575\n",
      "MSE train 2.6335677079993838 MSE test 6.110941067020651\n",
      "Epoch 4209 / 10000 loss: 52.6217041015625\n",
      "MSE train 2.633296376313572 MSE test 6.110732372069643\n",
      "Epoch 4210 / 10000 loss: 52.616106390953064\n",
      "MSE train 2.6330211509300017 MSE test 6.110523687596239\n",
      "Epoch 4211 / 10000 loss: 52.61042630672455\n",
      "MSE train 2.6327420313822896 MSE test 6.110314982274582\n",
      "Epoch 4212 / 10000 loss: 52.60465955734253\n",
      "MSE train 2.63245934624114 MSE test 6.11010630538722\n",
      "Epoch 4213 / 10000 loss: 52.598803758621216\n",
      "MSE train 2.6321741499055156 MSE test 6.109897909927039\n",
      "Epoch 4214 / 10000 loss: 52.59287095069885\n",
      "MSE train 2.6318886091333424 MSE test 6.109689804724801\n",
      "Epoch 4215 / 10000 loss: 52.58687996864319\n",
      "MSE train 2.6316060147795253 MSE test 6.10948219536836\n",
      "Epoch 4216 / 10000 loss: 52.58088183403015\n",
      "MSE train 2.631329639318978 MSE test 6.109275336830763\n",
      "Epoch 4217 / 10000 loss: 52.57494270801544\n",
      "MSE train 2.6310612921167493 MSE test 6.109069481044273\n",
      "Epoch 4218 / 10000 loss: 52.569135904312134\n",
      "MSE train 2.6308010569927136 MSE test 6.108864556580216\n",
      "Epoch 4219 / 10000 loss: 52.563499450683594\n",
      "MSE train 2.6305481378031956 MSE test 6.108660602789751\n",
      "Epoch 4220 / 10000 loss: 52.558034896850586\n",
      "MSE train 2.6303017345140165 MSE test 6.108457546098\n",
      "Epoch 4221 / 10000 loss: 52.55272567272186\n",
      "MSE train 2.6300613642318957 MSE test 6.10825524772519\n",
      "Epoch 4222 / 10000 loss: 52.54755449295044\n",
      "MSE train 2.6298267707205163 MSE test 6.108053591175925\n",
      "Epoch 4223 / 10000 loss: 52.542511343955994\n",
      "MSE train 2.629597858240225 MSE test 6.107852520141139\n",
      "Epoch 4224 / 10000 loss: 52.537590861320496\n",
      "MSE train 2.6293744221965603 MSE test 6.107651949942195\n",
      "Epoch 4225 / 10000 loss: 52.53279209136963\n",
      "MSE train 2.6291560586181872 MSE test 6.107451738897366\n",
      "Epoch 4226 / 10000 loss: 52.528109669685364\n",
      "MSE train 2.628942098834882 MSE test 6.107251795467774\n",
      "Epoch 4227 / 10000 loss: 52.523537158966064\n",
      "MSE train 2.628731698221286 MSE test 6.107052100862209\n",
      "Epoch 4228 / 10000 loss: 52.51905870437622\n",
      "MSE train 2.6285240488050974 MSE test 6.1068524778395386\n",
      "Epoch 4229 / 10000 loss: 52.51465678215027\n",
      "MSE train 2.628318581772317 MSE test 6.1066529752697285\n",
      "Epoch 4230 / 10000 loss: 52.51031136512756\n",
      "MSE train 2.6281151547274044 MSE test 6.106453562231066\n",
      "Epoch 4231 / 10000 loss: 52.50601351261139\n",
      "MSE train 2.6279141648076676 MSE test 6.106254365916464\n",
      "Epoch 4232 / 10000 loss: 52.501760840415955\n",
      "MSE train 2.627716417042326 MSE test 6.106055520933662\n",
      "Epoch 4233 / 10000 loss: 52.49755847454071\n",
      "MSE train 2.627522775756137 MSE test 6.105857140234931\n",
      "Epoch 4234 / 10000 loss: 52.493428111076355\n",
      "MSE train 2.6273337613226224 MSE test 6.105659419878715\n",
      "Epoch 4235 / 10000 loss: 52.48938298225403\n",
      "MSE train 2.627149276117047 MSE test 6.105462294457448\n",
      "Epoch 4236 / 10000 loss: 52.48544001579285\n",
      "MSE train 2.626968749784174 MSE test 6.105265762386868\n",
      "Epoch 4237 / 10000 loss: 52.481595039367676\n",
      "MSE train 2.626791277216453 MSE test 6.105069659059836\n",
      "Epoch 4238 / 10000 loss: 52.47783279418945\n",
      "MSE train 2.626615880705464 MSE test 6.104873789188523\n",
      "Epoch 4239 / 10000 loss: 52.47413766384125\n",
      "MSE train 2.6264415419955593 MSE test 6.104677885862223\n",
      "Epoch 4240 / 10000 loss: 52.470489263534546\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-107a6cd440f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(epoch_x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepoch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeansq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "hm_epochs = 10000\n",
    "tot_users = X_train.shape[0]\n",
    "# print(tot_users)\n",
    "\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0    # initializing error as 0\n",
    "    for i in range(int(tot_users/batch_size)):\n",
    "        # print(epoch_x)\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],feed_dict={input_layer: epoch_x, output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer, feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer, feed_dict={input_layer:X_test})\n",
    "    print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))      \n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a user\n",
    "sample_user = X_test.iloc[99,:]\n",
    "# get the predicted ratings\n",
    "sample_user_pred = sess.run(output_layer, feed_dict={input_layer:[sample_user]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "v1 = sess.run(hidden_1_layer_vals)\n",
    "f = open(\"weights.pkl\",\"wb\")\n",
    "pickle.dump(v1,f)\n",
    "f.close()\n",
    "\n",
    "v2 = sess.run(output_layer_vals)\n",
    "f = open(\"weights-output.pkl\",\"wb\")\n",
    "pickle.dump(v2,f)\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
