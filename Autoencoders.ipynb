{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# reading the ratings data\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv', sep=\",\")\n",
    "ratings_pivot = pd.pivot_table(ratings[['userId', 'movieId', 'rating']], \n",
    "                               values='rating', index='userId', columns='movieId' ).fillna(0)\n",
    "# creating train and test sets\n",
    "X_train, X_test = train_test_split(ratings_pivot, train_size=0.8)\n",
    "# print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many nodes each layer should have - Depending on the dataset's size\n",
    "n_nodes_inpl = 9724  \n",
    "n_nodes_hl1  = 256  \n",
    "n_nodes_outl = 9724  \n",
    "# first hidden layer has 9724*256 weights and 256 biases\n",
    "hidden_1_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_inpl+1, n_nodes_hl1]))}\n",
    "output_layer_vals = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1+1, n_nodes_outl]))}\n",
    "\n",
    "input_layer = tf.placeholder('float', [None, 9724])\n",
    "\n",
    "input_layer_const = tf.fill([tf.shape(input_layer)[0], 1], 1.0)\n",
    "input_layer_concat = tf.concat([input_layer, input_layer_const], 1)\n",
    "\n",
    "layer_1 = tf.nn.sigmoid(tf.matmul(input_layer_concat, hidden_1_layer_vals['weights']))\n",
    "\n",
    "layer1_const = tf.fill( [tf.shape(layer_1)[0], 1], 1.0)\n",
    "layer_concat =  tf.concat([layer_1, layer1_const], 1)\n",
    "\n",
    "output_layer = tf.matmul(layer_concat, output_layer_vals['weights'])\n",
    "output_true = tf.placeholder('float', [None, 9724])\n",
    "meansq = tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "\n",
    "learn_rate = 0.1   # learning rate\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)\n",
    "\n",
    "# initializing variables and starting the session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "writer.close()\n",
    "sess.run(init)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with one hidden layer\n",
    "\n",
    "![autoencoder with one layer](Images/autoencoders-1layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch size, number of epochs and learning rate\n",
    "batch_size = 100  # how many points to use together for training\n",
    "hm_epochs = 200    # how many times to go through the entire dataset\n",
    "tot_users = X_train.shape[0]\n",
    "# print(tot_users)\n",
    "# running the model for a 200 epochs taking 100 users in batches\n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0    # initializing error as 0\n",
    "    for i in range(int(tot_users/batch_size)):\n",
    "        # print(epoch_x)\n",
    "        epoch_x = X_train[ i*batch_size : (i+1)*batch_size ]\n",
    "        _, c = sess.run([optimizer, meansq],feed_dict={input_layer: epoch_x, output_true: epoch_x})\n",
    "        epoch_loss += c\n",
    "        \n",
    "    output_train = sess.run(output_layer, feed_dict={input_layer:X_train})\n",
    "    output_test = sess.run(output_layer, feed_dict={input_layer:X_test})\n",
    "    print('MSE train', MSE(output_train, X_train),'MSE test', MSE(output_test, X_test))      \n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a user\n",
    "sample_user = X_test.iloc[99,:]\n",
    "# get the predicted ratings\n",
    "sample_user_pred = sess.run(output_layer, feed_dict={input_layer:[sample_user]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
